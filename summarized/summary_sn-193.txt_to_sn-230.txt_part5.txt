GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#193

DATE:		April 23, 2009

TITLE:		Conficker

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-193.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's security news; then they closely examine the detailed operation and evolution of "Conficker," the most technically sophisticated worm the Internet has ever encountered.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 193 for April 23, 2009:  Conficker.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!.  We're ready to cover your security butt with Mr. Steve Gibson from the Gibson Research Corporation, creators of the SpinRite, the fabulous SpinRite disk maintenance and recovery utility, and discoverer of spyware, and our security guru.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again this week.



LEO:  Welcome back.



STEVE:  As always.  As we approach our 200th episode.  We're at 193 and counting.



LEO:  Wow.



STEVE:  So actually I'm excited about 208, since that will be four times 52, meaning that it's the end of our fourth year as we go into our fifth.



LEO:  And only you can do that math because only you do a show every week.  You're amazing.



STEVE:  Never missed one.



LEO:  He's the Iron Man of podcasting.



STEVE:  And it's so funny, too, because when you first suggested this years ago, I thought, well, Leo, I kind of like the idea, but there's no way we're going to have enough to talk about.  And now we've got people complaining that I have promises for future episodes backed up.



LEO:  You, too.  We're backed up.



STEVE:  Just can't get to them.



LEO:  I love it.



STEVE:  But we will.  We will.  We will.



LEO:  Well, let's start - we're going to talk about, I think, the number one security topic of the month, the year, who knows, maybe the decade:  Conficker.



STEVE:  Well, yes.  I don't think we've ever really gone into great depth about any previous worms or, for that matter, viruses because there really hasn't been that much to them.  I mean, it's like, okay, so MSBlast sprays the Internet with packets trying to spread.  Well, Conficker is interesting to me and to our, I'm sure to our audience and the broader Internet because it is a phenomenally sophisticated worm.  It's defying all attempts at eradication.  It is managing to survive.  The author is dynamically updating it, literally in lockstep with all attempts to thwart it that have been made by the industry and the so-called Conficker Cabal, which is a group of whitehat companies, Microsoft and the AV companies that are getting together to deal with it.  But there's so much to it.  And so it just, you know, it would make for a really interesting and meaty episode.  So I decided let's really talk about exactly what Conficker does.  And my feeling is, by the time we're through with our listeners today, Leo, there'll be a greater sense of respect for how bad and sort of deeply bad these things can be.  I mean, there's just so much this thing does.



LEO:  Well, as you say, you couldn't really do it ever before.  I mean, the stuff was...



STEVE:  There wasn't much to talk about.



LEO:  It was, I mean, I guess you could say, wow, isn't it interesting that they're using email now to spread, or that they're able to live on the 'Net.  But there wasn't great programming involved.  This sounds like this is pretty sophisticated.



STEVE:  Well, it digitally signs its transmissions...



LEO:  Incredible.



STEVE:  ...to prevent anyone from being able to spoof them.



LEO:  State of the art.  This is state of the art.



STEVE:  We're going to talk about it all today.



LEO:  So what is the security news?  What's going on in the wonderful world?



STEVE:  Lots of stuff here.  You probably heard that a verdict came down in the Pirate Bay case.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  The four guys that were the defendants were found guilty of breaking Swedish copyright law for their involvement in the Pirate Bay website.  Three were the maintainers of the site, and one was the financier.  They were sentenced to one year each in prison and ordered to pay 30 million Kroner, which is about 3.5 million U.S. dollars, to various media companies who brought the suit.  They plan to appeal the verdict, so we don't know how that will turn out.  They were as defiant as ever, I mean, these are the most defiant guys you've ever seen.  But it was a significant verdict in that, despite the fact that their defense was that they are not hosting copyrighted content, the argument was, yes, but they're making it - they're facilitating the clear violation of the copyright holders' rights.  And that was enough to find them guilty.



LEO:  They are probably judgment-proof.  They've already said we don't have the money, we don't intend to pay it, we're appealing.  And really, however you feel about them, the bottom line is it hasn't shut the Pirate Bay down.  It won't because, as they say on their page, we are from the Internets.  You can't stop us.  And, you know, they make an interesting point.  I wonder what you think about this?  They say we're just a search engine, in the same way that Google's a search engine.  Are you going to take Google to court because you can search for pirated stuff on Google?



STEVE:  That's, I mean, that is a good point.  My - yeah, I mean, I guess it's gray.  I'm trying to think whether I've ever needed anything from there.



LEO:  No.



STEVE:  I don't think so.  I don't think so.



LEO:  I mean, let's face it.  The name kind of says it all.  They're not really saying we're just a...



STEVE:  Yeah, but again, you know, we can't, I mean, part of free speech is you get to name things what you want, and that's too tough if people don't like what you chose.



LEO:  Well, the courts ruled, and that's the bottom line.  And I know that the recording industry and the movie industry are happy as can be.



STEVE:  Yeah.  Well, in another interesting bit of news, Amazon.uk has been the first of a number of high-profile companies to announce that it is going to block Phorm from scanning its pages.



LEO:  Right on.



STEVE:  Yeah.  Phorm, of course, we've talked about.  We brought up some news about it last week, in fact.  P-h-o-r-m is the really sort of nasty, very invasive technology that ISPs are still toying around with deploying, even though its technology is completely unproven.  I mean, it's amazing how much negativity is being generated by this company where it's not even clear that what they're doing is going to be effective.  You know, they end up planting their own cookies in every single website you visit. So your browser ends up just stuffed with their cookies because they add them to every site you visit by intercepting your connection to ISPs and dynamically seeding your web browser.



So anyway, the reason they scan pages is when people go to a site - like somebody who's using unfortunately a Phorm-enhanced ISP would go to Amazon.uk.  Well, the Phorm servers would be notified of that. They perform a keyword search of the site you go to, like Amazon, to figure out what kind of site it is.  And then on the fly they inject their own advertising, which is supposed to be germane to where you are.  So Amazon is saying we're going to block Phorm from doing keyword search scans on our website and actively resist it.  And there's an open rights group based in the U.K. that has asked, you know, high-profile websites like Amazon, AOL, Microsoft, eBay, YouTube and so forth, to opt out of participating with Phorm.  And so Amazon in the U.K. is the first one to do so.



LEO:  Good.



STEVE:  So congratulations for them.



LEO:  Big victory for all privacy advocates.



STEVE:  Yeah, that's just - again, it's that there is no informed consent.  I have no problem, and most people have no problem, if a user formally says - and that's not p-h-o-r-m phormally, it's formally...



LEO:  Officially...



STEVE:  ...with great formality.



LEO:  Yes.



STEVE:  If they formally allow Phorm to do this, then fine.  Then get tracked and have your browser filled with cookies and so forth.  But the whole problem is that this is just, well, in fact the suit that's being brought by the European Commission is due to the fact that there was no consent provided during British Telecom's, BT's, previous secret testing of this technology.  It was just being done to users without their knowledge or permission.  So that's not okay.



LEO:  Yeah.



STEVE:  One other little bit of news is that - or actually two more.  One is that there was a report put out by Verizon Business that said that it had responded in '08 to at least 90 confirmed data breaches involving on the order of 285 million consumer records.  And what was worrisome about this, I mean, this is a huge number, 285 million consumer records.  What was most worrisome was that the number of breaches and the size of the breaches in total was larger than all of the breaches in '04, '05, '06, and '07.  So '08 dwarfed the sum of breaches in the previous four years.



LEO:  Holy cow.  I mean, I knew it was bad, but I didn't know it was that bad.  Wow.



STEVE:  And interestingly, it turns out that the breaches at banks and financial institutions were responsible for 93 percent of all such records compromised last year.  So, I mean, these are high-value targets.  Now, in a strange little twist, there's a side effect of this.  So much of this material, stolen consumer records, is now available on the black market, that the prices have fallen on the black market, and the bad guys are not any longer making as much money as they used to.



LEO:  I guess that's good.



STEVE:  Because they're wading around in all of this stuff.



LEO:  I guess that's a silver lining.



STEVE:  Yeah, I'm not so sure, but...



LEO:  It's not that good.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  And then the last little bit of news, I'm sure you picked up on this one, too, is that the Pentagon found spies in the network for the Joint Strike Fighter project.  This is the $300 billion program that the Pentagon is running.  It's the most sophisticated weaponry we have yet.  The network was hacked.  And get this:  Several terabytes of files, which were encrypted by the bad guys before leaving the network, so no one knows exactly what it was that was taken, but several terabytes of data over the last about a year and a half.



LEO:  This is unconscionable.



STEVE:  They know that it was the design and the avionics material were siphoned off and sent somewhere.  They don't know where.



LEO:  Awful.



STEVE:  It's believed to be China.  But again, as we've said, it's impossible to really nail down full accountability on these things.  So but it was a big concern and a black eye for the Pentagon.  And, I mean, and I really hope that we begin paying attention to this because it just seems like this is rapidly on the rise.  This is the most publicized, worst such incident we've seen so far.



LEO:  Steve, how do you explain this?  This is not something that is hard to protect.  These are valuable, hundreds of billions of dollars' worth of valued state secrets.  First of all, why is this stuff even on Internet-connected computers?



STEVE:  Yeah, I know.



LEO:  Why is it not secured, if it is?



STEVE:  The Wall Street Journal's report indicated that the most sensitive of the material is on a separate network which is not connected to the Internet.  So there is some sense of that.  But clearly this material, which is on Internet-connected machines, should also not have been in that network.  I mean...



LEO:  It's not rocket science.  We know how to protect this stuff; right?



STEVE:  Yes, yes.  I mean, we do in theory.  And in fact that's why I'm so very nervous about the push that we're seeing towards medical records being put online.  It's like, oh, goodness.  I mean, I recognize we want to bring our healthcare costs down in the U.S., and it's one of the current administration's major pushes.  But it's like, you know, there's just no demonstration that government knows how to do this.  And I haven't yet seen a smart government person.  I mean, that's sort of an oxymoron, I mean, in terms of, like, technology and real security protection.



LEO:  Well, come on, the NSA must have smart people.  There  must be some smart people.  You think these people are just dufuses?



STEVE:  But then is it bureaucracy that prevents, I mean...



LEO:  I can't figure it out.



STEVE:  Yeah, I agree, the NSA down deep in some think-tank behind locked doors with all kinds of authentication, they've got really, really good people.  But it's very much like you don't put your good people on tech support.  You put them on development.  And so the people doing tech support, it's too expensive to have a good person and have them talk to customers.  So you have sort of an okay-enough person who deals with customers, and maybe they're able to escalate that to somebody who's more capable.  Similarly, the NSA is not going to have their really good guys doing IT networking because there's, like, really more important things that they need to be doing.



And but again, I mean, this sort of comes back to my rant, which I will not recap, from last week, where I was talking about how much we have grown to put up with Windows.  And I was reminded that, speaking of Conficker, that it knocked the, I think it was the Sheffield Hospital chain in the U.K. off the 'Net, I mean, out of operating mode for some length of time because the equipment in the operating theater was running Windows and was on the Internet.  So, first of all, it's worrisome that critical care equipment would have Windows as its operating system, and also critical that it would be on the Internet.  It's like, oh, well, we turned off Windows Update because the machines used to reboot in the middle of an operation.  Like, oh, what, how many things can you have wrong with the picture?



LEO:  But this I understand.  I understand this.  But this is the nation's most critical military secrets.  And they're not only sitting on the Internet, but they're apparently doing so with no really good protection.



STEVE:  Yeah.



LEO:  I mean, if you had these military secrets in your house, Steve, you could lock them down.  Right?



STEVE:  Yes, I could, actually.  Although...



LEO:  Yes,  you could.



STEVE:  ...my world is much simpler.  In fairness, my world is much simpler.



LEO:  I guess they have contractors who are looking at the plans online, or there's some sort of, I mean, there's something going on.



STEVE:  It's like, oh, don't worry, we'll just put this little website up that allows you to do vendor agreements or something, and so there's some cross-site scripting vulnerability that allows them to get into the server.  There was a guy many, many years ago, maybe ten years ago, who used to call me through, I mean, literally like sci-fi mode, linking through multiple satellites and jumping around between different points so that I couldn't track him back.  And he protected his identity.  And he used to tell me in detail how he was roaming around inside of Microsoft's most sensitive networks, and how he would find some entry point in the U.K. through an affiliate, that he was able to bridge across network interface cards from an external network to the internal network and then jump from there over through two other offices to Redmond, and convinced me through what evidence he produced that he was really doing this.



And it's because, as you say, Leo, these networks are incredibly complex, lots of interconnections.  And at some point doubtless this network was established by people who knew what they were doing, and it was really bolted down and secure.  But then over time stuff got added.  I mean, all it takes is for someone to stick an infected USB thumb drive into any machine on that network.  And unfortunately, if it's running Windows, and it's processing autorun.inf files, and it may have been stuck in a laptop before that that had Conficker B on it, because Conficker version B would jump over to removable drives when they appeared, that's all it would take to suddenly have the malware on that machine.  Or as we know, social engineering attacks are highly effective.  So some Excel document or plans or something was sent to somebody who was expecting them.  And sure enough, there was a virus that rode in, some sort of malware came in.



And so it's not that hard to set these things up so at the start they're secure.  But it's really difficult over time to maintain that level, that initial level of vigilance.  And I think that's what happens is it's like, well, we'll just connect this up briefly, or I'll just open a port in my firewall just for some specific event, and then we forget.  And it stays open, and something crawls in.



LEO:  It just seems to me this isn't rocket science.  And it should be something that, look, I understand if a bank gets hacked.  I understand if a hospital gets hacked.  I don't want our military secrets to get hacked.  I mean, there are just certain things - or our infrastructure, our grid.  I hope we've learned - I think we've learned something here, ladies and gentlemen.



STEVE:  The experts who were asked about this said that the nature of this breach is such that it arguably makes - whoever it is who received the information would have received enough to do a much better job at defending against what this technology is meant to do for us.



LEO:  You know, we did the Blackbird, the stealth bomber, the stealth fighter.  All of that was secret.  We got the jump on them.  We did the Manhattan Project.  We got the jump on them.



STEVE:  Yeah.  The good news was there was no Internet back then.  I mean, this global network really is a mixed blessing.  I mean, I don't have to tell any of our listeners that.  It is...



LEO:  Well, take it off the freaking public Internet, then, if you can't figure it out.  Right?



STEVE:  And, see, that's the other problem, too, is that because it is - the positive side, the Internet can be so useful that not having connectivity starts to become an increasing problem where it's like, wait a minute, we can't not be on the Internet in order to be in business.  I mean...



LEO:  Well, couldn't they make - I mean, look.  If it's defense contractors, I mean, okay, legitimately they might need a network to see this stuff.  But they could do a VPN and secure it and not allow public Internet access.  You shouldn't be surfing the 'Net on a machine that has the plans.  I mean, it just seems like there's ways to do this.  Maybe I'm wrong.  Maybe it's not a nontrivial thing.



STEVE:  I'm sure that this system was far more sophisticated than the typical corporate or home network.



LEO:  Oh, I would hope, yeah.



STEVE:  I mean, there's no doubt about it.  But clearly, whatever, however it was this actually happened, and we have no details about the actual details of how this happened, but I'm sure that it was somebody on the outside really wanting to get access to this who spent time working on how to do it.  And the problem is that we've seen digital technology is a little more analog than we wish it were.  Sure, everything is a one or a zero.  But there are ways around absolute protections like firewalls.  Which you'd think, okay, that's an absolute protection.  It's like, well, yes.  But what if the firewall itself, I mean, Cisco just did, as we reported, did a recent patch of IOS.  There were a bunch of problems with the Cisco IOS.  So anyone who's using defensive technology is depending upon the defensive technology itself to be safe and accurate and correct.  But if it's not, and we keep seeing instances where it's not, then that creates a way in.  I mean, unfortunately, complexity is the enemy of security.  And we do keep making these systems more and more complex.  Which makes them harder and harder to secure.



LEO:  Yeah, yeah.  Okay.  I'm going to get - I'm going to calm down here.



STEVE:  I had something interesting happen that I just wanted to bring up to our users as a little bit of errata.  One of the things that Microsoft did in XP that was very nice was they limit file and printer sharing to your local network.  That is, it's like, okay, why didn't they do this a long time ago?  But it's nice that they did it.  So if you look under the firewall configuration, when a default install of Windows XP, that is, everyone's XP, and Vista for that matter, that is in use will have file and printer sharing enabled by default.  And what that means is that you've got frightening services listening on ports 137, 139, and 445, the standard really scary ports that Windows has.  Well, when you're behind a router, as we know, your network is protected by the router.  Nothing can come in through those ports in the normal case.  Well, we're going to be hearing about an exception to that when we talk about Conficker in a minute. But normally you're safe.



Well, Microsoft enhanced the protection by not allowing packets to leave the LAN, the Local Area Network.  And so file and printer sharing is on by default.  But even if you had access to the global Internet, file and printer sharing is protected.  So it will not allow traffic to come in from a global address, only from a local address.  So that seems fine.  Except it occurred to me the other day when I was at Starbucks that, with their change to AT&T - they used to be T-Mobile, they're now AT&T - we  lost all encryption.  So Starbucks, for example, corporate, is an open WiFi network.  You need - there's, like, an intercept page.  It's not an open hotspot in that someone could just walk in and get on the Internet.  So you've got to - there's all kinds of rigmarole they've got with register your Starbucks cards and so forth.  I still have my T-Mobile account, so I'm able to use my T-Mobile account through the AT&T interface.  But it's an open, that is, it's a nonencrypted network.



What occurred to me is, ah, right, that means not only is all the traffic sniffable, but everybody's laptop in a given Starbucks location is by definition on the same LAN.  Which means all of our file and printer sharing ports are open to each other by default.  Which is, for example, exactly what something like Conficker wants because it scans the local network looking to make TCP connections on port 445.  So I don't know what people's habits of use of their laptops are.  But I wanted to remind people that it is very simple, if you do not need file and printer sharing for your WiFi connection, it's easy to unbind it, is the term, from the WiFi adapter.  Leave it bound to your regular hard-wired Ethernet adapter so when your laptop is plugged in, physically plugged in at home, given that you...



LEO:  Oh, that's a good idea.



STEVE:  ...plug it into a wire, there you've got file and printer sharing.  But unless you really need file and printer sharing wirelessly, I absolutely strongly recommend that it's just a matter of turning off the checkbox for file and printer sharing, and also to turn off NetBIOS, which is still in there for some reason, turn that off.  And then those ports are not open, those protocols are not available to wireless, which is - because you never know where you're going to be hooking into a non-encrypted network.  You figure you're secure because you're behind, like, the corporate firewall or a NAT router.  But you are participating in a LAN with everybody else on the LAN.  So you're implicitly trusting every other machine on the LAN not to be going after yours.  And it might well be.  One or more might well be.



LEO:  Right.



STEVE:  Certainly that's the case if you've got Conficker anywhere on the LAN, as we'll be discussing.



LEO:  That's a nice little fix, simple little thing to do, though.  Just disable it on the WiFi.



STEVE:  Yes, exactly, just unbind it from WiFi.  And I have an interesting little report of success from someone named Jerry who sent us email saying, "Just a thank-you note."  He said, "Steve, I bought SpinRite v6 last year, and it saved my butt then.  But I'm writing to let you know how much I appreciate the product now.  You see, I couldn't make a disk image of my laptop's hard disk drive.  I kept getting write error or disk full error messages.  Well, the disk wasn't full, so it had to be a write error.  I ran chkdsk /f and /r, but no errors were found.  So I ran SpinRite v6 in mode 2, and it also found no errors, either.  A retry of creating a disk image was still unsuccessful.  So I turned again to SpinRite and found that I could change the mode, SpinRite's mode, while it was running mode 2.  I changed the mode where it reads and rewrites the data.  That was just what was needed.  I guess some of the data was weakly stored.  The data was strong enough to be read properly by chkdsk and SpinRite mode 2, but not strong enough to pass a verification test between it and its image.  By having SpinRite I saved myself untold trouble of having to buy another hard disk drive and transferring data to it.  Who knows how that would have gone?  I just had to let you know how much I appreciate this product. Grace and peace, Jerry."



LEO:  Isn't that nice.



STEVE:  So another happy SpinRite success story.



LEO:  Happy SpinRite customer.



STEVE:  Love those.



LEO:  All right, Steve.  Let's talk Conficker.



STEVE:  Now, I want to - I need two ground rules laid first.  Or, well, okay, one ground rule and a little bit of technology.  I'm sure people understand, they know me well enough to know that when I say I'm impressed by something, it doesn't at all mean that I'm endorsing it or thinking it's a good idea.  There is a lot of state-of-the-art impressive technology in Conficker.  It's not bleeding edge, by any means.  It's not something no one has seen before.  It's that somebody who was not your typical script kiddy, who was not taking stuff somebody else did and just sort of mindlessly duplicating it, but whoever is the author or authors of this series of, this genus of worms, because we've had now four of them, and there's maybe a fifth one on the way, they really understand this technology.



So it's certainly the case that anybody who really understands networking, I mean, I could write Conficker.  There's any of the smart guys in networking, security companies could write Conficker.  I mean, you know, it's not like this is rocket science.  But this is unique for what it is, that is, that it is - it's been done in a way that is really reacting in lockstep to the industry's attempts to counteract it.



LEO:  How good would you say the guy or guys who wrote this are?  I mean, you said you could do it, any competent security professional could do it.  But can you look at the coding and say this guy knows what he's doing?  Is he a professional?  Is he a kid?  Do you have any sense of that?



STEVE:  Yeah, I would say - I guess I don't know, I mean, first of all, somebody can be good at any age.  So we don't have any sense for their - there isn't any nonsense in it.  For example, some of the early bots had, like, used four-letter-word slang.



LEO:  Variables, right, yeah, yeah.



STEVE:  Which sort of made you think, okay, we were a little maturity-compromised here in this case.  There isn't any of that.  It's...



LEO:  Can you see variable names?  You can't, can you?



STEVE:  Well, no, but...



LEO:  We don't have the source code, but you can disassemble it.



STEVE:  They weren't variable names.  They were, like, embedded strings in the executable where it was just like, okay, this is not somebody we need to take too seriously.  Although their tools were oftentimes potent.  But because they had patched these, patched codes that they got from somewhere else.  This is clearly being written by somebody who knows what they're doing.  And as I said, by the time we're through discussing this in detail, I think that our listeners are going to have a strong sense for, it's like, okay.  In many ways this raises the bar.  Conficker has gotten a huge amount of press.  It's been dissected by really smart guys.  And so there's now, like, okay, anybody else who's going to do a worm is likely going to do everything Conficker does.



Now, it is worth giving this guy credit for several things.  There is new technology in this, for example, the way it generates its domain names, that we haven't seen before.  It's like what some good guy who, I mean, someone who's really networking-aware who sat down and said, okay, how can I have malicious code scattered around the Internet somehow find a server to update itself and prevent somebody from reverse engineering the code to see what the domain is that I'm going to be contacting?



For example, back when I was tracking down the IRC-driven botnet that was attacking GRC many years ago, I was able to look at the traffic, see what the IRC server was that the bot was contacting.  And then I wrote my own pseudo-IRC client and logged into the same channel on the IRC server and watched all the bots talking with sort of my own version of an IRC client.  Well, so I was able to do that because there was a static domain name that all of the bots in that particular network were contacting.  Well, Conficker doesn't do anything like that.  Conficker has a whole - several aspects of next-generation-ness to it.  So while the technology is not surprising, the fact that it has been employed is arguably surprising and unique.  So that's really what's new.



Okay.  The second thing is I need to explain what a "thread" is because Conficker is highly multithreaded.  And I realized as I was preparing my notes for what I want to discuss that, I mean, I live in thread land.  Threads are one of my favorite abstractions in programming.



LEO:  Threads R Us.



STEVE:  But if people don't understand what a thread is, for me to say, oh, and it spawns three threads to do this, they're going to be, like, what?  What's the spawning of a thread?



LEO:  Right.



STEVE:  So a thread is an abstraction of computer execution.  Everyone's sort of familiar probably with the notion that a computer does one thing at a time.  It executes one little instruction - add two things together - and then maybe another one:  Oh, if the result is greater than something, then jump to here, and then do something else.  So the point is, as we know, computer programs are one thing at a time.  And it's because the computers are very fast that all those little things add up to something substantial like recalculating your spreadsheet or 3D rendering at Disney, I mean, phenomenally amazing stuff comes out of just lots of little additions and multiplications and decisions being made one at a time.



Well, as computer science has evolved, it's been nice to have a program, a single program being able to sort of do more than one thing at a time.  Windows had one approach, which is a so-called messaging paradigm, where you'd have a so-called message loop, and it would go and do something, then come back to the message loop and get the next thing to do and go do that and then come back.  And so it kind of kept checking back in.  Well, that was one way of creating sort of a feeling of asynchronous events.



A different way is through something called a thread.  So if you imagine this series of steps I was talking about - doing one thing at a time, add, compare, jump, store, load, one thing - now, if you imagine that's a chain of instructions or so-called a thread of execution, then it's possible to have one thread spawn, that is, start another thread, so it sort of forks into two chains of execution.  Now, we know that the computer itself can only be really doing one thing at a time.  Now, that's evolved a little bit as we have, like, a multicore processor where we actually have multiple cores.  But if we just take the case of a single processor, this model actually works well no matter how many cores you have.



What happens is a thread is going along happily doing its thing, and then it's preempted.  That is, the operating system says, okay, you've had enough time.  We're going to switch over to another thread, the other thread, for example, if there were two, and let it run for a while.  Well, this switching happens so quickly and so often that the effect is that two things are being done at once.  And in fact there's no practical limit to how many you can have.  At some point, if you have thousands of threads, or maybe tens of thousands of threads, well, switching among them all becomes a problem because it takes so long to get back to any one thread, and then you begin to have some overhead associated with switching threads.  So you don't want to have a bazillion.



But something like Conficker is doing many things at once.  It's checking to make sure that you're not running antivirus programs, and that's one thread's doing that.  So one thread, sort of a separate, a little spawned-off worker, its full-time job for that one thread is making sure that anything that you start up that might be used to shut it down doesn't have a chance to get going.  Then another thread is camped out on some listening TCP and UDP sockets, actually one thread per socket, so that if anything comes in and attempts to establish a connection, that thread will wake up and say, oh, hi, glad to see you, come on in, send me your data, and we'll see what's going to go on.



So I wanted to explain that's what a thread is.  It's a beautiful abstraction.  I call it an abstraction because, in the case of a single processor core, the processor core is only doing one thing at a time.  And so in Windows we've got multiple applications, and the multiple applications probably have multiple threads.  So this one processor is jumping all over the place, not only between individual applications, but between parts of the application where each part is a thread.  And again, it's because the system is so fast that it all sort of seems like everything's moving forward and alive and running simultaneously, when in fact literally it's timesharing.  So this thread-jumping is a sort of a form of time-sharing within a single application.



What's cool about multiple cores is, if the system has the job, like a contemporary operating system has a bunch of applications, and they all have a bunch of threads, well, then, the unit of execution is the thread.  And if you've got four cores, like a quad-core processor, well, you can literally be doing four things at once.  So it scales very nicely.  You add cores, and instead of having one processor that's madly flying around, trying to keep all of the threads moving forward by giving them all a little slice of time, now you actually have two or four cores that are able to simultaneously be running from this myriad of threads in the system, pushing them all forward in time.  So it's a nice way of actually leveraging additional processing power.



Okay.  So with that bit of foundation, we know that Microsoft identified and patched on October 23 of 2008 a flaw in Windows which was one of the many dreaded remote execution flaws, meaning that, if you had an open port, and your computer was just sitting there with this port exposed, a packet could come into the port, and this is a TCP connection over port 445, which would create a connection to the so-called RPC service, the Remote Procedure Call.  And it was then able to take advantage of a small defect in Windows that would cause the payload that it provided with a packet to be executed.



And in the case of Conficker, what Conficker did with this packet was it actually caused the computer that had received this packet to open a reverse connection in the other direction, back to the IP provided in the packet, and establish a connection to a service that Conficker was also running in that attacking machine that would cause the victim to download all of Conficker.  So the first thing was not Conficker.  That first arriving infection was not Conficker.  It was just - it was a packet that only had enough code in it to cause that victim machine to reach out and essentially download Conficker from that source target.



So, okay.  Right off the bat, a number of machines are going to be protected.  First of all, since port 445 has been a source of so many horror stories through Windows history, I mean, it is the Windows file and printer sharing port.  And many other things are overloaded on that port. Many other services are available.  So it's a ripe port for exploitation.  The good news is, many ISPs have responded by blocking it at their own borders, so no 445 traffic is able to transit into the ISP's network.



Now, it's not clear whether you are blocked from other systems within the ISP's network.  That is, it's not clear how fine-grained that blocking is.  It's not clear that somebody nearby, like literally on your block if you're using a cable modem, would not be able to reach your 445 port from their machine.  But it is the case, for example, that many ISPs are blocking incoming traffic from further out on the Internet into their internal customer network.  So that would prevent incoming infections.  Also, any properly configured NAT router would prevent incoming connections.  And I say "properly configured" because how many times, Leo, have you and I told people, begged them, advised them, implored them to disable...



LEO:  Universal Plug and Play.



STEVE:  ...Universal Plug and Play.



LEO:  So this opens it up?



STEVE:  Conficker does.  Conficker is a Universal Plug and Play client which will reach out and open incoming ports through your firewall and router if you have not disabled Universal Plug and Play.  So it's a perfect example of why Universal Plug and Play was a really bad idea from a security standpoint.



LEO:  So just to underscore this, we say a router is a firewall.  It is a firewall.  It will protect you.  Except that, if something does get on your system, and you allow Universal Plug and Play, it just opens the ports and says c'mon in, guys.



STEVE:  Right.  Right.  Universal Plug and Play allows you to do, through a network protocol, all the kinds of things you can do through the user interface on the router, like open static ports and set up a DMZ.  And in fact the Universal Plug and Play interface is even more powerful than what is surfaced on the web-based user interface of most...



LEO:  Really.



STEVE:  ...of standard consumer routers.



LEO:  Wow.  Wow.  And without warning, without any notice, it just does it.



STEVE:  Right.  Completely silent.  No pop-ups.  No security.  No passwords.  I mean, this was just a ridiculously insecure thing for - Microsoft of course was pushing it because it was part of their - plug and play was a prior technology that we saw for many years in Windows that allowed Windows to recognize when you put something in.  It's like, oh, look, la new piece of hardware has appeared.  Let me go find a driver for it if I can.  That was Plug and Play.  And this was Universal Plug and Play that was sort of awkwardly named because it is a completely different technology.  But it was the same goal.  It was to allow discoverability so that...



LEO:  Universal open my ports so I'm insecure.  That's what they should have called it, yeah.



STEVE:  Yeah, exactly.  The idea was it would be a zero-configuration sort of thing, so that if you ran some software on your computer that was intended to automatically configure your firewall or your router, it would be able to send out a broadcast to your network and say, hi there, got any routers out there?  And the router would, through Universal Plug and Play, say oh, yeah, hey, I'm over here.  And then the malware, if it was in this case malicious, would say, oh, good.  Lower your shields, please.



LEO:  Yeah.  Let me in.  Let my friends in.  Let 'em all in.  Wow.



STEVE:  Yeah.



LEO:  Well, but it's interesting, it's almost like the guys who wrote this listen to this show.



STEVE:  Well, they're definitely...



LEO:  They're up on security.



STEVE:  ...tuned in.  Again, this is taking advantage of every available facility.  Now, it's worth explaining also, just to make sure, just another definition, that we understand the difference between a worm and a virus.  Because this is a worm inasmuch as that, if left alone, it would infect all the machines on the Internet that are infectable.  That is, it needs no user interaction at all.  Once it's launched onto the 'Net, it finds vulnerable hosts, infects them with no user interaction, and they turn around and start trying to infect others.



Now, one thing that's different about Conficker than, for example, MSBlast or Code Red, is those worms, we may remember, really brought down or seriously challenged big chunks of the Internet because they were so rapidly reproducing.  They were pouring packets out as fast as they could.  So it had two consequences.  One was they tended to rapidly find other infectable machines and infect them.  But also it was like little local denial of service attacks.  And so if a network had a whole bunch of Code Red infected in it, it would pretty much go off the 'Net, just because its own infections were so actively trying to find other machines.



By comparison, Conficker is very patient.  In my own instance of it here, and I've seen this confirmed in other analysis, it sends maybe, oh, three to four packets a second.  Which, compared to what it could be doing, is really slow.  I mean, it's very patient.  It just sort of pokes away.



LEO:  Is that so that you won't notice it, that it's using a lot of bandwidth?



STEVE:  Yes.  I can't see any real other advantage.  For example, mine's been running...



LEO:  One thing people do to see if they're infected is they look at the lights on their router.  And if it's flickering when nothing's going on, they go, oh, somebody's using my connection.



STEVE:  Right.  If it's going crazy.  On the other hand, mine, I'm using a hub so that I'm able to monitor Conficker with another machine.  And, I mean, if I look at the lights, it's going blink blink, blink blink, blink, blink blink blink, you know, it's...



LEO:  Nothing to worry about.  Normal.



STEVE:  Just a few packets a second.  But it's not going [jackhammer sound], just like crazy.  And that's what we have seen in the case of other malware infections.  So it really - it's staying under the radar that way.  It also does make it less easy to find the clients.  Anything that's out there, malware which is pouring traffic out at random IPs, its own IP is going to end up being known by anybody who's curious because all they have to do is put a packet monitor on a block of IPs, and they're going to see all of this searching traffic coming into that block of IPs, that is, from all of the different infected machines on the Internet that are searching for other machines to infect.  So by being much more slow about this, although it means that it's going to be slower to find another machine, it also kind of keeps it under the radar.



LEO:  It's got all the time in the world.



STEVE:  I've got to say, too, that as we go through the way these Conficker variations have changed over time, there's this desire to find meaning in these changes.  It's like, okay, what's the guy thinking?  Why has it done this?  For example, Conficker A would immediately abort if the keyboard layout of the computer it had entered was Ukrainian.  So it would check the keyboard layout.  And if it was a Ukrainian layout keyboard, it would not infect.



LEO:  That makes you think it might be a Ukrainian that spread it.



STEVE:  Yes.  There are several reasons to believe that.  There's one company in particular, Baka Software, B-a-k-a, is a well-known sort of shady operator who's been responsible for all kinds of mischief in the past.  There was one connection that was caught by some folks that were analyzing Conficker.  And they set up a big honey net in order to look at traffic patterns and levels of activity on the Internet.  There was one packet that they found where it was Conficker B that was - I'm trying to remember.  It was a cross-version packet.  So it was Conficker B that was set up to infect Conficker A.  And that's never the case in any version of Conficker, that is, the versions always, with A and B, they had defenses against anyone malicious taking them over.



LEO:  Interesting.



STEVE:  So A would use A's protocol to spread version A.  B would use B's variant protocol to spread version B.  Well, this was one connection that was deliberately using A's protocol to spread version B.  So it would be upgrading A's to B.  And it happened that that came in from a block that is known to be used by this Baka Software Group in the Ukraine.  So there's some reason to suspect that there's some connection there.



LEO:  Interesting.



STEVE:  But again, unfortunately so much of this is just - it's, you know, you're having to divine intent and what's behind the design decisions that are being made.  Okay.  So we know how it originally started.  It originally started by taking advantage of this vulnerability which was patched on October 23rd.  I think it was November 10th, so not long afterwards was the first appearance of Conficker A, the first variation of Conficker, which says that a lot of this code was already ready.  That is, we hadn't seen this worm before.  But this is too much for someone to write in 17 days, or 18 days, between the 23rd and the 10th of November.  So, I mean, and a lot of this had to be perfected.  When we get a sense for the technology in here, you'll see that it's just way too much.  So somebody had this and was waiting for a vulnerability to surface.



Now, of course, the embarrassment is that the patch was issued on the second Tuesday - oh, actually not.  In this case it's October 23rd, so it was an out-of-cycle patch, not the second Tuesday of the month, that Microsoft patched it because they recognized this was important enough to talk about.  And we talked about it on Security Now!, of course, back then because this is, you know, you don't want to leave any wide-open remote wormable exploits available for any longer than you have to.  So Microsoft did an out-of-cycle patch to close this.  And still, months later, many months later, there are machines that have not been patched.  And as we were talking about this before, it seems that an analysis of the population shows that the density of Conficker infections, which are determinable by looking at the incoming IPs into a honeynet, that is, a block of IPs that have set up sort of like an Internet telescope in order to see what's going out on the Internet, the incoming IPs generally are highest in concentration in geographic regions of the world where piracy is more prevalent.  So it does look like there's a correlation between unpatched machines and pirated copies of Windows.



So the actual payload of Conficker is it's a DLL, a Dynamic Link Library, which is first compressed using a well-known compression tool, UPX.  It's the one I use myself.  It's a very nice executable packing program that makes Windows executables much smaller because the format that Microsoft designed is inefficient in terms of the EXE size.  So it's possible to use standard compression techniques to make it much smaller.  Then it is further obfuscated so that, even if you decompress the EXE, it still doesn't look like regular code.  It needs to get into RAM, and then it sort of self-decrypts itself.



So in order to do an analysis of it, it's necessary to actually load it into memory and then take a snapshot of memory in order to see what's going.  It installs itself in the svchost.exe process.  Anyone who's used Windows and is security aware has looked at their list of running processes, and they'll see a bunch of svchost.exe.  The idea is that in Windows an executable program, you always sort of have to have an EXE as an anchor.  But then the EXE can either have with it or can load dynamic link libraries into that executable process space.



So what Conficker does is it injects itself into an existing instance of svchost.exe by injecting a thread and causing the thread to run load library, that loads the DLL into the process.  It does a number of other clever things.  For example, the way a DLL, a dynamic link library loads is there's an initialization sort of stub at the beginning of the DLL that Windows calls in order to let the DLL set itself up and sort of do an internal housekeeping.  That stub is always returned from.  And after that returns, there's like a return code, success or fail.  So it's possible for the DLL to say, whoops, whatever it is I needed I didn't find here, so terminate me.  Do not load me.  Or the DLL is able to say, hey, everything's fine, I'm ready to stay resident here in this process.  So Windows waits for that return in order to list the DLL among those that are part of this process.



Well, Conficker, cleverly, never returns from that initialization.  It accepts the fact that it's running, and it spawns a bunch of threads to do all kinds of things, never goes back to Windows.  So Windows never lists it as a DLL that's part of the process.  And it's one of the ways that Conficker stays invisible.  It also has a null string name when it registers as a process.  It does so with an empty string name, and it flags itself as "Make me invisible," which is one of the status bits that a process is able to set.  So again, it works on remaining sort of off the radar.



LEO:  But it's not a rootkit, though, is it?



STEVE:  Well, I wouldn't call it a rootkit.  But it does a lot of things in order to hide.  I'm going to run through a bunch of the specific things it does to hide.  And it's also evolved over time.  One of the things that it needs to do is it needs to know its public IP.  If it has infected a machine behind a NAT router, the only IP it has is, like, 192.168.1.1 or 1.5 or whatever, you know, the nonroutable IP.  But when it sends its packet out to infect another machine, and the way the infection works, is that a reverse connection is made from the victim back to the attacking machine.  The attacking machine has to know the public IP.



So get a load of this.  It uses well-known IP-checking sites.  It connects to getmyip.org or getmyip.co.uk or checkip.dyndns.org.  It knows all - the A variant knows all three of those.  So it chooses one or two at random in order - or it actually chooses them until it gets the answer that it's looking for, and uses that remote site whose job is to tell you your IP, it parses the returned page to get the IP that is public for its router.  It also downloads a geographic IP database from Maxmind.com.  The GeoIP database relates IPs to locations.  And it uses that in order to avoid attacking any IPs in the Ukraine.



LEO:  Again the Ukraine.  Again the Ukraine.



STEVE:  Yes.  So when it's generating random IPs, it carefully filters out any Ukrainian IPs.  Now...



LEO:  Now, if I were writing a virus, and I lived in the Ukraine, that would be a very handy thing to make sure I didn't infect myself, my friends and family with my virus.



STEVE:  And to make sure you don't upset the local authorities.



LEO:  Oh, yeah, because that's the jurisdiction I'm in, isn't it.



STEVE:  Exactly.



LEO:  Oh, very good point.



STEVE:  And we know that it's much harder to get cross-country cooperation than it is to upset the police station around the block.  And so it's been, again, it's been surmised that they're not attacking anybody in the Ukraine because they don't want to rouse the local authorities.  Which again I think is very clever.



LEO:  That's smart, yeah.



STEVE:  Now, one of the new technologies that we have not seen in previous worms, that the A variant of Conficker starts, is this notion of using a pseudorandom number - essentially it's a pseudorandom number generator that maps to pseudorandom domain names.  Conficker version A, and this is one aspect that has changed a lot because it was one area where it was vulnerable to being blocked, Conficker version A every day would generate 250 domain names based upon the UTC date.  It would get the UTC date by querying from among a large number of well-known public websites.  One of the headers that comes back when you request a page is the current date and time in universal time.  So that way it knew sort of globally, that way all the Conficker instances all over the world would be synchronized to the same UTC date, which would mean that on a given day they would all use the date to seed the pseudorandom number generator which was used to generate domain names.  And the A variant of Conficker would generate 250 domain names based on that pseudorandom generator and then perform DNS lookups to look up the IP of that domain name using the standard public DNS system, and then attempt to make a connection on port 80 to a server, a web server because it's port 80, a web server running on that port.  If it succeeded in downloading a binary file, it would then go through a substantial process, which I'll describe in a second, to verify the validity of that file.



Now, the B variant made some changes.  For example, the B variant dispensed with the keyboard detection so it would no longer abort if you had a Ukrainian keyboard layout defined in Windows.  But it still did the GeoIP data in order to filter out Ukrainian IPs.  And that has remained to this day.  So Conficker really doesn't want to upset, apparently, the Ukrainian authorities.  B also began the task of terminating many popular antivirus, and it began blocking DNS lookups to prevent you from going to, like, Symantec or Microsoft or Windows Update to do things that were related to maybe wondering if your computer might be infected or, finally, getting the update that would cure this problem.



On the other hand, all versions of Conficker have closed the door behind them.  Conficker got in by using this MS, what is it, 08 dash - can't remember the number.  It's, like, dash 68 or something, Microsoft's ID for this exploit.  What they did was they would modify, by patching in memory, they would modify the vulnerability so that only they could subsequently use it to prevent somebody else from coming up with something malicious that would knock Conficker out of the system.  So after they got in, they didn't completely close the door, but they filtered any other incoming traffic to make sure that it was them.  So, I mean, a lot of thought was given to this.



B also began to incorporate extensive anti-debugging and anti-reverse-engineering defenses.  This is technology that's been known and done for years, a lot of it in the hacking community, to prevent malware from being reverse engineered.  So these concepts were not new.  But it's another layer of defense that Conficker was employing.  For example, it's possible for software to tell if it is being single-stepped through, which is one of the typical things you do when you're reverse-engineering code.  You go step at a time in order to see what the code is going to do, sort of running it under supervision.  But that always messes up, of course, the timing.  So not only timing, but there are other means that can be used to see if breakpoints are being set in the code.



So there's much that could be done for code to protect itself against analysis, and Conficker does a lot of that.  It uses an additional set of public services to determine its IP.  It uses getmyip.org, also whatsmyipaddress.com, whatismyip.org, and additionally, as did version A, checkip.dyndns.org.  So there has been some evolution and variation in Conficker's behavior over time.  Oh, and whereas the A variant went to Maxmind.com to load the GeoIP filter, version A incorporates it internally.  It uses RAR to compress...



LEO:  You mean version C.



STEVE:  I'm sorry.  No, no, B.



LEO:  B.



STEVE:  Version B uses - it incorporates the GeoIP list internally.  It uses RAR to compress it, and then RC4 to encrypt it.  And so it's part of the payload, it's built into the body of Conficker version B.



LEO:  Does it seem sensible, it sounds to me like this is the case, that it's the same guy doing all three versions?



STEVE:  Oh, yeah, yeah.  There's no doubt that this is the same - that it's the same guy.  And it's clear that it's, wow, look how A is succeeding.  I can make it even better.  So it's probably some notion of, wow, you know, it's succeeded beyond my wildest imagination.  Now I'm motivated to put more time and energy into it.  The way...



LEO:  Oh, great.



STEVE:  Yeah, exactly.  The way Conficker protects itself is really interesting, also.  I had mentioned before that it digitally signs itself.  So when anything is going to be accepted by an existing version, like an upgrade to Conficker, taking it from A to B or B to C or beyond C potentially, and that appears to be happening now, the block of executable code is hashed using a digital signature algorithm.  A used SHA-1.  B, Conficker B, used MD6.  What's interesting is that Ron Rivest of RSA, who designed MD6, publicly disclosed and announced and released MD6 just two weeks before Conficker B incorporated it.  So...



LEO:  Wow.  Wow.  That's amazing.  I mean, this sounds like this guy's, like, a genius.



STEVE:  Well, he's in the game.



LEO:  Yeah.



STEVE:  I mean, he's actively watching what's going on in the industry and, on some level, participating.  A little side note, the very first release of MD6 had a bug.  There was a buffer overrun glitch in MD6 which was found and corrected.  This guy was so quick to get MD6 into Conficker B that he incorporated that bug, although the nature of the way it's used would not allow anyone to take advantage of that in order to, like, take over Conficker.  So it didn't represent a weakness in his case.



Okay.  So the code is hashed to create a 512-bit hash.  That hash is used as the key, the symmetric encryption key for the RC4 stream cipher that we've talked about at length in previous podcasts.  RC4, you'll remember, was the cipher used in WEP encryption, which when used wrong is a bad thing.  In this case it's used in a sort of a noncritical fashion.  So the 512-bit hash is used as the key to encrypt the binary.  Then it is signed using public key encryption.  The hash is raised to the power of a private key, taken mod n to create a signature.  And that signature is appended to the end of the package.



That's the package, then, which is sent to a potential recipient version of Conficker.  So it reverses the process.  It takes the public key which it contains, raises the signature to that value mod n, and due to the miracle of public key encryption, that produces the hash.  So it then uses the hash to decrypt using RC4.  Remember that RC4 is just - it's just a pseudorandom stream.  So it generates the same pseudorandom stream as was used to encrypt it, XORs the stream with the body of the payload, and that produces decryption.  It then hashes that and compares it to the original hash.  Only if they match does it know it was signed by somebody who had the private key, meaning the author, and nobody else is ever going to have that, so only the author is able to produce new payloads which would be injected into the Conficker system.  The A variant uses a 1KB RSA modulus.  The B variant uses a 4K.  Again, just because why not?  1K was good enough; 4K, well, that's even better.



So, you know, you begin to get a sense for the amount of technology, I mean, state-of-the-art crypto technology which is in this and is serving the purpose of keeping this thing alive, preventing it from being commandeered, and maintaining this mysterious owner of this thing in control of this network.



Now, so we talked about how domains are being generated.  250 domains per day were generated by the A variant.  But they only had the top-level domains of .com, .net, .org, .info, and .biz.  So, you know, pretty much the five most popular domains.  The problem is that 250 a day in those top-level domains, it was easy for the so-called Conficker Cabal, the anti-Conficker folks, the white hats who were trying to protect us from this, it was easy for them to generate the 250 domains for tomorrow and the day after and the day after and go preregister them so that they were able to block Conficker from being able to expand.



Well, the first thing that happened - I'm sorry, to block Conficker from being able to basically phone home in order to get an update to itself.  Because the idea would be that the malware author would go and register a domain sometime in, like, a domain that would be used by Conficker next week.  They'd register the domain and set up a web server, point that DNS address to some IP that they controlled, set up a web server there with a signed package, signed using the technology we just talked about, and so then what would happen is on that day all the Conficker worms that knew what day it was would generate 250 domain names and try them all.  One of them would be a hit, and it would only take one.  They would find that one, look up the IP, connect to that TCP server and download a binary payload, use their public key to verify the signature and to generate the hash used for decrypting it, verify that, and run the code.



So, I mean, lots of technology here.  B added three more top level domains to that approach:  .ws, .cn, and .cc.  The other thing that B did was it expanded the domains that it uses for determining the date.  It used W3.org, Ask.com, MSN.com, Yahoo.com, Google.com, and Baidu.com, B-a-i-d-u.



LEO:  Yeah, that's like a Google for China, Baidu, yeah.



STEVE:  Right, right.  Okay.  Then the big change that we talked about several weeks ago was the one that also made a lot of press, unfortunately.  I mean, a lot of sort of Y2K scare stuff was what would happen with Conficker on April Fools Day, on April 1st, because the C variant was designed to have its behavior change.  We did talk about this...



LEO:  Is the C variant the one that you've been using, or you've been playing with?



STEVE:  Yes, C variant is the one I've got.  And...



LEO:  It ran, but did it ever get any data on April Fools?



STEVE:  No.  Well, no.  What happened was its behavior changed.  It suddenly began querying, it began generating 50,000 domains, up from 250, so to 50,000, from which 500 would be randomly selected.  And not only that, but whereas A, the A variant used the five most popular top level domains, and the B variant added those three more - ws, cn, and cc - the C variant uses 110 different TLDs.  I mean, just about everything you can think of.  And that creates a huge problem because these are TLDs literally spread globally and under the control of a phenomenal number of registrars.  Beforehand, all you had to deal with was the registrars who were registrars for .com, .net, .org, .info, and .biz; and then later ws, cn, and cc.  Now, if you're going to preemptively register, you've got a big problem.  Not only do you have to preemptively register 50,000 domain names per day, but you've got to do them with all the registrars controlling these 110 possible top level domains. So with the C variant this whole notion of - this cat and mouse, basically, really got escalated. Oh, it was MS08-067 was the original variant, the original vulnerability which was being used for exploitation.  So...



LEO:  So...



STEVE:  I'm sorry, go ahead.



LEO:  Go ahead, no, no.



STEVE:  Okay.  So, okay.  So A propagated.  So we have the way Conficker phones home by generating domains and trying to contact a server at a pseudorandomly generated domain name which has been, you know, is knowable in advance, but has been made much more complex after April 1st when we switched to variant C.  The only way that the A variant caused infections was the same way it got infected, that is, it would send out the packet, the so-called Server Message Block, an SMB protocol packet, to port 445 using the TCP protocol.  It would connect to the server surface and take advantage of the vulnerability.  It was the original vulnerability that was supposed to be fixed.  So a machine that got infected that way would attempt to reinfect other machines.  And what it would do is it would just generate IPs at random and attempt to make a port 445 connection to them, although it would avoid the Ukraine, any IPs that were physically geographically located in the Ukraine.



The B variant added two additional propagation techniques which, oddly, were removed from C.  So it hasn't always been escalating.  It's like its behavior has been changing for one reason or another.  And in fact C is less effective because these other two approaches were removed.  B would use NetBIOS shares to propagate.  It would look for other machines on the Local Area Network, and then it contained a list of 240 common passwords.  And so it would attempt to connect to any other machines, any other shares on other machines, and get into them that way.  And, oh, and this had an interesting side effect, too, because within corporate IT where policies could be enforced, if Conficker got in and began scanning the network, finding machines and attempting to log into them and guessing wrong, that would trigger the account lockout policies.  And so the actual users were unable to log into their machine because their machine would say, sorry, you've had too many failed login attempts.  You're locked out until you talk to your IT administrator.



But B did something else.  If it saw a removable drive arrive or in the system when it got there, it would copy itself to the removable drive and edit the autorun.inf file to cause itself to be run whenever that drive was plugged in somewhere else.  So it would use USB propagation in order to move from one system to another.  So C removed those two other strategies, but also changed - it added another approach using the SMB, essentially, using a so-called "named pipe," which is one of the APIs in Windows that allows you to essentially connect a - to establish a connection between two machines anywhere on the Internet and send data back and forth through the so-called "pipe," which is really just a connection between those.



So in terms of hiding itself, Conficker has always gone to some extremes to hide itself.  It would give itself a random name in the Windows system32 directory and set its time and date stamp to the same time and date as kernel32, which was clever because with Service Pack updates and security updates there's normally a bunch of things that are going to have the same time and date stamp.  But rather than, for example, not doing that, one of the first things people who are, like, used to looking for malware in machines do is they'll sort the directory listing by date and time and look for the most recent changes in the directory, thinking that something may have, if it got into the system recently, it'll have a current date and time stamp.  Well, Conficker says, not so fast.  We're going to set our own file date to the same thing that we know a lot of other files will be set for, which is the data and time of kernel32.dll.



It also sets up multiple threads.  One thread provides a constant security service disable, so that if any security services are running, like Windows Update, it'll shut that down, or any of the other third-party services.  It looks at a whole bunch.  There's, like, autoruns, avenger, confick and downad are both cleanup utilities, filemon, hotfix, regmon, tcpview, wireshark, it knows about all these different processes and terminates them if you try to run them.  It also is getting very smart about the IPs that are returned from DNS lookups.  If any DNS lookup returns more than one IP, it says, eh, I don't think so, and it just ignores it.  Or if it's a stub IP, like 127.0.0.1, which is a localhost IP, that's something that, for example, I imagine the antimalware guys were doing was they would register, instead of sending Conficker off to some other server, they may have been setting them up as just setting the IP to 127.0.0.1, causing it to try to connect to itself, which would fail, but it was just sort of a nice way of stubbing that lookup.



Well, Conficker over time became smart.  It also maintains blacklisted addresses.  And if it ever got an IP from one DNS lookup that it got from another DNS lookup, it would note the collision and not bother to connect to that same IP.  So the other behavior that the good guys might have had is to aim, when they were, like, preregistering all these IPs, they would aim them, like, at some monitoring location, saying, okay, we're going to preregister all these to XYZ Internet address.  Well, later on Conficker began remembering all IPs it had received.  And if it ever got the same one a second time, it says, well, I already contacted that, and I don't want to be tricked, because it knew that its own secret phone home IP would only be listed at one DNS.  Or that it would have contacted it, and there's no reason to contact it again.  So it was getting smarter over time.



It also had a long list of /8 networks, that is, the first byte of an IP address.  It knew that, like, 0, 1, 2, 5, 10, 14, 23, 27, 31, 36, on and on, are invalid IPs.  And we know that, for example, 5 is an invalid - anything starting with 5 because that was what the Hamachi peer-to-peer system used because it was IP space that had never been allocated.  So Conficker was evolving over time, making a better use of the resources that it had.  And it's just a very robust, strong piece of malware.



I wanted to read the final paragraph in a report from SRI International that did an analysis of this.  They said:  "Conficker C is in fact a robust and secure distribution utility for distributing malicious content and binaries to millions of computers across the Internet.  This utility incorporates a potent arsenal of methods to defend itself from security products, updates, and diagnosis tools.  It further demonstrates the rapid development pace at which Conficker's authors are maintaining their current foothold on a large number of Internet-connected hosts.  Further, if organized into a coordinated offensive weapon, this multimillion-node botnet poses a serious and dire threat to the Internet."



LEO:  Wow.  Well, it sounds like it does.  Now, I was just looking, and I saw that, at least according to Symantec, that some Cs had updated themselves to E after the April Fools thing, in the last couple of days.



STEVE:  Yes.  That was what finally motivated me to install my own Conficker in a honeypot.



LEO:  Are you letting it update?



STEVE:  Yes.  Yes.  I'm not allowing it to attack anybody else, but I am hoping it's going to go - I want to see it discover somebody and get itself updated.



LEO:  Oh, interesting.



STEVE:  It was shortly after April 1st.  The news went around the security community that there was an encrypted package that was being acquired by C.  And so it was like, okay.  At that point I thought this thing's not going away.  I've got to get in the game and be watching it myself.



LEO:  Very interesting, I've got to say.  It's very sophisticated.  Do you think it's a team of people?  Must be a team of people.



STEVE:  I don't think so.



LEO:  Could be one guy.



STEVE:  I mean, not necessarily.  One person could easily do this.  One smart network-aware author could easily do this.



LEO:  Could be his life's work.  His great achievement.



STEVE:  Well, who knows what the goal is, or the plan.



LEO:  The E variant put one of those creepy antivirus things on there; right?



STEVE:  Yes, I was going to say there is now some scareware that is being downloaded by the most recent Conficker.  And so it may be that they have decided, well, we might as well commercialize this now because we've established ourselves.  We're in millions of machines worldwide.  Basically we've got a technology that can live as long as it's able to.  We're able to give it encrypted, digitally signed payloads anytime by just knowing which domain we want to register ahead of time, grabbing that, aiming it at our web server, and some percentage of Confickers will find it.  The ones that don't will be establishing a peer-to-peer network among themselves, and they'll be able to pass it back and forth that way.



So we've got two things.  We've got Confickers interlinked through a peer-to-peer network.  That is, they're sending these packets out, trying to find other copies of themselves, that interlinks them in this peer-to-peer network.  And they're also periodically, daily, attempting to use DNS lookups on pseudorandom number-generated domain names to basically phone home in order to get payload updates that way.  So it's a very sophisticated network designed to survive what anybody tries to do to it to shut it down.  And since it's using public key encryption for its digital signatures, we don't know the private key.  We cannot know the private key.  Only the author knows.  And so that prevents anybody who might want to, even good guys, from taking advantage of that and leveraging that in order to somehow deal with this problem.



LEO:  It's really an interesting study, isn't it.  I mean, this is...



STEVE:  It is.  It's a perfect case study in how the technology can be used by a sophisticated author creating a sophisticated, state-of-the-art piece of malicious software.  I mean, there really isn't anything that this guy hasn't, or team hasn't come up with.  And the other thing is, thanks to the fact that they've got this dynamic update facility, they're able to respond to what the industry does.  And that's what we've seen them do.  Anything that the Conficker Cabal have come up with in order to thwart Conficker, the author said, okay, fine, I'll just bump the domain names up from 250 a day to 500 a day, chosen from a set of 50,000.  Let's see you preregister all of those in 110 different top levels.



LEO:  I guess the other thing we learn from this is how to protect ourselves.  I mean, it's demonstrating all the holes, all the things that you might want to be paying attention to.



STEVE:  Well, yeah, I mean...



LEO:  Like Autorun and Universal Plug and Play, I mean, there's a lot of...



STEVE:  What I liked about it is that everything we've talked about in the approaching four years of this podcast are things that, if our listeners were diligent about doing, would be one less way that they could be bitten by this.



LEO:  Right, right.



STEVE:  Because if they've got Universal Plug and Play disabled they're going to be in better shape.  And if they've got Autorun disabled on removable drives they're going to be in better shape.  So, yeah, I mean, it's an example of why security matters and how you can be protected by security.



LEO:  It surely does, Ollie.  Well, thank you.  Very interesting expos.  You could read more about this on Steve's website.  Security Now! is at GRC.com/securitynow.  Show notes there, 16KB versions, full transcript of all shows, all online at GRC.com, along with SpinRite, the world's best hard drive maintenance and recovery utility, and all of Steve's freebies, too.  There's lots of great free stuff there.



STEVE:  More stuff coming soon.



LEO:  Very good.  Next week, Q&A.



STEVE:  Yup.



LEO:  Submit your questions to:



STEVE:  GRC.com/feedback.



LEO:  There you go.  Thanks, Steve.  I appreciate it.  This is kind of like a ghost story.  You scared me.



STEVE:  It's all true, too.  I mean, it is impressive.  This author or team have really done something.  And now the question is, what's it going to do next?  I mean, this thing is alive.  It's a creature of the Internet.  What's it going to do next?



LEO:  Thank you, Steve Gibson.  We'll see you next Thursday on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#194

DATE:		April 30, 2009

TITLE:		Listener Feedback #65

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-194.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 194 for April 30, 2009:  Listener Feedback #65.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, Episode 194, the show where we talk about all your security concerns.  We haven't yet done locks...



STEVE GIBSON:  Actually, we'll give you security concerns, if you don't have any already.



LEO:  That's right.  Yes, exactly.  That's it.  And if you don't have them, we'll provide them for you.



STEVE:  That's right.



LEO:  That's Steve Gibson of GRC.com, the creator of SpinRite, the world's best hard drive maintenance and recovery utility, also a security guru, creator of ShieldsUP!, the discoverer of spyware, and our host.  Hello, Steve.



STEVE:  Yo, Leo.  Great to be with you this week.  Again, we're approaching the end of our fourth year.



LEO:  Whoa.



STEVE:  I'm excited.



LEO:  Whoa.



STEVE:  That's going to be - that's going to be very cool.  We're...



LEO:  That's hard to believe.



STEVE:  Yeah, oh, I know.  It's like, four years, wow.



LEO:  Unbelievable.  Amazing.  Well, it's been fun, and we never run out of topics, unfortunately.  In fact, you couldn't pick a...



STEVE:  Wait, unfortunately?



LEO:  Well, I guess fortunately.



STEVE:  Oh, yes, for security reasons, yes.



LEO:  And unfortunately.  But you couldn't really pick a better subject than security right now.



STEVE:  A fertile medium, yes.



LEO:  Holy cow.



STEVE:  We have sort of a fertile topic, certainly.  And our listeners, who've been anxious for the how SSL protocol works in detail episode, will - given that nothing really phenomenal and important happens during this next intervening week, that's our topic for next week.  Today we've got a Q&A.



LEO:  Excellent.  Your questions, Steve's answers.  Before we do that, though, any news to report?  An updates on anything?



STEVE:  Yeah.  It's been relatively quiet.  I did want to mention, I loved - I was watching, was it you and Dick or, no, it was one of the many feeds you have where they mentioned that there's now a - well, actually I didn't ever look for it.  But there are several star date calculators.  So I just thought it was...



LEO:  Isn't that funny that star - oh, yeah, we were talking on the TWiT about "Star Trek."  And I said, well, what's the - I can't remember how it came up, but how would you know what the star date is?



STEVE:  Yeah, and we are, today, this podcast's date is -314327.28.  Just so...



LEO:  You looked it up.



STEVE:  Of course.  Absolutely.  And it turns out you just put "Star Trek calculator" in.



LEO:  It's pretty easy, yeah.



STEVE:  In fact, there's a little guesser thing that's guessing what you're looking for.  It even had it on there.  So just wanted our listeners to know that we are -314327.28.



LEO:  That's great.  That's great.



STEVE:  There were - I only have three notes in security news.  The Firefox updates are coming fast and furious lately.  We just got updated to 3.0.9, which fixed a whole bunch of problems.  And then just two days ago, three days ago, we went to 3.0.10, which just fixed one more problem.  So anybody who's got Firefox is probably already up to speed on that.  If you haven't seen it, there is an update from .9 to .10.  And that's critical, by the way.  It is a buffer overflow problem in some text rendering.  So you want to do that.



I did also note that Microsoft's out-of-phase update - remember they do the important security updates on the second Tuesday, and they do, like, two Tuesdays later, they do things that are sort of, well, you know, we just thought we'd throw these in.  These aren't super critical.  Don't worry about them.  But I noted that IE8 has now been added to Microsoft Update.  So I was - actually I was at Starbucks, and I got this notification that they wanted to send me IE8.  It's like, eh, well, I guess they must be confident enough of 8.  I mean, my feeling was it wasn't ready yet for primetime.  I don't use it anymore except to go to Microsoft for updates.  I'm completely converted to Firefox.  So I'm not vulnerable to many security issues because - which I would imagine by default IE8 will have a whole new slew that'll now have to be found and hopefully won't be biting too many people until they are.  So anyway, IE8 is out.



And something we don't see very often, there was a critical Blackberry PDF vulnerability which was announced.  So Blackberry users, I just - we're all used to getting updated moment to moment by our Windows apps.  But I did want to make sure that people who were using Blackberries knew that opening a PDF, until they update their Blackberry after this problem, there are exploits that will allow your Blackberry to get taken over, which is of course not what you ever want.



LEO:  So it would be you would download a PDF?  Or you'd...



STEVE:  It would be viewing a PDF on your Blackberry is, I mean, the standard, I mean, PDFs have become unbelievably complex.  I mean, they've got JavaScript support.  And the state-of-the-art free Adobe Reader is now hundreds of megabytes in size.  It's like, I don't know what it's doing; but whatever it's doing, it's a lot of it.  So hard to imagine that there aren't problems when you've got that much code.



LEO:  No kidding.



STEVE:  Which is, you know, taking in something and interpreting it.  So there is that in the Blackberry.  Just wanted people to know.  And in the spirit of the Q&A, as I was going through my mailbag to collect our today's 12 questions, I ran across a SpinRite question.  So I thought, well, I'll do that as my little SpinRite mention of the week.  This was from Jose Cerna in San Diego, who wrote to ask, he says, "I use SpinRite regularly to keep all of my drives in top condition.  But recently I bought a laptop with an SSD, a solid-state drive.  So I was wondering if SpinRite would be okay to run on it, and does it need it.  Thank you for the great podcast.



P.S.:  I sometimes fix computers for others, and I have used your product to fix their drive and/or recover files.  I know that this goes against your EULA, the End User License Agreement.  But what I have been doing is I have them purchase SpinRite in front of me, then I download it for them and install it into a Flash drive that they can then use to maintain their drives from then on.  I have done this with three customers already, and they are very happy with SpinRite."  And of course I'm very happy with Jose for...



LEO:  Thank you, Jose.  A few yabba-dabba-dos right there.



STEVE:  That's some yabba-dabbas.  Anyway, to answer his question about solid-state drives, I can see absolutely no possible benefit to running SpinRite on a solid-state drive.  We know that solid-state drives, good ones, are very reliable.  I just bought a 64GB SSD for a new tablet that I own because I'm just - I'm so conscious of the mechanics of a hard drive and what kind of problems people have.  Naturally, it's been my bread and butter for more than 20 years.  And this thing, I checked it out, has an MTBF, a Mean Time Before  Failure, estimated - this is a Samsung 64GB SSD - estimated at two million hours.



LEO:  Whoa.



STEVE:  So theirs is good technology.  It is possible to buy crappy solid-state drives.  People are invariably going to do that.  There are multilevel storage as opposed to single-level cell storage.  You can get 64GB, for example, in a thumb that's for a couple, maybe a hundred bucks, probably.  But you get what you pay for in SSD technology.



LEO:  You know, I just bought a - we've covered this a little bit on our PC Perspective show because Ryan's very interested in this.  And he has a great guy, Allyn Malventano, who has become an SSD expert.  He's testing all the drives and stuff.  And he also likes the Samsung drives.  They recommended a Corsair model, which is Samsung parts, I believe.  MLC, though, not SLC.



STEVE:  Ooh, okay.



LEO:  Yeah, no, they said that's fine, that in fact very few drives are using SLC.  Those are really only the enterprise drives at this point.  They're extraordinarily expensive.  This was still expensive.  For 128GB it was 330 bucks.



STEVE:  Okay, see, I paid $800 for 64GB.



LEO:  You got an X25.



STEVE:  Yeah.



LEO:  The Intel.  I don't know if the Intel's SLC.



STEVE:  No, no, no, I got a Samsung.  It's...



LEO:  Oh, you got Samsung, okay.



STEVE:  It's a Samsung, but it is an SLC...



LEO:  It is SLC, okay.



STEVE:  Right.  I mean, it's, again, this was - I've done something weird, Leo.  I've been spending many hours at Starbucks coding by bringing a copy of my work, my regular home keyboard, because it's only on this full-size Northgate 102-key keyboard that I can type at full speed without even thinking.



LEO:  See, I can't use those.  They're so loud I can't use them in the studio.  They clatter.



STEVE:  Oh, exactly.



LEO:  It sounds like a teletype machine in here.



STEVE:  I finally figured out that that was the problem was, you know, when I'm hunched over my laptop, I just - it's like, okay, where's the delete key on this?  I mean, it's a compressed keyboard for a laptop form factor.



LEO:  Right, right.



STEVE:  That was my problem.  So I thought, okay, I need a tablet that has no keyboard, with a nice size screen, and then I'll get an old-style XP, I mean, XT to PS/2 converter, then a PS/2 to USB.  So I have a chain of sort of dongles that convert this thing into something that runs now USB.  And it's just fantastic.  I have the tablet propped up on a little bookstand in front of me, the keyboard there.  And you'd be surprised how many looks I get from people who walk by, go what the heck is that keyboard doing here?  Anyway, so, but I'm getting - I'm hugely productive now.  I've done five ten-hour marathons on the last five days in a row.



LEO:  Yeah.  And that prevents carpal tunnel, too, I think, because there's more motion, more travel...



STEVE:  It's fantastic, yeah.



LEO:  It's more physical, yeah.



STEVE:  So anyway, yes.  No need to run SpinRite on an SSD.  SpinRite is all about mechanics and magnetics, neither of which exist in, by design, in an SSD.  That's what you want to get rid of in order to get reliability up.  Thus SSDs are extremely reliable.



LEO:  I have to tell you the speed on the Corsair is amazing.



STEVE:  Yeah.



LEO:  Load times particularly.  But, you know, I did some transcoding, too, because there's a lot of reading and writing in transcoding video.  Like twice as fast.  I mean, remarkable differences.



STEVE:  Yeah, yeah.



LEO:  So mostly access time benefit, I guess.



STEVE:  Yup.  And I just, for me it's that, I mean, I'm just - I'm so twitchy about any portable machine with a hard drive because they're inherently - they're moving around.  They're going to get some bumps and things just inadvertently.  And it's like, okay, this is now my main development platform when I'm away from the house.  And I care about its reliability.  I mean, everybody cares about its reliability, so.



LEO:  Yeah, yeah, yeah.  Well, I'm excited about it.  They're still pricey.  But I just thought, I'm going to give it a shot.  Both Ryan and Allyn pushed me to do it.  And I put it in a MacBook Pro.  And it's just - I love it.  I can't wait till the prices drop.  I'll put them in everything.



STEVE:  Yeah, I'm not that excited for them to drop.



LEO:  Why?  Oh, it puts you out of business.



STEVE:  No one needs SpinRite.



LEO:  Whoops.  Well, you know what, I think here's what's going to happen.  Certainly the usage I plan is you'll use it for your boot drive, your applications, the stuff where you do a lot of I/O.  And then you'll have massive spinning drives, these terabyte or two-terabyte drives, for data storage.



STEVE:  It is the case that hard drives will not disappear overnight.  I mean, they're just not going to.  That technology is so mature, and they are so cost effective that - and, you know, SpinRite is recovering media for people now.  You don't use SpinRite to get Windows back because you can always reinstall that.  You use it for your priceless photos, your Ph.D. thesis, your huge music collection of borrowed CDs that you don't have.



LEO:  Or movies, frankly.  I mean...



STEVE:  Yeah, exactly.  So, yeah.



LEO:  So that's - and I think that makes perfect sense.  Why use Flash for something like that, where speed is not important, it's storage.  I bet you we will see these different classes of storage for some time to come.  So you're all right, Steve.



STEVE:  It makes sense that there would be a spread.  Well, and I've got my next product on the way.  CryptoLink is nascent, but going to be next.



LEO:  Well, you'll always have a home on TWiT, too.  I mean, you're the security guru.  That's the good news.  There's always going to be a need for that, I don't care what kind of drives we use.  What else you got?



STEVE:  That's it.



LEO:  That's all?



STEVE:  Yup.



LEO:  I have the questions, Mr. Steve.  Are you ready for me to read?



STEVE:  Yes, indeed.  And we have a special first question.



LEO:  From Elaine.



STEVE:  Yeah.



LEO:  Oh, that's so cool.  Elaine, our illustrious audio transcriber, asks this week's first question, and it's appropriately about Conficker.



STEVE:  Yeah.  There were a bunch of questions that I ran across in the mailbag.  There were some things I had - I sort of glossed over, or I didn't cover.  So we've got a - we'll have some clarification of the issues from last week.



LEO:  But do start, if you haven't listened to last week's show, Episode 193, the whole show is on Conficker, in great detail, how it works, what the dangers are, how it's spreading.  She says:  This Conficker thing's been giving me a headache for weeks, ever since you first mentioned it.  I don't need help with spelling any names in the podcast - often a cause of concern.  She says:  Instead, I need help with my own head.  Please, what I don't understand is, when you keep saying it's, quote, "generating domain names," end quote, and you say it's gone from generating 250 or 500 to 50,000 domain names, what does that mean?  Don't those generated domain names need to be registered in order to be used by the worm?  I must be misunderstanding something at a really basic level because it looks to me like it's costing someone half a million bucks a day just to run the worm.  I usually try to keep my ignorance to myself, but this is really bothering me from week to week.



Hey, Elaine.  That's great.  She's paying attention.  And I should have asked that question.  That's a great question.  What's the deal, Steve?



STEVE:  It is a great question.  And I don't think I was clear enough in explaining why this is so clever.  The idea is that the worm generates a huge number of "potential" domain names, and at random chooses from among those.  So, and it's based on the current UTC calendar date.  So everybody knows what the algorithm is.  The bad guys that designed all this, they know what the algorithm is.  The white hats that have reverse-engineered all this know what the algorithm is.



And what's clever about this is that this succeeds even with full reverse engineering.  That is, we know we cannot protect the secrets of anything that needs to run remotely, just like the DVD or Blu-Ray and HD guys were unable to protect the secrets even in their most fancy encryption/copy protection technology.  You just can't.  Because if a device has to run in order to display it, then you can reverse engineer what it's doing, no matter what the people who try to prevent that, whether they're good guys or bad guys, no matter how much they try to be clever to keep that from happening.



So we know that everybody understands the algorithm.  So this succeeds even in the presence of that complete documentation of the algorithm.  Every day a set of possible domain names that has increased in size after April 1st from a few hundred to 50,000, every day a set of those are possible.  From among those, the worm chooses only 500 to actually attempt to go to.  So the way this works in a large population of worms is the good guys on our side, the white hats, if they wanted to block all of the possible domains from which on any given day all the Conficker worms could get updated, they would have to preemptively register those, all of those 50,000 domains.  Whereas the clever black hat, the clever author of Conficker, only needs to register one or several on any given day.



LEO:  He knows ahead of time what the domain's going to be.



STEVE:  Everybody does.  The good guys and the bad guys.  But my point is, to preempt the update from getting into the new Conficker peer-to-peer network, to preempt it, all of the domains have to be blocked.  To get it in, only one has to be registered because some of those worms will contact, choosing randomly, that one domain.  And that will be enough to get them updated.  And then they use the peer-to-peer network to update all the other worms that contacted domains that were not registered or were registered by the good guys to block it.



So that's what's so clever is that, I mean, every single day 50,000 new domains are going to be probed.  And this is now in 110 top-level, like not just .com and .edu and .org and .net, but now all these obscure, 110 top-level domains.  Which makes preemptively registering them basically impossible.  And all the bad guy has to do is a few days ahead, just camp out, put a server on one of the domains that he knows in a couple days some small percentage of Conficker will visit.  And so he needs to register one. The bad guys need to register all of them.



LEO:  The good guys.



STEVE:  I mean, sorry, the good guys need to register all of them if they're going to block it.  And all of them every single day.  It's just not possible.  So it really creates this dramatic asymmetry of effort, which is why I think this was - and this was extremely clever.  And you can imagine that this will now be the paradigm for bad guys keeping in touch with their botnets is this kind of algorithm because it is simple to implement.  It is very clever.  And it is - there's really nothing you can do to prevent that asymmetry from existing.



LEO:  Very interesting.  Thank you for asking that, Elaine.  And I apologize for not asking it myself.  Doug Curry in Houston, Texas asks:  What have I missed?  Steve and Leo, I was just listening to 192 where you mentioned that the Conficker worm uses public key encryption digital signatures to protect itself from being spoofed with updates from someone other than the original authors.  Again, a nice, slick thing to do.  You said that even if you got the public key there was no way to reverse engineer the private key.  Of course that's the point behind public key encryption.  Fair enough.



But help me out here because I've got to be missing something.  I'm clearly no cryptographer.  But if you know the public key and encrypting algorithm, couldn't you put some set of known data through the algorithm, using the public key, obtaining the encrypted output, attempt to decrypt that output with the same algorithm and a sequence of successive potential private keys - there's the issue, we'll get to that - comparing the encrypted output to the original, in other words a brute force attack against this public key?  And given that a brute force attack would require massive amounts of computing power, could you not use a distributed computing methodology like SETI@home in order to get a large number of computers all working on small sections of the problem simultaneously to come up with a solution in a reasonable amount of time?  Well, you could do that, couldn't you, Steve.



STEVE:  No.



LEO:  No.



STEVE:  No.



LEO:  Oh, oh.



STEVE:  Not even close.  Now, we've never discussed brute-force attacks against public key encryption, which is the reason this question caught my attention.  We've discussed extensively brute-force attacks against symmetric encryption.



LEO:  Right, right.



STEVE:  Now, okay.  There's two reasons.  First of all, remember that symmetric keys are - they used to be 64 bits.  Now you probably need 92.  But people are at 128 or 256.  Okay, there are enough combinations in even a 128-bit key that brute forcing a symmetric encryption is completely infeasible.  And what do we know about symmetric versus asymmetric encryption?  We know symmetric is fantastically fast.  And asymmetric, that is, public key encryption, is agonizingly slow.  It is so slow because of the math involved - all kinds of exponentiation and higher level curve elliptical functions and things.  It is so slow that nobody uses it to encrypt anything but a symmetric key.



So as we've discussed before, the way you use public key encryption to encrypt a block is you choose a random number with a very good random number generator as your symmetric key.  You use that to encrypt the block of payload because it's so fast.  Then you only use the public key technology to encrypt just that one little 128-bit, 256, whatever it is, symmetric key because public key encryption is so slow.  Now, not only is public key encryption slow, meaning that, okay, brute-forcing attacks are just infeasible for that reason, but due to the different nature of asymmetric encryption versus symmetric encryption, the key lengths are much longer, like 1,024 bits, or 2,048 bits.  And you need that kind of a key length to get the equivalent level of protection that you get with a much shorter, like 128-bit symmetric key.



So on one hand, the algorithms are very slow, and the key lengths are eight or 16 times longer.  So that's why we've never discussed brute-forcing public key encryption.  Although the fact that we hadn't explicitly ever discussed it, I thought, well, this is a really good point.  Doug's question is something that we haven't covered before.  So ne now we have.



LEO:  So the deal is the raw number of possibilities makes a brute-force impossible?



STEVE:  Two, two things.  The raw number of possibilities, that is, already 128 bits is so many possibilities with a fast algorithm that there just isn't time in, like, billions of years.



LEO:  But now you're using 2,096 bits.



STEVE:  Yeah.



LEO:  And it's slow.



STEVE:  And, exactly, and every single one you try is incredibly costly in terms of time.  It's just nobody ever attempts to brute force public key encryption.  They do try to find mistakes in the algorithms or other short...



LEO:  Yeah.  That's your back door.  That's your hole.  Yes, yeah.



STEVE:  Yes, yes.  Other shortcuts of some kind.  But just not brute force because it's very clear to anyone who begins to try, oh, gee, let's see, we've tried six keys in the last 30 seconds.  How many more millennia?  I mean, the universe will expand and contract and expand and contract many times before you have a chance to get that to happen.



LEO:  You just can't do it.  That's just the bottom line.  You just can't do it.



STEVE:  Yeah.  Consequently, the Conficker guys do not need to worry about anybody replacing their payload.



LEO:  No, no.  Russell Gordon in Houston, Texas shares some experience and wisdom with Windows, using Windows in process control environments.  I'll find out what that is in a second.  I just paused the Security Now! 192 I was listening to so I could write and thank Steve for his response to Phil in Montreal.  I have worked in the process automation industry for 19 years, programming PLCs - Programmable Logic Controllers - and designing the operator screens called HMIs - the Human Machine Interface - that allow the operator to interface with the control system.  While the PLCs are not running on Windows, the software to program them is.  And the HMIs are usually industrialized PCs running Windows.  Of course.



I recently had to chase the Conficker worm out of a brewery because it was running rampant on their HMIs, which are unfortunately all connected to the corporate network.  We also have Windows PCs used in the control systems running pipelines, and chemical and pharmaceutical plants.  Luckily these are not connected to the Internet like the brewery.  I guess a brewery is not considered essential technology in the same way that pipelines and pharmaceuticals are.  Luckily these are not, as I said, connected.  But all it takes is a rogue laptop to bring something into the network.  Of course.  Thank you, Steve, for acknowledging the current state of Windows as it is.  I, too, understand how it got this way by supporting backward compatibility.  But I also know how much better it could be.  Russell Gordon.



STEVE:  Yeah.  So that was essentially, here's another person's direct experience with Windows and non-Windows systems, or also networked and non-networked Windows systems.  Here he's not saying that Windows itself was a problem, but letting them communicate is a problem because, as he said, you bring a rogue laptop into the network, and suddenly your off-the-net system is prone to be infected by something that's been brought into the network.  So, yeah, just not a good idea.



LEO:  Yeah.  Question 4, Paul Rudy in Astoria, Queens shares his Windows in the Machine story.  He writes:  I was just listening to #64 Listener Feedback, and it prompted me to send you this message.  I recently went to my local TD bank so I could withdraw some cash.  I looked at one of the three ATMS, noticed it was sitting at a Windows XP Professional logon screen.  That is not inspiring confidence, I'm afraid.  CTRL+ALT+DEL.  It's bad enough that my online password is limited to relatively simple rules.  But now I see the ATM that controls my money is running Windows XP.  I just pray they keep the OS up to date.  I would hate to think that Conficker or some other lovely worm was on this machine, keeping track of everyone's ATM card and PIN number.  This cannot be normal.



STEVE:  No, Leo, that's my point.  It is.  This is what's so disheartening is that - and I'm not going to say anything about what language that ATM software was written in.



LEO:  It's probably Visual Basic.



STEVE:  But we don't know.  But again, sometimes you see these systems unmasked, as this guy did.



LEO:  That's depressing.



STEVE:  One of the three ATMS was waiting for someone to login by CTRL+ALT+DEL.  Which means there's Windows underneath.  And it is truly, truly wrong that that kind of application has a consumer, I mean, this is for consumers.  This is not for industry.  Notice that the brewery we discussed before, they do use Windows for their UI.



LEO:  Just their interface, yeah.



STEVE:  Yes.  But the actual process control systems are non-Windows.  That's the stuff that's turning the valves and running the motors and making sure that beer comes out the other end instead of, you know, lord knows what you would get if those valves and pumps were being set incorrectly.  So it is - what I'm seeing is evidence of this creeping use of Windows in inappropriate instances, in places where you absolutely should not use Windows.  I mean, and there are places.  I mean, certainly consumers are using it.  I'm using it.  I'm sitting in front of it right now.  But not...



LEO:  But nothing's going to go wrong if it crashes.



STEVE:  Right.  I mean, because I'm not controlling a nuclear reactor with Windows.



LEO:  Oh, I hate to think that that's happening.



STEVE:  Oh, yeah, well...



LEO:  But I bet it is.



STEVE:  Let's hope not.



LEO:  [Sighing] Mark Davis, Sandston, Virginia takes issue with Steve's Microsoft bashing.  Okay.  I was hoping we'd get a rebuttal.  Let's hear what he has to say:  I've been a long-time listener to Security Now!.  I'm not sure when I began listening, but I enjoy hearing about what is happening with computer security.  But I take issue with always making Microsoft the bad software company.  I agree they could do a better job, as all software companies and writers of software with security bugs should do.  The issue I take is that most issues - okay.  I'm just going to rephrase this.



Most issues with infected computers come from the users themselves.  That's what I take issue with.  I find they're either too lazy with patching the machines, or they turn off security in their software, or they never read the manual or instructions about how to secure their computer equipment.  The moment software starts making people do the things they should is when they start complaining the program's not user-friendly, and why do I have to click three times to tell a program to do something?  Well, that's a good point.



We all know that software has bugs in it and there are people out there who will spend time looking to find those bugs.  The reason certain software gets targeted is because it has most of the market.  And when someone else has more of the market we'll hear about how bad their software is when the bad people decide it's worth targeting.  And yes, I have SpinRite, which is the only tool for those times when the hard drive says, "Captain, I don't know how much more I can take."



So he has a point.  I mean, I hate it when people blame users.  Look, I do a radio show for normal people.  Users.  And the first thing I say is you shouldn't have to be a security expert.  And because you do have to be a security expert to use Windows, I encourage them to use something else.



STEVE:  Okay.  I think I've probably made myself clear already.



LEO:  Yes.



STEVE:  But I want to make sure that Mark and anybody else who feels I was unfairly bashing Microsoft understands.  Now, okay.  it is the case that I called Windows a big steaming pile of crap a couple weeks ago.  So there's that.  But my point is not that.  My point is the misapplication of  Windows, as I was talking about before.  I mean, Microsoft, all they've got is Windows.  If Microsoft created a little real-time operating system kernel that was designed to be lean and mean and run breweries, I would bet they could do it, as long as they didn't use summer interns to do the programming, as unfortunately they do on a lot of the stuff that we're running.  The stories of the creation of NT - I read several books about that - are just horrifying, about the critical systems that some random summer intern was given to work on.  It's like, okay, fine, looks like you did a good job, good luck with your junior year.



LEO:  There is embedded Windows, I think, and there's CE and stuff.



STEVE:  Yeah, but all that is is stripped down steaming pile.



LEO:  Right.  That's a good point.



STEVE:  It's not rewritten from scratch.  And in fact what Microsoft has done, unfortunately, is they have made decisions over time which they felt were warranted then, but which negatively impacted the stability of the system.  There was once - the original design of NT was, remember, it was a multi-API kernel.  You could run POSIX, and you could run 16-bit Windows and 32-bit Windows.  It sort of had this plug-in architecture.  It was sort of a microkernel approach.  And, gee, we need more performance.  So let's move GDI into the kernel.  Oh, shoot.  Now that means that a buffer overflow displaying a JPG is a kernel overflow rather than out in the user space where it can't do any damage.  And so you could see the decisions Microsoft has made over time for expedience sake have ended up having dramatic security implications.



Okay, I guess I'm not supporting Mark's rebuttal here.  But I understand that software is difficult to create.  I don't blame ever, ever, Microsoft for having bugs.  I blame their policies.  I blame them for the things they deliberately do, like putting scripting in email, like once having scripting in Windows metafiles, apparently on purpose.  And those sorts of policy decisions, or moving GDI, the Graphics Device Interface, into the kernel.  That's what you do not do.  And Microsoft does it over and over and over due to a lack of respect for the consequences of these things.  But the other issue separate from this is there are places you should not use Windows.  Anywhere...



LEO:  Anywhere.



STEVE:  Yeah, well...



LEO:  I'm sorry.  I had to say that.



STEVE:  Anywhere that you absolutely need security and reliability, that's not Windows.  We all know that's not Windows.  And you could argue, okay, it's not Commodore 64 or Mac OS X or Linux or any of the big popular consumer OSes.  And I wouldn't agree - I wouldn't disagree with that at all.  There is a whole separate class of industrial-strength operating systems that consumers have never used because they don't have all the fluff on them.  They don't do all the things that we want.  They may not even have network connectivity like we're used to.  But they are what you want running your ATM at your local bank and the nuclear reactor in the next county.  That's what you want, not Windows.



LEO:  And there, you know, there's secure, I think, BSD, what is it, OpenBSD?  Which one is the one that you like that's the most secure?  NetBSD?



STEVE:  I'm using FreeBSD.



LEO:  FreeBSD, that's it.



STEVE:  Yeah.



LEO:  I mean, there are operating systems designed from the ground up to be secure, that are full consumer operating systems.  I mean, it is doable, if that's your intent.



STEVE:  And that's a very good point.  And Microsoft has not chosen that path.  Microsoft, as I said, has chosen, over and over, expediency.  And here's the real problem is that, now that hardware has caught up, you really don't need GDI in a kernel so much.  But back at one point you did, and that's where it's living now.



LEO:  Well, and there's where the legacy, the compatibility is biting them because they can't take it out.



STEVE:  Right.



LEO:  Even if they know better now, they can't.  Bill in Walnut Creek joins the operating discussion with a comment about the NeXT cube:  Steve, I see we're in agreement with just about how steamy a pile Windows is.  I've used many operating systems - Windows, Mac OS 9, Solaris, Red Hat Linux, HP/UX, IRIX, AIX, Be OS, et cetera.  If I have any criticism of my past work on technology, it was most of the industry completely missed what NeXT was doing.  Think about this.  It has been ported to these CPU architectures:  the Motorola 68030, Intel/PPC, Intel/ARM.  All of these transitions were completely seamless.  It is a tribute to the flexibility of the microkernel architecture that NeXT has maintained despite some cost in performance.  Just imagine if Microsoft had to move Windows to a new CPU architecture.  Oh, that's not going to happen.



STEVE:  No.



LEO:  Oh, that's not going to happen.  The big problem is that Microsoft has packed almost everything into the kernel space - oh, this is what you were talking about - to give them the performance advantage in the '90s.  But now that rooster is coming home.  I really think Apple has an edge on everyone else thanks to the heritage of NeXT, that is now the heart of OS X.  Time will tell, but so far so good.  The developer environment is second to none.  It's a nice hybrid of proprietary and open source software.  I could go on, but I'm sure you either already know or can research it yourself.  Yeah, it uses the mock kernel.  What is a microkernel?



STEVE:  The idea with a microkernel is, I mean, as it sounds, you have a very small trusted environment that provides the minimum set of services, so literally a very small core.  The beauty of that is that it's much easier to design a trusted, privileged, high-security environment which is small than it is to, like, do something like Windows in that kind of environment.  And then the idea then is that everything else that the operating system needs is an external non-trusted module which uses that set of core services.  So things like memory allocation and memory management, process creation and thread creation, the scheduler that jumps the processor around among all the processes that are running, you know, those fundamental services of the operating system are the microkernel.  And then everything else is - and that's trusted.  That has to work.  That has to be bulletproof and provably, knowably secure.



But then you design the system so that all the other things that the OS provides, even though they are traditional operating system services, they're provided as sort of add-ons outside of this microkernel.  And because they're outside, problems in them cannot affect the rest of the system.  So there's a much better sense of containment.  And the bloat that all of these systems end up acquiring over time, the bloat is not kernel bloat, it's user space bloat.  It's outside of the kernel.  So if there's mistakes in the bloat, as there inevitably is, they can't hurt you nearly to the degree that mistakes in a bloated kernel will.



LEO:  Linux uses something called a "modular kernel."  Which is I guess kind of a little bit of both.  You have a kernel, but you can add modules, compile them in to add capability.  I guess it's not a microkernel really.



STEVE:  Hasn't Windows 7 - isn't there something modular about Windows 7's architecture?



LEO:  Yeah.  They claim to have a modular kernel now and a modular system.



STEVE:  Well, but they have that buzzword, then.



LEO:  Yeah.  You know what they're doing, which is interesting, I'm sure we'll cover this in future shows, they've decided with Windows 7 to build in compatibility basically in virtualization.  So you know they've announced that they're going to include with the professional versions...



STEVE:  Yup, XP.



LEO:  XP Virtual.  So maybe this is their way out of this corner they've painted themselves into is, well, we could still be compatible.  We'll just do it in virtualization.



STEVE:  Well, remember that - I think it's in Windows 7 that all support for 16-bit code goes away.  And I think this demonstrates that Microsoft is just - is phenomenally unwilling to break anything.  And so they're saying, wait a minute, I mean, no doubt there is still 16-bit code somewhere that has to run.  And I'm sure that there are some corporate customers that are saying, look, we've got 16-bit code written by people that have wandered off so long ago their forwarding addresses no longer forward to a valid address.  And so someone somewhere is saying we have to have 16-bit compatibility.  And I'm sure that Microsoft said, uh, okay, let's - we'll give you virtual - we'll give you XP in a VM because XP still runs 16-bit code.  And that way you'll be good.



LEO:  It's a good solution actually.



STEVE:  Yeah.



LEO:  It's how I run XP is in virtualization.  Andy in Latvia and, if that were not enough, Peter Katt in Syracuse, ask good and obvious, in retrospect, questions about Conficker.  Andy writes:  Hello.  I was wondering how hard it is to trace the actual people who have registered the domains for the Conficker server used by the Conficker clients?  That's where those updates occur.  And Peter asks:  Steve, in last week's Security Now!, quite informative as always, wouldn't it be possible to track down the person or people behind Conficker by finding out who registered the domains it's using?  Yeah, there are a lot of them but I think someone would be following the money, even if they're using stolen credit card numbers to pay.  The registration orders must be coming from a computer somewhere.  Couldn't its IP address be recorded?



STEVE:  These two questions represent many that I received.  People saying, hey, wait a minute, why not just track down the guys that register the domains?  Well, now we've got 50,000 domains, only one or two or a handful of which need to be registered.  But more importantly, unless you are registering or, for example, acquiring an SSL certificate where your identity needs to be covered, and there is no SSL dialogue going on with Conficker, it uses standard unencrypted connections even though the payload that it is passing back and forth itself is encrypted.



It turns out, I mean, it is very easy to completely anonymously register a domain.  We know, for example, that the TOR network, The Onion Router network, is very good about anonymizing IPs.  So I wouldn't be at all surprised if whomever is setting up these IPs is bouncing through TOR, or maybe has their own network, or may be using their own existing Conficker fleet as an anonymizing service, going through somebody else's machine that they have control of and doing that work there.  And there are lots of ways, I mean, there are so many registrars around, especially when you're now expanded to 110 different domains, that it is entirely possible to forge an identity and register a domain with absolutely zero credentials.



LEO:  Well, and I don't know if this is germane in this situation.  But GJ Dunga says in our Stickam chatroom, remember, you don't have to register the domain, you just have to infect the computer that's providing that - serving that domain.  In this case because they're random domain names I think you in fact have to register that domain.  It's unlikely that anybody's going to have Q37914988873219.



STEVE:  Yes, very good point.  And, yes, yes.



LEO:  But other worms could take advantage of that fact by pointing you to a site that they know they can compromise.  In fact, that has happened in the past.



STEVE:  Yup.



LEO:  Bill Everson, Green Bay, Wisconsin brings news of an IronKey update.  Remember that's the USB thumb drive we really liked that had all those security features in it.



STEVE:  And it's now got one new very cool one.



LEO:  Oh, I'm liking this.  Steve, in case no one has told you about this yet - I'm going to order one right now -  IronKey now supports VeriSign's one-time passwords.  I downloaded the update for my IronKey - oh, you don't even have to buy a new one.  It just updates.



STEVE:  Right.



LEO:  And I'm now able to access my PayPal account with either the football or the IronKey.  Yes.  Since I have both activated, the IronKey can't logon automatically since PayPal brings up a screen that asks me which token I want to use.  Yeah, that's - me, too.  But it is a simple matter to select the IronKey token and have it manually generate the OTP.  That is cool.  So now you can carry a one-time - this basically makes it like a YubiKey; right?



STEVE:  Yes.  What's happened is VeriSign has opened up the SDK.  They have created a software development kit for people who want to do this.  VeriSign - oh, and also, Leo, there's now an iPhone app from VeriSign.



LEO:  Oh.



STEVE:  So you can install this on your iPhone and...



LEO:  Even better, so it can generate the passwords, too.



STEVE:  Yes.  And they've got a whole bunch - RAZRs, and there's a long list of them.  I've got this on my - I didn't have a chance to follow it up in detail, but I did get news directly from VeriSign because the guys thought that I would - that our listeners would find this interesting.  So first we've got IronKey.  Now iPhone and many other phones.  And I'll have a - I'll do some research about...



LEO:  Oh, it's free, too.  Wow.



STEVE:  Yup.



LEO:  So it has a credential ID that I would then register with PayPal.



STEVE:  With VeriSign.



LEO:  VeriSign.  Okay.  I'm already registered using their card.



STEVE:  Right.  And all of the providers who are using VeriSign as their backend authentication, this is then compatible with.



LEO:  Now, point of order, you might be a little less secure because you're putting it on your iPhone.  If somebody gets your iPhone, they've got your card.



STEVE:  Yup, good point.



LEO:  Yeah.  However, that's fantastic.  It's called VIP Access.  Which isn't that what they call it on the web, as well?



STEVE:  Yes.  VeriSign Identity Protection.



LEO:  I'm downloading it right now.  That's awesome.  I almost bought an IronKey, but I don't even need that.



STEVE:  Nope.



LEO:  Wow.  Cool.  I'm sorry.  I should probably continue with the show before I start installing that on my system.  This is Bill Gearhiser in Boca Raton, Florida.  He thought the Conficker podcast left out something crucial.  Steve, your Conficker podcast was fantastic and fascinating, but you left out the most important part.  How do we know if we've got it? 



STEVE:  Very good point.



LEO:  I guess so.



STEVE:  I did make the comment that Conficker has always been blocking DNS access for security-related sites.  So, for example, you cannot go to Symantec.com or McAfee or a number of other sites.  But I thought this was also a good time to remind people that we all, we all Windows users, have the Microsoft software, the Malicious Software Removal Tool in our systems; and it's always being updated monthly, on the second Tuesday of the month.  And remember, running it manually is fun.  It has the option of doing a deep scan.  And it's as simple as just clicking on Start and then Run to bring up the little Run dialogue box, and put in MRT.exe, MRT.exe.  Hit Enter.  A dialogue pops up.  And among other things, there's a link right there that lets you look at the list of all the things it's aware of.  And in alphabetical order, Conficker is among the many things that this Microsoft Malicious Removal Tool is aware of.  So you can absolutely just bring up the little Run dialogue under the Start menu, type MRT.exe, fire this puppy up, and give it a deep scan.  And then go away for dinner because it'll take a while.  But that way you can manually run this test and be sure.



LEO:  MRT.  And Microsoft's MRT has had that since January, I think.



STEVE:  Yes.  It's been aware of Conficker for months.  And it is being updated.  Oh, also, when it pops up, make sure that you've got the current version.  We did run across a Q&A some weeks ago where someone was saying, hey, I popped it up and it said November of '08, and this was in March of '09.



LEO:  Oh, yeah, yeah, yeah, yeah.



STEVE:  I just popped mine up, and sure enough it says April 2009.  So make sure you've got the current one because that would be an indication that Windows Update is not updating.



LEO:  Yes.



STEVE:  And we've seen that happen, too.



LEO:  Yup.  Very important.  D. Larson in Portland, Oregon and Todd Boring in Houston, Texas both wonder what Conficker is up to.  D. Larson writes:  Love the show, guys, especially the last show about Conficker.  I'm not sure what you could call - I am not what you could call an especially technical person.  My question is, what does Conficker do once it's on your computer, and how can you tell if it's on your system?  Sounded like right now Conficker is lying in wait and isn't actually doing anything besides updating itself, infecting others, and staying alive.  Is it logging keystrokes?  Is it tracking traffic to send home later?  Close the loop for me.



And Todd says:  Steve and Leo, thanks for the great podcast on Conficker.  Fascinating stuff.  Makes me wish I were a programmer working for the NSA or something.  That's true.  It's really an interesting field.  You talked at length about how Conficker propagates and how it updates and defends itself.  But I'm still wondering, what does it do?  It seems apparent that it has botnet potential as its owners could send an update command for all infected machines to, say, DDOS a particular website or corporate Internet linkages.  Any proof of it gathering, then delivering data to the author from the infected system?  What does Conficker do, Steve?



STEVE:  Well, these are great questions because I sort of implied but didn't explicitly say that, until E, which is where we are now, Conficker version E, Conficker itself, as D. Larson said, basically was just establishing itself.  It was creating a beachhead of this infection among, well, 10 million machines, if you count all the ones Microsoft has removed it from.  That is, the MSRT we were just talking about has been effective in removing it from, not tens of millions, but more than 10 million machines.  So there's been this battle going on.  Versions A, B, C, and D, they pretty much just existed to exist.  It was this technology, as D. Larson suggests, where is it just sitting there infecting other machines, updating itself, and staying alive?  Yes.



Now, E is behaving differently.  It's installing - there are two different reports.  There's a spam botnet called Waledac, which is well known, which is by the same people who did the very famous Storm botnet.  We remember the Storm worm from times past.  And so this Conficker E is installing this Waledac spam botnet.  And a different report indicates that it is also installing some malicious nagware, Spyware Protect 2009 specifically, which is one of those things that pops up and says, oh, we've just scanned your computer, and it looks like you have an infection.  Anyway, it duns you, just bothering you to death with these popup dialogues until you pay $49.95 for a download that does nothing.  So it's basically just sort of bribery ware, I guess.



The other change is that the E variant, which has now been analyzed and looked at since we talked about C in detail last week, it has restored the original vulnerability, that is, it's using the original unpatched machine problem to spread.  So whereas the later variants of Conficker were not using the original, they were not attempting to exploit the original unpatched vulnerability that Microsoft fixed in October of '08, E is doing so.  So it is now emitting probes, looking for newly non-patched machines to take over.



And the sense is, in the security community, is that some of the later behavior, which seemed to be less aggressive, was in fact resulting in a decrease in Conficker population, that the author may have been getting a little worried that some of the games he was playing with changing its survival and replication strategy weren't working.  And so he's gone back to traditional .A style spreading, which is what really made Conficker as potent as it was.



LEO:  Very interesting.



STEVE:  So the bottom line is, the answer is, Conficker until recently, well, Conficker itself is still just a delivery mechanism.  It's a worm that exists to exist, to communicate, to build itself.  Yet, because it has the ability to install and to acquire updates to itself and also other third-party packages, it has now begun to essentially generate cash.  And ultimately that's what these things are for these days, is until now it was sort of a technical curiosity.  Now it's installing a spamming botnet, this Waledac botnet, and this dunning popup Spyware Protect 2009 stuff in order to begin generating some money.



LEO:  I think they're like most Internet startups.  They're content to establish a base of users before they go for the monetization.  Or public offering.  Barry, question 11.  Barry, working somewhere for the government in Minnesota, writes:  Hi, Steve.  I've been listening since the beginning of the show, and I'm a fan.  But I must take exception to your comment in Episode 193 that you haven't yet seen a smart government person.  You didn't say that, did you?



STEVE:  Yeah, kinda.



LEO:  Steve.



STEVE:  I kinda did.



LEO:  Steve, Steve, Steve.



STEVE:  It isn't what I meant.  But let's...



LEO:  Of course it's not what you meant.



STEVE:  Let's hear Barry out, and I will explain.



LEO:  Yeah.  I know that's not what you meant because I know you know better than that.  As the CISO of a large state agency, I have the privilege of working with many very smart staff and colleagues.  My agency is involved in the healthcare and EHR world, and I share your concerns about the push toward online medical records and the associated security issues.  However, there are clear medical benefits to the consumer, and that's the main driver.  You and Leo answered your own questions within a minute or two of your statement.  However, you didn't retract that statement.



The push to move a product or service to market and accelerated development timelines drive so much that we in the security industry do, whether in government or business.  In the government sector we're also subject to the whims of elected officials, perhaps not unlike those of corporate executives.  It's the rare organization that truly builds security in, although we're all united in that quest.  This is a common theme in our industry, and one you've discussed at length on your fine show.  I suspect we'll find that the compromised Pentagon computers were Internet connected because of a requirement to make them accessible to external contractors.  The breach itself may have been caused either by compromising the contractor end point, or the remote access process, perhaps via social engineering or a weak password or a patch that wasn't applied because of a possible incompatibility with the development code.



All of those things happen.  I also suspect that appropriate security personnel warned about that possibility but were overruled.  So please recognize that those of us responsible for security of government systems, assets, and data are doing all we can, with minimal resources and budgets, to secure that data and maintain citizen confidence.  Keep up the great work, minus that one statement.  Well said.



STEVE:  I really, really apologize.  I know that I said that because Barry was not the only person to write.  I heard from many government people who said, how could you say that all government people are stupid?  Or, I mean, I didn't use that word.  But I'm - and I'm thinking, how could I have said that?  And I know exactly what I was thinking at the time.  And I was thinking about the legislators who I see interviewed that are just...



LEO:  There you go.  That's a different matter.



STEVE:  ...I mean, clueless about this stuff.  I mean, I absolutely meant no slight to the actual people like Barry that are on the ground, as they say now, doing this work.  Of course not.  It was the people, frankly legislators, who I just haven't seen one that understands this.  So, and I know even they, too, are dealing with a bureaucracy that I can't even comprehend, that would just make me shoot myself if I had to deal with that on a daily basis.  So they're doing things I can't do, either, in a different way.  So anyway, I have the greatest respect for government employees who are working as hard as they can, like Barry, and facing, as he says, resource constraints that are probably much tighter even than the corporate world has.  So I certainly apologize for having given that impression.  It was not what I meant.



LEO:  As do I.  Neither one of us believes that, for sure.



STEVE:  No.



LEO:  No.  Sam in Alsager, U.K. is smarter than your average monkey and the author of our last question.  Hi, Steve.  You said in a recent Security Now! episode that Visual Basic, quote, "allows monkeys to program."  You know, these things happen.  I am a computing student and a technology enthusiast.  And I feel that's a bit harsh for someone like me or someone in a similar position.  I know you started programming at my age, 16.  But times have changed a lot.  I've grown up very literate with computers.  However, programming is very different.  At times I've racked my brain for hours to get a program to do something or have to play around with variables or data types.  And so I feel it's a bit harsh to assume that anyone, even monkeys, can program.  There's been no evidence that monkeys can program, by the way.



When I started programming with limited help, and with the web being clogged up with useless crap doesn't help a lot, either.  Not everybody is an amazing Assembly language programmer like you are, although we would like to be.  And I can well understand that, as one further increases their knowledge of computers, we tend to grow farther away from the less technically literate.  And I understand less why they may not know something or understand something.  So I end up by saying, I understand where you're coming from, but please try to be a bit more understanding of the people just beginning with this stuff.  This doesn't change how I feel about the show.  I just wanted a shout-out for the people who are getting started or a little less technical.  Thanks a bunch for yours and Leo's hard work.  Sam.  Sam, that's a great letter.  And you're not a monkey.  But you really should take a look at Python.  Okay, I'm sorry.  Go ahead.



STEVE:  Now, okay.  I did say that monkeys could program Visual Basic.



LEO:  But not that all Visual Basic programmers are monkeys.



STEVE:  Exactly.



LEO:  It was a logical...



STEVE:  Thank you, Leo.



LEO:  ...a logical error.



STEVE:  Yes.  And nor do I think that all Visual Basic programmers are monkeys.  I should explain also something that is true, which is buried now in the depths of history.  And I doubt that many of our listeners will remember, although I know that Nevet Basker, who was the original product manager for Visual Basic, remembers, I am largely credited, that is me, Steve Gibson, Security Now! podcast, with putting Visual Basic on the map.



LEO:  What?  I didn't know that.



STEVE:  Yes.  They came up with it.  I was writing the InfoWorld column.  The product manager, a neat gal named Nevet Basker, came down to Southern California to show this new thing to me.  And we were all blown away.  I mean, this was the first time we saw anything like this, where you had a little toolbar of controls, and you dragged them over and stretched them out, and then you wire up event handlers for the various things.  And before you know it, you have a program.  And I'll never forget, one of my developers, because this was when GRC was growing, and we were probably about maybe 20 people at that point, and I thought I could stand having anybody else write code - which turned out not to be the case.  Thus we're three of us now.  But this guy's name was Millard Ellingsworth III.



LEO:  I love it. 



STEVE:  And Millard made a comment I will never forget.  We were standing there, I mean, I was just in awe.  And he said, oh, this is really bad.  And I said, what?  What do you mean?  He says, "Anybody can write Windows programs now."  He didn't refer to monkeys.  But, you know, he talked about humans, any human.



Okay.  I was so impressed that I wrote three columns.  The next three weeks of my weekly InfoWorld column were about Visual Basic, jumping up and down.  I mean, I was just - I thought, this is just fantastic.  And I once, in one of my trips up to Redmond maybe a year or two later, I ended up having the occasion to have dinner with a group of Microsoft people, including Nevet.  And she said that that following summer, maybe a couple months after I had written the columns in InfoWorld, she was in Europe, doing an European tour to introduce her product, Visual Basic, around to all of their corporate customers and various people there.  And she said that every door was opened to her because people were saying we have to see what it is that Steve is jumping up and down about.  So by all means, we'll give you as much time as you need to tell us about this amazing new Visual Basic that has Gibson just breathless.  So in all fairness, that was then.  I was tongue-in-cheek when I said that a monkey could program...



LEO:  Clearly.



STEVE:  ...Visual Basic.



LEO:  No ape yet has the...



STEVE:  Actually, yeah.  I mean, it is...



LEO:  Although an infinite number of monkeys, as somebody in our chatroom pointed out, typing on an infinite number of computers, would actually be able to write a program that would quote Shakespeare.  So there you go.



STEVE:  Yeah.  Okay.



LEO:  Thank you, Eric.



STEVE:  Anyway, Sam, I apologize for the slight.  I think it's great that you are programming at the age of 16, as I was.



LEO:  That's the best time to start.



STEVE:  It is.  It's a very different era, as you say, now than it was then.  It was, you know, Assembly language was what I got into then because that's what was happening.  I mean, there wasn't - we didn't have Visual Basic and the ability to drag controls out onto a form and stretch them to size and wire them up.  Or I doubtless would have been doing that.  I mean, I also think that Visual Basic has a place.  It certainly, in terms of just getting the job done, I'm sure that Visual Basic is probably still the most used language on Windows of any because in corporate environments where you're not trying to produce a finished product with all the polish and everything, but you're just trying to create some internal access for your SQL database backend, you want to - people have all the requirements, and they're needing this and that and the other thing.  And it's like, hey, just use VB.  And there's nothing wrong with it.  You can certainly write really good Visual Basic code, which has all the complexity and richness of code in any other language.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Yeah.



LEO:  Coding is coding.  Although I still think, I think it'd be great for kids to learn Assembler today.  I don't think there's any harm in doing it.  It's actually a very easy language to learn.  It's much easier than learning VB.



STEVE:  For me the advantage is that, first of all, I have run across many college references to things like the PDP-8 being the instruction set which is being taught.  There are - people have written PDP-8 emulators for the use in educational curricula so that it's possible to learn the simple instruction set and solve some problems.  I really believe there's something valuable about understanding what's going on underneath.  And those tools are available, although it requires that you delay gratification.  And it's certainly the case that you're not going to produce your typical, contemporary, state-of-the-art application quickly in Assembly language because that's just - because we're, you know, the old quote is standing on the shoulders of giants.  I mean, there's so much that Visual Basic is standing on, all the way down to the processor, that most people want an application that looks like something that they're able to buy off the shelf.  Visual Basic gives it to you almost without trying.



LEO:  Yeah, yeah.  And there are a lot of great student languages like Python where there's - Visual Basic gives you, as you say, all that UI access.  And that's nice.  And of course people should learn the concepts of programming before they get too excited about drawing Windows on the screen.  Maybe not, I don't know.



STEVE:  Of course Pascal was designed - it was a language designed...



LEO:  It was a teaching language, yeah.



STEVE:  ...by Nicholas Wirth for the purpose of teaching programming.  And, I mean, it's still the one I wish had survived, as opposed to C.  It's just, it's a little verbose with having to type BEGIN and END all over the place.  I do like left and right curly braces a lot better.  But still it produces beautiful code.  I mean, educationally beautiful code.  Which has a place.



LEO:  Another plug for a Mac.  It comes free with a development system that allows you to do a lot of the - it has a rapid application development tool, just like VB, so you can draw Windows and add code to it.



STEVE:  It's that Xcode pack; right?



LEO:  Xcode, it's amazing.  And you can code in Python, AppleScript, Ruby, all of these come with the Mac, as well as Objective-C.  And we were talking about how strong, what a great operating system NeXT was.  Part of the reason it was so portable was it was written in Objective-C, which is a really interesting extension to C that just really does a nice job.  So all of that comes with a Mac, which makes it a very good computer for people wanting to learn to program.  There's a lot of good stuff.  There's a lot of good stuff out there.  Alice, that Randy Pausch wrote at Carnegie Mellon, Alice.org, great language for teaching kids.  Anyway, we've come to the end of our 12 questions, Mr. Gibson.



STEVE:  Well, and not a moment too soon.



LEO:  Yeah, because I have to run.  But I thank you so much.  Always a pleasure.  Next week do you know what we're going to talk about?  Or is it a surprise?



STEVE:  We're going to finally, finally give our listeners who've been chomping at the bit for the SSL protocol episode what they've been waiting for.



LEO:  Wow.  That's great.



STEVE:  We're going to take all the building blocks that we've talked about, hashing and symmetric and asymmetric and signatures and all that stuff.  We've got all the pieces we need now to look at, okay, what happens with, I mean, this is, as we've said, the number one most used security protocol there is because we all use it.  Every time there's an S on the end of our HTTP, that's an SSL connection.  How is it formed, how is it secure, and how does it work?  We're going to do that next week.



LEO:  Thank you, Steve Gibson.  We'll see you next time on  Security Now!.



STEVE:  Talk to you then, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#195

DATE:		May 7, 2009

TITLE:		The SSL/TLS Protocol

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-195.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo plow into the detailed operation of the Internet's most-used security protocol, originally called "SSL" and now evolved into "TLS."  The security of this crucial protocol protects all of our online logins, financial transactions, and pretty much everything else.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 195 for May 7, 2009:  SSL.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security and privacy related, with our host Steve Gibson of the Gibson Research Corporation, GRC.com - creator of SpinRite, discoverer of spyware, and man about town.  Soon to be man about town with...



STEVE GIBSON:  Well, man about Starbucks.



LEO:  Man about Starbucks.  Yeah, that's a good...



STEVE:  I don't really get out on the town.  I'm pretty much at Starbucks.  In fact, today I was only there for five hours this morning.  As I was walking out at 10:00, Jackie, who opened the store at 5:00, and I helped unlock the front door because I'm always there at opening, she said, "You're leaving early."



LEO:  So wait a minute.  Let me get this straight.  You go there at 5:00 a.m.?



STEVE:  Yeah, every morning I'm there at opening at 5:00 a.m.



LEO:  And that's breakfast for you.



STEVE:  Well, it gets me up and going.  And my new deal now I'm so excited about is I've got my Northgate OmniKey 102 keyboard that I have under my other arm.  And I've been spending 10 to 11 hours a day there.



LEO:  What?  Oh, so you're programming there instead of at home.



STEVE:  Yeah, yeah.  In fact...



LEO:  Why is that?  You like the people around and the bustle?



STEVE:  Well, I spent 10 years sort of, you know, all by myself at home.  And that was good.  But there's actually more distractions here than there are at Starbucks, even though...



LEO:  Interesting, yeah.



STEVE:  Even counting the UCI cuties who come across the street and hang out at Starbucks.  I mean...



LEO:  That's just good for the soul.



STEVE:  Oh, yes, it's - it gives me a little bit of a break.



LEO:  When you get to our age, folks, it's not as much of a distraction as it used to be.  It's like, uh-hmm, and...



STEVE:  Oh, okay.



LEO:  ...back to programming.  Now, are you going to bring - I know you've ordered the new Kindle DX, the big one.  Are you going to bring that around?  Is that going to be your new, like, newspaper that you carry under your arm with your Northgate keyboard?



STEVE:  I don't - I'm not sure.  I've actually put my Kindle down.  I haven't looked at it much for the last few weeks.  I mean, I've really been having a ball, getting a ton of coding done.



LEO:  On, that's so neat.



STEVE:  And there's a very good chance that all of CryptoLink will be written at Starbucks, which would be kind of fun.



LEO:  That's really cool.  Well, you wouldn't be the first program to be written in a coffee shop.



STEVE:  Nope.



LEO:  It's very common.  In fact, we've kind of been looking at larger spaces for - maybe not for another year or so.  But at some point...



STEVE:  Like some retail space you were talking about.



LEO:  Yeah.  And one of the things I would like to do is kind of have a co-working space there so that people in the neighborhood who are smart techies would have a place they could come, they could use the WiFi, we'd probably have a little coffee bar there.  Because people do, I think you're right, I think even though you're working on your solitary thing, you don't want to be completely alone.  It's nice to have a little - people wandering around and making noise around you.



STEVE:  Yup.  And there's a bunch of Starbucks regulars there.  There's another guy, Robert, who's also always there at 5:00.  He's studying French, having mastered Spanish.



LEO:  Oh, that's neat.



STEVE:  And he goes out and paddles after a couple of hours, and so he's there.  So, you know, we - and there's a bunch of regulars.  And it's sort of a little bit of social dip.  But I just can't believe how much I'm getting done.  I'm just getting so much work done.  And I'm a little giddy afterwards.  I think, my god, this is what I'm supposed to be doing.  It's not like I'm playing hooky.



LEO:  Isn't that nice.  That's a nice feeling.  And not only that, you're doing it, and nobody's making you do it.  You're not on deadline.  You get to really enjoy the creative process, knowing that you're going to make something that people will use.



STEVE:  Yup.  Wait till you see it.  I think in two weeks I'll be, hopefully, unveiling this thing that I've been working on, this DNS benchmark.



LEO:  That soon.  Oh, cool.  That's cool.  Well, let's get down to business, to brass tacks, as they are wont to say.



STEVE:  Yes, this is Episode 195.



LEO:  Wow.  What are talking about today?



STEVE:  Well, I've been talking about what we're going to be talking about as the SSL Protocol, which is really a misnomer because it really is TLS.



LEO:  I see that setting in my email program sometimes.  It'll say SSL via TLS, or TLS/SSL or something like that.



STEVE:  Right.  It's really - TLS is Transport Layer Security, which is the renaming of the SSL, the Secure Sockets Layer, which was the name originally given to it by Netscape back in '94 when they originated this.  So with everything that we've learned, all of the background that we have in the previous 194 episodes, I'm going to describe today in sufficient detail that everyone listening who has been following along will really have a good sense for what the number one most popular, most used security protocol on the Internet is, how it works, in lots of fun detail.



LEO:  Cool.



STEVE:  So that's today's topic.



LEO:  Any - oh, goodness.  There's two of me.  Any errata to address before we get to the news of the day?



STEVE:  Well, having discussed the Kindle - I had that on my notes to discuss.



LEO:  That's pretty - we didn't discuss it - now, we should say we discussed it before we started the show.



STEVE:  Oh.



LEO:  So let's go through just a little bit about why you think this is an important thing.  First of all, why did Amazon, hard on the heels of announcing Kindle 2, do another Kindle?  I mean, I just bought a Kindle 2.  I just bought one for my mom a day before the announcement.  Should I send it back?  Should I say "Don't open it, Mom, send it back"?



STEVE:  Well, okay.  I don't have the DX yet, so I don't know.



LEO:  Okay, so you're not reviewing it.



STEVE:  Right.  And I only learned about it minutes before we began recording.  A friend of mine said, "So, do you have your DX yet?"  And I said, "My D who?"  So what I know about it is that it has a 9.7-inch diagonal screen instead of the 6.something that both the first and second-generation Kindles have; that it has a higher pixel resolution, so the individual pixel pitch is tighter; and, significantly, whereas both of the first two Kindles did not have native PDF reading, this one does.  Which is a big feature for me.



LEO:  This is their - I understand this is their way of getting into the textbook market, basically.  You need to have this size.



STEVE:  Yes.  Presumably.  I mean, I, for what I was doing this morning during my five hours at Starbucks, was re-reading the RFC.  It's RFC 5246, which it's the largest RFC I think I've ever seen.  It's 104 pages long.  And this is the detailed specification for v1.2 of TLS, the Transport Layer Security, which is the topic of this week's podcast.  And I printed it out.  I printed it out double-sided to save paper.  So there's 52 sheets of paper.  I would have much rather written it to a PDF, stuck it on something that I could read.  Now, yeah.  I could do it on a laptop.  But this DX, the fact that it is able now to render PDFs, and the screen is large enough that you can actually see the content of the PDF that's rendered, now I'll have a portable PDF reader.  And...



LEO:  So when I email a PDF to my Kindle, as I have just - as I've done recently, it's converting it.



STEVE:  Correct.  It converts it to its native format, to the Mobi book, the Mobipocket format.



LEO:  And why is that not okay?



STEVE:  Well, look at the PDF, and you'll find that it just - it didn't make it.  There aren't enough pixels to render a typical full page that the PDF assumes, and PDFs are non-reflowable.  Whereas books can be dynamically reflowed because really a book, a textual book is just a stream of characters.  And so when you change the font size, for example, you're able to reflow so that you repaginate.  But, for example, you can't change the font size on a PDF because - you can scale the whole page, but you can't change the font size because the PDF is a page layout specification.



So anyway, I'm excited.  And I know a number of my other techie friends, for example Mark Thompson, the one question he had about - of AnalogX.  The one question he had about the Kindle was will it display PDFs?  And I said no.  This one does.  The DX does.  And it's...



LEO:  Because its page size is big enough to show an 8.5x11 or an A4 page without reflowing it.



STEVE:  Well, with enough resolution.



LEO:  So you can just put the - basically, yeah, because a PDF is a picture of a page, basically.



STEVE:  Right, exactly.



LEO:  You can put the picture of the page on it.



STEVE:  You can certainly put that on your Kindle.  And I did.  Kindle 1, which has the same resolution as the Kindle 2, I did put a PDF on it.  And I thought, okay, well, I'm not doing this again.



LEO:  Okay.  Well, that's kind of intriguing.  But I'm a little worried.  I'm going to wait till you get yours because I'm a little worried that it's just too big because I mostly read my Kindle in bed or on an airplane and stuff like that.  And I'm a little concerned that it might be a little big.



STEVE:  Yeah.  I'm reading textbooks that often have diagrams.  And the diagrams don't survive very well on Kindle 1 or 2.



LEO:  Yeah.  Yeah, I'll give you that, yeah.



STEVE:  You have to get out a magnifying glass or squint and so forth.  And so that's another example where this DX, it will be much better for books containing diagrams.



LEO:  Well, I'm glad you're the guinea pig.



STEVE:  Hey, for the first time ever, Leo.  Normally you're...



LEO:  Normally I'm the early adopter.  If I hadn't just bought that Kindle.  I'm a little miffed, frankly.  But I guess I could have Mom send hers back.  Because she does want the big type.  I just don't know - she tried my Kindle 2 and loved it.



STEVE:  Yeah.



LEO:  [Grumbling]



STEVE:  Well, it's hard to say.  I mean, for your mom, she's probably, what, in her 80s, like mine?



LEO:  Right.  No, late 70s, yeah.  Mid 70s.



STEVE:  Yeah.  At that point, you know, having a bigger page with bigger fonts, I think there's some advantages there.



LEO:  Yeah.  Well, she had stopped reading books, and she couldn't read even papers for very long.  And when she tried the Kindle, she read a whole book while she was visiting last week because she could make the font size a little bit bigger.  But it's big enough on the Kindle 2.  So I don't know.  Well, I'm going to watch you.  Thank you for being the guinea pig.



STEVE:  Happy to be.  And it's pre-order time.  It's not like they're shipping them yet.  They're saying they'll be shipping...



LEO:  Right, summer.



STEVE:  ...sometime this summer.



LEO:  Academia time.



STEVE:  I immediately logged myself in to get in the queue.  So I'm excited.



LEO:  You know what, this really is exciting for school books, textbooks.  They're very, very expensive.  Kids carry 20 pounds, 30 pounds, 40 pounds' worth of books in their backpack.  This is a much better solution.  If Amazon can get those book prices down.



STEVE:  Well, and Leo, I mean, I just - I recently purchased a tablet PC as part of my new Starbucks kit because I'm using an external keyboard, the old Northgate OmniKey 102.  So I got them - I bought the tablet from Motion Computing.  They're a well-known, reputable tablet maker.  They sort of like do the higher end industrial tablets for, like, vertical markets, for hospitals and construction workers and things, really well built.  I really like it.  It's a 12.1-inch screen, 1400 by 10-something resolution, so lots of resolution.  Of course it's color.  It runs Windows.  I mean, it's a perfectly adequate PDF viewer.  You can run it in portrait mode instead of landscape.  And, I mean, so it's not like solutions don't already exist which would be totally adequate, except that that doesn't run for two weeks without a charge.



LEO:  The other thing that's going to be interesting...



STEVE:  [Indiscernible] run for two hours.



LEO:  ...is we haven't heard Apple, from Apple yet.  And next month Apple's going to come out with something, I suspect.  And many rumors are that it might be a reader, or at least have reading functionality.  So we'll see.  We'll see.  It's all very interesting.  What else is in the news?



STEVE:  Well, we have a significant Adobe zero-day flaw.



LEO:  Oh, a second - another one, like the one in February.



STEVE:  Another one.  And in fact this is bad enough that it's now time for all of our listeners to do the following:  Click on any PDF that you've got on your system that will open the Reader.  And this affects both Reader and the full Acrobat product.  Go to the Edit menu, which is the second one over.  File is the first; Edit is the second.  Choose Preferences.  There's a, now, you're going to have a big dialogue with bazillion categories down the left-hand side.  Fortunately they're alphabetical so you can go to "J" for, not surprisingly, JavaScript.



LEO:  I know where you're going on this one.



STEVE:  My number one nemesis, JavaScript.  Select that, and the first checkbox is Enable JavaScript.  Unfortunately, it's on by default.  Thus the problem.  Just turn it off.



LEO:  You know what's sad, there is no reason for you to have JavaScript in a PDF.



STEVE:  Exactly.  PDFs do not need JavaScript.  And so here again we've got - found in the wild was a remote code execution exploit, another one.  I mean, Adobe's been having a bunch of problems, not only in that but in Flash.  I mean, so all current versions of Reader and Acrobat, which is - I'm still on v8, as we've discussed.  So mine, the one I've got, 8.1.4, is vulnerable, 9.1, and 7.1.1.  So both 7, 8, and 9 releases on both platforms, Reader and Acrobat, are vulnerable to this.  It was a zero-day exploit, meaning that they discovered it because it was being used to run code on people's computers when they viewed PDFs.



Fortunately I had already taken my advice, and I had JavaScript disabled in my Reader.  Everyone listening to this should just turn off JavaScript.  You'll lose nothing because who even knows, I mean, I don't know that I've ever seen a PDF that had JavaScript in it.  You know, it's for reading documents.  So turn it off, and then you don't have anything to worry about.  And we'll let you know.  Apparently next week from this podcast, so here we are, this is May 7th is the date of this podcast.  So a week from now they should be pushing out a fix for this.  They're working on it feverishly.  Fortunately our listeners, who are smart enough to just disable JavaScript, can protect themselves right now.



LEO:  Many of our listeners use Foxit and don't use Adobe Reader or Acrobat.



STEVE:  And boy, Reader is 200-and-some megs in size.  It's just - I installed it...



LEO:  It's the JavaScript engine.  Why?



STEVE:  ...installed it on this new little tablet of mine, and I downloaded the latest one, 8.1.4.  And it was - I think it was 214 is the number I'm remembering.  It's like, yeow, just to read PDFs I've got 214 - well, that was the download size.  Who knows how large it blew itself up to when it landed on my hard drive.  So anyway...



LEO:  It's just - it's remarkable.  And I don't use - I stopped using Reader after the last problem.  But just, boy, you know...



STEVE:  And so have you been using Foxit?



LEO:  Yeah, Foxit's great.  I've used Foxit for a long time.



STEVE:  I think maybe - maybe I'll just switch.  I mean, you know...



LEO:  Not that they're immune from exploits, either.  But this is two in a row.



STEVE:  Well, and I'd rather have something smaller.  I just don't want 200-plus megs of bloat in order to read a PDF.  That's nuts.



LEO:  Yeah.  No, I'm with you on that.



STEVE:  So the only other thing I had was a really short little note from a happy SpinRite user, Doug Davis, who actually wrote to us on Halloween, and I had his in my list of testimonials to get to.  He just said, "I'm a very happy owner of SpinRite.  I have a laptop that would just shut down whenever the virus scanner tried to scan the disk.  Other scanners and disk checks caused the same result.  At first I thought a virus was compromising my machine, thus shutting it down so that it couldn't get scanned.  But finally I bought SpinRite on a hunch.  I ran it, and it magically fixed the disk, and my virus scanner now works again.  Another happy ending.  Thanks for this great product.  Regards, Doug Davis."



LEO:  Excellent.



STEVE:  So you never, I mean, I wouldn't have even recommended SpinRite in that case.  But that's what the problem was, and so he was able to fix his system.



LEO:  I'm hearing from our chatroom that Foxit also has JavaScript enabled by default.



STEVE:  Eh, well.



LEO:  Not the same - there isn't the same bug, of course.  That's a bug in the Adobe implementation.



STEVE:  Right.



LEO:  But there must be something that's going on in PDFs that there's a need for JavaScript.  I can't...



STEVE:  No, not necessarily.  Could just be bullet point-itis.  That's what bloated ZoneAlarm up to the point that it was no longer useful or recommendable.



LEO:  They've got JavaScript, so we have to have JavaScript.



STEVE:  Well, in the case of ZoneAlarm, of course, they were competing with Symantec and McAfee that were just - that were turning their own personal firewalls into kitchen sinks.  And, I mean, I was complaining to Gregor.  I said, "Gregor, don't screw up ZoneAlarm by putting all this other nonsense in it."  He says, "I hear you, but I have to.  We have to compete."  And so it may be that Foxit went out and got some JavaScript engine from somewhere and stuck it in, just so they had it, too, even though it'd be nice if they didn't, and it would be smaller if they didn't.



LEO:  It's crazy.  Oh, well.  These are the things we have to live with.  All right.  Let's talk about SSL, Steve Gibson.



STEVE:  Well, we really need to talk about TLS.  So SSL is, because it was what came first, it was - it's what we still refer to this protocol as, commonly, although it's really not the case actually that SSL is in use.  TLS has formally and completely replaced it.  It is substantially more bulletproof.  SSL has an interesting, somewhat spotty history, more so than is commonly known.  I mean, we've beaten up the early WiFi protocol, WEP security, pretty badly.  We've never really done the same for SSL.



SSL is a specification for securing any reliable protocol on the Internet.  Meaning, for example, PCP, as we've discussed, is a reliable protocol because even though the connection itself is not reliable, meaning that routers that are briefly overloaded have, by permission, have the ability to drop whatever packets they're unable to route.  They only make a best effort.  Routers make no guarantee.  So an unreliable protocol, that is to say a non-reliability-guaranteed protocol, for example, like UDP, which just sort of sends packets out, you cannot run, for example, SSL or TLS over UDP.



Turns out there is lately a variant that is a packet-based, a so-called datagram-based SSL which is designed to run over a non-reliable protocol.  But SSL or TLS, as it's been renamed, does assume that anything that it sends will get to the other end.  So that is to say that the underlying protocol, which is normally TCP, if packets are lost in transit, TCP will take responsibility for retransmitting them.  And at the receiving end the TCP protocol will assemble them in the right order and end up presenting to the next level up, which is TLS or SSL, it'll end up presenting sort of a reconstructed error-corrected stream.  And in fact it's worth talking a little bit about this notion of layering because that's inherent in the way SSL/TLS works.  In fact, instead of using both acronyms from now on I'm going to try to say TLS, since that is the protocol that we're all using.



All contemporary web servers support the latest version, which is TLS 1.2.  Firefox 2 and 3, IE7, and the latest versions of Opera, all the current browsers support TLS, as do servers.  There's a nice technology that we'll be talking about for sort of dropping back.  So the idea is that you will - the browser and the server will always negotiate the latest version and the best strength of available ciphers and hashing and signature and public key technology that each of them know about.  So that there's a - it's been really well designed so that the resulting connection is the lower of the highest versions that both support.  So it ends up doing the right thing.



But we have this notion of the physical connection, the actual - the protocol on the wire is, for example, often Ethernet, where we know that addressing is by MAC addresses.  And then running on top of that protocol is the IP layer, which provides - where addressing is by IP addressing.  But so IP protocol runs on top of the Ethernet protocol.  And then it is the host for the IP protocol suite.  For example, ICMP, which is like the ping and traceroute uses that, is a protocol running on IP.  UDP and TCP that we've talked about are two other protocols running on IP.  So in this case we've got Ethernet at the bottom, sort of on the physical wire, then the IP protocol to allow IP addressing.  Then that hosts TCP, which provides both this abstraction of an IP address and then this notion of port numbers so that you have a 16-bit port number.  So that's where portage sort of comes from.



Then normally you would then run your application layer, that is, your application protocol, which would be, in the case of a web browser and server, it'd be HTTP.  Or it could be FTP or Telnet or whatever.  That is, those are protocols, application-level protocols, that run on top of TCP.  They all assume a reliable TCP connection so that they're not worrying about lost packets and so forth.  They rely on the underlying protocol, TCP, to do that for them.



Well, what TLS does is it inserts itself in a transparent way between the TCP layer and the application layer.  So that essentially it's another wrapper, or sort of another little shim in this layered stack of protocols.  And so it relies, as I was saying before, on the underlying layer, TCP, to provide it reliability.  So it needs and assumes that it's running on a reliable protocol, TCP.  And what it does by inserting itself between TCP and the application layer is it provides a number of services to the application layer, to HTTP, turning it into HTTPS, or FTP if you have, for example, secure FTP or secure Telnet.  That is, any application is able to run on TLS and get all the benefits of security that TLS provides to any client application.



Now, this was originated by Netscape, and they pretty much did a good job.  They started off in 1994, which is 15 years ago our time, at this point, and it's interesting.  They're not security people, but they were smart people and tried to do a good job.  They came out with SSL v1.0 that was, unfortunately, so broken that it never saw the light of day.  They produced a formal specification and fortunately got some feedback from the Internet community before just going public with it.  And that really got the crypto guys involved, who looked at what they'd done and said, oops, you can't use this.  The crypto guys immediately saw a bunch of problems with the things that Netscape was proposing.  And so SSL 1.0 never happened.  Sometime later, in fact I think it was February of '95, Netscape took advantage of all the feedback they had received on the never-released 1.0 and did produce v2.0.  So SSL v2.0 is the first version of SSL, Secure Sockets Layer, that anyone ever saw.



So what does it provide?  Well, we sort of know from all the discussion that we've had over the last nearly four years what we rely on SSL for.  We know that we rely on it for confidentiality, that is to say, encryption.  It has ciphers in it such that no one monitoring the line is able to obtain any information, is able to know what it is that we're sending back and forth.  One of the nice features of both this original SSL and today's TLS is that all of the connection and handshaking is done before even the first byte of the application layer data is transferred.



So TCP, the layer below this security layer, TCP does its SYN, SYN-ACK, and SYN, the standard three-way handshake, typically involving three packets, which establishes sequencing and confirmation of a connection.  At that point SSL performs its handshake and negotiation, which is what we're going to talk about in detail here in a couple minutes.  And all of that gets done, and both endpoints of the security protocol are - they need to be satisfied and happy and established, essentially, prior to the application layer that's been waiting all this time.  The application layer initiated this, but no actual traffic is emitted at either end until this secure layer has been established.  So nothing of what the application is doing is able to leak out into, you know, in any way out of the LAN or the WAN, the Internet, anywhere.  So it really does wrap the entire dialogue in a confidential tunnel.



It also, as we know, both SSL and now TLS provide authentication.  We've talked a lot about server-side certificates, and we understand that a certificate is identification information and a public key which has been formally signed by somebody that the recipient of the certificate trusts, and that allows them to verify that nothing has been tampered with.  And that is a way for them to obtain the, for example, in the case of a typical web browser and server, it's a way for them to obtain the public key that matches the secret and private key of the server, which is used by this protocol in a way that we'll see here in a minute.  So that provides authentication and some cryptographic credentials.



It also provides tamper proofing, which is important because it's one thing to know that the message is secret and that it's authenticated.  But if it was possible to tamper with the message, then we're not so happy because there are various hacks that can be used if you could tamper with the stream that could still cause trouble, even though the message is confidential and authenticated.  And in fact that's where SSL 2.0, it's one of the places where it tended to fall down.  It also provides proof against message forgery so that nobody is able to, for example, do a replay by sending packets again and forging packets from either of the endpoints.  So all of the packets are serialized through the entire connection, and both endpoints make sure that they never get a duplicate serial number, no serial numbers are missing.  Because again, another - you could imagine some sort of a clever attack where somebody would - who, again, who can't see into the packet, who can't pretend to be someone generating the packets, might take some out and in that way again compromise the communication.  So SSL and TLS provide proof against that, as well.



So 2.0 had some problems.  It was good, and we used it for a long time.  And there weren't any highly publicized breaches in SSL 2.0 because it was well designed.  But, for example, it uses the MD5 hash.



LEO:  Whoops.



STEVE:  Well, that wasn't a problem back then.



LEO:  We know it's a problem now.



STEVE:  Yes, exactly.  We know that there are all kinds of problems with MD5.  So we had to move past using an MD5 hash.  SSL v3 sort of fixed it a little bit by coming up with a clever solution.  They hashed both - they produced both an MD5 hash and an SHA-1 hash, and they XORed the result.  So that means that the result sort of hybrid hash depended upon both, which was an interesting solution because it meant that either one could be compromised; but since the result was an XOR with the other, presumably uncompromised hash, you'd still get the full strength of the surviving uncompromised hash.



LEO:  That's pretty clever, actually.



STEVE:  It is, really clever.  However, the sense was, eh, you know, that's kind of a kludge.  And TLS, which is where we are now, it started off as SSL 3.0.  So it was sort of just a renaming of 3.0 into TLS.  And it was - when it went to TLS is when the IETF, the Internet Engineering Task Force, took it on as a formal standard.  They said, okay, this is important.  We're going to take this under our wing.  We're going to rename it in the process.  But 3.0 looks pretty - SSL 3.0 looks pretty good, so that's what 1.0 - that's what TLS 1.0 is going to be.



Well, we're now at 1.2 because a number of improvements and refinements have been made.  For example, the use of SHA-1 and MD5 is gone completely.  We're now using just SHA-256, which is state of the art, much stronger than either the MD5 or the SHA-1 hashes.  And those, again, can be supported in the case of downgrading your connection to an earlier protocol.  But given that both endpoints support TLS, that won't happen.



SSL 2.0 also had a problem in that it used identical cryptographic keys for both message authentication and encryption.  And while it's not a horrible thing to do, it's just not good.  The crypto guys worry that using the same keys for two different purposes is fundamentally less secure than using separate keys for separate purposes.  So one of the things that 3.0 did, SSL 3.0, is that it said, okay, we can make keying material at will.  So let's make more keying material and use separate keys for authentication and for encryption.  So that's one of the other things where we moved forward from v2 over to 3.0.



There was also an interesting attack that was discovered.  And again, it's sort of a theoretical problem where you could - a man in the middle could intercept and mess with the handshaking phase of SSL 2.0 where the two endpoints are negotiating the cipher that they're going to use and the authentication.  Basically - and I'll go into this in more detail in a minute.  But essentially the client sends a list of all the ciphers and hashes and public key and key exchange technology that it knows about.  And so it sends this list off to the server and says, here's how smart I am.  And basically it's - so the server knows all the different suites of protocols that are being offered to it, essentially, to use by the client.



The server then looks at its own list and in every case chooses - and this is a hierarchy - chooses the best of each of these categories that it also knows about.  So that's how the client and server are able to arrive at, like, the best way they each know of speaking to each other, yet in a way that allows a less capable endpoint to still establish a connection.  It's not as good, as strong a connection necessarily, if you wanted to get really picky at crypto.  I mean, even, like, the least secure is, like, way secure.  But it's not state of the art.  So that allows endpoints with different knowledge of cryptographic suites to still be able to negotiate a connection.



Well, it turned out that unfortunately this negotiation was not adequately protected.  So there was an attack possible where a man in the middle could essentially trick the server into believing that the client was much less capable, in fact virtually incapable of any useful security and therefore essentially really interfere with the resultant strength of the connection.  So one of the other things that was fixed in 3.0 was that that initial handshake, that we'll again be talking about in a minute, was strengthened to prevent any kind of modification and man-in-the-middle attack.



Essentially there's now a Finish message that each end exchanges which involves the hash of everything that they've said to each other, which is really very clever.  And that's encrypted based on the encryption keys and protocols that they have established.  And so what that does is each end is hashing everything it sends and hashing everything it receives and concatenating that.  And then the idea is that each end is able to verify that hash, which is a hash over the entire exchange so far.  So if anything was altered or modified in transit, the other end won't - the other end will have something different than the local end believes it sent.  Thus the hash won't match, and the endpoints completely shut down their connection and begin a renegotiation.  So it's much stronger now than it was before.



And it's interesting because SSL 2.0 didn't have this notion of any sort of a finish.  It just, well, it wasn't providing that kind of handshake protection.  And also the overall connection didn't have a "okay, we're finished with this connection."  And it turns out that there were some clever attacks that involved truncating a communication.  And in SSL 2.0, when TCP shut down, that is, the underlying protocol shut down, then the protocol above, that is in this case SSL 2.0, it said, okay, I guess we're done, and it sort of wrapped itself up.  Well, now there's a formal end-of-message communication added in at SSL 3.0 in order to say, okay, this is really the end.  I've been told by the application layer that we're done now, so it's okay to shut down.  Which was missing from 2.0, that was added in 3.0.



And finally, there's a feature that still hasn't been implemented.  It's funny because I was, in reading some of the commentary on the spec, there was some commentary that mentioned that, gee, you know, this feature hasn't - no one's used it yet, but it's in there, and it'd be really nice to have.  And that is, there is a provision that appeared in 3.0 and has survived in TLS that allows more than a single service.  That is to say, SSL 2.0, and actually all practical implementations because we're still not using it, as I said, assumes that everything is known about the remote endpoint, that is, that the identity of the remote endpoint is known.  So that when, for example, the client connects to a server at a given IP, that server responds with its certificate.  But this causes problems with virtual hosting because, in a virtual hosting environment that we have discussed in the past, you can have many different websites located at the same IP.  And it's the host header in the HTTP protocol that specifies which hosting website you want to connect to at that IP.  If you don't have that, if you're unable to use that, which is the case now, you can't - you have a problem with SSL certificates because you can only bind a single certificate to a single IP.  And so there isn't a good way to do virtual hosting.



What some people have done is used wildcard certificates, where it'll be essentially asterisk dot, and then an underlying domain dot com, and then other domains are defined.  So, for example, you might have webservice1.commondomain.com, webservice2.commondomain.com.  And so the certificate would be *.commondomain.com.  Well, that provides you the ability to establish an SSL connection to any of the subsidiary different domains.  But suddenly now you've lost a lot of protection because you don't know what domain - you've lost the authentication because you're authenticating to, essentially, to a parent domain, not to the subdomains, which is what you really want.



The point is that with 3.0, although it's never been used, and also in TLS, there is the ability for the client to specify which certificate it would like to receive from the other end.  So there is really nice native support for a virtual hosting environment.  And the reason I was chuckling was that, well, none of the certificate people are anxious to offer something like that.  They would much rather sort of force a certificate per IP and sort of leave things as they are.  It's interesting to me that this facility exists, yet no one has implemented it.



So all of these things that were wrong with 2.0 have been fixed in 3.0.  SSL 3.0 was then, as I said, sort of taken over by the IETF.  And that was, in terms of timeline, we got SSL v2.0 in February of '95, 3.0 in '96, and then the IETF, it was in '99 that the IETF took it over and began to sort of take it under their wing and create a more formal specification.  So I read, or reread, the specification this morning.



LEO:  On your Kindle.



STEVE:  No, remember, I don't have my big-screen Kindle yet.



LEO:  Oh, that's right.  On your tablet, yeah.



STEVE:  So I printed it out in old school - it's 104 pages of really dense stuff.  I mean, it's not - it's the exact opposite of light reading.  But I have to say it is - at 104 pages, that makes it one of the largest RFCs I think I have ever encountered.  But it is just - it's a pleasure to read.  It is a beautifully put together specification.  I mean, and in the beginning it talks about how this is - we've produced this document for people who actually have to implement a working TLS v1.2.  Everything is here that you should need.  And it's just - it's laid out just in a spectacular format.



So TLS further improved on v3.0 security.  They continued to tweak things.  More than anything there was more - it's sort of a more rigorous specification.  There's a formal approach used in RFCs where in the interest of improving interoperability, there's this notion of using the terms "may," "should," "shall," "shall not," "will not."  And, I mean, they've got real exact meaning in terms - sort of within the RFC specification protocol itself.  And so as you're reading RFCs it'll say such and such and such "may" provide this or "should provide" this or "must not."  And so - and often these are in capital letters because, I mean, they really intend for readers of the RFC to pay attention to that sort of thing.



Well, there always was some ambiguity that caused implementation problems in previous versions of SSL, so that people tended to copy each other's implementations rather than doing it from scratch themselves because they may not interoperate because the specification really wasn't rigorous enough.  It didn't really clearly specify exactly how everything should work, sort of in those edge cases, in the boundary cases where it's like - where a programmer goes, you know, who reads the spec goes, well, wait a minute.  You've sort of said "greater than or equal to" here.  But over here you said "greater than."  So what exactly do you mean?



LEO:  Which is it?



STEVE:  Exactly, which is it?  I mean, programmers, and of course who...



LEO:  And computers.



STEVE:  Who at that point are reflecting what the computer is thinking, you can't have it be either way.  It's got to be one or the other.  And that's typically where code falls down.  So TLS has really worked to make that a lot more strong.  It discarded in the later versions the use of this hybrid MD5 and SHA-1 approach so that it's just not even in there anymore.  There are alert messages where either end can send each other warnings when, like, something doesn't look right.  There are many more alerts in TLS.  And whereas before there were, like, "should" verbs tied to those, now they are "must" verbs.  So it's like you're more sure that, if there's a problem, the other point, the other endpoint will - the other implementation will be notifying you for sure that that's going to happen.



Also the pseudorandom sequence generator, both inherent in crypto, we talk about cryptographically strong pseudorandom number generators.  Crypto needs a lot of random numbers.  They are used, so-called "nonces" is used once and often encrypted using public key technology in order to provide a secret, even over a channel that may have eavesdroppers listening in, that can be received by the other end, decrypted using some pre-agreed upon cipher, and so the other end is able to get that information.



So again, TLS has a more robust and stronger pseudorandom number generator based on the HMAC.  And in fact one of the reasons I had been - we talked about HMAC some time ago, and I declared it as the final thing we needed in order to talk about SSL, or TLS, is that it's TLS that uses the HMAC, that is, the keyed Message Authentication Code.  And remember that the way that works, real briefly, is that you take something that you want to hash.  You append a particular hex pattern, I think it was 5C, a block of 5Cs, and then you hash that - oh, and I'm sorry, you append your key and then the 5Cs and then the content, which you hash.  And then you take the result of that, and you use the key, a different hex pattern, and the result of the first hash which you hash, and that's the result.  So that this is the so-called HMAC.



And it is so strong, and people are so happy with it, that they made that the basis for the hashing in TLS and even the source of pseudorandom data.  That is, you start with a seed and a key, and you run HMAC on it in order to generate some material, and then you HMAC that along with the same seed to generate a next chunk of material, and you HMAC that with the seed as many times as you need to as your source of pseudorandom data.  And this keyed MAC, this HMAC is good enough that what it's producing through just successive iterations of itself has passed all muster among the cryptographic security guys.



So, okay.  So that sort of gives us an overview outline of the history of the evolution of SSL to TLS, where we are now.  So let's talk about how these guys connect.  There is a series of protocols which are just packets in an agreed-upon format that's sent back and forth.  So when the client connects to the browser, the first thing that happens is a TCP protocol connection is established.  Then, if this is going to be an HTTPS connection, for example, a secure connection, the first thing that happens - oh, the way the server expects that is the port that you connect to.  As we know, web servers that are not going to be using a secure connection will connect by default to port 80.  If you are going to use a secure connection, by agreement you connect to port 443.  So any incoming TCP connection to port 443 assumes that an SSL, or I should say TLS, connection is going to be made.



So the first data that the server receiving this connection expects from the client is the so-called "Client Hello" message.  Now, packets and messages are sort of separate things because the packet is the unit of transmission over the Internet, but a packet can contain, I would say one or more, but actually even zero messages.  There is a provision, sort of clever, in the current TLS to deliberately allow null traffic to be sent in order to confuse anybody who might be trying to do a traffic analysis.  So it is even possible to send no application data, just sort of to send some blob, just to sort of, like, mess with the people who may be trying to figure out what's going on.  I got a chuckle out of that.



But so the client sends its Client Hello message, which contains the highest TLS or SSL protocol version that it knows about, that is, that it supports.  And this is the way, this is the first step in this negotiating for the best connection, the most secure connection possible.  Also in there is a 32-byte random number.  It's composed of the UNIX time at the client end.  UNIX time is just a 32-bit value which is the number of seconds since January 1st, 1970.  So it takes those 32 bits, or four bytes, and it appends that to 28 bytes that it has locally generated randomly.  That produces a 32-byte random number, which it includes with the highest protocol level that it understands.  It also sends a session ID.  It makes up a session ID.



And what's interesting is that there's always been this notion of caching credentials at each end.  We've talked often about how expensive public key crypto is.  And, for example, in the case of a very busy server, which is inherently using a lot of secure connections, a lot of TLS connections, there's some tremendous overhead associated with the public key aspect of this negotiation.  So there is the notion, both in the older SSL and now surviving in TLS, the notion of the endpoints being able to cache the result of that expensive public key work.  And so what'll happen is, if the client is connecting to the same endpoint, that is, at the same IP, same web server URL that it had connected to before, so that is to say, if it still has credentials cached from a previous connection, which may have just been seconds or fractions of a second before, it will offer the session ID from that cached credential to the server.  It doesn't - there's no guarantee that the server is going to accept it.  But it'll make the offer, suggesting that, hey, I still remember you from just a second ago, and maybe we could dispense with some of this if we both agree to do that.  So that's in there.



Initially in this same Client Hello packet is a list of all the cipher suites that it knows about, things like Triple DES, AES, various types of cryptographic packages, and also the compression methods that it knows about.  There isn't much work that's been done on compression.  And I've seen that sort of opinions vary about whether any of it's being done or not.  You either have no compression, or apparently there is the ability to use the standard UNIX-style deflate compression.  That's of course always done before you encrypt because, as we know, you cannot, by definition, you cannot compress anything that's been properly encrypted because it just looks like randomness.



LEO:  It's random, yeah.



STEVE:  Randomness has no compressibility.  And then optionally there is the ability for extensions to be added.  One of the nicest things about SSL and TLS is that they've always provided, by careful design, extensibility.  So that we don't have to break any of this in order to move forward.  That is, we're able to retire ciphers that, for example, if a cipher were suddenly discovered to have a problem, well, either end could remove it, and it could never again be used by that end or by anybody that it was going to have a conversation with.



Similarly, all of this sort of has a list-based architecture where new ciphers coming onstream can be added.  Because this is an IETF standard, the IANA is the sort of the formal enumerator of these things because they end up just sending, like, a list of numbers.  So you need to know what ciphers those numbers represent and which hashes and so forth.  So that's the IANA establishes all of those things for TLS moving forward.  So this packet, this Client Hello packet goes to the server saying this is the specification, the highest level specification I'm aware of.



Oh, and by definition all previous specs are known to state-of-the-art TLS client and server endpoints.  But it's felt now that enough time has gone by since SSL v2 - which remember came on in February of '95, so, what, 14 years? - that most endpoints will not downgrade themselves to SSL v2.0.  Some can be configured.  But by default they'll go back to 3.0, but no further back.  Even if they may know how to, they'll just - it's like, eh, no, we don't want to use MD5, for example, under any circumstances.  So there's a limit to how far back they will go.



So this packet says this is the version I know of.  Here's some randomness, 28 bytes of pure crypto random with this extra four bytes of UNIX time tacked on the front, just to give it a little extra, you know, non-reproducibility from one second to the next; the session ID, either one I'm making up just out of the blue or that may represent cached credentials that we have, that we may share; and then lists of all the different cipher suites, hashes, and compression methods that the client side knows about; plus any optional extensions which the specification formally allows.



So the server gets that and says, okay, now I know a lot about the client who is attempting to connect to me.  It looks at the protocol level that the client is offering and looks at its own best protocol level, choosing the highest level that they both can agree on.  It looks at the list of cipher suites and compression methods and similarly chooses - picks one, one from the cipher suite and one from compression, that it knows and that is the most advanced, most secure, best that the client knows.  It does the same generation of a random number, producing a 32-byte random number.  And it looks at the session ID and checks its own cache to see whether it is in agreement with the client that, hey, you know, the client is saying it's got this in its cache.



The server can either return a null session ID saying no resumption is agreed to, and by the way I'm not doing any caching at this end for whatever reason; it can return a new session ID, which is its way of saying, sorry, I don't have that in my cache, so this is the session ID we're going to use instead; or it can return to the client the same session ID that the client sent, which is the server's formal acknowledgment that they're going to have an abbreviated handshake because it still knows and is in agreement with the client about the stuff they had before.



So essentially the Server Hello message, which returns, has all of this decision made - the final protocol that they're going to use that's been agreed upon; its own 32-byte random number; the session ID that they're going to be using, which may be what the client sent, if they both have the prior credentials still in the cache; and the chosen cipher suite and compression method, chosen from among those that the client offered that the server end is able to agree upon.  It also, often in the same packet, sends its certificate message, even though it's technically in the protocol as a separate message.  As I said, you could have multiple messages in a packet.



So what may be in the same packet, though it doesn't have to be, will be its certificate message, which is essentially its certificate.  It's offering its certificate, which normally contains the whole hierarchy of signatures back to the certificate authority.  And of course the certificate has bound into it its public key.  So that's its way of providing the first stage of authentication, saying here's the certificate that I, the server end, have.  It also, well, and so that information goes back to the client end, and the server says hello is done.  That is, my job with the hello phase is finished.



The client then receives both the Server Hello from the server and the server certificate and the Server Hello Done messages and says, okay, we're in agreement here about all this.  This also tells it whether it's going to be using the same session ID or not.  If the session ID comes back that it offered, meaning that the server has retained the prior credentials, then at that point they need to do no more negotiation.  The client is able to send what's called a Change Cipher Spec message, which essentially says, okay, this is the last thing I'm going to send you that is not under the cipher data that we have agreed to.  Everything else from me henceforth will be.  And the server, upon receiving it, echoes the same thing back.  It sends the Change Cipher Spec message back to the client saying, okay, now we go under encryption.



At that point they then exchange Finished messages, which since those follow the Change Cipher Spec messages are encrypted using everything that they have agreed to so far.  And that's their final way of saying, of proving to each other that, for example, that these caches are valid, that all the encrypted data is present, and that they are in agreement and able and basically proving that they are both able to exchange encrypted, authenticated messages by sending this Finished message.  And thanks to the finely evolved design of TLS, they're not - they will not allow any application traffic to pass.  It won't begin doing any work on behalf of the layer above them that initiated all this until they have exchanged and verified these Finished messages.  Oh, and the Finished messages also contain this hash of everything that - basically the hash of their entire dialogue, everything sent and received, in sequence, hashed together, in order to verify that no packets were lost or inserted or changed.  And so that protects the whole handshake from any kind of malicious modification.



LEO:  Wow.  You came to an end.  I thought that was all one long sentence.  I heard a period.  That is the most complicated thing ever.  But it works.



STEVE:  Well, it does.  And, I mean, it is complicated.  But when you think about it, I can't see a way of eliminating any of that.



LEO:  No, you need it, yeah.



STEVE:  Yeah.



LEO:  No, I can see that, yes.



STEVE:  Yeah, you absolutely do.  You want, I mean, this is the most used cryptographic protocol on the Internet.  It's HTTPS.  It's what we're all using when we're logging into web servers, and we want to be protected.  And so you want a protocol which is going to be able to grow, which is going to be able to accommodate differing capabilities on the endpoints because lord knows we've got all kinds of crazy clients all over here that are trying to connect to the Internet.  So we've got Kindles, we've got phones, we've got iPods, we've got PCs, I mean, we've got refrigerators and all kinds of stuff.  It's clear to me that as processing power increases, and as the pervasive threat presented by malicious actions on the Internet become more of a problem, that security and the robustness of these kinds of communications is going to be increasingly important.  So, I mean, you can imagine a day where the notion of sending email over an unencrypted connection is just kind of quaint.  You know, it's like Scotty trying to talk to the mouse in the early Star Trek...



LEO:  "Hello, computer."



STEVE:  "The Voyage Home."  "Hello, computer."



LEO:  Use the keyboard.



STEVE:  The idea of not encrypting everything, which is where we still are today.  We only normally jump to encryption when we need it, and often fall back to standard plaintext communication.  And you really kind of wonder why.



LEO:  Yeah, I wish we could use it all the time.



STEVE:  Yeah.



LEO:  That would be nice, wouldn't it.  I mean, it's not that - so it's not so much overhead that you really wouldn't be - not want to use it all the time.



STEVE:  No, I don't think so.  I mean, sure, back when we were...



LEO:  There's some overhead.



STEVE:  ...on 4.77 MHz 8088s, on a PC, that was painful.



LEO:  Right.



STEVE:  But there's only a little bit of packet overhead to reach agreement.  There's a little bit of work being done in order to establish this - basically what you're doing is you are establishing a - you are secretly and with full authentication establishing a shared secret symmetric key.  Once you have, for example, an AES shared secret symmetric key, which you absolutely know no eavesdropper can access, then you're able to use a state-of-the-art, high-speed cipher like AES, which is, I mean, no overhead.  I mean, fundamentally really low overhead and super-strong security for all of your payload traffic.  And so once that final agreement is reached, and the application that's been patiently waiting for all this to happen is allowed to finally send something, it's just encrypted using this shared secret symmetric key which is extremely high speed.  And data goes across the wire, and nobody can figure out what you've done, no matter how much they want to.



LEO:  Very cool.  Very cool.  Well, maybe we could just - someday we'll all use SSL all the time.  Or TLS, as the case may be.



STEVE:  As I said, I think ultimately it will - the idea of not having encrypted secure communications will just be regarded as, oh, that's the way you did it then?  How did you guys - how did you survive?



LEO:  You sent everything in the clear?  What's wrong with you?



STEVE:  Yeah, yeah.



LEO:  Very interesting stuff.  I really appreciate the effort and time you put into getting it all in detail.  Now, I know a lot of people are going to want to listen again.  There's good news on that front.  You can.  Just download the darn thing from the iTunes store or the Zune store.  Or you can go to Steve's site and get it in 16 or 32KB - or, I'm sorry, 16 or 64KB versions at GRC.com/securitynow.  But you'll also find a very useful tool for shows, particularly shows like this, the transcription.  You can read along as Steve talks.  And I find that really, really helpful.  Those are also at GRC.com, along with all of Steve's show notes.



You can also find more information at our wiki, which is - and in fact we're always looking for people to help out with the wikis.  You don't have to have even an account to edit it.  So Wiki.TWiT.tv, and take a look at the show notes page there.  And if there's something you have to add, links or so forth, we sure appreciate that, too.  That makes it more valuable.  Also Google searchable, which makes it easier for people to find this great information.  Steve, thank you so much.



STEVE:  Absolutely a pleasure, Leo.  And we'll do a Q&A next week, and who knows what the week after.



LEO:  Get your questions in.  Security Now! feedback is at GRC.com/feedback, so it's easy to do.



STEVE:  Yup.  And I love getting feedback.  It's just great to hear from our listeners.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#196

DATE:		May 14, 2009

TITLE:		Listener Feedback #66

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-196.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 196 for May 14, 2009:  Listener Feedback #66.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security oriented with Mr. Steve Gibson of GRC.com.  Hey, Steve.  How are you today?



STEVE GIBSON:  Hey, Leo.  I'm great.  I'm glad to be with you once again for week number 196.



LEO:  Oh, you just love rubbing that in, don't you.  Never missed an episode.  In fact, we were just talking before the show began.  I'm going to China in July, and Steve's already arranging for pre-records to get ahead so that we don't miss a single episode.



STEVE:  Yup.  And you gave me the option of having, I guess, Alex Lindsay...



LEO:  Yeah, I think Alex is going to be here, so I think we'll have Alex actually do some of the shows, which is kind of cool.



STEVE:  Yeah, but I thought, well, I don't mind having a vacation, too.  So if you're willing to double up, and we'll pre-record those, then while you're in China I get to have a couple weeks off.  So...



LEO:  So there you go.



STEVE:  ...that works for me.  Not that I'm going anywhere.  I'm just going to - actually, speaking of Starbucks, or I am speaking of Starbucks, I broke my record on Monday.  I got there at 5:00 a.m.  I left a little after 5:00 p.m.



LEO:  What?  You spent 12 hours writing code, huh?



STEVE:  A little more than 12 hours of code-writing, yes.



LEO:  Now, here's the real question.  How many coffees is that?



STEVE:  It's still my standard three mugs, each with two short shots of espresso.



LEO:  Well, that's not so bad.



STEVE:  So it's not that much, no.



LEO:  A mere six shots over 12 hours.



STEVE:  Just I sort of pace myself.  And this particular mug I love.  It keeps the coffee warm for hours, so...



LEO:  And they don't mind you sitting there just beavering away while you're...



STEVE:  It's so strange, I mean, the model seems to encourage that.  They've got - it's across from UCI, so it's sort of a study hall environment.  They've got study tables with electrical connections down the center.  We've got plugs.  There's like tables on the side, all with electrical plugs, like much more closely together than they would need for their - to run their own vacuum cleaner.  So, I mean, it's designed to encourage people to come and plug in and hang out.



LEO:  Well, it's a pretty good deal because you're spending, what, 12, 15 bucks on coffee, and you get 12 hours of rental, of space rental.



STEVE:  Oh, it's better than that, actually.  It's $2.85...



LEO:  Oh, it's nothing.



STEVE:  ...I think for my coffee.  And that includes two refills, drip refills, which is what they qualify this as.  So that's 50 cents each.  So that's in the $2.85.  So that's my coffee for the entire time.



LEO:  Oh, geez, are you getting a deal.



STEVE:  I give them a Starbucks card which is registered.  And as a registered Starbucks card user you get to use the AT&T hotspot for free.



LEO:  Really.  Oh, so you're getting your WiFi for free, too.



STEVE:  I disconnect - yeah.  There's an up and a downside, though.  There's one guy who shows up that, whenever he's there with his laptop, the whole network just collapses.  And I've got a feeling he's running BitTorrent or, you know, he's doing torrent downloads.  He probably comes to the hotspot in order to be anonymous.



LEO:  Great.



STEVE:  And he's sucking down, you know, who knows what.  So that's a bit of a problem.  But, again, unfortunately it's free so it doesn't weed out anybody.  But overall it's effective.  And what I'm doing doesn't need much connectivity.  Mostly I'm in my own environment, writing Assembly language.  And I'm having a great time.



LEO:  Oh, that's so much fun.  And I'm sure they like having some cool coder in there plugging away at his Assembly.  People peer over at the screen and go, ooh, ooh.  I don't know what MOVE and LOAD mean, but that seems serious.



STEVE:  They see this Northgate OmniKey old-school keyboard.  It's like, what the heck are you doing?  It's like, ah, well.



LEO:  Couple people asked me, UCI is UC Irvine.



STEVE:  Yup.



LEO:  University of California Irvine.



STEVE:  And in fact we had a listener come by.



LEO:  No.



STEVE:  I think it was Monday also.  And he said, "Are you Steve Gibson?"  I said, "I am."  He said, "I love the podcast."  So he'd heard me talking about me being at the Starbucks across from UCI, and the keyboard, and he said, okay, that's got to be the guy, so.



LEO:  That's hysterical.  Yeah, how many people in that  Starbucks with a Northgate keyboard?



STEVE:  That would be zero.  Well, that would be one.



LEO:  You.



STEVE:  Yeah.



LEO:  So we're going to...



STEVE:  In fact, Elaine was curious about the keyboard.  And, oh, actually she was Googling in order to get the spelling, to see whether the "K" of OmniKey should be capitalized, and she found one on eBay for $150.



LEO:  Wow.  I think somebody sent me an email saying they still make them.



STEVE:  They're, well, there's a company, oh, it's three initials, I can't think of the name of it.  But yes, they're still around.  They're a little clankier feeling.  They're, like, a little kind of hollow.  But one of the - she mentioned, for example, all of the lettering on her key tops has long since worn off.  And my keyboard, these keyboards, are from back in the day when they were so-called "two shot injected," where the coloring is actually plastic that is injection molded up through an opening in the shape of the letter on the top surface.  So, I mean, you can't rub these off until you, like, wear the key down to its post under, you know, down below it.



LEO:  Wow.



STEVE:  So they were really made right.



LEO:  Yeah.  So you don't - that put the company out of business because nobody needed a second one.  I've been putting my keyboards in the dishwasher.  I don't know if that - if Northgate would stand up to that.  How do you clean it?  Do you actually pry it apart and clean it?



STEVE:  Yeah, it does acquire a distressing level of, like, strange hair and skin cells and stuff.  Like, okay.



LEO:  I don't really...



STEVE:  So every decade or so, whether it needs it or not, whether it needs it or not I open it up and get a brush out and clean all the gunk.  And it's good to go after that.



LEO:  You probably wouldn't want to put it in the dishwasher, only because it's about a 50/50 proposition whether the keyboard survives.



STEVE:  Well, Greg, my illustrious tech support guy, as we were shutting things down and getting back into all of us telecommuting and working at home, we had this stack of keyboards from all the employees I used to have.  They wandered off; I kept their keyboards.  And I said, Greg, I'd like you to go through and clean all these keyboards - because he had time - and bag them up, and then I want them.  And so I literally have an inventory of cleaned, as new, keyboards.



LEO:  Oh.  And they're all Northgates?



STEVE:  All Northgate OmniKey 102.



LEO:  Oh, you're set.  You're set for life.  You've got a lifetime supply.



STEVE:  Well, I'm still using my original one.  I mean, they don't die.  So, yeah, so all my machines have them.  And now Starbucks does, too.



LEO:  You should see if you can leave it behind the counter.



STEVE:  Well, what I'm doing, there's one - I want to make sure - well, it only goes - I leave it in the trunk of the car, so I'm not having to schlep it around too much.  But right now, of course, it's the old-style PC barrel connector, which was that large five-pin DIN connector.  That then has a dongle to convert it to the PS/2, that has then a dongle to convert it to USB.  And what I'm going to do, as soon as I settle on this, there's one keyboard that I've got on order which is the original so-called "buckling spring" IBM keyboard.  I just want to make sure that's not better.  I don't think it is, but I want to make sure because I'm then going to build all the conversion electronics into the keyboard, converting it into a USB keyboard.  So it simply has a female USB connector on the back, and I've got a little 12-inch short little pigtail USB dongle that'll go from keyboard to the tablet PC.  So I'm working on really getting this refined.  I have a feeling this is going to be a mode I stay in for a while.



LEO:  I love it.  I think it's great.  That's how people should work, I think, in coffee houses.  That's the best place to program.



STEVE:  Yeah.  I'm getting a huge amount of work done.  And the DNS benchmark is really coming along nicely.



LEO:  Oh, that's fun.  How cool.



STEVE:  And we'll be talking about it soon.



LEO:  Pretty soon he'll be giving lessons, programming classes to the UCI students in Starbucks.  It'll become like the Greek, what do they call it, the stoia, where Aristotle and Socrates would hold court?



STEVE:  Right.



LEO:  All right, Steve.  First I guess we should cover any news.



STEVE:  Yup.  We've got a bunch of news.  This is of course our podcast after the second Tuesday of May, so we've got Microsoft's standard "whoops" list of goodies.  The most important one is a critical remote code execution vulnerability in PowerPoint, which I think we might have talked about last week.  It was known.  Now it's been patched.  So they've got this one patched, as well.  I also think I noted, but I'll remind people, that IE8 is now being offered through Microsoft Update.  So, you know, it's checked by default.  Microsoft's encouraging everyone to download it.  And if you've got your Windows Update set to just accept everything that Microsoft provides without question, then you'll find you've been updated to IE8 behind your back, without your knowledge.



I don't have - I always go for "Notify me but don't download."  Then I go into custom mode in Microsoft Update or Windows Update so I can see what I'm doing.  I've actually had a problem in the past where updates had been offered that were not compatible with my hardware, like on various laptops, and it messed things up badly.  And so it's definitely not something that you necessarily just want to - that every user, certainly the more informed user, just wants to accept blindly.



And then the third thing they're doing is we've got the standard monthly MSRT, the Microsoft Software Removal Tool update.  So that's been added.  And now that you've got, after this process, a new version of that, you might consider doing a deep scan of your system since it's a month more current, and hope it doesn't find anything new that it didn't know about a month ago.  But it's always worth...



LEO:  So you do that every time.  Doesn't it do it when you download it anyway?  It does a scan?



STEVE:  No, not the whole deep scan.  It does sort of a cursory, quick, sort of in the background scan as you're booting.  It's the next time you boot that it does it.  And not surprisingly, most of these patches require you to do a reboot.  So it takes that opportunity to sort of scan on the way back into the system.  And you may notice sometimes that Windows seems to be starting a lot more slowly after an update.  That's one of the things that's going on back there.  But the deep scan is hours, and you'd definitely know if that was going on because, I mean, it takes as much of your system as it can, and for hours.  So it's the kind of thing where you could do it before you go to China, Leo, that'd be good.



LEO:  To all my machines.  But you do it every second Tuesday after you get...



STEVE:  No.



LEO:  No.



STEVE:  No.  I'm just suggesting that, I mean, for example, I don't run AV, either.  So I'm really not...



LEO:  You're the bad example, yeah.



STEVE:  I'm not the person I'm talking to.  But there are lots of people who like to scan their systems.  This is there.  It's free.  It's useful and good.  And you got a new one on the second Tuesday.  So I would say go for it.



LEO:  I'll do it before I go home tonight, maybe.



STEVE:  Yeah, that's good.



LEO:  Yeah, then it'll be done in the morning.



STEVE:  Google had a little bit of a trip-over-their-own-foot update.  They updated Chrome to fix a critical graphics integer divide overflow rendering flaw, taking Chrome to 1.0.154.64.  And they didn't do it right.  There were a bunch of problems relating to that.  So they went to .65 two days later.  It's stable now.  So if we've got Chrome users, you may want to verify that you're running the 154.64 version.  If not - I'm sorry, .65 version.  If not, you may want to update yourself to fix a problem there.  And the Mac had one of the largest wads that I've ever seen it download.  In fact, frankly, I was concerned here as the clock was ticking that I wasn't going to be online with you, Leo, in time, because this thing just - it took a long time.  It was half a gig download.



LEO:  Wow.



STEVE:  And then the whole, like, restarting, hold on a second, I'm doing stuff phase, it just went on and on and on.  And but I guess you have some information about that.



LEO:  Yeah, it is the biggest update, according to people who watch this thing, ever for OS X.  It depends, if you got the standalone one that works with all Macs, which probably, if you had more than one Mac, it'd be prudent to get that and just install it locally.  That was over 700MB.  And then the almost 500MB for the download that's specific to your machine, that would vary.  Over 16,000 files changed, or 13,000 files changed.



STEVE:  13,000 file changes.



LEO:  Yeah, that's according to a guy who apparently - the interesting thing is, unlike Microsoft, Apple is not very forthcoming about what's in these updates.  So there's a guy who actually goes through what they call the "bomb file," the archive file.



STEVE:  He was busy this time.



LEO:  Yeah, he had quite a bit - and he does - I think he even compares what's been changed and so forth.  And he does this and publishes his results in Macworld magazine.  Rob Griffiths.  Great guy.  And I guess he just - this is his job in life.  And he gives you a list of all the files that are changed.  Sometimes version numbers change; sometimes they don't.  But it's pretty much everything, including quite a bit of UNIX software.  Remember that the Mac is running BSD and has many, many, many BSD programs, including Apache, Perl and Python, Ruby, all of those are updated.  PHP, X11 was updated.  So they don't just have to update their own stuff.  They have to update also a lot of open source software.



STEVE:  There was a critical vulnerability that they fixed specifically in PDF printing.  There was a JBIG2 token rendering problem that was part of this.  So that was one thing.  And obviously they just sort of brought a whole bunch of other stuff probably up to current level, essentially.



LEO:  Yeah.  I think they, you know, they don't have a second Tuesday policy.  What they do, it's interesting actually, their process is very different from Microsoft's. They treat it almost like a new operating system update.  They beta test it.  They send it out to developers.  So they beta test in public with these things.  If you're, you know, you have to be a developer.  And then after a month or so they will release these massive updates.  From time to time they'll do small updates.  But these dot updates, these point updates, 10.5.2, 10.5.3, in this case 10.5.7, these are pretty big updates and often do modify quite a few files.  This is a big one.



STEVE:  Certainly in this case, yeah.



LEO:  Yeah, yeah.



STEVE:  Well, a bunch of readers wrote to me about a story that ran in the San Jose Mercury News.  Since it's a topic near and dear to our hearts, i.e., the Conficker worm, I wanted to just read it.  It's brief.  It was posted by, or reported by, Elise Ackerman of the San Jose Mercury News.  The subject or the title of the story was "Conficker Worm Found in Hospital Equipment."



LEO:  Oh, dear.



STEVE:  "A computer worm that has alarmed security experts around the world has crawled into hundreds of medical devices at dozens of hospitals in the United States and other countries, according to technologists monitoring the threat.  The worm known as Conficker has not harmed any patients, they say, but it poses a potential threat to hospital operations.  'A few weeks ago we discovered medical devices, MRI machines, infected with Conficker,' said Marcus Sachs, director of the Internet Storm Center, an early warning system for Internet threats.  Around March 24, researchers monitoring the worm noticed that an imaging machine was reaching out over the Internet to get instructions, presumably from the programmers who created Conficker.  The researchers discovered that more than 300 similar devices at hospitals around the world had been compromised.  The manufacturer of the devices told them none of the machines were supposed to be connected to the Internet - and yet they were. 



"Normally, the solution would be simply to install a patch, which Microsoft released in October.  But the device manufacturer said rules from the U.S. Food and Drug Administration required a 90-day notice before the machines could be patched.  'For 90 days these infected machines could easily be used in an attack, including, for example, the leaking of patient information,' said Rodney Joffe, a senior vice president at NeuStar, a communications company that belongs to an industry working group related to dealing with the worm."  So...



LEO:  That's interesting that they have that weird requirement.



STEVE:  Well, and so here you have a situation where clearly Windows - I mean, okay.  I should tell our readers in advance that this Q&A, as our Q&As sometimes do, has a theme to it.  Because there was so much listener response to the issue of instances of Windows being embedded in things that a lot of listeners have personal direct experience of one form or another, pro and con, with this behavior, or this practice.  So some of - there's maybe half of our 12 questions are people telling us interesting things and asking questions.  So I think it'll be - listeners will hear that sort of theme.



Well, this report is exactly that.  More than 300 MRI imaging machines based on Windows got themselves infected because, A, they were based on Windows, that is, if they were based on some industry standard operating system rather than the consumer operating system, that couldn't have happened.  And clearly the manufacturer says, oh, well, you weren't supposed to connect to the Internet.  Well, I guess my question is, what, does it have a standalone box standing next to the scanner?  I mean, don't give it an Ethernet adapter.  Don't install Ethernet drivers.  Or is it some just standard installation of Windows?  Anyway, I could go on.  And we've already discussed that.  We'll be discussing it more throughout this next hour.  So I'll let that stand.  But yes, that's certainly a problem.



LEO:  Wow.  Very interesting stuff.



STEVE:  Also we had a ton of people wanting to make sure that I knew about the controversy of NoScript versus Adblock Plus.



LEO:  You know, I almost mentioned that last week.  But, well, I'll let you tell the story.  NoScript responded, I think appropriately, so...



STEVE:  Yeah.  And I read the Adblock Plus posting, which I felt was very well written, even handed, not being out of control.  We'd discussed previously this fundamental problem of an ecosystem, which I so much like, in Firefox.  I mean, it happens that I'm using both NoScript and Adblock Plus.  Adblock Plus with the easy list just deals with advertisements.  It's amazing, when I go to a machine now that isn't using Firefox with Adblock Plus, everything's jumping around, and stuff's happening, and it's like, whoa, I forgot how peaceful things could be if you used Adblock Plus along with Firefox.  And of course I believe in controlling scripting.  So there's a fundamental problem if the interests of different add-ins conflict, and if the authors of the add-ons decide to respond to that conflict.  The position taken by Adblock Plus's author is that the NoScript author has an advertising-based revenue system, and the NoScript technology was deliberately changed and the code even obfuscated so that it would resist being seen and resist analysis, was arranging to defeat the ad blocking for the NoScript site.  And every time you get one of these NoScript updates, which really do seem distressingly frequent, I notice that I'm given a whole big page from the NoScript site, which I have to close because it has nothing else I really care about on it.  But apparently it does have ads.



LEO:  That's where the ads are.



STEVE:  Exactly.



LEO:  And that's the only place the ads are?



STEVE:  I don't know that because I haven't dug deep into this.  But I wanted to let our listeners know that I am aware of this issue.  And many of our listeners are really unhappy with the conduct of the NoScript author, saying, you know, I want to use this, but this really puts a bad taste in my mouth.  So anyway, that's the story.



LEO:  You read his response, though; right?



STEVE:  No.



LEO:  Oh, okay.  See, this is - I thought this was kind of over last week, otherwise I would have brought it up last week.  So he actually says, "I screwed up big-time."



STEVE:  Okay.



LEO:  "Not just with Adblock Plus users, but with the Mozilla community at large.  I did something extremely wrong which I'll regret forever.  I abused the power and wasted the enormous trust capital gained by the NoScript add-on through the years to prevent Adblock Plus from blocking stuff on four Internet domains of mine without asking an explicit preemptive user consent.  This is absolutely inexcusable, something I would never conceive again for the life of me.  Please let me apologize first."  He responds to Vladimir's post, says it's not quite as Vladimir said.  And he says he's changing it.  So to be fair...



STEVE:  He really did, he took the responsibility and he apologized.  And also Vladimir's follow-on postings did refer to responses back from the NoScript author.  So I would say lesson learned.



LEO:  Yeah, I think lesson learned.  I think that he has come up with a solution.  He realizes it was inappropriate to do what he was doing.  But there has been a back-and-forth dialogue between him and Vladimir.  And, I mean, he said, "I didn't obfuscate code."  I mean, in his defense he said some things.  So it's not completely one-sided.  I would say read, you know, go to his Hackademix.net site, read Giorgio's responses...



STEVE:  And give him as full an opportunity to explain himself.



LEO:  Yeah.  I think these are - my general gist of it, after reading the back-and-forth, is that both people are well-meaning.  Giorgio realizes he made a mistake, and I think he's going to fix it to the satisfaction of everybody involved.



STEVE:  Great.  Great.  I've been, as I've mentioned a number of times, I have sort of a background thread running relative to my plans for my next major commercial product, which as we know is called CryptoLink.  I've got the trademark on that now, so it doesn't hurt to mention that.  One of the things that I run across is this question of what mode CryptoLink is going to use for doing its ciphering and authentication.  We've talked about modes.  For example, Cipher Block Chaining, CBC, is a mode where you take the result of one, of the first cryptographic operation, and you XOR that with the plaintext of the second block's worth of text before you encipher it.  You take that, and you XOR that with the third block's and so forth, so that it forms a chain running down through.



What that does is it makes all the blocks dependent upon everything that has come before and, for example, is a much stronger solution than if you independently were to encrypt each block by itself because you could then - a bad guy could change something, and there would be no rippling effect.  It would be an isolated change.  Also, and more significantly, any patterns that were occurring in the plaintext could be seen very clearly because the patterns occurring anywhere would be replicated in the enciphered blocks.  Even though you wouldn't know what the plaintext was, the fact that it wasn't changing gives you information, and that's a bad idea.  So these modes take the basic cryptographic operations and make them a little more complicated.



Well, the problem is, all that does, for example, Cipher Block Chaining, is give you privacy through encryption.  It does not give you authentication.  So what everyone does is, for example, you have CBC.  Then, for example, there's CBC MAC, which is to say Message Authentication Code, where with a different key - and that's important.  We know that you can't use the same key, or you shouldn't, for ciphering and for authenticating.  That's one of the mistakes that the early versions of SSL used, and that got fixed in later versions.  So if you want to authenticate, you use a different key, and you often do the whole thing again, but, for example, using CBC to create - as your cipher for a hash.  And so you hash the message with a different key.  What this means is that you're essentially doubling the amount of work you have to do.



Well, there's one very cool mode which is called OCB, which was invented by a cryptographer, Phillip Rogaway, who is at UC Davis.  I wrote to Phillip in February, so a little over three months ago, asking him what the terms of licensing were.  His site says this is licensed, it's proprietary, it's patented, but we will make licenses available.  Well, I never heard anything from him.



So yesterday I remembered that I had let that ball drop so I sent him a short note just saying, hey, I'm just kind of wondering if I could hear something one way or the other.  A lot depends upon whether I could use this.  I just realized I forgot to tell you why this is so cool.  OCB does both - both privacy, that is to say, encryption, and authentication in a single pass with, like, one additional block operation at the end rather than doubling the number of block operations that you need.  So it's, like, twice as efficient as any of the existing technologies.  Anyway, I received a response this time from Phillip, like within an hour.  He said, "Hey, Steve, great to hear from you.  You can use OCB for free, now and forever, in any future versions, for your CryptoLink VPN."



LEO:  Oh, that's great.



STEVE:  He says, "I have no intention of profiting from a three-man software publishing company, so it's yours."



LEO:  He just wants to protect against the big boys.



STEVE:  Yes, exactly.  And, I mean...



LEO:  Understandably.



STEVE:  ...who can blame him?  I mean, so I'm just delighted because this, even though it's all going to be Assembly language, and mine would have been as fast as anybody else's, now it gets to be twice as fast.  So...



LEO:  That's great.



STEVE:  ...that's a cool thing, too.



LEO:  That's really great.



STEVE:  And I did want to make a mention, again, responding to all the email that we received, that I'm aware that my little freeware SecurAble has been mentioned all over the place in connection with Windows 7 because there's been a lot of question about what processor capabilities you have.  Windows 7 cares about whether you've got the advanced virtualization capabilities in your chip.  Yet it's not easy to know one way or the other whether you do.  And of course our listeners will remember that that's exactly what SecurAble tells you, is it makes - you just run it and, bang, it shows you a little presentation of what features your chip has.  So it's been picked up by PC World and Tech Republic and, you know, all over the 'Net people have been saying, hey, just go get SecurAble.  And downloads have spiked as a consequence of that.  So I wanted to make sure that our listeners knew that I knew that had happened.



I wanted to correct something I misstated about the Kindle DX.  I referred to its pixel pitch as being higher than the prior two Kindles, and in fact it's a little bit lower.



LEO:  Oh, it's lower, okay.



STEVE:  Now, the total resolution is higher, in fact nicely higher.  But the actual dot pitch, that is, the spacing between individual pixels, is a little lower.  On the first two Kindles, the original Kindle and Kindle 2, it's 167 dots per inch to yield a screen resolution of 800x600 at that pitch.  On the DX it's 150 pixels per inch.  On the other hand, the screen, because it's physically larger, ends up at 1200x824.  And 1200x824 is very respectable resolution.



LEO:  1200x824, yeah, that's bigger than a VGA screen.



STEVE:  Exactly.  Well, think about many laptops that are 1024x768.  1024x768 is a standard laptop screen resolution.  So this is more pixels in each direction.  And it's a physically smaller screen than your typical laptop screen at 1024x768.  So the actual visible resolution ends up being higher.  So I've got high hopes for it being a nice screen for viewing PDFs.  And it does have a rotation sensor in it, and it will go into portrait mode.  So you get the advantage - it'll be interesting to see how they handle that because you can't scroll eInk.  So if you switch it into portrait mode - I'm sorry, I meant landscape mode.  If you switch it into landscape mode so that you get the whole width of the - what would normally be the height of the screen becomes the width of the screen to get even greater resolution, you'd have to do a paging operation to move up the screen.



Which actually one writer or reviewer wondered why they weren't doing columns, like they weren't doing multicolumn text.  Well, you really don't want multicolumn text in a situation where you can't easily scroll because then you'd get down to the bottom of one column, and you'd have to scroll back to the top of the same page in order to start reading from the top of another column.  So it makes sense that they've stretched it all the way across.  So anyway, we won't really know much more until I get mine.  And then we will.  And I did want...



LEO:  And you may get yours someday.  It's not imminent, yeah.



STEVE:  And I did want to mention that a guy posting to our newsgroups this morning noted something disturbing about his D-Link router firmware update.  And that is that D-Link is now going to begin - they haven't actually started yet.  But they're going to begin taking over DNS by default.  And that's something I really think crosses the line, especially when the DNS that they're going to be routing people to is that kind which doesn't give you an error message, but instead gives you their own helpful, friendly, marketing-driven interception page.  They say, we're providing search engine services for our customers.  Turns out that it's some sort of a direct-marketing company that they're using.  So they're...



LEO:  It's not OpenDNS, it's some other weird - because I'm a big fan of OpenDNS.  I could even see maybe putting it in the D-Link router by default.



STEVE:  Well, I'm not a fan of anything that doesn't give you an error.  And OpenDNS does not give you an error.



LEO:  No.



STEVE:  OpenDNS takes you to their own page.



LEO:  Yeah.  That's how they monetize, exactly.  I mean, they say it's an error.  But they say, perhaps you meant this, and there's some ads there.  It's a surf page.



STEVE:  Well, but an error means something specific.  An error means that you receive a bad name error response in response to a query at the DNS level.  It does not mean that your browser receives a happy page of other links.  And so that breaks DNS.  This is fundamentally broken.  I understand they're monetizing, and I'm being a curmudgeon about it.  But, I mean, you ask for a name that doesn't exist, you should get an error.  You should not be given an IP that will satisfy your request by taking you to a page for marketing purposes.



LEO:  Yeah, well, you certainly shouldn't do that without - see, because most users of D-Link routers won't know that that's what's happening.



STEVE:  Precisely.



LEO:  This will be the new default behavior.  I don't have so much of a problem if people choose to use OpenDNS, and in fact I recommend it.



STEVE:  No.  And in fact you do need to deliberately configure your system to do that.



LEO:  Right.



STEVE:  And I'd agree.  I think it provides lots of good services, so long as the user understands...



LEO:  Yeah.  You did it yourself, and this is a conscious choice.  Problem is, putting it in the router, most people don't ever change the router settings.



STEVE:  Well, and what's really become annoying, and we'll be talking about this in the future when we're talking about DNS performance, as I will be when we talk about this benchmark that I'm in the final throes of, although I've been in those final throes for some time, I realize, but it's coming out pretty spectacular.  It turns out that many routers are not forwarding the ISP's provided DNS services to the computer.  Instead they're saying, I'm your DNS server.  And so they're intercepting your computer's or your whole LAN's DNS queries and managing them themselves.



The problem is, it turns out that this is being done poorly.  It's often slower than asking the actual DNS servers that your ISP is providing, and in some cases it creates a security vulnerability because some replies can crash your router.  And there may be buffer overrun possibilities there.  So when you set your computer to "Obtain IP address automatically," what you traditionally received was a local IP from the router for any machines on the network.  And then you received the router basically resending, rebroadcasting the DNS servers it had received from the ISP so that your computer would be making queries to those DNS servers.  Now the router is giving its own gateway IP as also the DNS IP, the single DNS IP for the whole network.



The other reason this is a problem is that DNS is pretty fancy about how it falls back in the event of a server being down.  The reason there's typically a minimum of two DNS servers being listed, I mean, the formal reason is if one is down, you can fall back to the other.  Because if you've got neither, you don't really have the Internet, unless you're really good with memorizing IP addresses.  And none of us do that.  So who knows how good the error-handling logic is in the router, which you're now depending upon if you only have one IP address, and that's the router's IP.



So I'm a little bit down on this whole notion.  And unfortunately this is the default setting.  And so what we're learning as we actually have really accurate benchmark results is that changing your router and telling it do not proxy my DNS is going to be probably the recommended setting.  And it also solves some potential security vulnerabilities which we're finding and discovering in a surprising number of routers.



LEO:  Very cool.



STEVE:  And lastly...



LEO:  I mean, not cool, but very good to know.  "Cool" is the wrong word.



STEVE:  Yes.  And lastly, in the spirit of our Q&A, I actually have a question from a SpinRite user that I would share because it's an interesting one.  He said, "Steve, I've been using SpinRite a lot at work with a four-copy site license - thanks - to both recover corrupt drives and files as well as maintenance on drives.  My question is, after running SpinRite Level 4 on a drive, is the drive safe to use?  One Western Digital drive, a 500GB SATA, was giving us errors and trouble.  So I ran SpinRite at Level 2.  It fully recovered a bunch of sectors.  After that I was able to get all the data off that I needed.  And then I ran SpinRite again at Level 4.  No bad sectors a second time; some ECC corrections, but I don't know what is common or too many.  Is this drive safe to use and trust again, or should I just toss it?  Thanks for the great podcast and great product.  Nathaniel."



LEO:  Very cool.  Very cool.  That is cool.



STEVE:  Nathaniel L. in Minneapolis.  And you know, that's a really good question to which I don't really have a hard-and-fast answer.  I would say no drive should ever produce an error like SpinRite always finds.  So that's never a good thing.  On the other hand, it's difficult to blame the drive if there hasn't been maintenance going on.  I mean, SpinRite is maintenance.  You run SpinRite on a drive, and it's able to show the drive that there are sectors that are going bad before they have gone bad.  And that's a critical distinction because these drives are so dense now, and they're relying so heavily on error correction to fix reads which are not perfect, that a lot of error correction is going on all the time.  It's when too much is required, more than the drive has, that it says I can't read this sector.  Which is then when you bring SpinRite in, and it checks it for you.  So if maintenance were going on, then this would probably have never gotten as bad as it had.  But maintenance isn't being done on most drives because most drives don't have SpinRite being run on them all the time.  Only people who are clued into this understand that.



So I would say keep an eye on the drive.  If you have some way of maybe putting it in a less mission-critical place, like make it a drive in a RAID array so that, if it goes belly up, you've got redundancy, and you're not relying on it completely.  I would say maybe store less mission-critical data on it.  Or if nothing else, make sure that you do run SpinRite over it from time to time and kind of keep an eye on it.  On the SMART display screen, SpinRite is showing you dynamically the rate at which error corrections are being required, even behind the scenes, something that nothing else shows you, the actual rate in terms of corrections per megabyte read.  And if you see that in general going up over time, then the drive is, I mean, SpinRite is a more sensitive early warning device than anything I've ever seen because it's able to show you the rate at which error corrections, which are still fine, are being relied upon by the drive as it goes about doing its work under SpinRite.  So if that makes a jump or a change, or if it's high compared to other drives of the same make and model - that's the other thing you can do is, if you have other Western Digital drives, see what their ECC rates are as shown by SpinRite when it's running.  And if you've got a drive that's, like, way off bell curve, it's like, okay, this really does seem like it's an early warning for a pending problem.



LEO:  Well, it's nice that people have this option to write in to you and ask the author what's going on and what you suggest.  I think that's a great - I've always had that feedback from you, but it's nice that others can do it, too.



STEVE:  Yeah.



LEO:  Go to GRC.com/feedback if you have questions for Steve.  Hey, by the way, Colleen handed me a keyboard she found that has buckling springs.  That's what makes your Northgate so good; right?



STEVE:  Well, no.  Maybe.  I know that what was called "buckling spring keyboard" was the original keyboard from the IBM PC.



LEO:  Right, the Model M.



STEVE:  And it had a very stiff response.  I joked in InfoWorld columns that you could just, like, load up a spitball in the curve of one of the keys and, like, let it go, and the spitball would get shot across the room because, I mean, it really - or I think I remember once saying it would bruise your fingertips if you didn't pull them away quickly enough because as soon as it wanted to snap back, I mean, it really did with a vengeance.  And I think that's too stiff.  I think that's more than I want.



LEO:  So these aren't buckling springs then in your Northgate.



STEVE:  Well, I don't know what the technology is.  I know that...



LEO:  That's what Dvorak has always said.  But, you know, who knows.



STEVE:  Well, I'm really careful about technology or terminology.  And I know that the original IBM keyboard was known as the "buckling spring keyboard."  And they're still available.  I ordered one.  Then they told me, oh, by the way, it's going to be maybe two or three weeks.  So I'm still waiting for it.  I think I'm not going to like it, and I'll probably have to put earplugs on in order to use it.  Mine are definitely - they have a nice snap action.  They're not that, you know, the reverse sheet dimples that you're typing on, which is what all contemporary keyboards are.



LEO:  Right, the mushy ones.  That's actually - I have to use those because the other ones are too noisy.



STEVE:  Yes.



LEO:  They really clackety-clack.  I can't use them on the air.



STEVE:  Yes, and in fact I've got this in front of me, and I've been conscious, sometimes when you're talking, and there's something I have to do, it's like, ooh, can I type on this quietly somehow because I don't want it to get recorded, yeah.



LEO:  Well anyway, she made a mention of it.  It's the DAS keyboard.  It's from Germany, DAS, using buckling springs.  So people are looking for that.



STEVE:  And do you have the keyboard in front of you right there?



LEO:  I don't.  She found it.



STEVE:  So you're not able to press the key right now and...



LEO:  I can't tell you, yeah.



STEVE:  Oh, I've just remembered the company, it's CVT is the company that still makes the equivalent of the Northgate keyboard, sort of modernized, and it's got some built-in macro programming and some other stuff.  So but it's CVT, Inc., I think is the name of the company.  And I have purchased a couple from them.  And they were - they didn't quite have exactly the same feel, I mean, I'm being really picky at this point.  But yeah, I think that's the name of the group that...



LEO:  I also - I bought one for the Mac.



STEVE:  Oh, yes, exactly.  There was one for - I have one also.



LEO:  Yeah.



STEVE:  That is, again, it's a nice, snappy...



LEO:  I like it.



STEVE:  Yes.



LEO:  And it washed well in the dishwasher.  But it's too noisy, its clickety-clack, and I had to retire it.  The new Apple keyboards, you know they're membranes because they're this thin.  They're aluminum.



STEVE:  It's like typing on a piece of paper.



LEO:  Yeah.  I've washed two of those.  One made it, and one didn't.



STEVE:  What is this washing you're doing?



LEO:  Well, you know, with the swine 'flu, you know, the keyboard is filthy.  It's filthy.



STEVE:  You've got a lot of people sitting on your ball?



LEO:  I do.  We have - because Colleen comes in here.  Sarah comes in here.  Alex does.  And a few other people have used or use this.  So I feel guilty having them sit down in front of my grungy keyboard.  I am actually using now something called the Silver Seal Antimicrobial Keyboard that is designed to put in the dishwasher.  It's for hospitals.



STEVE:  Get a guest keyboard and just put a big - put a Leo sticker, put your name on yours and get a guest keyboard and just swap it out...



LEO:  Maybe that's what I'll do.



STEVE:  ...when you're going to be away from your desk.  Or actually, since they're USB, you can probably leave them both plugged in and just sort of...



LEO:  Yeah, you can, yeah.



STEVE:  ...slide one aside and say, okay, this one's...



LEO:  Don't touch that.



STEVE:  ...got Chinese food all over it, so try not to - don't use this one.



LEO:  Are you ready, my friend, for...



STEVE:  Oh, I think everybody's ready.  We're 52 minutes in, and we haven't...



LEO:  Holy cow.  All right, well, we'll speed through these.



STEVE:  But we've had a lot of fun so far, and our listeners appreciate that.  So it's not just about the Q&A.



LEO:  No, of course not.  It's never just about the Q&A.  This is question number one, comes to us from Robert Minkler in Prescott Valley, Arizona.  And he says:  Steve, you skipped a beat.  I just finished listening to Security Now! Episode 195, the SSL/TLS episode, for the fourth time.  Holy cow.



STEVE:  Yeah, that was a pretty information-dense episode last week.



LEO:  Yeah, yeah.  I admire people who really just keep going through it till they get it.  Don't forget the transcripts, because that helps.  It's a great episode.  As usual you make a very complex topic easy to understand.  It seems like you missed an important detail of the handshake process, though.  See, I wouldn't have noticed that.



STEVE:  Yeah, I did afterwards, too.



LEO:  You mentioned what happens if the session details are already in the cache of both machines during the handshake.  You never said exactly what happens when the two machines need to create and exchange a new symmetric key.  I know you discussed symmetric key exchange in a previous episode, but seems like you should have mentioned that again.  So here's a chance.  How exactly do both machines end up with the same symmetric key and keep it a secret?  Thanks, Steve and Leo.  Security Now! is by far my favorite show.



STEVE:  That's a great question.  And it's funny because, as I wandered off after recording last week I thought, oh, in my notes I just must have skipped over it.  Because I talked about how, when the client is connecting to the server, the client, if it sees it has credentials which have been established from a prior connection still in its cache, it offers the session ID of those credentials to the server.  If the server is configured to allow reusing of existing credentials, and if it still has them, and it chooses to, it will respond with the session ID, coming right back to the client, telling the client yes, let's use the session ID that you suggested, and implying the use of the same credentials.



At that point I moved past that to other topics.  But the question that Robert asks - and I should say that a number of other listeners who were really listening carefully said wait, whoa whoa whoa whoa, what if there isn't a prior session?  What if it's the first connection to the server in 24 hours or whatever the cache expiration time is, which is never longer than 24 hours.  And they're right, I forgot to mention that.  It's pretty straightforward.  When the server gives the client its certificate, it sends the server certificate message to the client and then sends the so-called Server Hello Done message.  In the case that they need to negotiate a new shared secret key, the client sends what's called a Client Key Exchange message.



What it does, it takes the version number that is it, that is, its version number, which is two bytes, and generates an additional 46 bytes of cryptographically strong pseudorandomness, creating a 48-byte datum.  Now, having received the server's certificate, just having received it, it has the server's public key.  So it encrypts that 48-byte blob, which is not too long, with the server's public key.



Now, as we know, the public key allows you to go in one direction.  The private key, which is never disclosed, is the only thing that will let you go in the other direction.  So it encrypts the server's private key.  I'm sorry, it encrypts its 48 bytes of mostly randomness, but also the first two bytes are its own client version.  And then it sends that to the server in its Client Key Exchange message.  So the fact that everybody who's monitoring this handshake process can see that doesn't help them because, I mean, they see 48 bytes of blob go by.  But as we know, that's going to be random noise.  I mean, it's encrypted random noise.  They cannot determine what the actual plaintext, the unencrypted randomness is because they don't have the server's private key.  Only the server has that.  So it receives it and decrypts that using its private key.



Now both ends have the same 48 bytes.  The reason that client ID is tacked on the front is, cleverly, to protect against a client version downgrade attack.  Remember that all of this so far has been in the clear.  That is, the client sends its packet of information containing its version number, the ciphers and authenticating codes it supports and so forth, up to the server.  The server looks at those, chooses among them, and sends them back.



Well, the client is also sending the server a blob of random stuff.  The server sends the client a blob of random stuff.  This all happens in the clear.  So a possible attack would be to intercept that first client handshake packet that contains the client's version number and edit it down in order to make the client seem dumb and force the server to negotiate an older version protocol that has known weaknesses.  So that's prevented by having the client again put its client version, that is, the best it can do, as part of that 48 bytes, which is then encrypted.  And of course this is encrypted and authenticated so that nobody can change it.



Then the server receives it, decrypts using its private key, as I said before, gets all 48 bytes, the first two of which are the client version.  It compares that client version, which now they've got ciphering running in their connection.  Now it can't be spoofed.  It can't be intercepted.  And it compares it to what the client's first claim of its version number was.  If they don't match, the connection is broken.  The server just drops it like a hot potato and says "no thank you" and forces a complete restart of the negotiation.



Typically it will compare.  Then what happens is they've each generated some randomness in the beginning, which they sent to each other.  Then the client generates another chunk of randomness.  They each generate, oh, I don't remember how many, I think it's 48 bytes, and they send it to each other.  Then the client generates 48 bytes, which it encrypts, sends to the server, which it decrypts.  They mix all of that together - the client's randomness, the server's randomness, and their shared secret, which is called actually the "premaster key."  That's all mixed together using a common hashing function to generate the final master key, which is then used to generate all subsequent keys.



So that's how that's done.  They then both issue a cipher change spec message to each other.  And remember that that's the message that says everything henceforth will be done under the ciphers that we agreed upon, using the key we've agreed upon.  And then they each send the finished message, which is enciphered and authenticated using what they've agreed on.  And upon receiving that, and each end verifying it, they've established their secure communication.  And nobody knows of any way to get in there and mess it up.  So it's a tremendously secure technology.



LEO:  Very cool.  Question two.  Marv Schwartz at Case Western Reserve University in Cleveland, a very good school, worries about connecting to the LAN side of a router:  Hi, Steve.  Perhaps listening to every episode of Security Now! has made me paranoid.  Good, it's working.  You said that because of NAT, worms cannot cross from the Internet through the WAN side of a router to the machines on the LAN side of the router.  However, if someone connects a laptop that has been infected with a worm to the LAN side of the router, then the NAT protection does not come into play, and the worm will try to propagate to other machines on the LAN side of the router.  And we've seen that happen with Zotob, among other things.



STEVE:  And Conficker does it, too.



LEO:  Yeah.  When this happens, the only protection is the software in each attacked machine.  Even though I keep my machine updated, the frequency of security updates, zero-day exploits, and Conficker scares me.  So I carry a travel router with me and put it between my machine and a corporate, conference, or hotel LAN whenever I can.  Is this a good idea?  Or am I just being paranoid?  Thanks to you and Leo, a great service you provide so many of us who do not know enough to be paranoid before becoming regular listeners, did not know enough before becoming regular listeners to Security Now!.  Thank you, Marv.  That's a great question.



STEVE:  Well, it's a great question.  And one of my good friends, Mark Thompson of AnalogX, does that.  Sometimes when he's visiting he'll crash here overnight on his way up to L.A. or Burbank or wherever he's going.  And he just has a little tiny D-Link travel router.  It's a very cool little thing.  It's like the size of, like, sort of smaller even than a Mac power supply blob.  It's got a little plug built in.  You just sort of swing the plug out or slide it out, sort of like an electric razor being deployed, like the sideburn cutter on a razor.  And you just plug it into an outlet, and it is a complete little NAT router.



And so what Marv is doing is interesting.  You could argue that a properly running Windows firewall is the same thing, that is, if you've got no ports opened and exposed, then the Windows firewall is very much like NAT in that anything from the inside is able to get out, but nothing from the outside is able to get in.



The problem is that the Windows firewall is tricky because there's, like, tabs in the advanced mode where you're able to configure exceptions, you're able to allow things.  By default LAN is treated as a trusted domain.  But Marv's whole point is that a LAN shouldn't necessarily be trusted because it just takes one bad machine stuck on the LAN.  And one of the behaviors I witnessed myself in my own little Conficker honeypot here is it's sending out probes across the entire local network, looking for other machines to grab onto, to infect, and to move itself over to.



So for people who like the idea, getting a  little so-called "travel router," and I think everybody makes them now because it's a nice idea, running your Internet connection through that gives you sort of hardware-level protection outside of your Windows machine, that is, that local software cannot configure.  You want to do the right thing, of course.  You want to make sure you give it a good, strong administrator username and password, change them.  You want to disable Universal Plug and Play, otherwise don't bother because Universal Plug and Play essentially disables that protection, and there's no way to really know what's going on.  So you want to turn that off.  But with that turned off, a little travel router makes a great - basically it's a little hardware, a little portable hardware firewall.  And, I mean, I know people who do it.



LEO:  Failing that, the next best thing would be just to turn on the Windows firewall.  That'd give you some protection, too; right?



STEVE:  Well, no, that's the point, is that even when it's on it does not provide LAN protection.



LEO:  Oh, no, no, wait a minute.  If all the machines in the network have the firewall turned on, you are protected.



STEVE:  No.  No.  By default Microsoft has filesharing and their client, the Windows client on.  And the firewall trusts the LAN.  It does not trust the...



LEO:  Oh, that's interesting.  Oh.



STEVE:  Yes.  And so, like, if you go into the advanced...



LEO:  Because this was the recommendation after Zotob was turn on the internal firewall, and that will block Zotob.  But so when it sees traffic from the LAN it says, eh, you must know what you're doing.



STEVE:  Yeah, I mean, a LAN, it's your home, it's your office, it's your friends.  And again, it's interesting because there's a...



LEO:  So how do you protect yourself if, I mean, do you bring a little router with you even to work?



STEVE:  Well, you can configure the Windows firewall so that it doesn't allow these exceptions.



LEO:  Oh, okay.  How do we do that?



STEVE:  You dig down into the tabs.  And, I mean, we could certainly do a podcast to take our listeners through it step by step, but...



LEO:  It's probably obvious, though.



STEVE:  It's pretty obvious.



LEO:  So you turn off all the exceptions.



STEVE:  Although under each of those exceptions - you need to open it up.  And you'll see that it says LAN is an exception, and you're able to disable that and say, nope, I do not want LAN to be an exception.



LEO:  Holy cow.  I didn't realize that.  I've been thinking I was safe using the - turning on the Windows firewall.  So...



STEVE:  Not against internal threats.



LEO:  They make really good little travel routers you can carry with you.



STEVE:  Yes, and that's my point, is that everybody makes them.  And it makes it a no-brainer.  You need to, again, configure it correctly, make sure you don't leave the default username and password because we now know that malware tries, it does brute-forcing against username and password, and that it'll use Universal Plug and Play if it can.  So those things you need to deal with.  But when you do, you've got quick and easy security.  And the other problem is you can't ever really trust a software firewall running in the computer that you're protecting.  I mean, except...



LEO:  Because it's - a bad guy has access it.  But I'm thinking this is of use when you're sitting safe and secure, and there's bad guys outside on the LAN.



STEVE:  Correct, correct.  And so long as you don't click on a link that runs something that your browser has invited in...



LEO:  You're screwed if you - once you're infected, all bets are off.



STEVE:  Right. 



LEO:  I mean, you know, at that point, okay.  We're talking about protecting ourselves.  So, okay.  Yeah, that's good, okay.  I'm going to have to go out and get a little portable - there must be some - because I'm going to China.  I know I'm not going to - I'm going to the land of the hacker, baby.



STEVE:  Oh, baby.  I know that the little D-Link, this little cute D-Link that Mark Thompson has is really neat.  And he says, I mean, he was saying, he was commenting on how much he likes it.  And he said, oh, and it's also got WiFi.  So you're able to, like, for example, he's got WPA configured.  He'll come to my house, get a hard connection to my cable modem, for example.  And then that's all he has to do.  The router is permanently configured with his WPA key, big long key.  So then his laptop, he's able to roam around the house and use his WiFi connection, his secure connection to his little travel router that is then plugged into my cable modem.  Everything just works.  So it's like a zero-config solution.  It's also very secure.



LEO:  Yeah.  I think that's a great solution.  Okay,  I'm going to find one.  And of course if it's D-Link make sure you change the DNS.



STEVE:  Yeah.



LEO:  Just in case.  We've got two listeners with the same question:  Jason Russo, writing through our tech support - your tech support email for GRC.com, and also JD posting anonymously on the security forums, have comments about JavaScript in PDFs.  Jason writes:  Steve, sorry if this is the wrong email.  I couldn't find a good way of commenting on your podcast [GRC.com/feedback].



STEVE:  Yup.  Which is what I wanted to mention, make sure our listeners know GRC.com/feedback gets to me.



LEO:  Just a quick comment on JavaScript in PDFs.  JavaScript, in addition to Adobe's FormCalc, is used within interactive forms for programming logic in a PDF.  This is usually used for calculating fields, input validation, et cetera.  But it can also be used to dynamically change the user interface, which is where FormCalc falls short.  Unless Adobe abandons interactive forms, JavaScript is a necessary evil for the reader.  There is a reason for it, it's just not used by most people.  P.S.:  Love the show.  Well, thank you, that's good to get the clarification.



JD adds:  Hi, Steve and Leo.  First, let me express to you how much I appreciate your netcast.  It keeps me informed and up-to-date on matters of Windows security.  For that I am grateful, and I subscribe to Audible because of it.  Thank you.  Our sponsors thank you.  Per your comments in Episode 195, it appears there is a use for JavaScript in PDFs, at least according to Adobe.  PDFs have the ability to have Flash content embedded inside.  That, by the way, is a really neat feature.  You can make a book, a PDF that has audio, video...



STEVE:  Live things, yeah.



LEO:  Interactivity.  But herein lies the risk.  I've personally seen a demonstration of this in the form of a Flash-based dashboard that contained data represented in the form of pretty gauges.  These dashboards could then be sent to an executive or other morons for review.  They could then play with the data by adjusting graphically represented sliders and knobs to analyze the effects on the data as it's changed, keeping them busy and out of our hair.  No, I'm adding that part.



Following your advice, I switched off the JavaScript and attempted to open a PDF with an embedded dashboard sent to me by a coworker.  I got an error message telling me it would not display without JavaScript enabled.  Yeah, that's one way that you imbed Flash.  Well, I don't want to detract from his comments.  Perhaps there are others who could explain this in more detail, but I hope this sheds some light on why JavaScript might be used in a PDF.  Best wishes to you and Leo.  Keep up the good fight.  Thank you, JD and Jason.



STEVE:  Well, I appreciated both of these guys.  It's weird, too, Leo, because wouldn't you know, shortly after I said that, I wanted to submit to the state my request for voting by absentee ballot for this upcoming special election that we've got on May 19th.  And so I went to the site, and they gave me a PDF-based form that had auto fill-in stuff.  And it didn't work because I had disabled JavaScript, following my own advice to our listeners.



So the good news is it tells you, and I wanted to highlight that, that JD mentioned that, when he tried to run this, the PDF said wait a minute, this needs JavaScript.  So I continue to suggest that normally running with it disabled is the better thing because you'd rather be notified that malware or not malware is wanting to do something than to have it be able to do it without your permission or your knowledge.  So but I thought it was important, since I had just told all of our listeners go turn this off because it's dumb and you don't need it, well, okay, whoops, there are some places where you do.



But the good news is you will be told if you do.  And so then you can decide, again, very much like NoScript in Firefox, you can decide, does this matter to me?  Do I think this is probably legitimate?  In which case you turn it on, and then you get the full functionality that JavaScript provides.  I'm not saying it's not useful, I'm just saying it's so prone to abuse that it'd be nice to have that little intermediate step of saying, okay, this time I'm going to turn it on.  Instead of going to a site that is downloading a PDF without your knowledge and using it to take over your machine.  That's not what you want to have happen.



LEO:  SCS online is saying in our Stickam chatroom that the IRS also uses these interactive PDFs for tax forms.  That's - there's two things you really don't want to go together, insecurity and tax forms.  But, you know, yeah, it's an issue of functionality.  I understand that.



Okay, got a long one.  I'm going to try to skim through this one.  This is from Adrian Oliver in Chiang Mai, Thailand.  Wow.  Chiang Mai?  He cautions about getting "embedded" with Microsoft:  Hi, and greetings from Chiang Mai, Thailand.  Following one of your recent Security Now! programs about the power grid in the U.S. being compromised, I thought I would share the following:  I used to work with a large industrial automation systems manufacturer, which for the last 30 years has been designing, building, and installing big and small control and monitoring systems from nuclear power stations down to small factory systems.  Throughout all those years the critical control systems have always been based on either homegrown proprietary operating systems or a commercial real-time OS like VxWorks.



Ten years ago Microsoft were trying to convince us and similar companies to adopt Windows Embedded.  When asked the question of vulnerability issues, they stated they would guarantee a patch within two weeks of discovery.  The control system could then automatically download it from the Internet, install, and reboot.  Obviously the concept of rebooting the control system of a nuclear power plant did not worry them, but it sure wasn't feasible for us.  Given that the default for Windows is to automatically - first of all, it's online; right?  Problem number one.



STEVE:  Yeah.



LEO:  Given that the default behavior for Windows is to automatically download, install, and reboot at the same time, it would be likely that all such Windows-powered control systems would reboot - and potentially fail to boot - at exactly the same time.  Aagh [laughing].



STEVE:  Brings a new meaning to the notion of the second Tuesday of the month.



LEO:  Talk about unclear on the concept.  In the 20 years I've been in this industry our company never had any control failures in the dedicated control systems due to viruses, attacks, or hacking attempts.  Yes, it is true that almost all the supervisory systems are now Windows based, which are as vulnerable to viruses as any home computer.  However, they are normally operating as supervisory only, reporting, monitoring systems, hopefully never part of any control loop.  I hate that word "hopefully" in there.  All critical control systems are designed to operate and continue operating, even when the supervisory system fails for any reason.



Fortunately, I know that most European operators and manufacturers are extremely careful with what they allow to run their systems.  One pharmaceutical company near where I used to live in the U.K. manufactured penicillin.  Because the manufacturing process of penicillin produces a very fine dust, the explosion hazard is extremely high.  The estimated blast radius, should an explosion occur, is one and a half miles.  The local, permanently manned fire station is two miles away.  Consequently, the people who run the plant were extremely particular - no pun intended - about what software was used to control the plant, as their lives depended upon it.  It sure wasn't anything from Microsoft.



On a different but related note, NASA's Mars Rover is running VxWorks, as well.  Still running.  Had they been designed with Windows XP, we would have had to ask the Martians to reboot several times by now.  Hey, great email.  Wow.  Thank you so much, Adrian Oliver in Chiang Mai, Thailand.  That kind of says it all, doesn't it.



STEVE:  Yeah, I mean, this Windows Embedded is another one of these bad ideas.  We've seen it before.  This is what Microsoft does when something comes along that they don't really have an answer to.  We had UNIX on the Internet for years.  Then the Internet became important.  And Microsoft said, oh, hmm, we really didn't expect that.  We were going to do modems with MSN.  And so they said, oh, wait a minute. We'll just stick a network adapter in our Windows machine, and it's now a networked operating system.  Just as good as that UNIX.  We know how well that worked out initially.  Then of course they were unhappy with PDAs because there was the Palm and the Scion and the various PDAs.  And they said, oh, gee, batteries, that's a problem.  Oh, wait a minute.  We'll just - we'll do Windows CE.  And of course we know how well that worked initially because it was a huge power hog and space hog.  And again, Microsoft just sells what they've got in whatever package it needs to be crammed into.



LEO:  Yes.  And I don't blame them.  That's their job.  But you don't have to use it.



STEVE:  There are solutions, however, which are intrinsically wrong, and Windows always seems to step its foot there.  And then finally the embedded application market happens, that microprocessors are being used in dishwashers and microwaves and all kinds of consumer products and, god help us, cars.  And Microsoft says, oh, hmm, what have we got?  Oh, we've got Windows.  Well, let's call it Windows Embedded.  And the good news is apparently they have not succeeded in the nuclear reactor market so far.  Which we'd really rather have them just stay out of.



LEO:  Well, not so fast, Steve Gibson.



STEVE:  What?



LEO:  Question five from Daan Dingjan - I don't want to say his name "Don Dingdong," but that's what it sounds like.  Daan Dingjan in the Netherlands spotted Windows in a nuclear power plant:  Steve and Leo, love your podcast, listen to all the episodes.  I live in the Netherlands, so I have to wait till Friday morning to download it, just in time for any weekend trips in the car.  That's good.  That gets you - this one will get you all the way across Holland.



Anyway, the last two episodes I've been hearing your worries about Windows being used to run critical systems.  I'm sure you'll be happy to know that, yes indeed, a nuclear power plant in the Netherlands is run on Windows.  During a tour through the control room of the facility in Petten, I recognized Windows on the monitor.  From what I could tell, it was NT4.  Of course I asked whether this was actually used to run the plant or just for administrative tasks.  Without any trace of worry they replied it was used to run the plant.  When I expressed my concern and skepticism, they said, oh, don't worry, it's been running a long time.  It's completely secure.  If it ain't broke, don't fix it, was the gist of their reply.  Oh, dear.



STEVE:  Well, the good news is it was NT.  I mean, the original NT, which is actually 3.5, I think...



LEO:  Yes, that's right, yeah.



STEVE:  And even 4, those were very strong, bulletproof systems.  Now, you don't want to open metafiles on those.



LEO:  Well, and they came out really before the Internet was huge.  They weren't really designed to protect from the Internet.



STEVE:  Right.  And, I mean, I'm sure that Microsoft has nothing that will update NT4 dynamically.



LEO:  No, no.



STEVE:  On the fly.  So again, that kind of sort of pre-Internet, really, I mean, the architecture of NT4 didn't have the bells and whistles and fluff and three different APIs...



LEO:  It was a real business operating system.



STEVE:  ...browser du jour and everybody fighting over it the way Windows does now.  So I would say please don't change it.  Don't go to XP or Vista or Windows 7, you nuclear power plant people.  Just stay with NT4.



LEO:  And don't connect to the Internet.



STEVE:  Exactly.



LEO:  And they probably don't need to patch it at this point because that's it.  You're done.



STEVE:  Yeah.  And I actually - I keep several friends back on Windows 98 because it's so old now nothing infects it.  It's like a different DNA.  It can't get the diseases that Windows does.



LEO:  Really.  Is that true?



STEVE:  Yeah.  Yeah, none of these things - all of these things are all about the 32-bit environment and the new architecture.  They don't affect 98 at all.



LEO:  Well, unless it's like a metafile exploit or something like that, that happens to take advantage of code that has been running since '98.



STEVE:  Good point.



LEO:  And of course then you know it's not going to be patched, either.  I don't know.  I think Windows is a great choice if you're an accountant.  If you're working in a business.  We use Windows here on our office machines.  It's a great office operating system.



STEVE:  Well, it's a consumer operating system.  It's fantastic for...



LEO:  But it's not a good home operating system.



STEVE:  It's for consumers.  It's just not for industry.  And it's gotten used for industry, as we're going to see in some of the follow-on questions here.



LEO:  Oh, here you go.  This is one from, let's see, Lucas Qualls in Jonesboro, Arkansas.  You started something.



STEVE:  Yeah.



LEO:  He says:  I work at WalMart while I'm attending college, where I'm hoping to graduate with a degree in computer information technology this summer.  That's great, Lucas.  We need more smart people listening to Security Now!.  I'm writing because over the past few episodes I've heard you and Leo talk about Windows being the underlying technology in kiosks.  Well, I just wanted to let you know that, if you have ever seen the self-checkouts at a WalMart, they're running Windows XP.  My store doesn't have them anymore, thank god.  They were a total pain.  But when we did, I saw them reboot several times.  And it's, yeah, sure, it's Windows XP booting up.  And then a program loads at boot time to run the kiosk.  You just drag it into the Start menu.  An interesting side note is that they run a terminal emulation program that allows them to access the proprietary system that the other WalMart cash registers connect to.  Yeah, it's often you see kludges like that where it's kind of a text-based system.



Also recently they took out the reliable, quote, "old-timey" ATM that we had in the store - you know, the kind that has the green text and a screen and no graphics, the kind that just works - and replaced it with the WalMart Money Center Express.  We got word that it was supposed to be the most amazing thing in the world.  That's how this new technology is always sold.



STEVE:  Uh-huh.



LEO:  It has an ATM built in, but it also allows customers to buy money orders, purchase and reload gift cards and so on.  I've seen them that sell stamps.  Well, it'd be a great thing if it actually worked.  However, you guessed it, the new system runs, when it does, on Windows XP as well.  And not only that, the thing doesn't work at all half the time.  Things on it are constantly breaking.  It's always needing somebody to come out and fix it.  It has to be serviced by NCR at least once a week.  I personally never used it because I just don't feel comfortable using my ATM card at a terminal I know is running on Windows, and not even running well.  So this is just another example of how stupid some people can be when designing things.  Feel free to use this on the podcast.  I don't even care if you mention my name or location.  He's in, like, the home office practically.  They could come out and get you.



STEVE:  Well, again, I'm at the point I understand I'm beating a dead horse.  I want to get this out of my system.  Our listeners need to know that we won't keep this up.  But mark my words, this issue of Windows being used in mission-critical embedded applications where it absolutely should not be used is going to be something we're reading about in the future.  This is bad behavior.  There are fundamentally sound places where Windows should be used, like on all of our laptops, and absolutely places where the ease of use is, like, the first concern.  Because sometimes you ought to have a certain minimal level of expertise before you're allowed to implement important systems that can affect all kinds of people.  And anyway, I'm - good thing I don't have a cuff hooked up to my arm measuring my blood pressure when I talk about this stuff.  Ugh.



LEO:  Barry Burton in Scotland wonders about WiFi PSK disclosure rules:  Hi, Steve.  I have a question about how a computer knows it's safe to disclose a preshared key to a WiFi access point.  Now we're talking.  Here's a good question.  No more Windows.



What made me think of this is on my Linux machine - I use Arch Linux - I define the WiFi connection I want to use by creating a brief text file - this is how you do it in a real operating system, kid - a profile in /etc/network.d.  That profile is used by the netcfg program to connect to an access point.  In this file I list three lines:  SECURITY="wpa"; ESSID="myssid"; KEY="mypsk".  So in this profile I'm identifying my access point by an SSID string and nothing else.



Say that my access point's down for whatever reason.  What's to stop someone else creating their own access point with the same SSID, then recovering my secret PSK - preshared key - when a computer of mine tries to connect?  If they recovered this information, then they presumably would have full access to my access point whenever it came back in service.  In other words, could you spoof the SSID and get the preshared key?



STEVE:  Yup, that's what he's asking.  And the cool thing - I liked this question because it evidences a little bit of misunderstanding about the nature of preshared keys.  But it's also the thing, the reason that they are so strong and the reason I like them so much, is that it is not the case that the client machine provides its preshared key to the access point.  It's specifically called a "preshared" key, meaning that it's been shared with the access point prior to the connection.  As part of the configuration process at each end they both receive the same key.  Thus they are preshared.



So the access point knows the key ahead of time that it shares with the client.  And they don't even bother with anything except both of them encrypting everything they send using that key and attempting to decrypt everything they receive with the key.  So no part of the key, none of the key ever goes in the air.  It's only the use, the result of using the key that is sent back and forth.  And the nature of ciphers, contemporary ciphers, are such that none of the result of the cipher leaks information about the key that was used to produce it.  That's certainly important as you wouldn't want to be able to reverse engineer the key from the results.



The only way to do that we've talked about over and over and over.  It's the so-called brute-force attack, where you just guess keys, checking the results to see whether you guessed correctly.  And the strongest ciphers are those that have long enough keys that guessing is the only way to obtain any knowledge about the key.  And getting close doesn't count, that is, if you're off one bit in the key, it still produces something that looks just as bad as if you're off all the bits in the key.  So there are criteria for this.  But all of our contemporary symmetric ciphers meet all of those criteria.



So, I mean, preshared keys are so strong, I mean, stronger even than asymmetric keys, stronger than public key technology.  That's one of the reasons, for example, I'm not going to use public key technology in my VPN, because something like a breakthrough in factorization we've often talked about, that breaks public key technology.  It does not break symmetric key technology, which is fundamentally simpler.  But of course it's got the problem that you need to preshare the key.  Many situations, like with a VPN, that's practical.  But situations, for example, on the Internet, where you're connecting to a remote server that you've never connected to before, you can't have a preshared key.



So that's why we need public key technology, to allow a temporary and ephemeral key to be shared.  So there's a need for public key technology.  It does something that private key technology, symmetric key technology, does not do.  But it's not quite as strong as just having preshared key technology.  And in the case of a WiFi network you're able to just go manually configure the access point, give it the knowledge to decrypt whatever it receives, and so that way at no point is the key being exposed.



LEO:  It's never transferred in the clear.



STEVE:  Right.



LEO:  But so what are you going to use, if you're not going to use public key in your VPN?



STEVE:  Just preshared.



LEO:  Preshared keys, okay.



STEVE:  Yup.  And they're arguably stronger.



LEO:  A preshared key could be a one-time pad, too; right?



STEVE:  Well, one of the things that you never do is you never actually use the key itself in order to do the encryption.



LEO:  Right.



STEVE:  That is, you create the notion of session keys.



LEO:  Right.



STEVE:  And so the master key is never itself exposed, but rather you come up with a process of creating session keys.  In fact, the CryptoLink tunnel is going to be continually rekeying.  It will always be rekeying.  Probably no more than, like, every minute it will automatically negotiate a key, and both endpoints switch to it.  That provides something else called Perfect Forward Secrecy, where even if you - it's not possible to decrypt it.  But even in the event that you did, you wouldn't get all of the session.  You would get just a chunk of it.  So it's, you know, a little going overboard, but why not?



LEO:  Yeah.  Very interesting stuff.  I love crypto.  It's one of my favorite topics.



STEVE:  And it's just spectacularly great.



LEO:  Yeah.  Little too much math for my limited...



STEVE:  Well, that's why I wanted - I want to do CryptoLink so I get to play with this stuff.



LEO:  Yeah, I bet.



STEVE:  Deliver some value at the same time.



LEO:  It's a little arcane, and it's also very, I mean, you could tease it all out logically.  But boy, it would be hard to do it in a vacuum.



STEVE:  Yup.



LEO:  You really need to know - you need to learn something, too.  An anonymous listener wonders something I wonder every day.  Why is the Internet still up?  Thank you for the informative and entertaining podcast.  I have a question with regard to Conficker, botnets, and the risks they present to cloud computing and the Internet in general.  If a criminal organization has control over that many machines, don't they have the ability to take down any website on the Internet?  And if so, wouldn't extortion be another method of gaining money?  Has this happened?  And is there an effective countermeasure to a massive DDoS attack?  Continued success in your endeavors.



STEVE:  Well, certainly.  It's happening all the time.



LEO:  It's happening today.  Right now.



STEVE:  DDoS attacks, yes, DDoS attacks are now at an epidemic level.  And it's because they make money.  It's because it's no longer the case that script kiddies, back ten years ago they would DDoS their friends in order to knock them off of an IRC server in order to sort of take over and become the IRC operator, sort of playing in an electronic version of king of the hill.



Now it's all about money.  It's about extorting, for example, gambling sites are often extorted because it's critical that the site be up during a horse race or a boxing match or whatever the site is focused on and accepting bets for.  So the extorters will say, look, we're going to knock you off the 'Net during this important time unless you pay us this ransom.  And oftentimes the first time the gambling site will say no.  They're knocked off the 'Net.  It costs them a huge amount of money.  The second time they say, well, gee, can we get a discount for a quantity?  A quantity discount?



So, now, one of the problems is following the money because, in order to get paid, money needs to be transferred.  And that's of course the Achilles heel of this.  It's very easy for attackers to be anonymous in their attacks and in their threats.  But somehow money has got to get from the source of the attack or the target of the attack who's said, okay, I'm going to pay for, quote, "protection," unquote, back to the people who are doing the extorting.  And that's sort of the weak link in them maintaining their anonymity.  And there are various vehicles that the bad guys have used to try to get around it.



But the Internet as a whole is still up because, big as these botnets are, the Internet is even bigger.  And the whole notion of a Denial of Service attack is a focusing of bandwidth on a single spot.  I've likened it in the past to taking a magnifying glass, and first you put your hand out in the sunlight, and it's fine.  Feels warm, but not a problem.  If instead, though, you take a magnifying glass and hold it the proper distance over your hand, the same amount of sunlight that is being collected by that lens that was fine when it was falling diffusely on your hand, it is now focused into a very bright spot of burning flesh.



LEO:  Yow.



STEVE:  And that no longer feels good.



LEO:  No.



STEVE:  So a DDoS attack is the same thing.  It's a whole bunch of bots, individually not very strong.  Collectively, aimed at a single website, that site is down.  Nothing can defend against contemporary bot attacks.  But while they're attacking that site, they're not attacking any others.



LEO:  In theory, though, they could attack the Internet as a whole by attacking the name servers, the master name servers.



STEVE:  Yes, there have been attacks against the Internet's own infrastructure, that is, for example, the DNS servers is a key.  However, many things make that more difficult.  Even though there appear to be 13 IP addresses for, for example, the root servers, there are actually many more machines than just 13.  And they use complex routing technologies in order to route traffic to the nearest root server, even at a single IP.  So when bots think they're all attacking, even if they were all attacking a single IP, their traffic is automatically diffused across the Internet, so they're not all actually attacking a single location.  So that's one thing.



Also, all of this information in DNS is cached, often for a day or more.  So an attack for an hour would hurt a little bit, but not tremendously.  And there's lots of root servers.  So you really need to hold them all off the 'Net for a long period of time.  And that, due to the distributed nature of the root servers and the fact that we've got caching and that there are 13 IP addresses, all that need to be under attack, that's a huge job.  And it's not clear really what benefit there is.  I mean, if you had pure malice, then you could say, okay, we're going to try to do that.  But really these botnets are now profit centers.  And so they're looking for someone that they can extort in order to get money.



LEO:  There's a movie plot there somewhere.  You know, a plot to take down the Internet.  I mean, that would be - the old days the bad guy, the Bond villain would be aiming a nuclear weapon at New York City.  But in the modern days the extortion is I will take down the Internet unless you give me one million dollars.



STEVE:  Well, I heard you talking during - I don't know if it was another podcast, or I think it was something with Amber recently.  And you mentioned that your son was home, and he called you in a panic, and he said, Dad...



LEO:  The Internet's down.



STEVE:  "The Internet is down.  Come home now."  I mean, we're dependent upon this.  Increasingly, every single day, we are depending upon this connectivity more and more.



LEO:  Yup.  He freaked out.  As would I.  I'm completely sympathetic.  However, I had to finish the podcast before I ran home to save his butt.



Marv Schwartz at Case Western Reserve in Cleveland, another one.  You know, that's a great technical school.  Great computer science program.  Wonders if we're not just choosing the wrong languages.  He writes:  Hi, Steve.  I'm an avid Security Now! fan.  You've never discussed how the choice of language in which a system is written impacts the reliability and therefore the security of the system.  In fact, since you are an accomplished Assembly language programmer, perhaps you inadvertently promote Assembly language programming.  Assembly language, C, C++ all put a huge and unnecessary bookkeeping burden on the programmer and lead to mistakes.  And they all provide unnecessary opportunities to clobber registers and memory through bookkeeping errors, bad pointers, subscripts out of range, buffer overruns, and so forth.  They require the programmer to allocate and release memory.



Language design that promotes writing reliable software is at least 40 years old.  These languages are strongly typed.  This immediately eliminates Assembly, C, and C++.  Although I've never used it, I remember a colleague returning from a stint at Xerox PARC and commenting that when a MESA program compiled, it would run.  So if we're serious about writing reliable software, which is a prerequisite for secure systems, shouldn't we be using languages that help us do that and avoiding languages that invite us to mess up?  Is this worth a session on Security Now!?  Are you going to write CryptoLink in Assembler?  And if so, what are you planning for a UI?  Thanks again for a wonderful program.  Cheers, Marv.  Remember Ada?  That was a...



STEVE:  Ooh.



LEO:  Ooh.  The Defense Department created that language - it had a horrendous spec - for that express purpose.  Ada...



STEVE:  I don't think anyone ever actually created an ADA compiler.



LEO:  It died.



STEVE:  You talk about the horrendous spec.  And it's like, the spec was so horrendous that you couldn't actually make it go.



LEO:  But the point of it was to write a provably reliable, secure program.



STEVE:  Yup.  Yup.  And in fact MESA was an early ALGOL-like language that PARC designed.  And it evolved through several levels.  And in fact it was - there's parts of it that were - is the basis for Java.  Okay.  So Marv's right.  There's nothing more dangerous than Assembly language...



LEO:  Because you're programming to the bare metal.



STEVE:  Yeah.  You can do anything you want to.  And sometimes you do those things inadvertently.  The same is with C and C++.  The reason programmers like C and C++ is the fundamental power that it offers, the fact that it deals with pointers with abandon.  And, you know, you can point at anything you want and do pretty much anything you want with it.  It is very powerful.  There are definitely languages which wrap the programmer in layers of prophylactic protection.  And programmers don't like that because they don't feel robust and powerful, and that's what programmers want to feel like.



LEO:  Well, they feel like the compiler is nitpicking all the time.



STEVE:  Well, and it is.  But it's also keeping them out of trouble.  It also is generally introducing enough overhead that they're not going to have the speed that they would if they were able to program to the bare metal.  So I completely agree that this is a tradeoff.  I even agree that you could argue we're making the wrong choice.  The solution, however, for example, take NASA, where the code that's being used in the shuttle absolutely has to be bulletproof.  I mean, it absolutely can't suddenly be crashing and needing a reboot in the middle of a launch sequence, when it's up in the sky and under thrust.  Their solution is inspection.  Well, testing and simulation and inspection.  They just pound on it and pound on it and make changes very carefully and really look at it carefully and test it and perform regression analysis, rather than using languages which are unable to create some sorts of problems, because they recognize, well, there's still other problems.  I mean, sure, maybe it's not a buffer overrun.  But it's a plus that should be a minus.  I mean, if the programmer makes a mistake, it's still a bug.  And so they're working on pounding it out just literally by sheer force of will and brute force and a methodology that allows them to be as sure as they can that this thing is working.  The problem is, oh my goodness is that expensive.  It is phenomenally expensive to produce software that way.



LEO:  How do you do it?



STEVE:  Well, I mean...



LEO:  A lot of human checks, or...



STEVE:  Yes, it's a lot of people involved, and really good people who realize their reputation and the lives of the astronauts hang in the balance.



LEO:  And they just comb through the code by hand?



STEVE:  Yeah.  And they simulate it, and they look at - they've got a whole procedure and a structure for making sure this is as good as it is humanly possible to produce.  And the problem is it's insanely expensive.  And it's why commercial code is not produced that way.



LEO:  Well, I mean, there are some little things you can do even with C, like don't use strcpy, use strncpy and things like that, that eliminate some buffer overruns.  But you made a great point, which is that you cannot eliminate all programmer errors with any language.



STEVE:  Right.



LEO:  And so it gives you a sense of false confidence to use a so-called "safe" language because you still have to check it.



STEVE:  Yup.



LEO:  So that's a really - it's an excellent point.  I can also see why Microsoft, having spent years building a code base of C and C++, is not very likely to convert it all to MESA.  That's called rewriting 50 or 100 million lines of code.



STEVE:  Yeah.



LEO:  Charles Palen in Norwood, Massachusetts works in the museum industry and explains why they use Windows:  I listen to your show every week.  I've been a long-time listener.  Thanks for your hard work, blah blah blah.  Writing in response to Episode 192 where you discuss the inherent problems with running Windows on kiosk and museum systems.  I work as an interactive developer for a company called Boston Productions.  We actually build and install museum and visitor center exhibits.  I have previous work experience in corporate and small business IT.



It was always a mystery to me why museums, signs, and kiosk systems run on Windows until I started working in the industry.  There are several reasons, including total cost of ownership, IT support, dual display support, driver support.  My boss recently wrote an elaborate article about this at backroom.bostonproductions.com.  To summarize, the major reason we use Windows is touch screen driver support, which is terrible even in Windows across different overlay vendors, and multiple display support.  How easy do you think it would be to configure a touch screen in a 1366x768 vertical resolution with dual monitor support so it can be viewed on a KVM from the exhibit machine room if the machine were running FreeBSD?



Although I'm a longtime Linux user and utilize FreeBSD with dummynet to simulate network lag when doing network programming, most of the museum and creative design industry are Mac users.  It's unfortunate, but the vast majority of the people working in our industry simply don't have the computer skills needed to use a stripped-down OS for exhibit deployments.  Everyone in our office uses a Mac except my boss and me, who are the programmers in our company.  We utilize Windows Vista on our development machines because we need access to the Flash IDE, multi-monitor support, and many other features.



So what he's I think really saying - by the way, Macintosh supports the Flash IDE and multi-monitor support.  But what he's really saying, I think, is that they want to use cheap, off-the-shelf components in these devices, and only Windows supports all that.



STEVE:  Yes.  And that they want development to be easy.  And Windows...



LEO:  Yeah.  And developers know Windows.



STEVE:  ...is easy to develop for.  So I liked this, and I wanted to share this with our listeners because it does represent sort of an alternative view, that is, the good news is, this is not nuclear reactors.  And you can imagine that a museum doesn't have an unlimited budget.  And they're probably being asked to do a lot for not much money.  And if the machine crashes when someone presses a corner of the screen that they didn't anticipate, okay, whoops, pull the plug out of the back, count to ten, plug it back in again.



LEO:  That usually works.



STEVE:  No biggie.  So again, here's an application where I don't have a problem with a consumer operating system being used because the hardware is cheap; the expansion is available; it's going to be compatible enough; it's going to do the job.  And if it doesn't, if it stops working, someone'll say, oh, look, the screen froze.  It's like, okay, fine, pull the plug, plug it back in again.



LEO:  Reboot.



STEVE:  No problem.



LEO:  So, yeah.  And it's not - it's an aesthetic thing to see a Blue Screen of Death or a Windows error message on a kiosk or a big billboard in Las Vegas.  But that's only an aesthetic concern.  I mean, there are other concerns, as well.



STEVE:  Right, exactly.



LEO:  I understand that.  I'm glad you wrote, Charles, because that does explain it a little bit.  Dan in San Diego wonders about the security of VPN solutions.  How dare he?  I really enjoyed your discussions on SSL, or I'm sorry, TLS.  One question, though.  How do government organizations, or individuals for that matter, spy on people who use VPNs?  I know it's possible.  Do they need the assistance of the company providing the VPN service to that customer?



STEVE:  This was a great question because it deals with one of the fundamental issues of security that I want to continue to remind our listeners about.  And that is, you need to appreciate and hopefully understand what it is that your security is protecting you from.  A perfect example from earlier this hour, Leo, was this issue of the Windows firewall.  You know, the assumption is, oh, turn on the firewall.



LEO:  Right.



STEVE:  But whoops, well, wait a minute, it's not protecting us from LAN-based threats.



LEO:  Right.  Had no idea, yeah.



STEVE:  Only from WAN-based threats.  So similarly a VPN, a Virtual Private Network, like SSL or one based on SSL, or even my CryptoLink forthcoming product, what it does is, it is protecting the link.  It's protecting the connection between the two from attack, modification, eavesdropping, or any leakage of information of any kind.  But, for example, if a protected - if a machine using the protected link had a keystroke logger on it, then that's not the VPN's job.  That's not the SSL connection's job.  The keyboard could still be monitored and filtered and checked for whatever, completely separate from the fact that the connection to the Internet, if that's what the SSL VPN is being used for, is secure.



So again, the way government organizations or individuals could spy on someone using a VPN is to install a little hardware keystroke logger in the connection between the keyboard and the computer.  And it will gleefully suck in and record all the keystrokes and even get the protection of the VPN when it tries to send them back to the mothership.  So again, it's the case that you can rely upon the security technology, whatever it is, given that it's been properly implemented and designed, to do what it's supposed to do.  But it's also equally important to understand what it doesn't do, what it wasn't intended to do.  And important not to assume that you get total protection for something that never said that's what it was going to offer.



LEO:  I never said I'd do that.  Finally, the last question, and it comes from the islands, from Jamaica.  Andre says he knows something about Windows and ATMs:  Hi, Steve and Leo.  I can relate to the surprise Paul experienced upon discovering that ATMs at his bank ran Windows XP.  I always assumed they ran a special, robust, embedded program or operating system, or at least a customized flavor of UNIX on these machines.  Needless to say I was very surprised last year when I started working as a software engineer for a company that sells and supports ATMs, only to discover that the majority of ATMs run Windows XP.  It turns out that the manufacturer whose ATMs I work with used to run OS/2 on them.  When OS/2 went under, they moved first to Windows NT, then to XP.  They sold that move to Windows based on ease of software development, among other things.



On the security side of the equation, these ATMs run in a somewhat isolated environment network-wise.  They're not connected to the internet.  No personal data is stored locally.  There are many levels of encryption, including hardware-based for really key stuff as well as on communications.  And for the record, no, Leo, we don't write ATM software in Visual Basic.  There are also many pieces of software that manage failures, crashes, Blue Screens of Death and the like.



That being said, personally I don't believe anything or anyone should run Windows except perhaps the Death Star.  I was going to say the Borg, but they wouldn't be that stupid.  So yes, it's a bit unnerving that Windows pops up in places which are obviously bad ideas.  It's getting back to that same thing.  We want to run a commodity hardware.  We wanted developers to know how to write for it.  He didn't say what they use, but I presume it's Visual Studio and C-Sharp or C++ or C.



STEVE:  You notice one thing we have not seen is anybody saying we're running on Vista.



LEO:  That's surprising to me.  I wonder why that is?



STEVE:  Oh, goodness.



LEO:  Well, they're just slow, they're always slow to move to the new OS.  But XP is now seven years old.



STEVE:  Please be slow.  Please, well, and of course what'll happen is, as we know, Microsoft is not going to be letting people use XP forever.  Microsoft is shutting the door, and they're going to stop doing security updates, and they're going to abandon it, basically, and force everyone to move forward.  So at some point all these systems that are running XP will probably be migrated to - I hope they skip over Vista.  Maybe they'll go to Windows 7, and not soon.  Please, please, please let's give Windows 7 a year to settle down and get a first few service packs under our belts.



LEO:  Yes.



STEVE:  Okay.  That's the last word on embedding Windows where - application and, well, application-prudent, application-proper use of Windows.  We will move on.  But again, mark my words listeners, this is going to be something that bites us at some point.



LEO:  Not the end of the story by any means.



STEVE:  And you heard it here first.



LEO:  So what is next week, Mr. G?



STEVE:  I don't know.



LEO:  Ah, how exciting.



STEVE:  See what comes up.  I've got a whole bunch of list of things.  I'd love to talk about the DNS benchmark, but I don't think I'm going to quite have all the documentation and everything pulled together by then.  So probably three weeks from now we'll do that, and we'll do something next week.  Not sure what.



LEO:  You know, I should mention that in a couple of weeks, on May 24th, we're going to do a TWiT with Dan Bricklin, the creator of VisiCalc.  And you're welcome to join us, if you'd like.



STEVE:  I'd love to.



LEO:  I think it's going to end up being a computer history TWiT.



STEVE:  Dan wrote something called DBD, Dan Bricklin Demo.



LEO:  Yes.



STEVE:  Or, shortened, also known as just Demo.  The original one was just a text screen slideshow where it was basically a text screen editor where you could edit characters and colors and so forth, and then you were able to step through.  And the idea was that back in the day, for example, a program like VisiCalc was also text based.  VisiCalc ran on a text screen.  And word processors did, and many programs did.  So he wrote this - basically it was just a textual slideshow to show someone, to demo - oh, it also had, like, macros and things.  So you could kind of wire it up and make it sort of look like it was a live-running app, when it fact it was just the screens.  I used it to design SpinRite.



LEO:  Really.



STEVE:  The basis for all of my screens.  I have DBD files for many versions of SpinRite.  All along I've used Dan Bricklin's Demo as - basically I never made it run.  But I designed the UI because the UI expressed all the features the program would have.  And then I basically wrote SpinRite behind the screen in order to make all those things that I designed visually, make them come alive.



LEO:  Well, that's kind of the idea behind RAD, Rapid Application Development, and Visual Basic is you design the screen first.  You design the UI first, with no wiring.  And then you lift up the hood, and you go, I'll make that button go to there, and this and this and this.



STEVE:  And you hook everything up.



LEO:  You hook it all up.



STEVE:  Yup.



LEO:  So he was kind of ahead of his time.  He says he's now doing open source programming in, sorry about this, JavaScript.  But JavaScript's actually a great language.  It's a very, I mean, well, I wouldn't say it's a well-designed language.  But it's a very useful language because you can do so much with this client-side browser stuff.



STEVE:  Yeah.



LEO:  So if I were a young guy starting out in programming, I'd absolutely learn JavaScript and jQuery.



STEVE:  I think so, too.  I mean, it is - well, and the other thing, I mean, we know for example that Java and JavaScript sort of hand in hand, as I understand it, it's the platform for the Pre also; right?



LEO:  I don't know about Java.  But JavaScript and CSS and, yeah, and this was what Apple did first with the iPhone.  They said, well, you don't have to write applications.  You can use JavaScript and CSS to create applications.  That's how dashboard widgets and Windows gadgets and a lot of the Yahoo! widgets are all created the same way.  You can do a lot with this.



STEVE:  And so essentially you have a universal client base.



LEO:  Exactly.



STEVE:  You've got, you know, everything understands it because everything has a browser or a browser component.



LEO:  Exactly, yeah.



STEVE:  And that means everything can run what you write.



LEO:  It suffered initially because the spec was so poorly written, and it was implemented differently on every browser.  And you had to write lots of code that said, well, if it's this browser, then do this.  If it's that browser, then do that.  I think that's gone away.  And then use of libraries like jQuery have made it a lot more kind of orthogonal language and easier to understand, easier to learn.  I'm, you know, I've been playing with it.  I love it as a language.  I mean, it looks just like C.  If you use C, you kind of know JavaScript.  You just have to learn the DOM API, and you're set.  But it can also be the source of much pain, as we have learned.



Steve, next week, who knows, a Security Now! episode that could cover anything.  You go to GRC.com, you will find of course SpinRite there.  That's Steve's incredible program for disk recovery, disk maintenance.  It's a must-have.  If you have a hard drive, you need SpinRite.  You'll also find lots of free stuff there.  Steve has so many great free security applications like ShieldsUP!, DCOMbobulator, Shoot The Messenger.  Also some fun tools like Wizmo, and soon some new stuff coming.  Of course transcripts of the shows are there.  You'll find 64KB and 16KB versions for the people who don't have all the bandwidth in the world.  It's all there at GRC.com.  I didn't ask you, did you go see "Star Trek" yet?



STEVE:  I'm doing that right now, as a matter of fact.  This afternoon.  This is the first of the Star Trek movies that I have not done the whole stand in line, see it on opening day routine.  I guess I am getting a little old.  Actually I just - I didn't want to fight the crowds.  And I knew that I'd be able to go Wednesday afternoon...



LEO:  Perfect.



STEVE:  ...after recording, when the theaters are quiet, and slip in and really enjoy it.  And boy, I mean, the reviews have been great.  It made $80 million in the first long weekend of opening.  And they made more money on Saturday than they did on Friday, which is...



LEO:  Always a good sign.



STEVE:  That's a good sign because it's growing because word of mouth is so strong.



LEO:  It's probably the best Star Trek movie, certainly one of the best.  And it's just really a pleasure.  So I think you'll love it.  I'll be very interested in your reaction next week.



STEVE:  I'll tell you next week.



LEO:  Thanks, Steve.  We'll see you then.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#197

DATE:		May 21, 2009

TITLE:		Windows 7 Security

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-197.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, Steve and Leo discuss the changes, additions and enhancements Microsoft has made to the security of their forthcoming release of Windows 7.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 197 for May 21, 2009:  Windows 7 Security.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure and insecure.  We actually cover insecurity more than security.  Privacy, too.  Steve Gibson is here.  He is the guru of security and privacy, the man who discovered spyware, coined the term, wrote the first antispyware program.  He's also famous for [SpinRite], still the world's best disk maintenance utility.  And he is here every week talking about security issues, answering questions.  Hey, Steve.



STEVE GIBSON:  Insecurity issues.



LEO:  It really is.



STEVE:  You're right.  Security is boring.  It's the insecurity that's exciting.



LEO:  Yes.



STEVE:  And trying to get there from here, or here from there.  Or somewhere.



LEO:  So this week, what insecurity will we be discussing?



STEVE:  The source of the world's greatest lack of security, Windows.



LEO:  Oh.



STEVE:  We're going to talk about Windows 7 security, what they have done since Vista in their now more than half-hearted attempt, I mean, I think they're wholly hearted, to get Windows security cranked up.  They're basically still trying to recover from years of really not giving a damn.  And now that they do, they've got all these legacy problems.  And so they're continuing to move forward.  We're going to talk about the things in Windows 7 that Microsoft has deliberately continued to work on since the big changes that they made in Vista.



LEO:  I'm really liking 7, and I'm hoping - my sense is it's more secure.  But I'm hoping that you will give it at least a qualified thumbs up.



STEVE:  The short version is:  Yes.



LEO:  Oh, whew.  But we'll get the long version in a moment.  I want - we want details.  Yeah, I want details.



STEVE:  That's why we have listeners.



LEO:  Also I'm sure we have some news and errata from the world of security.  So what's new in the world of security?



STEVE:  Well, the good news is it's been a surprisingly quiet week.  Only one thing happened that is of potentially substantial note.  It is of course with Microsoft.  And that is that they've been informed of a defect in IIS, their main web server system, in the WebDAV protocol.  WebDAV is the technology that essentially uses HTTP to connect to and allow directories to be viewed and modified remotely.  So, for example, it's a way, for example, that people could edit the pages on remote servers.  The traditional way has been to use FTP, File Transfer Protocol, where you'd work on a page, and then you'd FTP it up to the server in order to make it go live.  WebDAV, for example, is what Jungle Disk uses.  It uses that protocol in order to create folders on your local system that are actually files remotely located at Amazon in their S3 service.  So it's a useful and sort of increasingly popular protocol.



Well, Microsoft, it turns out, has a Unicode parsing problem in their password handling for their WebDAV adjunct component to IIS, both 5.0, 5.1, and 6.0.  So that's a problem.  There aren't - they don't know yet of any exploits to it.  But potentially this allows any WebDAV services that are exposed to be exploited.  And it's not good.  So I would imagine they'll have this fixed for the June patch because it's potentially really bad.  I wanted to let any of our listeners know who do have WebDAV running, since it's running over the same port, that is, it runs over port 80, you can't just close the port.  What you have to do is shut down that service and not use it.  And that's Microsoft's recommended workaround for this.  I mean, this is bad.  So I just wanted to make sure that our listeners who are using IIS, if we have any, who also have the WebDAV component actively used, since it's available to anyone who has access to your web server, a mistake in its password processing is bad.  And so this is. 



LEO:  I saw that Ball State University actually fell prey to this on Monday.



STEVE:  Ooh, already.



LEO:  And so it's, yeah, it's out there.



STEVE:  Okay.



LEO:  It says - this is from the Register.  Hackers have wasted no time targeting a gaping hole in Microsoft's IIS server, according to administrators at Ball State University, who say that servers that use the program were breached on Monday.  So as of this morning web accounts at Muncie, Indiana-based university remain inaccessible.  And the service isn't expected to be restored till tomorrow or the next day, so...



STEVE:  Yeah.  In fact, I think it was Monday that this was announced because I knew - I've known about it for a couple days, and I've been waiting for this podcast to update our listeners.  So, yeah, people jumped on it immediately.



LEO:  You know, there's one that also is breaking this morning.  You probably didn't see it.  But according to SecureMac they issued a critical warning for an unpatched Java security vulnerability in OS X on the Macintosh, including - remember we talked last week about that half-gigabyte update.



STEVE:  Oh, the mega patch, yeah, 13,000 files updated?



LEO:  Even in the mega-patched Macs, the vulnerability could be used to perform something they call a "drive-by download," the ability to infect a computer by visiting a web page.  The flaw allows malicious code to run commands with the permission of the current user.  So you have to say yes, apparently.  But Landon Fuller, who discovered this, is a little upset.  He says, you know, they've known this exploit has been around, and they didn't patch it.  So he released - he said, I've got to release code just to prove that it exists.



STEVE:  Yup.  It'll get fixed now.



LEO:  It'll get fixed now.  He says the workaround is to disable the use of Java applets in your web browsers.



STEVE:  Imagine that.



LEO:  Yeah, and turn off Open - this is something that Apple does called "open safe files after downloading."  And I wish they'd put "safe" in big old quotes.



STEVE:  Believed safe.



LEO:  Yeah, because this was a problem before with I think dashboard items just opening and running and installing, you know, presuming that they're safe.  And really that should be turned off on the Mac.  It's a convenience, but it's a bad idea.  So something to be aware of.  And since we're going to cover Windows security, I didn't want anybody to think that we were biased.



STEVE:  Especially you, Leo.  No one would think that you were a Mac fan boy.



LEO:  Not now, because I'm telling the truth.  I want everybody to know.



STEVE:  Well, I have two other little blurbs of errata.  I discovered the other day, searching for a solution, another little add-on for Firefox.  I know from talking to a lot of the people in our newsgroups that many of them use Windows large fonts.  Just because their screens are high resolution, the fonts end up being too small.  When I'm at Starbucks I'm using this tablet, and the tablet has a lot of resolution relative to the screen size.  It's a 1400x1050...



LEO:  Oh, it's big.  How big is the screen?



STEVE:  It's a 12.1 diagonal screen.



LEO:  Oh, that small.  So you really have little dot pitch there.



STEVE:  Yes.  And what I was noticing is I was - I've got old person eyes now.  So even though I've got my left contact lens is focused for reading close, and my right one is focused for distance, so that I'm not having to do the whole reading glasses thing, even so, I was noticing that lots of websites and even Microsoft's MSDN help file stuff is really small.  Well, so I thought, gee, you know, is there, like, some way to, in Firefox, to change the font size?  Well, first of all, Ctrl+ and Ctrl-, that zooms a site in and out.  And it zooms the text and leaves everything else the same, which is very nice.  And Firefox even remembers, I notice, what your zoom settings were per site.  So when you go back to something where you've been before, it's the size you left it, which is...



LEO:  I use that all the time.



STEVE:  ...very nice.  What's missing from Firefox 3 is a default zoom factor, which would be very nice.  I've put in about:config to bring up the private config page.  And I got a little prompt saying, are you sure you want to go there?  This is, like, for people who know what they're doing.  Wind  up your propeller.  And I said, yes, I'm sure.  And I think it had an option not to be harassed with this extra little intercept every time.  And then I put in z-o-o-m.  And I found, like,  five entries under the about:config that were about zooming.  And like there was, like, what - it had a list of zoom factors, minimum and maximum, some cool things, but no default.  It's like, why not give me a default entry which would default to, like, 1.0, meaning 100 percent, and then I could change it.  But no.  So it turns out, naturally, there's an add-on.  It's called NoSquint.



LEO:  Not NoScript, NoSquint.



STEVE:  Exactly.



LEO:  I love it.



STEVE:  It's NoSquint.  No S-q-u-i-n-t.  So I wanted to share that with our users, our listeners, who are also maybe 40-plus age and who are finding themselves squinting.  What this does...



LEO:  So it still zooms, but it jumps to, like, a zoom that you like.



STEVE:  Well, it does even more.  You are able - it's got both this notion of zooming the whole page versus zooming the text...



LEO:  See, I like that.  Safari does that.  And for, well, for TV, for what we do, it's great because the pictures get bigger, too..



STEVE:  Right.



LEO:  So you don't lose formatting.  You just kind of are zooming in.



STEVE:  Right.  So you have independent control of those two factors.  And what Firefox 3 doesn't offer is a default.



LEO:  Right.



STEVE:  So I set mine to 130, to 130 percent.  And so now it's just the size I want.  So I wanted to notify users I found - our listeners that I found something else that's cool, NoSquint for Firefox 3.



LEO:  Now, do you still do Ctrl+ or...



STEVE:  I haven't had to.



LEO:  Oh, it just does every page 130.



STEVE:  Yes.



LEO:  Ah.



STEVE:  Although then it will also do the per-site exceptions.  And so it's able to memorize anything that you do aside from that.



LEO:  That looks great.



STEVE:  So it's just, you know, for me it's just what I want.  And I thought, hey, cool, I'm going to share that with people.  The other thing, there was a - I've had a huge, tremendously positive reaction to the little KatMouse utility.  That's the thing that allows your mouse's scroll wheel to scroll whatever you're over, even without having to click on it to make it the active window.  And, I mean, an amazing amount of mail came back saying, my goodness, I really like this.  Well, I wanted to tell people about a mouse which works really well with this.  And actually it's the whole family of Logitech mice that have - and I don't know how they do this - a virtually zero friction mouse wheel.



LEO:  Ooooh.



STEVE:  So that you can spin this wheel...



LEO:  Oh, yeah.



STEVE:  ...with your finger.



LEO:  Yeah, I think it has, like, a clutch; right?



STEVE:  Well, it's got two modes.  When you push it in, it goes into, like, the traditional kind of click-click-click-click detent mode.  But if you push it again it, like, toggles back and forth.  It puts it in this zero friction mode.  I mean, this thing really spins.  So that now you're able just to kind of give it a flick and, like, literally zoom, I mean, like, scroll all the way to the top or all the way to the bottom.  But I'm noticing that it works well enough, you can spin it like the speed you want.  And then as soon as you get to where you want to be, you just put your finger down on it, and it freezes the window.



LEO:  Which mouse is this, Logitech mouse is this?



STEVE:  Well, I'm actually using their Nano VX, which is...



LEO:  Oh, yeah, I have that.  I love that mouse.



STEVE:  That's my - it's the mouse I'm using.



LEO:  It's designed for laptops.



STEVE:  Yes.  It's the mouse I'm using at Starbucks.  It's got a little tiny, I mean, a super tiny little transmitter that's - literally it's the size of the USB plug with a little tiny head on the top of it, just enough...



LEO:  I was so sad because I lost my transmitter.



STEVE:  Oh.



LEO:  It's this small.  You can eat it.



STEVE:  Well, in fact, me, I'm sort of a battery fanatic.  So when you put it back into the mouse, it stores inside the battery compartment of the mouse.  And of course in the process of plugging it into, like, returning it to its storage position, it disconnects the battery so that your mouse is turned off.  But I think they think in terms of, like, leaving it sitting there on your laptop all the time.



LEO:  [Indiscernible].  It barely protrudes.



STEVE:  Yes.  And the mouse knows when it's not being moved, and it goes into an idle mode anyway.



LEO:  Do you prefer that to using Bluetooth for - I do.  Bluetooth seems to drop out, and it's just...



STEVE:  I agree.  I've not had success with Bluetooth to the degree that I have with this thing.  But they do - I can't remember.  They have a trademark name for this style of wheel.  And many of their mice, they don't have a Bluetooth mouse with this, but they have a whole range of, like, larger desktop mice, as well, that have this same zero-friction wheel.  And I tell you, when you combine that with the KatMouse, you know, just hover scroll thing, it's just a - it's a hot setup.  So I just wanted to pass that on to our listeners as something that I found.



LEO:  I think that this Nano VX is good for these Netbooks because they really have lousy track pads.



STEVE:  Well, they don't have room for a full-size track pad.



LEO:  Right.  So you almost need a mouse.  And something this small, it's perfect.  It's just right for it.



STEVE:  Yeah, I like it.  And in fact I'm seriously, I mean, I'm liking the wheel so much, I've got the big Microsoft ergonomic mouse under my hand, my right hand right now.  But it's got the traditional sort of stiff wheel.  And I'm seriously considering moving over to a Logitech mouse just to have this zero-friction wheel because it just - literally, you just kind of give it a kick, and it zooms up.  And then when you see where you want to be, you just stop the wheel, and the scrolling stops.



LEO:  Like a fishing pole.



STEVE:  Lets you jump - yeah, exactly.  And we did get a really nice note from a listener, Mac Morris, who wanted to share a SpinRite testimonial, which he named as such.  He said, "I recently downloaded SpinRite 6 to fix a hard drive at my workplace.  The hard drive would attempt to boot and then give the famous Blue Screen.  I ran SpinRite and received a clean bill of health.  However, the clean bill of health led me to the real problem, which was a corrupt Windows installation."  So it wasn't a problem with his drive at all.



He says, though, "After repairing the installation, all was well.  Well, my boss decided not to let SpinRite go to waste.  I have since used it to successfully recover two dead hard drives, and have two more on which to run it.  I think we need new hardware," he says.  "Thank you for such a great product, and thank you and Leo for Security Now!.  I hope to catch up on the episodes soon.  Luckily the CD player in my car plays MP3 files."



LEO:  Well, you'll be able to catch up.  Just take long drives in the country every once in a while.



STEVE:  Exactly.



LEO:  Listen to all the shows.  All right.  We're going to get to Windows 7 security issues.  I think this is a great topic.  I'm dying to hear this.  I've been saying, and I hope that you're not going to prove me wrong, that this is the best version of Windows ever.



STEVE:  No.  Well, okay.



LEO:  We'll see.  I know that there's qualifications and caveats and so forth.  But I don't have your depth of knowledge on the security side, so that's what I really want.



STEVE:  For the typical user I think it is the case.  I'm not going to contradict you.



LEO:  Wow.



STEVE:  But I'm not going to go there for a year, either.



LEO:  Yeah, I understand that.  This is a guy who was using Windows 2000 for the last eight years.



STEVE:  My XP installation is still fresh.



LEO:  So let's talk about - I am excited about this conversation - Windows 7 security.  Now, remember Vista, they said we're going to rewrite everything from scratch.  And you were very worried, the TCP stack, brand new.



STEVE:  Well, yeah.  And Vista had fewer problems than XP.  Remember that it added kernel patch protection, where it was not going to allow things to go hook the kernel, which was controversial because many third-party products did rely on patching the kernel in order to function.  It hardened services and drivers by requiring that they be signed, which was arguably a good thing.  Worked more for data execution prevention, DEP.  Also offered Address Space Layout Randomization, ASLR, where it would deliberately load the various subcomponents of Windows at random locations in order to make it harder for malware to jump to a specific location in the kernel, which was one of the approaches that malware depends upon, for example as part of an exploit using a buffer overrun.  You would jump into some place in the code that just happened to execute a few instructions that had a side effect of, for example, turning off User Account Control or something.



So they did a lot in order to improve the security when they went to Vista.  Now, of course they also, talking about User Account Control, which was very controversial, they arguably maybe went too far.  I think we could now say clearly and confidently that they did because they have backed away from some of the annoyance factor.  But the good news is they really - they've done so in a way that is some reengineering rather than just turning things off.  So they really haven't backed out of the security that they were offering.  So, but Windows 7 offers, running through the list briefly, and then we'll go back and look at it in depth, is something called a "biometric framework" which is currently only supporting fingerprint readers.  But it offers some good features.  They have extended authentication protocols for small networks.  They've improved BitLocker so that it may actually be useful.  They've added BitLocker support for removable drives.  They've really made some changes to User Account Control.  There's something new called AppLocker.  They've fixed firewall policies to make them better.  They've got DNSSEC, that is, DNS security support in the client.  They've fixed autoplay so that it defaults in the right way.  And they've got something called Direct Connect that works with their built-in VPN client stuff.



So a bunch of things which they have - they've basically gone into, they've looked at.  I would sort of call this, you know, like major improvements to - mostly major improvements to the security, to the existing functions in Vista.  This is like Rev. 2, or Round 2.  We're going to - they took all the feedback and problems people had, and in many cases did some real reengineering of it.



Now, one thing that's new that I talked about first was the so-called "biometric framework."  They call it WBF, Windows Biometric Framework.  It's in response to the fact that an increasing number of machines, probably primarily principally laptops, have built-in fingerprint readers.  I know that both of my ThinkPads do, as does this new tablet that I got, all have fingerprint readers.  Under XP, which is what I'm using, it's necessary for the vendor to basically bring along a whole collection of add-ons to make the fingerprint reader work.



And in fact one of the problems I had, remember we talked a while ago that I had my two employees, Sue and Greg, were out roaming around and wanting to get secure access to the GRC network.  Well, I ended up doing the whole Perfect Paper Passwords technology to create a paper-based, one-time password system that would allow them to do that securely.  But that was only after a great deal of frustration trying to figure out how I could write an application to use the fingerprint reader that we all already had in our laptops because I set them both up with these nice IBM Lenovo ThinkPads, all with fingerprint readers.  Yet there's no API, no Application Programming Interface, that would allow me in any way to say swipe your finger on the reader now, even though I'm running, swipe it again to prove that this is really you at the keyboard.  Well, we get that in Windows 7.   So...



LEO:  Ah.  But that was kind of inevitable; right?  I mean, that's been - these biometrics have been built into machines for a while now.



STEVE:  Yes.  And so Microsoft is responding, so...



LEO:  Finally, yeah.



STEVE:  And what it also means is that we'll see shareware and freeware applications using the fingerprint in different ways.  I mean, I'm, as we know, I'm a fan of the YubiKey.  It offers the ability to - it's different because it allows you to authenticate yourself wherever you are.  Inherently you're authenticating your fingerprint to your own machine.  On the other hand, you've always got your fingers with you, hopefully, so that's convenient.  So what this does is this essentially turns the fingerprint reader from a proprietary device only supported by manufacturer-specific drivers and, like, some third-party glue that, like for example, Lenovo provides their own third-party stuff and keeps it very closed.  This opens it up.  And I think we'll end up seeing lots of good use for it.



For example, my own forthcoming VPN will certainly leverage that API when it's available as one of the many means that it will have for authenticating.  So when you want to create a connection it'll say, okay, you've told the server that you want to make yourself swipe the fingerprint right now.  So do that right now.  Prove that it's you who's doing this.  And so that's going to be - that's a nice step forward.  I consider that a good thing.  And I think we're going to be seeing, then, as a consequence, much more use of this kind of inexpensive pervasive biometrics where it's available.



Also, because Microsoft has carefully engineered this with security in mind, we noted - and we've talked about how, for example, that a problem with biometrics is that unlike, for example, a password, you can't change your fingerprint.  The fact that you can't change it means you don't want it to get away from you.  It's one of the reasons that we've had listeners write in during our Q&As saying that they object to Disneyland Florida using their fingerprint as getting into the turnstile at Disneyland.  It's like, uh, no, I'm not - this is where you give them your knuckle instead because you want to keep control of your fingerprint.



So one of the things that the Windows Biometric Framework does is it encapsulates that knowledge and prevents any application from having access to the fingerprint.  It gets a token that represents you, but absolutely cannot access that biometric information, which you really want to protect because it's something about you that you can't change.  So that's new in Windows 7, and that's a hundred percent good news.  I mean, as long as they didn't screw it up somehow.  I mean, it certainly represents a nice move forward for security, and something I'm glad to see.  I mean, I will absolutely take advantage of it.



LEO:  Are they tying it in to TPM or any of the hardware...



STEVE:  Oh, yeah, yeah.  It's absolutely based on the Trusted Platform Module to do authentication and storage of stuff.  I mean, as is, for example, in the ThinkPad, and even in my tablet, all of these things do use the TPM.  But there isn't an application-available API.  Just adding that hugely opens this up to the ability for all kinds of applications to say, hey, let's have you reauthenticate right now before we proceed.



Oh, in fact, User Account Control can be tied to the fingerprint reader now.  So, for example, in a home environment, the kids would be running as a limited user.  And you can then put parental controls on things which are tied to the fingerprint reader.  So that in order to do something, the box comes up, and the kids have to say, hey, Mom, can you come here for a second, I need permission to whatever it is, charge a micro payment on your credit card or something.  Mom comes over, scans her finger, and bing, it works.



LEO:  That's good.  I like that.



STEVE:  So, yeah.  We're going to see - this is just like, you know, lots of good move forward.  Traditionally in a home network you log onto your own machine.  Or if you're doing filesharing, and you have different credentials on another machine, you have to - you put those credentials in, in order to map a network drive.  Microsoft has done something that they call "extending the authentication protocols" with what they call "home group authentication."  And with home group authentication, essentially it's a little bit like sort of a mini enterprise.  You know, in an enterprise you authenticate to the domain.  And so that allows an individual to be in various parts of the enterprise.  And when they authenticate on a machine where they happen to be, they're authenticating against their credentials that are stored on the domain controller.



Well, Microsoft has sort of juniorized that and created this notion of a home group authentication, where the idea being that it essentially creates peer-level authentication providers that will allow you in a home network environment to authenticate against another machine on the network, which is a whole new level of sort of flexibility for what home networks are doing.  And I don't really have a good sense yet for how that will be applied.  But I'm glad that that foundation is there because it makes sense in a home network environment.  I'm the only one in my home.  So I've got credentials synchronized among my different machines.  And so connecting to them is transparent.  Really in a more heterogeneous environment, where you've got different log-on users and passwords on all the different machines in the environment, it'd be nice to have, to be able to authenticate as Mom or Dad on your kids' machine, depending upon how you wanted to set up filesharing and media sharing and so forth.  So we get that.



Now, BitLocker.  I've never been impressed, and many people have never been impressed with BitLocker, only because, unlike TrueCrypt that I am very impressed with, BitLocker has traditionally been a big pain to set up because, as we'll remember from our podcast on BitLocker, you need to create a separate system partition, separate from the main system partition.  That is to say that Microsoft didn't do the sort of boot sector intercept approach that TrueCrypt took, where you're able to just do an in-place encryption of the whole drive and add that after the fact.



And so the problem with Vista was that Vista came with the whole drive partitioned as the C partition.  And the problem is you couldn't just say, oh, I want to add BitLocker to this because it needed repartitioning.  And sure, you could use some third-party tools to do that.  But that was enough of a barrier that lots of people didn't.  So two main changes to BitLocker in Windows 7.  The first is that Windows 7 setup itself, by default, creates a separate active system partition.  So it sets itself up so that it is ready to be BitLockerized if you decide you want to do that.



And if you are upgrading from Vista into 7, of course you wouldn't be running Windows setup from scratch on an empty drive.  The whole drive would already be a C partition.  So Microsoft has taken responsibility for essentially allowing you to retrofit the BitLocker-required partitioning into any non-prepartitioned drive.  That is, literally it comes up with a dialogue, and it shows you shrinking drive C, which is what's necessary in order to create some empty space where it can set up its separate active system partition.  So that means that you are for the first time able to, without using any third-party repartitioning tools, and the potential concern of, like, okay, well, which one do I use, how do I do it, how much space do I need and all that, you're able to just tell, in Windows 7, you're able to tell BitLocker, okay, I want you to install on this drive, even though it's not ready for you.



So BitLocker will shrink the partition, create the new system drive, set itself up, and then prepare to encrypt the whole drive, which is very cool.  And of course the flipside of the overhead that this represents is that you end up with an arguably much more capable authentication environment.  For example, I wish that I could use biometrics to authenticate with TrueCrypt, or I wish that I could use my YubiKey to authenticate with TrueCrypt.  TrueCrypt right now only allows you to enter a password.  And so the advantage of the more heavyweight Microsoft approach is you've got a Windows system there running, so you can take advantage of much more powerful authentication technologies in order to say, for example fingerprint reading, in order to say yes, this is me, unlock my BitLocker partition.



Then the next thing that they did is that they call BitLocker to Go, which short version is it's BitLocker for removable drives.  Which is very cool.  One of the things that they have done that I think is really a tremendous improvement is there is - when they added BitLocker to Go, meaning that you had BitLocker for - you had encryption of removable drives, meaning USB solid-state drives or removable hard drives, they said, okay, we're going to enforce that.  So there is now, for the corporate environment, a group policy setting that says any removable drive is read-only unless it is encrypted with BitLocker.



LEO:  That's great.



STEVE:  Yes.  So, now, they did have to do a little bit of a kludge in order to retrofit this into FAT file systems because of course most removable drives, in fact I don't think I've ever seen one that came preformatted as NTFS because of course you don't have...



LEO:  Compatibility issues.



STEVE:  Exactly, compatibility issues across Mac and Linux and other OSes, whereas they all support the FAT file system without any problem.  So Microsoft has this weird sort of virtualization overlay that they create on top of the FAT file system.  They realized that's not a problem because only they and BitLocker can read it.  So they were able to sort of kludge up the architecture of the FAT file system.



The other thing that they had to do was they said, well, okay, we're doing BitLocker to Go in Windows 7.  But we can't get away with only having Windows 7 work with these things, that is, at least being able to read them.  We need a solution for XP and Vista.  So they do have, when you set this up, there is a reader which is installed on that removable drive which both XP and Vista are able to invoke in order to have access to the FAT file system.  So it creates sort of a little decryption system which is XP and Vista compatible so that the drive that you create under Windows 7 with BitLocker to Go can be read by XP and Vista.  So it's a nice solution.



They also have, in existing BitLocker systems, every single volume you created needed a different recovery key.  And they realized that was too burdensome for keeping track of all this.  So it is now possible, for example, in a corporate IT environment, to have a single recovery, a single master recovery key that will work across all the BitLocker drives in the organization, which makes doing data recovery, they have something called a "data recovery agent" in Windows 7 which they actually - they got this technology from EFS, their Encrypted File System, and set that up.  So essentially they've made this portable in a way that's useful.  And I think this solves a lot of problems.  And as you said, there's group policy enforcement, the fact that they're able to say removable drives you plug in are read-only unless they're encrypted.  Again, that's a major step forward for Windows 7 and long-term security enhancement.



LEO:  You could disable that.



STEVE:  Yes.  Oh, absolutely, yeah.  Oh, yeah.  



LEO:  But it's the right default behavior.



STEVE:  Yes.  And it is not the case normally.  So it would be something that corporate IT would say we're enforcing this.  So that you can plug drives in, your thumb drives, without encryption, and you can read from them.  But you can't write anything to them.



LEO:  Right.



STEVE:  Well, speaking of that, the other thing that they did - yay - is autoplay.  Autoplay...



LEO:  Yeah, this is the problem.



STEVE:  Yes, is now disabled by default on everything except removable optical drives.  That is to say, CDs and DVDs.



LEO:  And this is in response to Conficker, basically.



STEVE:  Yes, essentially, yeah.  Well, and in general.  Microsoft actually did a study which showed, I think it was 17 percent of viruses, yes, 17.7 percent of malware was propagating through autorun.  And so they said, okay, this is wrong, let's turn that off.  So that's another improvement.  So CDs and DVDs by default will still launch when you install them.  But no other removable drives will.  You don't even get the pop-up that prompts you for what action to take because users tend to take the wrong action. It's just silent.  It's like, nope, we're not going to have that.  That does mean, though, that simulators of CDs and DVDs, like U3, they do still work.  They look like a CD, like a removable optical drive, specifically in order to get that autoplay functionality.  And so those will still work.



LEO:  That's too bad.  But I guess that's...



STEVE:  Yeah, but again, security-conscious users can disable that themselves.  So that won't be hard to fix, either.  User Account Control.  This is, of course, the very controversial pop-up which has been the bane of Vista users for so long.  Several things have happened.  The good news is that User Account Control was such a problem that a great deal of pressure was put back on application writers to make it work right.



For example, I remember when I wrote SecurAble, I thought, okay, I want to make SecurAble work correctly with Vista.  So there is a means for an application to declare its need for administrative privileges right upfront, right in the loader, essentially, so that Microsoft asks you preemptively, hey, this program wants administrative rights.  Do you want to allow that?  And then you're able to give it to the program and never be harassed later, like downstream when you're doing specific things that require the rights.  Most applications traditionally, well, first of all, this didn't exist before Vista, so of course no applications were doing it then.  So it would be when the application stepped into a directory or tried to touch the registry or did these things that you'd get the pop-ups.



And so the problem was you could get them all over the place in a single application, rather than just permitting it once.  So what happened was, or what has happened over this span of time, from the time that Vista happened until Windows 7 is threatening to happen, is that put back pressure on application writers to make their applications quieter, and/or to make them run as a standard user.  As we know, traditionally, because this whole notion of running as a non-admin, a non-superuser is relatively new.  Certainly it wasn't new in the UNIX world, but there wasn't any concept of it for a decade of Windows use.



So as security advice began to be don't run as the admin user, people were saying, yeah, but it's a pain in the butt not to run as admin because nothing works.  I mean, all my applications are, like, causing all these problems.  So in addition what's happened is this migration away from running as admin has also put pressure on developers not to assume admin privileges, only require them if it's really necessary.  And typically it's just the installer.  It's just the setup process that needs to put something on the machine, install device drivers, have access to privileged directories or the registry during setup and install.  And after that you don't need that so much.



So one of the changes that's happened is just natural, and that is these sorts of - this evolution in security policy toward being more secure is never painless.  And so we've seen some pain.  Over time that's been getting better because applications are evolving not to assume that they're going to have admin privileges.  Okay, but Microsoft also responded, and they made some major changes, two real major changes to the way UAC works.  One is that prompting for standard admin tasks has been removed.  Things like changing the screen resolution.  I mean, Vista used to require you to say yes, it's really me wanting to change...



LEO:  Yeah, that was silly.



STEVE:  ...my color depth.  Okay, that's just dumb.



LEO:  Yeah.



STEVE:  Exactly.  And so that they removed.  The other thing is that they've better aggregated the way things trip User  Account Control.  So for example when you were installing an add-on in IE, for example, there would be an initial prompt when something tried to sort of look like it was about to do it.  Then you'd say yes.  And then when the add-in then tried to do something itself to install, you'd get another one because you'd get blocked again based on the add-in's behavior.  So what Microsoft did was they said, okay, this is really annoying for people.  Let's create sort of an encapsulation of that, that is, we'll recognize when something is going to install.



One of the other problems was that some of these, many, actually, of these User  Account Control pop-ups didn't give you much information at all.  It said, do you want to install this add-on?  Well, okay.  I'm trusting the site that I'm going to that's telling me I need this add-on to be installed.  But I'd really like to know more about the add-on because I'm not sure how much I trust this site.  Can't you tell me more?



Well, the original architecture didn't have any more information.  The new architecture does.  So that the process that presents you with the permission query reaches into the ActiveX control that you're trying to install, extracts its name, publisher and so forth, and presents that to you; and then permits it to do - given that you have said yes, of course - permits it to do whatever it wants to do.  So you're not getting multiple successive pop-ups after you've said yes, I want to install this.  Essentially you're saying, I want to install it, and you've told me enough that I'm going to trust everything that it does while it installs.  And that's the decision I've made.  Don't keep bugging me about this.  So that's been fixed.



LEO:  Good.



STEVE:  And Microsoft is trusting themselves, that is, their own code which is making changes they trust.  They don't trust foreign code.  And of course that's the activity that you want.  Now, they of course made one famous screw-up, and that is, one of the pop-ups that they decided not to have require User Account Control was User Account Control itself.



LEO:  Right.



STEVE:  Where a couple clever guys figured out that we could use the Send key's technology to essentially pretend to be the user, turning off User Account Control, and the act of turning off User Account Control would not ask you for permission because Microsoft just deadened all of those permission queries, including that one.  So they said, whoops, good point.  It's interesting, too, because their initial reaction was, no, that's by design, go away.  And then they started to actually listen to what people were saying; and they said, oh, yeah, that's a good point, maybe we ought to ask for permission if we're going to be turning off all asking for permission.



So there's now a slider, a four-level slider in Windows 7 where the default setting is level three.  One, two, three, and four.  Level three is not quite as onerous as level four.  Level four is essentially the same as we had in Vista, that is, you're notified when programs install software or make changes or change Windows settings.  You're notified, and you are required to reply.  So that's pretty much the same as what we had in Vista.  Three, level three gives you the notification, but you're not being forced to respond.  It's just sort of a notification, and then it's like, okay, fine, we wanted to let you know that this is going on, but we're going to move on.



Level two is a little bit of a concern, but a little bit less visually jarring.  As we know, every time User Account Control comes up the whole screen behind it goes dark, and it's sort of the only thing illuminated.  Well, this is actually a different desktop.  It's a security-enforcement desktop which prevents any software that's running in the normal environment from being able to see and reach into the User Account Control dialogue.  So this darkening of the desktop is a visual metaphor for something that's actually happening in the architecture.  Normally, and this is a fundamental security problem with Windows, different windows running on the same desktop are able to see each other.  They can enumerate them, they can get all their names, they can send them keystrokes.  And that's how macro programs work.  A macro program is sending keystrokes to another window which is emulating what the user is typing.  Well, you wouldn't want to emulate User Account Control receiving the click of Okay for permission.  So this darkening of the desktop is a security feature that is creating an isolated environment for the User Account Control dialogue to pop up.  But it turns out that some video drivers are very bad about implementing this switchover.  Some of them blank off completely for a while and then click back on, which is...



LEO:  I've seen those.  It's really annoying.



STEVE:  Yeah, it's really annoying.  So what Microsoft again, trying to respond to this, created level two, which is not as secure because it does not invoke the secure desktop.  But it's way less visually disturbing.  So the User Account Control dialogue will come up, leaving, you know, it's on the same dialogue.  So there's the concern about, okay, something bad could click on the buttons.  On the other hand, and this is a point that I'm going to bring up here in a second, by that time it's too late.  That is to say, you've already got something on your computer if it's able to click the button.  So you could argue, okay, well, if we're compromised, we're compromised.



And level one, lastly, does nothing at all.  If you go to level one, it will warn you that you are about to disable User Account Control, and you're going to have to reboot your machine because, you know, we've wired this all in so deep that we can't turn it off on the fly, like making major intrinsic changes to Windows settings.  So that's the way those four settings lay out.  So the point I want to make, and I know, I mean, I've heard you say this, Leo, on other podcasts and on The Tech Guy radio show, that by the time your computer is infected, it's too late.  And it's a funny concept that people have a hard time grasping, but...



LEO:  Well, we've been trained that, you know, antiviruses can remove this stuff for years.



STEVE:  Right, right.  And of course there's still the hope that that can happen.  But we know that with the growth of rootkit technology, I mean, basically malware has gotten much worse in terms of what it does to your system once it gets in.  It's not just, oh, look, it's in the Startup group, let's take it out.  Or it's in my Run key in my registry.  I mean, that's just - none of that stuff is the case anymore.



So the point I wanted to make, though, I wanted to, I mean, you're exactly right when you say that - and I've been sort of trying to figure out how to make a really clear distinction.  The idea is that, if you've got a castle with a moat and a drawbridge that's up and high walls, the idea is that there really is a useful function to keeping things out.  That is, inside the castle walls you can have all kinds of secrets, and you can be doing anything that you want to.  And the moat and the walls keep the bad things out.  And there's a fundamental change when those walls are porous, the moat is filled in, the drawbridge is down, whatever, when something is able to get in.  Now it's on the inside.



Well, I mean, I guess the point I want to make is everything changes at that point.  We're hardening Windows to be better at this.  We're trying to keep things out.  So User Account Control is trying to make users more aware of typically the things that they do.  But it also could just be, you know, drive-by websites.  You go to a website that is trying to, for example, run Java in order to install something on your computer.  Well, if your computer never told you when something was being installed, then you're in trouble.  But if the computer is able to say, wait a minute, something is trying to install itself, do you want to allow this to happen, it's very much like you've got a door through your castle wall, and someone's knocking on it.  And it's like, someone's knocking on the door.  Are you going to open it and allow whatever happens to happen?



But I guess the point is that it seems to be a difficult concept for people to grasp that having the bad stuff outside the castle is just fine as long as you don't let it in.  Once you do let it in, really, the jig is up.  I mean, Windows is trying to be hardened against ever letting it get in.  But once it's in, all software is being run by the operating system on pretty much even basis.  Now I'm about to talk about something that changes that a little bit called AppLocker, which is another really good improvement in Windows.  But again, this notion of before and after and the value of User Account Control is that it helps with notifications.  I really think Windows 7 is an improvement because it's going to be in your face a lot less.  It's been - people that have incorrectly criticized what Windows 7 has done to User Account Control say that Microsoft has neutered it, they've turned it essentially off, or down to a point where it's not nearly as useful.  And that's a complete misunderstanding of the changes that have been made.



Microsoft has - basically this is Rev. 2 of User Account Control.  It's much quieter.  It's much saner in terms of, as we said, lots of little things aren't going to be in your face.  You can go weeks at a time without ever seeing any UAC pop-ups.  When you get them, you're not getting a flurry of them, but you're getting one.  And they're also containing more information.  So, I mean, I think this is...



LEO:  All that's good.



STEVE:  ...really a good - this is really a big improvement.



LEO:  The real problem, as you say, is user fatigue.  Well, first of all, lack of information about what the pop-up means.  And then there's user fatigue, where they just go yeah, yeah, yeah, yeah, yeah.



STEVE:  Yeah, exactly.  If it's coming up all the time, and the thousand times they've given it permission nothing bad happened, then they get trained into, like, oh, this is just, this is what I have to do now with this darn operating system.



LEO:  Right, I just say yes and get it over with.  And of course that's exactly what you don't want to do.



STEVE:  So AppLocker, A-p-p as in application locker, AppLocker, is another refinement to something that we've had for a long time which was called Software Restriction Policies, or SRP.  This is something that unfortunately really upset users and really upset IT.  The IT in the corporate environment, well, they wanted to bring software restriction policies into play because they wanted some control over what employees in a corporate setting were running on their workstations.  The problem was, the software restriction policies were based on sort of a very low or non-granular security certificate, if it existed, and hashing of the EXE.  Well, what that meant was any change of the security certificate because of, well, the security certificate or the executable file as a consequence of, for example, updating, completely broke the hashes.  And the program was no longer recognized as permitted, just because you went from version 1.0.297 to 1.0.298.  And so it was a huge problem for actual deployment and use because it was far too brittle.



So what Microsoft did was, thank goodness, they made it smarter.  They actually call it, the information is called SRPv2, which is stored in the registry as an XML format file off a registry key.  But they're now formally calling it AppLocker to sort of give it a more friendly name.  What it allows IT to do is to create rules that are based on the certificate that comes with the application.  So, for example, you're able to say, I want to trust all applications by this publisher.  Or I want to trust this publisher's application named this for all versions later than that.



And so the beauty of that, given that applications are digitally signed, and we understand how signing processes and certificates work, I mean, they are bulletproof and robust and provable, now using AppLocker you have sort of a much more working the way it should always have system for software restriction policies, allowing the corporate environment to say this is the set of software we want to run, and this is going to be a robust rule set even in the face of software being changed and updated.  So this is - I expect that as a consequence this will end up being much more feasible to use than it ever has been before.  And as a consequence it'll get used.



Now, employees are going to be annoyed because they're not going to be able to install their own software and run them on corporate desktops.  But you could argue that's a huge source of security problems, and in a corporate environment the company has a right to control what runs on their desktop.  Overall, though, this means more security.  And that's a good thing.



LEO:  So it'll be even in the home versions.



STEVE:  Yes.  It is built into the kernel in a new driver.  It's called...



LEO:  That's where it should be, isn't it, yeah.



STEVE:  Yes, appid.sys driver, and it does kernel mode rule checking at process creation and DLL loading.  It also is able to individually manage executables, scripts, installers, and DLLs so that - to provide corporate IT a lot of control.  I don't know that an end-user would use this.  Maybe really security-conscious people would.  It does have an audit-only mode which might be very interesting.  That is to say, you're able to say audit but don't enforce, and then you're able to look at your audit trail to see what has been run.



And I know that sometimes I'm interested to know what's been going on.  I associate a sound in Windows when an application starts, and one when it stops.  Under the  little sound applet in the Control Panel you're able to create sound associations.  Many of the themes that Microsoft has bring a set of WAV files for sound associations.  And I've always had something that I can hear when an app starts and when an app stops.  And so sometimes I'll be working away, and an app, something will run.  And it's like, whoa, wait a minute, that wasn't me, what was that?  I'd like to know.  And so this audit-only mode that AppLocker now adds will allow you to look at essentially an audit trail of everything that's been going on in order to answer questions like that, which I think will be very useful from a security standpoint, as well.



Also, we now have the first client in Windows 7 which understands DNS security certificate records.  We did a podcast a while back on DNSSEC, as it's called.  But it hasn't been natively enforced at the client end.  And with Windows 7 we have that.  So it will be able to validate DNSSEC signatures in the data returned from DNS lookups.



LEO:  Excellent.  So now everybody can go out and implement this.



STEVE:  Yeah.  Well, I mean, it starts to be time to get serious about this because this absolutely, this allows intermediate DNS servers like ISP servers to accept the DNSSEC data and then to cache it and then to make it available to clients.  So it solves the spoofability problem completely.  You're no longer dependent upon just making - you're no longer dependent upon the ISP's server not having been hacked or having it set up in a secure way because the data itself carries its own validation.  And so you're able to, with Windows 7, to say, okay, I want to make sure that this is safe.  And no doubt the browsers will surface that information at the UI so users will see, in a way that today we see when we've got an extended validation certificate, and so the URL bar turns green or something to say this is an extended, an EV certificate, and we've verified it, which is a nice thing to see.  You can imagine at some future point saying we have verified the credentials of the DNS data that we just received so that we know this is the IP that you think you're going to. 



LEO:  Excellent.



STEVE:  Which is again very cool.  And then I got a kick out of one thing that they added in Windows 7.  They call it Direct Connect.  I got a kick out of it because it's a feature that CryptoLink has always been able, or always had planned, and Microsoft has added it to their VPN solution.  The idea is that it makes VPN tunnels essentially automatic so that whenever you connect to, like your laptop if you're out roaming around, it automatically and silently reconnects your VPN back to corporate headquarters so that your corporate assets are just always there.  That's something that I had in my notes a long time ago for CryptoLink because it's an obvious missing piece for just VPN ease of use.  And so Windows 7 adds that.



Now, theirs, of course, is still an IPSec and PPTP VPN.  So you've got all the problems associated with inaccessibility of the VPN in an environment instead of blocking VPNs deliberately.  But given that you've got a VPNable location, Direct Connect will be nice in that it will allow you to sort of maintain a persistent connection back to home base.  And I certainly think that's the future for people who are roaming.



LEO:  Yeah, no kidding.



STEVE:  And the last thing that I wanted to mention was Brian Krebs, who writes one of my favorite security columns for the Washington Post, he noted that in Windows 7, unfortunately file extensions are still hidden.



LEO:  Oh, that makes me so angry.



STEVE:  I know.  It's funny, too, because, I mean, it's one of the first things I have always done in Windows is, when I'm setting up a new version of Windows, is to turn that off because it is so prone to exploitation.  You know, Microsoft says, oh, but the file extension, even if you can't see it, you can tell by the icon because extensions are associated with icons.  So you can tell, like, when a file is a text file because it looks like the little Notepad icon.  The problem is that if you name something malware - well, you wouldn't call it malware, you would call it happyware...



LEO:  Happy, good stuff for you.



STEVE:  ...good stuff for you.txt.exe, and only the .exe is being hidden, then what you see is happy stuff good for you.txt.  Well, EXEs carry icons with them.  And so all that malicious happy good stuff.txt.exe file has to do is put the Notepad icon in itself, and that's what the user sees.  They see the Notepad icon, and they see the .txt confirming that that's what it is.  But in fact it's an EXE with a hidden file extension.  I mean, it's just nuts.  I don't think we're ever going to succeed in getting Microsoft to change that.  But I appreciated that Brian said, well, he was hoping maybe that users would get to see what the actual file type is.  But nope, we're still not going to get that from Microsoft.



LEO:  Why do they do that?



STEVE:  I just think they're worried about confusing people.



LEO:  Yeah, but that doesn't - it's the opposite of confusing.



STEVE:  It is.  I mean, I want to see .doc or .pdf.  And, you know, maybe - I think Brian's right.  In this day and age people know about documents and about PDFs.  They know they have to have a PDF reader, not some magical link between this unextensioned file.



LEO:  Yeah, they've figured it out.



STEVE:  Yeah.



LEO:  And that's how it used to be.  In DOS we had it.



STEVE:  Yup, and we survived that, yeah.



LEO:  Oh, well.  It really does make it hard to solve this.



STEVE:  So overall I'm bullish on what has been done in Windows 7.  I think they've done a lot for UAC.  They've made BitLocker far more feasible and useful and usable.  I mean, basically making it a pleasure to use and deploy.  And they've allowed it to work in a useful fashion on FAT devices to be backward compatible to XP and Vista, and a group policy that will allow corporations to enforce that removable drives are read-only unless they carry encryption with them, so we ought to see much - ultimately.  This will take years to happen.  But you've got to start somewhere.  And these things always take years to happen.  So we'll see five years from now problems with lost thumb drives containing the corporate records or all of the identity information for hundreds of thousands of medical records that'll be - at least it'll be encrypted.  It won't be just sitting there for anybody to pick up and exploit.  So these are really good changes.



LEO:  How about - what is your sense overall of the code?  I mean, a lot of the problems that we have with Windows these days is because the code has exploits in it.  Have they done anything to clean that up?  I mean, it's still Vista, I think.



STEVE:  Well, yes, it's still Vista.  And the problem is they're still human, and security is still hard.  And so that's why, no matter how good this looks, I'm waiting a year.  I mean, I'm in no hurry to, I mean, none of this particularly affects me.  I mean, it's like, okay...



LEO:  Yeah, none of these things, you know better.  You turn on extensions, you don't need AppLocker, you know how to do security with the...



STEVE:  And I'm using TrueCrypt.  I'm using TrueCrypt on my drive, yeah.



LEO:  You don't have - you turn off autorun.  All of these things you've done anyway.



STEVE:  Right.



LEO:  And frankly, anybody who listens to this podcast has done, and most people who are sensitive to security have done.



STEVE:  Yup.



LEO:  So but what we're talking about is making it - I mean, look, if you're sensitive to security, XP's safe.



STEVE:  Yes.



LEO:  What we're talking about is making it safe for the people Microsoft is selling hardest to, which are novice computer users, people I think probably shouldn't be using Windows.  But those are the people that Microsoft needs to make Windows secure for.



STEVE:  Well, and these are the people who have Conficker running on their machines.



LEO:  Precisely.



STEVE:  And this none of our listeners probably do.  So this is for them.  And that's good.  We want them all to be more secure because it makes everything more secure.



LEO:  Right, exactly.  We all suffer from the stuff that happens because novices aren't secure.



STEVE:  Yup.



LEO:  Well, Steve, that's reassuring.  I'm excited.  I believe, having now put Windows 7 on many machines, that it really is a much better way.  It's faster, it's lighter, it's cleaner in the UI.  It seems to be, from the outside, more stable and secure.  I'm hopeful.



STEVE:  You probably know from talking to Paul, and I haven't done the research, what's the status on - because we're not yet at final...



LEO:  This is release candidate, yeah, right.



STEVE:  ...RTM.  And I do think I remember reading something about some changes to RC1.  Where are we relative to upgrading from this beta 7 install, I mean, I heard you say you put it on all those machines.



LEO:  You should be using RC1 now, which is Build 7100.  That's the last officially released one.



STEVE:  But I guess my question is, once they finally release it, is the beta upgradeable?



LEO:  Yeah.



STEVE:  Okay.



LEO:  But you know what we say, what Paul's been saying, and I have to agree with him, is clean install each time.  And so that's kind of one of the drawbacks that people should be aware of if they want to run this beta, is when the final version comes out you're going to want to upgrade.  Now, I have to say, for a beta, even the last beta, very, very, very robust and reliable.



STEVE:  Well, again, because it's mostly just Vista.



LEO:  It's Vista.  It's Vista with the knobs, you know, the rough spots polished off, that's what it is.



STEVE:  Right.



LEO:  A little tweaking here and there.  Yeah, of course it's got - it's going to - what's interesting, I find really interesting - this doesn't really address security - is it's much faster.  So they clearly were able to tune Vista to get better performance out of it.



STEVE:  Well, yes.  And apparently there is a technology also where it's much better about not bringing the kitchen sink of device drivers along with it.



LEO:  Yes, yes.  Which may be why it's more reliable.



STEVE:  Yeah.



LEO:  It also - and faster.  And also at some point I'd love for you to address the virtualization capabilities because I think they've enhanced - they're really moving towards this hypervisor idea.  And I think that's, I mean, they've already announced that if you get Windows 7 Ultimate or Business, whatever it is...



STEVE:  It will include an XP VM.



LEO:  Right, right.  And I think we're moving towards really running in virtualization all the time.  Which would be more secure; right?



STEVE:  Yes.



LEO:  Hypervisor mode.



STEVE:  Yes.  I can easily see the day where applications are actually in their own virtual machines, where everything is just - where there's much more control.  And again, from that vantage point we'll look back at these Wild West days with viruses jumping around and sending keystrokes to other applications and all this and think, wow, how did you guys even survive that?



LEO:  I hope you're right on that one.  I do.  Steve's at GRC.com.  That's his home, the Gibson Research Corporation.  You can go there yourself.  And you'll find wonderful stuff.  SpinRite, of course, the world's finest hard drive maintenance and recovery utility, that's a must-have.  There's a lot of free stuff, too, like Wizmo and ShieldsUP!, Shoot The Messenger, DCOMbobulator, and of course the Security Now! forums, the security forums are there.  If you have a question for Steve, we'll be doing questions next week.  Go to GRC.com/feedback, and you could leave a question or a comment or a suggestion.  16KB versions of the show are there, as well as the full 64KB, full-quality audio and transcripts, too, so you can read along as Steve speaks.  All at GRC.com.



Steve, have a great week.  Enjoy your programming at Starbucks.  I think that's great.  Are you getting close to the end?



STEVE:  Yes.  It's funny, I'm now adding CSV, Comma-Separated Value, export and import.  This is going to be a great little utility.  I think it's going to really - it's going to be significant for us.  And so I've just decided - I'm actually doing a bunch of things more for it than I really need.  But it's technology which will also be part of CryptoLink.  So I figure, well, I might as well put that in, get it developed now.  That'll just make CryptoLink development go that much faster.  So it's got a whole bunch of nice things that we'll be talking about here soon as I get it done.



LEO:  I can't wait.



STEVE:  We're getting close.



LEO:  Thank you, Steve Gibson.  We'll see you all next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#198

DATE:		May 28, 2009

TITLE:		Listener Feedback #67

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-198.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 198 for May 28, 2009:  Listener Feedback #67.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure and private.  And Steve Gibson is here...



STEVE GIBSON:  Except your parts.  We're not covering your private parts.



LEO:  Yes.  He's the general of private.



STEVE:  Just your private data.



LEO:  From GRC.com, Gibson Research Corporation, and creator of SpinRite.  Hi, Steve.  How are you?



STEVE:  Hey, Leo.  We are approaching our double golden anniversary.  We're at 198.  And in two weeks obviously we'll be at 200.  So, and then of course we have a short eight-week jump, and that's our four-year anniversary.



LEO:  That's what blows me away.  It's not the number of shows, it's the four years of continuous production that blows me away.  That's incredible, Steve.  Well done.



STEVE:  Well, we've both been up for it, and we've never missed an episode.  So...



LEO:  Well, that's thanks to you because I've missed episodes on other shows, quite a few.  So that's really cool.  Well done.  Bravo.



STEVE:  And I do, as I'm running through the mailbag from people who go to GRC.com/feedback and enter their questions into the little web form there, so many people really appreciate the fact that they can count on an episode of Security Now! every week.  So I'm...



LEO:  Consistency is really everything in broadcasting.  I think, you know.



STEVE:  Yeah.



LEO:  But easier said than done in many cases.  So I'm really appreciative...



STEVE:  Unfortunately we have a fertile topic, or I guess it's a mixed blessing that we have a fertile topic.  There's always all kinds of things going on...



LEO:  Ain't that the truth.



STEVE:  ...with security, yeah, and lots of technology to talk about, too, so.



LEO:  Well, this week on Security Now! it's Steve's questions - I mean, your questions, Steve's answers, Episode 198.  So in just a bit we're going to get to those questions and answers.  We also have security news, errata and addenda.



STEVE:  And errata, yup.



LEO:  Steverino, let's see, I guess we should start with the news.  Is there anything going on?



STEVE:  We got news.  We got some news.



LEO:  Got some news.



STEVE:  Yeah.  Good news and bad news.  Well, actually kind of all bad news.  Well, no.  There is some good news.  Microsoft just released Service Pack 2 for Vista.  So the good news there is that everyone who's setting up a new Vista system until now has needed to first install Service Pack 1, and then do the Windows Update and stand back, maybe go on a short vacation while all the individual updates from Service Pack 1, which was March of '08 was when SP1 came out.  So more than a year of security fixes and changes and patches and glitches and so forth.  Now, if you just - you do need SP1 installed as a prerequisite for SP2.  So it's no longer the case, remember that it used to be that you could just get the most recent service pack.  In this case Service Pack 2 only contains all the fixes since SP1, rolled up into a single deliverable.  So if you are now setting up a new Vista machine, you need SP1 and SP2, and you have to install SP1 before SP2.  But just those two actions brings you current as of today, as opposed to needing to go through all the incrementals.  So that's good news.



And for what it's worth, anybody using Server 2008, this is a hybrid service pack which is also Service Pack 2 for Server 2008.  Server 2008 came with SP1 built in, so there's no need for an SP1 for it, followed by SP2.  Just Server 2008 followed by this hybrid service pack, SP2 for Vista and 2008, and that brings you current there.



The other sort of news, it actually was Greg my tech support guy who first noticed this, and that is that many people, as we have discussed, have had a problem with Windows XP Service Pack 3.  I'm still not running it on my main system.



LEO:  Really.



STEVE:  Because it hurt me when I...



LEO:  It's been a year.



STEVE:  I know.  And that's the point, is the blocker tool expired on May 19.  And you'll remember that Microsoft provides the Service Pack Blocker Tool which will, for a period of a year, allow you to keep their Windows Update from trying to install a service pack on your system.  And you can, however, tell it do not offer this to me again.  And I - so what happened was, after the blocker tool expired on my own main system, it's like, wait a minute, now I see what Greg's talking about.  It's for the first time since a year ago it's saying, hey, go for Service Pack 3.  And it's like, no, I'm still reluctant to do that.  I mean, they haven't changed Service Pack 3.  And it messed up things.  So I'm finding I'm cautiously putting it on additional systems that I have, and I'm not seeing problems.  But on systems where I know that it seems to be unhappy I've not moved forward.  So I guess I ought to make an image of this system and try it again.  It'd be nice not to fall too far behind.



LEO:  As I remember, the issue with Service Pack 3 was driver incompatibilities that they - well, maybe that's Vista Service Pack 1 that they were patching so that you could have - you might have - in other words, you might have had a fix in the interim.  Did you do no patches after SP3, or no?



STEVE:  Oh, no, no.  I'm keeping - see, that's the nice thing, is Microsoft allows you not to install SP3, to opt out of that, yet will give you all the other incremental things continuing forward.  So I'm frankly a little cloudy on how this all fits together.  That is, it seemed like when you were installing SP3, all you were doing was catching up to all the incremental things between SP2 and SP3, which I was doing all along.



LEO:  Right, right.



STEVE:  I was staying current.  So it's like, okay, why do I need Service Pack 3 if I've been doing the incrementals all along?  It's certainly the case that on setting up a new system, just like we were discussing with Vista, where you would - it's so much nicer to just be able to do SP1 for Vista and SP2 for Vista and then be current.  So I certainly think that installing a brand new system - and I have, by the way, for example, when I was setting up my little tablet, this new tablet that I'm using at Starbucks.  I'm an MSDN user, the Developer Network, so I have access to these builds of Windows as part of the $2,500 I pay every year to Microsoft for the privilege.  So I installed brand new from scratch XP, and then I think I put in Service Pack 2 and then Service Pack 3, because I think even with XP you need Service Pack 2 at least before you can install XP's Service Pack 3.  So I did that, and I have no problems.  And I manually put in all the drivers myself because this thing came with Vista.  And it's like, okay, well, I'm not ready to do that yet.  So I'm really happy with XP SP3 on that machine.



LEO:  Good, good.



STEVE:  So it makes sense when you're setting up a new system to do that.  But for whatever reason, even though this main machine I'm sitting in front of now while I do the podcast with you, it's a relatively recent install and setup of XP.  Still it didn't - it got a little funky when I put in Service Pack 3.



LEO:  Really, wow.



STEVE:  So I was able to back out of it, yeah.  And actually Greg, again, my tech support guy has had several systems where, I mean, this is the reason he was really concerned.  He said, hey, what do I do now?  He said, I mean, there are systems I absolutely know collapse with Service Pack 3 on them.  So, yuck.



LEO:  So you're going to have to get it, though.  No way around it now.



STEVE:  Yeah.  Now, Macintosh security.



LEO:  Uh-oh.



STEVE:  I don't know if you've seen this.  But there is a bad known vulnerability in Java which virtually the whole industry has fixed except Apple.



LEO:  Really.



STEVE:  Windows has fixed it.  All the Linux and various UNIX builds have fixed it.  Apple has not.  It's been known since December of '08, long since been patched.  One of the security researchers, sort of a gray hat guy, decided, you know, this is dumb that Apple has still not fixed this.



LEO:  Oh, so he released...



STEVE:  Yes.



LEO:  ...an exploit.



STEVE:  So he released a proof-of-concept...



LEO:  Oh, boy.



STEVE:  ...which has been decompiled, and the source is now available.



LEO:  Oh, I wish they wouldn't do this.



STEVE:  It is being exploited in the wild.  The security community is telling people, Mac OS X people, that they should disable the Java virtual machine support in Safari.  The same exploit is functional under Firefox.  And if you go to a malicious web page, that is, that runs a Java applet, it can take over your machine.  Proof-of-concept code exists.  It is truly being exploited in the wild.  So, I mean, I guess certainly Apple will now fix it.  I mean, there's no way that...



LEO:  Does Apple use Sun's Java, or do they have their own Java?  I though they used Sun's Java.



STEVE:  No, Sun's, yes, and it was Sun who warned in December of '08 about the flaw, made the fix available.



LEO:  I wonder why Apple hasn't pushed it, since it's available from Sun?



STEVE:  It's a good question.  I don't know if they missed it, or if they have got some reason.  I haven't been able to track that down.  But I do know that certainly now the pressure is turned up.



LEO:  Yeah, no kidding.  It's odd that they didn't fix it in the big, you know, that 500...



STEVE:  Oh, the mega patch.



LEO:  ...megabit patch.



STEVE:  The 13,000 files.



LEO:  And that just came out a week or two ago.  I don't understand why they didn't...



STEVE:  Yeah.  And in fact that's what this guy was waiting for.  It's like, okay, let's see if that does it.  And they didn't.  So I think we can - I imagine we'll see something shortly that Apple will say, okay, I guess for whatever reason we need to do this.



LEO:  Yeah.



STEVE:  So, and there's a lot of dialogue in the community saying, well, Apple is arguably becoming a larger target as they're succeeding more, as they're moving more into the mainstream.  I mean, it's no longer the case that it's such a small segment that people are ignoring it.



LEO:  Apparently Apple does their own Java.  They're using their own code.  So that's why they're behind.



STEVE:  So they're not using - oh.



LEO:  They're not using Sun's code, yeah.  Otherwise they would have just shipped Sun's code and had done with it, I imagine.



STEVE:  Okay.  Well, and then it's odd, if it's really their own code, that they've got the same problem that...



LEO:  Well, it's probably a reference, there's a reference implementation that they modified.



STEVE:  That they followed.



LEO:  Yeah, they followed, yeah.



STEVE:  Okay.



LEO:  A bad reference.



STEVE:  Last little bit of security news is that Adobe, under the increasing pressure to get their act together with all the problems they've had in PDF format interpretation in Reader and in Acrobat, has announced what I think is sort of a mixed blessing.  They said, okay, we're going to do regularly quarterly updates, synchronized with Microsoft's second Tuesday of the month update.



LEO:  Hmm.



STEVE:  But they're not doing it monthly.  So they're only going to do every third one.



LEO:  Quarterly.



STEVE:  And it's like, well, okay.  I'm not sure that that's often enough.



LEO:  Right.



STEVE:  Does that mean that they're not going to do one mid-quarter?  I mean, Microsoft does them mid-month when something comes up that's bad enough.



LEO:  People are so reluctant to admit there's something wrong with their code and patch it.



STEVE:  Yeah.



LEO:  Or maybe it's just the issue of testing it and the concern that companies have about implementing this stuff and...



STEVE:  Well, but Adobe's no small group.



LEO:  Gosh, yeah.



STEVE:  And you've got to think, okay, Microsoft is managing this for this whole nightmare called Windows.



LEO:  Right.



STEVE:  I mean, all of Windows.  And here Adobe's got a reader.  Basically they've got a PDF...



LEO:  Yeah, what's the tough...



STEVE:  They've got a PDF interpreter.  So anyway, they've made a lot of noise recently saying, okay, we're going to really get serious.  They've come up with their own acronym for, like, their security development life cycle, which is, you know, SDL is Microsoft's, but the equivalent for them.  And we're going to be looking at old code that we've had in Reader to make sure.  It's like, yeah, okay, good.  Get going, folks, because PDF format, I mean, it has become the standard document transfer format for the 'Net.  I mean, they won that.  Microsoft has tried a few of their own that never - that just sort of sputtered and never happened because, again, Microsoft would like to own that, too.  But Adobe owns that.  And so it's like, okay, time to make this thing work solidly.



LEO:  It's just odd.  It's just very odd.



STEVE:  And get serious about security.  I just think that quarterly doesn't sound to me, it's like, well, okay, we're going to do it, but we're only going to do it every three months.



LEO:  But up to now they've been doing it as necessary, as needed; right?



STEVE:  As needed.  Well, and what they've been doing is they've been doing the most recent version first, and then catching up backwards, then, like releasing, like sort of, for example, like the patch for 9 came out first, and then 8 and 7 came out a few weeks later.  I mean, like, and almost deliberately like a week later, almost like they're saying, well, you're going to be vulnerable.  We're going to leave you vulnerable for an extra week if you're not using 9.



LEO:  Yeah.  It's like, well, that's a bad - that's a really bad, bad thing to do.



STEVE:  It really is.  That's a fundamentally flawed policy.



LEO:  Well, it's driven by commercial concerns.  I mean, that's not a nice thing to do.



STEVE:  Right, right.  Well, it had to be done deliberately, too, because they announced a month beforehand that the 9 patch would be available on this date, and the 7 and 8 patches would be available one week later.



LEO:  Oh, they knew.



STEVE:  So they planned to do this.



LEO:  Just upgrade, you'll be patched.



STEVE:  Yeah, huh?  Yeah, we'll patch a week - it'll be patched a week sooner.



LEO:  Yeah, that's not nice.



STEVE:  Okay.  So now, I mean, watch.  I'm predicting here that this quarterly update will not stand.  It's - there's just - this is wrong.  And so we're going to see a flaw come out that's really bad, and they will do a mid-quarter...



LEO:  Well, even Microsoft does that, though; right?  Out-of-cycle patches?



STEVE:  But they're saying they're not going to.



LEO:  They say they will never do that?



STEVE:  No, they're saying we're going to make them - we're going to update more often, and it's going to be quarterly.



LEO:  And it's sufficient.



STEVE:  And it's going to be synchronized with Microsoft's second Tuesday.



LEO:  That I don't understand.  Is that so, like - I don't understand why you would synchronize it.



STEVE:  I don't know.  I don't get anything about this.  This is just, you know, what you ought to do is, especially for something like Reader, it's like, okay, it's not like the whole OS.  It's a reader.  And there's alternative readers.  So, like, look.  If there's a problem, fix it fast and give us an update.  And we'd rather have three in a row, on successive days, if that's what it takes to keep our PDF reader secure.  And we're certainly not going to wait around for months while a known problem is out there.  That's just dumb.  So anyway, that's Adobe's big news and announcement.  So it doesn't make any sense to me.  We'll see.  We will be watching this closely, and we'll let our listeners know what happens.



LEO:  Do you remember, I mean, this latest double flaw, but have there been a lot of flaws before that?  I mean...



STEVE:  Oh, yeah, Adobe's been having lots of problems.  I mean, like almost every month or two.  It's like, oh, here's a PDF problem again.



LEO:  Oh.  Well, they need to patch it more often then, clearly.



STEVE:  Yeah, they do.  In reading through my mailbag, a number of readers took exception to our sort of dismissive glibness, I guess I would phrase it that way, about Ada, the language.



LEO:  Ada, oh, Ada, yeah, yeah, yeah, the programming language.  Did it ever get implemented right?  I mean, that was our - it did.



STEVE:  Yes.  Yes, yes, yes.  I've now been pounded on.  They've enumerated all the compilers.  There's open source compilers, closed source compilers, there's sideways compilers, there's PDA compilers.  It is everywhere.



LEO:  Ada is everywhere.



STEVE:  So I just want everyone to know, yes, my information was dated.  Oh, and people are using it.



LEO:  That's the question, is it being used in the...



STEVE:  There are colleges...



LEO:  Well, okay, but is the DoD, which invented it, using it?



STEVE:  I don't know.



LEO:  Yeah.



STEVE:  But colleges are training with it because it's such a great language.  And I just, okay, fine.  I give up.  Yes, it's everywhere.



LEO:  It's a wonderful language.



STEVE:  We love it.  We love it.  I meant to tell you, or to mention last week, and I forgot, Leo, so it's in my errata list here, I also loved, but this time really seriously, "Star Trek."



LEO:  Yes.  Oh, we didn't talk about it.  Yeah, you were about to see it two weeks ago, and I didn't want to spoil it for you.



STEVE:  I literally, I hung up the phone, and I went, and actually I've seen it twice now.  I thought it was spectacular.  Everything I could ask for.  I mean, even in my own sci-fi newsgroup, we have a sci-fi group at GRC, there are...



LEO:  Oh, you do?  I didn't know that.  That's cool.



STEVE:  Oh, yeah.  We just - gives us sort of a place to talk about it because, I mean, so many - there's such a cross-interest in, you know...



LEO:  Right, sure.



STEVE:  ...technology and science and sci-fi.



LEO:  Is that GRC.com/forums?



STEVE:  No, I don't have a web-based viewer.  We have a traditional old NNTP, Network News Transfer Protocol, NNTP news server.  So anybody who has got, for example, has Outlook or Thunderbird, you just need a real news reader.  And so it's news.grc.com is the server.  And when you subscribe to that there's a whole bunch of newsgroups.  One is GRC.scifi, s-c-i-f-i.



LEO:  Okay.



STEVE:  But anyway, so the point I was going to make was that there were a bunch of sort of purists who were saying, well, this wasn't at all like TOS, which of course is the acronym for The Original Series.  And it's like, well, right.  Okay.  So maybe they thought they were going to get what - sort of what we heard.  We heard for years that this was going to be where Kirk and Spock first meet and go forward.  And so they were really wanting a formal, correct prequel to the original Star Trek series.



LEO:  This was a reset, was what this was.  This was more than a prequel.



STEVE:  This was.



LEO:  This is starting over.



STEVE:  Yes.  And I will not say too much because I don't want to be a spoiler.  I avoid spoilers because I want to see normally these things for myself.  So I can't explain what it was that happened that really releases this new - this movie and anything subsequent from needing to follow the same timeline that we all know so well who've been following Star Trek for all these years.  So anyway, I just wanted to say I saw it.  I saw also "Terminator Salvation" yesterday.  And I really liked it, too.



LEO:  Really, because it got crappy reviews.



STEVE:  I know.  Something was missing.  I can't quite put my finger on it.  I mean, the James Cameron Terminator movies, the first two were just spectacular because, you know, that's what James Cameron...



LEO:  Well, they had Arnold.  Arnold is the key.  You are not Arnold, you are not the Terminator.



STEVE:  And this one was good.  I mean, it was not fantastic.  But again, I'm like a thirsty man in the desert when it comes to sci-fi.



LEO:  Exactly, you'll take anything, yeah, yeah.



STEVE:  So I'll take anything.



LEO:  You'll take anything.



STEVE:  And this was fine.  I thought this was better than No. 3.  No. 3 was sort of, ugh, you know, really forgettable.  But...



LEO:  I think I've only seen 1 and 2, to be honest.



STEVE:  Yeah.  And I watched all of the "Sarah Connor Chronicles" on...



LEO:  I have no desire to see this new one.



STEVE:  ...Fox.  And so I'm pretty much well steeped in Terminatorness.  Maybe that was part of the problem, is that maybe it's a little overexposure of all things Terminator at this point.  But I did want to mention that I saw it, and I liked it.  But "Star Trek" was spectacular.  I mean, I was literally, I was trembling and out of breath when...



LEO:  Oh.  Oh, Steve.



STEVE:  ..."Star Trek" ended the first time.  I was.  I'm a sucker for...



LEO:  It was so good.



STEVE:  No, it was great.



LEO:  It was so good.  That's cute.  That's really cute.



STEVE:  Well, I have, you know, Leo, I'm - I have to tell you, I think I've mentioned to you before that my buddies and I in high school made a Star Trek movie?



LEO:  Oh, yeah, that's right.



STEVE:  It was on 8mm back in super...



LEO:  Yeah, no, you come by it honestly, yeah.



STEVE:  And we did beaming out by standing under a chandelier in the dining room of one of our friends.



LEO:  And that was before the movies.  That was after just one, the one series.



STEVE:  Just the original series.



LEO:  So you really get a lot of credit because that original series, as I think most people know by now, was kind of a flop and canceled early on.  They didn't do a whole lot of episodes, and...



STEVE:  Well, I had dinner with Gene Roddenberry.



LEO:  You did.



STEVE:  At COMDEX one year.  And this was after, I mean, this was obviously years later.  And it was funny because I met Stew Alsop down at the bar in the Las Vegas Hilton, and we chatted about the idea of me doing a column in InfoWorld.  And which of course did happen.  I did that for eight years.  But Stew said, "Hey, what are you doing for dinner?"  I said, "I don't have any plans tonight."  And he says, "Well, why don't you come with me?  I'm going to meet some guys, and we're going to go have some food."  I said, "I'd be glad to."



LEO:  Oh, man.



STEVE:  So I had no idea what the group was.  But we go upstairs, I believe at the Las Vegas Hilton, and there's just, like, three regular random people sitting, kind of lounging in the hotel room, I guess waiting for Stew to show up.  And I was tagging along.  And so these people introduced themselves, round robin, and one of these guys says, "I'm Gene Roddenberry."



LEO:  Geez, Louise.



STEVE:  Now, okay, now I have to explain, Leo, that we stood under the chandelier with the camera, the Super 8 film camera mounted on a tripod, running the - and everyone stood still.  Then we stopped the camera, and everyone got out of the way, and then we started the camera again and filmed some time with nobody there.



LEO:  Yeah.  Smart, very smart.



STEVE:  Then after the film had been developed, we went back in, and on the emulsion side found the spot where...



LEO:  Oh, my god.



STEVE:  ...everyone in a single frame disappeared, and then we began scratching...



LEO:  You scratched it.  Oh, my goodness.



STEVE:  Yes.  We scratched the emulsion.



LEO:  I'm so impressed.



STEVE:  On both sides, diminishing in each direction, so that when you played the film back, you saw everyone get under the chandelier, and then the appropriate sound effects, and then suddenly all of the centers of them began scratching until they were completed scratched out.  And then it dissolved again, and they were gone.  So it looked like they transported.



LEO:  That's fantastic.



STEVE:  And we needed a...



LEO:  Did you go [transporter sound]?



STEVE:  Oh, we had sound effects.  In fact, we even had alien-sounding bad guys.  Scott Wilson was - actually this was where most of this filming took place.  And he was arguably the most over-the-top Trekkie in our group.  His sister had a large collection of stuffed bunny rabbits.



LEO:  Oh, you had Tribbles.



STEVE:  Well, no, no.  These were the aliens.  They were evil.  They were the Bunnons.



LEO:  The Bunnons [laughing].



STEVE:  The Bunnons.  And so...



LEO:  Oh, Steve.



STEVE:  Oh, it was bad.  So...



LEO:  How old were you?  This was, like, 14 or 15?



STEVE:  Yeah, exactly.



LEO:  Oh, that's so cute.



STEVE:  And so we used stop-frame animation to have the attack of the Bunnons.  But when they of course had to hail the ship and be threatening, we needed them to sound alien.



LEO:  Right.



STEVE:  So what we wanted them to say was, "We are the Bunnons.  Surrender your ship or be destroyed."



LEO:  I think we talked about this last week, and you did it backwards.



STEVE:  Well, yes.  I came up with the idea, since this was actually that brown, actual magnetic recording tape that we no longer have...



LEO:  Right, Mylar, yeah.



STEVE:  And this was reel-to-reel deck.  So we recorded, "We are the Bunnons.  Surrender your ship or be destroyed."  And then we reversed the tape mechanically so that it would play backwards.  And we listened carefully to the way it sounded and learned how to say it backwards, which happens to be yo-sha ba-di-dro, sna-na ba-na-ni, pa-shor-yor-nar-ros.



LEO:  Of course it is.



STEVE:  Now, if you say it carefully, because things sound a certain way backwards, it's actually more like yo-sha ba-di-dro, sna-na-ba-na-ni, pa-shor-yor-nar-ros.



LEO:  Hey, if you're listening to this, Tony, could you just take that and reverse it, and let's hear what that sounds like.



STEVE:  So...



LEO:  Now, I have no idea what that sounded like, but I think it was probably pretty good.



STEVE:  Well, we recorded that, and then we reversed that.  So that re-reversed the reversal.



LEO:  Right.



STEVE:  And it really, it was - it came out "We are the Bunnons.  Surrender your ship or be beshroyed."  And we never quite got...



LEO:  [Laughing] I can't do this in real-time, but I think Tony is going to do this on the show, and you're going to hear this.



STEVE:  Well, I have to tell you that because, I mean, I never obviously forgot this, nor what those phrases were.  Remember when I was messing around with the SIP compressor?



LEO:  Yes.



STEVE:  And I wrote a little app that would just - you could record something and then play it back.



LEO:  Right.



STEVE:  Just for the hell of it, I had a different shift key you could hold down, and it would play the buffer backwards.  And I practiced that again, and it was just the way I remembered it.



LEO:  So we can be pretty sure that that's actually going to sound like that when we...



STEVE:  It'll be something like that, yeah.  But anyway, so yes.  Serious, over-the-top Trekkies.  And I've been such ever since.



LEO:  Oh, that's great.



STEVE:  And I'm one of the...



LEO:  You've earned your stripes.



STEVE:  ...people who think that the Next Generation was the ultimate series.  That's the whole Jean-Luc group.  I just think that...



LEO:  I agree.  I kind of agree.  I think that was a really great group of people.



STEVE:  Well, and it was - this recent "Star Trek" movie was action.  It was fun and action, and it was that sort of thing.  The Next Generation was a far more cerebral show, which is why I liked it.



LEO:  Yeah, I liked - yeah, me, too.  I liked the strategy and the solving the problems and that kind of stuff.



STEVE:  And, you know, they'd meet in their little conference room and go around and give their opinions, and then Jean-Luc would declare what action they were going to take.  And I just - anyway, so I sat next to Roddenberry at dinner.  And I didn't want to be like the oh, you know, the annoying groupie.  But I did find an opportunity to ask him what happened.  And he said that what happened was they had a three-year run.  There were three seasons of the original series.  And...



LEO:  Something like 77 episodes.  I can't remember the exact number.



STEVE:  And after that it was canceled.  And the way Gene explained it to me was that several years later they were developing the technology, the first developing technology for the TV demographic profiling, what's it called, where you're...



LEO:  The Nielsen ratings?



STEVE:  The Nielsen ratings, yes.  They were developing the original Nielsen technology, which factored demographics in for the first time.  And that was the difference.  Star Trek was canceled after the third season because the raw numbers didn't justify its continued production compared to other shows.  But when years later the raw data was reprocessed using demographic technology, it turned out that it had the most perfect demographic profile for advertisers of any show that had ever been created.  It was the yuppies, the young...



LEO:  Until TechTV.



STEVE:  Yes.  Young, upwardly mobile, married newlyweds who were buying strollers and cars and homes and, I mean...



LEO:  Smart people.



STEVE:  It's exactly who advertisers wanted.  There just has never been a better show.  But they didn't know it at the time.  And so they said, well, look at the numbers.  I mean, look at the count.



LEO:  TechTV was like that.  We had the most highly educated and affluent audience on cable television except for the Golf Channel.  But inevitably, advertisers are slow to respond to that.  It's one of the reasons that TWiT succeeds is because the demographics...



STEVE:  I was just going to say, not our advertisers.



LEO:  No, they get it, they get it.



STEVE:  Yup, exactly.



LEO:  So, let's see.  We've got some letters.  You've got a letter, a SpinRite letter?



STEVE:  I just got a nice note from, not a listener, I think, this time, because he wrote to our support email, and his name is Bob Blaine.  And he said, "Hi, I just wanted to thank you for your SpinRite software.  I was a little surprised at the price and wasn't sure if the problem I was having was going to be fixed by it.  But based on reviews and your money-back guarantee, I thought I'd take a chance.  Your software was easy to use and actually fixed the problem I was having.  I'm very impressed!"  Exclamation point.  He said, "The problem was that I had a hard drive failure on an XP machine that was not allowing the machine to come up into Windows.  It was giving some obscure message that I eventually found out meant that the registry file was corrupt.  Amazingly, SpinRite fixed that so that I was able to get into Windows and back up all of the data on the drive before I replaced it.  Thanks again, Bob Blaine."  So yes, SpinRite to the rescue.  Not a surprise for our listeners, I'm sure, but...



LEO:  I think it's worth emphasizing that money-back guarantee because I think people do, you know, a new hard drive is about the same price as SpinRite in some cases.



STEVE:  Yeah, in fact I was listening to your replay of a podcast...



LEO:  Must have been The Tech Guy or...



STEVE:  No, it was the one that was just playing with Andy Ihnatko...



LEO:  MacBreak Weekly, yeah.



STEVE:  MacBreak Weekly, just as we were getting ready to do this.  And he made a comment about - you were talking about ripping DVDs.  And he said, yeah, you know, you can get a terabyte drive now for 90 bucks.



LEO:  Exactly.



STEVE:  And I'm thinking, yeah, and that's what SpinRite costs.  And he said so, you know, there's really no need to burn all those.  Just rip them all onto that terabyte drive.  And I'm thinking, yes, please do.  Because, please.



LEO:  Why is that, Steve?



STEVE:  Good.  Put your whole movie collection on there because I will have your money.  When that $89 terabyte drive craps out on you...



LEO:  We're buying - are you saying people should buy fancier drives, or just this is inevitable?



STEVE:  Put all the crown jewels, put everything you have on hard disk.



LEO:  Well, don't throw away the DVDs.  Keep them.  But it really is true that, if there's data on there, it's worth more than 89 bucks.  It's not a question of buying another drive, it's a question of getting that data back.



STEVE:  Yes.  I mean, people, for a while people were saying, well, gee, Steve, $89, that's pretty steep.  And I'd say, yes, I understand.  And then they'd say, well, we can buy a new drive for that.  Yes, but it doesn't - it's not all of the data that you've got.  It's not everything that's been installed in your system before.  It's not, I mean, what's your time worth to, like, recreate everything from scratch?  And in some cases these are irreplaceable.  These are people's entire photo libraries that have never been backed up, never put somewhere else.



LEO:  Well, and the other issue is that you're not just talking about recovery, you're also talking about maintenance.  And you probably have a lot of drives.  Nowadays we, I mean, I have dozens of hard drives.  I buy - I literally buy terabyte drives by the six-pack now, probably about once a month.  And so SpinRite's really great on checking those drives before I put them in use and making sure they're in great shape and maintaining them.



STEVE:  Yes.  I do read people who say, hey, I bought SpinRite, I run it, I'm waiting for a miracle.  But maybe the fact that I'm running it on my drives every few months means that I'm never going to have a disaster that requires a miracle.  And of course that's the optimal situation.



LEO:  Right, I'm with you.



STEVE:  You want to keep the drive from getting that bad.  But yes, we do sell it with a money-back guarantee.  The problem is I can't give a demo because, once you run the demo...



LEO:  You're done.



STEVE:  ...and it fixes problems, you're done.



LEO:  Yeah, you're done.



STEVE:  It's like, uh, okay.



LEO:  People often say I want to download a trial.



STEVE:  Yeah.



LEO:  And you don't want to do the thing, and this really bugs me, the unerase programs, there are some out there, will say, oh, yeah, I can see all your data.  500 bucks, please.  And that's even worse.  That's like, c'mon.



STEVE:  The tease, yeah.



LEO:  That's that tease, yeah.  So, no, it's worth it.  Money-back guarantee if it - and I think that's the best way to do it.  That's basically, you're basically saying try it for free.  If it doesn't work for you, I'll refund your money.



STEVE:  Absolutely.  Absolutely.  And, I mean, there may be people who've bought it and then asked for their money back anyway.  It's like, well, if that's how you want to play the game, that's fine, too.  I'm not going to, you know...



LEO:  I bet that doesn't happen very often.



STEVE:  Not among our audience.  Our audience is great.  And they help make the podcast possible and make GRC possible.



LEO:  That's right.  We want to support Steve, that's for sure.  I have in my hands 12 questions from 12 listeners good and true.  All for you, Mr. Gibson, starting with No. 1, Alexandre in Quebec.  He's a Quebecois.  He says:  You made me love you.  Actually made me love Assembly language, he says.  Assembly language.  Hi, Steve.  I'm a young 18-year-old guy from Quebec, and I just love your show, pretty much everything you made for the beautiful yet now somewhat dirty computing world.  I'm also a SpinRite customer - yay - and I love it.  Sorry if the English isn't very good.  I'm a French guy.  So I'm very - your English is better than mine.  Don't worry, Alexandre.  So I'm very interested in Assembly language programming for Windows.  That is just awesome.  I just love hearing that.  And I would love to know what Assembler you use or would recommend to me.  I would like to use the same one.  Anyway, I know NASM, but I have become interested in FASM.  I don't know much, but it looks very good.  Have you tried it?  And what do you use?



STEVE:  Okay.  Again, I try to choose questions that are representative of many that we receive.  And there's been an interesting surge of interest, I guess because I've been talking about it, among our listeners about Assembly language and Windows.  And there have been some postings, I know, in the GRC newsgroups.  And I run across questions like this many times in reading through listener email.  My recommendation is to go check out MASM32.com, the website, www.masm32.com.  It is a tremendous site.  And I have always been programming Windows in Assembly language, and I was sort of on my own when I began, I don't know, 15 years ago or something.  MASM32.com is a site that has a tremendous tool that's at v10 now, a complete IDE, an Integrated Development Environment, all the libraries and include files, lots of sample code, the source for everything.  It is dedicated to programming Windows in Assembly language.  There's also a forum that is available there with a whole bunch of enthusiasts that are all doing exactly this.  There are all aspects of programming Windows in Assembly language.  So there really is a complete, I don't want to call it really a subculture...



LEO:  And this is free.



STEVE:  Yes, it's all free.



LEO:  Wow.



STEVE:  Now, MASM is Microsoft's Assembler.  That's what I use.  That's what I've always used.  I really like it because they've extended it, the syntax of it, just a little bit in order to make it more pleasant to use.  For example, you can say .if eax = ecx, and then have a bunch of code, and then a .end if.  And so you have a traditional if/end if enclosure...



LEO:  Oh, that's neat.  And that's done with macros?



STEVE:  Well, no.  It's native to the language.



LEO:  The Assembler knows this.  Oh, that's neat.



STEVE:  Yes.  It's built into the Assembler.



LEO:  You're starting to get a little higher level now here.



STEVE:  And you can have an else, for example.  So if something else.  And then but the reason I love it is that it exactly assembles into the same code I would write.



LEO:  So it's still very clean.  There's not a lot of cruft introduced as there would be in a compiler.



STEVE:  Well, there's zero, zero overhead.



LEO:  Yeah.



STEVE:  Yeah.  So I would have to write cmp eax, ecx; and then jne, which is to jump not equal, then to something down below.  And I'd have to invent some label for it to jump to, which clutters things up.  Visually it's easier to see if there's, like, an if/end if, and then you indent the code that is inside.  So there's that.  They even have looping constructs, repeat until or while.  I mean, so you've got those nice flow control things that are the standard structures from higher level languages that exactly assemble into the same thing you would write for yourself.  And they have a really nice construction called "invoke," which is used for calling subroutines, including the Windows API.  So I can say, for example, invoke space create file, followed by a list of arguments.  And the way Windows works is when you call into the Windows API, it expects those arguments to be on the stack in reverse order.



LEO:  Right.  So it actually puts them on the stack and everything.



STEVE:  Yes.



LEO:  Oh, that's nice.



STEVE:  It'll convert the lengths to something else.  You're able to say address of a - if Windows wants a pointer to something, you could say addr and then the value.  So my point is that, without any overhead, you're still programming in Assembly language at bare metal; yet it's a really pleasant environment.  And this MASM32.com website has the core - it's at v10 that you can download, that installs basically a complete working development environment on your system, and help files, all the libraries, include files.  Basically it's a turnkey, get you up and going.  And so I recommend it without reservation.



LEO:  When I did Assembly programming, and I used to do it on a 68000, which was a much cleaner, easier processor, I think, than the X86.



STEVE:  Yeah, very nice instruction set.



LEO:  Much nicer.



STEVE:  Very orthogonal, meaning it could do most things in most instructions.



LEO:  And no memory segmentation or any of that stuff. 



STEVE:  Right.



LEO:  But I used macros a lot to make it look more English like.  Do you use - in fact, I noticed a lot of Assembly language programmers would build large macro libraries to kind of simplify things.



STEVE:  Yeah, I do that, too.  For example, I have a macro called "zero," z-e-r-o.  And so I'll say zero eax.  And all that's doing is...



LEO:  Just a move.



STEVE:  It's an XOR.



LEO:  Or an XOR, oh, you're clever.



STEVE:  Yeah.  You could use a move, you know, move eax zero.



LEO:  Is XOR more efficient?



STEVE:  Yes.  XOR is smaller.  It does modify the flags, that is, the condition code.  But sometimes you want that.  But the point is, if I wrote XOR eax eax, I know that that's going to zero it because if you XOR something with itself, the ones cancel out; the zeroes were never on.  And so it ends up being zero.  But as I'm reading the code, if I say z-e-r-o, then I immediately know what I'm doing there.



LEO:  Right.



STEVE:  And I've got a bunch of things.  I have one, a favorite of mine, it's called roundiv, r-o-u-n-d-i-v, which is a fancy little bit of code with no - that doesn't involve any other registers.  But it does a division, and then it compares the remainder to the dividend and sees if it's greater or less than half of that, in which case it adds one to the result, so it does a rounding division.  And so it's just, it's very convenient.  So, yeah, I've built up a macro library over time of all kinds of little tricks like that, that I use in my code.



And the other thing that I think really puts people off of Assembler is very often you'll see somebody's code which is just atrocious.  It's running down the left-hand edge of the page, and it's just the stream of acronyms and weird arguments.  And you look at it, and you think, what the hell is that?  Just no way can I read that.  But my code, I mean, I take some pride in the way it looks because I know eventually I'm probably going to have to come back and read it.  And so I'm expressing this to myself and to the computer at the same time, as good coders do, and the result is something which is really pleasant.  It's not cryptic and horrible.



LEO:  I'm going to be - I've kind of volunteered to teach, to do a little programming tutorial for my kid's high school because they don't do anything like that right now.



STEVE:  Wow.



LEO:  And I'm not an adept programmer, but I think I'm good enough to get them started.  But I just - I was going to, you know, use Python.  But I just had a thought, it might be a great idea to spend some weeks learning basic Assembler because what a great way to learn how the computer works.



STEVE:  Yeah.



LEO:  You're working bare to the metal.  And so it gives you an understanding of what registers are, moves, loads, conditionals, bits, all of these things are very, you know, conditionals, conditional bits and stuff are very useful to understand, I think, at a low level.  As you then move into higher level languages, you kind of know what's going on.



STEVE:  I don't know if - it could be Mac based.  But remember that that little PDP-8 emulator is a beautiful piece of work.



LEO:  There you go.



STEVE:  On the Mac platform.



LEO:  Every kid in the high school has a Mac laptop.  They matriculate with a Mac laptop.



STEVE:  It's perfect then because the PDP-8, being that I only has eight op codes...



LEO:  Very straightforward.



STEVE:  ...is a perfect little language to begin to, like, do little experiments with.  And I have used that PDP-8 emulator now on my Mac and written some code with it.  It just works beautifully.



LEO:  I will be calling you.



STEVE:  Okay.



LEO:  I'll be calling you for some fatherly advice.  I think this is going to be great.  This is going to be so much fun.  Start them with a PDP-8.  That is a great idea.



STEVE:  Yup.  It's just a junior perfect little machine.  And you're able to single step, I mean, it does, it disassembles the code, it single steps, you can see the contents of all the registers.  It's a visible computer which is perfect for learning, for giving you a sense for how they really work underneath.



LEO:  Oh, I'm so excited now [laughing].  Moving along, Question 2.  Marsh Wildman in Sacramento, California says, what do you mean when you say "scripts," exactly?  Dear Steve and Leo, I constantly hear you warning about the security risks presented by scripts.  What kind of scripts are we talking about here?  This web form I'm entering in this message into, for instance, doesn't this run on a script?  I'm looking for a form such as this or an order form.  There are many options out there - Java, ASP, Perl, XML.  What is the best choice for performance and to give me and my users the safety we rightly expect and increasingly  need?  Thanks for any help.  Love the show.  SpinRite is on my birthday wish list.  I love that.  Scripts.



STEVE:  Well, that's a really good point.  We've talked about scripts.  I just sort of use it as a - I assume that it is a term that everybody understands.  But I think Marsh had a really good question.  That is, okay, what exactly is it that we talk about?  Okay.  So there's probably no really rigid formal definition.  But in general a script means that something is being interpreted, that is, it's like a batch file is - you could say that that's a script because you're not compiling that into executable code, the actual code that the machine runs.  Instead, an interpreter is reading the script step by step.  Now, again, that definition even has kind of a problem because the original BASIC language was an interpreted language, so that it was an interpreter interpreting it.  But you really don't think of BASIC as a scripting language.  I mean, that's not the way it's been known.  So...



LEO:  Scripting languages are typically, when they're run - I'm going to try this, too.  We're both going to fail on the perfect definition.  But when they're run, they're often plain text, which then is run, as you say, and on the fly interpreted and executed.  I'm thinking of JavaScript, Python, Perl.  Sometimes, like BASIC and Python, they have intermediate steps of precompiled code.  But they're still interpreted in real time, as you say, as opposed to something like C or Assembler, which is machine-translated ultimately into machine code, which is run, then - can compile once, run forever.



STEVE:  Right.  And I guess the problem is there's a gray area where something you don't think of as a scripting language is interpreted.  So it's not just the interpretedness of it that makes it a scripting language.  And so I don't think there really is a rigid, clear definition.  But the reason I'm upset with scripts, or scripting, is not the scriptingness itself.  It's that, for example, in the case of JavaScript, that JavaScript, which is by the way a very nice language, I mean, it was developed by the guys at Netscape.  It unfortunately really bears no connection to the Java language itself from Sun.  I mean, they're not at all the same.  So in that sense it's sort of a poor choice of naming terminology.  But the Netscape guys sort of wanted to pick up some of the glamour of the Java language, so they called theirs JavaScript.



LEO:  Yeah, no relation at all.



STEVE:  Right.  What makes me uncomfortable is that browsers, web browsers interpret JavaScript.  And that means, well, and for the purpose of executing code from a remote web server.  So that just makes me really uncomfortable.  That's the classic Gibsonian reaction.  The idea that you're going to click on a link, you're going to receive a web page from some remote server who you don't have necessarily a trusting relationship with, and that page is going to come into your browser.  Your browser is going to parse the HTML, find scripting commands in there, and then run code which you've just received.  The idea, I mean, that's fundamentally a bad idea.  I mean, I recognize...



LEO:  That's really what we're talking about then here is client-side/browser-side programming, languages that run on the browser side.



STEVE:  Except that Active Server Pages, ASP, that's a scripting language that is server-side.  So you can also - or Perl.  You could say Perl is, I mean, in fact, Marsh listed Perl among his choices.  Perl is...



LEO:  That runs on the server as a CGI script as opposed...



STEVE:  Right.



LEO:  It doesn't, you know, the browser doesn't know Perl.



STEVE:  Right.  So mostly it means something, you know, in general it means that interpretation is going on.  And I would say maybe the right description is to say that scripting is used in web processes.  You know, you're scripting on the client; you're scripting on the server.



LEO:  But generally server-side stuff doesn't seem to be anywhere near as dangerous.  For one thing, it doesn't have access to the contents of your machine.



STEVE:  Although you also have, for example, UNIX shell scripts.  And there's scripting, but this is not...



LEO:  But they're only dangerous when they run on the hardware that's being compromised; right?



STEVE:  Correct.  And I'm...



LEO:  That's the issue, I think.



STEVE:  I'm just sort of - I was sort of like trying to say, well, so it's not just web things that are scripting.



LEO:  Right, right.



STEVE:  It's interpreted.  Mostly I think I would say scripts are interpreted.



LEO:  And but the risky issue is the stuff that is running on your computer that you are receiving from a website, and that the website is getting to run on your hardware.  That's the problem.



STEVE:  Yes.  That's why I - exactly.  That's the source of my continual concern about scripting is it's fundamentally very powerful, I mean, all of the Web 2.0 stuff, you know, any online forums which are accepting content, and the state-of-the-art fancy stuff, Facebook and MySpace and this next-generation technology.  It relies on you - well, and all the Google stuff.  Gmail is a perfect example, Google Mail.



LEO:  Right, it's all in JavaScript.



STEVE:  And calendaring, all of that.  That's all based on scripting.  It's arguably doable not with scripting.  So, for example, Marsh said, hey, this form at GRC - he's at GRC.com/feedback - is this scripting?  No, because it's from me.



LEO:  Intentionally, you wrote it, although almost everybody else uses a script.  You wrote it without script.



STEVE:  Yes.  Mine is all server...



LEO:  It's just using HTML, HTML...



STEVE:  It's in Assembly language, Leo.  It's in Assembler...



LEO:  Running on your side.



STEVE:  On the server side, exactly.  So it's just - it's a naked form which you submit, and then I take the form and do it all over on my side.



LEO:  It's not unusual for people who have forms on their website to have some JavaScript around it validating input, things like that.



STEVE:  Right.  Or in fact sometimes the actual email engine itself is on the page, and that's been used and exploited in the past.  People could change the addresses that the script was using and essentially use it as a remailer back in the early spam days.  So the exploits of scripting are legend.  And, I mean, and not surprisingly from my standpoint because it's code.  You know, you're accepting code from somewhere else and running it on your machine.



LEO:  That's the real - that's the fundamental issue.  And it could be Java, which is not a script, by the way.  We just talked about a Java exploit on the Mac that - you wouldn't call that scripting.



STEVE:  Or my even bigger nemesis is ActiveX controls, where that's code that you've just accepted and your browser has run.  Microsoft is getting smart finally, and the browser says, hey, something's trying to run ActiveX.  Do you trust where it is that you've gone?  And as we mentioned last week, Windows 7 is going to get better about telling you more about this thing that's trying to run so that you're able to make a more informed decision.



LEO:  Yeah, I mean, I think really we shouldn't probably use the word "scripting" because that's not the issue.  Really the issue is a website putting...



STEVE:  Code from somewhere else.



LEO:  Code from somewhere else running on your machine.  That's almost always where the security issues come in.



STEVE:  Right.



LEO:  Because it has to run a - I can run a Perl script that runs on my server.  It's hard, nay, virtually impossible for it to corrupt your machine without it getting some code on your machine that you run.



STEVE:  Right, exactly.  And on the server side you're able to provide the same benefit.  I would argue that most of what is being done client-side can be done server-side.  It's not as sexy, it's not as interactive, it's not as fast.  So there are...



LEO:  But it's safer.



STEVE:  It's way safe.



LEO:  So, and that's why you say use something like NoScript which turns off JavaScript because that's one of the common venues, or vectors.



STEVE:  Yes.  I love the idea of giving the user the choice, so that their browser is not just running any code that it happens to stumble over.  But when you get to somewhere that you care about, it's like, oh, look, this fill-in-the-address form doesn't seem to be working correct.  Then you turn on scripting right now for that.  And then, oh, look, now it knows what state my zip code is in and the other fancy things that scripting are able to do for you.



LEO:  As long as we're doing definitions, let's do another one.



STEVE:  Okay.



LEO:  Victor in Pretoria, South Africa writes.  He says he's been listening and wonders what a socket is:  Hi, Steve.  Since you've been discussing network technologies recently I thought it might be a good idea to discuss sockets.  We use the term all the time.  But I don't actually know what they are and what they do.  What's a socket?



STEVE:  Well, the term as far as I know originated at Berkeley with their implementation, their first implementation on UNIX of Internet-style networking.  The idea is it's an abstraction to mean an endpoint of communication, and also sort of to mean what your program talks to when you want to communicate across the network.  Perhaps a more common or familiar sort of related name is a handle.  The idea, for example, in programming you call the operating system and say I want to create a file.  And from that you get back this handle, and you then write to that handle sort of as an abstraction for the file.  And you're actually writing to the file that you created using the handle sort of as your token.



Well, a socket is very similar, but in networking parlance.  So you create a socket, and then you may give it an address on your machine which is sort of like creating, like naming it.  You may then connect this socket to a socket on a remote machine.  And then as you write to your socket, it is possible to read from the remote socket.  So sockets are maybe connected in that sense.  They don't have to be connected.  There are so-called "connectionless sockets."  But sort of from a definitional standpoint it's the way programmers think about the way they talk to each other over the Internet, first in UNIX, and then Microsoft adopted the sockets interface and model, modified it a little bit of course because they can't leave anything alone ever, and so theirs is not really compatible with the Berkeley standard sockets model.  Later they've made them more compatible. 



But so that's what it is.  When we talk about sockets, we're talking about sort of the programming interface and also - that is, from the programmer's side, and also the communications endpoint from the networking side.  So, for example, in the Internet case, a socket would have an IP address and a port number.  And together that IP address and a port represent a unique reception point or transmission point in an operating system for it to communicate to the outside world.



LEO:  I've struggled with this myself because I get asked it on the radio show.



STEVE:  Really, you have listeners that are...



LEO:  What's a socket?



STEVE:  Wow.



LEO:  You know what I get a lot is, "What's a port?"



STEVE:  Yes.



LEO:  So a socket's not a port.



STEVE:  No.



LEO:  They have kind of the same functionality, in a way; right?



STEVE:  I would say that the difference is a port is - when I think about it, I know exactly what a port is.  A port is a number from 1 to 65535 that port-based protocols carry.  I know, that didn't make it much simpler.  But, for example, the IP protocol has IP addresses, but no ports.  You need to then layer on top of that the TCP protocol or UDP where they have - they bring this notion of a port so that the packets that are UDP or TCP format say I was sent from this port, and I'm going to that port.



And so the beauty of that is you can have services listening for inbound packets carrying a certain port number.  So really the only thing that is, is just a number.  It's carrying a port number.  But when it arrives at the server running an operating system, the server says, oh, this is aimed at port 80.  It's coming in to port 80.  Which means I'm going to give it to that process, the web server process running inside me.  If it's coming in to port 110, oh, that's the POP3 protocol port, so I'm going to give it to the email service running in there.  So really you could think of ports as like the final switching stage, like in a switchyard, where when the packets come in, it tells the operating system which of the various servers that those should be routed to at a single IP address, that is, in a single server. 



LEO:  So really a port and a socket aren't the same thing at all.



STEVE:  Right.  The socket is more of the programming abstraction, the way programmers see the Internet.  Ports are an abstraction that lives on the packet side, the way that packets get routed once they arrive at the proper IP.



LEO:  But they both have to do with communication.



STEVE:  Yup, and they make the world go round.



LEO:  Sockets make the world go round.  Let's remember that.  Could be a good song.  All right, long one here from Shawn Poulson, Middletown, Delaware, about SSL:  Hi, Steve.  Another fine Security Now! podcast with a deep dive into a big technology we could all understand, or we should all understand.  He's talking about SSL.  Well done.  I wanted to write in to comment about a remark made near the end of that podcast.  You and Leo were suggesting that with the power of computing these days, SSL doesn't represent much overhead.  So why not use it for everything and continuously offer more security?



Let me point out a couple of cons that were not discussed.  And if you like, use them, if you think I'm on to something.  First of all, the cons:  Web browsers don't cache content over HTTPS.  It turns off caching.  So that means they have to download every image, HTML, JavaScript, every single time.  Of course, browsers these days cache a lot, and that speeds up browsing considerably.  Of course you shouldn't cache the secure content or it wouldn't be secure.  In addition, caching proxies won't cache this content either.  ISPs often employ transparent caching proxy devices that save their upstream bandwidth to the 'Net by caching what their users often access, like say the Google search page logo.  So when you go to a Google page you're probably getting that logo, not from Google, but from your ISP.



So it's important to know what content is truly public and safe to disseminate to anyone listening in and which is confidential in any way.  I don't think it's ideal to blanket all web content as suitable for HTTPS.  To that regard your CryptoLink package might be a good solution.  I've often griped to myself how insecure it is to fire up my laptop at a local Internet caf.  Anyone could listen in on all my doings from a distance.  That's why you would use a VPN.  He makes a good point.  It just would be inefficient.  It's not that the computer can't decrypt it, it's just the waste of bandwidth.



STEVE:  Yeah, and, I mean, so yes, I wanted to share Shawn's notion because he's absolutely right that web browsers are prevented from caching secure content, which is what you normally want.  I have seen the option in the configuration dialogue sometimes that gives browsers permission to cache secure content.  You probably don't want to do that because you want to know that those pages which you are looking at, just you, having logged on to your banking site, for example, and where all of those pages are wrapped in the security of that communication, you want to know that, when you close the browser window, that stuff was never written to the disk.  It isn't in - it's not sitting there able to be scrounged around by anybody else using your machine or any malware that may be on there.  So it is the case that the browsers are smart about that in the case of SSL.



And he mentions caching proxies and how using a secure connection will bypass your ISP's proxy.  That's, for example, what I do when people are entering the ShieldsUP! site.  Many users are behind ISP proxies.  So nonsecure connections are going through the ISP's proxy to the remote server.  So if I didn't ask for a secure connection when you were using ShieldsUP!, I would see your IP as the ISP's proxy.  And that...



LEO:  That's not right, yeah.



STEVE:  You don't want me testing the proxy.  You want me testing with ShieldsUP! your machine.  So the entry point to ShieldsUP! gets a secure connection so that specifically to avoid intermediate proxies.  So both of those things are the case.  Where what we were talking about differs from these examples that Shawn was suggesting was more my sense that all connections should be secure.



LEO:  Yes.



STEVE:  Not necessarily that the content that is being exchanged always needs to be secret.  And so I would differentiate the secretness of the content from the security of the connection.  So, for example, email connections should be secure, even if it's just your random old email when it gets there, something where you're not concerned about the security on arrival as arguably you are if, for example, you're doing banking, and you want your banking pages not to be written to the hard drive.  So this sort of - this confusion is a function of all of this still just being immature technology.  This sort of came upon us half baked and half thought out, and we're all using it and making the best of it.  And how often have I said someday it's going to be better.  We're going to be marching...



LEO:  [Singing] Someday...



STEVE:  We're going to be marching slowly toward that day for quite a while, hopefully doing podcasts all the while.



LEO:  And we will have a celebration when it's better.



STEVE:  So it's really not HTTPS that I was referring to, it's this notion that setting up SSL connections are easy and inexpensive with today's technology.  So given all of the, I mean, all of the problems with insecure locations where you can be doing things, like in open WiFi hotspots, it'd be really nice if our protocols were just secure by default, and then had this extra layer of, oh, yes, obviously it's secure, but also please don't cache it because this is sensitive.  And, you know, it's sensitive content, carried in a secure connection.  Be nice if everything were carried in a secure connection.



LEO:  I blame myself.  I think I was the one who was saying, well, why don't we just use HTTPS all the time, for every page?



STEVE:  Okay.



LEO:  And there's a reason why not.



STEVE:  Right, because it's certainly the case that caching really gives us a tremendous performance boost.  But boy, have you noticed how big, how much space on a hard drive web browser caches start eating up?



LEO:  Yeah, hundreds and hundreds of megabytes, yeah.



STEVE:  Well, yeah.  I mean, if you empty your cache, sometimes that takes half an hour just to delete all that crap.  I mean, all...



LEO:  But to be honest, I mean, hard drives are big now.  And it's not, I mean, even if you have a gigabyte of a cache, that's still a small percentage of your total hard drive space.  We're just old-timers, and we go, oh, a hundred megabytes for your cache, that's outrageous.  But there's plenty of space.



STEVE:  Although you do really wonder how much of that is getting reused.



LEO:  Yeah, that's true, too.  It's caching everything.



STEVE:  Obscure stuff that you're never going to be seeing again.



LEO:  Well, and that raises another issue, which is you should know, if you're not on a secure page, that frequently content that you're looking at is saved.



STEVE:  Yup.



LEO:  And that's how people can get in trouble sometimes.



STEVE:  Often, in fact.



LEO:  Yes.  Simon Iremonger - love the name - in England wonders about processor security flaws.  We don't talk about that much.



STEVE:  Never have.



LEO:  Hi, Steve/Leo.  I know there's all manner of interpretation going on in modern processors creating microcode, predicting the flow of the program in advance, all manner of optimizations.  In one form or another, this is using a relatively fixed logic in order to interpret a user-supplied program.  Yeah, it's a von Neumann machine.  So why do we not hear such things as "a flaw in the AMD64 microcode allows malformed SSE2 instructions to bypass ring privileges"?  Why do we not hear of "flaw in Intel atom cache row buffer allows unprivileged process to read cached kernel memory"?  Just what's going on?  I don't believe processors don't have bugs.  Clearly they could present security issues.  Is this security by obscurity?  Is the nature of the hardware logic engineering more secure by design?  Do those elite teams of CPU designers simply not resemble typical application developers?  Your comments are welcome.  I think this would be an interesting discussion topic.  Thanks for the great show.  It is a good question.



STEVE:  It's a really great question.  And I found myself having to - pausing this morning at Starbucks as I was going through the mailbag, assembling these, thinking, okay, that's a good question.  There have been flaws in processors, like in processor microcode.  There was a famous - remember the Pentium divide flaw, where I remember seeing it demonstrated back in...



LEO:  That's exactly what I was going to bring up, yeah.



STEVE:  Yup, in the Lotus 1-2-3 days you could put some specific data into the spreadsheet, and the spreadsheet would give you the wrong answer.  Which was a consequence of there being a bizarre little subtle bug that affected specific cases of a division instruction.  And it's conceivable that that kind of thing could be leveraged into a, like, into a public exploit.



But I think the best way to explain why we don't see this so much is that the model for a processor is very much like the model that we were discussing recently of code for the shuttle, you know, the NASA shuttle, where it absolutely - or even the Rovers on Mars, that absolutely has to be right.  I mean, it has to be right to a much greater degree of "has to" than regular consumer software, where they go, oh, sorry, here's an update, download this.  I mean, this is a processor where, for example, in the case of Intel of AMD, they can afford to spend huge amounts of man centuries making sure this is right because they're then going to encapsulate it in a chip and start spitting out millions of these things.  It has to be right.  It's high profit.



It's also high damage if they mess this up.  And they've got very sophisticated tools for making sure that, as they've gone from one generation of X86 to the next, that this thing still executes similarly.  That is, you have to know that they've got test suites of code that they run on a new design, emulating the next-generation chipset, really, and initially it's failing.  There's things they missed.  And it's not until all of the so-called regression analysis passes that they let it out the door.



Now, we know that Microsoft does something similar, but we've seen that Microsoft, for example, just to choose someone, doesn't catch everything because the guys down at eEye Security in Southern California, they have found many Microsoft faults by doing what Microsoft should have done.  They've got a lab full of machines running Windows, and they're just throwing junk at them.  There are, like, all kinds of wacky packets and all kinds of junk.  They're keeping a trace of everything that they do.  And every so often they crash a machine.  Well, we know that crashing a machine is the first stage in exploiting a machine.  So when one of these machines crashes because some random junk packets were thrown at it, it's like, whoa, wait a minute, what exactly did we throw at this machine that caused it to die?  Then they back up, and they go forward.



So chips are done in the same fashion.  I just think the reason we don't have problems like we see so commonly with software is, I mean, not so much differing levels of complexity, because exactly as Simon suggests, modern contemporary processors are phenomenally, phenomenally complex with the out-of-order execution and instruction renaming and flow prediction, I mean, I've been reading in the last few months, sort of studying processor design a little bit, and it just makes your head spin how complex these things are.  But they're correct because they can afford to make them correct, and the cost of a mistake would be so phenomenal that they just can't afford to make the mistake.  So a lot of time and money goes into making sure that when we get the chip, it works exactly as the spec says.



LEO:  That floating point error was very - billions, I would imagine, it cost Intel.  I mean, huge.



STEVE:  And here we are talking about it today.  I mean, it isn't even dead yet.



LEO:  Yeah, yeah.  I mean, so, yeah, they learned their lesson.



STEVE:  Yeah.



LEO:  It's really an interesting question, though.  I'm surprised we don't hear more exploits.



STEVE:  I think it's a function of having the right tools and the right methodology and understanding we can't - this one we can't mess up.



LEO:  It's also simpler.  I mean, it's not as big a - it's not Windows.  There's not, I mean, how much microcode is there?  It's not a huge amount.



STEVE:  It's - I'm reluctant to say that it's much simpler because I've looked at what's involved now with a contemporary processor.  And, I mean, and it's just mind-boggling.  It's just mind-boggling what's going on in there.



LEO:  So props then to these guys at AMD and Intel, and all the other chip manufacturers who do such a good job of this.



STEVE:  They're right because it has to be.



LEO:  I like that.



STEVE:  Just like the shuttle code.



LEO:  It's kind of neat.  It's neat when you see somebody doing a job above and beyond.



STEVE:  Yeah.



LEO:  Doing such excellence.  Talking again about JavaScript, we have a bunch of questions and comments about that.  Matthew Srebinski of Essexville, Michigan is getting warnings.  Warning, warning.  This may be one of the most common questions I get on the radio show, if it's the question I think it is:  Steve, I just listened to Security Now!, your netcast on SSL and TLS, 195.  As soon as you mentioned the latest Acrobat Reader problem I disabled JavaScript on several of my work and home computers.  The first PDF I opened after that gave me an error.  It said this contains JavaScript, but I had JavaScript disabled.  Since you said you'd never encountered a PDF with JavaScript in it, I thought you might want to know about it.  The file was a topographical map downloaded from the U.S. Geological Survey.  I'm not certain what they use JavaScript to do, but it's interesting to know that somebody other than black hats is using it.  I'm an avid Security Now! listener, and I own a copy of SpinRite, which has fixed several problems for me.  Keep up the good work, and let us know how well the Kindle DX works as a PDF reader.



Also Eric in San Jose, he's getting false JavaScript warning messages.  He says:  I disabled JavaScript in Adobe Acrobat Professional 8 as instructed.  However, now when I receive and open attachments from my co-workers I get two - count them, two - popup messages to click through that say "This document contains JavaScript.  Do you want to enable Javascripts from now on?  This document may not behave correctly if they're disabled."  So I clicked "no" twice and moved on.  The files did behave themselves.  The PDFs I received were created using the Print to PDF feature in Acrobat 5 or 7.  I don't know why they'd contain JavaScript.



STEVE:  Okay.  And these questions are representative of a bunch that I received.  The problem is that - and this is just laziness, frankly, on Adobe's part.  They're not used to running with JavaScript disabled.



LEO:  And they get mad.



STEVE:  So, yes, so it doesn't - so the reader doesn't behave itself very well.  There may be some lazy tag in the PDF that says it may have JavaScript, but it doesn't actually.  And so that causes the popup.  I don't know, and it would take days to weed into this and wade into it and look at the actual raw PDF code to determine what's going on.  What I do know is that these are false positives.  It's that they only occur because Adobe hasn't taken the time to prevent them from occurring.  Because Adobe has JavaScript turned on all the time, as do all Acrobat and Reader users except those who listen to this podcast and who understand that, okay, whoops, we've got an unpatched vulnerability, let's turn off JavaScript.



So as I mentioned before, there are definitely PDFs that use and depend upon JavaScript.  And I had said that I ran across one myself at the State of California website.  They had something, it was a PDF form that sort of filled itself in and helped you when you were applying for a permanent mail-in balloting status.  And you really did have to have JavaScript turned on.  On the other hand, it was obvious that you did.  But static documents like these guys are talking about don't have to have it.  You can say no, and everything works just fine.



So maybe the commenting, you're able in Acrobat to, like, add annotations and things.  Maybe that uses scripting.  But if you're just printing to a PDF, chances are there's no scripting, and you just don't need it, even if this thing says, oh, wait, you know, you've got scripting turned off.  It's like, yes, I know, thank you for confirming that.  So I'm going to read this without any scripting and be just fine.



LEO:  Hmm.  Humph.  Harrumph.  Question 7, William listening in Canada is interested in the XP mode that Microsoft has announced in Windows 7:  Hi, guys.  Is XP mode in Windows 7 properly sandboxing Windows XP?  This is a particular concern if XP mode can be used as a vector of attack on Windows 7 systems, or if malware gets into the XP virtual system.  The reason this may be a concern is because of the integration technology that is included with XP mode where XP applications are able to be on the same desktop as Windows 7 applications.  They're using Virtual PC for this, if that helps.



STEVE:  Yeah.  And I wanted to post this question to sort of put this on the map because we've received it a number of times.  People want to know if this is the same as, for example, a VMware-style enclosure.  And I don't know.  I'm reluctant to look at it too much until Windows 7 gets, like, to release candidate.  I mean, I know we're at release candidate.  I meant, you know, RTM, Release to Manufacturing stage.  My concern is that I'd be surprised if it was sandboxing properly.  That is, that would be too inconvenient for most users.  They would expect things running in Windows 7's XP mode to have access to the hard drive, to be able to see their documents and the normal things that they see outside of the virtual machine.  I don't know either way.  But I just wanted to share the question and to let our listeners know I will - we will find out exactly what's going on with that because it's going to be an important feature of Windows 7.  I'm skeptical, though, about its use as full security sandboxing, only because doing that really does circumscribe the environment for the user.  So Microsoft may have done default things, like made the whole external hard drive, external to the VM, available in a transparent fashion.  I wouldn't be surprised if Microsoft had done that, which would completely zero it from a standpoint of security and use as a sandbox.



LEO:  Hmm.  Here's a really interesting one.  This is from Rick Slater in Carriere, Mississippi.  I'm thinking MS is Mississippi.  He's worried about Slashdot's article about the Kindle DX's kill bits.  In fact, I'll put a link to the article in the show notes so you can see it [http://slashdot.org/article.pl?sid=09/05/14/1356253].  You can see that the new Kindle DX has a number of kill flags built into the hardware which allow Amazon to reduce its functionality when they want to.  This was disturbing enough, in fact, so much so I canceled the order that I had placed for the new DX pending the time that this whole thing gets sorted out.  I'd be interested in hearing what your take is on the subject during the next Security Now! netcast.  Thanks for the great show.  Haven't missed one since the beginning.  Kill bits.



STEVE:  Well, first of all, it's not plural, from everything I could...



LEO:  It's kill bit?



STEVE:  It's kill bit.  And this is addressing the concern that either we've talked about, Leo, or I've heard you talk about, that is, the audio reader.



LEO:  Oh, this is the text-to-speech stuff.



STEVE:  Yes.  So apparently there are some Random House texts which have required of Amazon that they not be read-out-loudable on the Kindle.



LEO:  Right.



STEVE:  And so all that this is, this whole Slashdot story is people spinning off sideways, as they so often do on Slashdot, and exaggerating what's going on.  We don't know that there aren't other kill bits.  But there don't have to be.  There's only one that this whole issue is about, and that's a single bit which says don't allow this particular title to be read out loud.  Amazon designed that into the original specification for their content when they added the text-to-speech.  They thought, well, maybe there'll be some situations that come up where this book should not be read-out-loudable.  And we've now run across some.  So that's what this is.



LEO:  Yeah, it's just it's an incendiary term, "kill bits."  I think people get upset just because it's called a "kill bit."



STEVE:  Well, and there was some guy who did post on Slashdot who said this thing bit me.  There are some books that I purchased which...



LEO:  I wanted to read, I wanted to hear.



STEVE:  I bought them so that they could be read to me, and they won't - and he's like, and he's grumbling about I'm sure Amazon won't take them back.  And I'm thinking, no, I'll bet they would.  I'll bet you could say, hey, this doesn't work for me, remove these from my bookshelf and cancel them.  I mean, I just bet you could get cooperation.  So I think it's a little tempest in a teapot, myself.



LEO:  This next one...



STEVE:  But be aware that not all books can be read to you.



LEO:  Yeah.  This next one comes from a friend of mine, Steve Vance, who's with the Golden Gate Computer Society in San Rafael, California.  He's a great guy, see him every year when I speak to the club there.  He wants to know about how to detect SSL proxying:  Hi, Steve.  You've mentioned that if I'm using a company computer, and they have installed a certificate on it, they can decode my HTTPS packets, look at them, then reencrypt them and send them on.  Kind of a man in the middle almost.  All right.  So I want to go to my bank's website on my lunch hour, but I don't want anyone in my company to watch me do this.  Is there some way to tell if they've installed the certificate and are doing it?  It looks like my bank's website.  The address bar is green and everything.  If my company were doing this, would it somehow be obvious?  How would I go about trying to detect if they're doing it?  For extra credit, if they're doing this kind of proxying, is there any way I can thwart this?  Would CryptoLink solve this problem?



STEVE:  Okay.  That's a great question.  And again, my discussion of this a couple weeks ago caused a whole bunch of concern, very much like Steve's, on the issue.  What you can do is pretty simple.  If you, for example, went to any secure site, and since I know my certificate you could go to the page I was mentioning earlier, the ShieldsUP! page.  So you just go GRC.com and then choose ShieldsUP! from the main menu and go no further.  That'll take you to sort of the entry page where we're saying hi, click this button to proceed, but stay there.  You'll see then that you've got the padlock showing that you're on a secure page.  You look in the address bar, it's https.  I have not yet bellied up to the bar and purchased an EV, an Extended Validation certificate.  I'm considering that when I next renew my certs because it would be a nice thing for GRC to have, to also have the green.  I think that's - it'll be a good value for my money, although it is a lot of money.



So then you can, if you hover, at least in Firefox, hover your mouse over the little padlock, you'll see something that says VeriSign Trust Network.  You can also double-click on that to open up the properties.  What you want to do is you want to poke around in there.  Various browsers have these in different places.  But you want to look at the so-called chain of trust that we've talked about, the sort of a hierarchy of links for the certificate.  And in the case of GRC's certificate, which I get from VeriSign, you'll see GRC.com, you'll see a VeriSign intermediate, and then that trusted root, the certificate authority, and nothing else.  That's the key.



If you did this in a corporate, within a corporate region where they were proxying your SSL, you would see that you had a secure connection.  But when you looked at the certificate, it would show, for example, GRC.com and then link to some non-trusted certificate authority that had been planted in your browser and that had been used to generate a certificate on the fly.  It would not link back to the real certificate from GRC.



So to be sure, you could go to any website, doesn't have to be GRC, but mine's always going to be there, and do it from within a corporation, see what that chain looks like.  You can probably tell for sure just there.  But if you went outside that corporate environment, for example, you went home and did the same thing, you should have exactly the same chain no matter how or where you connect to the secure website like that page at GRC.  So if they're different, then you know for sure that some funny business is going on.



LEO:  Excellent.  Simple enough.  Just check.  And by the way, would CryptoLink help with this?  Yes; right?  Because then you have a tunnel, and they can't break through the tunnel at the work.



STEVE:  Yes.  Now, okay.  Good point.  I forgot that last part of his question.  The CryptoLink will excel at getting out of pretty much anywhere.  For example, you'll be able to use a connection to port 110, which is the POP3 port, for example, and 80, and 443, and 25, which is probably going to be blocked anyway.  But, I mean, in fact, the way CryptoLink will work is it will spray simultaneously a whole bunch of SYN packets out towards different destination ports in order to opportunistically find an opening out in order to reach the server that you're connecting to, which will be looking at - actually CryptoLink has the ability to look at all ports, all there are, all 65535, because the packets are self-authenticating.  So it's able to detect incoming packets that are from its matching client.



So again, I'm designing this so that it just works, no matter what situation you're in.  But it's still conceivable that a corporation could have its border so locked down that nothing that's not proxied can get out.  In which case nothing can get out.  I mean, I would be surprised if that were the case.  But it's conceivable.  You know, I mean, CryptoLink will be able to use both UDP and TCP, blah blah blah, I mean, if there's a way to get out, I'm going to get out.  But it's conceivable that if they're proxying port 80 and proxying port 443 for HTTP and HTTPS, and like nothing else is allowed, then you would know, for example, you couldn't be getting POP mail, you couldn't be getting email from some other ISP, for example.  That would mean that port 110 was open, in which case CryptoLink would go, ah-ha, and it would find a way out.



It's conceivable that a corporate network could be so locked down that nothing but web surfing works, and all of that is proxied, in which case nothing would be able to get out of there.  But seems unlikely.  I hope that Steve will, if he's in such an environment, let me know while we're beta testing CryptoLink if it's able to get out because it'd be fun to know.



LEO:  Yup.  Ren Zhi Zhang in Auckland, New Zealand wants to verify the security of a portable router solution:  Hi, Steve.  I like the idea you mentioned in Episode 196, carrying around the portable router - like AnalogX does - and using it as a hardware firewall when I connect to someone else's LAN, say at a hotel, to protect against other machines on the LAN.  I'd like to be cautious and extra secure by testing this setup first.  However, I'm not aware of anything remotely similar to ShieldsUP! that I can run from another machine on the LAN to confirm that there aren't any ports left open by my portable router.  I ask the question because ShieldsUP! - correct me if I'm wrong - would only scan for open ports on the initial router connected to the Internet, not that router in between.  Any suggestions?



STEVE:  I have a great suggestion, and that's a great question.  We've never talked about local port scanning.  I don't think we've ever talked about it.  There's a neat security company a little bit south of me called Foundstone.  They were independent for a long time.  I think they were purchased by McAfee, but I'm not sure.  But they're continuing to operate independently.  And in fact one of their guys hangs out in the newsgroups.  And he's an author of security-related software.  Foundstone has a little, free, nice, very well designed, standalone, Windows-based scanner called SuperScan.  So if you just put into Google Foundstone, F-o-u-n-d-s-t-o-n-e space SuperScan, it's the first link that comes up.  And it's free.  You can download it.  They don't ask you any questions.  You have to agree to their little license agreement, but they're not asking for email address and your name and all this other nonsense that sometimes it's not quite as free as it seems.  It's nice and small.  It's like 100 and some K in size.  I think that Robin Keir may be its author.  I know that they caution a little bit that some functionality was lost when Windows removed raw sockets.



LEO:  Oops.



STEVE:  I mean, that's the consequence of removing raw sockets to tighten up the security and prevent abuse of that technology.  But they're still able to perform a lot of scans.  It's got unrestricted IP ranges.  There's a whole bunch of features in it.  And I heartily recommend SuperScan from Foundstone.  It's at v4, which requires a Windows 2000 or NT or later machine.  They do still leave v3 available because it would work on even earlier machines - 95, 98, and ME - if anyone is still using those.  And so the idea would be that Ren would set up his travel router, and then a machine behind it, and then from another machine on the same LAN would use SuperScan to scan all the ports on that IP.  And he's right that using ShieldsUP!, ShieldsUP! being out on the Internet, its whole intention is to be an Internet-facing security test.  But in this case he specifically wants a LAN-based security test, so like an intra-LAN test.  And SuperScan will do that for you.  And I recommend it without hesitation.



LEO:  Cool.  SuperScan.  And is it free?



STEVE:  Yeah.



LEO:  Wow, that's nice.



STEVE:  Yeah.  They have a whole bunch of great free security tools there at Foundstone.



LEO:  Have to make a point of writing that one down.  Darius in Port Moody, BC wonders about multi-site version control:  Hi, Steve.  I've been listening to you and Leo for the past couple of years.  I've been listening to Security Now! since Episode 99.  You often talk about the code that you write for your various projects.  It sounds as though you use different computers to work on these projects depending on whether you're at GRC HQ or Starbucks.  I was wondering what your solution is for secure source control.  How do you keep your source code safe and well protected on the move?  Do you use SVN or some sort of versioning tool?



STEVE:  You know, I don't.  I found a great Windows utility.  It's not free, and not even particularly inexpensive.  And I'm drawing a blank right now.  I was just looking for it in my tray because I always have it running down there.



LEO:  Do you use Brief?  What do you use as your editor?



STEVE:  I use Brief.  Brief is my editor.  But, and I use Jungle Disk and Amazon S3 as my repository.



LEO:  Oh, interesting.  So it's not just a backup for you.  That's where you keep updated code.



STEVE:  Okay, I got - I remembered.  It's FileBack PC.



LEO:  FileBack, okay.



STEVE:  FileBack PC is a phenomenally powerful, general purpose backup utility.  And it does versioning.  So, for example, in the configuration dialogue you're able to say, I want to keep a maximum of 20 copies of my source code.  I want no two to be closer together in time than an hour, no more than seven in a day, and no - and, I mean, you're able to granularly specify exactly how you want this thing to operate.  And what I love about it is I'm also able to say, okay, I don't want any .err or .map or .exe, you know, you're able to give it like a long chain of, like, file pattern descriptions of whether you do want it or don't want it to back those up.



And so what I have is essentially, answering Darius's question, is by sort of gluing together a couple solutions, Amazon S3 is amazingly inexpensive, Jungle Disk is a one-time cost of I think it's $19, and FileBack PC allows me to be working at Starbucks, to be saving the code.  It's transparently all copied to Amazon.  It's completely secure because we know that FileBack - we know that Jungle Disk does encryption on the client so that nothing that's ever at Amazon can be decrypted.  I mean, I'm not trusting my source code to anyone.  And so, and I trust this setup because it is bulletproof.  Then, when I'm back home, everything that I was doing at Starbucks has been kept with multiple versions.



And boy, I'll tell you, that does come in handy because there have been times when I've sort of gone off on a tangent and deleted a whole bunch of stuff that I didn't think I was going to need anymore, and then it's like, oh, shoot, I wish I had that.  Well, you know, I still do.  I'm able to reach back in time and grab a file that still has something that I got rid of prematurely or grab some snippets of code.  So it ends up working really well.  And I just like the transparency of it.  And of course FileBack PC is a general purpose file backup solution.  So I'm using it, for example, to spool content among many of my systems as I'm doing work.  It's able to be - you can configure a huge list of different sort of tasks.  And, for example, every time I hit the hibernate button I see it briefly pop up and shoot things off to Amazon because it senses that you're going to sleep, you're hibernating, you're shutting down.  And it does, like, pre-end-of-session work.  And all of this is really configurable with a lot of granularity.  It's a very mature tool.  So that's what I use, and I love it.



LEO:  Going to have to get you on Git one of these days.  That's a little more modern.  But if it works for you, you know, you're still using Assembly, after all.



STEVE:  I'm still using a DOS box.  And a DOS editor, a 16-bit editor that won't...



LEO:  Yeah, that's right.  I don't know if Git - I don't know if you could run Git in DOS, to be honest with you.  That's actually a very interesting question.  You might have to stick with FileBack.



STEVE:  I'm not worried about it, Leo.



LEO:  David Greenberg in Nyack, New York has our last question of the day.  He's got his Travel Router Tip of the Week, is what he's got:  Steve, I'm an avid fan of Security Now! and have been since day one.  In your most recent show you discussed a D-Link portable router as a neat solution for protection against malicious traffic from other machines on the same LAN.  I'm actually using my Apple AirPort Express to do the same thing.  You can put in your pocket.  You can plug it in anywhere, use it in the hotel.  Oh, look.  He says:  Without any affiliation with Apple specifically, I also want to recommend their AirPort Express travel router.  It has a - you know, because I was going to go out and buy the D-Link.  And then I went, I've got, like, two AirPort Expresses that I'm not using.



He says:  It has a similar wall-wart form factor, complete with swing-out prongs, and can be configured to serve WiFi after being connected to a wired Ethernet connection.  However, it can also be used to attach to an existing WiFi AP as a client, in which case it may be used in several interesting modes.  In one mode it can be used to extend the range of an existing WiFi network.  That's what I used to do with my AirPort Extreme and my AirPort Express.  I used it in WDS mode.  In another mode, its built-in USB port can be used to attach a printer, creating a print server.  Finally, the unit has a built-in D/A converter and a 1/8" stereo audio jack, can receive streaming audio directly from iTunes or, via a third-party program called Airfoil from Rogue Amoeba, any other audio-generating piece of software.  In my case I use it to stream music from my desktop and laptop PCs to my living room stereo.  Then when I travel I reconfigure it as a WiFi AP, take it with me for that purpose.  I guess you take speakers, too.  It's really quite a versatile device, with one drawback.  Rather than running a web server for easy configuration, you have to run a specific Apple utility on your machine to connect with and configure the unit.  And that's why it's not so hot for a Windows user.



STEVE:  That's just what I was going to ask you, if there was a Windows solution.



LEO:  I don't know.  I don't think so.  Thanks for such a high-quality program and for occasionally sharing the details of your own personal background and interests.  We have several interests in common, and I'm sure we'd have a lot to talk about if we ever met someday.  Let me tell you, having a glass of Cabernet Sauvignon with Steve Gibson is always a pleasure.  I can speak from personal experience.



STEVE:  I miss those, Leo.  That was fun.



LEO:  We're due for that.  I know, we haven't had that in ages.



STEVE:  I'll have to get up to your neck of the woods.



LEO:  Please do.  I have a bottle of Cab just waiting for you.



STEVE:  Anyway, I wanted to share David's posting.  I know we have Mac listeners.  And this little AirPort Express sounds like a spectacular little unit.



LEO:  It's great, yeah.



STEVE:  Yeah, I love the idea that its little fangs swing out, and you plug it directly into the wall to get power, so in that way it's like the D-Link that has got it built in.  And I think it's very cool, too, that if you're in a hotel you can plug it into the hotel's wired network, which is exactly what Mark Thompson does when he brings his little D-Link with him here, is then it's your wireless access point, secure I'm sure with WPA.  So it's a router protecting you, as we were talking about, and then you're able to use your laptop anywhere in the hotel room without having to be wired down.  So it sounds very cool.



LEO:  It says - I'm looking at Apple's documentation.  They say to set up AirPort Express using a Windows PC you can use iTunes.



STEVE:  Yay.  Well, that's good.



LEO:  Although, y ou know, I'd have to - it's really, I mean, it is designed for Macintosh hardware.  I've never tried it.  I'll have to - I'll tell you what.  I'll report back next week.  I'll try and figure out how I can configure it from a Windows machine.  I'm just, I mean, the truth is, if you set it up kind of in generic DHCP mode, you don't have to configure it at all.  You just plug the thing in and, you know, say hello.



STEVE:  Right.  I was thinking similarly that I've got Macs, so I could use a Mac to get it configured, and then use it in Windows mode with no problem at all.



LEO:  There is, I guess there's a Windows AirPort setup application.



STEVE:  Oh, good.



LEO:  Yeah.  So you just use their application.  I guess there might be some advantages to having a dedicated application doing this to using the browser to do it.



STEVE:  I don't think so, except maybe just...



LEO:  For security?



STEVE:  ...if it lowered the cost of the device.  Because, you know, you'd have to have a browser in there and a lot of web page content and so forth.  So maybe it's just simpler to do it that way.  I did note, by the way, when I was doing a little bit of quick pre-podcast research about this, everybody's got a travel router now.  You know, Linksys, Netgear, D-Link, Asus, Belkin, and Apple are the ones that I saw.



LEO:  Right, right.



STEVE:  So it's like, whatever brand you like.  I can say that the D-Link works that way with a little built-in adapter.  And that's what you really want, I think, you want something small that you can just toss into your bag and not have lots of cordage and things dragging around.  It sounds like the Apple Express travel router is exactly that, too.



LEO:  Pretty small.  I think that APC may even make a smaller one, designed just for laptops.  There's stuff around.  Steve, we've come to the end of our 12 wonderful questions from our 12 wonderful listeners, and we thank everybody.



STEVE:  And look, we made it in less than two hours.



LEO:  Just.



STEVE:  It's a miracle.



LEO:  Barely.  Barely.  I am downloading right now the PDP-8 emulator.



STEVE:  Yay.  It's beautiful.



LEO:  It's designed for older Macs.  It's a Carbon application.  You have to run it kind of in a - but it runs, seems to run fine.  However...



STEVE:  Maybe you got the wrong one, Leo.



LEO:  Oh, where do I get it from?  I'll tell you where this came from.  It came from Bernhard-Baehr.de.



STEVE:  Yeah, that's the guy.  But it just runs on my Mac.



LEO:  Well, it runs.  It's not a - it's a Power PC.  It does run on Intel.  It will run up to Leopard.  It is, you know, once you get it running it's a little cryptic.  It's like, well, now what do I do?  I'm going to have to ask you for help there.



STEVE:  Yeah, I was very, very impressed with it.  It knows when you, like, drop some source code onto its icon in the - whatever you call that on the Mac, the tray or the...



LEO:  Yeah.  Well, you know what's kind of cool, it looks like it - there was an alternate disk image which I got, as well, that had, I mean, this is - it comes with Pascal.



STEVE:  Oh, yeah, it's got a full OS 8 operating system.  So you're able to, like, mount the OS 8 drive and run the original - and that was like the final operating system for the PDP-8.



LEO:  It's got a front console, front panel.



STEVE:  Oh, beautiful rendered console.  You're able to see the contents of the registers.  It simulates all the different I/O devices.  And you can see what's in them.



LEO:  Yeah, I mean, when you print something to the file, to the line printer, you can then save it to a disk.



STEVE:  Yeah, he did a really nice job.



LEO:  So, but where's the interface for pro- oh, I guess there it is, there's the console.  ASR33 console teletype [laughing].



STEVE:  Yeah.  And in fact there's a - somewhere, I think he's got it in there, is a Towers of Hanoi - or maybe I typed it in.  But I remember watching it like, you know, going [mimicking teletype].  And it's like, you know, you can have it run at 30, or at 10 characters per second, just like a real teletype did.  And I remember, like, I think I might have typed in the FOCAL program, which was DEC's interpretive sort of response to Dartmouth BASIC back in the day.  And it sat there [mimicking teletype], typing out the height of the...



LEO:  Here it is, Towers of Hanoi, yeah.



STEVE:  Ah, good.



LEO:  FOCAL-8.  So now if I open this, it loads it in.  And now how do I run it?  Do I type "run"?



STEVE:  I don't remember.



LEO:  [Laughing] Typing "run" did not do it.  But I'll...



STEVE:  I would imagine you'll, I mean, I figured it out very easily.  And after you get the hang of it, you're able to make it look pretty simple for people to use.



LEO:  Yeah, and that's going to be the key for me is I'm going to take a bunch of high school kids and say, guess what, you now have a PDP-8.  Let's...



STEVE:  A 12-bit computer with 4K of memory.



LEO:  Let's program it, what do you say?  Oh.  I think this is great.  What a great way to teach computer science, the kind of fundamentals, to start with the basics?



STEVE:  And Leo, when then you take them to higher level language, they will be so appreciative.



LEO:  They'll be grateful.



STEVE:  Instead of just taking it for granted, they'll go, oh, thank god, we have variables now instead of memory addresses.



LEO:  Yeah.



STEVE:  But again, I think - I'll bet you none of them ever forget that.  And it's a valuable lesson.



LEO:  A great way to learn, if you ask me.  I mean, maybe it's because we're old-timers.  But I just think that's a great way to learn.



STEVE:  No, given the reaction from our listeners to this stuff, the gray-haired episodes, there's a lot of appreciation for it.



LEO:  I mean, there's a disassembler window.  You can see the memory contents.  You can see the stack.  You can see the interrupt controller.  I mean, you get to see how it's working.



STEVE:  Yup, it's the whole machine made visible.



LEO:  I have a pointer here at address 200.  That must be the code I loaded in.  I wonder if I can just run it from there.



STEVE:  And that's the default starting point because the page 0 - and that's 200 octal, which is actually location 128.



LEO:  Ah.



STEVE:  So the first page is a special page because remember that with the instruction format there aren't that many addressing bits.  So you're able to only address the page you're in or page 0.  So page 0 is sort of special because you can get to it from anywhere.  Otherwise you're only able to address the page you're in.



LEO:  So you keep page 0 blank and there for pointers or things that you need.



STEVE:  Exactly, sort of like your global variables that you want to be able to access as you wander through code space.



LEO:  Oh, this is so cool.



STEVE:  It really is.  It's just...



LEO:  Do you have a manual somewhere online that you recommend for people, I mean, I'd like to learn more about this before I try to teach anybody how to use it.



STEVE:  Yeah.



LEO:  I might have to get a PDP-8 manual.



STEVE:  There is a - there's a bunch of stuff...



LEO:  There's some tutorials, it looks like, on the website.



STEVE:  ...built in.  And there is a - I want to say Chicago or Indiana.  There's a college that is using this and using the PDP-8 for their curriculum.



LEO:  That's what I need.



STEVE:  And that professor has a whole bunch of really nice sort of laid out like, you know, here's the memory reference instructions for the PDP-8 and so forth.



LEO:  That's what I need.  I need to steal somebody's curricula.



STEVE:  Yeah.



LEO:  Yeah, the Towers of Hanoi FOCAL source code.  Is FOCAL  like a language?  Like BASIC?



STEVE:  Yes, FOCAL was DEC's sort of answer to Dartmouth BASIC.  And so it's a funky language.  But, I mean, it was very popular, and people were using it on...



LEO:  It also comes with FORTRAN and Pascal-S.  So you're in pretty good shape here.  This is a great little development environment.



STEVE:  Yeah.



LEO:  All you need is a Macintosh.  All you have to do is buy a thousand dollar computer, and you can run it.



STEVE:  It'll slow you down to 10 characters per second [mimicking teletype].



LEO:  It does, it warns you, it says "This is really slow.  Be patient.  Interpreted FOCAL programs running on a PDP-8 simulated by a slower or faster Macintosh are very slow."  This is the old days, folks.



STEVE:  Yup.



LEO:  Thank you, Steve Gibson.  For more information, of course, Steve has his show notes online at GRC.com; also 16KB versions of the show for quick download; transcripts so you can read along.  There's the forums there, the security forums.  You can leave feedback at GRC.com/feedback.  And of course don't forget there's some great stuff on there, free to download - ShieldsUP! to test your router, Wizmo, DCOMbobulator, a lot of free stuff.  And the bread and butter of the whole operation, SpinRite.  GRC.com.  Steve, we'll see you next week on Security Now!.  I've got some PDP-8 programming to do here.



STEVE:  Cool.  Thanks, Leo.



LEO:  See ya.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	199

DATE:		June 4, 2009

TITLE:		"The Geek Atlas," IPv6 & Non-VPN

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-199.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo explore three different topics:  a terrific new book of interest to geeks or non-geeks alike; the still-questionable future and operation of IPv6 (the next version of the Internet protocol); and Steve's novel idea for making secure TCP  connections across the Internet without using a VPN tunnel.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 199 for June 4, 2009:  "The Geek Atlas."  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure - privacy online, SSL, VPN, all the acronyms.  Here he is, ladies and gentlemen, from another acronym, GRC.com, the Gibson Research Corporation.  It's Steve Gibson.  Hey, Steve.



STEVE GIBSON:  You know, this week we could also say that it's all things geeky because it certainly is.  But we have something especially of interest to geeks this week.



LEO:  Oh, good.



STEVE:  And I want to cover - I want to do something we haven't done before, and that is talk about three sort of different things, sort of smaller things, rather than just one central topic.  So...



LEO:  I like that.  Kind of a geek potpourri, a security potpourri.



STEVE:  Yeah, that's - interesting things, just some things that have sort of been on my radar recently.  We will have some security news, a little bit of errata, and then we'll get into it.



LEO:  Very good.  So before - let's see.  Yeah, let's talk about the security news first.



STEVE:  Okay.



LEO:  I want to send you a link to a great conversation, hacker conversation.  I'll send it to you for next week.  About security.



STEVE:  Oh, okay, good.  But we do have a number of things that have happened since we last spoke.  You may have been aware or may have heard that Apple had a QuickTime flaw which they have now addressed.



LEO:  They patched, yes.



STEVE:  I just, when I turned my Mac on, there were three things it was updating.  I don't remember whether QuickTime was one of them because my attention was distracted because that band program, whatever the heck it is, oh, Garage Band, was 108MB, and I don't even know where it is or what it does.  But apparently it needed some updating.  So I guess you don't want your banjo to have a - to blow up on you or something.  I don't know, who knows.  So my Mac has the current version of Garage Band, for all the good it's going to do it.  And presumably this Apple QuickTime flaw.



There was, in the .PICT handling, there was a flaw in a - there was a 16-bit length attribute that was mishandled that will allow people to generate a malicious QuickTime file which can, naturally, take over your machine remotely.  So you want to make sure that you get yourself updated on that.  Once again, PDF is in the security news.  This time BlackBerry.  They've had, like, three or four problems in, like within the last year, BlackBerry has, with their PDF handling.  And there's a new one which allows you, or allows bad guys, to malform email containing a PDF file, send it to a BlackBerry, and take it over remotely.



LEO:  Wow.



STEVE:  So updates are available.  Before they were available, BlackBerry was very forthcoming and said, look, we want to acknowledge this vulnerability.  They got some kudos for being really so upfront about it.  And now they've got it fixed.  So if anyone is, like, using BlackBerry in corporate environments, they want to make sure that their corporation has updated the server, which apparently is involved in the parsing and the generation of PDFs as they're sent out to the BlackBerries.  So that's been fixed.



We have also a zero-day Microsoft DirectX vulnerability in DirectShow, which is a component of DirectX, the DirectShow QuickTime parser.  Now, there is no fix for it yet.  It does not affect Vista and Server 2008 and Win 7.  So it's only the down versions of Windows - Windows 2K, XP, and Server 2003.  Microsoft doesn't have a fix for it.  Oh, and because it's zero-day, remember, that means it is being actively exploited now.  And again, it means that the way it was discovered was people's machines were crashing or getting code executed on them remotely.  And so this is one of those things where you just visit a website, and DirectX can trigger, that is, the JavaScript in the website can trigger the playing, without any user interaction, of a QuickTime file which executes this code which is vulnerable and allows somebody to do malicious things on your machine without you taking any action other than just viewing it through your web browser.  Now, the good news is, Microsoft has deployed their "Fix it" system.  I think I've heard you and Paul talking about this, kind of this Microsoft "Fix it" thing where...



LEO:  Yeah, it's kind of cool.  If you go to some of their support pages, their knowledge base pages, there's like a button that says "Fix This."  And usually, I think, I suspect, it's just a registry patch.  But they might do other stuff, too.



STEVE:  Well, and so this is a perfect lead-in.  Thank you, Leo, for this.  If our listeners go to support.microsoft.com - you can do this right now, Leo, and you'll see.



LEO:  Okay.



STEVE:  Support.microsoft.com/kb - as in knowledge with a silent K, knowledge base.  So it's /kb/971778.  That's the magic number for this.  So support.microsoft.com/kb/971778.  That will take you to a page acknowledging the problem.  And there are two big buttons there.  One is the disable the QuickTime parser, which is where the problem is, for DirectShow. And the other will reenable it if you want it to be enabled.  So you can also download these files rather than executing them.  For example, if you had a computer that was temporarily disconnected from the Internet or for whatever reason you couldn't go to the site, you can download them as files and then run them standalone on other machines.



LEO:  Interesting, they're COM files.



STEVE:  Yeah.  So anyway, so this is a problem that exists now, has not been patched yet.  One imagines, here we are, what are we, we're just shy of the second - the second Tuesday of the month.



LEO:  But no, it's a QuickTime problem.  So is it really an Apple patch or a Microsoft patch?



STEVE:  No, Apple does not have the problem, this problem.



LEO:  Oh, I see.



STEVE:  So it's a Microsoft implementation.  It's like...



LEO:  It's DirectShow is the problem.



STEVE:  Yeah, it's DirectShow parser that parses QuickTime content.



LEO:  Got it, I see, I see.



STEVE:  So Apple does not have it.  So, let's see, the first Tuesday of the month was, you know, based on the timing of this, this podcast will be aired on June 4th.  So that would have been the 2nd.  So that means next Tuesday is the second Tuesday of the month.  This has all just happened.  So it's not clear to me, I mean, we'll see whether Microsoft is able to fix this in time, get this into their patch update.  They don't have much lead time to make that happen.  So it's not clear whether they will or not.  So I'm, you know, certainly you do run across QuickTime videos on the 'Net.  And once you do this you will be disabling QuickTime playing for your browser on the 'Net under Windows, which you can choose to do or not.  You can certainly reenable it afterwards.  I imagine that Microsoft's update, when they do it, will probably reenable it for you.  They may take responsibility for undoing the disabling that they're now recommending.  But anyway, again, support.microsoft.com/kb/971778 to disable this as an interim measure because there is no fix for it.  It is a zero-day exploit being actively exploited to take over people's machines.



LEO:  Very interesting.



STEVE:  And then the final thing, I'll bet you've probably had this run across your radar, Leo, as a big kerfuffle has arisen.  I think maybe Brian Krebs, who I talk about from time to time, who writes a security column for the Washington Post.  He may have been the first person to bring this up.  And that is that Microsoft was found to be surreptitiously installing a Firefox add-on for .NET.



LEO:  Oooooooh.  Oooooooh.  Oooooooh.



STEVE:  And get this.  The Firefox add-on that they installed as part of their regular monthly patch, that is, the second Tuesday of the month deal, when they did, they introduced the .NET Framework 3.5 Service Pack 1, which was back in February, just without telling anyone they slipped this into the Firefox add-on list.  I have seen it for months...



LEO:  Yeah, me, too, yeah, yeah.



STEVE:  ...because it's been there for a while.  It's like, oh, I mean, I've already given up because it's like, okay, either you're trusting what Microsoft is doing or you're not.



LEO:  Or you're out of luck.



STEVE:  Exactly.  I mean, if you don't, then go to Linux or a Mac.  But it literally, this add-on establishes in Firefox, get this, "The ability for websites to easily and quietly install software on your PC.  So the problem here is this is why you're using Firefox, is that you don't want websites to have the ability to easily and quietly install software on your PC.  You've moved to Firefox because you don't want to be using the most historically vulnerable browser, Internet Explorer, in the industry.  And yet Microsoft has reached over and added this feature to your Firefox browser without your knowledge or permission to do just that.  Now, what makes it even problematical is that the uninstall button is disabled.



LEO:  Oh.



STEVE:  So no one can remove it.  Now, now Microsoft is saying, oh, well, I mean, talk about double-speak.  I'm going to quote what Microsoft says on their site because they've been slapped so hard and it's raised so much concern that they've now backed off from that.  But they say, "In .NET Framework 3.5 SP1, the .NET Framework Assistant enables Firefox to use the Click Once technology that is included in the .NET Framework.  The .NET Framework Assistant is added at the machine level to enable its functionality for all users on the machine.  As a result, the uninstall button is shown as unavailable in the Firefox add-ons list."



LEO:  In case there's somebody else who's using it.



STEVE:  Oh, well, yes, exactly.  It's at the machine level.



LEO:  Oh ho.



STEVE:  Too sophisticated for you to manage.



LEO:  Wow, yes.



STEVE:  "As a result, the uninstall button is shown as unavailable in the Firefox add-ons list because standard users are not permitted to uninstall machine-level components."



LEO:  Okay.



STEVE:  Even though an...



LEO:  So if I'm an administrator I could do it.



STEVE:  ...end-user running the machine got it installed just by using Windows Update.



LEO:  Yeah, no problem, yeah.



STEVE:  That you're being pounded on to make sure is turned on all the time.  So they're saying, "In this update for .NET Framework 3.5 SP1, and in Windows 7, the .NET Framework Assistant will be installed on a per-user basis.  As a result, the uninstall button will be functional in the Firefox add-ons list.  This update will also make this version of the .NET Framework Assistant for Firefox compatible with future versions of the Firefox browser, whatever that means.  To properly update the .NET Framework Assistant, this update must be applied while the extension is enabled in Firefox."  And it goes blah, blah; it goes on and on.



So, once again, we have a URL where Firefox users can get this.  It is support.microsoft.com/?kbid, as in knowledge base identifier.  So it's ?kbid=963707.  So again, support.microsoft.com/?kbid=963707.  That will get you to a page where you can do a number of things.  You can manually edit the registry.  They've got all kinds of different ways of rummaging around and making this happen.  But there's...



LEO:  No automatic "Fix it" button, I notice.



STEVE:  Yeah, there's not the happy little guy with the tool waving at you.



LEO:  Sorry, you can't do that.



STEVE:  However, what this will end up doing is disabling the disablement, which is to say reenabling as it - now that they've been scolded, you can reenable the uninstall and then say thank you, Microsoft, but I would prefer not to have Firefox able to easily install software in my machine so that I'm not inconvenienced with the question.



LEO:  This is unconscionable.  I can't believe this.



STEVE:  Yes.  Yes.



LEO:  I'm stunned.



STEVE:  This is bad.



LEO:  How dare they?



STEVE:  Yeah.



LEO:  In fact, this is exactly the kind of thing that they've been brought to task for by the Department of Justice and the EU.  I mean, it's one thing to say, well, you have to use Internet Explorer, we'll going to include Internet Explorer; anther thing to modify other browsers that you use on the system to make them less secure.  Am I correct?  This makes it less secure?



STEVE:  Yes, that's exactly what it does.  And which is why Brian Krebs, when he, like, I guess a couple people brought it to his attention, and he said, huh?  And he looked at it and did the research, and it's like, oh, goodness, I mean, this is really, really bad.



LEO:  That's unconscionable.



STEVE:  And this is - Microsoft has worked to build our trust in the whole Windows Update facility.  I mean, as I said, you either trust them or you don't use Windows because we've given up control.  They're downloading code and dunning us and punishing us and with red flashing lights and things if we try to take control back from them.  And it's funny because a friend of mine this morning at Starbucks came to visit and says, so, are you on IE7?  I said, oh, yeah, for quite a while.  And he says, oh, I guess - so you've made peace with it?  I said, well, the only time I ever run it now is to run Windows Update.



LEO:  Right.



STEVE:  I mean, I'm completely converted to Firefox with, like, zero trouble.  So, I said, so kind of.  I mean, it's on my machines; and 8 is sort of filtering in to my machines as I think, well, okay, why not?  I mean, I'm not using it anymore, so I don't care if Microsoft wants to push IE8 on my machines.  Fine, you know, it has no effect on me except for running Windows Update, which insists on running under IE.



So, yeah, Leo, I agree.  This is, I mean, this is a breach of trust.  The fact that this was slipped in, that it is a software installation shim for Firefox so that their .NET Framework is able to be more pervasive and to run on more websites.  And so that website owners are not going to say, well, I'm not really going to update or start using that because, after all, Firefox doesn't support this.  Well, Microsoft slipped this in so that it does, even if it's not what the end-user would want.  And so anyone with Firefox, if you look at your add-on list, and you've been keeping your Windows current, you'll see this thing sitting there, and its uninstall button is grayed out, preventing you from uninstalling it until you go here, reenable the button, then you can say thank you, but no, Microsoft.



LEO:  Now, what do you lose, just out of curiosity, if you do that?  I mean, is there anything that I need this .NET bug for?  Is this the Click Once thing?



STEVE:  Well, that's what it is.  And the question is, I mean, you can think of it as, like, super-advanced scripting.  The question is, for example, and we discuss this often here, what do you lose if you disable scripting?  Well, you lose some functionality that may or may not be something you care about losing in return for increasing your security.  So hopefully - I don't know what.



LEO:  I mean, is there - okay.  Yeah, well, for one thing, yeah.  There's no question this was a stupid and wrong thing to do.



STEVE:  Yes.



LEO:  I mean, there's not a question about that.



STEVE:  Without permission.  They could have, I mean, look at all the things we do have to give permission for.  Every time Microsoft does something, we're having to reverify our license.  Yes, I reassert my compliance to your EULA.  I mean, often we're being asked to recertify that, yes, we're going to abide by these license terms.  It's certainly not out of the question to imagine that Microsoft might say,  hey, we want to - we're updating the .NET Framework.  It's becoming more pervasive.  It's the future.  So we want to bring Firefox, which we happen to notice you have on your Windows machine for some reason, we want to bring it into compliance and make sure that things stay synchronized and the functionality that we hope you've become dependent upon will also be present in Firefox as it is in IE.  So do we have your permission to do this?  I mean, all they had to do was ask.  And then people could have said, oh, yeah, I guess I should have that, or not.



LEO:  Do you think this is a case of - clearly what Microsoft thinks, I'm trying to put myself in their head, is this is too complicated for our users.  We're just going to make this decision on their behalf.  And we're not going to explain it because even explaining it is too complicated.  So we're just going to do it.  We know what's best.  We're not causing a problem here.  You've trusted us to run your system, so we're going to just do this.



STEVE:  I mean, yes, you can certainly say that, hey, you know, trust us or leave.



LEO:  Right.  I mean, well, you have to.  I mean, that's - that's the deal.



STEVE:  Yeah.



LEO:  Oh, I just think that stinks.  Now, some people have said this is anti-competitive, as well.



STEVE:  I have to imagine that there was a conference of some length at Microsoft where they decided to do this.  I mean, I hope this wasn't something that they did thoughtlessly.  So following your logic, Leo, there must have been the argument made that this is something that was in their and their users' best interests to pursue.  I don't know enough about the architecture of Firefox's innards to know whether they had a choice of making this visible on the surface of the UI or not.  They may have had no choice.  They may have preferred to just sort of slip this in as they do in IE, secretly.  But it may be that the architecture doesn't allow them to do that, that they weren't able to just deposit this somewhere and have it take action without being visible on the surface.  Or they may have felt, shoot, you know, once that's discovered we'll be in even bigger trouble.



So it would have been nice to be asked, and it certainly would have been nice not to have the uninstall button grayed out.  Or, if you click it, have them then present a dialogue that says, whoa.  You can uninstall this if you want to, but here's what you lose if you do.  Instead it just - it appears magically.  It's about installing software into your system without you, making it easier to do that.  And we're not going to let you take it out.



LEO:  Now, I have Firefox installed on my Vista machine, and IE8 installed, and I'm looking in the add-ons.  And I don't see anything.  I do see some Microsoft stuff, the Windows Presentation Foundation and Silverlight.  I think I installed those.



STEVE:  In Firefox.



LEO:  Yeah.  Mozilla Default Plug-in, Java Platform, iTunes.  It says .NET in the name of it?



STEVE:  Yes.  And I definitely...



LEO:  I've seen it on some of my browsers, I mean, some of my systems.  But I'm just looking at my Vista system here, and I don't see it.  And a couple of people in the chatroom said, well, I don't see it.  So I wonder what circumstances - or maybe you have to download a...



STEVE:  Okay, I'm looking at it.



LEO:  Oh, wait a minute, it's in extensions.  I'm sorry.  It's not in plug-ins.



STEVE:  Correct.



LEO:  I do see it.  Ah ha.



STEVE:  Correct, it's extensions.



LEO:  I was looking in the wrong place.  As Click One Support.  There's no disable button.  There's a disable button, but no uninstall button.  So I could disable it, but I can't remove it.  Prompt once before running Click Once.  Report all installed versions.



STEVE:  Now, that's interesting.  Mine is disabled.  I must have done that.  I had forgotten.  Because I'm seeing my Enable button is enabled, and the little popup toolkit says "Enable this add-on when Firefox is restarted."  And so I had clearly disabled it, saying - seeing it and saying I don't think I want this, thank you very much.  And so, and I restarted the system, and now it's sitting in there.  It's not removed.



LEO:  It's not uninstallable, but it is disabled.



STEVE:  Exactly.  I can not uninstall it, but I did disable it in the past.



LEO:  Very interesting.  I don't - regardless, I mean, I guess maybe Microsoft said, well, you can disable it.  But I don't want them installing it.



STEVE:  Yeah.  I mean, and we can be grateful that this came up, that they've certainly, whatever decision they reached around the conference room, the discussion that I hope they had, they may recognize now that they went too far, and they won't do something like this again.  So we can hope that they learn from it.



LEO:  Yeah.  It does seem unconscionable.  You know, there's supposed to be - maybe that's expired.  But after the terms of the settlement with the Department of Justice, Judge Colleen Kollar-Kotelly I remember required a judge-appointed ombudsman in Microsoft, maybe even a committee, watching what they do to make sure they don't do anti-competitive things.  I wonder if these people are paying any attention at all.



STEVE:  Well, I did pick up a little news blurb earlier this week that the EU is not through with Microsoft.  They're gearing up, or teeing up, on Microsoft.  Apparently what they're considering is requiring Windows to include competitive browsers.



LEO:  They're requiring Windows to include competitive browsers.  Wow.



STEVE:  Literally Firefox and Opera...



LEO:  Have it built in, good.  I think that's not a bad idea.



STEVE:  And so what would happen is, when you first turn Windows on, they call it a "ballot screen."  It comes up, and it says, which of these browsers do you wish to install, and which do you want to set up as your system default?  So the EU would be requiring that users who are first turning their machine on in that initial sort of pre-usage configuration phase are actually given a choice, and the browsers are present, and you can choose to install any of them that you like, and choose which one you want to use.  And so they're talking about moving much further than they did in their prior work of requiring Microsoft to unbundle the media player.



LEO:  Ken Shepardson's saying in our FriendFeed chat room that to decouple the Microsoft-is-bad stuff from the security stuff, well, here's the security issue.  I mean, they're installing something into Firefox that allows a website to automatically install software on your machine; is that correct?



STEVE:  Yes.



LEO:  Okay.  That seems to me on the surface of it that that's a security issue.



STEVE:  And that's why - and my complaint is it's why people left IE.



LEO:  In the first place.



STEVE:  I mean, you have to leave IE.  You don't - you're using Firefox because you went to Mozilla.org and got it, and you know why you're using it, and it's a little bit uncomfortable because you have to go back to IE for Windows Update and doing things that only Microsoft will allow to happen under IE.  So it's like, this is a conscious choice people are making for some reason, probably because they've decided they don't trust Internet Explorer.  So here it's Microsoft reaching over into that decision and saying, eh, not so fast.  And then I have one little bit of errata.



LEO:  Yes.



STEVE:  And you probably know this, too.  Amazon has indicated that my Kindle will arrive next Thursday.



LEO:  Oh, that was fast.



STEVE:  Yes, June 11th, the new DX, the big...



LEO:  Now I'm jealous.  Now I'm jealous.



STEVE:  So I won't be able to wave it in front of the camera, Leo, for next week's recording on Wednesday.  But the 10th, next Wednesday, is the release date.  And so they estimated delivery for the 11th.



LEO:  Wow, that was faster than I thought it was going to be.  I mean, I got the impression it would be a few months.



STEVE:  Yes.  I'm excited.



LEO:  So now your Kindle will be bigger than my Kindle.



STEVE:  Then I have a real PDF reader, more than anything else.  I mean, for the first time ever.  Because I'm busy printing paper all the time, printing PDFs.  And that's just - that's not why...



LEO:  I have to admit, I'm...



STEVE:  That's old school.



LEO:  I'm intrigued because more and more I'm reading books on the Internet, programming documents, that kind of thing, as I'm sure you are.  And that would be really nice to have that slightly larger form factor and the ability to put the PDFs on there.



STEVE:  Yeah, I mean, what you said stuck in my mind.  That is, it's the convenience of the smaller size Kindle, being more paperback size, being able to carry it around easily; whereas this is more of a slate.  It's like, yeah, we'll see how that is.  Because, I mean, my feeling is I like the larger real estate when I'm reading.  Seeing more text, paging less often, maybe scaling things, using a larger font in dim light and still being able to have plenty of text on the screen.  So anyway, in two weeks I'll be able to wave it in front of the camera and tell our listeners what I think about it.



LEO:  Woohoo.



STEVE:  And I had a really neat SpinRite testimonial lined up, and I don't know where it went.



LEO:  [Laughing]



STEVE:  I mean, I have a whole file of them.  But I thought, ah, well, what the heck, I mean, our listeners all know that SpinRite leaps over tall buildings and is faster than a speeding bullet and so forth.  So there's my - we'll do the non-testimonial testimonial.  We'll skip it for this week because everyone's probably thankful to have a week off from SpinRite testimonials.



LEO:  You're preaching to the choir anyway.  We all know it's the best.



STEVE:  It does work.  It does the job.



LEO:  I recommend it.  I recommended it twice on the radio show this past weekend to a couple of different people.  I mean, it's interesting, and I guess this is probably a symptom of the fact that these hard drives are getting so much bigger.  But I get more and more hard drive failure-sounding questions.  Oh, you know, when I try to run this program it takes a really, really long time, and it finally starts, and little things like that, that really sound like bad sectors.



STEVE:  Right.  So if the drive is being very patient, it's retrying and retrying and going around and around in circles, and is getting a sector at a time, reading very slowly, that's a perfect example of something that SpinRite would just make quick work of.



LEO:  That's what I said.  I said, well, you just run SpinRite.  It'll move.  It's more persistent than the operating system.  It'll get the data if it's at all possible.  Even if it takes days, it'll get that data and move it to somewhere safe and then mark that sector bad and unusable.  And that's really what you want.



So we both got this book, and I'm really excited about this.



STEVE:  Well, I didn't know that you knew the author, Leo.



LEO:  I've known him for a long time, probably because of our connection because he's a regular in your forums.



STEVE:  Well, he is.  And what happened was about a month ago I got this polite piece of email from John Graham-Cumming, who I've known through the newsgroups for years.  I may have referred to him before, back in the Perfect Paper Passwords era, because he was one of the people who wrote a very nice, high-tech implementation of the Perfect Paper Passwords algorithm for a particular platform.  And I've sort of forgotten which one now.  But so, I mean, but he's always contributing and knowledgeable, and I've just appreciated his presence.



And so this email said hey, Steve, would you - and I'm paraphrasing - would you mind if I posted a note in the newsgroups about my forthcoming book?  And I said, what forthcoming book?  Well, it's a book called "The Geek Atlas."  And it is, essentially, it is describing 128 - and of course I love that, you know, it's 2^7, it's not 100 or 150, it's 128 - locations around the world of technical and historical geeky interest.  And what I really like about it is that, well, in fact what I should do is, let me just read, or, yeah, read for our listeners the review that I wrote which I have posted at Amazon.  Because the book is now available.  It's called "The Geek Atlas."  And it's less than 20 bucks.  It's 19 something or other...



LEO:  What's nice is it's like one of those guidebooks, you know, it's like a - it has lay-flat binding.  I mean, it really is like a guidebook.



STEVE:  Well, and it's published by O'Reilly, so it's got that standard O'Reilly feel to it.



LEO:  Oh, yeah, nicely done.



STEVE:  And so what I wrote was:  "This terrific book first came to my attention when its author politely asked whether it would be okay for him to mention it in the technical newsgroup forums my company hosts.  I had known of John through his many years as occasional contributor in our forums, though I knew nothing of his being an author.  Little did I know.  Now, I have a copy, and I love it.  When I take it with me to coffee, other regulars who have seen it before grab it if I'm reading something else.  We all love it because it is so accessible.  And these are people who are not nearly as geeky as I am.



"Opening the book to literally any page pulls you immediately in.  Even if you're not a traveler - I'm definitely not - the book is a compendium of bite-size worldwide technical history of innovation and invention in gratifying detail.  No single topic is more than four pages long, so you can read many before your coffee gets cold.  And you may be ordering a second cup because this book is difficult to put down.  You can read by region or scan the table of contents for anything that looks interesting.  The Escher Museum in the Netherlands, the Experimental Breeder Reactor No. 1 in Idaho, the Arecibo Observatory in Puerto Rico, the Mendel Museum of Genetics in the Czech Republic, and 124 other notable places and times where something geeky and technologically important happened.  I used to wonder how and where the speed of light was first measured.  Now I know.



"John has filled the pages, not only with a discussion of interesting brief historical notes, but also with his own diagrams and explanations of every principle and discovery.  He has a direct, straightforward and clear writing style.  And best of all for geeky readers like myself, he clearly knows what he's talking about, unlike some authors who are disconcerting because you sense that they're not sure of their facts."



LEO:  Right.



STEVE:  "You won't find any of that here.  The technical content is precise and will satisfy the geekiest among us.  This book would be a bargain at twice Amazon's price of only $20, so think about getting two.  Even if you're not a geek, you'll love this, really.  And I'll bet you know a geek who would value this just as much."



LEO:  Yeah, I agree that it's much - it's great because it's more than a guidebook because you're learning the science or the principle or how Enigma worked and that kind of thing.  And so, I mean, look at this, it's got the ideal rocket equation when you go to White Sands Missile Range Museum.



STEVE:  I know.



LEO:  I mean, that's great.



STEVE:  And, like, details about Foucault's Pendulum that is swinging from the - is the Pantheon?  I think it's in France.  And, I mean, there was an impulse rocket engine that I was reading about this morning.  And, I mean, anywhere you pick it up, it's like, oh, wow, I didn't know that.  Anyway, I just - I think our listeners would get a kick out of it.  If it sounds like something from our description that you would like, my guess is you will like it more than you imagine you would because it's, I mean, it's really nicely done.



LEO:  It's really, it's fascinating.  I don't - you don't even have to go to these places, just to read the book.



STEVE:  I'm not going.  I'm just reading the book.



LEO:  Yeah.  Although it'd be fun to kind of make a geek tour and go to all of these places.



STEVE:  Yes.  John is clearly a traveler because, as I was mentioning to you before we began recording, he'll say in there that, well, and if you stand on this mound and look to the northwest, you can - it's like, okay, well...



LEO:  He was there.  He was there.



STEVE:  ...this guy is traveling around and picking up all of these interesting tidbits.  But again, it's not just about travel.  It's as much, for me, about history of technology, written by somebody, a serious techie, not a writer who's trying to water it down.  I mean, there's - it's full of diagrams and explanations of stuff.



LEO:  It's interesting, boy, I wonder if he's been to all these - I guess he has been to all these places.  



STEVE:  It reads like he...



LEO:  Yeah.



STEVE:  It reads like he's been there.



LEO:  This is a labor of love.  I mean, this must have been a book that he's been working on for years, I mean, to go to all these places.  Really cool.  I mean, this is one of those obsessive things that only a geek could really do justice to.  I love it.  I mean, here's Eiffel's diagram of the Eiffel Tower.



STEVE:  Exactly.  I just opened "Galvanic Corrosion and Cathodic Protection:  The ability of batteries to make electricity by immersing two different metals in an electrolyte.  See page X."  It's very, oh, and, see, I have a pre-release proof copy, so they didn't fill the page number in.  But...



LEO:  Oh, I have it, yeah, yeah, yeah, I have them.



STEVE:  It's very useful.  But "Metal objects can accidentally become batteries and end up corroding.  This galvanic corrosion is a problem for everything from the Statue of Liberty to a ship's rudder.  And pipelines are particularly vulnerable because of their size.  The problem can even occur when only one type of metal is present because of slightly differing compositions of the same base metal."  I mean, this is really good stuff, Leo.



LEO:  Yeah.  I'm going to send a copy of this to my father-in-law.  He was a science teacher in high school.  He doesn't travel much anymore.  But he would love the material in this book, I think,.



STEVE:  "For example, the Statue of Liberty is made from a copper skin with an iron structure.  When Gustave Eiffel built the statue, he anticipated that galvanic corrosion would be a problem.  So he insulated the copper and iron from each other using the natural plastic shellac.  See page" - again blank.  Who knows what that one talks about.  "Over time, the shellac insulation gave way, and between the metals an electrolyte - moist, salty marine air - was able to create a simple battery."  And it goes on.  I mean, it just is, I mean, it's a technical atlas as much as anything else.  I mean, and then it all ties in to places all over the world where these things happened.  Oh, here's Bletchley Park; and here's Instrument Landing System, ILS, British Airways flight training in Hounslow, England.  And so we've got little icons for it looks like there's hotels nearby, and then GPS coordinates for everything, and how ILS works, which I never knew.



LEO:  Oh, yeah, that's interesting.



STEVE:  The localizer and the glide...



LEO:  You should know how it works.  You've got a couple of ILS computers there.



STEVE:  That's true.



LEO:  You might be called into service at any moment.



STEVE:  Bunhill Fields Cemetery in London, England.



LEO:  This is so geeky.  I love it.



STEVE:  Oh, it's Bayes' Theorem.



LEO:  Yeah, because he wrote...



STEVE:  Talking about Bayesian.



LEO:  He wrote POPFile.  I used POPFile for a long time.  I don't use it anymore because I use Outlook.  But it was a great - actually I guess it worked with other programs, too.  But it was a great Bayesian antispam filter.



STEVE:  "Bayes' Theorem gives mathematicians a way of updating a probability when new information comes along.  For example, say that 70 percent of the pupils in a school are boys, and 30 are girls.  The girls have a choice of uniform, trousers or skirts, and the boys just wear trousers.  If a mathematician encounters a pupil at random, then he knows that the chance of the pupil being a girl is 30 percent.  Now suppose the mathematician, who is deep in thought and staring at the ground, only notices what's covering the pupils' legs.  If he sees a pair of trousers, he can calculate the probability that the pupil is a girl using Bayes' Theorem.  He's updated his original estimate, which was 30 percent, based on new information, and comes up with the answer of 18 percent."  I mean, anyway, this just - it's, like, full of stuff like this, just really interesting.  Oh, here's Hooke's Law and Clocks, which is how the escapement works, where, you know, you have a swinging pendulum.  And the escapement, every time the pendulum swings the little disk, the ratchet moves one notch; but in the process it also powers the pendulum?  So here it's got - we have two pages on all that.  It's just - oh, here's Chernobyl.



LEO:  I know, there's some really - there's a picture here of the hammer and feather experiment that Apollo 15 did on the moon, to see if Newton - was it Newton? - was right that - oh, I just love this stuff.  I just love this stuff.



STEVE:  Yeah.  And so here on the page after Chernobyl, it's potassium iodide and the thyroid.  And so what it is about potassium iodide.  "One of the immediate dangers after the explosion was the presence of radioactive iodine in the food system.  Radioactive iodine, iodine-131, is produced in nuclear reactors in normal operation as a product of the fission of uranium-235.  The uranium-235 breaks apart when its nucleus is hit by a neutron, releasing energy and creating new elements from the split-apart atom.  The elements typically created when uranium-235 breaks apart in a nuclear reaction are cesium, iodine, zirconium, technetium, strontium, promethium, and samarium."  And this goes on.  So, oh, my goodness.  Anyway, like I said, it's hard to put down.



LEO:  It is.



STEVE:  Just full of cool stuff.



LEO:  What a great idea.



STEVE:  So I wanted to bring it to our listeners' attention.  I did post in the newsgroups to bring it to our newsgroups' attention.  And I wrote that review that I read for Amazon since.  And John...



LEO:  Galileo, not Newton.



STEVE:  Shortly after I posted he says, "I'm speechless with gratitude."  And I said, "John, look at the work you put into this thing."  I mean, this is an amazing amount of work.  So he's earned...



LEO:  Yeah, props to John, absolutely.  And it is Galileo, of course, who dropped the cannon ball and the feather off the...



STEVE:  Off the Leaning Tower of Pisa.



LEO:  Leaning Tower of Pisa, yeah.  Not Newton.  Thank you, Dr. Mom.  All right.  So that's item one of our trilogy.



STEVE:  Yes.  Number two is IPv6.  We're now using, and have been since the beginning, IPv4.  And in fact in the first four bits of the header of every packet traversing the Internet gives the version number so that software that receives the packet knows what to do with the rest of the bits in the packet, the idea being that the first four bits say I'm an IPv4 packet.  And so then the software says, ah, good, in that case I know what all the other bits in the IP header layout are, and I know how to process them.  If the packet came and said, hey, I'm IPv5 or something - which actually is a streaming protocol that was developed related to IPv4, and that's why it's not available; and the guys at the IETF who were standardizing on the next-generation protocol, they had to jump over 5 and call this one 6.  If the packet said, hey, I'm v6, today our hardware would go, or most hardware, huh?, and just abort.



LEO:  Oh, dear, that's not good.



STEVE:  Well, no, I mean, because - well, okay.  So here's what's happened is people from time to time ask me, and I was asked yesterday, if the DNS benchmark program that I've been working on, laboring on for the last many months, which is always almost done, and we're always closer to being almost done, if it would be supporting IPv6.  And it sort of makes me just sigh because it is - IPv6 is still so far away that I want to say it doesn't matter.



Now, there are some instances where it does.  For example, it turns out that if your stack in your Windows machine is configured for IPv6, then, for example, it'll emit IPv6 DNS queries.  I guess my issue is that this doesn't affect end-users today.  That is, the whole IPv6.  So, for example, yes, on a server-side platform like the spoofability tester, it's necessary for me to be able to accept queries in IPv6 format.  But this is not affecting end-users today.



And it's not clear to me, I mean, ever is a long time.  But the whole reason IPv6 was created, the fundamental motivation was a concern for the depletion of IP space.  We know IPv4 has 32-bit Internet addressing, 32-bit IP addresses.  And that gives us 4,294,967,296 different IPs.  Now, what's significant in my mind is that today, in 2009, fully 40 percent of those IPs are not even in use.  They're, like, remember Hamachi uses the five-dot block of IPs?  Because they're non-routable.  No one is using them.  Somebody has them.  But they've never been used.  So there's, right there, 16 million IPs that are available, but no one's using them.  And there's a whole bunch of other Class A network regions that are the same.



And, for example, there are universities who were early into the game, who got themselves a Class A network, meaning 60 million IPs.  And they're not using them because they're assigning their students NAT-based IPs, Network Address Translation-based IPs.  But they're jealous of this IP space.  It's sort of a nice thing for them to have.  They'd rather not give them back.  So instead we're basically changing everything on the Internet.



And, I mean, the reason I'm of two minds about IPv6 is, first of all, it has no effect for anybody today.  It's not clear to me that in another 10 years it will.  It's already 10 years old.  This spec was ratified in 1998.  And so it's been 10 years.  And there's some deployment of the so-called "6bone," the IPv6 backbone.  Normal people have no access to it.  There are services that will allow you to create a tunnel through IPv4 to get to it.  So you're able to, if for some reason you want to mess around with IPv6, access that 6bone.  But there's not much there at the moment because it's not necessary.



I mean, so what happened was that we started this when there was a concern for, like, exponential growth of IPs on the Internet.  But the solution turned out to be NAT.  So what's happened is that the emergence of Network Address Translation has essentially solved the problem completely, in a way which is compatible completely with everything we have now.  For example, many people have networks where they've got a little switch.  You know, it used to be hubs, then we went to switches.  Well, none of those can work on IPv6 because the switches, as we've discussed in ancient history on this podcast, build a table of IP addresses, and they memorize which IP is connected to which port of the switch.  Well, all of that is in hardware, and all of that is IPv4.  So that won't work.  Maybe you could flash, someday flash the firmware on your router in order to be v6 aware.  Right now, routers mess up IPv6 packets completely.  They drop them, or they don't even return an error message typically.  They don't know what to do.  And that causes connection delays for anybody who's receiving these wacky packets, if you're even able to get them.



So when someone says, oh, well, does this - and I know I've kind of got myself worked up into a rant here.  But I get the question enough that I just thought it was worth taking some time to say, wait a minute.  I recognize I'm a little bit of a Luddite here.  I never went to Vista.  I'm still on XP.  It'll be a year before I go to Windows 7 because I want to let it mature.  When IPv6 matters, then it would make sense certainly for the things I'm doing in network space to be IPv6 aware.  Certainly when I'm writing CryptoLink I'm going to anticipate that hopefully, over that product's long life, people may be in some place where they need IPv6 compatibility.  So I will design 128-bit addresses, that is, an architecture that supports IPv6 from the beginning for that product.  But for any kind of application today, IPv6 is just not here.  Some statistics are interesting.  Believe it or not, Russia has the highest percentage of IPv6 penetration.



LEO:  Really.



STEVE:  And they're at 0.76 percent.  So less than 1 percent of machines in Russia are IPv6.  Then falling down from there is France at 0.65, the Ukraine at 0.64, Norway at 0.49, and the U.S. at 0.45.  China is even, that is talking about being a big IPv6 deployer, is at 0.24.  Because there are so many machines, their numbers are high.  But as a percentage it's less than a quarter of 1 percent.  So it's just not happening.



Now, I know that our listeners are very privacy and security aware.  So get a load of this, Leo.  The 128-bit address is divided into two 64-bit pieces, a network number and a host ID.  Now, we've talked about how IPv4 addressing works.  Once upon a time you had this notion of Class A, Class B, and Class C networks, where the idea was you have a 32-bit IP address which is four bytes.  So in a Class A network the first byte is the network number, and the other three bytes is the host within that network.  So somebody who had, like, a four-dot IP would have four bytes, and then all the other bytes below that in a Class A network would be part of that network.  So you could have, as I mentioned, 16.777 million hosts under that Class A network.



Or you could divide the bytes differently.  You could have the first two bytes would specify the network, and the second two bytes the host.  That's a so-called Class B network.  And there you can have, since you've got two bytes or 16 bits, we know that that's 64K or 65536 hosts, and the same number of Class B networks potentially if all of those were available.



Or you could have a Class C network, which is, frankly, well, for example, everyone who's running behind a NAT router, a typical consumer NAT router, you know, the 192.168.0.something, that's a Class C network because it's the last byte.  So where you have 256 possibilities, you lose the first and the last IP within the network, so it's 254 actual machines can be within that network.  So that's a Class C network.

Well, the reason we had to sort of fudge those so that there's now what's called CIDR, C-I-D-R, Classless Inter-Domain Routing, what that allows is for the boundary, instead of just being on byte boundaries, to be on any bit boundaries.  So, for example, my connection at Level 3, I have a small block of 16 IPs and another one of 8 somewhere else.  But so I don't have a block of 256.  They slid that boundary down, so I've got the last four bits of my IP block that specifies different machines within my little 16 IP space.  Bizarrely, here at home I've got 64 IPs, thanks to my history with the guys from Verio, who then moved over to Cogent.  So but then again, it's not 256, it's 64, so that barrier is able - you can slide it up and down in order to economize on the allocation of IPs.



So, for example, if we only had the division, for example, of a Class C, then the minimum network, the minimum block of IPs you could give someone would be 256.  Instead, by sliding that boundary down lower, I can have my 16 IPs on my little network.  Somebody else can have 16 right next to mine.  And we're not on the same network.  We're on separate networks.  So that's the advantage of the so-called Classless Inter-Domain Routing, CIDR.



Well, when we went to IPv6, all of that problem went away because now we've got - or when we go to IPv6, or when we went to the specification of IPv6, I should say, because it hasn't really impacted the world yet.  Now we've got 128 bits to work with.  So they say, oh, okay, let's dispense with all of this, the whole Class ABC nonsense.  That's gone.  We're just going to chop it in half.  The high order, the highest 64 bits is the network.  The lowest 64 bits is the host on the network.  Now, understand that 64 bits for the host means you've got - we used to have 32 bits for all the IP addresses on the Internet.  Well, we do now under IPv4.  So this is that number squared, four billion squared hosts.



LEO:  That's enough.



STEVE:  That's plenty.



LEO:  Somebody, I think it was Vint Cerf, said that would be an IP address for every, what is it, molecule in the universe or something like that.



STEVE:  Oh, it's ridiculous.  It's like...



LEO:  It's plenty.



STEVE:  I read somewhere it's 2^54 IPs for every star in the sky.



LEO:  Well, there you go.



STEVE:  So, I mean...



LEO:  That's enough.



STEVE:  Again, these numbers get big when you start adding bits to them.  I mean, they get big fast.  But there's a little problem because the guys who designed this protocol said, well, how are we going to assign IPs to machines?  And they said, well, we'd like to make them unique.  So why don't we base it on the MAC address?  So...



LEO:  That seems sensible.



STEVE:  Well, it's sensible except that the MAC address doesn't change.  Remember the MAC address is a 48-bit quantity.  The high 24 bits is the manufacturer of the network adapter's ID.  The low 24 bits is a serial number for that manufacturer, that is, within that manufacturer.  So you concatenate those, and you get a 48-bit quantity which is guaranteed to be unique in the world.  So they said, well, that'll just be perfect.  We'll just use that as the host identifier.  The problem is that doesn't change.  And that's your IP which you reach out over the Internet with whenever you use IPv6.



LEO:  Okay.



STEVE:  So it is a super cookie.



LEO:  Right.  It's really identifying you.



STEVE:  There's a huge, yes, it's identifying that machine indivisibly.  So everyone said, okay, that's a problem.  So there's an RFC called 3041.  And I've got it in front of me.  I'm going to read a little bit of it just so you can understand what the problem is.  So reading from RFC 3041, it says:  



"Nodes use IPv6 stateless address autoconfiguration to generate addresses without the necessity of a Dynamic Host Configuration Protocol" - DHCP that we've talked about often - "server.  Addresses are formed by combining network prefixes" - that's the first 64 bits - "with an interface identifier.  On interfaces that contain embedded IEEE identifiers" - that's the MAC address - "the interface identifier is typically derived from it.



"The division of IPv6 addresses into distinct topology and interface identifier portions raises an issue new to IPv6 in that a fixed portion of an IPv6 address (i.e., the interface identifier) can contain an identifier that remains constant even when the topology portion of an address changes (e.g., as the result of connecting to a different part of the Internet).  In IPv4, when an address changes, the entire address (including the local part of the address) usually changes.  It is this new issue that this document addresses.



"If addresses are generated from an interface identifier, a home user's address could contain an interface identifier that remains the same from one dialup session to the next, even if the rest of the address changes.



"A troubling case concerns mobile devices ... that move topologically within the Internet.  Whenever they move ... they form new addresses for their current topological point of attachment.  This is typified today by the 'road warrior' who has Internet connectivity both at home and at the office.  While the node's address changes as it moves, however, the interface identifier contained within the address remains the same....  In such cases, the interface identifier can be used to track the movement and usage of a particular machine.  For example, a server that logs usage information together with a source address is also recording the interface identifier since it is embedded within the address."  It's the lower 64 bits of the address.



"Consequently, any data mining technique that correlates activity based on addresses could easily be extended to do the same using the interface identifier."  So it's like everyone on the Internet had a permanent IP address that never changed as you moved around, and it was used to identify you.  So anyway, continuing, it says:



"This is of particular concern with the expected proliferation of next-generation network-connected devices (e.g., PDAs, cell phones, etc.) in which large numbers of devices are in practice associated with individual users (i.e., not shared).  Thus, the interface identifier embedded within an [IPv6] address could be used to track activities of an individual, even as they move topologically within the Internet.



"In summary, IPv6 addresses on a given interface generated via Stateless Autoconfiguration" - which is the default case, that is, not using DHCP - "contain the same interface identifier, regardless of where within the Internet the device connects.  This facilitates the tracking of individual devices (and thus potentially users).  The purpose of this document is to define mechanisms that eliminate this issue in those situations where it is a concern."



So what RFC 3041 does is introduces a way of randomizing this lower 64-bit identifier that would otherwise be static.  The good news is, it exists in Windows and is enabled by default.  But a command can turn it off.  And if it's turned off, you don't know it.  You just start generating a fixed cookie, a fixed IP address.  You know, "net sh" is a command, "space int" for interface, "space IPv6," and then it's "set privacy disabled."  You give that command, or something in your machine gives that command, and your IPv6 system starts now using an IP that never changes, rather than changes normally.



And, although I haven't looked at it closely, because again this isn't a big concern for me yet, apparently other operating systems which are IPv6-enabled do not have this RFC 3041 support enabled by default.  Windows, thankfully, does.  But other OSes don't.  So there are concerns associated with IPv6 that users are going to have to address.  And notice that it says this is a problem when we don't have, for example, DHCP.  Well, when you do have DHCP assigning addresses, for example, in a NAT network, none of this is a problem.  And IPv6 is unnecessary.



So anyway, I just sort of wanted to address the issue.  It comes up from time to time, people saying, oh, you know, as if it's this great solution to, I think, a problem that we don't have; and, due to the way it's been implemented, it introduces some interesting new problems for security and privacy.



LEO:  Yeah.  I had no idea.  You know, I've been - Vint Cerf came on The Screensavers many years ago, really pushing v6.  He's been one of the people who's been pushing v6 very hard.  And at the time, of course, we were very worried that we were running out of addresses.  And as you pointed out, this has all changed thanks to DHCP and widespread use of routers.



STEVE:  Yeah, exactly.  The ability to use NAT, which is 100 percent IPv4 compatible, it's completely changed the game.



LEO:  Yeah, right.



STEVE:  So that this just isn't a problem.  And even now we're still using - we still have huge chunks of IP space unused.  I mean, all we have to do, and I'm sure there's mechanisms for doing it, is to go to people who are squatting on unused Class A networks and say, okay, give 'em up.



LEO:  Right, right.



STEVE:  We're de-assigning these to you for the good for the world.  Because you're not using them; and, guess what, you don't need them.  So the world has changed since back then.



LEO:  All right, Steve.  Non-VPN, what the heck are you talking about, dude?



STEVE:  Well, okay.  You know I've been spending a lot of time at Starbucks, where our listeners come by and say hi and introduce themselves, which is always fun.  And I've been using OpenVPN to post updates to the DNS benchmark at GRC, and sometimes to get to my network here at home if I need a file.  And one of the problems is that, if I've got an established connection - for example, I've got my news reader that's connected to the news server at GRC, and it's connected through the Starbucks hotspot to the Starbucks router and out to the 'Net.  Well, if I bring up the VPN tunnel, the news reader starts to complain because I've disconnected it.  I've basically put an enclosure around myself saying that I'm now suddenly participating in this remote network.



Well, I've understood that that's a problem.  And so I've always had in my own planning for CryptoLink this notion of what I call, for lack of a better term at the moment, my working term is "full enclosure" or "partial enclosure."  The idea being that the way OpenVPN, for example, and as far as I know all other VPNs work, is that the machine is completely enclosed and is participating as a peer on the remote network.  Which is useful, but sometimes it's not what you want.  And so for CryptoLink I've sort of identified a feature that I believe will make it unique, which is a partial enclosure where you can designate specific remote locations whose traffic will be routed through the VPN tunnel, and others that won't.



Now, in theory you can do that with OpenVPN because you're able to modify the routing table to determine what's routed through the VPN interface and not.  But that gets into some pretty hairy rocket science.  And of course I'm going to make this a lot easier.  But the other problem is there's still the weight of this sense of, like, bringing up a tunnel, like doing something to establish a connection that all VPNs have.  And what's occurred to me, and I just sort of wanted to share conceptually with our podcast listeners, is there's an alternative approach which I'm really intrigued by and which I may implement, I'm not sure, which is a non-VPN solution which is every bit as secure as a Virtual Private Network solution.  And it solves a bunch of problems in a way that I'm intrigued by because I'm coding everything in Assembly language, implementing protocols myself.  I really - what drives me is lightweight solutions, minimal solutions, something that works, doesn't get in the way, and there's no baggage.  There's nothing extra.



So what I'm wanting to do when I'm at Starbucks, for example, and this applies to any or many telecommuters, certainly there's an application where you need to be on your corporate infrastructure, that is, you need to use a VPN to participate as a peer on your - like to be as if you were at your desk in your corporation.  For example, a corporate mail server that maybe you only can get to if you are on the inside, and the VPN allows you to simulate being on the inside.  But for many users, like Windows users, for example, something that works very nicely is file and printer sharing.  I know that all kinds of people, for example, in their networks at home, they're mapping drives, as is the term, from one machine to another, so that you just - you map a drive on a different machine to a drive letter on your machine, and it's like you're there.  You're able to open it, to explore it, to browse around in it and so forth.  Well, all you're really doing is you're making a connection between your machine and the other machine over the Windows file sharing port, which is port 443.  Is it 443 or 445?  445.  443 is SSL.



LEO:  443 is SSL, yeah.



STEVE:  Yeah.  So all you're really doing is making a TCP connection.  Now, the question, of course, is why is that dangerous to do from Starbucks?  And the answer we all know, I mean, the answer is legend, is for me to do that I would have to have port 445 open and facing the Internet on the machine I want to connect to.  So say, for example, I wanted to access my C drive at home when I'm at Starbucks.  Well, I'd have to have file and printer sharing exposed and, in my case, mapped through a router to that machine, which would be incredibly unsafe.  No force on earth could make me do that.



But if there were a way for that to be safe, then I have the simplest of all possible modes of access.  I'm not having to mess with a VPN.  I'm not having to raise a barrier which cuts off other things I'm doing.  And also, for example, routes all my traffic through there and then back out onto the Internet, which can result in lower performance.  I mean, I'm at Starbucks, I've got a direct connection to the Internet now.  Why force all my traffic up through my connection to home and then back out the same connection, which introduces delay and bandwidth constraint?  But of course it's not safe.



Okay.  Well, imagine that there were a way to make it safe.  Oh, the other thing, the other problem is many ISPs are now blocking these unsafe ports, like they'll block 137, 138, and 139, which were the old-style NetBIOS over TCP/IP file and printer sharing ports.  And they're also blocking port 445 because of all the problems that Windows has had historically.  Well, it's good that it's being blocked because bad things can't get into it.  But it's bad if it's me because I want to get to it.  So we want to avoid ISP filtering.  We also want to avoid there being any security vulnerability.



Well, so I had this idea, and I call it sort of like a junior VPN.  It's not a VPN.  I don't know what to call it.  But imagine that there were device drivers, network drivers, at either end.  And that at my home end, this network driver was listening to other ports, not 445, but other ports, and strongly encrypting and authenticating any packets which arrived there with a symmetric key, a secret symmetric key.  And at Starbucks I have a network driver which is sort of doing the complementary thing.  Windows thinks it's sending packets out toward 445.  But when they come to this driver, it says, oh, this is going to home, so we port shift.  We shift the destination port up to one or multiple ports, because there's nothing to say one packet can't come in and seven can't come out, aimed at different ports, in order to make sure that we get through to the other end.  And that same strong symmetric encryption and authentication is applied so that what the packets contain is absolute gibberish.  I mean, as strong as any VPN.  And that's all that a VPN really is, after all, is just symmetric encryption and authentication using a key that no hacker can know.



And so this packet leaves, gets shifted to a different port, goes out, passes the ISP's filter, comes in, gets decrypted and authenticated, meaning that only my machine at Starbucks is able to generate a packet which decrypts correctly and authenticates.  The port is shifted back down to 445 so Windows is happy with it.  And I'm able to map my C drive or whatever drive or resource that I want to from home remotely with no overhead, no tunnels, no routing, no encapsulation, I mean, there's other complexities which introduce the performance problems that people using VPNs often experience.  This dispenses with all of that.  Far as I know, this has never been done.  And it's the first experiment I want to try as I begin coding CryptoLink for my own use.



And it occurs to me that it would be useful for lots of instances.  When I was reading - the thing that sort of spurred me to mention this is I was reading the mailbag last week for last week's Q&A.  And we had a listener, Steve Hiner, who was having fun.  He said, "At the primate exhibit, writing VB with all the monkeys."  And so he said, "I wanted to make a suggestion for a CryptoLink feature.  As a software developer, I sometimes need to be able to set up communication between one of my programs and my server.  Back when I found out about Hamachi through your show I found myself wishing I could use a Hamachi DLL" - like a lower level Hamachi component - "to temporarily create a secure link to my server.  That way my programs could communicate with my server without having to deal with the security hassle of running a web server.  With a goal of trying to reduce the surface area for an attack, it would be great not to have to expose a web server, but use a CryptoLink connection instead.  What do you think?"



Well, I mean, he's talking about sort of a variant of exactly what I'm saying because the other thing about this is, I mean, it's perfect for program-to-program communication.  In addition to, for example, me manually mapping a drive, there would be nothing to prevent you from connecting to a file using the Microsoft-style UNC, the standard format for generating those sorts of links.



So anyway, it's - one of the challenges I face is creating the feature set that I'm looking for in CryptoLink and not having it be confusing to people, but at the same time wanting to offer features like this that have never been done before, but which, I mean, create a compelling capability.  I just - I love the idea that, again, wherever I am, I would have access to the drives I have at home in a way that's supported by Windows and that in no way mucks around with or messes with or creates any other problems for my normal use of the machine.



LEO:  So this is going to be in CryptoLink, you think.



STEVE:  I don't know.



LEO:  Can you try it as an experiment, and then see how it works, and then maybe put it...



STEVE:  I'm absolutely going to.  I mean, I know it'll work.  It's a simple means for allowing, well, there are two things.  First of all, it only really works this easily over TCP, so it's for TCP things.  But that's what Windows file and printer sharing are.  That's what desktop, remote desktop is.  So it would require TCP things.  But again, there's all kinds of other problems associated with tunneling that this completely sidesteps.  It's just - it's a simple solution.  And it's just - to me it just seems very compelling and absolutely as safe as a VPN because nothing but - no one but I can generate these packets.  And there isn't even a port or ports open that can be scanned because one of the things that the technology I've got does is it allows you to authenticate - it allows CryptoLink to generate self-authenticating TCP SYN packets.  So you're completely stealth.  Nothing can see that you've got multiple ports open.  And only you are able to connect to it.  And it's just as easy as mapping a drive or printer on a remote location.  Anyway, I'm intrigued, and we'll see where it goes.



LEO:  This stuff is hard, though, because you just, well, you know.  But I find this stuff difficult because it's hard to think of all of the ramifications, isn't it, and all of the possible holes and so forth.  I guess this is pretty straightforward.



STEVE:  It's what I find so compelling is it really is very straightforward.  And we've got a really good team of developers and testers hanging out in the newsgroups who are smart guys like John Graham-Cumming who wrote "The Geek Atlas" and others who will check me on this stuff, too.  I mean, they've done it in the past, and I'm sure they will here.  Anyway, that's just - I wanted to share it because it's been on my mind.  It was brought up by this Steve Hiner in last week's mailbag.  And I thought, you know, I'll just give it to our listeners to think about because I think it's really compelling.



LEO:  Good.  This is how you test something like this.  You ask a lot of people.  You ask security experts.  You try it out.  You see what happens.  Very good.  Steve, some great, fascinating stuff.  I thank you for a potpourri today.



STEVE:  You know what next week is, Leo.



LEO:  What's next week?  Oh, our 200th episode.



STEVE:  Number 200.



LEO:  That's kind of amazing.  We should celebrate.



STEVE:  Not a week missed.



LEO:  I'll drink champagne on this side; you drink champagne on that side.  Or you can have a nice burgundy, whatever you prefer.



STEVE:  Cabernet.



LEO:  Cabernet, that's right.  By the way, his place is GRC.com.  That's the place to go on the web to find Steve's show notes, the 16KB versions of this show, the transcripts.  We have transcripts for each and every episode.  But also Steve's other great software:  SpinRite, which is absolutely the one and only, the best disk recovery and maintenance utility, the one you've got to have; all his free stuff, like ShieldsUP!, Wizmo, DCOMbobulator, all that great stuff.  It's all at GRC, Gibson Research Corp., GRC.com.  And we will be back here in your iPod or iPhone or Zune or Kindle or whatever you listen to us on, maybe on the web, next Thursday and every Thursday, pretty much for the rest of our lives.



STEVE:  I think so.  At the rate we're going, that's definitely the case.



LEO:  Thanks, Steve.  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



LEO:  Bye-bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#200

DATE:		June 11, 2009

TITLE:		Listener Feedback #68

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-200.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 200 for June 11, 2009:  Your questions, Steve's answers.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure online, privacy, all that stuff.  Here he is, our security expert, Steve Gibson of GRC.com, creator of SpinRite, discoverer of spyware, and the host of Episode 200.  Steve.



STEVE GIBSON:  Yes, our double golden anniversary episode.



LEO:  Holy-moly.  Who woulda thunk it?



STEVE:  200, yeah.



LEO:  That's pretty great.  I'm really happy.



STEVE:  Well, and from all the feedback that I get - this is a Q&A episode, so I ran through the mailbag.  And we've got of course our regular 12 questions and a ton of security news this week.  But it looks like from the feedback we get we're going strong.  And everyone just says please never stop.  Please please please, never never stop.  So...



LEO:  Well, unless Steve stops, I don't have any plans to stop.  I'm really enjoying it.



STEVE:  Based on the security news this week, it doesn't look like we're going to ever run out of content.



LEO:  I love that.  Well, so we have one commercial from our new sponsor, GoToAssist.  That's coming up a little bit later, so we'll get to that.  How about after the security news?



STEVE:  Sounds great.



LEO:  Let's find out what's going on.  I understand Microsoft did its biggest Patch Tuesday in history, I think.



STEVE:  31 vulnerabilities.



LEO:  Holy cow.  Holy cow.



STEVE:  I mean, yeah.  Even there's a vulnerability in Search, if you can believe it.  And in Works, that no one even has used for quite a while.  It's just...



LEO:  How do you even find a vulnerability in a program nobody uses?



STEVE:  And the print spooler has three vulnerabilities.



LEO:  What?



STEVE:  It's like, oh, goodness, yeah.  It's quite something.  So the big news, though, I just sort of had to kind of smile because I told all of our listeners this was going to happen.  I said just wait, this is a bad idea, we're going to see how bad it is.  Trojans have - trojan software has been found in ATMs located in Eastern Europe.



LEO:  Oh.  Oh.



STEVE:  From many different vendors.



LEO:  Oh, dear.



STEVE:  But what one thing do all of the trojan-infected ATMs have in common, Leo?



LEO:  Let me guess.



STEVE:  Mm-hmm.



LEO:  Windows?



STEVE:  Windows XP.



LEO:  Ai yi yi.



STEVE:  The LSASS service is the manager of protected content in the system.  It's not quite the right acronym.  I can't think of what it is right now.  But it's like the main security service.  And fake ones have been found in the Windows directory.  The LSASS EXE normally lives in the Windows System32 directory.  They were written in Borland's Delphi.



LEO:  You're kidding.



STEVE:  No.



LEO:  Well, that's kind of sophisticated for a hacker.  Wow.



STEVE:  And it's considered, I mean, it's commercial-grade code.  It's good code.



LEO:  Oh, boy.



STEVE:  These are not remote installation trojans.  It's believed that somebody had to have access to the machines.



LEO:  Oh, even worse.



STEVE:  But they have special credit cards.  When they swipe the special credit card in the infected machine, it accesses the trojan software, which among other things allows them to dump out all the cash from the machine.  But in the meantime it's logging all of the users' information and PINs, which it's able to dump out encrypted with DES encryption from the printer, from the ATM printer in the front of the machine.



LEO:  Wow.



STEVE:  So the - and anyway, so it's interesting to me.  Again, it's, you know, people defended the idea of implementing these things that I contend should never have been written in Windows.  They say, well, but it's easier to write them.  And it's like, yes.



LEO:  For everybody.



STEVE:  And it's also easier to write trojans.



LEO:  For everybody involved.  We're all happy.



STEVE:  You can have a, yes, a really nice GUI interface and, you know, lots of third-party support with something like Borland's Delphi in order to write your trojans.  But if it were instead written in one of these much more obscure industrial and industrial-strength multitasking real-time operating systems, it'd be far more difficult.  They wouldn't be able to write the software on the machines that they received for Christmas.  So anyway, I got a kick out of that.  I mean, it's bad news.  The good news is, as far as we know, it's relatively constrained to Eastern Europe, and - but many machines over there.  But this is not the kind of thing you want on your own local bank's ATM, logging all of your ATM transactions and then being willing to dump them on command.  So, yikes.



Also the Pirate Bay appeal was denied.  Remember that the four Pirate Bay guys were found guilty.  Then there was an appeal that was brought based on the membership of a couple of the judges in a pro-copyright organization.  So it went to appeal.  And the judgment quickly came back that, yes, we know that these guys are pro-copyright members.  But that's just to keep them informed of the copyright law and what's going on.  There's no indication that it in any way biased their judgment.  So the sentence stands.  At the same time there was recently an election, as you may know.



LEO:  Yes.  This is amazing.



STEVE:  And the Pirate Party won one of 18 seats in Sweden's Parliament.  The Pirate Party was established three years ago in response to Swedish legislation that made filesharing a crime.  So the party's publically declared aims are to reform European copyright law, abolish the European patent system - got to get rid of that pesky intellectual property altogether - and eliminate digital rights management, DRM.  And also to allow, as a consequence of all that, free filesharing on the Internet.  And what's interesting is that this wacky Pirate Party got a substantial percentage.  I think it was 9.something, 9.1 percent of the vote for these guys, and they won a seat.  So I don't know what that means in terms of their goals.



LEO:  Well, these people are pissed off about DRM.  I think people haven't thought through the whole issue of, well, if you don't have intellectual property protection of any kind, if you have no patent or copyright system, nobody's going to invent or copyright anything in Sweden.



STEVE:  Right.



LEO:  But I think what this is, is the pendulum swinging the other way.  People have been - are fed up by the ridiculous copyright, patent, and DRM issues.



STEVE:  By having the stuff really getting in their way.



LEO:  Yeah.



STEVE:  Yes.  I mean, again, we know that it's one thing to pirate, which we're all against.  It's another to be able to have your own personal fair use blocked by things that get in your way.  I mean...



LEO:  This is what happens when companies assume and treat you as a pirate.



STEVE:  Right.



LEO:  Then you're going to have some reaction.  And I think that's what this is.  It's really stunning that they got almost 10 percent of the vote.  That's amazing.



STEVE:  I did pick up on the mail that you forwarded me yesterday, or I guess it was last evening, about the Comcast Social Security number insecurity.



LEO:  Can you believe that one?



STEVE:  Oh.  On the Unixjunkie blog, a guy named Greg Miller blogged - and Greg is a Google software engineer.  This is not super recent.  This was last October 26th in '08 he blogged.  He was setting up his - he was going to be moving and setting up Comcast, a new Comcast subscription in the new location where he was moving to.  And everything seemed to be going fine until the last step required that he do an online text chat with a nameless, faceless Comcast person.



So this Java applet downloads, and he noted that it downloaded over HTTPS.  But he was skeptical of whether the actual interactive chat text was also encrypted, hoping that it was, specially because one of the things they required was that he enter his Social Security number into the chat.  And it already had his name and address and other clearly personally identifying information.  The chat-ee at the other end said, oh, don't worry, you can trust Comcast, it's secure.  Well, being a Google software engineer and a techie, he fired up a packet capture and watched as unencrypted, in the clear transactions went back and forth.  You didn't even have to guess what the content was because every field was clearly labeled, you know, Social Security number equals, and then first name, last name, date, address, city, state, zip, all the fields clearly identifying what their content was, just being sent right out of his machine with no security at all.



So he put the blog posting up to warn any other people that they absolutely didn't want to do that.  Oh, and he gave the person a hard time because I remember looking at actually the chat text that was in the clear.  And the person responded, "Well, if you don't trust us to do this, then you can call somebody and do it live over the phone."  And he says, "Thank you, that's what I think I'm going to do."



LEO:  Wow.



STEVE:  Unbelievable.  When I turned on my Mac this morning, there was a whole bunch of updates, but for a change not security related.  These were just feature updates.  You know, "i" everything - iLife, iDVD, iMovie, iPhoto, and AirPort - all got updates.  And of course there was a big Safari 4 update.



LEO:  Yeah.  And a nice one, too.



STEVE:  Yeah, it looks really...



LEO:  They put the tabs back, I mean, where they belong, instead of the top of the window.



STEVE:  And it's got this whole panoramic sort of, what is it, is it 9 or 16 pages, it might be 16 pages, that it learns where you go the most and sort of shows you sort of that folder view that they've got for the iPod view of, like, your popular sites and what the current faces of those are.  It's not real fast.  I mean, when you fire it up, mine took - I was curious, so I ran Safari 4 after the update.  It took a good minute, maybe, to fill in those things, so - and it was doing them one at a time.



LEO:  It does it very fast once you have - the first time you did it, it was looking through your bookmarks.



STEVE:  Ah, okay.



LEO:  It's instant.  If you just do create a new tab now on Safari, you'll see that that's the default blank page.



STEVE:  Oh, good.



LEO:  And it does it very, very quickly.



STEVE:  Okay.



LEO:  Yeah.  No, I think the, you know, they're using the latest WebKit, which is a very fast JavaScript interpreter.  I think comparable to Chrome.  And this is important for them because Safari is also on the iPhone.  So they really want to keep this thing up.



STEVE:  Right.  Well, and Microsoft.  We have a little more after Microsoft, but it's time for Microsoft.  31 vulnerabilities in Windows.  There's some in Windows Active Directory, in the kernel itself, in IE, in Word, Excel, in  Works, in IIS - the web server - and in Search.



LEO:  Unbelievable.  Wow.



STEVE:  But believe it or not, with all of that, remember the bad zero-day exploit that we discussed last week?  It was in DirectX's DirectShow component for displaying QuickTime, and we gave our listeners that link to the "Fix it" button that they could press in order to fix the problem there.  For whatever reason, that's not fixed.  So there is still a known zero-day exploit where it's a remote code execution problem, it is in the wild, it is being done, and it involves, if you went to a web page that brings up QuickTime player, that would be played by DirectShow, then there's a known vulnerability there that is being exploited.  So disabling that in the meantime, and maybe we're going to need to now wait a month.  I don't know if Microsoft will do an out-of-cycle patch for this.  I don't know what the delay is because they had the "Fix it" button certainly at this time last week.  But it's not part of the fixes.



What is part is two vulnerabilities in Active Directory, which are critical remote code execution; three vulnerabilities in the print spooler, which are critical remote code execution; eight vulnerabilities in IE, again, critical remote code execution, open a specially crafted web page and, bang, you're owned; two vulnerabilities in Word, open a specially crafted Word doc and something can take you over; quote, "several" in Excel.  I think they just got tired of counting at this point.  This didn't say, although I did go to another, their other page and counted.  That's how I know that it's 31.  A vulnerability in Windows Works, same thing, open a specially crafted Works file.  The RPC, Remote Procedure Call, has a privilege elevation, so that's not what they call critical, it's just important.  And the kernel has four privilege elevation bugs.



LEO:  And that's serious.  Those have to be critical.



STEVE:  Yeah.  Two were publicly disclosed, and two were privately shared only with Microsoft.  IIS, their web server, has one, a vulnerability that involves authentication.  If you're challenged for authentication, there's a way that you can send a specially crafted response which will essentially bypass the normal privilege level that you would have authenticating at that level, and you're able to elevate.  And Search, Windows Search, has a - depending upon, like if there's some way that you can search and return a file, and that trips it up and allows an information disclosure vulnerability is what they called it.  So not real bad.  But overall this is, I mean, it's a definite reboot of your system.  I've got all of mine sitting here pending.  I didn't want to do it before the podcast because who knows if the machine would survive and come back up afterwards.  But I'll do it when we're through recording.



LEO:  Yes.



STEVE:  And I want to tell all of our listeners, shut down things gracefully.  But this is one - there's so much in this package that it's definitely worth a reboot in order to catch up.  And we also talked last week about Adobe's formally announced plans of coming into synch with quarterly updates.  Well, this being June, which is an even quarter in the calendar, and this is Microsoft's Patch Tuesday, it's also Adobe's Patch Tuesday.



What I found interesting was that my Acrobat on this machine was giving me no indication of new versions.  But when I asked it, it said, oh, yeah, got something.  And it also appears that it is needing to install these sequentially.  Just the other day I installed a brand new install of Acrobat in my tablet that I'm using at Starbucks.  And I was able to download, I think maybe it was 8.13, I mean 8.1.3.  But then I had to successively have it do - have it apply .4, .5, and I think that's where it stopped.  So what I'm noticing is when I ask my older Acrobat on this system, it says 8.15.  But I know that 8.16 is available.



So what our listeners need to do is update until it tells you there are no more.  So don't just do it once.  So your target is, if you're using v9, major v9, with day before yesterday's, that is, Tuesday's update, we're at 9.1.2.  Version 8 is at 8.1.6, and v7 is at 7.1.3.  So in any event, what you want to do is just keep, you know, maybe it makes you reboot each time or not.  But keep working at it until it finally says okay, whew, there is nothing else.  And you should be at 9.1.2, 8.1.6, or 7.1.3.



LEO:  Good.



STEVE:  We also had some interesting news in the DNS world.  On June 2, which was, what, like last week, the .org root was the first major root of DNS to receive a DNSSEC signature.



LEO:  Hello.  Hello.



STEVE:  Oh, sorry, got distracted.  I just had something come or go.  I forgot to - I always forget to turn my speaker down.



LEO:  I thought that was a Skype sound.



STEVE:  I ought to just turn that off because I don't care if people are coming and going.  Anyway, so last week the .org root was signed, which is the first of our major DNS roots to be signed.  But also the NIST, the National Institute of Standards in Technology has asked ICANN, you know, the main governing body of the Internet, to work with VeriSign, who has been given responsibility to get all of the root name servers signed with DNSSEC by the end of 2009.  So by the end of this year we're going to finally get the root servers signed.  The .gov servers were signed a few months ago, which is a good thing.  That was mandated by the government, and it was made to happen.  So now the public servers are going to get themselves signed.



LEO:  And this will take care of that Dan Kaminsky security flaw that we talked about.



STEVE:  Well, you really need - it's moved forward.  We've got a long way to go because you need DNSSEC at both ends.  You need a DNSSEC-aware server in order to understand and verify the signatures that are being given.  So the fact that the DNSSEC records are, that is, the signatures are available, that's the prerequisite to using them.  But you still have to use them.  But so we've got a ways to go before when you actually get a record out the other end, the whole chain has been, like, it's very much like the way we think of certificate chains, where you need a chain of certification all the way back to the trusted root.  So the same thing has to happen here.  But again, it can't happen until it starts.  And so it has started, which is way good news.



LEO:  Yeah.



STEVE:  And then last thing I just want to mention, I haven't mentioned this for a long time, I developed the Perfect Paper Passwords system when I was needing some way to allow my employees, Sue and Greg, to roam with their laptops, yet still have really, really robust, secure authentication to GRC.  I'm now using it since I'm at Starbucks.  So I'm a roamer, too.



LEO:  Oh, that's neat.  Oh, that's neat.



STEVE:  And it's just, I have to say, I mean, obviously the stuff I do in the future, like CryptoLink, will support Perfect Paper Passwords natively.  But it just - it really works, Leo.



LEO:  Are you surprised?



STEVE:  Well, you know, it's one thing to design it and write it.  But then to actually be a user of it...



LEO:  No, it's good to eat your own dog food once in a while, that's good.



STEVE:  And I was never using it.  But so you go to the page, and it says, we need C7.  And so you get your little - I have it in my wallet, my little index.  And I go, oh, C7.  And I type the characters in that it wants and then also give it my password.  So it's something I know and something I have.  And it says, okay, fine, here you go.  It's like, wow, you know?  And I can't give it the wrong one, and I can't give it the same one again because it's a one-time password system.



LEO:  So just to clarify, this is a system you wrote, but it's logging into your corporate VPN, your corporate network.



STEVE:  Actually it's, yeah, it's secure web access to resources that we have at our...



LEO:  So it's not a VPN, but it has - it's SSL, but it's via the web, yeah.



STEVE:  Correct.  Correct.  And uses a whole interlocking cookie system.  I mean, you have to - I described it all in detail once.  You have to receive a cookie when you're at your home address to, like, enable the machine to then be a roaming machine.  And then so you have to have that.  And then you get an authentication cookie when you are roaming which is valid for a limited period of time until you close the browser.  So it's a session cookie, not a static cookie.  I did, I went over the top with security.  But is there such a thing? 



LEO:  Can you go over the top?  No.



STEVE:  Exactly.



LEO:  I think not.



STEVE:  And I do have a short little blurb about SpinRite.  I have a really interesting and fun long one.  But since I'm sure this episode is going to go long because it's one of our Q&As that are never short, I just thought I'd share a fun short story from someone named Nate Friedman.  Dane wasn't sure if maybe he was somebody that you knew.



LEO:  I don't think so.  That doesn't - but I shouldn't say that.



STEVE:  Well, he's also in - I notice now that he's in Santa  Rosa.  And Dane said there was someone who is in the chatroom, I think, that is...



LEO:  Oh, he might be a chatroom guy.



STEVE:  Anyway, so he said:  "Steve, I wanted to share my SpinRite story while it was fresh, but would love it if you read this on Episode 200..."



LEO:  Okay, deal.



STEVE:  ..."of Security Now!."  So I was all set to read the other one, too.  And I thought, well, okay, since Nate's asking for a specific episode number, he gets it.  He said, "I've been listening to you and Leo for a few months straight now and wish I had started sooner.  I recently inherited responsibility for a mission-critical server with a failing hard drive.  The previous administrator had tried to clone the hard drive during nighttime hours three times, and failed each time.  Having heard the many success stories about SpinRite, I talked the money people into buying a copy.  It found a few bad sectors running at Level 3, so I ran it again at Level 4, just over that section of the drive.  Then I went back and properly cloned the hard drive without any trouble to a fresh one, and the server's been humming along like a champ ever since."



LEO:  Excellent.



STEVE:  So Nate, thanks for the story, and another success for SpinRite.



LEO:  We have, Mr. Gibson, some good questions for you, 12 questions good and true from our wonderful listeners, questions compiled from GRC.com/feedback, including questions about BRIEF...



STEVE:  Oh, and actually there was a bunch of stuff from last week, some errata-ish questions, too.  I just put my foot in my mouth at one point.



LEO:  Uh-oh.



STEVE:  So that's question number one.  I wanted to get it right off the top of the show.



LEO:  All right.  Starting with the foot-in-mouth - foot-in-mouth extraction.  Jim Millard in Kansas City, Missouri picked up on - and you wrote this, not me - Steve's bone-headed statement about IPv6 and consumer switches.  He says:  Steve, I've posted this in the newsgroups, but you made a mistake - I'm sure he didn't mean this in a mean way, just wants to get it corrected - in your characterization that commodity switches will "break" - I'm paraphrasing - when we move, if we move to IPv6.  I presume Jim works for somebody like Linksys or somebody.  Recall that a switch, unless outfitted with extra functionality that is NOT typical in consumer equipment - operates at Layer 2, not Layer 3.  A switch keeps a list of MAC addresses for each port, not the IP address.  So v6 is not going to bug it at all.



STEVE:  I know.  Oh.



LEO:  Oh, don't feel so bad.



STEVE:  And it's not that Jim needs to work at Linksys or somewhere.  You wouldn't believe, I mean, I'm impressed with our listeners because...



LEO:  They picked that up right away.



STEVE:  When I picked up the mail I thought, wow, look at all this mail.  Unfortunately half of it was people saying, eh, I don't think so, Gibson.  Didn't you have your coffee that morning?  I mean, I know.  And we've talked about this so many times on the show.  It's like, okay, I don't even know what I was thinking.  I think this is what they call a "brain fart," Leo.



LEO:  Yeah, yeah.



STEVE:  Just for clarification, a switch, exactly as Jim and many other listeners said, runs at Layer 2, meaning that it's at the MAC addressing level, not the IP addressing level.  So it doesn't - it's not even aware of the payload of the Ethernet packets.  It's switching the Ethernet packets based on MAC address, which is what we understand is unique on the physical local LAN, thanks to MAC addresses being unique.



When a machine, an active machine, not the switch itself, which is sort of passive, when an active machine is trying to send an Ethernet packet to a machine on the LAN by IP address, it uses an ARP packet - ARP, Address Resolution Protocol.  And it broadcasts it to the last IP on the network, which is a special - I'm sorry, the last, yeah, I'm sorry, exactly, it broadcasts it on the network so that all devices on the network will hear it.  And it says, which of you has this IP, that is, has that IP assigned to your adapter?  Well, one of them will respond, it's like, hey, I'm the guy with that IP.  The switch is passively monitoring this dialogue, and it knows which wires, that is, which ports these various chunks of the LAN are plugged into.  So it memorizes the MAC addresses living on each of its different ports.  And that's how, for example, a switch can - the same switch can be used, not only for IP traffic, but for example Novell's older IPX/SPX protocol, which is - it's IP related, but it's not the same protocol.  So again, yes, Jim was right.  I don't know what I was thinking when I rambled off the wrong statement.



LEO:  You knew better.  You knew better.



STEVE:  I wanted to correct the record for everybody who - first of all, for people who I may have confused with that.  And I wanted to acknowledge the torrent of corrections that I received and to thank everyone for making sure that I knew what I was talking about.



LEO:  No one doubts that anyway.  Let's move on to question two.  John Meuser in Indianapolis, Indiana wonders about non-VPNs.  He writes:  Steve, your non-VPN solution - this was somebody who had written this in; right?  Oh, no, you were talking about - this was the third subject of last week's show, of course - sounds a lot like SSH port forwarding with something like a port-knocking daemon to hide that there is a port listening.  Is it?



STEVE:  Yeah.  There are - we also got a ton of responses to my talking about this notion of a non-VPN solution, sort of a secure connection approach.  And I'm gratified because it's very clear from the response that our listeners have a huge interest in secure connections.  So I wanted to clarify a little bit briefly about how this is different.  With SSH port forwarding you run essentially a listening service on your local machine which is listening for connections to the so-called localhost address which we've talked about, 127.0.0.1.  So it's a server inasmuch as it's looking for connections to that address.  It's also a client of the remote end which is functioning as a server.  So the idea is you tell your IMail client or your POP client or whatever to connect to your own machine at whatever port you have set up this SSH listener to be listening on.  It accepts the connection, and then it in turn reaches out and securely connects, using SSH secure protocol, connects to the remote endpoint running at your actual destination.  And so that's how the conversation works.



My approach that I talked about last week is a little different in that, very much like many UNIX solutions, this doesn't require anything in the kernel.  This approach is essentially able to run a daemon which is listening to - that is, the SSH approach is able to run a daemon which is listening for connections to a port, and it then forwards them to somewhere else.  So it's nice in that it's able to run in user space.  My approach, and the one that I will be taking with the development of CryptoLink, will involve a kernel driver which inserts itself in between the NIC, the network LAN adapter, and the rest of the PC, that is, before the protocol stack that does all of the work, and just before the packets leave or just after they come in.  So the CryptoLink driver will have raw access to the actual packet.



So what that allows is much more transparency of operation.  So, for example, you would not need to reconfigure your email or POP or Windows networking or anything, telling it to aim at your own machine.  You'd actually tell it, connect out there to the target.  And so the CryptoLink driver in this case would see that happening, intercept the packets on their way, as they've left the protocol driver, just before they get to the LAN adapter, the machine's NIC, and it would change them and encrypt them on the fly so that this system just works without the added overhead of starting up the port forwarder and configuring it and so forth.  So that's really how my approach is different.



And as for the port knocking side, again, that's another clever solution which is able to run in user land, sort of as a user-level application over on the receiving system, to allow packets to - and we've talked about port forwarding or port knocking in the past - to allow packets to hit a firewall and be noticed, and the sequence or content of those packets in some cases is used as a key that then causes something to open a port on the fly, which then allows the actual traffic to come in.



What I have the first of a number of patents pending on is I've figured out a way for the connection-opening SYN packet to self-authenticate so that it itself contains the authentication information allowing it to be identified as coming from a legitimate matching CryptoLink client that shares the same key as the recipient.  And so while you've got CryptoLink running, your system is completely stealth.  It appears that you have no ports open at all, when in fact they're all opportunities for CryptoLink packets to come in.



And that's the other cool thing is that, which will allow CryptoLink to establish connections more robustly, is you could send packets to any port number.  And again, because the CryptoLink driver is listening before the computer, that is, just after the packet is received and before it starts being processed, it's able to look at these packets, authenticate them, and say, oh, hey, this is a special one for me.  And then it's able to do its job.  So there's a bunch of extra magic happening.  I'm glad for our listeners' interest, and it's going to be fun to be developing this.



LEO:  Be careful.  You keep promoting it.  Pretty soon there's going to start being people storming your doors, saying, "Where is CryptoLink?"  We're getting - you're giving us more and more reason to want it.  I'm excited, really excited.



Brad Beyenhof in San Diego, California says: NoVPN?  Port forwarding?  Sounds like NoVPN - or he probably means non-VPN; right?



STEVE:  Sure.



LEO:  Would have to either, A, use port forwarding to let the secure ports through your router; or, B, put the non-VPN server machine into a DMZ and rely on the software firewall plus non-VPN authorization encryption to remain stealthed.  Former might be a little tough for the average user, and it's difficult to provide help given the wide array of router interfaces out there.  They don't even call it port forwarding on many routers.  So you can't even say, well, you need to do port forwarding, because every router has its own terminology for what you're doing.



The latter, DMZ, is slightly less difficult, but still requires router reconfiguration to disable the hardware firewall.  Anyway, didn't you tell us years ago not to rely on software firewalls?  So what's the story, Steve?



STEVE:  Well, I wanted to - I selected this question because I realized I had inadvertently also confused some people.  One of the things that I hope will make the VPN very popular is that in a very Hamachi-like way it will support NAT traversal.  So it will not be necessary for you to preconfigure your routers.  You'll be able to use NAT traversal.  However, there's absolutely no way around the need for a third party if both endpoints are behind NAT.  We've talked about NAT traversal in the past.  I'm sure probably I'll bring it up again when I'm deep in the middle of actually solving the problem and characterizing various NAT routers.



But the idea is that, if one of the two parties that wants to connect is behind a NAT router, well, the one behind the NAT router is able to send packets out through the NAT and directly to the other party that's not behind a NAT router.  That works.  If neither party is behind a NAT router, of course you have no problem.  If both parties are behind a NAT router, the problem is that they're not able to send packets to each other because we know how NAT routers function as very good hardware-level firewalls.  They allow the egress of traffic.  And then traffic that's expected back in can come in.  But they don't allow unsolicited traffic to get in.



So the solution is for a third party, like a so-called rendezvous server, a third party that's not behind a NAT router, standing out where both of them are able to access it, like out on the public Internet, they send traffic to that third party.  The third party analyzes the traffic, figures out how their NATs are mapping between the private network and the public network.  And then, through the connection that they initiated to the third party, that third party sends instructions back to each of the parties behind their respective NATs, saying here's how you need to send packets to each other.  They then simultaneously send packets to each other with the hope that the transparency that's been created by the presence of the third party providing them this extra information will allow their packets to get back into each other's NAT.



So it's tricky, but it obviously works.  NAT traversal, Skype has it, Hamachi has it, our show sponsors have it.  It can be done.  I'm going to do it, too.  But it breaks my TNO, my Trust No One model, because you have to have a third party.  And the other problem that many people experienced with Hamachi is, if Hamachi was ever down, and unfortunately Hamachi spent a lot of time being down, you couldn't initiate new connections.  If the third party's missing, then you're out of luck.  So I recognize that there are more sophisticated users who can configure their NAT router, who don't need a zero configuration solution.  What they would prefer is a, first of all, absolutely Trust No One solution, no third party involved ever, and in return for that they'll have to do a little bit of configuration.  But then they also get the reliability of not relying on a third party, in addition to the additional security.



So CryptoLink will work both ways.  It'll work in a zero-configuration mode and do NAT traversal.  But for professional people, I mean, the way I would configure it for myself is I would configure my router to allow external traffic in to the CryptoLink server, knowing then that I'm able to accept connections from anywhere, whether behind a NAT or not, because I've essentially made the receiving end transparent.  So I just wanted to clarify that, that it will work both ways - in a "just works" fashion where it may be necessary to rely on a third party, but for our sophisticated users you won't need to use that.



LEO:  Very good.  Again, you're making us salivate.



STEVE:  I am, too.  I can't wait to get started on it.  Have a little more work to get done, then I'm on it.



LEO:  So you haven't actually started it.  We should just make that clear.



STEVE:  No.  I've got a ton of notes.  I've got intellectual property stuff working.  But I've got a short list of things that I just, I want to finish, that I've invested hugely in already, that it's just dumb not to finish them.  So I'm going to get them finished.  I talk about the third-party cookie stuff, the DNS spoofability, the DNS benchmark, and just a few other things.  And once those are out of the way - and they're almost finished.  I just need mostly documentation.  So I'm on it.



LEO:  I'm on it.  Yeah, you forget that there's all this other kind of prep work that you have to do before you can even begin.



STEVE:  Well, and frankly I'm...



LEO:  At least it'd be prudent to do.



STEVE:  I'm glad to have the time to think this through.  I mean, remember, Leo, you and I were in Vancouver, and I ran through the list of several pages of things that CryptoLink would do that nothing else has ever done.  And you looked at me like, my God, this is going to be really good.



LEO:  It looks really cool, yeah.



STEVE:  Yeah.  But I just, you know, it's just me, so...



LEO:  Well, you know what carpenters say.  You say measure twice, cut once.  And planning is really important.  We were talking about how I was looking at curricula for high school students for programming and so forth.



STEVE:  And we've got - we have a couple ideas about that in our Q&A, as a matter of fact.



LEO:  Oh, good.  Well, one of the books I found is called "How to Design Programs."  It's a wonderful book that's been used as a curriculum at Yale and Rice and MIT and a lot of other places.  I mentioned this before, it uses DrScheme, which is a stripped-down version of LISP.  But it very much focuses on planning.  Before you write one line of code.  It really teaches you a methodology so that you think - you do what you're doing right now.  You really think about what you're going to do, and you know what you're going to do before you write a line of code.



STEVE:  Oh, and I forgot that, as a consequence of this last week, of all the email and the dialogue in our newsgroups, I realized that this notion of a secure connection is not what I want to do.  What I want to do is what I call "tunnel on demand."  So it's just as transparent except that you're running a full VPN with all the additional features that it provides, like you can send multiple connections through a single tunnel.  You can have many different types of traffic.  What I was trying to avoid was the overhead of having to start something.  And I'm used to having to do that with OpenVPN because - and it takes, with OpenVPN, it takes several seconds of starting it up, and it scrolls through all the stuff it's doing.  There's all this happening before you get your tunnel established.  And so it's definitely overhead.  And so I realized that's - there's no reason it has to take that long.  A tunnel can be established almost instantaneously.  So what you want is, you want the ability to establish a tunnel on demand, I mean literally on the fly.  And so there's no reason that that can't be done, and that's what I'm going to do.



LEO:  Oh, great.



STEVE:  So it was a good exercise.



LEO:  See?  See?



STEVE:  To sort of think that all true.



LEO:  You see?  You see?  See what I mean?  This next is John Clayton in Billings, Montana.  He wants to set the record straight, help us do so about Microsoft's ClickOnce and Firefox.  This was that weird .NET extension that was added...



STEVE:  It was .NET 3.5.  It appeared, people found it, discovered it, Brian Krebs writing for the Washington Post, in Firefox.



LEO:  Right.  And there was no uninstall button.  Well, there is in Windows 7, but not...



STEVE:  It was disabled.



LEO:  Yeah.  And I, by the way, afterwards went back and read the whole, you know, there was a bug report filed with Firefox about this.  And Firefox explained why it wasn't their responsibility to protect you against this, you know?  It's a very interesting discussion.  I encourage people to read the whole bug thread.  But here's a good message that talks about it, as well.



Just listened to Episode 1999.  As a .NET developer with first-hand experience with Microsoft's ClickOnce technology, I felt there were some misconceptions that needed to be addressed.  It won't be winning any awards for easy implementation, but ClickOnce is, simply put, a way for packaging and deploying thick-client applications.  These 

applications run on your desktop like any other that you would otherwise download, not in your browser.  They get an icon in the Start menu; they get an entry in Add/Remove Programs.  The user is always prompted to install the 

application, so there's nothing silent as you implied.  ClickOnce even supports Authenticode signatures and gives a warning if the signature can't be verified, as in the case of, say, a self-signed certificate.



The plug-in that Microsoft installed into Firefox simply provides a handler for the .application files that initiate the install process.  Without the plug-in, the user would just get XML. The browser wouldn't know what to do with this, you know, XML file.  It wouldn't know that this is an installer prequel.



STEVE:  Right.



LEO:  As a full-time Firefox user, if I want to install a ClickOnce application, the last thing I want to have to do is launch Internet Explorer to do it.  While I'm not defending the way the Microsoft installed this update, I do have to present a Thurrott-ian argument.  Paul Thurrott, of course, the host of Windows Weekly.  If I look at the add-ons right now, I see that Skype, Office 2007, Adobe Acrobat, Apple iTunes, and Apple QuickTime all have their hooks in Firefox.  These are all independent applications that installed stuff into Firefox without notifying the user.



If Adobe didn't install their plug-in, PDFs wouldn't open in the browser. If Apple didn't install QuickTime, the QuickTime plug-in, videos wouldn't play automatically.  These work the same as the ClickOnce add-ins.  They are just handling special files.  And this is, by the way, this is traditional architecture for browser plug-ins.  It's a BHO, basically, that's what the Internet Explorer term - I'm adding this.  This is editorializing.  Leo speaking.  Back to the email.  I should just shut up.  These work the same as the ClickOnce add-ins.  They're just handling special files.  Skype, iTunes, and Office?  Those have even less business being there without notification.  My point is that when anyone else does this kind of thing, no one cares.  When Apple does it, people thank Steve Jobs.  When Google does it, people wonder why it wasn't there in the first place.  But when Microsoft does it, all hell breaks loose.  



I hope this helps you and your listeners better understand Microsoft's technology.  Always look forward to Security Now every week.  Keep up the good work.



STEVE:  And Rob, our next questioner, has sort of a different take.



LEO:  Shall I just go right - segue right into it?



STEVE:  Let's go do that.



LEO:  Okay.  So Rob is near Ottawa, Canada.  Here are his thoughts about reducing the security risks for ClickOnce.  He says:  Steve, thank you for pointing out the monopolistic behavior of Microsoft by installing a Firefox plug-in for ClickOnce that significantly reduces security for Firefox browsers.  Microsoft should be shot and raked over the coals for this.  You should have noted that for quite some time now there has been a third-party extension for Firefox that adds the ClickOnce capabilities to Firefox.  It's called FFClickOnce.  So the MS .NET update that included its own Firefox extension wasn't even necessary.  In my opinion, if MS wanted to include its own Firefox extension, it should have made it a separate optional install in MS Updates.  Since it did not do this and made it a mandatory installation when you installed .NET 3.5, one can only speculate that MS wanted to make its .NET framework more desirable to developers by increasing the number of users who use a browser with ClickOnce capabilities. 

 

As you noted, ClickOnce is very dangerous.  Just by clicking on something on a webpage, an application will be downloaded, installed and run.  It would be easy to trick someone into clicking something on a web page that would run 

with a malicious webpage.  Best to disable or uninstall the MS ClickOnce Firefox extension.  But if you need to use it, I would highly recommend clicking the Options button right next to the Disable button for the extension and enabling the option that asks the end user for confirmation before running the ClickOnce app.  In other words, it's best to turn ClickOnce into ClickTwice.  I think he's right.  Much safer.



STEVE:  Yup.



LEO:  By the way, that's the default behavior of the third-party FFClickOnce Firefox extension, however, not the default behavior of the Microsoft add-on.  P.S.:  ClickOnce is very similar to Java's Web Start.  But unlike Java Web Start, ClickOnce is unproven technology and likely has security holes.  By default, Java's Web Start apps run in a sandbox in a "restricted" mode, which means they don't have access to some system resources like local files.  That's to me always been the benefit of Java over ActiveX and these other Microsoft technologies.



STEVE:  Yup.



LEO:  You're installing an application with Microsoft that has full application privileges.



STEVE:  Right.



LEO:  No sandbox.  But publishers can remove those restrictions by signing their Web Start applications with the jarsigner tool that comes with JDK.  So you better 

trust the developer noted in the digital signature before running a signed Java Web Start app, too.  So there's two different points of view on this issue.  What do you think?



STEVE:  Well, I just liked them because it was lots of good information.



LEO:  Yes.



STEVE:  We understand now that what this is doing, Microsoft is promoting a brand new standard for the industry, saying to .NET developers, rather than telling people to click this link to download the setup file, then you get that on your system.  And many people are like, okay, wait.  I downloaded it, but the box disappeared, and I forgot where, I mean, I've had that happen, you know, it's like, okay, where did that darn thing go that I just downloaded?  And so they're trying to make this a simpler process so that you, if you want to run something on your machine, you want to install it locally, you just click it, click the button on the browser, and it does so.  It's hard to say what the long-term future of that will be.  But it's another thing Microsoft is doing for making their software more accessible.  That is, software built with the .NET framework.



And I really do like what Rob suggested, and that is, if you're going to leave this in Firefox and have it installed, we now understand clearly what it does, that by all means, selecting that option to ask for confirmation, that makes much more sense than being fooled into clicking something, and that's all you have to do, and have this thing run.  So click twice makes a lot more sense than click once.



LEO:  Yeah.  And what is your response to that whole thing that, well, Skype does this?



STEVE:  Well, I looked, and I don't have Skype running on my system, so I didn't have an add-on.  I was curious what other things were there.  And I did not see the list that the first questioner had.  But certainly there are things, I mean, it certainly is reasonable that that would be happening.



LEO:  Right.  Okay.  Let's move on.  Interesting subject, though.



STEVE:  Yeah, it is.



LEO:  And I think you're going to always have a debate over what's appropriate and what's inappropriate.



STEVE:  What needs to be automatic and what needs not.  I mean, and, okay.  So say that Skype asked you before installing this, given that we are correct and there is something installed on Firefox.  I would opt, I think, for not having more junk in my browser.  You know, people talk about how long it takes Firefox to get started sometimes.  And it's having to parse and load and find and set up all these different things so that there are extensions to its core functionality.  And I know that a freshly installed Firefox tends to launch a lot faster than an old one that's had a chance to collect all these barnacles all over it.



And so as a minimalist I would generally, if given an option, say no, I use Skype for this particular purpose.  I don't need links to be Skype-enabled or enhanced in order to launch Skype sessions.  That's not something I'm going to do.  So I'd rather not have that in my system.  So, you know, I would opt, and I imagine our listeners would generally opt for being informed and being trusted with having the ability to answer the question.  On the other hand, I know lots of users, some who are friends of mine who are non-computer people, who, like, uh, do I want that or not?  I mean, they would have no grounds for determining...



LEO:  No idea, yeah.



STEVE:  ...even for them what the right answer is.  Do I need that or not?  And their sense is, it's need.  Do I need it or not?



LEO:  Right.  I don't even know if I need it.  I don't what these are.



STEVE:  Right.  So if you told them you don't need it, they're like, oh, okay, good, thank you very much.  I'm glad I don't need that.  Because they're a little anxious about needing anything that involves the PC.  But for some people who are, like, avid Skype users, the convenience of that would offset the cost of having it installed in their browser.  So, I mean, it really is a problem because what we're doing, and here Microsoft has just taken us to another level, is we're making these systems ever more complex.  We know that complexity is the enemy of security.  We know that especially today because Microsoft has just patched 31 vulnerabilities that are a consequence of the complexity of the software that they are creating.  So it is certainly a tradeoff.  I would opt for having the choice.  But that's not a choice we're being given because it causes more  problems for these companies that then have tech support.  It's like, well, do I need to click yes or no on this?  It's a mess.



LEO:  It's a mess.  It is.  This is always the tradeoff.  We've mentioned it many times before, convenience versus security.  Michael in Missouri takes issue - boy, we have a lot of unhappy...



STEVE:  Yeah.



LEO:  But I commend you for putting this stuff in so we can respond to it.  That's good, I like it.  He says:  Hello, I've been listening to you for some time, and I feel the need to write to you to address some issues.  You claim to address security, yet you fail to truly take to heart the Linux on the desktop platform.  I started out a very proud Microsoft fan myself, and I understand that many users are Microsoft users.  But as a technical person I learned the true power of Linux and other open source technologies.  Let me make it clear, Ubuntu can be used with no experience or knowledge.  However, Linux provides a degree of control that 

you just can't get with Windows.  Linux is modular, does not hide its code in 1's and 0's.  You know what you're getting when you use Linux.  Please do not dismiss me as a Linux fan boy.  I do program, and I understand the choices that both systems make.  But even Microsoft declares Linux as its competitor.  Microsoft CEO Steve Ballmer admitted Linux is a serious competitor.  In any case, I just wish you would truly look into what Linux has become.  Even spend an episode addressing it as a security option.  You did so with Windows 7. 

 

The next problem I have is with you, Steve Gibson, not making your code open source.  You can do whatever you want with your code, and it's nice to keep some code closed source.  But I just can't get over your reason for doing so.   In one of your episodes you said you don't make your code open source because you were worried it would allow hackers to use it.  To me that seems arrogant, to assert that your code is above any others without merit or reason.  However, in a security sense, it seems you're condoning security by obscurity - something we mock.  I thank you for your podcast, and I enjoy listening to them.  I just wish you'd be a little more open - capital O - minded.



STEVE:  Okay.



LEO:  Can I say one thing?



STEVE:  Yeah.



LEO:  From day one we've always said this is a Windows security show.  I mean, we really focus on Windows because  most users are using Windows.  We don't cover security on the Macintosh particularly.  We haven't covered security on Linux particularly.  We do have other shows that talk about those subjects.  In fact, we're going to talk about Ubuntu next.  Right after this show we've got Jono Bacon from Ubuntu to talk about [indiscernible].  So we do have other shows that cover this stuff.  I don't know if this is something you consider part of your portfolio.



STEVE:  Well, it's not.  And for a couple reasons.  I mean, there is a limit to my scope, to what I am able to cover.  And I live in Windows, so it's accessible to me.  The way I deal with things like Linux is we spend a lot of time on fundamental technology, on the way things work, which is universally applicable to all platforms.  You know, when we've talked about crypto, that's not Windows crypto.



LEO:  Sure, sure.



STEVE:  It's as much Linux and Mac crypto as it is Windows crypto.  It's fundamental stuff.  So there's - I recognize the validity of what Michael said.  However - and I also know that there is certainly a Linux population who listen to the show.  And I can only say, well, as you said, Leo, we're primarily a Windows security-focused presentation, but also heavy on fundamental technology, fundamentals which are universal and apply to everyone, which is why I think we've got Linux users who are listeners.



LEO:  Right, right.  We're Windows except when we're not.



STEVE:  And as for my source being open code - my code being open source - maybe someday.  I mean, I can easily foresee a point someday when I'm no longer a commercial producer of code, that I'd be happy to share my stuff openly.  But this is all, you know, SpinRite is a commercial program that is my bread and butter.  CryptoLink I hope will grow into the same thing.  There was some discussion even of this forthcoming DNS benchmark, which has turned into just a beautiful piece of work that I'm going to be very proud of and have a lot of fun sharing with our listeners as soon as it's finished.  And somebody posted in the newsgroups, Steve, you're doing this thing, and it's freeware.  Why aren't you making it open source?



And Michael did misunderstand something.  It certainly wasn't arrogance, me believing that my code is better than anybody else's, that's why I don't want other hackers to use it.  What I was concerned with is it would be very simple for malicious versions of my code to be created if here was the whole package, and you assemble it, and you get something that looks exactly like what GRC produces.  Then they could stick their own stuff in and say, oh, look, this came from GRC.  Obviously you can trust it because it's from Steve.  Now, it's certainly true that someone could start from scratch and create something that looks exactly like mine, but that's substantially more work.  I mean, that's a lot more work than just adding some little bit of something to an existing body of code.  Also the fact is, the fact that it's all in Assembler means that it's much less accessible to a large body of people.  So I wonder how much use it would be as open source.



But more than anything, I'm not done leveraging my work for the support of myself and Greg and Sue.  And so the DNS benchmark is free, but I regard "free" as separate from "open."  I mean, it is, it's been a labor of love.  Fundamentally it's all I've done to this point this year.  So I'm hoping it's going to be useful and valuable.  People will come to GRC in order to get a copy.  And some will go, oh, look, SpinRite, that thing's still around.  I'm going to read some testimonials, and maybe they're going to buy a copy.  And so that's just really been the model for GRC for a long time.  And thus ShieldsUP! and all the other freeware that I've produced, and all the things I give away, we're still a commercial enterprise despite the fact that I'm trying to do everything I can to give back to the community.



LEO:  Would you consider, because I would like to see your code, open sourcing end-of-life applications?  Stuff that's obsolete?  Or are there macros in there that...



STEVE:  Yeah, there's still, I guess...



LEO:  ...you don't want to - proprietary code that you don't want to release.



STEVE:  Yeah, I do feel proprietary about it.  It's stuff I've developed carefully and painfully that - and often put a lot of time into that makes my stuff small and fast and special.  So...



LEO:  Yeah.  No, this is frequently the case, even though maybe that program is not in use, there's libraries in there that you still use that you don't want to release and things like that.  I don't think anybody should be - I don't think there's any onus on anybody to do open source.  If you choose to do open source, that's great.  But no programmer, there's no - I think it's actually inappropriate to kind of urge programmers to release their stuff.



STEVE:  Well, and I think...



LEO:  That's a choice you have to make.



STEVE:  I think the other thing that's a little confusing, certainly this was sort of the genesis of the comment in the newsgroup recently, is what I have is a very, I mean, a phenomenally open development process.  I mean, it's already, if you were to look at GRC.dns, which is the newsgroup at news.grc.com, you'd see literally thousands of postings with us interacting, me interacting with a group of interested people who are saying, hey, Steve, right-clicking here really ought to do this.  And I think about it, go yes, that's a very good point.  And now the app has that.



And it's now locale aware for people - it'll export a CSV, a Comma Separated Values file, so you can save all your benchmark results.  And basically they've been responsible for hugely broadening the scope of what I was going to offer.  They've also been responsible indirectly for this thing never ending.  But we're still getting closer.  And I am really pleased with what it is because I think a DNS benchmark is going to be very valuable for people.



And I know that the same thing is going to happen with CryptoLink.  We'll set up a newsgroup.  Actually it's already there, GRC.cryptolink.  And people will say, hey, I have this need.  And if it looks to me like that's something I hadn't thought of, that more than this one guy has, it's like, oh, good point, I'm glad you brought that up because I'd rather know now than later.  And so it's a little confusing that the development process is so transparent and so open.  And, I mean, it's fantastic for me because I'm able to just churn through, I'm able to implement things and say, okay, here's a new version.  And these guys look at it, and they pound on it, they go, yup, you got it; or, oops, you forgot this over here.



And so it's an amazing environment for developing.  Yet I'm the final arbiter.  I'm not sharing the code.  I'm not sharing the decisions.  I'm taking responsibility for it.  Ultimately what I produce is mine.  Yet in the case of the DNS benchmark I'm making it freely available for everyone.  So it's a model that we've proven, and it's just fantastically productive.  I really like it.  And boy, I never get things finished because everyone keeps wanting new things.  But it just ends up getting better and better.



LEO:  Right.



STEVE:  And I know that that's going to influence CryptoLink's development, too.



LEO:  Good.  Mike Potts, Columbus, Ohio has a recommendation for teaching programming to young people.  We've been talking about that a lot because I just have the fantasy that I might sometime want to teach a class on that to my kid's high school.



STEVE:  I think that's going to happen.



LEO:  I have a feeling it might.  Hi, Steve.  This note is more for Leo and also for other listeners who want to help younger people who are learning to program.  I like an open-source program called Basic-256.  It's available at kidbasic.sourceforge.net, means it's open source.  Pre-built Windows binaries, source-code, and Ubuntu packages are available.  The article "Why Johnny Can't Code" on Salon inspired Basic-256.  This program is easy to learn and use. There are reasonable tutorials available.  Some sleuthing in the source material will find some nice extras.



But really what sets this program apart is that it has a small graphics window.  The programmer is given an approximately 300x300 pixel graphics window with all <grin> 16 colors, and enough primitives to do some real work - circles, rectangles, dots, et cetera.  Sure, you could teach the classic algorithm of "have the computer guess your number between 1 and 100," which is my favorite beginner problem.  But nothing generates more excitement - and I agree - or holds their interest more than having them generate their own primitive civil war, dodge ball, or soccer game.



This program held my 14 year old's interest for several months.  What he really learned from this experience was one very important programming lesson:  The computer did exactly what he told it to do.  Not what he wanted it to do, but what he said to do.  You can always get more experience, but I don't think you can get a deeper lesson than that.  That's true, that is the fundamental lesson of programming.



STEVE:  Yeah.



LEO:  Computers just do what you say.  You can't get mad.  They just did what you told them to do.  When Basic-256 was starting to wear off, I spent a couple of days explaining, book-only, processor memory cycles and 8-bit Assembly language to him.  I didn't think of looking for an emulator, but maybe now I'll look for that PDP-8 emulator you guys found.  Thanks for a great netcast.  My copy of SpinRite=1, bad_harddisk=0.



STEVE:  I took a look, and I really think this looks pretty neat, Leo.  You may remember the other sort of graphic-enabled learning language was Logo.



LEO:  Right, Turtle Graphics, yeah.



STEVE:  Turtle Graphics.  And what it offered was that immediacy of feedback.  And we were talking about the Tower of Hanoi relative to the PDP-8 and the teletype going chug-chug-chug-chug chug-chug-chug-chug, you know, putting out X's.  But this thing, this Basic-256, it's a really nice integrated environment where you have code, you write code on the left, and then in the upper right are all your variables.  So you're able to see, which I think is really important, the current state of all the variables in real time, that is, at that point.  And then below is a graphic window.  So you're able to write some code that says circle at this location of this size, and it goes blunk, and there it is.  I mean, and that's like, hey, cool.



LEO:  Yeah.



STEVE:  How about, how, how would a loop work, where I change the X and Y coordinates, and suddenly [vocalizing], and you've got circles all over the place.  And again I just - I wanted to share this because I think it is an interesting, very accessible way of, like, letting people play with a simple programming language that modifies variables and has loops and actually does something visual.



LEO:  There are a lot of debates, you know, as I started researching this I found so many debates about how to do this, what's the best way to do it.  And I think you're right, I think you can't knock getting a kid excited some way or other.  Certainly that's how we did it.



STEVE:  If it's too dry, you're going to lose a lot of people because they're going to go, oh, who cares about...



LEO:  Every single one of us in our generation got excited because, you know, learned because we got excited by usually small computers - in your case a PDP-8, but my case an Atari, many people Apple or Commodore - and figured it out on our own.  We weren't taught, but we figured it out.  But I think now that's the debate is, well, is that the best way to start out?  But I think you're right, if you don't get excited about it, if you're not inspired and turned on by it, there's no point...



STEVE:  And also, Leo, times have changed.  Back then a teletype spitting out X's was...



LEO:  Was exciting.



STEVE:  That was a lot of - that was sensory overload for us back then.  Now...



LEO:  These kids are a little different, yeah.



STEVE:  I don't think you can possibly sensor overload a modern teenager these days.



LEO:  No, you're right, you're right on that one.



STEVE:  So it takes a lot more to get there, to get to the same level.



LEO:  Well, thanks for the input.  I really appreciate...



STEVE:  Yeah, do check it out.  I think our listeners should, too.  Anyone who's interested in, like, dabbling around with simple programming, this Basic-256 is very cool.



LEO:  I will take a look.  Greg M. in Fort Wayne, Indiana wonders about expired SSL certificates.  Danger, danger, Will Robinson.  You wrote that in.  But I had...



STEVE:  No, he...



LEO:  He wrote that in?



STEVE:  He wrote that, yeah.



LEO:  Danger.  By the way, somebody took your backwards...



STEVE:  My "sna-na ba-na-ni, pa-shor-yor-nar-ros"?



LEO:  And sent me the reverse.  And it did, it was perfect.  I was very impressed.  Sounded just like an alien.  Hi, Steve and Leo.  First, I want to think you for a great podcast.  You helped me to ace my Security+ certification.  Yes.  The podcasts on encryption came at a perfect time. 

 

After listening to the SSL and TLS podcast, a question came to mind that I do not recall your ever talking about.  Neither was this covered in my Security+ class.  What about an expired SSL certificate?  Not that I'd use a site with an expired certificate, but many everyday users might just click by any warnings and continue on.  If everything else with a cert is okay, would a user's data still be encrypted?  Oh, that's a good question.  Thanks for the podcast.  Keep up the good work.  What happens when they expire?



STEVE:  A really good question.



LEO:  Yeah.



STEVE:  We've never talked about ever exactly that, this notion of expiring certificates.  I'm annoyed by it because it seems primarily designed to guarantee revenue to the certificate issuers, number one of course in the world being VeriSign.  And believe me, every two or three years they get more money from me.  However, there is nothing insecure about an expired certificate other than the fact that it has expired.  I have visited websites where I got an expired certificate warning.  Now, I'm immediately worried about,  okay, well, what does this mean about the management of the website that they would have an expired certificate?  If I check, and when I have, normally it's only been expired like that day, or maybe the day before.  So it's not like they've survived a long time.  They're probably scurrying around...



LEO:  Oh, boy, it expired, we forgot.



STEVE:  Exactly.  They're, like, trying to cram an emergency recertification through VeriSign or whomever as quickly as they can in order to replace it.  But the certificate continues to work.  It is just as secure.  Now, I'll add a caveat to that to say, well, technically the longer something like this exists, the greater the chance is for it being hacked.



LEO:  Right.



STEVE:  So in theory you expire these because, well, also there's that the certificate implies a representation of you, your existence, your organization, your location, your going concern, which is being made by the signer of the certificate.  So the signer, in my examples often VeriSign, is saying, well, yes, we've checked you out, and you're breathing, and you're a good person, and you were a Boy Scout once, so we're going to sign the certificate for you.  But if you suddenly go to the dark side, within a couple years this certificate will have expired.  So our representation about you is time-limited.



LEO:  It's good security policy.  You know when I create a PGP certificate, I usually say expires in a year.  Frequently the passwords that people assign in a corporate environment will expire in a month or two months or three months.  That's not a bad thing. 



STEVE:  No.  And again, exactly, so stale information that's getting older has just a greater chance of exposure, greater chance of leaking out, getting out and so forth.  So there's some reason to understand, I mean, there's some justification for certificates expiring.  I would just say that, well, to answer Greg's direct question, there's nothing in any way more dangerous.  I would say consider the circumstances, consider the website, maybe ask or determine why it's expired, how long it's been expired.  But it actually can be that expiration can sneak up on the owner of a certificate.  I'm knocking on wood here that that's never bitten me.  We've always had plenty of time.



The other thing I will mention, I've been worried about renewing a certificate well before the expiration date, wondering if I would get credit for how much earlier I am over the expiration.  The good news is I've confirmed I do get credit.  So sometimes I remember, before I was sure of that, I'd wait till not many days before expiration because I was already pissed off that I was having to pay so much money so often for, like, nothing, for some bits, essentially.  But now I know that when I get my first email notice from VeriSign that, hey, you've got some certificates coming due here, it's like, okay, good, do it now because they're going to extend me from the actual time of expiration, not the time of renewal.  So for people who have certificates, that's something good to know.



LEO:  Moving along.  Jonathan the IT student from Roseville, California doesn't like NAT.  It sounds like a kid's book.  Jonathan doesn't like Nat.



STEVE:  Get those gnats off me.



LEO:  I just listened to episode 199.  And while I liked the episode, I have to take issue with what you said about IPv6 vs. IPv4 with NAT.  While NAT is an acceptable stopgap before we run out of IPv4 addresses, it is not an acceptable permanent solution.  We said that IPv4, we were running out of numbers, but thanks to NAT it's not the critical situation it was before.  The problem with NAT is that it breaks up the Internet into segments, while the purpose of the Internet is to bring people together through the computer.  Not through my router, however.  But all right, we'll get to that.  Essentially it cripples, while not breaking, the Internet.  For example, my brothers and I like to play Battlefield 2 together in Co-Op mode.  To do so one of us has to act as the server and the others connect in through their IP addresses.  My parents' house, however, is behind a NAT router at the ISP level, so there is no way they can serve as the server.  With me playing behind my college campus NAT, fortunately I have at least one of us, at least one of us is on the Comcast network and has a public address.  NATs are not a solution, they are just a patch.  Is the IPv6 solution better than NAT?



STEVE:  Well, okay.  This brings up an interesting point, and something that I failed to mention when I was talking about this last week, and Jonathan's note reminded me.  And that is that another aspect of this issue of addressing really goes back to sort of the original Internet sort of UNIX guru purists.  These are people who fundamentally believe what Jonathan is saying.



LEO:  One CPU, one IP address.



STEVE:  Yes.  That every single machine on the Internet should be available by a unique IP address.  I mean, that's like - that was the fundamental concept in the beginning was every one of these machines would have an IP address, and this amazing routing architecture with packet forwarding would allow by this incredible technology any machine to reach any other.  These are the same people who are really annoyed by the notion of stealth because, oh, that's breaking the fundamental structure of the Internet.



LEO:  You're talking about the thing - you coined this term, the idea that a router might not respond to a ping from another router.



STEVE:  Yes.  Yes.  Or, exactly, or, well, yes, precisely.  And then the idea that an ISP would be blocking the ICMP because they don't want their internal networks to be tracerouted.  And again, the purists are, like, infuriated by this.  It's like, wait a minute, that's - any machine, any router, any hop, any endpoint needs to respond to ICMP because that's the underlying low level intermachine glue that allows us to figure out what's wrong with the Internet, where something's broken and so forth.  And, sadly, this is not the way the world turned out.



What they're saying is, that purist view says everybody on the 'Net is a good guy.  And everybody has everybody else's best intentions and doesn't wish anybody ill.  Unfortunately, we really know that's not the case.  So here's Jonathan, for example, with his example in Battlefield 2.  He's got three people.  He would like them all to have access to each other.  Well, what he's saying is, then, we need no routers and no firewalls.  Because if you have firewalls you still have to configure the firewall to allow access in.  Just as you could, you know, he's saying, well, his parents' house is behind a NAT.  Well, although actually he said "NAT at the ISP level."  Now, that is a particularly extreme form of problem because that means that his ISP is giving him probably 10-dot addresses or, like, all of their customers, or maybe 17-dot or 192.168 or something.  So that's a problem because there's no NAT for them to configure.



So but in the normal case with a residential NAT router, well, okay, it's a firewall.  And so if you want incoming penetration, you need to configure it, just like you would a firewall.  And we now know that there's just no way that Internet use is safe without a firewall.  That is, your system cannot be wide open to the entire Internet.  So again, unfortunately, reality impinges on the Internet UNIX gurus' original immaculate conception of what the Internet could be.  And we know that the 'Net has lots of bad people who do not wish us well.  And we need to protect ourselves from them.



LEO:  Is it possible that you could have that kind of an open system and still be secure, I mean, with other techniques?



STEVE:  Well, you could certainly have per-machine addressing, i.e., or  la, IPv6.  You could have per-machine addressing.  But you're absolutely going to have a firewall.  I mean, to not have a firewall means to trust, I mean, absolutely trust all of the code that you've got running on your machine, I mean, which are increasingly complex today.  One of the things I don't do when I'm running through security news is talk about the 5,000 other applications per week that have security problems, I mean, because they're not major problems for people.  Our OS is our major problem.  But, I mean, all kinds of other security problems exist.  But we don't have time if we broadcasted 24/7, Leo, for talking about all the other problems.



So I just - with our systems being as complex as they are, I can't imagine it being safe not to have a firewall protecting it, that is, to allow a system to be wide open.  It would mean that any applications that people used that were receiving packets would have to be secure against everything.  I mean, Battlefield 2, if it's acting as a server, lord knows what kinds of security problems it has.  I guarantee you it has them.  But because its exposure is limited, thanks to the fact that it's behind NAT routers and behind firewalls, and people have to go to some pain to configure it, that pain is allowing access in a controlled fashion.  If it were uncontrolled, all hell would break loose.



LEO:  We wouldn't want that.



STEVE:  The world is just not - it's just it's not the way it was originally conceived when the Internet was born.



LEO:  All right.  Are you ready for the Tell-Tale TPM?  Jeff in Michigan asks about that.  He says:  Hi, Steve and Leo. Thank you so much for your great podcast and the wealth 

of information, security and otherwise, every week.  My question is if there's an easy way to tell if your computer is equipped with a Trusted Platform Module, or TPM.  As I understand it, TPM is required to use the Windows Vista/ Windows 7 full-drive encryption.  When I tried to enable this feature on my HP tx2500 laptop - that's fairly old, I think - it complained about not having a TPM available and 

would not continue.  For some reason I thought that almost all computers in recent years - oh, no, I'm sorry, this laptop is less than a year old, he says - have shipped with TPM, but I guess I'm wrong.  Since I only wanted to play around with the encryption, it wasn't a big deal, and there's always the great whole-drive encryption available 

through the free True-Crypt we talk about all the time. Anyway, do either of you know if there's a handy utility 

or website that will help me figure out if a computer has TPM available without poring though the chipset and motherboard specs? 

 

I've been a listener of Security Now! since your episode on Internet Anonymity and have loved it ever since.  Thank you again for all the work you put into the show.  It's worth every second.  Signed, Jeff.



STEVE:  Well, here's a few more worthwhile seconds.  Every single machine I have ever seen with TPM has it disabled.



LEO:  Because it would be problematic if you didn't know it was enabled.  Is that right?  No.



STEVE:  Frankly, I don't think so.  But for whatever reason, I mean, I can't think of any good reason to always have it disabled.  But every machine I have, every laptop I have, and I've got a bunch, and also desktops with TPM on the motherboard, if you go into the BIOS, typically under Security, and then it'll have maybe trusted platform or some lingo of some sort that will sort of guide you there, you'll find that it is turned off.  So you have to go through some - you have to basically just mess with the BIOS.  So Jeff in Michigan, what you want to do, you don't need to really do anything except get into your BIOS by F2 or Delete or F1 or whatever it is you do to get into the BIOS, and poke around under the Security section, which most BIOSes these days have.  You'll probably, if your system has TPM, that's where you'll be absolutely definitively determine it.



And if it's off and disabled, as it will have shipped almost certainly, then Windows doesn't know anything about it.  It hasn't installed the TPM driver.  It has no information that there's a TPM underneath that is disabled.  It's completely hidden until you enable it in the BIOS.  And normally it's a multiboot process.  You first enable the TPM.  Sometimes you then have to reboot after saving the new configuration.  Then you need to initialize the TPM, which is sort of a flushing out and cleaning out process to sort of put it into a known state.  So you do that.



And then when you get back into Windows, Windows will pop up and say, oh, new hardware is found, Trusted Platform Module.  Well, what do you know?  And normally there will be a companion driver that came along with the laptop.  Maybe it's already installed.  You may want to check and see if you can find a Trusted Platform Module driver for the particular laptop or desktop model you have because you probably at some point need to let the system sniff that driver in order to incorporate it into itself.  And then you're good to go.



But in every case, for whatever reason, these things are disabled when they ship.  You need to go in and manually say I want Trusted Platform Module services.  Turn them on in the BIOS.  Then they'll surface in the OS, and you can precede from there.



LEO:  Yeah.  I wonder if there is a tool that would tell you.  If it's disabled, it wouldn't tell you anyway.



STEVE:  There are probably...



LEO:  Go into the BIOS.  If you've got TPM, the BIOS is going to say "Turn on TPM," right?  It's going to have some switch like that.



STEVE:  Yeah, well, it does, absolutely.  Every BIOS I've seen makes it very clear.  You just have to dig around in there, typically under security issues, and it'll be an option there.



LEO:  There you go.  Go into your BIOS, look in the Security tab, and see if there's anything about TPM.  That's a good fix.



STEVE:  Yup.



LEO:  Don Daniels in Evergreen, Colorado discovered something about Skype and Universal Plug & Play:  Dear Steve, I was poking around through the settings on Skype, the current version 4.0.0.226, and noticed in the Tools, Options, Advanced, Connection tab there is a block that says "Enable uPnP" that is checked by default.  Panicsville!  I unchecked it, but then thought, well, I'll try an experiment.  So I re-checked it, shut down and restarted Skype, ran UnPlug n' Pray, and it showed no problems.  It said, "UPnP is safely disabled."  Oh.  I see a problem here.



STEVE:  Yup.



LEO:  What is going on?  And thanks, Microsoft, for confusing this issue.  What is going on, and does this default setting in Skype open us up to any security threats?  Don Daniels, listener since Episode 1.  I found you at Episode 18, but I went back and caught up.  So this is really a confusion of terminology is what this is.



STEVE:  It's got confusion coming and going here.  First of all, when he referred to UnPlug n' Pray, he's talking about one of my closed source, but free, security bits of freeware that I wrote a long time ago in response to a very bad security vulnerability in Microsoft Windows Universal Plug & Play service running in Windows XP before Service Pack 2, when most people didn't yet have a firewall running.  And so there was a remote code exploit which bit all kinds of people, where you could simply receive a packet at your Windows XP system, and because Microsoft's own Universal Plug & Play service was vulnerable, it was a remote code exploit.  You could get your system taken over.



So I wrote UnPlug n' Pray, which all it does is stop the service.  It just disables it and then tells you, okay, that service is safely disabled.  And at the time, nothing was using Universal Plug & Play, so it was unfortunate that it was on, open, running, and vulnerable.  Okay, so what's happening with Skype is different, but it's also a concern.  What you're doing now, and this is an example of sort of Universal Plug & Play beginning to come into use, Skype is saying, hey, you know how Steve and Leo have ports mapped through their routers, so they're able to get really clear connections.  Because Steve and Leo have ports mapped through their routers for Skype, they never use a relay, a third party to relay their traffic.  Remember we were just talking about NAT traversal.  There are some situations that Skype cannot handle.  So in that event, if both of us are behind NAT routers without any ports mapped, and telling Skype to use those mapped ports, Skype may have to bounce our traffic off of a third party that's somewhere out on the Internet that we can both reach because we can't reach each other.



LEO:  They call those the supernodes; right?



STEVE:  Well, exactly, those are so-called Skype supernodes.  So what Skype has now done with this most recent version, I don't know how far back it goes, is they've said, hey, routers are generally Universal Plug & Play aware.  And we've talked about that, how routers enable UPnP also.  So if the router's enabled when Skype is started up, it's able to send a broadcast out onto the network to say, hey, what Universal Plug & Play guys are out here?  And basically every Universal Plug & Play device on the 'Net will enumerate itself.  It'll report in and say - and one of them will be, hey, I'm a router.  And Skype says, hey, great.  I got a little port I want you to open for me.



And so without you doing anything, and remember this is all default, so Skype's default was enabled, your router's default is enabled.  Without you doing anything, Skype has opened a port on your router which is good for Skype, and it's good for your Skype connections.  It means, hey, look, I upgraded to a newer version of Skype, and somehow my connections are better.  What's happened is it's allowed Skype to receive traffic through that port to itself.  That requires that Skype has that option enabled, and your router has that option enabled.  Then they both get together.  And without you knowing it, they do this port mapping through your router.



So that's what that's about.  I can't say that that's a huge safety concern.  I hope that when you shut down Skype it closes the port behind itself; that if it's not using it, it doesn't leave it open.  We hope of course that Skype doesn't have any bad security problems because what we are saying then is that this incoming port is always going to be forwarded to Skype running on your machine.  If there were a security problem, then that could be a security exposure.  On the other hand, in order to get the kind of communication clarity that you want, it's necessary to let two Skype endpoints find each other without going through a relay.  And this certainly does make it much easier to have that happen without needing to go do it manually.



LEO:  So we have, for best results, that's what we do.  We have a dedicated port.  I use 22222.  And so you can use any arbitrary port, usually I would say between 1024 and 65535.  But...



STEVE:  Yes, it wants to be up in the client port range.



LEO:  Higher side, yeah.  So that's why I use 22222.  That's not claimed by anything.  And so that's the same idea.  And then I have to, by the way, port forward any incoming traffic from the router to that machine, the Skype machine.



STEVE:  Correct.



LEO:  And then in theory we are both preventing being a supernode, which could impact your performance, and getting a dedicated port, which should give us better results; yeah?



STEVE:  Yes, exactly.  We have a non-relayed connection because our Skypes that are - Skype uses a trusted third party, that is, there is Skype Central which does all the so-called presence management.



LEO:  Right.



STEVE:  When I start up my Skype, it shows me, of my contact people, who's online.  So that happens by me logging into Skype Central and sharing my contact list, or maybe Skype maintains it for me, who knows in detail how it works.  It doesn't really matter.  But one way or the other it says, oh, here are the people that are also currently logged on that you know.  So it tells me about that.  Then it also knows if I have opened a port for it to use.  So when somebody wants to connect to me, like Leo, when we're initiating this recording and you want to connect to me through Skype Central, it tells your Skype that you're able to reach me on a certain port.  So your Skype sends its traffic to my specially pre-opened mapped port, which comes directly to me, and we're able to get a non-relayed communication.



LEO:  So that's a good thing.



STEVE:  That's a good thing.



LEO:  And that's not any - that's not a security hole unless, as you say, Skype has a flaw.



STEVE:  Yes.  What it means is that incoming traffic will be received by Skype.  And we want to believe and we hope that Skype was written carefully and securely, that it, for example, isn't listening to that traffic when we're not actually in a communication, in a conversation.  I'd be much more comfortable if the packets were just bouncing off of my machine and there was nothing listening, than having, like, Skype always ready to receive something because that creates a larger security target.



LEO:  Our last question.  Are you ready, sir?



STEVE:  It's a quickie and easy one.



LEO:  Jeffrey Dunn in Riley TWP...



STEVE:  And I don't know what that is.  I Googled it, TWP, where is that?  What is that?  That's where he said he was.



LEO:  Don't know.  I'm sure we'll find out.



STEVE:  Yeah.



LEO:  Anybody in the chatroom have an idea?  What is TW - oh, Township.  Riley Township.



STEVE:  Okay.



LEO:  Thank you.  We have a lot of - I tell you, our chatroom...



STEVE:  Smart people.



LEO:  That's my brain.  They're good.  Yeah, Riley Township, we don't know where that is, but it's somewhere they have townships.  Which could be almost anywhere.  Wonders about BRIEF and syntax highlighting.  Steve, I heard you mention that you use BRIEF, which is an ancient, I mean ancient, text editor.  I was curious, does your version have syntax highlighting?  It had been a while since I used BRIEF, but I dug out the floppies and have started using it again.  I forgot how productive I could be with it.  This is a DOS program.



STEVE:  Yes, it is.  And it will not run in Windows 7 because...



LEO:  Oh, no.



STEVE:  Yeah.



LEO:  So finally it comes to the end of its life.



STEVE:  Not yet, because I'm not running Windows 7 yet, either, so.



LEO:  And may not be for some time to come.



STEVE:  Long time ago, far...



LEO:  This was a programmers text editor that Steve still uses.



STEVE:  Yes.  I mean, it's even an acronym for Basic Reconfigurable Interactive Editing Facility.



LEO:  Because it's totally configurable.



STEVE:  Oh, it is.  It's phenomenally.  And I've completely reconfigured mine.  However, syntax highlighting is a fantastic thing to have.  And editors at the time did not offer it.  There was a piece of freeware that came out called Colors.  And it's interesting because you would run it, and it would kind of go resident in the same memory as other applications that would then load on top of it.  It would turn around and then load BRIEF.  But it had hooked a whole bunch of so-called interrupt lines to the BIOS for the keyboard, for video output, for the timer and a few other things, so that it was able to determine when text changed on the screen.  And when text changed on the screen, it would quickly go up, check to see what had changed, check a configuration file that the user provides, and color it.  So essentially it provides sort of third-party instantaneous coloration of text in a DOS box.  And it works perfectly.  I've been using it for nearly 20 years.



LEO:  Wow.



STEVE:  It was freeware.  Excuse me?



LEO:  Wow.



STEVE:  It was freeware.  But I was so in love with it that I didn't want ever to not have it.  So we paid, as I remember, a couple thousand dollars for the source code.



LEO:  You're kidding.



STEVE:  No.  Because, I mean, this thing was so cool that I thought, well, if it ever - if there's something I need that it won't do, I want to be able to do it.



LEO:  What's it written in, C?



STEVE:  I don't even remember.  I never compiled or assembled the source.  I never needed it because the thing has worked perfectly all this time.  I mention all this because, being free, I can let people play with it.  And so it is available.  Several other people, listeners and people in our newsgroups, have asked, hey, Steve, I love the screenshots you've shared of the way your code looks.  I want mine to look the same way with colors.  So the URL is GRC.com/miscfiles, as in miscellaneous files, /colors.zip.  And in there - I spent a couple hours last week putting together some documentation just out of my own memory and gave some examples.  The configuration file that I use is there.  The little couple hundred K, I don't even think it's that big, Colors EXE is there.  Again, it's free.  The source is not there because that we purchased, and I don't have the author's permission to share that.  I don't even know who it's written by.  I looked through the EXE trying to find any name or anything.  But that's been lost to history.  But I do know that it was freeware.  So GRC.com/miscfiles/colors.zip.  And anybody who wants to play with it is welcome to do so.



LEO:  Wow.  That is great.



STEVE:  And it colorizes DOS boxes.



LEO:  Really cool.



STEVE:  Yeah, it's really neat.



LEO:  Really cool.  And of course any modern text editor does that without any additions.  But you don't have all the key bindings.  You can't use dot commands and stuff like that.



STEVE:  Well, and nobody supports Assembler.  Imagine that, Leo.



LEO:  Nobody?  Nobody supports Assembler?



STEVE:  Nope.  Nope.



LEO:  Oh, that's interesting.



STEVE:  Yeah, well, because no one...



LEO:  So you do need that.



STEVE:  ...[indiscernible] with crazy people, yeah.



LEO:  Huh.  Well, that's kind of intriguing.  Just the crazy folks.



STEVE:  Just the crazy - just us crazy people.



LEO:  I think more people should write in Assembler.



STEVE:  Well, actually there's been a little bit of a groundswell of interest as a consequence of me having talked about it as much as I have.



LEO:  Oh, that's nice to know.



STEVE:  So, yeah.



LEO:  That's great.  All right, Steverino.  We have come to the end.



STEVE:  Episode 200 is behind us.



LEO:  200 episodes.  It's exhausting.



STEVE:  Eight more, and we wrap up year four at 208.



LEO:  I don't know which is a bigger deal, year four or 200th episode.  Anyway, congratulations.  I'll toast you with a glass of Cab.



STEVE:  Sounds great.  Now, hey, speaking of which, I wonder if that 208 episode is you in China because that's two months from now.



LEO:  No, no, I'm going to China in about three weeks.



STEVE:  Oh, okay.  Then we're going to have to be doing double episodes here soon so we can continue never to miss one.



LEO:  We will.  I'm going to be in China July 2nd through the 18th.  And while we will miss some shows, we're not going to miss this one because Steve's unswerving commitment to never missing an episode means that we'll have to double up before I leave.  So if you do watch this live, and we do do it live every Wednesday at around 11:00 a.m. Pacific, that's 2:00 p.m. Eastern, 18:00 UTC, and probably the next couple of weeks we'll do two in a row.



STEVE:  Yeah, actually I have a note here.  I just fired up my little Post-it Notes app.  It says Security Now! double recordings June 24th and July 1st.



LEO:  Okay.  So we're going to get right up to the edge there.



STEVE:  Does that sound right to you?



LEO:  That does sound right because I leave July 2nd.



STEVE:  Perfect.



LEO:  Thank you, Steve.



STEVE:  Okay, my friend.



LEO:  Happy 200th.  And we'll see you all next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#201

DATE:		June 18, 2009

TITLE:		SecureZIP

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-201.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo examine the operation, features, and security of PKWARE's FREE SecureZIP file archiving and encrypting utility.  This very compelling and free offering implements a complete PKI (Public Key Infrastructure) system with per-user/per-installation certificates, public and private keys, secure encryption, digital signing, and other security features we have discussed during previous podcasts.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 201 for June 18, 2009:  SecureZIP.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure, Windows - and there he is.  Look at the smiling, shining face of Steve Gibson from GRC.com, the creator of - I shouldn't say the creator of spyware, the coiner of the term "spyware."



STEVE GIBSON:  Oh, yes, please.  I've never created any, and I never would.



LEO:  Nor was he really the discoverer.  Well, I guess you were.  It was something you found on your system and raised the alarm.



STEVE:  Yep.  Certainly it existed before.  But I found a piece, and it was during a conversation with Gregor Freund that I said, you know, this is spyware.



LEO:  Gregor.  Gregor, this is spyware.



STEVE:  He says, oh, I like the - he says, "I like that, that spyware."



LEO:  Well, Steve, what are we going to talk about today?



STEVE:  Today something very cool that I mentioned a couple months ago that I wanted to get to, and today seemed like a perfect opportunity.  And this is sort of where the formal ZIP utility has evolved to.  We talked about it briefly in the past.  And this is something called SecureZIP, which is a very compelling set of features in a 100 percent free download from the people who invented the ZIP format, PKWARE.  And of course...



LEO:  Oh, yeah, that's Phil Katz; right?



STEVE:  Phil Katz.  PK stands for Phil Katz, K-a-t-z.  And he - you remember old-school back - the whole SEA, remember SEA and the older sort of prequel to the ZIP format.  There was...



LEO:  SEA, yes, yes.  But before ZIP there was ARC; right?



STEVE:  Oh, yeah, I think ARC predated - A-R-C, right, predated.  And anyways...



LEO:  SEA was Self-Extracting Archive, so that was a ZIP.  But it was a ZIP you could double-click.



STEVE:  Well, yeah, right.  And in fact, you know, there have been self-extracting ZIPs and EXEs that use this compression and so forth, where they bundle into the file the little decompression engine.  What is exciting about this program is, for many of our listeners, this could be their first exposure to the so-called PKI, in this case not Phil Katz.  This is Public Key Infrastructure that we've talked about.  In fact, we've been - this is like a perfect, practical, real-world example of all the stuff we've talked about before, that is, public keys and private keys, symmetric and asymmetric encryption.  SecureZIP has all that but has wrapped it in a really user-friendly package that frankly, as I've been playing with it, it's like, wow, this, I mean, this just works.  I've got friends who I don't want to find out about this because they will never send me a non-secured, non-encrypted, non-digitally-signed ZIP again because it's just too fun to do it.  So anyway - and, of course, super secure.



LEO:  Now, there are freeware programs, I use one called 7-ZIP, that do ZIP.  In fact, nowadays Windows and Macs both come with ZIP compression built in.  So PKWARE has to come up with something better to convince people to buy something; right?



STEVE:  Yes.  And I'm going to explain today what they've done and why this is - as I said to you before we began recording, Leo, you're going to be a little jealous.  Now, it isn't available for the Mac, which is why I said you'll be a little jealous of the Windows platform.  They have a bunch of support for IBM mainframe end of things, and also UNIX and Linux servers.  But the only desktop product is available for Windows.  Which, as they point out, is still the lion's share of the market.  But it is - it's really slick the way they've put this together.  So I'm going to tell our listeners all about it today.



LEO:  I can't wait to find out about it.  Also I imagine there's some security news from the front lines of security.  But not much.



STEVE:  Not much this week.



LEO:  It was all last week when we had that gigantic 31...



STEVE:  Well, you know, that was a record breaker.  It was a formal record-breaking update.  So, yeah.



LEO:  31 patches.



STEVE:  For Windows.



LEO:  For Windows.  But we did get a big one from Apple.  I guess Apple finally sat up and listened.



STEVE:  Yes.  We talked about this last week, and maybe even the week before, that there was still - that they were the only surviving remaining platform that had not dealt with the at that time very well-known, substantial, significant, important, even critical Java problems, you know, known problems with the Java system.  So when I turned my Mac on a couple hours ago to get it warmed up for our podcast it said, oh, you've got a 158MB security update.  Now, what's interesting, in my case, I don't know why, but it failed the first time.  It just said, uh, can't update you.



LEO:  You know, mine did, too.



STEVE:  Isn't that interesting.



LEO:  I think maybe if a browser is open or something like that.



STEVE:  No.  I never had - at no point did I have any  browser open.  It just - it was the empty machine with nothing running.  But it said, uh, no, sorry.



LEO:  That's funny because I was going to investigate because it failed.  And I thought, oh, I must have something going.  So even then.  But yet it did it later.



STEVE:  Yes.  Well, I just stopped, I rebooted, tried it again, and second time was a charm in this case.



LEO:  All right.  I'm going to do that.



STEVE:  Who knows what was going on.  But it's like, okay, fine.  And so it did a 158MB update and restarted the machine after that.  Actually, it didn't.  It didn't need to.  I did just because...



LEO:  Why not?



STEVE:  ...reboots are good, yes, and I had time.  But it did not make me reboot afterwards.



LEO:  Just to recap, what was the flaw?



STEVE:  You know, I wish I were better prepared to answer.  I've forgotten now what it was.



LEO:  Yeah.



STEVE:  I know that...



LEO:  I know it was very serious.  It allowed a hacker to craft a malicious Java applet and put it on a web page that would, without warning, I think, give them access to your system.



STEVE:  That's exactly what it was.  I'm just bumping back here through...



LEO:  Well, anyway, people can explore that.



STEVE:  But essentially, get it.



LEO:  Yeah.



STEVE:  You know, this is not one where it's like, uh, do I really need that or not?  Yes, you do.  You want that.



LEO:  Yeah, yeah.  Thank you, Apple, for - you know, it's interesting what happened there.  We talked about this a couple of weeks ago.  The guy who discovered this exploit finally tired of Apple's inaction.



STEVE:  Right.



LEO:  And as sometimes happens in the security community, he pressed the company into action by releasing code.



STEVE:  He said, okay, you guys have had lots of time to get this fixed, and you've had notification.  So...



LEO:  It's on you now; you know?



STEVE:  Exactly.



LEO:  And it worked.  I don't know if that's the best policy.  But boy, Apple does sit up and take notice when all of its users are at risk.



STEVE:  Yup, yup.  Well, and oddly, it's been a very quiet week in security.  So that's all I had to offer...



LEO:  Good.



STEVE:  ...in terms of news and anything that is significant.



LEO:  You'll never hear me complain about that.



STEVE:  I thought I would take that example to, or I would take this opportunity to share a little bit longer, although when I was actually reading it, it's like, okay, it's not that much longer, little SpinRite story from a David Brant, who sent this at the beginning of June.  He said, "I've owned SpinRite for a couple of years now, so I have a ton of routine SpinRite success stories that I could tell.  But that would just bore you."  Maybe not.



LEO:  I don't think it would bore Steve, no.



STEVE:  "So I selected two unusual stories for your entertainment."



LEO:  Oh, all right.



STEVE:  "First story:  The patient was an aging Pentium 4 PC with 4GB of RAM running Vista."



LEO:  [Doddering voice]  "I'm a Pentium 4."



STEVE:  Yeah, I know.  I was thinking, running Vista?  Okay, I guess it's...



LEO:  I don't know how.



STEVE:  "One fine day I was just writing something in the word processor when, boom, a blue screen.  A real bad one.  It wouldn't boot.  I couldn't even coax it into Safe mode.  Nothing.  The SpinRite CD was sitting there on my desk, so I stuck it in and Level 4'd it."  We're now using SpinRite's levels as verbs.  I Level 4'd it.  I gave it a Level 4.



LEO:  Oh, dear.



STEVE:  Take that.  Take that.



LEO:  Is that the highest level of...



STEVE:  Yeah.  That's full deep cleaning, just, yeah, exactly.  He said, "I came back the next afternoon and tried my luck.  It booted straight into Windows without even offering Safe mode, as if nothing had happened.  Even my document that had been open at the time of the BSOD..." - which is the acronym we know as Blue Screen of Death.  You have to imagine that Microsoft's not happy with that particular acronym.



LEO:  No, no.



STEVE:  So, he says, "I looked around and couldn't find any evidence of lost files.  Perfect.  So I just went right back to work on my document.  About 10 minutes into my new work session, Vista put up a friendly dialogue, telling me that the license for this copy of Vista was already in use on another computer.



LEO:  Oh, geez.



STEVE:  It only gave me the option of purchasing a new license from Microsoft.  Oh, really.  Well, that was it.  That was really it.  I closed my document and quickly copied all my files to another computer.  I shut down the machine and removed the hard disk.  I carried it into the next room where I installed it as the third internal in my main workstation" - get this - "formatted it under Mac OS X Extended, and put it into service as a documents disk."



LEO:  Oh, that's an interesting choice.



STEVE:  This guy has obviously multiple platforms and machines to run on.  And he thought, hey, I'm not buying another copy of Vista just because Vista decided that I've pirated it.  I'll just turn it into a document storage.  He says, "That was about a year ago.  It has been working perfectly ever since, thanks to the Steves."  And he made that one plural, apparently lumping me in with Jobs.  And then he says, "P.S."  And of course remember this guy's name is Dave Brant.  He said, "P.S.:  As I write this, I am half watching a little sci-fi flick in which another Dave has also become quite exasperated..."



LEO:  "I'm sorry, Dave."



STEVE:  Uh-huh, "...has also become quite exasperated with his computers telling him what he can and can't do.  He also decided to dismantle it.  Perhaps this was Kubrick's most prophetic insight..."



LEO:  [Singing]  "Daisy, Daisy...."



STEVE:  "...into the world of the 21st-century computing."



LEO:  You know, I use that - of course talking about Hal in "2001," I use that on my radio show.  Almost - at least monthly somebody'll call up and say, "My hard drive, I've been getting strange errors or whatever."  And I'll say, "Well, immediately back up because it could be failing."  But it's still operating, or it's making funny noises.  So I always use that line from "2001" where Hal says, "I suggest we put the unit back into operation and let it fail."  Because, you know, I mean, well, I usually say, "Buy SpinRite."  And then when they balk, because they often do because SpinRite costs about the same as a new hard drive - people buy SpinRite when they have data that they've got to get back; or, and this is why I bought it say back when, if you use a lot of drives.  If you're always, you know, if you're putting - we go through a drive a week on the TriCaster, stuff like that.  If you're, you know, we have dozens of computers.  In fact on my desk I have dozens of computers.  If you're always using new drives, then it's really worth, what is it, 80 bucks?



STEVE:  Yeah.  89.



LEO:  Yeah.



STEVE:  So his story number two is a different one, but you'll like this one because it sort of relates to what you were just saying.  He says, "This time the patient was an elderly Series I DirecTiVo."  



LEO:  Oh, yeah.  Those are like gold because they're not protected.



STEVE:  Right.  Or, well, they often have...



LEO:  Less protected.



STEVE:  Yes.  Actually they're hacker-friendly.  You can do all kinds of things to them.  And you can get them with lifetime paid-for subscriptions that never expire as long as TiVo doesn't go out of business.  So he says, "...an elderly Series I DirecTiVo.  It still worked fine except that the menu system had gradually become dead slow.  It had gotten to the point where it would take a minute or longer to respond to a single down-arrow press.  Once you had brought up the main menu, it could take as long as 15 minutes to navigate down the Now Playing list to choose the show that you wanted to watch."



LEO:  Now, my experience there is if you reset the TiVo it usually, you know, erase all data and start over usually fixes it.



STEVE:  Well, he didn't have to do that.  You know what he had to do.



LEO:  Oh, interesting.



STEVE:  He says, "I realized it was time to act.  I wrestled the hard drive out of the TiVo."  And actually that is - that does take some wrestling.  They use the Torx screws for everything.  And you have to have a #10 and a #15, I think they...



LEO:  I have my Torx tools with me at all times.



STEVE:  He says, "I wrestled the hard drive out of the TiVo and installed it in a spare PC."  He says, parens, "(See story number one, above.)"  So that was apparently the machine that was now free of its hard drive he used as his SpinRite operating station.  He said, "I planned to Level 4 it, but needed to change my plan.  Instead of the usual screen, SpinRite put up a screen that said something like, 'WARNING:  DANGER AHEAD.'"  He has it here in all caps.  He says, "I forget the exact wording.  It had determined that drive failure was imminent and even one SpinRite run might be the last thing it ever did.  It told me to copy any files I could first.  But I decided to go for it anyway.  When it got started I noticed on SpinRite's SMART monitoring screen that the top row was all red.  No wonder."



LEO:  Wow.  That means - all red means that the sectors are bad?



STEVE:  It means that the - and the reason he immediately got that warning was that SpinRite was - one of the first things SpinRite does is ask the drive, "How are you feeling today?"  And the drive was able to say, "I'm really sick."  In which case SpinRite says, "Whoa, hold on.  Just to let you know, the drive is saying that it doesn't have much life left."  Which is really, it happens in this day and age, and real-time continuous background SMART polling is one of the features that I added in the SpinRite 6 from SpinRite 5.  Remember it was a little controversial at the time among our developers, the people who hung out in the SpinRite.dev newsgroup because they were saying, "Oh, you can't really be polling SMART all the time."  And I said, "Why not?"  "Well, we don't know.  But we heard you can't."  That's like, okay, fine, well, I'm going to ignore that.



LEO:  SMART has a lot of - SMART has a lot of mythology because it doesn't, you know, it kind of works, it doesn't work, I mean, nobody knows what it's supposed to do.



STEVE:  Yeah, well, and the problem is that there isn't a defined set of meanings for these parameters.  They're just sort of like, oh, it's not as good as it should be, or it's like sort of a number.  It's like, well, what does that mean?  We don't know.  But if it's lower, that's worse.  It's like, okay, fine.



LEO:  Um, okay.



STEVE:  So anyway, I've managed to integrate all that into SpinRite so that it does the right thing.  And in this case SpinRite was saying right off the bat there's a problem.  So he says, "It survived its intense SpinRiting, seemingly without expiring on the operating table.  I reinstalled the drive into the TiVo and hoped for the best.  I went into the menu after bringing up the TiVo and found that the problem was completely cured.  The menus were now as fast and responsive as new.  So maybe a routine run of SpinRite every few months might help a sluggish PC, as well.



LEO:  Okay.  It would, wouldn't it.  Because as we've talked about before, sluggish can mean it's just trying really, really hard.



STEVE:  Well, I would say it could.



LEO:  Could.



STEVE:  Wouldn't say it would.



LEO:  Yeah.



STEVE:  In the case of DirecTiVo, well, or any of the TiVos, one of the things that they do is they redundantly store all of the critical system files and other material in multiple places, specifically so that it can generally survive the slow death of the hard drive.  You know, there's no provision for TiVo to say the hard drive is having trouble because it's meant to be a turnkey consumer product that you just sit down and plug in and you never think about it.  I mean, the idea of, for me, TiVo is always recording.  Everything coming in is going onto the hard drive into an on-hard-drive buffer.  So when you pull the cord out of it the way you do a VCR or a clock radio or anything else, you've just blown whatever chunk of drive was underneath the head at that time because it was busy writing.  So when you pull the plug out of it, it's unable to finish that.  But the TiVo system is designed to heal itself, or at least survive that kind of abuse.  For myself, I always go into the menu system and do a system reset if I'm going to unplug it.  That way basically it's rebooting, and it's not in a mode where it's writing to the hard drive.  Then I'll pull the cord out if I have to move it somewhere else, or if our power company has notified us we're going to have a power failure in the afternoon to repair equipment and so forth.  So, yeah.



LEO:  Very, very good stuff.  You know, if you've got one computer and one hard drive, okay.  But, yeah, everybody should really own SpinRite.  I just think it's just a natural thing.  And a TiVo.  That's a really interesting use of it.



STEVE:  Well, we do hear from a lot of people who have SpinRite and who say, hey, I'm still waiting for my success story.  I'm running it on all my drives.  So maybe I'm never going to have one.



LEO:  I think you need it less if you use it all the time; right?



STEVE:  Oh, you probably need it never.



LEO:  Right.



STEVE:  I mean, all these stories where finally the drive died on some event, some morning, his BSOD where he ran it and it fixed it.  Had he run it the day before, it wouldn't have died the day after because it would have had a chance to, I mean, it's sort of like you could think of it like defragging, but in the preventative sense, like defragging puts things back where they have sort of wandered off from.  Well, running SpinRite really reads and rewrites the entire drive in a way that allows the drive to deal with incremental low-level problems, underneath the level of the file system, before they get to be really severe.  So certainly a good thing.



LEO:  All right, Steve.  Let's talk - you're going to - okay.  Steve has a challenge.  He's going to make me jealous.  How could you possibly make me jealous?  I have built-in compression on my Mac.  What more could I want?



STEVE:  Well, what...



LEO:  That's a setup.



STEVE:  Yeah.  What PKWARE has done is they've evolved their PKZIP program - and PKZIP still exists separately from SecureZIP.  SecureZIP offers all of the kind of technology we've been talking about in the past in a really simple-to-use, state-of-the-art, really pleasant user interface.  But they've basically taken all of the configuration and setup hassle out of the process.  The program will compress files in ZIP format, TAR, BZ2 - which is Block Zip 2 - BZ2, GZIP.  It'll UUEncode, XXEncode.  Also will compress in LZMA, PPMd, and Java (JAR) files.  It can open and decompress ZIP, TAR, JAR, BZ2, RAR, GZIP, CAB files, LZH, LZMA, PPMd, UUEncode and XXEncode.  So it's not just ZIP format.  It's a broad spectrum archiving utility.



What really makes this thing stand out is the built-in and really easy-to-use support for asymmetric, that is to say, public key encryption.  As you install this in your system - it's about a 20MB download.  They use CacheFly as their delivery system.  If you just put into Google "SecureZIP," the first link that comes up is to the free SecureZIP download.  There is a commercial version for the individual user.  There's also lots of enterprise support for this.  So for our listeners that have more of the corporate IT enterprise side, keep that in mind when I'm talking about this.  I'm focusing sort of on our typical listener end-user person.  But there's tons of enterprise stuff.



So if you wanted a purchase-it version, it's $39.95 for a single end-user person.  But what that gives you is integration into Office and email, that is, seamless integration where, like, in the file menu of Word there's "Save as a secure file."  And so it's just as simple as selecting that option in the file menu, and you're able to do that.  So the free version has that stuff for 30 days so you can see what it's like, decide if it's worth to you $39.95 to keep that after 30 days.  If so, you're able to upgrade and do it.  Otherwise it'll go away after a month.  And you're still able to use SecureZIP with its nonintegrated features, which is just like a standard archive manager, which in my opinion is still spectacular.  I'll explain why.



During the setup you give it your name and your email address.  It then transparently, sort of automatically, goes to Comodo and registers a certificate, a standard PKI - Public Key Infrastructure - certificate, under your name and email address and creates it, downloads it, and installs it, all sort of automatically.  So you end up with a private key installed in your certificate store in Windows which you're able to use to sign or encrypt any of the archives that you create with this.  So the other thing that you get is it automatically places this in the SecureZIP global directory for - that is, it places a reference to your certificate, and the public key is available globally.



So what it means is that somebody else who is also a SecureZIP user is able to build an archive that they want only you to be able to access.  They literally, when they say they want to encrypt it, they're able to put your email address into the program itself, which transparently queries the global directory to get your public key.  It then encrypts the archive using your public key, creating an archive that absolutely only you, that is, the machine where you've set up your SecureZIP, are able to decrypt.  And what's even cooler is, if you only select that user's public key, you get a little warning dialogue that says, hey, we're happy to do this for you, but you're encrypting this with only this public key.  Not even you can decrypt it.  And so it says, you know, you could if you'd like also encrypt it with your public key so that you have the option of decrypting it if you ever, for whatever reason, want to.  So it gives you a little reminder that basically, when we're saying only that the destination user can decrypt it, we're not kidding.



LEO:  Right.



STEVE:  Now, we know...



LEO:  That's great.  That's really neat, yeah.



STEVE:  Oh, it really is cool.  And the other thing you can do is you can sign it.  Since you and only you know your private key, you're able to sign the archive or sign a file.  You don't even need to encrypt it.  You can just use SecureZIP as a public key technology signing tool.  So you're able to apply your digital signature to the archive.  So you could do two things.  You could encrypt it using a public key that is just found for you using your target user's email address, which this thing finds for you.  The whole thing is transparent.  It just says, oh, here's the person.  And you go, yeah, okay, cool.  I want to encrypt it for them.  And I want to sign it so that they know whatever this is actually came from me.  So that process is just done beautifully.  I mean, I'm really impressed with the whole UI of this.  It just couldn't be any easier.



Then you end up with this ZIP file, which you can then email or stick on your website for somebody, I mean, get it to them however you want to.  But only their system where they have this certificate installed is able to read it because - so they've got the private key on their system.  So when this ZIP comes, they're simply able to open it.  I mean, it'll open.  It won't open anywhere else, but they're able to open it.



And in addition to all this, you also have secure passphrases so that you could also protect it, not only with a public certificate, but you could also protect it with a passphrase that's as long as you want it to be.  There's a big, plenty ample dialogue box where you're able to type in anything that you want to, which will further lock this ZIP so that the recipient would have to have both the knowledge of the passphrase that you used this particular time to send or encrypt this particular ZIP file, and they would have to have a digital certificate.  Or you don't have to use digital certificates.  You could just use a passphrase.  So you could use either a passphrase or a digital certificate or both.



And say that you wanted a ZIP file that three people would be able to see, would be able to open, but nobody else.  Again, you're able to simultaneously apply multiple digital certificates so that you've got multiple - you've encrypted it once, yet you've then encrypted the symmetric key which was randomly arrived at.  Remember we've talked about this multiple times.  You don't actually encrypt the payload of the ZIP with your public key.  Instead on the fly you create a so-called "session key," a long, 128, 196, 256-bit whatever, and all of this is just done for you.  You create a completely random session key.  That's what you encrypt with your asymmetric key.  And then the encrypted result is just bundled in with the ZIP.



So the idea is, if you wanted three different people to be able to decrypt this ZIP file, you're able to attach their certificates to that file.  And essentially it takes their public key and encrypts this one-time-use symmetric key for each of them and connects it.  So that when any of them receive it, they're able to open the file, and they're able to inspect the certificates that are bundled along with it.  And, for example, if you decided you wanted to sign it securely, they're able to inspect the signature to verify that it came from you.



It's just - it's beautifully put together.  I mean, and I would recommend it, frankly, to our users, if they want to play around with public key infrastructure technology.  We've talked about this over and over extensively.  Here's just a useful and simple-to-use turnkey application that incorporates all of these concepts that we've been talking about in something which is extremely easy to use.



LEO:  Sounds...



STEVE:  And it doesn't run on the Mac.



LEO:  That's okay.  I can live.  I can live.  It does sound great.  So reiterate.  The features that I'm not going to get if I don't pay for - I know I get to try them at first.



STEVE:  Yes.



LEO:  But the features that will turn themselves off after, what is it, a month?



STEVE:  Yeah.  All they are, the only things that die after 30 days are the integration into Microsoft Office and Outlook.



LEO:  I don't even use those, so I can live without that.  That's fine.



STEVE:  Right, right.  But all...



LEO:  Everything else works.



STEVE:  Yes.  Everything else works.



LEO:  Wow, that's great.



STEVE:  The certificate has a one-year life.  And it is possible, though, to renew it.  I also, just for the hell of it, I went over to Comodo, and I said, hey, let's pretend you just didn't make a certificate for me through this built-in UI that was easy.  You're able to go, if you put into Google "Comodo personal certificate," the first link that comes up, again, is to Comodo's free certificate.  They call it an email certificate, which is the one that we're using for this case.  And it's completely free.



So I tried this.  I created a - I went to Comodo.  I said, hey, I want a certificate.  I used a different email address, gave them my name.  They sent me email containing an authorization code.  I clicked on that.  The browser, using scripting, automatically created with Comodo, and without me having to do anything else, a certificate just like the one which had been created for me automatically during installing SecureZIP, and installed it in my machine.  Now I have two.  So I didn't even need to use the certificate that SecureZIP created on the fly while I was installing it.  I was able to use that.



And you are able to export the certificate that you've created.  If you, for example, were someone who had multiple laptops or multiple computers, you didn't want to only be tied, didn't want that certificate tied to one machine, you are able to export it and import it into other Windows platforms.  So, for example, you create one certificate, and you stick it on the various machines you're using.  All of those will be able to open ZIP files which have been keyed to your certificate, even though they're on different machines.



LEO:  You know, one thing I did - I'm looking on the web page.  It just says "across all major computing platforms."  But correct me if I'm wrong.  It sounds like if I use SecureZIP on a file, I cannot unzip it on a Mac, for instance.



STEVE:  Yes, I'm sure that's true.



LEO:  Yeah.  So that's a little misleading when they say "all major computing platforms," and they leave out Macintosh.



STEVE:  Yeah, or the Linux desktop.



LEO:  Or Linux.  I mean, it's really - it's a Windows application.



STEVE:  Well, they also - they do have support, non-desktop support for UNIX and Linux servers, they say, for Windows clients and servers, and then a bunch of IBM machines, like mainframe sort of world.



LEO:  Oh, I see.  Okay.  Okay.  I get it.  Yeah, wow, that's neat.  So the certificate I get from Comodo, I don't get from PKWARE.



STEVE:  I hope I didn't confuse people with that.  Either certificate works.



LEO:  Oh, I could use PKWARE's, as well.  Okay.



STEVE:  Yeah.  Well, and PKWARE's actually - PKWARE got theirs from Comodo.  They just did that negotiation...



LEO:  Automatically.



STEVE:  ...through the user interface automatically.



LEO:  I see, I see.



STEVE:  And I was just curious because, okay, so the certificate lasts a year.  And when you first get it you'll see, for example, mine said, oh, it's good until 6/17/2010.  So I'm thinking, okay, what happens after that?  I don't want everything to die or, like, things to stop working.  Well, first of all - and I posed the question to the guys at PKWARE.  And they said, oh, you know, you'll get email two weeks before it expires, telling you here's the link you click to renew it for another year.  And as long as Comodo or anyone makes certificates available for free, you'll always be able to create certificates.  And even if a certificate has expired, all that happens is it's expired.  Remember we talked - actually, coincidentally, we answered this question in last week's Q&A.  Someone said what happens if - like in this case it was a web server certificate expired.  And I said, well, the only thing that happens is you're warned that this server's certificate is expired.  But it still works.  And that's absolutely the case with SecureZIP.  So you could be using a certificate if you were a curmudgeon and for whatever reason five years from now you didn't want to keep updating a certificate.  You're still able to use it, and it still works just fine.  It'll just be giving you warnings saying that the certificate you're using is expired, just FYI.  But it's easy to renew, and still free.



LEO:  Cool.  And somebody who sees an expired certificate may be a little nervous at that.



STEVE:  Well, yes, that's exactly it.  So, for example, if you didn't renew your certificate, and you told somebody to send you a ZIP file - so essentially what this means is that you would be using SecureZIP, and anybody else could send you a ZIP content that is, like, the industry's strongest available security that only you can open.  And so they're able to encrypt it knowing that only somebody with your private key, which is installed on your machine in the Windows certificate store, is going to be able to open this file.  So they might wonder why they were being warned that the certificate that you've told them to use is expired, though they still could use it.



LEO:  Well, this is good.  Yeah, I'm going to download it on my Windows machines.  And be nice to have it on my Mac.  But that's - so it's really - it still can be used as a ZIP utility.  But really, I mean, the idea is transfer and protection of files and encryption.



STEVE:  Well, yes.  It's absolutely...



LEO:  Does all the ZIP stuff, yeah.



STEVE:  It's got all the ZIP stuff.  It's multi-format, you know, BZ2 is a...



LEO:  Oh, is that built in?



STEVE:  Yes.



LEO:  Oh, I love BZ2.



STEVE:  Yeah, I was going to say, it's probably my favorite compression mode because it gets really good compression.



LEO:  I think it's - I don't know of anything that does smaller, let's put it that way, unless it's a specialty for a certain kind of file format.



STEVE:  Right, exactly.  That Block Zip 2 format, that block zip compression is really good compression.  So it will do ZIP and TAR, BZ2, GZIP, among others.  So I'm just very, very impressed.  I think for users who are curious, or I should say our listeners who are curious about learning about, or like, you know, having experience of public key stuff, and certainly anybody who has this need - again, I'm a little maybe of an exception.  I just - I'm not needing to send secure stuff from one place to another.  But I know I've got some friends who, as I said at the top of the show, if I told them about this, they'd be using it all the time.  They'd just think it was so cool to be able to send ZIPs to me that only I could decrypt.  And in fact, if you put "Steve Gibson" into the global directory, you will find me now under SecureZIP since I just used my name when I set up my certificate.  And it's like, oh, you know, cool.  There's my public key, which is available globally to anybody who wants it.



LEO:  Very good, Steve.  That's a nice find.  A lovely little program.



STEVE:  Thought I wanted to tell our listeners that it's very, very cool.



LEO:  PKWARE.com.  You can get it right now.



STEVE:  Yup.



LEO:  And Steve, we'll see you next week for another great lesson in security.  Everybody should go to GRC.com, by the way.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility; also Steve's free stuff like ShieldsUP!, Wizmo, Shoot The Messenger, DCOMbobulator, Unplug n' Pray, and soon some wonderful new software, I know, I know.



STEVE:  Coming, yes.



LEO:  And find out more there about Perfect Paper Passwords, too.  Also show notes; transcriptions for every show, so you can read the shows; 64 and 16KB versions for the bandwidth-impaired.  It's all at GRC.com.  And next week we're going to do question and answer.  So if you go to GRC.com/feedback, you can leave a question for Steve, and he'll be glad to answer at least 12 of them next week.



STEVE:  Yes, and please do, again, GRC.com/feedback.  I really, really love to get everyone's thoughts, feelings, feedback, ideas, everything.



LEO:  Steve, have a great summer day.  We'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#202

DATE:		June 25, 2009

TITLE:		Listener Feedback #69

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-202.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 202 for June 25, 2009:  Your questions, Steve's answers, #69.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure.  And ladies and gentlemen, the star of our show, Mr. Security himself, Steve Gibson.  I can give you a Johnny Olson.



STEVE GIBSON:  We also - yeah, you know, we just lost Ed McMahon the other day.



LEO:  Yeah, isn't that sad.



STEVE:  Really sad, yeah.  He lived, I think he was 86, and then he 86'd himself.  So no one really talked about what the cause of death was.  But of course you and I grew up with him and Johnny Carson.



LEO:  Oh, he was so good.  He was so great.  I think it's interesting because I think you and I are of an age that Johnny and "The Tonight Show" was really important.  I didn't realize Leno had done it for 10 years.  So that's amazing.



STEVE:  Yeah.



LEO:  And now he's moved on, and it's Conan O'Brien.



STEVE:  But you remember the big controversy when it was who's it going to be, Leno or Letterman.



LEO:  Yeah, they made a wonderful miniseries about that.



STEVE:  Yeah, exactly.



LEO:  That was really good.  What was - I can't - was it called "Night Shift"?  I can't remember.  Anyway, hi.



STEVE:  Hello, Leo.



LEO:  How are things going?  First of all, I've got to ask you, how's your DX?



STEVE:  We have that question.  The first question on the show actually is that because I had a note to bring it up last week, and I just - I hadn't written it down, and so I forgot in scanning my stuff.  So let's do that when we get into our Q&A.



LEO:  We'll save it for the questions.  This is a Q&A day, as all our even episodes are.



STEVE:  Yup.



LEO:  At least for the time being.  And, good, so I want to find out about the Kindle DX.  Before we get to our questions and answers, is there any security news to talk about?



STEVE:  Yeah.  Not heavy news.  There was, of course, mega news last week and the week before.  I did want to mention that all Mozilla stuff - Firefox, Thunderbird, and SeaMonkey - have recently been upgraded to fix, naturally, some bad various sorts of remote code execution exploits.  So Firefox needs to be at, as of this podcast, 3.0.11, where mine is.  Thunderbird comes up to 2.0.0.22.  And SeaMonkey needs to be at 1.1.17.



LEO:  As of this recording.



STEVE:  As of this recording.  This is all a moving target, of course.  So but as of this point, that's where you want to have those versions.



LEO:  Now, I'm using the beta of 3.5 on Firefox.  And I don't know if they've updated that.  I presume they have.



STEVE:  Yeah.  I read something about that recently, I don't remember what now.



LEO:  The release candidate one is - let me check.  The last version that I got was release candidate one.  Let's see if they have - I'll check and see if there's an update.



STEVE:  And as I remember, that adds some HTML 5 features.



LEO:  Yes, that's where we're all headed.  And I'm sure you're going to hate that.



STEVE:  I'm hating it.



LEO:  [Laughing].



STEVE:  If it's new, I'm skeptical.



LEO:  Yeah, it doesn't say "beta" anymore, so I guess this is the final 3.5.  I'll check for updates and see if they're updating it.  Nope, no updates.



STEVE:  Now, I did note that we - last week we commented on the release of Safari 4.  And there was a little tweak that they made to it to version 4.0.1.  Not a security issue, just a compatibility issue with iPhoto.  So they fixed a little problem that they had.  This sort of stuff, software development, sort of tends to mature and get finished exponentially, where the rate of things that are being fixed slows down, but it doesn't just stop instantly.  So it makes sense with a big new release like this they would have found something that sort of sneaked through their final qualification.



And then I did want to note something that I just picked up in the news.  We also talked about the iPhone having been updated to 3.0 and all the new features that it offers.  I thought it was also significant that it fixed more than 46 security vulnerabilities.



LEO:  Wow.



STEVE:  That existed in the last version 2.0 release in Safari and Mail.  And that those flaws, which they kept relatively quiet about, could be exploited to make calls without user interaction, execute malicious code, and crash the phone.  So, and also interestingly, that number of fixes is nearly four times as many as in the previous iPhone update.  So they're focusing on it and keeping it clean.  And phones are a target for all kinds of mischief, so it's a good thing.  I mean, it's inherently a communicating device.  Our phones are getting very sophisticated.



LEO:  Well, and they're always online now.  So that's...



STEVE:  Exactly.



LEO:  That's the problem with computers these days, too.  They're always online.



STEVE:  On the topic of my being skeptical of new things, when I was running through the mailbag here, I ran across a question from a listener that was exactly something I was going to mention.  He says, "I love the security show.  I listen to every episode each week at least two or three times.  I can't get enough learning about viruses, bugs, spyware, malware, botnets, backdoors, trojans, spoofing, super worms, rootkits, exploits, ghost nets, hackers, et cetera."



LEO:  Yay.



STEVE:  I'm not sure that he left out anything for the "et cetera" to encompass.  And he said, "In addition, I love studying cryptography, steganography, biometrics, and computer forensics."



LEO:  Steganography is where you put the crypto...



STEVE:  You hide something.



LEO:  ...in a picture or something; right?



STEVE:  Yes, exactly.  I bet, for example, the least significant bits of a high-resolution photo can actually contain, like, a black-and-white image or text or whatever.  And he says, "I've been listening to Security Now! over the past year, so now I'm going back in time, starting with the first episode, which has been really exciting."



LEO:  Oh, that's nice.



STEVE:  "I listen to one or more episodes every day on my iPhone while eating, while showering, while driving, and before going to bed.  Your show is awesome.  Thanks for the hard work, endless security alerts, and motivation to learn more.  So my first two questions are, what do you think about Microsoft Security Essentials, a.k.a. "Morro"...



LEO:  This was just announced last week.



STEVE:  Yes.  "Have you tested the public beta yet?"  And so to answer that question, I have not tested it.  It is certainly interesting.  I think it's going to be significant.  It is essentially, for those listeners who haven't heard of it, it is what's essentially Windows or Microsoft's next-generation of their Live OneCare, which used to be for purchase.  What's significant is this is going to be the first from Microsoft full AV for spyware, malware, viruses, free, which will be available from Microsoft.  And it does not only scanning, but on-the-fly interception and detection.  It'll be compatible with XP, Vista, and Windows 7, not back to Windows 2000, both 32 and 64-bit versions.  You will have to have a genuine certified Windows version that their servers are happy with.  So it will not be able to be used with illegitimate pirated versions that don't get the genuine advantage stuff from Microsoft.



At this point it's beta only, and the beta is closed.  They had it open for about 75,000 users.  It went immediately, bang, and it shut down.  So I wouldn't be saying more about it at this point anyway.  But certainly it will get a podcast as soon as it's available so that it's relevant to our listeners.  And I've got friends where I feel a little guilty telling them that they've got to pay an annual license fee to get AV, or they install a demo version and then it expires, and it tells them, well, you have to pay for this, or it's not going to work anymore.  So I think this is going to be significant.



LEO:  Yeah, we frequently recommend free antiviruses for that reason.  Better a free one, even if it's not as good, than nothing.



STEVE:  Exactly.



LEO:  But you've got to wonder what do Symantec and McAfee do if Microsoft's giving away AV?



STEVE:  Yeah.  This is the steady march of Windows functionality.  I mean, once upon a time it didn't have a browser, and it had no firewall, and it had no AV.  Then it got a browser, and all the browser people were all in a kerfuffle.  Then Windows got a firewall.  Oh, no, it's going to put all the firewall guys out of business.  Well, you know, initially it wasn't very capable.  Initially it was turned off.  Now it's turned on.  So you argue, well, do we really need a third-party firewall now?  And now Windows gets AV.  I mean, it was foreseeable.  It was inevitable.  And I just think, well, the people who were doing those things had a certain window of opportunity to make profit and to get ahead.  And I'm sure they'll stay around.  They'll come up with enterprise solutions and additional features that Microsoft doesn't have.



LEO:  That's what Thurrott said.  He said it just gives - they have to branch out.  They have to expand.



STEVE:  Yes, yes.



LEO:  But the real question is, first of all, I think we both agree it's great that Microsoft's doing this.



STEVE:  Yes.



LEO:  It's kind of almost incumbent on them to provide a security solution for free.



STEVE:  Yes.  And as someone, as I am, who really prefers lightweight, integrated, nice solutions, I will say that the people who have played with the beta are very impressed with how lightweight it is.  Because one of the things, unfortunately, that these third-party kitchen-sink products have evolved into is something heavy, that it's almost more of a problem for your system than actually getting malware.  And this is software that you deliberately install.  I mean, it's hooked into everything.  It's just sitting there really being more of a problem most of the time than the actual problem it's trying to solve.



So the idea that Microsoft has something which is lightweight and simple and free and works and is being updated and - there's some interesting things they're doing that we'll be talking about when we actually cover this in depth in the podcast.  But I did want to just sort of do a little shout-out about it and let our users know that we'll certainly be covering it in depth when it becomes relevant.



LEO:  Yeah.  And of course, yeah, that's the issue, too, is is it going to be as good.  If Microsoft gives it away, it's going to be widely used.  They're not requiring people to download it.



STEVE:  No, no.  At this point, again, it's like we also weren't, once upon a time, required essentially to use Windows Update.  But now...



LEO:  Right, now we are.



STEVE:  ...you're crazy if you don't.  And, yes, and things stop working unless you keep yourself current.  So again, it's foreseeable that at some point in the future Microsoft will say, well, this is just so good for everyone that it's no longer optional.  It's like, okay.



LEO:  Not just for everyone, but for the 'Net.  I mean, really that's the issue.



STEVE:  Yes.



LEO:  You're protecting not just yourself.  And that's the thing I kind of try to beat into people on the radio show.  This isn't just for you.  This is for the ecology of the Internet as a whole.



STEVE:  Right, right.  In the errata category I have two little blurbs.  A reader sent me a fun PDF that was a slideshow that Brian Kernighan of Princeton, in the Princeton Computer Science Department, gave in his CS-152 lecture.  And we were talking the other day, one of the questions in our, I think it was our previous Q&A was prompted by a listener's question, trying to nail down exactly what scripting was, you know, what is scripting.  And we talked about how it's sort of amorphous.  I mean, it's a thing.  I mean, I know what it is, and I know what it isn't.  But when pressed to really define where the boundary is, it's definitely a fuzzy boundary.  Well, what I loved was that in this slide presentation from Kernighan was a quote from Larry Wall, the creator of Perl.



LEO:  The ultimate scripting language.



STEVE:  Exactly.  And so this quote, and I'm not sure where it appeared, where Larry said it.  But he said, quote, "Scripting is a lot like obscenity.  I can't define it, but I'll know it when I see it."



LEO:  Quoting the old Supreme Court, I can't remember which Supreme Court Justice, was it Brennan, who said - I think it was Justice Brennan who said, "I can't define pornography, but I'll know it when I see it."



STEVE:  I know it when I see it.



LEO:  Well, that's actually a good definition.  You do know scripting when you see it.



STEVE:  Yeah.



LEO:  And it's hard to make a technical definition.



STEVE:  Right, right.  I love that.  And then in my final little bit of bizarre, I mean, an event I could have never predicted, literally, in the last couple Q&As we were talking about the expiration of security certificates.  One of the questioners asked, hey, when a certificate expires, what happens?  Does it stop working?  Can you still use it?  Can you still connect to the service and so forth.  And I talked about how every so often I'd run across a website whose certificate had expired, and you got this warning notice that said, hey, the certificate's expired.  And I talked about how you could imagine behind the scenes they were scurrying around.  Actually that's the term I chose.  Well, wouldn't you know it, GRC's main security certificate expired, caught me completely unaware, last Thursday.  And I was scurrying.



LEO:  I got some emails saying does Steve know his certificate has expired?  Now, do they not send you a notice saying your certificate...



STEVE:  They tried.  I have no doubt.



LEO:  I've done this.  I've done this, too, so.



STEVE:  Yes.  They had a three-year-old email address because I signed up for the longest duration certificate I could.  And so when I went back and was scurrying, I thought, oh, that's why I got no notifications was that I'm sure that they were trying, and that email address from 2006 was bouncing.  And so it's funny because I was all settled in at 5:00 a.m. at Starbucks on Thursday for a nice long coding session.  I checked my mail, and Sue, my bookkeeper, had sent me a note the prior afternoon, late in the afternoon, saying, hey, when I tried to connect to GRC to do our bookkeeping stuff, check in with our ecommerce system, I got this notice about a security certificate expired.  And first I'm thinking, wow, I wonder what "she" did.



LEO:  It's her fault.



STEVE:  What is Sue doing wrong now?



LEO:  Yeah, I blame Colleen when anything like that happens, yeah.  What did Colleen, what did "she" do?



STEVE:  So I kind of sigh and go to GRC and try to bring up Perfect Passwords, which is one of many things which, I mean, basically all of GRC is wrapped in SSL.  You go to ShieldsUP!, you need an SSL connection in order to deobfuscate your connection IP.  You use Perfect Passwords to protect the passwords that you're receiving.  That's SSL.  Of course ecommerce is.  And so nothing worked.  It's like, oh, my goodness.



LEO:  That's not so good.



STEVE:  So I checked on the page's certificate.  And in fact, in Firefox, which of course I'm using now, it said, "Your certificate expired on June 16th."  It's like, argh.  So I folded up shop and came scurrying home.  And a couple hours later we were good to go again.  So...



LEO:  How much is that?  It's pretty expensive, isn't it.



STEVE:  Oh, it was horrendous.  And in fact I'm annoyed with myself because it was $2,580 or $2,850 or something.



LEO:  Oh, geez.  Oh, man.



STEVE:  I got it for three years, and I'm buying the best.  I use VeriSign, which is the most expensive there is.  But for some reason three years ago I had upgraded to their "pro" version, which is not the EVA, not the Enhanced Validation that we've talked about.  But I could have spent a thousand dollars, but I would have had to fight with somebody there by phone to downgrade what I bought three years ago.



LEO:  Because the pro version's meaningless, really.



STEVE:  It is.  It forces...



LEO:  It's an upsell.



STEVE:  Yes, it's upsell.  It prevents you from having a 40-bit key, requiring you to have a 128-bit key.



LEO:  But you wouldn't do a 40-bit key anyway.



STEVE:  Exactly.  The export stuff was relaxed a long time ago.  Everyone uses 128 bits.  I completely could have done it.  And then what really bugs me is that, as I think I may have mentioned this once before, last summer when I was working on the DNS spoofability stuff I got a wildcard certificate, *.GRC.com, thinking that I could have used it for anything .dns.GRC.com, only to learn that the star only gives you one domain level of wildcardness.  Well, that certificate was still valid for a few more months because it hasn't been a year.  And I only bought that one for a year because I was experimenting.  So I could have quickly switched to that one, which would have given me then months to resolve the issue of this over-expensive, up-sold, pro certificate.  But of course, with the benefit of hindsight, I didn't realize that I had that extra one until I was installing the one I had just bought.



LEO:  You were in a hurry.  I don't blame you.



STEVE:  Yes.



LEO:  You said, "I've got to fix this."



STEVE:  Well, yeah, I mean, basically everything that GRC is about was down, and in the most embarrassing way possible.  It's like, uh, hello, Steve. 



LEO:  Oh, boy.



STEVE:  Yeah.  So anyway, it's all fixed, and we're better for three years, and I've got all kinds of bells and whistles.  I gave VeriSign a never-to-expire alias for themselves to use, so this time I won't get caught short again.  But I did get a kick out of it because I was just talking about what happens when this happens.



LEO:  So say that again.  So you did something so that you never expire ever again?



STEVE:  No.  What I did was I can set up with my email system various email aliases.  And so I gave them their own personal email address for me.



LEO:  Ah.  So that gets right through...



STEVE:  Exactly.



LEO:  Yeah, yeah, yeah, so you don't miss it again.



STEVE:  So no one else will ever have it.  It identifies where it came from and why.  And it'll always map to my current email address.



LEO:  Oh, that's clever.



STEVE:  So they'll always be able to get through to me.



LEO:  Very clever.



STEVE:  And what I did find interesting was that people were still buying SpinRite.  They pushed past the scary expired...



LEO:  Ooooh.



STEVE:  No, no, I mean, it's fine because...



LEO:  Yeah, but, I mean, there's nothing wrong with them doing that.



STEVE:  Right.



LEO:  But that certificate is what guarantees they're getting a good SpinRite.  They should be more cautious.



STEVE:  No, because it said it expired, that, I mean, it expired right then.



LEO:  Oh, okay.



STEVE:  And that it was from www.GRC.com.  So everything was still there except that it had expired some number of hours before.



LEO:  Got it.



STEVE:  So they still had verification that they were at the right site.  And they were still secure through the whole purchasing process.  They had to make a judgment, okay, how much do I want SpinRite?  I trust Steve.  This thing just expired.  He's scurrying no doubt somewhere, as indeed I was.  So I'm going to go ahead and push through the scary message and purchase SpinRite.  So to our listeners I would say use your best judgment.  Look at, if you run across an expired certificate, when did it expire?  Who did it expire against?  If it expired years ago, then I would worry.  But if it happened that day, they're scurrying.  And if you need a secure connection, you can still get it.  And the rest of the certificate is still as good as it was before the calendar changed the pages.  It's just that, first of all, this is a revenue stream for companies like VeriSign, which really annoys me, but it does help by forcing this constant reproving who you are.  You could argue that the whole issue of these things expiring periodically does increase security, and that's the whole point.



LEO:  Right.  Are there free certs?  Thawte used to do a free cert.



STEVE:  Thawte did before they got purchased.



LEO:  Right.  Now they're VeriSign.



STEVE:  Now they're VeriSign, yup.



LEO:  Yeah.  Okiley-dokiley.  We have some questions for you, Mr. Gibson.



STEVE:  Oh, yes.



LEO:  Would you like to get to those questions?



STEVE:  Let's do it.



LEO:  All right.  Michael in St. Louis asks about a review, as you mentioned, of your Kindle DX:  I was curious when we're going to get the review you commented on in a previous podcast.  I've been really looking at that as a possible reader.  But there's no local store I can go to and put my hands on it.  That is a disadvantage, isn't it.  I'm weary, wary rather, to make such an investment.  I read and have a large collection of technical books in PDF format - there's a good reason to do it - and would like to know how native PDF support works on the DX.  So you've had it a couple weeks now.



STEVE:  [Sighing] And I think your original intuition about it was correct, Leo.



LEO:  Oh, no.  Which was?  I forgot.



STEVE:  A little big and ungainly and difficult to use as a book.  I was thinking, okay, fine.  I'm an early adopter of technology.  I mean, I'm easy about having all these things.  This will be my PDF reader.  Because the fact is, PDF being a page layout format, as we've said, you cannot reflow a PDF the way you can reflow a book, which is inherently just a string of text.  The PKWARE guys provided me with a big pile of documentation for SecureZIP, the topic of last week's  podcast.  And so I thought, oh, cool, this will be a great opportunity for me to use the Kindle DX, instead of printing out all these PDFs, as I would have in the past.  And they were illegible on it.



LEO:  What?  Oh, that's very disappointing.



STEVE:  I mean, I would say unreliably legible.  A couple were...



LEO:  You mean font size problem?  Or...



STEVE:  Yes, and font color.  So it was gray.  I couldn't, I mean, if you rotate - the DX has rotation, which unfortunately they're doing the auto rotation thing.  And I don't know if they haven't got it down right, or I haven't messed with it enough.  But it's the first thing I fumbled around trying to turn off because just in normally holding it, it was switching over into landscape mode when I didn't want it to.  So the good news is, you can take over manual control so that you - in the same button where you change the font size is a dialogue that allows you to set what you want for your orientation.



I'm a leftie.  And I really like sometimes being able to hold it in my left hand.  They removed the page turn buttons from the left-hand margin.  It's only now on the right-hand edge of the tablet, which I'm not happy with because now I can't hold it in my left hand and turn the page.  It had to have been for reason of cost reduction because additional parts and additional buttons, those all cost something.  And so they must have said, oh, well, no one's left-handed, or if they are they can hold it in their right hand.  But so that annoys me about it.



If I rotate it into landscape mode, then the virtual PDF page is expanded enough to be legible.  But if you have, for example, a two-column PDF, as many PDFs are, then when you get down to the bottom of the first one, you've got to go backwards up to the top.  The PDFs don't page align.  That is, as you page down, you end up with sort of the bottom of one page and the beginning of the next one coming up, instead of them arranging to align correctly, which is annoying.



Anyway, overall I'm disappointed.  I mean, it is truly large.  It's funny, too, because after - when I first unboxed it and was looking at it and holding it and oohing and aahing and thinking, oh, look at this magnificent big screen, and you sort of get used to that size, then I said to myself, I wonder what the other one looks like, what my Kindle 2 looks like?  And I went right to it and took it out, and it looked dinky by comparison.



LEO:  Right, compare it.  Because, I mean, this thing is much, much bigger, huh.



STEVE:  Now, what I will say is that what's compelling about the DX is that the screen as a percentage of the total surface is much larger than on the Kindle 2.  The Kindle 2's keyboard is much larger, and the screen seems very small in the overall size of the Kindle 2.  Whereas certainly the DX has just a magnificent screen.  But I think it's sort of in between.  It's not good enough to be used as a general PDF reader.  Certainly, I mean, I have read PDFs that are magnificent on it.  And if I were, for example, printing an RFC, a multipage Request For Comment, an RFC document from the Internet, I could print it to a PDF, move the document to my Kindle DX, and read it just magnificently.  It'd be perfect.  So PDFs you make and PDFs of simple text, they work beautifully.  But that's not always what your source material is.



And I found many of the PDFs from the PKWARE guys, for no fault of them - for example, I did end up reading them on a regular PC browser, and they were fine there.  But the DX did not do them justice.  And so I would argue that for $500 people are going to be disappointed if they really think they're going to be able to read any PDF they encounter.  It's really the case still that a higher resolution color screen like you have on any laptop or tablet is a better solution for PDF.  Or printing it out on paper.



LEO:  Oh, well.



STEVE:  So again, I think your intuition was right.  I could wish for a Kindle 3 which would be the physical size of the Kindle 2, but much more of it as screen.  That is, do what they did with the DX and squeeze the keyboard down.  Because you hardly use the keyboard...



LEO:  Yeah.  You use it to order, and that's it, pretty much.



STEVE:  Yes, exactly.  And so squeeze it down, give us more screen, but keep it paperback book size because, I mean, that really - you were right, Leo.  The convenience of it being that size, compared to it being of the size of the DX.  It's just big.  The problem is, there's no way you're going to be able to read page documents on a small screen.  It's just - they're going to be too small.  So it's just like the problem with the keyboard.  You can't have a small keyboard and full touch-typing speed because you can't.  You have to have a full keyboard in order to run at the speed that you normally do.  So that human factors interaction is just - it's a fact of life.



LEO:  Yeah.  Oh, well.  I'm glad you spent the money, not me.



STEVE:  Yeah.



LEO:  Thank you.  We all owe you a debt of gratitude.  I'm happy with the Kindle 2.  And I took it with me to the beach.  We were spending the week at the beach house - at a beach house we rented.  When I say "the beach house," it sounds like I own one.  I do not.  We rented a beach house.  And it's been great on the beach, sitting on the beach.  The sun is shining, and it's really legible.  Which a laptop would not be.



STEVE:  No, that's very true.  And I have to say also, while I'm dunning on the DX, it's also heavy.  The people I gave it to said, oh, I mean, it's like - so you try to hold a corner, and it's trying to twist itself out of your hand because it's heavy enough.  I think what that says is that there's a lot of battery in there.  I think there's probably a very large surface area battery...



LEO:  Lot of mass.



STEVE:  ...because it does turn pages more quickly than the 2.  I think they're running the processor faster, which they can afford to do - which is going to consume more power, but they can afford it because they've got much more battery area spread out in this DX than they do in the Kindle 2.  It's probably about twice the area.  So, I mean, it's snappy performance.  I like that about it.  But it's just - it is unwieldy.  It's too big.



LEO:  Well, thank you for that, and I'm glad I waited.



STEVE:  Yeah.



LEO:  For you.  Another question.  This is from Steve Whaley in Lexington, Illinois.  He asks:  Hey, you talked about SecureZIP, and you said it was free.  Really?  I'm unable to find a download of this product that's free.  It seems PKWARE wants $39.95 per user for home PCs.  Am I missing something?



STEVE:  Many people wrote variations of this question.  So I apologize to our listeners for not having given you the simple URL.  I'm sure I said just put "SecureZIP" into Google, and it'll take you right there.  It does, but the URL is SecureZIP, so I should have just said that:  www.securezip.com redirects you to a page...



LEO:  Oh, yeah, that says right there "Free Download."



STEVE:  And it is.  And it does have that 30-day feature expiration that I mentioned where it'll give you the Office integration, the Office and Outlook email integration for 30 days.  And then that dies, yet everything else about it stays fully functional.  And if you don't want to be able to, like, if you don't need to send a piece of email literally with a single click, or save a Word document with a single embedded function, then that free post-30-day SecureZIP, which continues to function just fine, is really all you need.



LEO:  Another question from a professional programmer in Sacramento.  I love that.  His name is Damien Eversmann.  He wonders why coding error equals remote code execution:  Steve, first, ditto to what everyone always says.  I've been listening since Episode 1.  Hope you and Leo keep it up for some time to come.  So here's my question.  I'm a professional programmer.  I've been doing it for about 15 years now.  I understand most of the programming errors you describe when you talk about various software flaws that vendors are patching in your weekly security updates.  But what I don't understand is why it always seems that every coding error means remote code execution vulnerabilities. 

 

In my experience, my coding errors just mean my application ceases to work.  It freezes or crashes or quits.  But every error you mention every week seems to mean remote vulnerabilities.  Buffer overrun equals remote code execution.  String index mismatch equals remote code execution.  Array index out of bounds equals remote code execution.  It almost seems like programmers would need to try to make remote code execution so available.  Sometimes after your reports I feel like remote code execution flaws seem more reliable than a program functioning as described.  What am I missing?  Again, love the podcast.  Looking forward to Mac-SpinRite so I can run it without removing drives from my Macs.  With a PR person like Leo, I think you'd sell a few thousand copies in the first five minutes if it were available.  Thanks so much, Damien.  I'd like to echo that, by the way.



STEVE:  What Damien is missing is that the show talks about remote code execution because it's a bad thing.



LEO:  Right.



STEVE:  So the bugs which software has and which are not bad security vulnerabilities, we don't talk about.



LEO:  They just crash.



STEVE:  There's plenty of other bugs in software that just makes them crash.  Where they're bad, they crash, people are annoyed, but there happens, exactly as he is suggesting, there happens to be no way of preloading the content of the buffer which you overflow into, or leaving stuff on the stack which you end up executing.  We understand how it is that some of the mistakes result in remotely provided code getting executed.  We've talked about those earlier in the beginning podcasts of this four-year run that we have so far.  So our listeners understand that.  It is the case that, exactly as Damien suggests, many bugs don't provide you with the means of loading code at the same time.  But those aren't problems of security.  So we don't talk about those.



So there are definitely plenty of problems that do not create this kind of remote code execution.  There are also problems that just, you know, they end up with like a privilege escalation where you're able to - code that is running is able to elevate its privileges from your limited user status to admin or something.  And so there are other tricks that can happen.  The worst, of course, is that without you knowing it, you visit a website, and now you've got something running on your machine as a consequence of viewing that page.  Those are the exciting problems.  Those are the problems that make the news and that force Microsoft to jump through hoops and get things patched, or Adobe, or Apple, or anybody who's now in this Internet-connected world.  So the point is, yes, it seems that all these problems cause remote code execution because those are the ones we talk about.



LEO:  We only talk about those.



STEVE:  Those are the security problems.



LEO:  Although, credit where credit's due, these hackers work really, really hard and are quite ingenious in finding code, finding ways to inject their code into these overflows.  I mean, it's nontrivial to do that.  It's not...



STEVE:  Yes.  I've mentioned, for example, the guys at eEye, who have a whole lab full of machines.  And these machines are literally throwing random API calls with random parameters and packets with random data at the operating system and waiting for it to crash.  When it crashes, then they go in forensically and find out what packet it was that caused the crash.  Then they go in and disassemble the processing of that packet to look at why it crashed.



So, A, they've got a crash.  Okay, that's news because it shouldn't crash.  But then, by looking at every detail of the nuance of what preceded the crash, they look to see whether, for example, the crash occurred when the computer executed just some random garbage that was in the packet.  If so, then they think, wait a minute, let's give it a packet which qualifies for the crashing, that is, that makes it crash.  But if possible, can we put other data in that packet that would also cause it to execute the data we choose?



So they literally, they reverse-engineer the exploit from a seemingly random occurrence.  Most of us, the machine crashes, and we curse its maker and reboot, and we're going again.  But security researchers take that event of a collapse and say, ooh, could this have been much worse than just a random-seeming event?  And so, yes, you're right, it takes, you know, it's serious kung fu to back this out into an exploit.  But some people have nothing better to do.  Some people get paid for it.  Some people sell their exploits on the black market, unfortunately.



LEO:  Because there is such a lot of money to be made, there is some incentive to do this extremely difficult and time-consuming work.



STEVE:  And Leo, if you had said to me this was what we'd be talking about 20 years ago, I'd have said, this is science fiction.  I mean, it makes a great...



LEO:  Yeah.  It doesn't seem possible.



STEVE:  ...makes a great story.  But come on, it's not - it's like I mentioned Neo selling the little disk in the opening scene of "The Matrix."  It's like, come on.



LEO:  Couldn't happen.



STEVE:  In the future we're going to have fixed all this; aren't we?  Well, apparently not because the future is here.



LEO:  I think it's going to be worse as we get older and there's more code.



STEVE:  There's no indication that it's getting better, Leo.



LEO:  Yeah.  And, well, and I bet you there's some questions in here - we talked a little bit about the idea of using languages that prevent this kind of stuff on previous episodes.  And as you pointed out, as long as there's programmers, there'll always be some mistakes.



STEVE:  And those aren't fun.  



LEO:  They're no fun to work with.



STEVE:  Those languages.  We want bare metal, written for the geeks [indiscernible] language.



LEO:  Let's get in there, yeah.  Joseph Vollmer in Waterloo, Ontario, Canada wonders whether WPA/WPA2 is "quickly crackable."  I'm fully up to date with all the episodes.  Started listening to Security Now! in January 2007, and I've been listening ever since and love the show.



I'm an IT support pro, and a bunch of my co-workers claim they can, or it is possible to, crack WPA and WPA2 without much trouble at all.  Yeah, the usual swagger.  I always argue, saying if you set it up properly, like using AES and use one of Steve's pseudorandom 63-character printable ASCII characters, it's not going to be crackable in a usable amount of time.  They claim there are all kinds of readily available hacking tools that allow you to crack it quickly.  They say because of the number-crunching power of GPUs it can be cracked quickly using hacking tools.  I agree cracking WEP, as we know, is easy.  Do that in 30 seconds now.  Could you please shed some light on WPA?  I'd appreciate it.  I continue to argue with them, saying it's not possible.  Which I always say you've got to set it up right, of course.  If you use dog1234 for a passphrase, no problem.



By the way, I'm a proud owner of SpinRite.  It's saved my bacon many times.  Now if only work will finally listen to me and buy a site license, all will be well.  I'm working on that  One day I hope I'll get it approved by management.  And I will not stop until it happens.  So, Steve, yes or no?  WPA2, easily crackable?



STEVE:  Joseph is absolutely right.



LEO:  I thought so.



STEVE:  And I just - I liked the question because it sort of feels like sort of this is coming from youngsters, you know, young...



LEO:  I could crack it.  Eh, no problem.



STEVE:  ...wannabe hackers, yeah, exactly.  Joseph should just say fine, show me.



LEO:  Crack it.



STEVE:  If these tools are available, if they're easy to do, put your evidence on the line.  Show me.  I mean, he could make as large a bet as he wants to.  If he uses one of GRC's random passwords, I mean, I use those myself.  The other day I needed a random string for the header of a file to be used as an index mark for some versioning stuff in the DNS benchmark.  I went to my own site, to my page.  Fortunately the security certificate was still valid at that point.  And I had it generate those numbers for me, and I grabbed them, and I used them because they're as random as anything you can get.  So, I mean, Joseph could make - he could make a bet as large as he wanted to, saying okay, great, crack it.  And it's absolutely safe.  I mean, this is - there is this sort of, as you said, swagger is a perfect term for it, among young hackers who read stories and hang out on BBSes.  And they're these people who to really lay people sound like they know what they're talking about.  But they're just full of it.



LEO:  Yeah, they throw in the little tech obfuscation, oh, you use the GPO.



STEVE:  Yup, just put some jargon in there, and it's like, oh, that sounds convincing.  Well, it's just not the case.  There is, exactly as Joseph says, there is no known problem at this point.  And it was highly vetted, unlike WEP.  The WPA protocol has really been well designed and well thought out, and we know of no way to get around it.  And it's been designed also so that, for example, even GPUs are able to crank through, we're talking about many bits.  And as you add a bit, every bit you add, as we've said, doubles the length of time that is required even from a brute-force attack.  So you could use a room of graphic processing units designing this, and they're still going to be churning away for a long, long time.  Joseph would get his money from his bet.



LEO:  Let's see.  A Security Now! listener in California has asked to be anonymous while asking about a homegrown VPN client:  As a consultant I'm often asked to use a client's VPN for remote access to their network.  My current client has a homegrown VPN client.  It is an ActiveX add-on to IE.  Is there some way I can determine what this VPN client is doing?  Is there, I don't know, a keystroke logger I could use?  Is it capturing non-VPN activities?  Can it provide information about what I do for other accounts on the same computer?  Can it be used as a gateway to install rootkits or other technologies on my system?  Please sign me Anonymous in California.



I see his concern.  He's being asked to run software, strange software on his system, and he's got other clients to protect.  He's not sure it's safe.



STEVE:  Yeah, it's a great question.  And, I mean, you can see the position he's in.  They're saying, oh, well, this is our homegrown VPN client.  Well, first of all, I'm skeptical of some random company home-growing their own VPN client.  It's probably something that they got from somewhere else.  Who knows...



LEO:  As you know, because you've tried to - you've been writing VPN software, it's nontrivial.



STEVE:  Yes, exactly.  It's a nontrivial task.  So I'm wondering where it really came from.  But even so, this is a great question because, I mean, we could broaden it a little bit and say, okay, I'm somebody who, exactly as you say, Leo, I'm responsible for the security of many different people, many different clients.  One client, for example, wants me to install something random on my machine.  Well, how do I make that safe?  How do I know what it's doing?  How do I know that it's aboveboard?  And this, I would say, is a perfect example of where wrapping this thing in a virtual machine makes sense.  If I were in this situation, I would be running one of the VMs, like VMware.  And, I mean, especially, hopefully our listener is using Firefox normally.  This thing is an IE ActiveX add-in.  So put it in a virtual machine.  Get Windows running there.



LEO:  That's a good idea.  That's a very good way to do it, yeah.



STEVE:  Yeah.  And then it's going to have some isolation. Then you know when you're not running it, you're not running it.  It's going to have full networking abilities.  It's going to be able to still do its VPNness.  And you can full-screen that VM so that you can even forget that you're in a VM.  But when you shut it down, you've shut it down.  And it's very unlikely that it's going to be able to get out of that because the VM as we've looked at provides high levels of integrity.  It's not necessarily absolutely bulletproof and perfect.  But something that's not written to bust out of a VPN, I mean, out of a virtual machine, is just not going to be able to.  It's not going to stumble out of it by mistake.  So I think that's the best you can do.  I mean, the alternative is dual boot.  Set up a separate boot for stuff, like for this guy, or use a different machine.  But it certainly is worth noting that this is a concern.  I think that's a great concern.



LEO:  Steve, another question for you from our great listeners.  This is Anthony Fitch from Blaine, Kentucky.  He says he saw it happen firsthand:  First of all, I've listened to every episode of Security Now!, and it has filled in all the gaps in content that were missing in my formal classes in college.  That's awesome.  This show has lead me to win First Place in the Computer Concepts category in the Phi Beta Lambda state competition two years running.  Steve, that must make you feel good.  That's awesome.  That's fantastic.



STEVE:  That's very cool.



LEO:  The reason I'm writing is to share with you that you were right about the insecurity of Eastern European ATMs.  On a recent - two weeks ago - trip to Europe, while in the Czech Republic, one of the members of our tour group had her debit card number stolen because she used an ATM in that area.  This is good for me to remember because I'm going to China next week.  Her bank kindly returned the money that had been stolen because they emptied her bank account, although it was an extreme headache due to time zone differences and of course the costs of making phone calls back to the states. 

 

Thank you very much for your time.  And as much as I would like to, I do not have a SpinRite testimonial yet.  That's good.  As long as you have SpinRite, you probably don't need to do a testimonial.  Everything just works.  P.S.:  I'd be honored if you'd read this on the show.  Of course, Anthony.  And that's great.



STEVE:  I thought that was just a nice little tidbit from a listener, that we've talked a lot about the inappropriate use of Windows in mission-critical environments.  And also we did cover the security news of trojans being found in a whole bunch of Eastern European ATMs.  And a listener of ours knew somebody who - he was standing there when it happened.  So it's like, yep, this stuff is real.



LEO:  Yup.  And it does remind me, as I head off to Asia - I'll be in China, Korea, and Japan.  And, I mean, but that's what you do when you travel nowadays.  You don't carry traveler's checks anymore.  A lot of people don't even take them anymore.



STEVE:  Right.



LEO:  You use the ATMs to get the local currency.



STEVE:  Yeah.  I would say what you could do, if you can, don't use a card that's associated with all the cash that you have.



LEO:  That's a good point.



STEVE:  Set up an account that you can afford to have...



LEO:  Yeah, I do, I have - oh, that's a good idea.  Okay, I'll bring my - I have an ATM card that I don't use very - it's like a secondary account.  Great thinking.



STEVE:  Yes.



LEO:  And I think, if I make sure to use it inside of banks, I'm probably a lot safer than if I just use one on the street.



STEVE:  Yeah, but again, belt and suspenders.  I would also just use an account without a ton of money in it.



LEO:  That's a very good idea.  Thank you.  Rick Huebner in Melbourne Beach, Florida is worried about "same plaintext and multiple ciphertext in SecureZIP."  I'm sure he'll explain what that means.



STEVE:  Get your propellerhead on.



LEO:  Here we go.



STEVE:  Get your hats.



LEO:  Here we go.  Steve, in the discussion on SecureZIP you said, and I quote, "So the idea is, if you want three different people to be able to decrypt this ZIP file, you're able to attach their certificates to that file.  And essentially it takes their public key and encrypts this one-time-use symmetric key for each of them and connects it.  So that when any of them receive it, they're able to open the file, and they're able to inspect the certificates that are bundled along with it." 



STEVE:  Yup.



LEO:  Now, here's his question:  Does the fact that one recipient now knows the plaintext symmetric key, has the ciphertext for the other recipients, and presumably can get the other recipients' public keys because those are stored easily, widely, would it make it easier to crack the private keys?



I thought in one of your previous episodes you said you never want to encrypt the same message with different keys.  Or was it that you never want to use the same key to encrypt two messages?  Either way, does this in some way weaken the cipher?  If so, is it something ridiculous like going from 100 billion years to 10 billion years? 

 

I've been a listener since Security Now! 001 and actively read the newsgroups, as well as owning a copy of SpinRite that saved my father-in-law's bacon.  Man, SpinRite on a newly purchased 1.5TB drive takes a lot of time.  Also I SpinRite my two Series 2 TiVos and my old dinosaur Series 1 TiVo, all with additional hard drive capacity, because my wife would kill me if she lost any shows.  That's actually a very good idea.  Those drives get thrashed on a TiVo.



Keep up the good work.  I can't wait for CryptoLink to come out to replace my current Hamachi implementation.  Any chance it will support Windows Mobile devices?



STEVE:  Okay.  So great question from Rick.  What he's saying is, and he's exactly right, is that in the case where multiple certificates are attached to - in this case he's talking about the SecureZIP system where, for example, you zip and you want to encrypt the content so that three different people, each with their own certificate, are able to decrypt it; but no fourth party, for example, nobody else can.  The way that's done is that a 128 or 256 or 192, however many, however long the key is, a cryptographic-quality, high-quality random number is chosen out of the air, called a "nonce" in crypto terms.  It's something that's just random, and you're just going to use it once.  That is used as the symmetric key for performing the bulk encryption of the content instead of using, as we've talked about, you don't use - you don't do the bulk encryption with the public/private, the asymmetric key because it's very time-consuming and number-crunching intensive.  Instead you just choose a random key to do your bulk encryption, and it's that random key that you then encrypt using the asymmetric, the so-called public key technology.



So this random key is encrypted three times, once with each certificate.  Not serially because that would require that all three be used to decrypt it.  You would do it like in reverse order then.  But instead I mean that, like, that random token is encrypted once with one certificate, so now it's there.  It's encrypted again with the second certificate, and a third time with the third certificate.  So now you've got three encrypted versions of the key.  Each one can only be decrypted with the matching private key for that certificate, which isn't available - it's only available on the systems where those certificates are installed for these three different people.  So now the zip file goes off to them all.



So Rick's wondering if one of the recipients gains an advantage of any sort in this scenario.  Because he's got one of the certificates with a private key, he's able to decrypt the encrypted nonce, that encrypted symmetric key which is intended for him.  That allows him to get the plaintext version of the symmetric key, which is what he needs in order to view the contents of the zip.  But he also has the two other encrypted versions of the key which were bundled into the zip file.  And he's got the public keys which are publicly available for the other two people.  So he's saying, hey, now I've got a lot of information here.  I've got both the plaintext, which I decrypted using my certificate, and the ciphertext which is individual for each of the certificates that were created, and the public key.  Do I have an advantage?



The answer is absolutely not.  The good news is, this is exactly what the public key, the asymmetric key technology was designed for.  A perfect example is the normal case of digital signatures.  Remember that when you're doing a digital signature you take a document, and you hash it using a cryptographically strong hashing algorithm.  Now the signer will take their private key and encrypt that hash and then include it with the document.  Now the recipient gets the document and wants to verify it.  How do they do that?  They decrypt that signed hash with the signer's public key, turning it back into the plaintext version of the hash.  Then they independently hash the document using the same hashing algorithm and compare their resulting hash to the decrypted hash.  So the information they have is exactly the same as the information that one of the zip file recipients would have.  That is to say, they have both the plaintext and the ciphertext of - oh, and the public key, the same information.  And as we know, the public key technology is secure against this sort of scenario.  So the SecureZIP system, where you've got multiple recipients, is no less secure because of the way it implements the public key technology.  But great question.



LEO:  Yeah, yeah.  And actually when he stated it I thought, oh, yeah, that makes sense.  So I'm glad you clarified.



Steve, we're out of time for this episode, but not out of questions.  Every other episode we answer your questions.  You can submit them right now to GRC.com/feedback, and we will get to as many questions as we can, each and every even number, mod 2 episode.  Meanwhile, don't forget to go to GRC.com, that's Steve's website.  It's short for Gibson Research Corporation, now with a shiny new certificate for your security [laughter].



STEVE:  Good for three years at least.  We don't know what'll happen after that.



LEO:  And when you're there you can try ShieldsUP!, his great program to test your router.  You can download all sorts of free, wonderful programs.  And of course get SpinRite, the world's finest hard drive maintenance and recovery utility.  We also, or Steve also puts a transcript of every show up there so you can read along, or cut and paste into your questions if you should choose next time.  You can also listen to the 16KB version or distribute that for the bandwidth-impaired.  It's all at GRC.com.  Steve, we will see you next time on Security Now!.



STEVE:  Talk to you then, Leo, thanks.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#203

DATE:		July 2, 2009

TITLE:		Boyer & Moore

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-203.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and Steve explore the invention of the best, and very non-intuitive, means for "string searching" - finding a specific pattern of bytes within a larger buffer.  This is crucial not only for searching documents but also for finding viruses hidden within a computer's file system.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 203 for July 2, 2009:  Boyer & Moore.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers your security, your privacy, protecting you online.  And here's the guy, just the guy to do it, Steve Gibson of the Gibson Research Corporation, GRC.com, creator of SpinRite, discoverer of spyware.  I feel like it's a Barnum & Bailey intro.  Creator of SpinRite, discoverer of spyware, world traveler, the world renowned...



STEVE GIBSON:  And you know, Leo, I've heard this before.



LEO:  Once or twice.



STEVE:  Well, 203 times, actually.



LEO:  Well, I think it's important, if somebody's listening - hard to believe - for the first time...



STEVE:  Yeah, you're right.  You're absolutely...



LEO:  ...that they know who I'm talking to.  Maybe it's just an old, you know, TV thing.  But I always feel like I have to introduce my guests.  But...



STEVE:  Well, it certainly does let people know that if they've got complex iPods full of stuff, that they've found the channel that they were hopefully looking for.  Or they've found the wrong one, depending upon what they're in the mood for.  So that works.



LEO:  Yes, yes, yes.  So today we have one of two segments we're going to do.  We'll have a break in between with a Q&A.  But two segments we're going to do on, what, fundamental computer science topics.



STEVE:  Yeah.  There are - the reason I thought of this was that I was actually implementing this particular amazing idea in the DNS benchmark the other day.  And I just was thrilled again by how cool this is.  It's a way of finding a substring in a buffer.  And...



LEO:  Now, before you say any more, why would you want to find a substring in a buffer?



STEVE:  Well, okay.



LEO:  What are you talking about?



STEVE:  Has anyone ever searched a document for a string?



LEO:  Sure.



STEVE:  That's what this is.  This is string search.  But it  bears directly on our audience and the topic of Security Now! because how would you imagine you scour your system for viruses?  You're searching memory.  You're searching your files for known, you know, we talk about patterns or fingerprints or a snippet, a known snippet of a virus.  You want to very quickly check your whole hard drive, essentially, your file system for something.  Well, there's the way you would expect to do it, and we'll talk about that.  And then these two guys named Boyer and Moore, Bob Boyer and J. Strother Moore, at the time they were at SRI and PARC, both up in Silicon Valley in Northern California.  And in 1975 they said, we have a better way.  And it's just, I mean, it just curls my toes, it is so cool.  And I just, when I was thinking about this, I thought this is something that our audience would just get the biggest kick out of because I can explain it conceptually, and it's one of those things where people are going to go, oh, my god.  I mean, you would have never thought of it.  But here it is.  And it's like, oh, it's so much better than, like, the dumb way.



LEO:  You know, I love algorithms.  Maybe that's a nerdy thing to admit.  And there have been big, long books written on it, including the classic Donald Knuth books.  Which are really, I guess, in a way logic puzzles.  They're inventions.  They're creations.  And something like this, which can make a huge difference in something that every program does all the time, has a huge impact.



STEVE:  Well, yeah.  And computer science has, like, it happened when we invented computers.  And then over the years people have discovered things.  They've invented really cool solutions to common problems.  In two weeks we're going to talk about data compression as, like, there's two guys also, interestingly enough, whose initials are LZ.



LEO & STEVE:  Lempel and Ziv.



LEO:  I know them, yes, yes.



STEVE:  And so LZW is Lempel-Ziv-Welch; LZH, Lempel-Ziv/Huffman.  Many people built on that.  But there was again, just as with Boyer & Moore, these two guys had this really cool idea for, like, this is how we can compress data.  And it works better than anything that had been done before.  And people have improved on it.  But there's still this fundamental concept.  So we're going to have a couple episodes here of just really neat conceptual stuff.  And as you say, Leo, this stuff is sort of fundamental computer science.  It's actually why I like writing in Assembler is I'm constantly doing algorithms of various sorts.  Not amazing ones all the time.  But I've got my own Boyer-Moore string searching routine that is in the server at GRC, checking for various things in incoming data and also in the DNS benchmark that'll be happening soon.



LEO:  So let's get this errata and updates out of the way before we get to Boyer & Moore.



STEVE:  We've got a bunch of security news.  Nothing horrifying, although this first one is really annoying because of a real problem with terms and terminology.  It turns out that Adobe Shockwave has a pretty significant remote code execution, remote people-take-over-your-machine problem.  The problem is that this is not Flash, which is what is most common.  This is sort of the original Shockwave that is authored by their Director tool, which of course they all - Adobe bought all of this from Macromedia.  So there was Macromedia Director and Macromedia Shockwave.



LEO:  Yeah.  Right.



STEVE:  There was also Flash.  And the problem is that the way this stuff identifies itself in your computer is very confusing.  For example, you'll see Shockwave Flash, and okay, wait a minute, is that the Flash or is that Shockwave?  Is that the problem or not?



LEO:  Right.



STEVE:  And so, for example, under Internet Explorer, IE has the facility for managing its add-ons.  You click the gear and then select Manage Add-ons.  And this is IE8, which is of course the current one and the one Microsoft is now pushing on people.  So people who are at 7 or 6 are probably there deliberately, so I'll assume they're a little more expert.  Anyway, you find the Manage Add-ons feature.  And in IE8 it's got them listed, broken out by publisher.  So then there's a heading, Adobe Systems Incorporated.  And Shockwave Flash Object was what mine showed.  And I thought, oh, there's Shockwave.  But that's not the one that you need to worry about.  You need to - normally IE only shows the loaded add-ons.  You need look for, to select the list box for all the installed add-ons.  Then it'll sit there and think for a while and give you a much bigger list.  Scrolling down through all of the Microsoft debris which is not currently running in memory, you'll get down to, like, another Adobe section, likely.  And so what you're looking for is just Shockwave, but not Shockwave Flash.  What Adobe's site says is you need to uninstall this, then restart your computer before you install their update.  So they have an update.  Where we're trying to get is...



LEO:  That's annoying.  You mean, oh, you have to uninstall, then reinstall?



STEVE:  Yeah.  That's what they say.  And what I found was that I didn't have it installed.  But apparently 60 percent of PCs and Macs do, and there's some 450 million - no, it's got to be 45 million, 45 million instances of this.



LEO:  So not everybody who has Flash has Shockwave.



STEVE:  Correct.  And so fundamentally, I mean, backing up, what I ended up doing was then I went to, under the Control Panel, after sort of getting myself confused about which one we were talking about because the nomenclature is very confusing, I went to the Control Panel in Windows to Add/Remove Programs, and there was a collection of little Adobe things.  Normally it's sorted alphabetic, so they'll be near the top.  And so I saw Adobe Flash and Adobe ActiveX, I think they were, and nothing else.  When I installed the update from Adobe, then there was a new item in Add/Remove which was Adobe Shockwave.  And I think under Firefox there was a reference to Director, like Shockwave for Director.  Anyway, what I realized after all of this was I never had this installed in the first place.



LEO:  [Laughing]



STEVE:  So then I uninstalled it, using Add/Remove Programs to uninstall it.  And it's like I was back where I was.  But at least now I know that I'm not one of these 45 million people who had installed this.  So it may very well be that our listeners won't have it.  But for anyone who does, apparently it will have been something that you installed manually.  That is, it's not sort of where you go to a site and it says, well, you need Flash, click here to install it, and it just sort of does it for you.  So that means that it has a presence in Add/Remove programs, at least in Windows, where you can remove it if you have it.  And maybe you just ought to leave well enough alone after removing it and don't go install the update unless you know that you need it for something.



LEO:  There are some pages that do say you need Shockwave.



STEVE:  Yes.  And they're generally, I mean, they're...



LEO:  They're older, I think.



STEVE:  They're older, and they're sort of - Shockwave and Director were sort of almost more like gaming.  I mean, it's a high-end authoring package, not just like Flash, which is sort of like Silverlight for doing animated little simple lightweight things.  It's like much more content is what the original Shockwave Director is used for authoring.  So it's not something that I had installed, and now I'm sure.  So I wanted to let our users know.



Anyway, where Adobe is now is at 11.5.0.600.  And 11.5.0.596 and earlier are vulnerable.  So if you've got Shockwave, which is again different from Flash or Shockwave Flash or however your system identifies it, then it is worth doing because this is one of those things where there's a large enough target size for the bad guys.  If 60 percent of PCs and Macs have this installed, I mean, that seems like a high number given that it seems relatively uncommon and unnecessary.  I've had my system running now for all year, and I have not run across a site that needed it.  On the other hand, I'm not surfing as broadly as many people are.  So I wanted to let our listeners, now that everyone's completely confused, know what's going on.



LEO:  Yes.  Well, that's good to know.



STEVE:  And, by the way, you go to get.adobe.com/shockwave, if you decide that you do need to update to the latest.  So it's get.adobe.com/shockwave.



LEO:  All right.



STEVE:  Google's Chrome browser has a new problem.  It turns out that, if you have a deliberately maliciously formed reply to an HTTP request, so that is to say if you went to - if something got you to click on a link that went to a malicious server, and technical exploit details are available publicly, then the server can craft a response which will take over your machine.  So that's not good.  Chrome currently has about a 1.8 percent usage share on the 'Net.  So less than one in 50 people are using it.  Anything prior to Chrome 2.0.172.33 is vulnerable.  So essentially that means if you're using Chrome, you just want to make sure you're using the latest one.  Updates are available that fix this problem.  So that's worth doing.



And we've also talked - we've talked recently about Foxit as the alternative to Adobe's increasingly large PDF reader.  People, a lot of our listeners, I know, use the Foxit reader.  Well, there's an optional add-on that has a new problem.  It's the JPEG2000/JBIG2 add-on.  Which is not...



LEO:  Isn't the JBIG2 the same problem...



STEVE:  We've been having problems with that recently.  It's not installed by default.  You may not have it as part of your Foxit installation.  But if you had installed it, you want to make sure that you're using something later than 2.0.2009.303.  303 and earlier are vulnerable of this JBIG2 or JPEG2000 add-on.  And again, something tricks you to viewing a PDF document with one of these images embedded, and it can be a malicious image which will trip an overflow that exists in that add-on and execute code of the bad guys' design.  So you want to make sure if you're using that add-on that you are later than 3.3 or earlier.



LEO:  Okay.



STEVE:  And in errata, I did want to observe an interesting headline from CNN which was late last week, relating to Michael Jackson's death.  CNN - this is the technology section of CNN.com.  The headline was - it just said:  "Jackson Dies, Almost Takes the Internet With Him."



LEO:  Yeah, I saw that.  I thought that was a great headline.



STEVE:  And I don't know if anyone knows this, but there was such a flurry of people jumping on the 'Net when they heard through word of mouth or through whatever channel that Michael Jackson had died, Google thought it was a Distributed Denial of Service attack.



LEO:  I'm sure they didn't think that for too long.  But initially that spike must have scared them.



STEVE:  Yeah, there was a huge spike on Google News.  And apparently it's one of the largest mobile computing events.  That is, it was people with their iPhones and cell phones and all their radio-connected...



LEO:  Refresh, refresh, refresh.



STEVE:  ...cellular mobile devices, all wanting to find out what happened.  The L.A. Times website crashed.  And Twitter's servers suffered multiple crashes as everyone was twittering each other or tweeting or whatever.



LEO:  That's how I learned about it.  I learned about it on Twitter.  And then my son texted me.  And then my daughter called me.  So, yeah.  I'm sure - that was just me, I had a lot of traffic going on.



STEVE:  Exactly.  And so you can imagine.  So anyway, this is sort of an interesting commentary on the, I mean, the Internet obviously didn't die.  But it definitely suffered a blow when suddenly something happened that caused a lot of people to all at once, in a relatively short timeframe, use the 'Net in a relatively focused way, people all tweeting or twittering or whatever the verb is you use.  The L.A. Times being, of course, where this happened.  At UCLA was where Jackson was taken, I guess.  UCLA Medical, I think, is where they were piling in to find out what was going on.  So the L.A. Times was where people naturally went.  Maybe they were following links from Google News, who knows.  But anybody in that chain suffered from the event because, as we've discussed before, the networks and even servers are generally sized to be able to handle the traffic they're normally receiving plus some amount of variation because you get daily variation.  But not 100 times that much.  And when that much hits, they collapse under that strain.



LEO:  Well, because you don't design a site to always be able to handle that traffic.  It would be just too expensive.



STEVE:  Oh, exactly.  I mean, exactly.  You would have servers sitting around doing nothing.



LEO:  Excess capacity, yeah.



STEVE:  Exactly.  And they'd have to be ready at a moment's notice.  So they have to be on, burning power, heating up the air, so you've got to cool it off.  And you'd have all this bandwidth that you're not using.  So, I mean, it absolutely is the case, I mean, we know for example that the phone system will collapse if everyone goes off hook at the same time.  It just doesn't have the capacity for dealing with that.  When normal loads occur, and people go off hook, they get dial tone.  If everyone does, nobody gets dial tone.



LEO:  Now, there are, it's interesting, there are services you can buy now, kind of bandwidth-on-demand services that are designed to handle this.  I don't know how well they handle this.  But they kind of ramp you up.  You don't pay for it all the time.  But when you need it, it ramps up to scale to handle it.



STEVE:  Well, and the way they work is, again, they work on the law of numbers.  They work on the idea that they'll have many customers who need the ability to have high, it's called "burstable," high burstable bandwidth.  But it's unlikely that all of their customers would be needing to burst at the same time.



LEO:  Right, right.



STEVE:  And so they say to people, okay, we're not going to charge you that much, but you're going to have this high burstable limit.  They say to everybody that is their customer the same thing, presuming that no one is - that various customers have, for whatever their demographic profiles are, they're different from each other, so they're not going to be bursting at the same time.  Once again, if by some weird coincidence many of their customers tried, they'd again hit the wall because no one can afford really, really high levels of bandwidth on an ongoing basis.  It's just too expensive.



LEO:  Isn't that interesting, yeah.  And we had talked before about that's how people can insure themselves against DDoS attack, that they can buy bandwidth on demand so that if they get DDoSed they can - that's one way to handle this, to have so much bandwidth that the DDoS doesn't stop you.



STEVE:  Well, in fact that's a perfect model of what we were just saying.  There are suppliers who say we will give you DDoS protection.  So they've got all of their customers who are behind much bigger pipes, and they're sharing the daily cost among all those customers who want to make sure, if someone tries to attack them, they'll be prevented.  And the goal or the hope is that not all of that company's customers would be attacked at once.



LEO:  In this case, the traffic was huge everywhere.



STEVE:  Yeah.  And it was legitimate traffic.  It was just too much of it.



LEO:  Right, right.  



STEVE:  Yeah.  I did have an interesting and sort of short little SpinRite anecdote from a Michael Barber, who wrote saying "SpinRite Saves My TiVo Without Finding Errors."  He said, "For the past few weeks, when I was watching TV, it would cut out and go all pixilated.  For months I assumed that it was just the digital cable since that does happen from time to time.  But lately it's been getting worse, much worse.



"One day I tried to go back to the recorded list, and the screen was frozen.  No amount of button-pushing would work.  I rebooted the TiVo - it's a Series II - and it hung on rebooting.  I reset it again, and it came up that time.  At this point I knew it was the drive and not the cable causing the pixelation, and my drive was dying.  So I took the 160GB drive and took it out of the TiVo and put it in my PC and ran SpinRite on level 3.  It said level 4 was going to take 25 hours.  And three hours and 30 minutes later at level 3, SpinRite was done.  I was a bit confused because SpinRite didn't identify any bad spots on the drive.  Regardless, I put the drive back in my TiVo, and all has been well ever since.  No more pixelation.  Thanks for writing SpinRite and hosting Security Now!, two truly invaluable tools."



LEO:  Isn't that interesting.  Does that make sense?



STEVE:  Yeah, it's often the case.  It's one of the things that is a constant annoyance, frankly, for me is that SpinRite's working with the drive, and there's really nothing that I can report because the drive's relocation of defective sectors is deliberately invisible.



LEO:  Oh.



STEVE:  I mean, it's even invisible to SpinRite.  SpinRite is able to cause the drive to see that it's got a problem reading a sector, which is still correctable but getting almost to the point of not being correctable.  That's what causes the drive to say, oh, shoot, we've got to fix this now.  So the drive fixes it.  But there's no error at any point.  This is normally supposed to be automatic, but some drives need SpinRite's help.  Or the sector is coming back unreadable often.



Well, SpinRite keeps asking for the same sector.  It does a whole bunch of different things like moves the head in different, in either direction random distances and then comes back at that sector.  That causes slight different alignment of the head during each attempt.  And so the idea is that SpinRite will sit there working with the drive, continually asking for this sector.  And it comes back bad, bad, bad, bad, bad.  Just once it'll be correctable.  And then the drive says, ah, we got the data.  It uses that opportunity to swap in a spare, and everything's fine.



So there's really nothing for SpinRite to report except, hey, your drive's all fine now.  Put it back in your TiVo, and everybody'll be happy.  So there weren't errors caused.  There weren't bad sectors because they were fixed.  So I know it's difficult to explain; and people say, well, I don't know, it didn't do anything, but it works now.



LEO:  But it fixed it.  It didn't do anything, but it fixed it.



STEVE:  Exactly.  It's like, well, yes, it did, but there was really nothing I could tell you.



LEO:  Right.



STEVE:  Except, you know, be glad you have SpinRite.



LEO:  Sometimes just poke - in other words, sometimes just poking the drive and checking every sector gets the drive to fix the problem itself.



STEVE:  Well, yes.  In the TiVo the drive was returning errors.  So TiVo was saying, oh, I can't boot.



LEO:  TiVo remapped it.



STEVE:  Well, no.



LEO:  No.  The firmware did.



STEVE:  It was seeing that the sector was bad.  SpinRite doesn't give up.



LEO:  I see.



STEVE:  And so - and SpinRite has a bunch of strategies for helping the drive get one last good read.  It just needs one last correctable read.  And then the drive at that point is so freaked out that it says, oh, my god, look how - I had a burst error that was the maximum I'm able to correct.  Thank goodness I can correct it.  So it did.  But that stimulates it then to spare the sector out and bring in a new replacement where it puts the data that it corrected back in.  So there's no - at no point is there anything that is like a bad sector because we fixed it.  But we really did fix it.  I mean, work got done even though SpinRite said well, you know, this took three hours and a half, but look, you've got something for your time and trouble.



LEO:  And that's another point is that there are bad sectors all the time on hard drives that they fix you don't even know about.  I mean, that's just part of the process.



STEVE:  Yes.  Well, in fact, exactly.  So the degree of  badness is always being tolerated.  Once upon a time in the old 20MB drives they would list the known defects on a label on the front, and you hopefully put those in when you were low-level formatting the drive.  Many people didn't.  So one of SpinRite's features back then was it would find the defects and mark them out for people.  You know, many OEMs were just slapping the drives in and sending them out the door because they didn't have time to do all that.  Or they didn't have people trained to do that.  So SpinRite would find the defects and mark the sectors bad and protect you from yourself.



Now what's happening is the densities are so high that almost all sectors have some degree of correction.  There's some problem with them, but it's not bad.  And the drives are designed to tolerate that.  It's when they get bad that you have a problem.  And so what can happen is the sector can go from not very bad to really bad, that is, like, unreadable.  That's when you need SpinRite to come in and sort of back it away from unreadable, get one last good read, which allows the drive to say, whew, thank goodness we got that.  And then it's able to put a spare in.



LEO:  Very interesting.



STEVE:  So it's all just science.



LEO:  Now, let's get Boyer and Moore in here.



STEVE:  Okay.  So this is time for everyone to sort of take a deep breath.



LEO:  [Taking deep breaths]



STEVE:  I'm going to describe something as clearly as I can, that I think will be clear.  But it's going to require some visualization.



LEO:  Okay.



STEVE:  So maybe set your propellers to half speed.  It's not too hairy, but it's just so conceptually beautiful that I needed to share this with our listeners.  I think our listeners will get a kick out of this.



So here's the task.  We have a big block of data we'll call the "buffer."  So I'm going to make sure I use my terminology correctly so I don't get people confused.  So we have a buffer of data which are characters, we'll call it English characters, in ASCII, which is the standard encoding for characters where each character is a byte long.  And we have what we'll call the "pattern."  The pattern is another much shorter string of characters, and we're trying to find any locations where that pattern occurs in the buffer.  And as we said at the top of the show, an example of this is any time you search for something in a document.  The document would be the buffer of this larger collection of a string of characters.  And even though on the page we see them as going across and then down and over and across, in normal reading order, internally it's really just one long stream of characters.



And so we're looking, when you do a Find in a word processor document you're saying, okay, find this string, that is to say the pattern, within - somewhere within this buffer.  And of course then the other very important use is this is how you search your file system for malware.  You have the so-called - we know that we're getting updates of so-called patterns from our antivirus vendor constantly, and that we're having our system checked for these known malicious patterns.  So it's very important for all kinds of reasons to be able to do this.  And we would like to be able to do it as quickly as possible.



So anybody sitting down, sort of learning programming for the first time, and is given the task, okay, how do I find this short pattern anywhere within this much bigger buffer?  And so intuitively you say, okay, well, let's see.  I look at the first character of the pattern.  And a good place to start would be to just sort of scan forward, looking at each character in the buffer, for an instance of the first character of the pattern.  Because of course if you're going to have the whole thing match, then that means that all the characters have to match, and it makes sense to start with the first one.  So you just sort of - you would scan forward through the buffer looking for the first instance of the first character of the pattern.  When you find it, this is a - it's like, okay, hey, I found the first character of the pattern.  This is a possible match at this point.



So what you would do is you then compare successive characters in the pattern and in the buffer, one for one, looking to see if they all match.  And if you get to the end of the pattern, that is, all the characters have matched the pattern and the buffer until you've got to the end of the pattern, then you've obviously found a match of the pattern in the buffer.  If you get, like, partway through the pattern, and the pattern's character corresponding doesn't match in the buffer, it's like, whoops, well, we thought we had something.  We got a few characters in, but we didn't make it all the way through the pattern.  So we've got to keep looking.  So you just keep moving forward till you find another instance of the first character of the pattern in the buffer and then compare successive characters until you see whether you've got them all.  And so that's, I mean, that's sort of the straightforward, this is how you would think you'd find a substring, a pattern in a buffer.



LEO:  That's, you know, if you sat me down and said how would you do it, that's the intuitive way to do it, the obvious way to do it.



STEVE:  Yeah.  I mean, and many, many, many, many people...



LEO:  I've done it.  I've written routines to do that.



STEVE:  Yes, exactly.  That's the way you would think to do it.  So in '95 these two guys, Bob Boyer and J. Moore, his middle name is Strother, J. Strother Moore, were collaborating in Northern California.  And they're both computer scientists.  Boy Boyer was at SRI, Stanford Research Institute; and Moore was at PARC, the famous Xerox Palo Alto Research Center.  And they, being algorithm guys, came up with a substantially better way to do something this simple, I mean, this obvious.  And it's massively cool.  What they said was...



LEO:  Should I interrupt you here and say, "Save this," while I mention Nerds On Site?



STEVE:  I think you should do that.  We'll come right back.



[Commercial break]



LEO:  So we understand kind of the problem.  And I think it's pretty obvious...



STEVE:  Obvious solution.



LEO:  Yeah, I mean, that's how I would do it.  But clearly this uses a lot of cycles.  And I think there's some magic coming to get this down into fewer cycles.  I'll tell you, in a way this was the discipline in the early days of computing when you had little memory, slow CPUs, small hard drives.  You had to optimize.  And in some ways I think it was better then.  I mean, Bill Gates constantly was - every pioneer I've talked to - you, Gates, Steve Wozniak - in Woz's case it was parts.  They're always trying to pare it down to the most efficient.  And there was a joy in getting the fewest lines of code or the fewest parts.



STEVE:  Or the design of the Apple II.  I mean, Woz is a friend.  And I was just, when I looked at the design of the Apple II, it was so elegant.  I mean, what they did with so few parts was just amazing.



LEO:  And we've lost a little bit of that now because there's so much RAM and such big hard drives.



STEVE:  Oh, we haven't lost a little of it, Leo.  It's just gone.



LEO:  I think probably - I would bet in hardware design you have it because you still have to keep those costs down.



STEVE:  True.



LEO:  So you're still trying to reduce the chip count.  Not to the degree that Woz had to.  I mean, they had hocked Steve Jobs's VW bus and sold Woz's HP calculator to fund Apple.  So they didn't have a lot of money.  But I still think that some of that in hardware design; but you're right, in coding, you know, save a few cycles on a substring search?  Bah.  Fortunately this stuff is around, and people use - I presume people use it in their libraries.  So, all right.  I love this.  This is the - I think we're coming to the aha moment; right?  Where you did the obvious.  You did the basic intuitive thing.  But as is often the case in computer science and algorithms, the first thing that comes to mind is not the best thing that comes to mind.



STEVE:  Well, and this happened in 1975.  You know, computers had been doing string searches for 20 years before then.



LEO:  Wow.  Wow.  So everybody had been doing it that way.



STEVE:  A lot of people had been writing the normal kind of string search.



LEO:  Character-by-character string searches, yeah.



STEVE:  Start at the beginning and march down until you see that they don't match.



LEO:  And start over.



STEVE:  And then start again.  And so...



LEO:  But you could see how that would kind of algorithmically increase in CPU usage because...



STEVE:  Well, yes, it does mean you're examining every single character in the buffer looking for potential matches of the string.



LEO:  Right.



STEVE:  So, okay.  To visualize this a little more clearly, sort of think of the buffer as Scrabble tiles, like a long, long, linear string of Scrabble tiles.  And the pattern is a shorter, similar sort of little string of Scrabble tiles.  And so what we've been talking about is we've been talking about sliding this shorter pattern of Scrabble tiles along the long buffer of Scrabble tiles.  And what we're trying to do is we're looking for anywhere as we slide along that they all match up, that the adjacent tiles of the pattern exactly match those in the long buffer.  And so intuitively, to save on - in terms of like an algorithm, as we were saying before, you just slide along till the first tile matches up with the one adjacent, the pattern and the buffer, and then you check along to see if they all matched up, in which case, bingo, we've found a match.  If not, you just keep sliding along, checking the first one, until it lines up, and then you check to see whether they all do.  What Boyer & Moore hit on was don't look at the first tile, look at the last one.  And...



LEO:  Okay, now, I'm trying to - okay.  All right.  So this is a huge insight.



STEVE:  Oh, well.



LEO:  Start at the end.



STEVE:  Start at the end of the pattern rather than at the beginning.  Why does it matter?  Because if you...



LEO:  You know, this is interesting because I'm looking in Volume 3 of Donald Knuth's "Sorting and Searching."  And I think this came out before Boyer & Moore.  So it's not in here.  This is 1973, and you say Boyer & Moore was right at 1973?



STEVE:  '75, and they published in '77.



LEO:  Ah, so it's interesting.  So this is the classic algorithm book.



STEVE:  Yes, and Knuth does have his own search, which is a forward-oriented search.



LEO:  Right.



STEVE:  So you're right, this was after that.



LEO:  Isn't that interesting, wow.



STEVE:  So, okay.  So...



LEO:  Start at the end.



STEVE:  Start at the end.  So we've got our first little pattern of tiles lined up at the beginning of the buffer.  We look to see whether the last tile matches the buffer.  And presumably, I mean, chances are it's not going to.  Well, here's the key.  So the last tile didn't match.  But the question is, what did it not match against?  That is, what was the tile in the buffer?  And here's the insight, is if that tile that did not match doesn't occur anywhere in the pattern you're searching for, you can jump that pattern all the way down by its length.  Because think about it.  If the tile at the end doesn't match, and it doesn't occur anywhere in the pattern, then as you slid the pattern along one tile at a time, you couldn't ever get a match in any of the intermediate positions because we already know that the tile that was in the buffer where the last tile of the pattern was doesn't occur anywhere in the pattern.  So there's no point in sliding it along one tile at a time.  Just jump the entire pattern down by its length.



LEO:  Oh, of course.  So that, if the pattern's long, could save you a huge amount of time.



STEVE:  You've got it, Leo.  This is a huge win.  The longer the pattern is you're looking for, the faster this goes, rather than the slower it goes.  Which is what you would think, you know, which is what you would end up with starting at the beginning and moving down.  So you like longer patterns.  Now, okay.  So what happens if the tile in the buffer does occur somewhere in there?  Well, the way this is implemented in code is a table is created that is where every entry in the table corresponds to a character.  So, for example, if we're matching bytes, then we've got - we know bytes are eight bits.  And so we would have eight bits' worth of entries in this table, which is to say 256 entries.  And most of those entries would probably represent characters that did not occur in the pattern we're searching for.  So we fill them all with the length of the pattern.  That is because - so the idea is, if we find that at the end of the pattern, we look that character up in the table, and it says jump the whole length of the pattern.  So the entry in the table tells us - it's called a "jump table," not surprisingly - how far we can jump the pattern forward.



But say that we had a pattern we were searching for that had "E" a couple times.  Well, if when we're checking a match the last character in the pattern doesn't match up with what's in the buffer, but what's in the buffer is an "E," well, what we want to know is, what's the minimum distance that we slide the pattern to cause the last "E" in the pattern to line up with the "E" in the buffer.  And so the idea is with Boyer-Moore you build this table before you start.  Before you do any string matching, you build this table.  You first fill it all with the length of the pattern.  That is, you fill all the entries in the table the length of the pattern.  Then you go through, and you quickly scan the pattern from the back to the front.  And as long as you haven't changed that entry in the table, you put in the distance that that character occurs from the front of the pattern.



So, for example, if "E" were four bytes from the end, that says then you're able to slide the pattern forward four characters that will cause the "E" in the buffer to line up with the "E" in the pattern.  The point is, that's the first chance that the pattern might all match in the buffer is if you slid it forward four.  So what this means is that, from an algorithmic standpoint, searching for a string is as simple and fast as you check the last character in the pattern and the buffer to see if they're the same.  If not, you use the character that you found in the buffer to look in this table for how far you can jump.  Most of the time you're going to be able to jump the whole distance of the pattern because the chances are that character doesn't occur in the string.  Sometimes you can't jump the whole distance because the character you found at the end does occur one or more times in the pattern.  But you can still instantly compute by looking it up in this table how far to jump to line up that character with the last instance of the character that occurs in the pattern.



So everything is this table lookup, which is extremely fast with computers.  They've got instructions just for doing table lookup.  And so the idea is you then jump forward by however much, and you start at the end again.  As soon as you have a mismatch, you look in the table how far you can jump.  Most of the time you can jump the entire distance of the pattern.  And that's this amazing insight that these guys came up with, which everybody uses.  It is today like the most efficient way of finding a substring in a longer buffer.  And exactly as you instantly got, Leo, the longer the string you're looking for, the faster the algorithm runs.



LEO:  That's the big surprise of this.



STEVE:  Yeah.



LEO:  Yeah.  In fact, now I think whenever I do grep searches on text, I'm going to have to make a longer string.  I always thought, oh, I'll make it shorter.  But make it longer, and it'll be faster.



STEVE:  And so what happens is, before you start searching, that jump...



LEO:  The table is built, yeah.



STEVE:  ...table is built that tells you how, for every character that you find, how far you can jump.  The other thing that's interesting about this is that the larger the alphabet, that is, like when we're searching for, say, some random binary data in malware, which is not - or actual executable code that is what malware is written in, uses the whole alphabet.  All eight bits' worth are generally going to be occurring in binary files.  Whereas in ASCII files we're using a small subset.  For example, the alphabet is 26.  With upper and lowercase we're at 52.  With alphanumerics we're at 62, and special characters.  Still we're many fewer symbols that are common than the 256 in a byte.  So the other nice thing about this is the more dense the use of the alphabet, the less likely it is that the character you hit in the buffer is going to be in the string.  So in general...



LEO:  Right, it's more efficient.



STEVE:  ...you're just flying through the buffer doing your search.  Anyway, it's just - it's one of those things where you can - it can be described visually.  You can sort of think about it.  But again, searching from the end is not what you would ever sort of just automatically come up with when someone said, hey, you know, write me a little routine to do a string search.  Yet it is so powerful to start at the end because, if you get a character, you hit one that doesn't occur anywhere in the string you're looking for, there's no point in sliding all the way along all those intermediate positions.  You know you can't get any matches because you already know that the character at the end doesn't occur anywhere in between.  So just jump over the whole distance and then check again.  And then, by using this table, you're able to quickly do intermediate jumps.  When you do get a character that occurs somewhere, you jump to where it might match.  But then you start again at the end.  And if it's wrong you just say, oh, forget it, and jump the whole distance.  It's just way cool.



LEO:  Very, very interesting.  Not intuitive at all.  Now, sometimes with algorithms like this, I know this happens with search, that it's better at some kinds of material than other kinds of material.  And there may even be places where it's counter-indicated.  It makes sense that, if it's completely random data, it's better; right?  Because you're going to have - you now have fewer hits.



STEVE:  Yes.  You would certainly have - if you had, well, for example, if the string you were looking - if the pattern had many duplicate characters in its body, then you would tend to be checking...



LEO:  More, right.



STEVE:  ...those possible alternatives.  Instead of doing whole jumps, you would have a more likely chance of doing little, less-than-full-length jumps.



LEO:  So is it less efficient if it's looking through ones and zeroes, then?



STEVE:  It's more efficient when you're taking larger chunks at a time.  That is, when...



LEO:  Right, bigger alphabets.



STEVE:  Right.



LEO:  More randomly distributed would be good.



STEVE:  Right.



LEO:  So if it were ones and zeroes, a small alphabet might not be as good in binary data is what I'm wondering.



STEVE:  Well, but the beauty is you're taking the binary data at a byte at a time.



LEO:  Oh, okay.  You're right, of course.  So you are doing an alphabet, then.



STEVE:  Right.  So aggregating in larger chunks increases the size of the alphabet.  And as I was saying, the larger the alphabet, the more efficient the end result.



LEO:  It's really, really cool.



STEVE:  It is just - it's one of those conceptual little just gems.  And you can imagine Knuth saying, ooh.



LEO:  Ooh, I missed that.  I missed that one.  Well, there's a lot of algorithms in his - you know, he's only published two volumes.  I think that he's working on the third.



STEVE:  Actually he has three.  I own the first three.  But I think there's, like, there's a bunch more.  And you're right, he is working on them now.



LEO:  Yeah.  He stopped because they were stalled out.  But that's the point.  I mean, if you've got thousands of algorithms in a book like this, I have - oh, I see them behind you, yeah.  Is that it?  There's one, two, three, four it looks like you've got there.



STEVE:  Yeah, but I've got two copies.  And maybe you're right.  I was trying to look just to see...



LEO:  I think there's only two.  I think there's Volume 1 and 3.



STEVE:  I've got two of each.



LEO:  Yeah, Volume 1 and 3.  I know that's what I've got.  And I heard he was working on Volume 2.  Donald Knuth is a professor of computer science at Stanford, and these are...



STEVE:  No, I've got volumes 1, 2, and 3.



LEO:  There are three.



STEVE:  So there are three, but he's definitely working on finishing them, which those of us who are into this stuff, it's like, oh, come on, come on.  I mean, those are the bibles.  Just he's done such a beautiful treatment of these fundamental approaches to solving these problems.



LEO:  He'd better hurry.  He's in his 70s now, so...



STEVE:  Yeah, but he's good.



LEO:  He's really good.  And he also...



STEVE:  He can spit this stuff out.



LEO:  He also created his own...



STEVE:  Typesetting system.



LEO:  Yeah, he created TeX to do this.



STEVE:  Because, yeah, because there was nothing that was able to adequately - he wasn't able to express himself on paper using the computer.  So he said, okay, well, I'll just have to do a sophisticated typesetting system.



LEO:  And it uses kind of a pseudo language, a pseudo - it's almost Assembler language to demonstrate this.  Because he didn't want to do it in any specific language.



STEVE:  Well, he has - it's called MIX, M-I-X, which is his own little Assembly language.  And so he shows you code for these things in this little MIX language.  And in fact a MIX emulator is available under GPL on the 'Net.



LEO:  Oh, really.  Oh, that's neat.



STEVE:  You're able to actually write, and it'll compile and run these little MIX programs for you.



LEO:  Oh, how neat.  In January - I'm reading in the Wikipedia article.  "January 1990 Knuth announced to his colleagues he would no longer have an email address so he could concentrate on his work."  He knew in 1990 that what we now know...



STEVE:  This was going to be a problem.



LEO:  20 years later, oh, yeah, email's a problem.



STEVE:  I don't think he's probably doing any tweeting or twittering.



LEO:  He's not twittering, either, I can guarantee that.  Yeah, three volumes so far, and he's working on Volume 4.  And apparently updates are released to the website.  So that's really cool.  That's really cool.



Steve, I loved this.  This is really fun.  And I know next week we're going to do a Q&A segment.  But the week after you want to do another one of these computer algorithm shows?



STEVE:  I've got one lined up, Leo.  That's what we're going to do.



LEO:  Good.  All right.  Do you want to tell us, or is it a surprise?



STEVE:  Well, we've got two guys once again.  This time we had Boyer...



LEO:  Oh, you mentioned at the beginning, yeah, yeah.



STEVE:  Bob Boyer & Moore; right.  And next time we're going to do Lempel and Ziv.



LEO:  I can't wait.  I know a little bit about this one because I wrote a very early compression program for the Mac when there were no compression programs out there, using LZW.



STEVE:  Cool.



LEO:  We will return next week.  Please listen every, let's see, the show comes out Thursday.  We record on Wednesdays on live.twit.tv, Wednesdays at 2:00 p.m. Eastern, 11:00 a.m. Pacific.  But because I'm going to China, the next recording will not be for a couple of weeks.  But we will be back on July, let's see, 18th, 19th, 20th, 21st - 22nd.  I think that's a Wednesday.



STEVE:  Yes, it is.  And the 23rd is the Podcast 206, and I've got it slated here as a mega security news update.



LEO:  There'll be a lot to talk about.  Let's see, while I'm in China...



STEVE:  We're going to have a lot to talk about, so we're just going to do that.



LEO:  ...the Chinese hackers will be busy.  Then we'll have something to report.  Steve, always a pleasure, especially when you do this kind of stuff.  Go to GRC.com.  That's his website.  You can get a copy of SpinRite there, the world's best hard drive maintenance and recovery utility bar none.  I can say that unequivocally.  Also great free stuff like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Wizmo, soon some really neat new stuff coming out.  Of course Perfect Paper Passwords are there, as well.  And his forums, some great security forums.  And that's where you can also leave questions for our Q&A sections.  That's at GRC.com/feedback.



STEVE:  Yes, please do.  The questions are definitely appreciated.



LEO:  16KB versions of these shows, transcripts, and show notes also there.  And we have additional show notes thanks to our intrepid audience at wiki.twit.tv.  Steve, we'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#204

DATE:		July 9, 2009

TITLE:		Listener Feedback #70

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-204.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 204 for July 9, 2009:  Listener Feedback #70.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security/privacy related, with Mr. Steve Gibson, the man of the hour, the guy who discovered spyware, coined the term "spyware," and just disappeared as I pressed a button on the screen.  Hi, Steve.  Welcome to the show.  Your show.



STEVE GIBSON:  Hey, Leo.  Great to be with you.  As our listeners are hearing this, you are somewhere over the water in Asia.



LEO:  [Singing] Somewhere over the rainbow.  Let's see, this is July 9th.  So, yeah, I will actually be on the boat sailing from China to Korea right now, exactly right.



STEVE:  And if you heeded the advice that we discussed two weeks ago, you're carrying an ATM card that is not backed by too much cash.



LEO:  That's right.



STEVE:  Because you don't really control the environment over there to the degree - in fact, maybe no one controls the environment over there to the degree that we enjoy here in the U.S.  So I hope that your cash is safe.



LEO:  I don't know, you know, I mean, I think in the old days travel was a great adventure, and all sorts of horrible things could happen to you.  And now with the Internet and television it's just become, you know, and air flights, it's just become pretty mundane.  So maybe a little adventure.



STEVE:  It's very much more like you never even left home because, after all, there is a Starbucks on every corner, no matter what country you're in.



LEO:  I was warning Henry that, oh, you know, the food in China, you know, may be very difficult for you.  We might have to go through a week of suffering in China.  And then somebody told me, oh, no, there's McDonald's everywhere.  It's like, oh.  They said the best Kentucky Fried Chicken you ever had is in Beijing.  It's like, oh.  Oh.



STEVE:  But as a consequence of the fact that we are recording this two weeks ahead, or three weeks ahead, actually, of when it's going to be aired, I don't have any security news.  However, what we're going to do to make up for this is the Q&A in two weeks is just going to - is going to be our mega three weeks' worth of security news catch-up.



LEO:  Everything that happened while Leo was in China.



STEVE:  Everything that happened while Leo was floating around Asia somewhere, we'll be talking about.



LEO:  But to Steve's credit, he doesn't want to miss a single episode.  He's never missed an episode.  We are at 204 episodes in 204 weeks.  So we decided to double up a couple of shows and make sure that we get everything recorded so that you miss nothing.



STEVE:  Well, I hear so many thank yous as I read through the mailbag - by the way, that's at GRC.com/feedback.  So many people appreciate the reliability of knowing that they're going to have a Security Now! podcast absolutely every week, come hell or high water, that I don't want to disappoint them.  They're going to have to wait a little bit for news.  But they'll get the news that happened only a couple of weeks late.  So we're going to do a special mega news catch-up podcast for the next Q&A two weeks from now.



I did have, when I was going through the mailbag for this particular story, a really nice sort of short SpinRite story that I wanted to share with our listeners from a woman named Louise who said that her - the subject was "GRC is my new hero."  She says, "Hi, Steve and Leo.  I have a SpinRite story for you.  Recently someone using my computer managed to get it infected with a trojan."



LEO:  Ugh, don't you hate that?  Don't you hate it when that happens?



STEVE:  Yup.  "Being a long-time Security Now! listener, I decided to reformat the drive" - good girl - "and reinstall Windows."  Because after it's infected, that's what she means, is after - she knew that after it was infected she could never trust it again.  So she said, "I backed everything up to my external drive.  This drive locked up while I was attempting to move my data back onto my newly reinstalled computer.  I shut everything down, checked all my connections, and tried again.  Imagine my horror when I discovered all of my backed up data had disappeared.  The drive still worked, but my folder was mysteriously empty.  I prayed for a miracle."  So that means she was able to see the drive, but the folder where she had put everything had no contents.



LEO:  So that's kind of a good sign.



STEVE:  Well, it's better than if the drive was completely, completely not spinning anymore, or hosed in a bad way.  I mean, yes, it's a hopeful sign I would say.



LEO:  Hopeful, there's the word I was looking for.



STEVE:  So what she prayed for was what she needed.  She says, "I prayed for a miracle and booted up my copy of SpinRite.  (I had originally purchased it three years ago after losing two hard drives in grad school.)  It took 27 hours, but I'm happy to say my data is all back and currently being copied back onto my laptop.  Thank you so much for SpinRite.  It is definitely worth every penny."  So, neat story.  Thank you, Louise.



LEO:  Wow.  Very interesting.  Well done.  Are you ready, my friend, for some questions and answers?



STEVE:  We've got - this one, okay, I put this at the top.  Because we're recording double shows this week, we have a little bit more limited time than usual.  Normally this would have been the absolute mind-blowing story of the week, which we would have put at the end.  But I didn't want to risk missing this one because this is just too wonderful.



LEO:  Nothing wrong with starting with a bang.  And this is a bang.  Trevor in Wall, New Jersey takes the cake with his Story of the Week.  Subject:  Windows in Places It Shouldn't Be - Supermarket Edition.  Hey, Steve and Leo.  I've been a listener since Episode 20, and I've listened to all of it in reruns.  I certainly agree with Steve's attitude towards Windows, a consumer operating system, being used in mission-critical places.  I recently had a horrifying experience at my local A&P supermarket here in New Jersey.  I walked up to a self-checkout aisle and began to scan my items.  Out of nowhere the system freezes, beeps, and begins to reboot.  Lo and behold, a friendly Windows 2000 boot screen appears.  I cringe.  I cringe.  As a long-time Security Now! listener, I watched in horrified fascination as the machine automatically logged in a user named "Terminal6."  There was an icon on the desktop labeled "Shopping Panel" that probably was the interface for the checkout application.



So I decided to do a little investigating.  I opened Internet Explorer 6, and it brought me to MSN.com.  Hmm, guess they never changed the default web page.  At this point an annoyed A&P employee walked over and took control of the machine.  He launched the checkout application and walked away.  There was no antivirus software on this machine.  There was no software firewall.  And this machine had direct access to the Internet, running probably unpatched Windows 2000 Professional.  Good lord.



STEVE:  I know.



LEO:  I am never putting my credit card into one of these self-checkout machines ever again.  Thanks for all the great work on Security Now! as well as Leo's other - I'm so glad that this person listens and had the sense to try that.



STEVE:  Isn't that wonderful?



LEO:  Unbelievable.



STEVE:  I mean, I just - I get the hugest kick out of, okay, we're surfing the Internet from the self-checkout machine in the supermarket.



LEO:  It's connected to the 'Net, unprotected.



STEVE:  Launch IE6 and up comes...



LEO:  Never patched, obviously, yeah, if it's running IE6.



STEVE:  Ugh.



LEO:  By the way, he says:  I convinced my dad to purchase SpinRite last year, and it saved him from losing his entire novel.  We have been SpinRiting every two months ever since.  There you go.  That must make you feel good.



STEVE:  It does.  That's just great.



LEO:  Somebody's using your stuff to save their life.



STEVE:  Yeah.  Anyway, Trevor, thank you, thank you for the story.  I just - I get the biggest kick out of, you know, he's scanning his items, and it's Windows, so of course it was going to freeze sooner or later, and it chose to do it right then.  Then it restarts itself and doesn't launch into the app, just gives him a desktop where he sees IE6, which he probably double-taps on the touchscreen and, whoop, up comes IE6 and brings up the news on the MSN.com site.  I just love it.



LEO:  I guess he could have run Windows Update, but that would've probably broken everything.  You broke our computer.



STEVE:  Oh, goodness.  And as he says, I'm not putting my credit card in one of these suckers again.



LEO:  No, I don't blame him.  Nor will I.



STEVE:  Wow.



LEO:  I don't like those automatic checkouts anyway.  But now I really - of course you can't, you know, they're probably using the same system for the checkers, I mean, it's probably exactly the same system.



STEVE:  Yeah, and Terminal6.



LEO:  Terminal6.  Question 2, Doug Zuckerman, Bethesda, Maryland, asks about finding Q&A questions:  Steve, just a suggestion for the future, I think it'd be a great addition to the website, but wouldn't it be nice if on the main Security Now! page in the topic title for each Q&A episode of Security Now! it showed the specific questions you answered in that episode.  I find that not only do I listen to your show for new information, I also use it for reference.  And it's difficult to find the right Q&A shows to go back to when the questions aren't listed.  Anyway, of course your site has tons of great resources as it is.  I'm not trying to suggest you guys don't do enough already.  I just think it'd be a really good enhancement if you ever feel like it.



STEVE:  Well...



LEO:  I think we might do that ourselves in our show notes; don't we?



STEVE:  Well, the problem is that the questions are often hard to summarize.  I mean, what would I write for that question that Doug just asked?



LEO:  Right.  Yeah, you're right, it's a good point.



STEVE:  And the good news is that we have the transcripts for everything, and those are indexed by Google and other search engines.  I had an experience just a couple days ago of where, I don't remember, I was at Starbucks, of course, and I was looking something up, and the second link that came up in Google search results for the keywords that I was searching was one of our own podcasts.  And it was #120.  Oh, I put in "TrueCrypt" and "BootIt NG" because I was talking to a buddy of mine who had dropped by, and he was wondering whether you could use TrueCrypt and BootIt NG at the same time.  And I said, gee, that's an interesting question, because I could see that there could be a boot sector track zero collision, much as there was initially with TrueCrypt and some of the Adobe copy protection stuff, the Macromedia stuff.  So I put into Google "TrueCrypt BootIt NG."  And in Security Now! Episode 120 we were talking about that.  And so it was the second link that Google brought up.  I thought, hey, now, this is exactly why we're doing transcripts.



LEO:  That's really the point, yup.



STEVE:  Aside from the fact that people really do like to read along or read them instead of listen to them in some cases.  And so we've got Elaine doing a great job of that.  So, Doug, the only thing I could suggest is that on the Security Now! page at GRC, as you noted, SecurityNow.htm at GRC, there is a search box on the upper right.  And it will search only Security Now! podcasts if you configure it that way.  If you ask for that, it will limit itself to Security Now!.  And so put in some keywords, and you can probably find the podcast.  I think that's much more practical than trying to summarize the questions in each of the Q&As, which they're just - it'd be really hard to summarize them.



LEO:  Well, but I also will point you to our wiki.twit.tv.  We do show notes for all the shows there, and we have very detailed show notes, including the questions there for each episode.  And on FriendFeed, as we're doing the show we have a FriendFeed conversation for every show that we do on the network.  If you go to FriendFeed.com/twit-conversations - I don't think you have to sign up to see these,  FriendFeed.com/twit-conversations - you can go back through all the shows.  And as we ask the questions of Steve, I post the entire text of the question in there.  So there are a number of places you can go.  These will also be Googled.  But there are a number of places you could go to find that information.  But our wiki.twit.tv has very complete show notes, including timecode.  And I don't know who's doing that, but I thank that person for doing all that effort because that's a heck of a lot of work to put in there.  So thank you for all your hard work on that.  Actually, if I look at the history I might be able to see.  We have, it's nice, Steve, we have listeners who use the wiki, which is a media wiki, it's the same as Wikipedia, to really enhance the content of the website.



STEVE:  That's great.



LEO:  And we do that for the same exact reason, I mean, the problem with a podcast, it isn't searchable.  So having text related to the content so that you can search on Google is so important, I think, as time goes by.  So thank you, Doug, for that question.  And thank you to AKalair Mind Tricks for putting in all that information in our show notes.



Brad Banko in Cuyahoga Falls, Ohio - isn't that where Bailey Savings & Loan was?  I don't know - asks about Assembly language.  I listen to your podcast from time to time.  Chess Griffin of the Linux Reality podcast pointed me to it when Vista opened my eyes to the need for an alternative to Microsoft software.  By the way, I use Fedora Linux quite a lot, really love it.  30 seconds to boot, 30 seconds to desktop, 30 seconds to shut down on a 10-year-old machine.  The only thing that I still use Windows for are my scanner and TurboTax.  My question is, you mentioned you develop your software in Assembly language.  Doesn't that mean your work is tied to a particular, presumably Intel process architecture?  Or has Assembly language programming advanced to the point that you can write architecture-independent code?  My background's mainly science, with computing as a hobby and a tool.  Thanks, enjoy your show. 



STEVE:  Well, he is exactly right.  What Assembly language is, is the actual instruction set of the machine.  So I've been programming Intel Assembly code ever since the IBM PC happened.  Before that it was the 6502 chip on the Apple II machine and also the Atari and the Commodore machines.  So the 6502 was on multiple platforms, so I was able to use a single programming language among those manufacturers who were all using that chip.  In this case, of course, the Intel architecture is dominant.  It, for better or worse, won out over the PowerPC because people liked the idea that the clock rate was faster on the Intel chip, even though you could argue that the PowerPC, being a very nice RISC design or heavily RISC-influenced architecture, was doing more per cycle than the Intel was.  Still, people wanted Intel chips for whatever reason.



So it is the case that I'm definitely writing platform-tied code.  But I'm writing it for almost all the machines out there.  I mean, I guess you have PDAs, for example, which are using ARM chips, and I couldn't use Intel Assembly language for writing to that platform.  On the other hand, there is, when you're an Assembly language programmer, you're dealing with binary registers and motions of data among registers.  And you're at a low level such that moving everything you know to a different platform isn't difficult.  I mean, if someone said, Steve, we need you to write something for the ARM processor, which I've never programmed before, I would just sit down with the instruction reference and go, okay, how does the ARM add?  What's the instruction for subtract?  What's the instruction for load and move?



So I can easily map everything I know, all the experience that I have on one low-level architecture onto another.  It's just a matter of knowing what the instructions are.  Just as I went back, you know, turned the clock back and was writing code for PDP-8.  It's like, oh, what a quaint little machine.  But, you know, all the rules still apply.



LEO:  Well, you have even more dependencies than just the code because you use - don't you use interrupts on the hardware?



STEVE:  Oh, yeah, I mean, you're right, it's not just the instruction set.  It's the whole architecture.



LEO:  I mean, you could in theory, I mean, Mac runs Intel.  But you're writing not just to the processor, you're writing to the BIOS.  You're writing to...



STEVE:  Correct.



LEO:  So it's not portable beyond a PC.



STEVE:  All the hardware resources of that machine; right.



LEO:  Which answers the question people often ask me, why is there no Mac version?



STEVE:  Right.



LEO:  So, yeah, I mean, you get advantages with hardware dependence.  But you also - that's the disadvantage, it's not portable.  That's why I think most of the world's moved to higher level languages for most of the code.



STEVE:  Way most.  Way, way most of the world.



LEO:  Brian Taylor, Walnut, California, wants to know Steve's secret.  What is your secret?  I have a quick comment and a question.  I've been listening to your wonderful netcast since Episode 1, lately have gotten way behind.  I'm still in January.  We've just made him a lot more behind.  I just finished listening to an episode where you mentioned the PDP-8.  I immediately headed over to SpareTimeGizmos.com to find out he sold out of the front panels this spring and has no intention of making more.  Oh, well, my fault for not staying up to date.



As for my question, how do you do it?  How do you wrap your mind around all the complexities of what you do?  Is it an inborn ability, or is there something else in the mix?  After listening to one of your episodes my brain feels like it ran headlong into a brick wall.  Help me, Steve, I want to be smarter, I need to be smarter.  I always think of it in this way:  I'm just smart enough to know how dumb I really am.  I'm with you on that one, Brian.  I'm right there with you.



STEVE:  Well, okay.  I've been wanting to say something along these lines for a while, and that is that you and I, Leo, have been around for a long time.  So I'm drawing from a large base of stuff that I learned a long time ago.  And I also have extensive knowledge about a relatively narrow category of things.  But this format of the podcast does allow me to seem to have more facts at my grasp than I do.  I spend, not a day, but many hours preparing for the podcast.  And so, for example, I don't have RFC numbers memorized, or I don't have MD5 hashes of things memorized.  I focus on the topic of the podcast for many hours beforehand, brushing up and bringing myself up to speed, getting all revved up and ready to go so that during an hour, an hour and a half, I'm at the top of my game on whatever topic we're discussing.  And a couple weeks later it's all a blur.



LEO:  Oh, thank you for admitting that.



STEVE:  It is.



LEO:  It's all a blur to me a couple of minutes later.  But at least - well, you know, as often is the case when somebody's really working hard, it makes it look easy.  And you work really hard to make it look easy.



STEVE:  Well, yeah.  I mean, I love the topic.  I love the technology.  I understand the fundamentals of this stuff.  But nobody could know everything that's going on in every corner of the industry.  And I certainly don't.  I mean, I've got a day job.  And I'm focused on one area.  And I would argue where I'm focused, it's hard to fool me.  But I can't talk about just that all the time, so we're talking about much more.  And so I'll pick a topic.  I'll say, ooh, this is something neat that I think would interest our listeners.  And I then focus myself on that with the advantage of a lot of background that helps me digest it quickly.  But the excruciating minutiae and details, again, it's like somebody will - sometimes I run across a question about something from a few weeks ago, and I go, oh, boy, we were talking about that.  What is the answer to that one?  You know?



So anyway, I just wanted to say that, in response to Brian's completely understandable question about wow, you know, how is there so much here, it's like, okay, Brian, I'm cheating.  It's here today; it's gone tomorrow.



LEO:  I forget it all very quickly, too.  And I make more mistakes than you do.  Mat Ludlam in Weybridge, London wants a bit of help with cookie programming.  He says:  Steve, I love the show.  I've been a long-time listener since the very first episode.  And I'd like your opinion on the subject of storing data in cookies.  I want to store a cookie - he's obviously writing web applications here.  I want to store a cookie on a user's machine that allows them to automatically log into my system.  I want this cookie to have a lifespan of about seven days, and I don't trust the users.  I don't have a problem with users seeing the information, I just don't want it changed.



My thoughts are to create a cookie which has the information I care about - login, password, et cetera), an expires date, and a hash total.  I would take each of the pieces of data and put them through a hash along with some salt which is one of your secure passwords.  This would be the hash total that I store on the browser cookie with other data.  The salt would never leave the server, my server, so it's a secret.  Is this system resistant to the data being changed?



On a related subject, I don't want to store the password in a cookie in cleartext, so what would you advise?  If I store the password hashed with the userID, is that enough?  Or do I need to add some more secret salt?  Finally, how can I stop the user from copying a cookie from one machine to another?  If I try to add the IP address of their machine, then I probably have the address of their company's NAT router, so it does not get tied to a single machine, rather an organization.  And finally, am I doing this the right way, or is there a far better way of doing it?  Thanks in advance for your help and advice.  A little cookie programming advice.



STEVE:  Yeah, and an interesting question.  I would say there, surprisingly, sort of is a right and wrong way to approach this problem.  The biggest question that I would have for Mat is does he have the ability to store stuff at his end, on his server.  We know that he can have keys and salt.  But the question is, can he store information?  Does he have the ability, does he have access to some sort of a database, even a simple database that he could write himself, sort of a flat file database.  The point is, you either store the data in the cookie, the data itself in the cookie, or you just store a pointer to data that you're maintaining on the back end, on the server side.



So it's certainly not necessary to go through any of these gyrations if you've got the ability, if you've got state, if you can store state of some sort on the server end.  In which case you would just take a counter, you'd take, like, a 128-bit counter, and you'd encrypt it with your own secret symmetric key.  That would turn the counter - which starts at zero and runs up to, you know, all one bits - it would turn it into a completely pseudorandom-looking token.  And so that the unencrypted counter would just be a record number in your own little private database.  You encrypt it, and that's what you store in the cookie.



So the cookie itself has no data.  It just has this, as we used the word two weeks ago, a "nonce," a one-time-use little blurb which is completely random-looking.  The user could change it if they wanted.  But when it came back to you and was decrypted it would be nonsense because you would know what the valid range of values was, zero to some limit.  And if they made any change to it, it would send it off, when that was decrypted, it would completely turn into nonsense.  So there's a simple solution, but it does require that you're storing no data in a cookie, you're just - essentially you're storing a pointer, an encrypted pointer, to a record in your own database back on the server.  And of course then you've got all kinds of flexibility - username, password, expiration date, you can put as much data there as you want to and manage that.



If for some reason you cannot, you don't have the ability to have a database, to have any state stored at the server side, then you have no choice other than to store that data in the user's browser in a cookie that you give them.  And there again the solution is simple, and that is you simply use your own secret encryption, your own secret key to take the data that you've got and concatenate it into a record and encrypt it.  You'll want to hash it so that you generate a signature, so that it's essentially digitally signed using the techniques we've talked about before.  Use one key for a keyed hash in order to create a digital signature, and then encrypt that with a different key.



That's going to be a blob of data which you can safely put on the user's browser.  It's just, I mean, it's nonsense for them.  Again, they can't change it.  It means nothing to them.  There's nothing that they can do to gain any leverage.  Anything they do to, like, mess with it will just break it.  And then every time they have a browser transaction, apparently you want to use that for allowing them back into your website for a period of seven days, well, that cookie would be sent back to you.  You'd decrypt it with your symmetric key.  You verify the hash of it using a different key.  That tells you that nothing has happened to change it.  And with every single transaction you get all the data back that you want to store - username, password, expiration date.  You're able to then look at those things, decide what you want to do with them, and permit or not the user to proceed.



So either in the first case you're storing the data at your end and just giving them a little token for it, a pointer to it; or, in the second case, you give them all the data to store in their cookie, and they give it back to you every time.  So either way will work, and it's just a function of what you're most comfortable with and what makes sense based on the capabilities you've got at the server end.



The last question you asked was, is there a way to prevent them from moving it from machine to machine?  And I cannot see any way to do that without involving scripting.  If you've got scripting involved, and the login facility can have JavaScript running, then you could certainly incorporate something into the cookie which binds to something unique about their machine.



LEO:  Can you see their MAC address?  Can you...



STEVE:  You could use the MAC address.  And, for example, if this was on Windows, there are various GUIDs, G-U-I-Ds, for Windows.  There are various things that are pretty much guaranteed to be unique from one machine to another.  So if you incorporated that into the cookie, and then when they attempted to re-log in, you would again use some script to verify that.  Then I could see how you could lock it to a given machine.  But you'd have to have something active on the client side.  Otherwise a browser is a browser is a browser.  And if you move the cookie to a different machine, then it would be able - it would look the same from your viewpoint, from the server end, a client making that request.  You really wouldn't see any difference.



And there's metadata that browsers send along with their queries that might be different from one machine to another, like what version of the browser, what version of Adobe and PDF reader and other things sort of tack themselves onto the queries.  So you might see some difference.  But if you really need to prevent it from being moved, you have to do something with scripting locally on the machine.  And I think that solves the problem.



LEO:  Steve, let's talk tethering.



STEVE:  Okay.



LEO:  John in Indiana wonders about the security of tethering his cell phone to his laptop:  Thank you both for your time.  Leo, I can thank you for turning me on to the podcasts, so many so I can't keep up.  All of TWiT's shows help me stay on top of the tech news, and that lets me help people that come to me asking for advice.  So thank you for your time and energy.  You're welcome.  Security Now! is still my favorite.  Yay.



I'd like to hear your thoughts, Steve, on the security of connecting to the Internet on a laptop via tethering from a cell phone.  This is something they've added to, you know, the Palm Pre does it, I think.  They've added it to the iPhone once AT&T says okay.  I guess you're not behind a router, as you usually suggest.  Can I assume that I'm at risk, that not having a router makes me less secure on a cell phone access?  And does the same thing happen with these cell phone access cards, the EVDO cards?  What about those?



STEVE:  Well, it's an interesting question.  The only reservation I have about a cell phone tether as opposed to a cell phone access card is that we have seen instances of cell phones themselves being compromised.



LEO:  Right.



STEVE:  That is, you know, it's a computer.  It's running an operating system.  It's got a browser.  It's got instant messaging.  It's got all those things that tend to have problems.  And we mentioned two weeks ago that when the iPhone was updated to v3.0, more than 40-some security problems were patched.  Many of them were like, can take over your phone remotely and execute remote code, et cetera.  We know that many phones also have Bluetooth, and Bluetooth is another vector of real security concern because people often leave them in discoverable mode.  And there are many well-known exploits where you can take over somebody's phone using their discoverable Bluetooth pairing.



And so the problem is, when you combine that with its use as an Internet modem and tether it to your laptop, you're essentially hooking two computers together, one which tends to be exposed to a lot of threats.  So as opposed to a cell phone access card, which is just a dumb cellular modem, and itself cannot be compromised.  So from a security standpoint I would be much more comfortable using a cell phone access card than tethering my phone to the computer.



But aside from that, the cell phone service itself, that is, you know, the technology of cellular communications, is secure, but not nearly as secure as is state of the art.  It is definitely the case that all of the different cell phone technologies can be cracked and have been cracked.  They go to a great extent to obscure the traffic.  And so I would say it obscuration rather than security because, for example, some of the cell phone technology used cleverly designed shift registers with prime number repetitions to create pseudorandom data which is mixed in, then XORed with the stream of data leaving the phone.



Well, it means that it's good security, but it's far from the type of security we talk about on this show as being absolutely uncrackable.  And it has been cracked.  I mean, all of the cell phone technologies have been cracked.  There's no question that NSA people and even much less skilled hackers are able to get into that conversation.  So you should consider that your use of a cell phone communication is not much more secure than an open WiFi hotspot.  I mean, it is more secure than that because a hotspot is just sniffable with anything.  But and so it takes much more technology to crack a cellular connection.  But it is definitely crackable in a short, relatively short length of time.



So you should think in terms of using a VPN, making sure you're using an SSL, you know, HTTPS connection when you do things, the sorts of things that you would do if you were in an open WiFi hotspot in order to have the kind of security that you probably want to have.



LEO:  I have an interesting hybrid product I've been using.  It's called a MiFi.  And it takes an EVDO connection via Verizon.  And it has a hotspot WiFi access point built into it.  So it is a router.



STEVE:  That's the worst of all worlds.



LEO:  [Laughing] Yeah, you just made me think that.  Well, the router, I turned on WPA.  So at least I have that.  But so they'd have to crack the EVDO to make that...



STEVE:  Yeah.  And again, it's not easy.  But every one of the cell phone standards has been cracked.  They've got - the problem is...



LEO:  Wow, I didn't know that.



STEVE:  ...they were designed a long time ago.  They were designed back when we had much weaker hardware.  So in the same way that the original WiFi with its WEP was designed, it's like, okay, this is good enough to secure, well, the hardware grew in capacity, but a standard had been established.  Similarly, these cellular standards, I mean, the hardware to implement them is worldwide, spread out in towers and in pockets all over the globe.  You can't change it now.



And the bad news is, it was regarded as strong back then, but also it was a clear compromise because the hardware, the cellular handset hardware was so low power in terms of computing power that they couldn't do much more than they did.  So they said, well, this is as good as we can get now.  The problem is, technology has made huge leaps since then.  The standard hasn't changed.  So you really, I mean, if security is a concern, you want to provide your own wrapper, your own security wrapper around your traffic so that, if anybody - I mean, and I doubt this is happening.  And remember that, you know, the NSA doesn't have to crack it in the air.  They just have to go visit the base station at the other end, and it's been cracked for them.



LEO:  They have access to everything, presumably.



STEVE:  There's much easier ways to do this, yes.



LEO:  If you've got the clout.  Brandon in Portland, Oregon wonders if size really does matter:  Dear Steve and Leo, I have a question about hard drive data integrity and how it declines as hard drive storage and density goes up.  I've heard you mention in the past that, as hard drive density goes up, the margin for error goes down, which in turn requires more error correcting due to the density at which the data's stored.  I thought I heard, and correct me if I'm wrong, that your comfort zone for hard drives is around 500GB and lower.  Anything above that density has too large a chance for error for Steve.



My question is this.  Is a terabyte drive really any less robust than a drive with much lower density?  Isn't a terabyte drive usually four 250GB drive platters in one drive enclosure?  In this case, wouldn't a terabyte drive be just as reliable as a 250GB drive, seeing as how the data is being stored on essentially four 250GB drives?  I'd love to know the verdict and why especially, since you make everything that requires a propeller hat so simple to understand - oh, especially you, since you do that.  Love the podcast, listening since day one and looking forward to it every week.  Next Friday is my paycheck at a real job, so I'm looking forward to buying my first copy of SpinRite.  And I've been a TWiT supporter and donator since day one.  Thank you.  Thanks for both of your hard work.  Thank you, Brandon.  So actually I don't know if that's the case.  What you're talking about is areal density, the amount of bits squoze onto a single platter; right?



STEVE:  Squoze, yeah.



LEO:  Or a single cubic centimeter, I guess.



STEVE:  See how Elaine spells "squoze."  I have to confess that I think this is largely me just sort of being an old curmudgeon.



LEO:  Curmudgeon, yes, that's the word I would use.



STEVE:  Yeah.  Brandon is correct that you'll notice that drives jump in capacity by sort of fixed numbers, which is the number, is the amount of bytes that go on a platter.  So you'll have, like, the 40GB and the 80GB and the 160 and the 320.  And it's like, is it any surprise that these things are jumping by that amount?  That is, literally, they put another platter in, and it doubled it.  Or another one, and now it went up by two thirds of that size and so forth.  So it is the case that they develop a technology that fits a certain density on a surface.  And in some cases they'll leave one surface unused because that's what their marketing department tells them to do, even though it doesn't make any sense logically.



Now, is four 250GB platters the same reliability if they're put in a single drive, as if they were in four drives?  You could argue that if you had them in four separate drives you could run RAID on them.  So you'd lose the equivalent of one drive, yet that would give you dramatically more reliability because then, if any one drive died, you've still got a hundred percent of your data.  Whereas the more data you put in a single enclosure, it's sort of like the problem of the airliner that crashes.  It's like, well, boy, you know, we lost a lot of people when that happened.  Whereas you also say, well, more people die on the road every day in little onesie accidents that don't draw nearly as much attention.



So, I mean, the reliability question is an interesting one.  I would have to say that contemporary drives are extremely reliable, but you never want to be in a position where losing one really creates a problem for you because they die.  And so, for example, as I have said before, there's no system I have where I have mission-critical data where I don't have a RAID and some sort of on-the-fly, in-the-background backup happening.  You really do want to make sure that a catastrophic loss of a drive is not something unrecoverable because drives die.



LEO:  Yeah.



STEVE:  And I'm glad that Brandon's going to be buying a copy of SpinRite, so he'll be prepared when one does.



LEO:  Drives die.  That's the bad news.  So are you buying terabyte drives now?



STEVE:  I've had no occasion to because Assembly language doesn't take up that much space, Leo.  No, I'm kidding.



LEO:  We buy six of them at a time, you know?  And we record everything on terabyte drives.  And I'm sure we'll go to a bigger size at some point.  But right now the sweet spot, I mean, a Caviar Green Western Digital drive is about 85 bucks from New Egg.



STEVE:  Wow, wow, wow.



LEO:  For a terabyte.  And these are really good drives.  They run a little slower, but the areal density is so high they don't feel slower.  But the RPMs, I think, are 5400.  So I think that - of course, this isn't mission-critical, either; right?  I mean, these are just recordings of the shows and stuff.



STEVE:  Yeah, it's just what we do all day long.



LEO:  But we have other - we have other recordings.  These are more like archives.  I don't, you know, I actually don't do anything with them right now.  But we'll have them.  I don't know if somebody will want them someday.  Look back, the good old days...



STEVE:  Good to keep them.



LEO:  ...back before aliens took over the world and eliminated all security flaws.  Scott Teriano in Port Pirie - not sure how you say that, Port Prairie? - South Australia says Steve's non-VPN idea is partly original:  Hi, Steve, Leo.  Your idea - I'm sorry, I won't do this - your idea of a non-VPN is indeed a fantastic idea, and much better than the traditional VPN.  However, something very similar has unfortunately been done in the past.  In fact, I'm currently running a similar setup myself.  I was shown how to do this by my cousin, who is 16 years old, who had implemented everything you described except for the encryption and configuration part of what you described using OpenBSD's PF, which is their Packet Filter program.  I have my implementation and IPtables under Linux since both my client and my router run Linux, and I have the Netfilter kernel module loaded.



The two things your solution cleverly applies, which mine and my cousin's do not, is encryption, which is obviously important if you have sensitive information, and the easy configuration.  Writing PF or IPtables rules by hand is definitely not for the faint of heart.  I know, I've done it.  Of course, if you're using Windows, neither IPtables nor PF are available, so I guess it's unique for those folks.  So is what he's talking about similar to what you were talking about?



STEVE:  Okay.  This is an interesting - this question caught my attention because he describes - he says something very similar has "unfortunately" been done in the past.  As if the fact that I'm doing something similar to what was done before is unfortunate.



LEO:  Like it wasn't completely original or something.



STEVE:  Yes, and that's exactly it.  There was somebody in our newsgroups, when he heard about my idea with the Star Trek Bunnons of reversing...



LEO:  You didn't invent that, you know.



STEVE:  He was disappointed because he realized that I'm so old that I probably did it before he did.



LEO:  Oh.



STEVE:  And I wrote back, and I said, wait a minute, I said, it's not about who did it first.  It's that you had all the fun of being confronted with a problem and coming up with a solution.  No, Leo, I mean, this is something I feel so fundamentally, it's a weird thing, I don't know if I'm strange or there's something that I'm not understanding.  But like I independently invented stateless TCP connections, which I later found were called SYN cookies, and they've been done.  And it's like, I didn't feel at all diminished because I independently invented something really cool.  So what if I wasn't first?  I came up with it.  And like this guy posting in the newsgroup who said, hey, you know, gee, I really thought that that was mine, unique.  Well, it was yours.  You know, if you did it by yourself, you had a problem, you scratched your head, and you came up with a solution, that's the joy.  I mean, that's the benefit, the fun of being out there, being creative, and coming up with solutions.



So I don't feel in any way that it's unfortunate, for example, that the idea of port shifting was done before or isn't unique with me.  I didn't really think it probably was.  It was a problem, and I found a solution.  And so I just sort of want to address, because this did come up in the context before, and it has before, and no doubt as I'm doing this CryptoLink VPN there are things that are going to be absolutely new, but I'm also going to be treading well-trodden territory, doing things other people have done before.  I want to solve the problem myself.  I don't want to take somebody else's code.  I don't want to take somebody else's idea.  I want to scratch my head and say, okay, great, people have done it before.  I'm going to challenge whether theirs is the best way it can possibly be done.  People have done router traversal.  Great.  I haven't done it.  Maybe I'll come up with something better.  Maybe not.  I don't know.



But, I mean, the joy is in doing it.  The reason I'm wanting to tackle this is there are problems I haven't faced before.  And so I just - I don't get that psychology, that sense that, I mean, I understand from an intellectual property standpoint and patents and who came first and who came second.  That's got to be honored, and I respect that.  But the idea of independently solving a problem, that's where I think the value is.  That's where you learn something.  I'm going to learn a lot writing CryptoLink.  I can't wait.  Even if a lot of it's been done before, I don't care.



LEO:  There is that funny thing going around that you have to be first.  I think the Internet really encourages that.  You've got to be the first to do something or say something or post something.  And you're right, you get the pleasure out of doing it, regardless of whether you're first or not.



STEVE:  Yeah, I just don't get that it diminishes what I do in any way that it isn't first.  Hey, it's mine.  So it's been done before.  Okay, that was theirs.  And the guy who came up with reversing English twice, good for him.  I mean, yeah, I did it.  There was no Internet to publish it, and I don't care.  It was just fun for me to do it.



LEO:  I had fun doing it, yeah.



STEVE:  Yeah, I'm glad he came up with the same solution.  Bravo.



LEO:  All right, here's one from Tom Shuman in Minneapolis.  We were talking on an episode some time back about teaching teenagers computing.  Hi, Steve.  Thanks to you and Leo for the program.  I'm a long-time listener and SpinRite user since version 2 - wow - on my spacious 20MB Seagate ST-251.  Oh, I had a few of those.



STEVE:  Yeah.



LEO:  I remember when 20MB was a lot.



STEVE:  It's all you needed, Leo.



LEO:  I used SpinRite to change the sector interleave - oh, I remember doing that - on the drive, so my XT clone in "turbo mode" would approach the full 7.44MHz of the processor.  That's right, there was a default interleave.  But if you wanted to tweak it, you could.



STEVE:  And remember the XT clones?  There was like a compatibility mode where they would run at 4.77, which was the original speed.  But, oh, you could juice them up to 8MHz.  And then it was, like, really fast.



LEO:  I had a machine like that, and it never was stable.



STEVE:  No.



LEO:  It could not handle 7.44.  And, you know, we just had all sorts of stability issues.  7MHz.  My phone does that when it's just thinking, when it's just waiting for me, I mean, it's ridiculous.  Leo has expressed interest in teaching a programming class.  Let me say first I have no vested interest in what I am about to suggest.  Just another idea he might consider.  ISECOM, that's the Institute for Security and Open Methodologies, has a program called "Hacker Highschool."  I like that.



STEVE:  Yeah.



LEO:  It teaches security awareness for teens.  Oh, we're definitely adding that to the curriculum.



STEVE:  Yes.



LEO:  While I don't like the name of the program - hacking is not what it used to be - the program itself is awesome and would be terrific if taught by someone with a background in programming and a background in the history of the industry, a sense about how we got where we are today.  Perhaps the gang at Tech Guy Labs would find the program interesting fodder for a series of videos.  Hmm.  I can't imagine anyone else that could do it better.  Check it out at hackerhighschool.org.  Just a thought.  Keep up the great work.  Thank you, Tom.  What a great suggestion.



STEVE:  Yeah.  I want to say that I looked at it, and it is really nice.  And, I mean, I immediately, you know, high school kids, they would love the idea.  I mean, hacking seems glamorous and immediately hooks them just much more so than bit twiddling would.  And anyway, the site is really nice, hackerhighschool.org.  And so I wanted not only for you, Leo, to run across it, but to also aim our listeners at it because they may well have their own teenagers or know some that might get a kick out of this, too.



LEO:  So it teaches you how to be secure online, basically; is that it?



STEVE:  Yeah.  It's, well, it's just - it's like, yes, security awareness, like what's going on, how does the stuff work.  And, I mean, I can't think of anything more important for teenage kids to get a grip on as they're moving out into the world.  And computers and laptops and cell phones and the Internet is tomorrow's reality.  Only it's today's reality.  But certainly it's going to be with them for their entire lives.



LEO:  Neat.



STEVE:  And apparently not much more secure than it is today.



LEO:  Yeah.  Brad Beyenhof in San Diego, California wants a little more detail on CryptoLink.  He says:  Hi, Steve.  In Episode 200 you read a letter of mine asking about the NAT traversal capabilities of your non-VPN CryptoLink solution.  You mentioned that advanced users will be able to configure port forwarding, but a third party will be available for those who won't or can't do so.  Are you going to be providing this third-party service?  If so, what will be the terms of that service?  I'm of course referring to the possibility of subscription fees and so forth.  If you're not going to provide the third-party service, will you be relying on others to develop their own CryptoLink connection services?  Or will there be a solution for advanced users to offer themselves as that third party using a coordinating service similar to those used by BitTorrent, TOR, and SETI@home?  What's the plan?



STEVE:  I have no idea.



LEO:  Good answer.



STEVE:  I mean, again, I didn't really intend this to feed off of my prior rant about first invention.  But really, I know where my heart is.  My heart is that buying CryptoLink gives you access to everything it is for life, forever.  No subscription fees, no recurring anything, nothing.  I mean, that's really what differentiates it from service-oriented offerings which are very different from the tool.  People in the newsgroups have asked, hey, will there be a per-system fee of some sort?  The answer is no.  That is, an individual who owns it can use it for their own purposes as much as they want, on as many systems as they want, wherever they have a problem that CryptoLink can solve.



I'm hoping to have the most sophisticated and capable NAT traversal system ever created.  I mean, that's one of the reasons I want to do this.  I just don't want to say, oh, I have it.  I want to be able to say mine nails anyone else's NAT traversal that's ever done it before.  And so all kinds of technology will come out of this.  I know that, for example, we will have a web-based NAT router characterization service, much like we have now ShieldsUP! testing your security, the DNS spoofability system that we'll be talking about before long, and Perfect Passwords and other stuff.  There will also be a NAT router characterizer where users will be able to find out exactly how their NATs work because I'm going to have to know that in order to design the technology to traverse them. So there'll be things that fall out from this research which is really going to be fun and interesting and useful.



I imagine that GRC will have to provide that rendezvous service because I think, my plan is, that I'm going to be doing things that have never been done before to make the NAT traversal more robust than anybody else's.  At the same time, I don't like the idea, as I've said, of anyone depending on us.  If GRC was DDoSed, and we were gone, I wouldn't want for people not to have an alternative.  So my intention is that the protocols will be open, that it would be possible for someone else to create such a third-party service.  There are publicly available NAT traversal facilities.  Maybe you could downgrade to one of those if you didn't want to use GRC, or couldn't.



But it's also the case that you don't need to use that at all.  If you were able to map a port through your router, then you would be able to connect to anybody, and anybody would be able to connect to you.  So a lot of this is going to be a journey.  I know it'll be interesting for everyone who wants to participate in the newsgroups while I'm churning out this technology.



LEO:  Great.  But there is going to be some cost if you do a third-party server.  It wouldn't be unreasonable to charge for that.  I don't think anybody would think any the less of you.  That's how you do the NAT traversal is you have a third party that they both connect to?



STEVE:  I would never do that.  I mean, my plan is for the ongoing sales of CryptoLink to provide for the service.  I mean, the fact is, Leo, bandwidth costs nothing these days.  I mean, I'm running servers.  And I would not be, ever, I would never be proxying the data.  That is, for example, the way NAT traversal works in the GotoMyPC case, for example, is they are transiting the data.  Both endpoints connect out to them, and so they're transiting the data.  It's trivial to do that, but it does require that they then be a carrier capable of handling all the bandwidth.  My approach is never to be involved in the data transit.  I just want to introduce the two endpoints to each other and so that somebody looking at the traffic, somebody with a packet capturer can see that GRC or any other rendezvous service is not involved in that traffic.  Thus it follows my TNO, my Trust No One model, of saying we don't want to be involved, so this is provably secure.



LEO:  Moving along, a note from Paul Scott in Las Vegas, Nevada, a quick note about Apple's AirPort Express.  He says:  I love the show, have been listening from day one.  I fell a little behind, and while catching up heard a comment from a listener that he uses AirPort Express as a way of hiding his machine behind a NAT router when he's in a hotel or traveling.  And Steve asked if there is Windows software to configure the AirPort Express.  The answer is yes.  Apple has created an AirPort configuration utility for Windows.  It works just fine, in my experience.  I've used it when I didn't have my MacBook Pro handy to fix someone's Time Machine base station.  Apple in recent years has done a pretty good job creating Windows software and making their OS play nice.  That's great news.  Didn't know that.



STEVE:  Nor did I, so I wanted to make sure our listeners knew because the question did come up when we were talking about it before.  It's like, well, would this work in a Windows-only environment.  And Paul says, yes, absolutely.



LEO:  Finally, our last question, from Amir Katz in Kfar Saba, Israel.  He wonders about TPM, the Trusted Platform Module.  Following up on your answer from Episode 200, how to activate TPM in the BIOS of your system, I wonder whether there are any downsides to doing that.  I do recall your explanation how the DEP - Data Execution Prevention - was introduced in the x86 family, and it used to cause a lot of applications to crash as they were trying to execute code on the stack or heap.  And DEP, of course, prevents that.  So I wonder if TPM might have similar side effects, breaking some applications?  If there are no issues, why don't BIOS vendors or the PC vendors turn it on by default?  Also, apart from full-disk encryption, what other benefits do you get by enabling it?  Thanks, Amir.



STEVE:  That's a great question.  The answer is, do you remember how much trouble Intel got in...



LEO:  Yes, yes.  I know where you're going.



STEVE:  Uh-huh.



LEO:  They announced processor IDs with the Pentium.



STEVE:  Yes, yes.  The idea that every single chip would have a unique serial number.  And it didn't take the privacy people half a millisecond to say, whoa, wait a minute.  What?  And in fact I remember going into BIOSes that had it turned on by default and turning it off.  It's like, thank you, but I would prefer not to have, for whatever reason, it just seems like a bad idea for my Pentium to have a unique serial number which is available to the outside.  And so the good news was, you were able to disable that feature, and now it's gone completely because it was just a bad idea.



Well, the Trusted Platform Module is very much the same.  There's definitely a privacy-related concern because it has the ability, I mean, part of its function is to be an anchor for identity of the machine.  I would argue that its benefits outweigh the liabilities.  But the motherboard BIOS manufacturers weren't going to have this happen to them again.  So they said, okay, just so that no one accuses us of having a serializing crypto unique machine of any kind on every single motherboard, we're going to just have it off by default.  If the user needs those services, they can turn it on.



And to answer Amir's second question, apart from full-disk encryption what other benefits do you get, well, it is the identity enclosure for your system.  There's actually a lot more that the TPM is doing than just providing sort of a vault for security information.  During the boot process it's actually looking at the image of the code running during booting and performing hashes of it to make sure that step-by-step during the boot process nothing bad has happened.  There's no malicious code that has managed to stick itself into the boot process.  So it's very useful.



The idea is that, if you start from a known secure condition, that is, with the machine off, it's hard to get much more secure than that, and if you validate every stage of the booting process using secure validation technology, then once the OS gets booted, it can be sure that nothing malicious has happened before it got in control.  And the Trusted Platform Module makes that, I mean, that whole process possible.  So it's very useful.  And of course it's also useful for providing secure authentication.  If you're going to use a fingerprint reader, like at boot time, then it's always tied to a TPM chip.  So you enable that, then you enable your fingerprint reader, and it's very possible then to swipe your fingerprint and to have that verified by the BIOS and have that provide a password to the hard drive that unlocks the physical hard drive that makes it possible to boot.  And absent both the fingerprint swipe and the TPM, nothing can access the data on your hard drive.



So there's a lot of good stuff there.  Not only hard drive encryption, but also authentication.  And as we learned in Windows 7, they will be - and I'm really excited about this in Windows 7 - they will be making a public API that would, for example, allow applications running on Windows 7 to say,  hey, before we do this, please reauthenticate yourself.  That is, for example, it's a feature that I will definitely take advantage of in CryptoLink where you could require that the server ask a client to reverify that they're really themselves, from a human factor standpoint, by wiping their finger across a fingerprint reader.  Right now there's no way to do that because there's no common API for the fingerprint reader.  But that's something that Microsoft is going to be providing in Windows 7, which will be very cool.  And again, it's all based on the TPM.



LEO:  Yeah, I mean, I think it's - I remember a lot of controversy when TPM was first proposed, and people like Cory Doctorow were freaking out because one of the possible uses would be to expire documents, that you could send a Word document that would be expired after a certain period of time, I mean, there were all sorts of issues.



STEVE:  Right, well, because it's nonspoofable.  It is deliberately a nonspoofable technology.  So, sure, somebody could abuse the power that it gives them.  But, you know, it's like, well, okay.  They could also, I mean, there's all other kinds of ways they could do that, too.



LEO:  And as a result I think manufacturers opted to, well, let's just avoid the whole thing and default to off.  That way we don't have to defend it.  And if somebody needs it or wants it and in full knowledge of the risks and benefits turns it on, all the better.



STEVE:  Right.



LEO:  Steve, once again, a wonderful time.  You get your questions in to Steve by going to GRC.com, that's his website.  And if you go to GRC.com/feedback, that feedback form is right there.  You can ask questions there.  You can also get the 16KB versions for those of you who are bandwidth-challenged.  We've got show notes, a full transcription by Elaine, a lot of detail.  And of course SpinRite's there, the world's best, finest, one and only hard drive maintenance and recovery utility and all those great free programs.



STEVE:  And we even have a valid security certificate, Leo.



LEO:  And a shiny new security certificate.  That's GRC, Gibson Research Corporation, GRC.com.  And that tells you how long Steve's been doing this.  He's got a three-letter domain name, which are as rare as hens' teeth.  Steve, great to talk to you, as always.  I am in China as this airs.  And so, let's see, I think our next live record date will be...



STEVE:  Two weeks from now.



LEO:  Two weeks from now.  It'll be...



STEVE:  We're going to do the mega security update podcast.  It would normally be a Q&A.  But we will have been not recording live at that point for three weeks.



LEO:  There'll be lots to talk about.



STEVE:  Lord knows what will have happened.  I hope the Internet is still here, computers are still booting.  And then we'll let our listeners know what has happened in the three weeks that you've been floating around Asia.



LEO:  You bet.  You can watch us do this live Wednesdays, again, starting up again July 22nd, Wednesdays at, let's see, we start at 2:00 p.m. Eastern - that's 11:00 a.m. Pacific or 1800 UTC - at live.twit.tv.  Or just listen to the podcast when it's available every Thursday on iTunes and the Zune Marketplace and everywhere.



STEVE:  Every Thursday like clockwork.



LEO:  Like clockwork, thanks to Tony and now Erik, who's also working on the show.  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#205

DATE:		July 16, 2009

TITLE:		Lempel & Ziv

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-205.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo examine the operation of one of the most prevalent computer algorithm inventions in history: Lempel-Ziv data compression.  Variations of this invention form the foundation of all modern data compression technologies.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 205 for July 16, 2009:  Lempel-Ziv.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



Get ready, it's time for Security Now!, the show that covers your privacy, your security, protects you online.  Our protector, of course, the great Steve Gibson of the Gibson Research Corp., GRC.com, the inventor of SpinRite, the discoverer of spyware, and a lover of great cabernet.  What is it, cabernets?



STEVE GIBSON:  Cabernet, yup.  Red wine.  Good for you, too.



LEO:  It is good for you.



STEVE:  Yup.



LEO:  Do you like dark chocolate, as well?



STEVE:  Huh?



LEO:  Do you like dark chocolate, as well?



STEVE:  Dark chocolate is very good for you, too.



LEO:  I know.  See, if I could live on red wine and dark chocolate, I think - hey, Steve.  Good to see you again.



STEVE:  Great to be back with you, Leo.  You are, as our listeners are hearing this, you're floating somewhere out in Asia.



LEO:  Let me see.  I could check the date.  You know, I am the opposite of a private person, as you probably have gathered.  And I have posted my entire itinerary, including everything you'd want to know except maybe the phone number to call.



STEVE:  So this is airing on July 16, Episode 205.



LEO:  July 16.  Oh, that'll be a sad day.  I'll only have a day left on my cruise.  We will be in the China Sea, sailing back to China for our departure.  So when you're listening to this, think of me crying over the railing.



STEVE:  Well, we are recording this because I refuse to miss any weeks.  I don't want to leave our listeners stranded.  We're recording this several weeks in advance.  So we don't have any security news.  However, we're not going to miss any news.  The episode after this one, when you're back, will be the mega security news update, where we'll be catching up on three weeks of everything that went on.  And I have a feeling there'll be enough that will have happened that we can do a whole episode just on everything that happened while you were out traveling.



LEO:  Let's look on the bright side.  Maybe I'll come back, and nothing will have happened.



STEVE:  [Laughing]



LEO:  There'll be no security - yeah, we laugh.  Not possible.  Not possible.



STEVE:  No.  Not these days.



LEO:  Not these days.  So what are we going to do today?



STEVE:  We're going to do the second of our two episodes interestingly enough named after people, because it's about sort of a fundamental concept or technology or basically computer science breakthrough that is named after the people who invented it.  In this case, the initials are "L" and "Z," for Lempel & Ziv, who were two researchers, I think they were at IBM at the time.  I remember reading their original patent.  And I think it was assigned to IBM, although I didn't dig back prior to the show and verify that, because the history is tangled with patents and other people doing modifications to their concept.  But basically this is the way data compression is done.  It was done in a whole bunch of other ways that were less good until 1977, when Lempel & Ziv told the world how to do this.



LEO:  Now, I know a little bit about this because when I was a younger fellow and still could program my way out of a paper bag, I wrote a program called Mac Arc.  Remember before ZIP there was ARC?



STEVE:  Yes.



LEO:  And there was no ARC for the Mac.  This was, like, '84 or '85 when the Mac had just come out.  And we - I had a BBS, and we wanted to be able to compress files for the Mac.  And there was no real easy way to do this.  So I took the source code for ARC on the PC, which was I guess open.  We didn't know about open source at the time, but the source code was available, including the Lempel-Ziv algorithms - I think it was table-based, as I remember - and ported it over to the Macintosh.  I never got to the compression part, just the decompression.  But even that was better than nothing.  So I remember doing this, writing this algorithm out.  It's clever.



STEVE:  Well, it's way cool.  And so we're going to take our listeners through a little bit of sort of starting at how you might think about compression.  And essentially we'll go through various stages of different types of compression, up until these guys said, okay, here's how it's done.  And boy, were they right.



Since we don't have any security news or errata, I have nothing but sort of a fun SpinRite story to share.  This was actually a posting in the GRC newsgroups that I ran across.  And it's like, oh, there's someone to talk about SpinRite.  Jacob Janzen is the person who wrote this.  And he said, "SpinRite has saved my bacon," as he put it, "three times now, and also saved my mother's business from losing all her data, and saved us $1,500 in recovery costs.  He says, "Of course I have purchased a license, which is kind of a funny story you might enjoy.



"So four years ago I was playing around with Partition Magic, and it screwed up halfway through a partition adjustment.  I was floored.  All of my source code," so I guess this guy's a programmer, "all of my source code was on the machine, and I hadn't backed up in a week.  Which is a ton of code to lose.  So I ran to my brother's house and consulted him. We determined that we needed an adapter to plug the laptop drive into his PC so we could talk to it.  And his first suggestion was, 'Buy SpinRite,' which I did on the spot.



"The funny thing is, when we mounted the drive, we decided to boot into Windows first, to see if we could see any data and copy it right away.  And bloody Windows fixed the broken partitioning.  I then ran SpinRite anyway as a precaution, and have been using it routinely ever since.  And as mentioned above, it has saved me personally three times."  He has in parentheses, "(Those darn laptop drives)," he says, "and saved my mother's business, too.  She now has Jungle Disk backing up all her data nightly.



"Oh, and a friend of mine in the Canadian Armed Forces used SpinRite to save a hard disk drive in the field, albeit on training, no lifesaving events, although they did manage to save face by having access to the navigation.  So SpinRite has earned me a case of beer."  He said, "My buddy balked at buying it, but after it saved his bacon, he bought me a case of beer in thanks.  $1,500 in savings for my mom and relief from endless suffering via restored hard disk drives."



LEO:  Well, I hope that not only did he buy a case of beer, he bought a copy of SpinRite.



STEVE:  Oh, I think he did that first.  Yeah, he said his buddy balked at having to buy one.



LEO:  Right.



STEVE:  But when it worked for him and saved him, then he was glad.



LEO:  Yeah.  Yeah.  There you go.  SpinRite is a must-have.  If you have disk drives, you kind of have to have SpinRite.  We use it all the time around here, and it's very handy.



STEVE:  It's fun to have Colleen as a believer, having seen, you know, she saw it first-hand, so...



LEO:  We won her over, we really did.



STEVE:  That was very cool.



LEO:  All right.  We get to Mr. Lempel and Mr. Ziv in just a little bit, the creators of the most amazing compression algorithm ever.  There have been successors; right?  Are they all based on the same notion?



STEVE:  They're all based on this concept.  I mean, very much like we talked about two weeks ago with Boyer & Moore, where once this, like, this revelation - in that case it was searching from the end of the pattern forward - once you get that it's like, oh, I'm never going to do it any other way.  Well, similarly, Lempel & Ziv have a key concept which, as you said, many people have extended in different ways because theirs is so fundamental that there's all kinds of things, different things you can do with it, different ways, like twists on, you know, variations on the theme, but the theme has survived.  And basically, well, not even basically, all compression today is done with Lempel & Ziv at its core.



LEO:  Isn't that neat.



STEVE:  And we're going to explain what that is.



LEO:  All right, now, let's talk about Mr. Lempel and Mr. Ziv.



STEVE:  Well, we'll wind back first and talk about the things, the approaches that led up to it.  First of all, all of this is data compression.  And this occurred to me, not only because it's another sort of fundamental core piece of computer science, but of course a couple weeks ago we were talking about SecureZIP, ZIP and ARC, and the things that PKWARE does, and basically compression everywhere.  When you right-click in Windows and say you want to compress a file, back in the DOS days there was - remember the company Stacker?



LEO:  Oh, yeah, Stacker.



STEVE:  Yeah, Stacker was doing partition compression.  And they had LZS was their technique.  So obviously data compression has been around for a long time and has been interesting to people.  And, I mean, the audio that we're doing, now, we're doing, when we compress with MP3, we're not doing what's called "lossless" compression.  Similarly, when you compress an image with JPEG, both MP3 audio compression and JPEG image compression are lossy compression, meaning that when you decompress it, you do not get back exactly what you put in.  You get back something that's good enough.  The picture looks good enough, not too blurry.  The audio sounds to your ear indistinguishably different from what went in, yet it was much smaller while it was compressed.



So there's two classes of compression, lossy compression and lossless compression.  With lossless compression you get back precisely what you put in.  And that's the type of compression we're talking about.  That's what LZ compression does, and many other types of compression that led up to it.



LEO:  It makes sense.  It makes sense because an analog thing like sound or a picture or video, you can degrade them a little bit.  But you can't degrade binary code.  You can't take your word processing document and take out the E's.  It's not going to work.



STEVE:  Right.



LEO:  So there's some things you have to compress losslessly.



STEVE:  Yes.  And we've also talked about, in the context of security, we've talked about the need to compress something before you encrypt it.  Because, as we know, good encryption turns regular plaintext into pseudorandom noise.  Well...



LEO:  Right.  Which is not very well compressed.



STEVE:  Well, actually pseudorandom noise, one of the really interesting tests for the quality of pseudorandom data, that is to say, how random is it, is how compressible it is.  Because truly random data won't compress at all.  You can't compress it.  You can't find anything meaningfully redundant in the data.  And that's the key.  In every case the lossless compression where we're talking about getting back exactly what you originally gave the compressor, it involves redundancy.  It involves something that is repeating.



And so, for example, the simplest, most sort of obvious compression is known as, it's very simple, it's known as run-length compression.  So that was, for example, what faxes used in the early days.  If you were feeding a fax in, and there was a line of black that went all the way across the page, instead of sending individual bytes of black code, for example, the sender would say, wait a minute.  It would sort of - it would store up what was coming so that it could look ahead in its buffer before it sent it out.  And it would see a whole scan line across the fax of black pixels.  And so instead it would have a code that said I'm going to send you a count instead of the actual data.  And then it would send a count, and then the data that's to be repeated that many times.



Well, so that's just like three symbols - an escape character, a count, and then what it is you want to send, instead of, you know, who knows how many hundred individual pixels across the page.  So, and then the same is true with white space.  Faxes, for example, have lots of white space.  So the scanner in the fax would scan ahead, be able to look sort of into the future to see how much, you know, how many scan lines, how many individual pixels of white it's going to encounter before the first pixel of black.  And it would just - it would compress that by saying, okay, here comes 3,000 white pixels.  So there you go.  So it would send that across the line.



At the other end, the receiver would be receiving this and see the escape character, meaning, oh, instead of actual data, I'm about to get a count and then the data.  And it would say, oh, here comes 3,000 whites.  Well, it would expand that as the fax is coming out of the receiving end, back into a whole bunch of white space before the next line of text starts.  So run-length compression is very effective in some contexts, except it requires obviously lots of the same thing in a single run.  And if you don't have that, for example, if you just had the word "the space the space the space the space," well, you're got t-h-e space t-h-e space t-h-e.  So no character is repeated.  Yet it's obvious to us looking at it that there's a lot of redundancy there.



So the next approach that was taken, sort of in sort of fundamental compression technology, was developed by an MIT student back in 1952, a guy named David Huffman.  What he recognized was that different - that one way to represent data in a smaller space was to represent those things that occur most often with a shorter code, and the things that occur less often with a longer code.  Well, my favorite example of this actually way predates David's work.  What he did, what Huffman did, was come up with a mathematically precise, scientific way of taking any alphabet with known frequency characteristics and developing an optimum encoding for it.  But somebody back in the 1840s had a similar problem.  His name was Samuel Morse.



LEO:  Oh, Mr. Dit Dit Dit Dot Dot Dot Dash Dash Dash.



STEVE:  Exactly.  The Morse code was designed - so Samuel Morse comes up with this way of having a telegraph key and a wire heading out West somewhere, and a little clanker at the other end, an electromagnet with an armature that would - and all he could do was press the key and go clankety-clank-clank at the other end.  So he says, okay, I've got that now.  How do I send English through this thing?  And what he realized was he needs to encode English in an efficient way.  So he decides, okay, I can send short events and long events, which are called dots and dashes.  And so I'm going to have to do groups of those to represent characters, and he's not going to have highly trained people at each end, so it's got to be basically a system where someone can look at a page, it was called a "telegram" I guess back then, and by just sight-reading it, turn this into some impulses which go over the wire that somebody at the other end can be transcribing, very much like Elaine does, what comes out the other end.



So he said, okay, well, I'd like the characters in English that occur the most often, they should be the shortest.  So not surprisingly, "E" is a dot.  And "T," which actually occurs more often in English than most people would think, is a dash.  Just, you know, "E" is one dot; "T" is one dash.  "A," that occurs often, but not as often as "E," it's dot-dash.



LEO:  Do you know how he figured out the frequencies of English letters?



STEVE:  No.



LEO:  Kind of an interesting footnote to this.



STEVE:  Really, how?



LEO:  Well, if you think about it, in those days, newspapers were typeset.  And they made individual characters, cold type characters, for each letter in the newspaper.



STEVE:  Nice.



LEO:  So they analyzed the bins.  They actually got it a little bit wrong.



STEVE:  See how many E's you had to have in order to typeset the typical page.



LEO:  Exactly.  Isn't that clever?



STEVE:  Very nice.  Very nice.  So "A" is dot-dash.  "N" is dash-dot.  "I" is dot-dot.  "M" is dash-dash.  And to give you an example, the other end of the spectrum, "Q" is dash-dash-dot-dash.  So a long pattern for the things that don't occur very often, and a shorter pattern for the things that do occur the most often.



So what Huffman came up with was a way that you could take a block of text and count the number of each of the different characters and build an efficient, like, the most efficient, the provably most efficient encoding such that those characters that occur the most often will have the shortest representation.



And here we're talking bits.  So, like, "E" might be one zero, and "T" might be one one.  And then the next longest one might be zero one zero and so forth.  So the idea being that you break this byte orientation.  Notice that normal ASCII, for example, where we use an alphabet of just typically alphabetic characters and numbers, we're storing that in a byte because it's convenient to do with a computer that moves things around in eight-bit lumps, which we've been using for, you know, decades now.  But that's inherently inefficient because a byte gives us, as we know, 256 possible combinations.  Yet if we just have a text document, we're only using typically the alphabet is 26 times two for upper and lowercase, plus numbers and symbols, many, many fewer than 256.  So bytes, eight-bit characters, are an inefficient way of representing text.



What simple Huffman coding does, when it's applied, is to essentially re-encode this fixed-length eight bits per character in a variable length token, much as Morse code uses variable length dots and dash strings in order to represent a message, taking advantage of the fact that the shorter ones represent symbols that occur the most often.  So Huffman coding was another step forward.



And then time went by.  People were using computers.  And compression, the need to compress things efficiently was continuing, it continued to be important, certainly as it is for us today.  We're all using ZIP and Gzip and GIF images and PNG images, all which are lossless compression based.  So the next innovation was the move towards dictionaries.  The idea was that, if you had a dictionary, and each end had this dictionary, instead of sending the individual symbols through or storing the individual symbols, you could instead store pointers into the dictionary.  So if you had, for example, a dictionary of English, and it made sense based on what it was that you were trying to compress, you could, instead of sending the individual symbols, you could just send the location in the dictionary of the word that you wanted.



So now a pointer represents a whole word instead of all the individual characters being sent.  And if you think about it, I mean, even though there's lots of words, as soon as you have four characters, well, if the characters started off being eight-bit bytes, you've got four of those, so that's 32 bits that you've consumed using four byte-size characters.  Well, we know that 32 bits gives us four billion possible combinations, which means that with those same four characters, those four bytes, you could point to any of four billion words.  That's a lot of words.  And you could also, of course, always have, like, some extra code that's reserved, saying, okay, this isn't in the dictionary, so we're going to give this to you a character at a time for those exceptions.



And so that was a nice approach.  That was an effective approach for some classes of use.  The problem is that you would have to have dictionaries that matched.  You'd have to - the decompressor or the person at the receiving end would have to have a dictionary.  Otherwise all they've got is gibberish.  So there developed this notion of a dynamic dictionary where you would scan through the content that you wanted to compress or that you wanted to send, and on the fly you would build a dictionary.  That's sort of what Huffman was doing with his symbols.  There he's encoding - he's looking at the frequency distribution of symbols and encoding each symbol in the minimum space possible.



In dictionary compression you're taking larger chunks, larger pieces of source, like words, for example, using spaces as the delimiting boundaries, and you're saying, okay, the word "the" occurs this many times.  The word "apostrophe" happened once.  And so you preprocess the content that you want to compress or send, look at the whole thing, perform an analysis, and create a dictionary just for that single use, that is, the dictionary would be optimal for this particular content that you want to send.



The problem is that, while that's a nice approach, it means that you have to, in order for the receiver to understand what you send, that is, the pointers into this custom dictionary, you've got to send the dictionary.  So to transmit this message you send the dictionary, then all the pointers.  Or, if you were compressing something statically, the whole front, the whole, like, the header of what you were compressing would just be the dictionary.  And then what would follow would be pointers back into the dictionary.



So that was, you know, another step forward.  The brilliance of what Lempel & Ziv came up with in 1977 won them a patent and, I mean, as we said before, this is an approach which has been used ever since in variations.  So here's what they realized.  They came up with a way of either statically compressing, or they actually described it in terms of a transmission channel.  And I've used that example a couple times here with Morse and the telegraph, or with a fax machine where you've got a sender and a receiver, and some transmission channel, and you're wanting to minimize the bandwidth you need, minimize the number of characters you send, which is to say you want to compress what you're sending through the channel so that it can be decompressed at the other end to reconstitute the original text.



Now, really, compressing a file is the same way, where the channel is just your hard drive.  So you compress it to this static file which at some point later you're going to decompress.  So the idea of compressing a file statically and sending it through a channel, they're equivalent for our purposes.  So what Lempel & Ziv realized was there was a way that they could sort of use this concept of a dynamic dictionary, and at the same time avoid having to ever send it.  Which is, like, what?  How can you possibly avoid sending a dynamic dictionary, if that's what you're going to use?



Well, they came up with a way of incrementally constructing the dictionary on the fly.  And the idea is that both the sender and the receiver start with an empty dictionary.  We can think of it as a buffer or a dictionary which is empty.  So the sender looks to see whether the character they want to send is in the dictionary.  Well, since it's empty, it's not.  So they send the character.  Then, and the receiver...



LEO:  Oh, I get what's going on.



STEVE:  Uh-huh.



LEO:  They're going to build it.



STEVE:  They build it.  So they put the character that's not there in the dictionary, and they send it.  The receiver sees that they've received a character, so they put it in the dictionary.  So then they come to the next character.  Is this in the dictionary?  If not, stick it in the dictionary and send it.  And the receiver receives the character, puts it in the dictionary.  So what you're going to do is, you end up essentially building a linear buffer of everything you've sent before, until at some point, say that like you've sent the word "the" in the past, in the recent past, and you have the ability also to look ahead.  So you get a "T," and you're able to look, because you know what it is you're sending, you see a "T," followed by an "H" and an "E" and a space.  And looking in the dictionary you realize, hey, we sent that before.  We've already sent T-H-E space.  And so you match as much of what you're about to be sending as what you've already sent to find the longest string that exists in the dictionary, and instead you send a pointer to it.  So you come up with a compact way of saying, here in the dictionary for this many characters is what I mean.  And that you send...



LEO:  Clever.



STEVE:  ...instead of the T-H-E space.  The receiver, because they've been essentially building a synchronized dictionary - and that's what's so cool is that, by playing by the same rules, at the other end of this channel, whether it's a real-time communications channel - and, by the way, like the V.42 modem spec used Lempel-Ziv compression.  That was how we had compression in the modems we were using before we finally stopped using modems.  Of course people still do today.  And so you've got it, literally are doing this on the fly.  And so whether you do it in real-time in a communications channel or storing a fie, when you use PKZIP, when you use ZIP, or Deflate in UNIX, Deflate is the same thing, it is this Lempel-Ziv technology where the receiver then receives this little token which says look here in your buffer for these many characters and expand that.



And so that's the way this works.  The beauty of this also is that the buffer is of a fixed length. So at some point you start losing the stuff that's really old.  And it's interesting how well this works because, if you think about writing, like, a long document in English, the subject of what you're writing about sort of - there's like a locality.  You have a couple paragraphs talking about this.  Then you start talking about that.  And you're talking about something else.  And so there's local context which is sort of relevant to the recency of the text that's just come before.



So this Lempel-Ziv approach of having sort of a sliding buffer of the past, the older stuff that may no longer, like there's less chance of redundancy, it sort of leaves the end of the buffer, and new stuff is coming in on the front that you've more recently sent.  So the chances of talking about what you're talking about redundantly is much higher than talking about something that, you know, you were referring to a few pages ago.  So the fact that that sort of left the history buffer, sort of it dynamically adjusts in a really elegant way.



And so that's the fundamental concept, which is just - it's just beautiful because the sender and the receiver, or the compressor and the decompressor, they build, they sort of dynamically build this dynamic dictionary.  And the more redundancy you have, the greater chance of finding a match that's in the dictionary, so you can just send pointers to the other guy's dictionary, which you know is the same as yours because they've been building it as you have.  It's just beautiful.



LEO:  Yeah.  Very slick.  Very elegant.



STEVE:  And then all these variations.  They published a paper in '77, their first approach.  They called it "A Universal Algorithm for Sequential Data Compression."  And a year later - and that was called LZ77, which is the date of their paper.  Then LZ78 a year later.  They did another paper called "Compression of Individual Sequences via Variable Rate Coding."  And so they began to get fancier with the way you encode these positions and lengths in the dictionary.



And essentially everybody who's come afterwards has come up with various twists on that.  You know, this LZW stood for Lempel-Ziv-Welch.  A guy named Terry Welch in '84, so, what, six years later, produced a paper, a technique for a high-performance data compression, where he referred to the Lempel-Ziv approach, but he said I've come up with a different way.  I'm going to - the Lempel-Ziv approach, you still needed to send characters across the line because you started with empty dictionaries.



So Welch said, wait a minute, let's preload the dictionaries with the whole set of symbols so we'll never have to send a character.  We can always only send pointers.  Because we know if we put the whole character set in each dictionary, the sender and the receiver, to start with, then we know that all the characters we could ever encounter will be there somewhere.  And so it's that kind of variations on what Lempel & Ziv did that people have come up with.  But fundamentally the concept was something that would dynamically adapt where the sender and receiver or the compressor and decompressor were able to follow rules such that the symbols, the pointers that they were sending to refer to entries in the dictionary would always be synchronized, even though the dictionary was being built on the fly.



LEO:  Neato.



STEVE:  And of course it's also been a patent mess.



LEO:  Yeah.  Let's talk about that.  So did Unisys own the patent?  Did they work for Unisys?



STEVE:  I think they were with Sperry at some point.



LEO:  Sperry Univac, which became Unisys.



STEVE:  Exactly.  And so they licensed this to Sperry that became Unisys.  And without really knowing any better, CompuServe, remember the old bulletin - the big commercial bulletin board system, CompuServe...



LEO:  Are they gone?  I guess they are.



STEVE:  Oh, yeah.



LEO:  H&R Block owns them.



STEVE:  Right, right.



LEO:  I guess they're gone.



STEVE:  Which was strange.  It was like, okay, well...



LEO:  Well, you know what it was, it was a timeshare that had extra time.  And so they said, well, let's try letting other people use it, pay to use it.



STEVE:  And I think in fact - I think they were running on CDC Systems because...



LEO:  Oh, wow.  I think you're right.



STEVE:  ...the userID that CompuServe gave people...



LEO:  75106,3135.



STEVE:  Exactly.



LEO:  I happen to remember that.



STEVE:  I think those were CDC usernames...



LEO:  Oh, that explains it.



STEVE:  Like, log-on approach.



LEO:  How ridiculous was that?



STEVE:  And that's what was, like, surfaced as your userID.  Well, they did the GIF image format, or GIF, depending upon who you talk to, G-I-F, which was a lossless image compression.  And they based it on Terry Welch's LZW compression, not knowing that it was patent encumbered.  And this all got very popular.  Years went by.  And then after the fact, historically, Unisys said, you know, it just occurred to us we have a patent on everyone's GIF images, I mean, on the technology to compress and decompress.  And the way patents work is, even if you didn't write the software, if you've got the ability to display a GIF image, you've got the algorithm in your machine.  And every time you display a GIF image, you're violating the patent unless you have a license to do that.  And so...



LEO:  There was a complete freakout on the Internet over this.



STEVE:  Oh, people, oh, I mean, there was this righteous indignation, and people were - they were talking about burning all GIFs and, I mean, really upset that Unisys was choosing to assert their patent rights.  Although you could argue they had the full right to do so.



LEO:  Sure they did.  It was CompuServe's mistake.



STEVE:  Yes, exactly.  And then of course what happened was the PNG format...



LEO:  Portable Network Graphics, I think.



STEVE:  Yes, exactly.  And it was deliberately not patent encumbered.  They used a different variation on compression that didn't stomp on the Welch patent, the LZW patent.  Probably by that time Lempel & Ziv's had expired.  Because I remember that their patent was expiring a lot sooner.  And even LZW did expire in the middle of June.  In 2003 June LZW became - went into the public domain.  Because that's one of the nice things about patents is they're limited to 17 years.  And after 17 years there's been full documentation of the technology published in the patent, which then becomes completely free for anyone to use.



LEO:  Really interesting stuff.  I love the algorithm stuff.  And of course this time it ties very closely into computer history.



STEVE:  Yeah.



LEO:  I mean, it really - this one made a huge difference, and everybody knew about it.  Steve, you're the best.  If you want to get more Steve, there's lots of it at GRC.com.  His software, of course, SpinRite, the world's best hard drive maintenance and recovery utility.  And he also publishes a bunch of free software you can get at GRC.com.  And also services like ShieldsUP! where you can test your router.  You'll find 16KB versions of our show there, as well as complete text transcripts, searchable text transcripts at GRC.com.  And next week's a Q&A segment, so you might want to get to GRC.com/feedback if you've got any questions or comments or suggestions, and we incorporate those into the show, every other show.



Steve, I will see you next week.  We'll be back live recording the show on Wednesdays:  11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC.  So you can watch at live.twit.tv, if you'd like to see us do it live.  But you can always listen.  These shows are available on iTunes, on the Zune Marketplace, everywhere podcasts are available, absolutely free.



STEVE:  And we will have jumped from July 1st, when we're recording this, Leo, all the way to the 22nd, when you're back from your trip.  And we'll pick up from there.



LEO:  See you in three weeks.



STEVE:  Thanks.



LEO:  Or next week [laughter].



STEVE:  Exactly.



LEO:  Depending on how you're enjoying this show.  Thanks, everybody.  We'll see you next time on Security Now!.



STEVE:  Bye bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#206

DATE:		July 23, 2009

TITLE:		Mega Security News Update

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-206.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  A LOT of security news transpired during the three previous weeks since Steve and Leo last recorded live.  So instead of the regularly scheduled Q&A episode (which is moved to next week), today they catch up with this week's "mega security news update."



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 206 for July 23, 2009:  Security News Updates.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



I've only been gone for two weeks, and I can't talk anymore.  Hello, Steve Gibson.  It's Security Now! time.



STEVE GIBSON:  Yo, Leo.  Actually it's been three weeks, hasn't it?  Because I had a 21-day vacation.  So I would think you did, too.  Or I guess you got back before this.



LEO:  I had to be here on Sunday and do the radio show and TWiT.  But it's, you know, two and a half.  I don't know what it is.  But anyway, it's good to be back.  Although maybe you can explain this to me.  I'm going to have to find somebody, Kiki or Maxwell or you or somebody to explain this, why it is that jetlag is so bad when you're going west to east, and so mild when you're going east to west.



STEVE:  I do not know.  Not having experienced much of it myself.  When I was coming to you to do the shows in Toronto, I was back the same day or the next day.



LEO:  Yeah, you didn't have time.



STEVE:  But you're right.  My solution has always been just to sleep a lot.  And when you finally wake up, you're like, oh, okay, I'm here now.



LEO:  Sleeping doesn't help.  You know, I couldn't get to sleep until 4:00 in the morning this morning.  I'm just lying awake like this, [humming].  I mean, I'm in bed.



STEVE:  Maybe cabernet is my secret.  Because I always mix in some - I mix in some cabernet, and that really seems to solve the whole jetlag problem.



LEO:  [Singing] Cabernet is what I need.  Dr. Mom says she's going to help me.  She says, "Call me later, I'll help you."



STEVE:  Okay.



LEO:  I've tried, like, the melatonin.  You take the melatonin.  I've tried...



STEVE:  Well, so you're still back in readjusting mode.



LEO:  It took me two weeks last year when I came from Australia.  This is roughly the same.  It's...



STEVE:  Wow.



LEO:  Yeah, it's - I'm expecting two weeks of kind of waking hell.  And, you know, I do, you know, I stare into the sun, and I go outside and walk with the bright sun because you're supposed to tell your body - somebody told me if you take your shoes off, your feet somehow - that can't be right.  I think I should go outside naked.



STEVE:  There was some movie where someone gave someone else advice, I think Richard Gere, for some reason I picture him.



LEO:  Yeah.



STEVE:  Something about taking your shoes off and curling your toes on the carpet or something.



LEO:  Yes, yes.  That's what I've heard.  But that makes absolutely no sense.



STEVE:  None at all, no.



LEO:  That's like saying pinch your arm flab, and that will fix everything.  That makes no sense.  Steve, how are you?  Has it been - now, for those who don't know, Steve is adamant about this, will not miss an episode.  So we prerecorded the last - the last three episodes?  Something like that.



STEVE:  Yeah, we double-recorded the two prior weeks before your departure so that we would have two extra ones to fill in while you were gone.  And it worked.  And here we are back.  And we do have a bunch of catch-up to do because we haven't been live recording.  In fact, this week is the "mega security news update" episode of Security Now! where we're going to talk about everything that's happened while you were off cruising around in Asia, and I had my two weeks off from recording.  And then since this would normally be a Q&A, and we have also not done any Q&A for a long time live because we haven't been able to, the next two weeks are going to be Q&A episodes, which will finish off our fourth year.



LEO:  Wow.



STEVE:  Of Security Now!.



LEO:  Fourth?  Wait a minute, no.  Beginning our fourth.  Finishing?



STEVE:  No, no, no.  No, no, no.



LEO:  We've done four years?  I guess we have.



STEVE:  This is Episode 206.  So we'll do 207 and 208 in the next two weeks.



LEO:  That's four years.



STEVE:  And that's four times 52, which is 208.  So, yeah, at the end of our fourth year, starting into year five.



LEO:  [Laughing]



STEVE:  Yay.



LEO:  Well, congratulations.  And early happy anniversary.  I did, I was, when I was in China I wasn't completely in touch with the news.  But I was paying attention, looking for security updates and flaws.  And it seems like there were a few things that happened.



STEVE:  Oh, there's lots of things going on.



LEO:  While I was gone.



STEVE:  Before we get into that, I had a couple - I had just one little non-security note.  I know this is of interest to you.  It certainly was for me.  The Economist is now available on the Kindle.



LEO:  Yeah.  I saw that before I left.  I thought that's great news, yeah.



STEVE:  The Economist magazine.  And Barnes & Noble had a big news announcement a couple days ago.  They formally announced they're going to get into the eBook business and compete with Amazon and the Kindle.  There's an interesting technology that was shown at a recent demo conference.  The company is called Plastic Logic.  And they've got a competing technology.  I've not looked at what the technology is.  I did check out the eInk technology that Amazon is using.  But this literally, they've got a flexible plastic sheet which displays monochrome images.  And they've got a reader.  It also - it includes a touchscreen.  So their UI is touch-based.  They don't have physical controls.  And apparently Barnes & Noble will be - I don't know if they're going to be OEMing it, or if they'll be tied into the Plastic Logic storefront.  Because the Plastic Logic reader has - I guess the Plastic Logic folks are doing some sort of an eBook system themselves.  So Barnes & Noble apparently will have some sort of arrangement with them.



But that was the announcement, was that Kindle will have potentially a major competitor that also has a brick-and-mortar interface to the public, not just an online, web-based interface.  So, I mean, that could help a lot of people who want to go see one of these things rather than just ordering it blind and hoping they like it when it arrives.



LEO:  Do you think it'll be better than the Kindle screen?



STEVE:  It looks pretty much the same to me.



LEO:  Yeah.



STEVE:  Questions would be resolution.  The guy who was demoing it...



LEO:  Bur the DX, they say that the DX is better than the Kindle 2 in terms of screen contrast and clarity.



STEVE:  Well, you - I don't really see any difference.  I have both.  And in fact...



LEO:  I'll tell you why I'm asking.  I left my Kindle on the airplane.



STEVE:  Ohhh, Leo.  Oooh, ouch.



LEO:  So I - actually I looked at the DX.



STEVE:  Wait.



LEO:  But I remember you didn't like...



STEVE:  This is not the first time you've done that.  Or am I thinking of something else?



LEO:  I left my Sony 505 on the...



STEVE:  That's right, the Sony, the 505.



LEO:  Yeah.  And so the next Sony I got, I got engraved with my name on it.  But now I don't use that anymore.  And the Kindle didn't have really any, you know, it has contact information inside it, but I don't think they looked.  You know, I knew that I'd left it on the plane after I went through customs.  And I went right to the desk, and they said, no, we don't have it.  So somebody probably snagged it as they were walking out.  They said, hey, some idiot in business class left his Kindle.  He can afford another one.



STEVE:  Well, I have to say I'm beginning to see them, which is really interesting.  There are at least three other Kindles that I've encountered, people reading them at Starbucks or in a restaurant or...



LEO:  Yeah, I think they're much more common than I thought they'd be.



STEVE:  Yeah, I mean, I think it's really beginning to happen.



LEO:  Well, they dropped the price to $299, so.



STEVE:  Yes.  And frankly, well, this morning when I was out early getting some blood work done for my Vitamin D study that I'm going to be doing on myself, like does the sun really produce Vitamin D, I had my small one...



LEO:  Steve, not content to accept years of science, is doing his own, walking around naked or something.  I don't know what he's doing to test this.



STEVE:  Well, yes, actually I'm thinking probably that I will be getting full-body exposure in order - you know, brief - in order to...



LEO:  What, are you going to become a nudist?  What are you going to...



STEVE:  In order to generate, well, I have the ability, I have a location where I can't be seen.  And I just sort of - I'm going to give it a try.  But...



LEO:  I might try that in my own backyard.  For jetlag that might be the solution.



STEVE:  The reason is that apparently we should be getting much more Vitamin D than we do.  We used to get it from the sun because just 30 minutes of sun exposure generates about 10,000 IU of Vitamin D.  Yet supplements contain 400, which is what the RDA has set, or that is the RDA.  And it's very difficult to get much in your diet.  So now that we're wearing clothes and we're indoors, we're not getting the vitamin, we don't have the production of Vitamin D we should.  And...



LEO:  Of course in those days people didn't live long enough to have to worry about skin cancer, so...



STEVE:  Yeah, and frankly, Leo, I'm wondering how much that's overblown.  I mean, there are apparently people who feel, and I haven't looked at this at all, that all of this slathered-on sun protection is really bad for you, too, but better than skin cancer.  But you don't need a lot of sun in order to generate enough Vitamin D for the day, just 30  minutes.  Which probably is, I mean, it's not like you're going to become crispy and be in the sun all day.  But my point is that, once I start adding Vitamin D to my daily routine, which I haven't yet, I'll never want to stop it.  So I only have one opportunity to sort of measure my Vitamin D level just the way I am now.  And so that's what I did this morning.



My point was, though, before I got off on this tangent, was that I have both Kindles, the DX and my Kindle 2, and I took the Kindle 2 with me because it is so much more convenient as just a general-purpose reader.  The DX has a magnificent screen.  I loaded the - I had Amazon send a copy of the Economist to both so that I could look at them both sort of side by side.  And the DX is beautiful, but you really do feel that it's too large, unless you want to be looking at PDF where, you know, it excels for that kind of performance.



LEO:  That's what Dwight Silverman said, too, of the Chronicle.  He said he couldn't lie with it in bed.  And frankly, that's when I read most of the time is when I'm in bed.  And he said it's just too big to hold up.



STEVE:  And I'll tell you, I really miss having navigation on both sides.  I liked the extra...



LEO:  Yeah, I'm a lefty.  I need that left button.



STEVE:  Yes.  As am I.  And for the same reason.  It's really nice.  So were I you, I would replace it with a K2.



LEO:  Good, because that's what I - I said, I'm not waiting till they find it, if they find it.  I was in the middle of this great book I was telling you about...



STEVE:  And even if they do, you need a spare, clearly, so that you...



LEO:  Oh, man.  I'm in the middle of this Kim Stanley Robinson Mars book which is fantastic, "Red Mars."  And I can't - and it was one of those I couldn't put it down the whole time I was in China.



STEVE:  And I've got mine loaded in the Kindle.  Haven't started yet.



LEO:  Oh, you're going to like it.  It's really good hard science.  And what's nice is, just like Peter F. Hamilton - by the way, we'll get to security in a moment - just like - we got a lot - we have to catch up.  Just like Peter F. Hamilton, he's very good at characters.  And yet the science is - you're going to love this because it's clear that Kim felt like he wanted to do the research so that it would be this is what we have to do if we're going to explore Mars.  And as we get closer, I think get closer and closer to,  you know, doing that, he has to solve all the issues.  And you're going to love it.  I mean, the science in it is fantastic.  Lot of geology because Mars is a rock.



STEVE:  Yeah.



LEO:  Fascinating.  Oh, it's one of my - I'm really loving it.  You're going to love it.



STEVE:  Oh, cool, cool, cool.



LEO:  But I'm halfway through, and it's like, I need my Kindle fix.  All right, Steve Gibson.  Patch Tuesday was last week.



STEVE:  Yes, it was.  And there was a bunch of stuff fixed.  I wanted to start by giving our listeners a little bit of news about Yubico and the YubiKey.



LEO:  Oh, I got, like, three YubiKeys in the mail the other day.



STEVE:  Okay, are they blue?



LEO:  Yeah, they're the new ones.



STEVE:  Aha.  That's the news, is that they only made 150.  So what you have are very rare, limited edition, blue YubiKeys.  They are the new dual function.  Remember that the YubiKey can either function as a one-time password system or as a long, but fixed, password.  The way they implemented the next version of the YubiKey, which Stina calls 2.0, is that you have both functions, or you have any two, either two different one-time passwords, two different fixed passwords, or one of each.  And that you're able to trigger with a single contact.  So there is a special offer, though, that they're making for our listeners.  Reading from Stina's note, she said, "Also I wanted you to know that Yubico has offered existing customers a 40 percent discount when ordering up to nine units of 2.0 YubiKeys before the end of July.  If you would like to, we would be happy to offer the same discount for Security Now! listeners, independent of whether they are Yubico customers or not."



LEO:  Well, that's very nice.



STEVE:  "If you like this idea, please tell your listeners to enter the coupon code, SecurityNow, all one word" - and she has a capital N, I don't know if their coupon code is case-sensitive, but capital S-e-c-u-r-i-t-y capital N-o-w - "in the ordering process on Yubico's web store, and they will only pay $15 per key instead of $25.  We would have the discount campaign for your listeners open for four weeks after your podcast, whenever in time this would be sent out."  So I'm notifying all of our listeners that there's a special opportunity to purchase these new 2.0 version YubiKeys which are the dual function, for 40 percent off, $15 instead of $25, if they enter "securitynow" as their coupon code in the Yubico store.  And that's Yubico.com.  And I'm sure you could navigate to where to purchase them from there.



LEO:  Cool.



STEVE:  So that's news from Stina Ehrensvrd at Yubico.  So, yes.  A bunch of, well, all, I mean, pretty much in the time since we last spoke, Leo, everything has been updated.  Nothing is the same.  Last Tuesday, July 14th, was the second Tuesday of the month.  Which is interesting, I mean, it's the latest you could have a second Tuesday of the month because the first was on Wednesday two weeks before that.  So the 14th is the farthest into the month you could have the second Tuesday.  Three critical updates from Microsoft and three important ones.  Microsoft has said that they expect exploits for all of the vulnerabilities that were addressed.  There were problems in Windows; Microsoft Office; their IAS, which is Microsoft's Internet Acceleration Server; and even their Virtual PC and Virtual Server products.



In the case of Windows there was a very widely publicized, actually, Microsoft announced this beforehand because it was a zero-day exploit.  There were exploits happening on the 'Net, so they'd let everyone know.  They had the MSVidCtl ActiveX control had a buffer overflow which could allow arbitrary code to be executed just by visiting a website that would invoke that control using scripting.  So that they fixed.



There were two patches in what they call the Embedded Open Type Font Engine, EOT.  And that was exploitable from a website or email.  Apparently websites and email are able to, like, specify that they want a specific web font embedded in the page, and that invokes this font engine on the fly, this open type font engine on the fly.  And there was a problem with that, which Microsoft fixed.



And you may remember we talked several weeks ago about Publisher having a problem, that if you opened a Publisher file, if users opened a Publisher file that was part of, like for example attached to email, that could cause a problem.  And that was one of the other things that they fixed.  And then also there was a different problem with a video ActiveX control where Microsoft has told people just to set the kill bit.  And I've got a further note about that a little bit later, so we'll come back to that because there's a Knowledge Base article that allows people to fix this.  That's important because that was not included in this patch, and it is being actively exploited now.



LEO:  So this is the one - this is one hole left open.



STEVE:  Yes.  And this is a zero-day exploit, actively being exploited now.  They apparently found out about it the day before the second Tuesday, not in time to fix it.  I don't think they're going to do an out-of-cycle patch, but they've got one of those little fix-it buttons where you just - or the Fix me button where you can just click it.  And basically all I does is it sets these so-called "kill bits" that prevent this control from being instantiated by Internet Explorer.  And of course our listeners are hopefully just not using IE anymore.  I mean, none of these are problems if you're not using Internet Explorer.  If you switch to Firefox, which is what we recommend, you're not having this problem.



On the other hand, 3.5 of Firefox did have a critical memory corruption flaw in its Just-in-Time JavaScript compiler fixed recently.  It's now at 3.5.1.  So anyone using 3.5, and I know that you are, Leo, I'm holding back.  I'm staying with Firefox 3 until 3.5 settles down a little bit more.



LEO:  Oh.  Yeah, I'm using it.  I went to 3.5.1.



STEVE:  Yes.  And so...



LEO:  But that's not enough.



STEVE:  So, well, no, no.  3.5.1 is current.  They fixed this Just-in-Time JavaScript compiler problem.



LEO:  Oh, okay.



STEVE:  And apparently there were some performance problems, some startup problems with 3.5, like having a really slow startup in Windows.  And so they say that they also addressed several stability issues and this performance problem that was causing a real slow startup in Windows.  I know that my tech support guy, Greg, had upgraded himself to 3.5 and was really seeing Firefox being unwilling, I mean, just, like, really slow to start.  And so he said, wait a minute, I thought it was supposed to be faster.  And so apparently they fixed that in 3.5.1.  I'm hoping.



LEO:  That's a Windows issue, yeah, and it has to do with loading temporary folders for randomization.



STEVE:  Interesting.



LEO:  For encryption, yeah.



STEVE:  Oh, okay.  And over on Firefox 3, where I still am, that had an update also.  It's now at 3.0.12, which is the current version.  And in fact when I fired it up this morning I got the upgrade opportunity just now.  So that's fresh off, you know, hot off the press.  There were four things that were fixed there.  There was a crash and remote code execution problem using scalable vector graphics.  We don't hear about that that often.  But scalable vector graphics is a technology that really, I don't know, for whatever reason it hasn't taken off that much in terms of actual deployment.



LEO:  There's been Flash out there and...



STEVE:  Exactly, lots of competition from existing technologies which do the job.



LEO:  Right.



STEVE:  There's also a heap integer overflow in this Firefox 3 in its font glyph rendering libraries that was fixed.  There was a problem with Flash player unloading that was able to cause a remote code execution, of all things, when the Flash player was done.  So the way it was able to unload, the bad guys were able to cause a problem.  And they were also - there's some sort of a crash that had evidence of memory corruption, that just sort of referred to it generically.  All of that's fixed in this 3.0.12 of Firefox.  And you know me, I'm just - I'm going to wait a while before I go to 3.5.  I ultimately will, but I'd like to let it settle down a little bit and get the debris shaken out.  I know you, for the stuff you do...



LEO:  It's a lot faster, you know, so.



STEVE:  It really is?



LEO:  Yeah.  That's the main reason.



STEVE:  I did update to it by mistake, and I found that none of my add-ons said that they were compatible.  How are you seeing...



LEO:  That must have been when it was still a beta, I'm thinking.  Because once it came out in a release, all my add-ons worked.  You know, sometimes it takes a while for the add-on guys to update.



STEVE:  Just to - right.



LEO:  So maybe, you know, I'm not using NoScript, so it might be that one does not work.  But all the ones I use...



STEVE:  I had all of mine, actually.  So something must have been strange.



LEO:  I don't know.  I mean, we're not using the same ones.  But that was true in the beta that a lot, almost all of them didn't work.  And then once 3.5 came out officially, almost all of them did work.



STEVE:  And so AdBlock Plus, for example, do you use that?



LEO:  No.



STEVE:  Okay.  I think what I'll do is I'll do a test install and see whether the things that I care about are ready yet.  But again, in general, I'm not in a hurry to jump on the latest bandwagon because those are just not secure.



LEO:  Yeah, yeah.  I don't know.  I mean, you know, you get security updates forever anyway; right?  It's not like...



STEVE:  Yeah, yeah.  Well, but tried and true, I mean, you want to let it settle down.  You'd like, for example, there not to be a really big problem that was not known.  For example, have you heard about the iPhone SMS problem?



LEO:  No, tell me about that.



STEVE:  Oh, we'll be talking about that in a minute.  Anyway...



LEO:  Oh, boy.



STEVE:  So, and that's not been fixed yet, and that'll be introduced at the Black Hat Conference this weekend.



LEO:  Great.



STEVE:  But Google Chrome has also had an update.  There was a problem in the Apple WebKit browser app framework, a heap-based buffer overflow vulnerability.  And once again, it was just one of these random things.  A specially crafted regular expression in JavaScript was able to cause a remote code execution, probably contained within the Google Chrome sandbox, that is, you know, Google is saying that.  They're deliberately withholding further details until more users have updated.  I did check, fired up one of my virtual machines that has Chrome in it.  And sure enough, now I'm up to where everyone should be who's using Chrome, all 3 percent of you on the 'Net, and that's version 2.0.172.37.



LEO:  But that happens kind of automatically, without your even knowing about it; right?



STEVE:  Yeah.  So you're probably going to be current already.  Although I did have to go to the About box, where I found Check for Updates, and then I was told that there was one.  Although I didn't - I wasn't using it, and so maybe it was going to take a while and then do its check and verification.  So then there was a different problem with it, where a malicious site could cause it to allocate huge amounts of memory and force a crash and, in the process of crashing, cause arbitrary code to run.  So you would crash the browser, but in the process malicious code was able to get injected into it.  And while Google was doing that, they also updated their V8 JavaScript engine to the latest version, which is 1.1.10.14.  And then they also updated Gears to the latest version, which is 0.5.25.0.  So that brings Chrome current.



And then Safari also had an update.  We last left off with version 4.0.1 that we talked about a few weeks ago.  Now we're at 4.0.2, which fixes two flaws.  One's not so bad, a cross-site scripting flaw, but you'd like to not have any of those.  We'll be talking about that later in this episode in another context, in the context of web-based appliances that have, like, real problems.  But there was a memory corruption issue in Safari 4.0.1 and earlier that could be exploited to crash the browser or to execute arbitrary code, just by visiting a web page.  So and that affects both Windows and Mac OS X versions of Safari.  So you want to be sure that you're running 4.0.2.



LEO:  Yeah, I noticed that update, and I didn't - they don't really tell you why.



STEVE:  Yeah, interestingly enough, Microsoft tends to be the most open of any...



LEO:  Yeah, they really are, yeah.



STEVE:  ...of these companies because, you know, they've got to be.  They've taken their lumps, and they were the pioneer with insecurity.  So I think their policies are pretty well mature.



And lastly, I had a really nice SpinRite note from a guy who sounds like he's not easily impressed.  And, I mean, this is one of those where, okay, I'm not making this up.  This is Brad Schick, who wrote to tech support.  I don't think he's a listener.  But he just said, "I seldom send out praise for products because I expect to get what I paid for.  So I generally consider praise unnecessary.  In this case, I was so impressed with how well your SpinRite program worked that I must tell you it is truly remarkable.  My computer had locked up while in screensaver mode.  Nothing would bring it out of the lockup, so it had to be shut down via the power button.  Upon restart, it would start to load XP for a count of 14 seconds.  Then it would flash the Blue Screen of Death for one second, then go to the problem screen, asking if you want to start Windows normally, in safe mode, safe mode with networking, et cetera."



LEO:  I hate that.



STEVE:  [Laughing]



LEO:  Hate it when that happens.



STEVE:  "Trying to boot in safe mode or any of the other options proved to be futile since it would make the same loop again.  XP attempted to start, Blue Screen of Death, then the safe mode option screen.  I was skeptical that a program on a disk would be able to fix my problem.  But after booting to SpinRite and having it do its magic for the Data Recovery Level 2 in only 17 minutes," and he says, "(17 minutes, it's not a typo)," he says, "it had finished its work and found and repaired a bad sector.  My computer then booted normally and has been working perfectly ever since then.  Your SpinRite program is easy to use, and it is truly amazing at how well it works.  I will be spreading the word about SpinRite and the other programs you offer.  Also, in regard to the price, it would have cost more to take my computer to a shop for repair, and that is not factoring in the time lost to do so.  With SpinRite I have a tool that can be used over and over and over.  SpinRite is an incredible product, just incredible.  Regards, Brad Schick."



LEO:  isn't that nice.



STEVE:  So thank you, Brad.



LEO:  Don't you love getting email like that.



STEVE:  Oh, yeah, well, I mean, when we solve the problem.  And he's, I mean, really addresses the benefits of SpinRite, what it does.  And, I mean, even saying yes, it would have cost more.  And besides, the shop would have just run SpinRite on it anyway.



LEO:  Do you know for a fact that a lot of computer repair places use SpinRite?



STEVE:  Oh, absolutely.  It's their secret weapon.  They just say, oh, just run SpinRite.  And then they don't spend any more time, and they charge hundreds of dollars.  Thank you very much.



LEO:  Yeah, I want to ask you, and I don't know if you've prepared anything about it, but you know Google announced an OS, I guess based on kind of Linux, but also with Chrome as the centerpiece of it.  I'm kind of curious, especially with all these security flaws we've been talking about.  And you're...



STEVE:  Chrome OS.  I don't - I know of it.  It generated...



LEO:  Nobody knows anything about it because Google said nothing.



STEVE:  Right.  It generated a tidal wave of news because it's like, well, because the way it was put out was this is going to compete with Windows.  This was like Google's battle against Microsoft.  And the other thing is, it's supposed to start up in two seconds.  You turn it on, and it's, like, there.  Basically it sounds like a very fast boot of Linux, running the Google browser basically, running Chrome.  They're calling it the Chrome OS.  And they're, of course, taking the web-based model where you would be connected.  You'd have apps in cloud...



LEO:  It's cloud computing, yeah.



STEVE:  Yes, cloud computing.  Although apparently you are able to bring local copies onto your machine so that, if you don't have a live connection, you can still do things.



LEO:  Right.



STEVE:  So it'll be calendaring and office app suite sort of things and the stuff that Google's doing now.  They're just saying, okay, we're going to - you really don't need Windows.  It won't be something you run - you won't run our browser on top of Windows.  You'll run it on top of nothing.  And presumably for free.



LEO:  Yeah?  As are all versions, or almost all versions of Linux.



STEVE:  Right.



LEO:  Yeah, it's very interesting.  But we'll find out more about it in a year.



STEVE:  When it happens, we'll definitely be bringing news.  And no doubt updates to that, too, now.



LEO:  Let's take a break.  When we come back you have more security news?  We should mention...



STEVE:  Oh, my goodness, news, news, news, news, news.  We have an iPhone problem; a zero-day exploit in Microsoft; big news about Phorm, our nemesis in the U.K.  McAfee had problems.  Remember about - certainly you probably heard about the distributed denial of service that was launched against the U.S. and South Korea.  I've got the whole tune-up on that.  News about Pirate Bay, a survey about people and spam...



LEO:  Boy, you go away for three weeks, the whole world goes to hell.



STEVE:  Some more Amazon news; cyber warfare may be becoming offensive; and a problem with embeddable web servers in devices.  So lots of stuff to talk about.



LEO:  All right.  We'll get to that in a bit.  I should mention that normally on a mod 2 episode like this we would be doing Q&A.  But we're going to do two, you want to do two Q&A next week because we need to get caught up on the news.



STEVE:  No, no, I want to do a Q&A next week and the week after.



LEO:  I mean two in the next two weeks, I mean, yes, yeah, yeah.



STEVE:  Yes, exactly.



LEO:  So get your questions to Steve at GRC.com/feedback.



STEVE:  Yes, yes, yes.



LEO:  And if you have a question, we'll get to those in the next two weeks.  All right, now let's see what's going on in the world of security.



STEVE:  Okay.



LEO:  We've got all - that was just patches, folks.



STEVE:  That was just patches.  What we have now are things that are not yet patched.  This coming weekend, starting on the 25th, is the - so the 25th through the 30th, I think, is the next annual Black Hat Conference in Las Vegas.  Always interesting things are being shown.  What is being shown this weekend is a remote execution vulnerability in the iPhone's SMS handling.



LEO:  Which is - so you mean - well, I'll let you explain that.  But it sounds like somebody could send me a text message and hack my phone?



STEVE:  Yes.



LEO:  That's not good.



STEVE:  And there is no way to turn off text message reception on the iPhone.



LEO:  That's right.



STEVE:  It is a zero-day exploit.  It has been demonstrated by a security researcher.  He has agreed with Apple that he will not release details until this weekend.  So expect an iPhone patch.  Apple is frantically working on fixing this.



LEO:  Wow.



STEVE:  But this allows any iPhone to receive a text message and be taken over.  Arbitrary code can be executed...



LEO:  Somebody just sent me a text message that says "You've been hacked."  [Laughter]  They must be listening.



STEVE:  For example, they could determine where you are by polling the phone's GPS.



LEO:  What?



STEVE:  They could turn on the microphone and listen to what was going on.



LEO:  Oh, my god.



STEVE:  They could join the phone to a botnet, recruit it to participate in a botnet.



LEO:  Because it's a computer.



STEVE:  Well, see, yes, that's exactly right.  It is a full-power computer.  And it is like the - and it's relatively new, and the software is still being polished.



LEO:  Well, it's three years old.  It's not that new.



STEVE:  Well, but they keep changing it.  I mean, so there are...



LEO:  Yeah, the version 3 is relatively new, yeah.



STEVE:  Exactly.  And, I mean, change is - not only is complexity the enemy of security, but so is anything new.  Which is why I'm not going to Firefox 3.5 yet.  It's new.  New is bad.  I mean, it's just fundamentally bad.



LEO:  Has he said if there's any way of knowing if this has happened?



STEVE:  No.  Now, initially he was crashing the iPhone.  When he gave a demo, the person who was the target looked up, and it just said "No Service," so the phone had crashed.  But he will be demonstrating this weekend that he's able to execute arbitrary code on a 3.0 unpatched iPhone.



LEO:  As we know, the crash is often a precursor to that; right?



STEVE:  Yes.  Crashes are the way these things - exactly.  You start by crashing it.  Then you analyze exactly what happened and then realize, oh, if we put this binary as part of our packet, then that'll get executed.  And as you said, Leo, I mean, it is - it's a connected computer.  And there is nothing more vulnerable in the world than a connected, open computer that is able to execute code from the data incoming.  And normally you're just going to display text when you receive an SMS message on the screen.  Unfortunately, there's a way to get the phone to execute what you send.  And apparently there's a site you can go to to disable some reception features of the iPhone.  You can, like, turn off email something-or-others.  I was scanning to understand the nature of this.  But there is no way to turn off the phone's vulnerability to SMS.  So Apple will be patching within the next few days.



LEO:  I hope.



STEVE:  Rushing to get this thing done because the guy said, look, I'll give you until the Black Hat conference.  But this is the title of my talk.



LEO:  Now, Black Hat, there's really two conferences, Black Hat and then DEFCON.



STEVE:  Right.



LEO:  One right after the other.  Black Hat is like the hardcore, invite-only conference?



STEVE:  Well, and this guy is well known.  His name is Charlie Miller.  He wrote the "Mac Hacker's Handbook."  He co-wrote it, and he's regarded as an OS X authority.  So he had Apple's attention immediately.  And he's, you know, it's serious business.



LEO:  Wow.  Yeah, no kidding.



STEVE:  So there's news on the iPhone.



LEO:  But we just got - we don't know, and let's hope hackers don't know, the details until this weekend.



STEVE:  Yeah.  And the good news is it sounds to me like you just can't randomly send a text message to it.  You're going to have to go through some work in order to make this happen.



LEO:  And you have to know the phone number, obviously.



STEVE:  And exactly, you have to know the phone number in order to...



LEO:  Most everybody knows my cell phone number, so...



STEVE:  I was just going to say, I was surprised when you received a text message because I...



LEO:  Well, you know, it's gotten out so many times it's not really a secret.  And, yeah, oh, boy.



STEVE:  Yeah.  Maybe you ought to turn it off, Leo.



LEO:  The phone?



STEVE:  It's your phone, isn't it.



LEO:  It's my phone.  I can't turn it off.



STEVE:  That's a problem.  Well...



LEO:  Hey, if I'm hacked, I'm hacked.  What the heck.



STEVE:  As far as we know, this is not in the wild.  This one guy knows about it.  He's acting responsibly.  But he's told Apple, look, get your act together, get this thing patched.  What's the patch technology for the iPhone?  Is it able to, like, push patches out very quickly?



LEO:  Yeah.  Just like all cell phones, AT&T pushes it out and says - wait a minute.  No, that's not true.  I take it back.  That may be a capability that AT&T has.  But normally your phone is not patched until you hook it up to iTunes and synch it.  And iTunes will then say, usually, there's an update.  Do you want to apply it?  It's really much more volitional.  It's not - there's no automatic patch.  Unless AT&T, you know, a lot of cell phones you have that automatic capability.  Maybe AT&T does have that.  I hope so.  It's not just AT&T, though.  You know this is a worldwide system.



STEVE:  The exact quote was "A bad SMS vulnerability that allows an attacker to remotely install and run arbitrary, unsigned software with root access."



LEO:  Couldn't be much worse.



STEVE:  No.



LEO:  Could not be much worse.



STEVE:  When you receive it in a text message.



LEO:  Geez.



STEVE:  Yeah.  Meanwhile, there is a zero-day exploit which is unpatched, zero-day meaning currently being exploited, of an ActiveX control for Microsoft's Office web components.  There is no way around this.  If you go to a malicious web page or you open email with an HTML viewer, your machine can be taken over.  This is not a problem for people running Firefox.  This is only if you're using IE.  I use IE only to run Windows Update.  So I'm safe.  I'm hoping our listeners are to the point now where they're no longer using Internet Explorer, in which case they're not going to have a problem.  The next Patch Tuesday for August I'm sure will cure this.



However, if you need to use IE, the only solution is to turn on the kill bits, the so-called kill bits for this ActiveX control.  Microsoft has a page that makes it as simple as a single click.  It's support.microsoft.com/kb - which coincidentally stands for kill bits.  Also knowledge base, of course.  So it's /kb/973472.  So again, that's support.microsoft.com/kb/973472.  That'll take you to a page that's got the new Fix me button on it, where you click it, and in doing so it runs some script which turns these kill bits on.  Now, the kill bits, this is something where you're wishing Microsoft had done this the other way around.  They ought to be enable bits for all these ActiveX controls, which are normally off.



LEO:  Right, right.



STEVE:  This is like...



LEO:  Default to off.



STEVE:  Yes.  This is like the old days of the firewall, where the original firewalls were allow all, and then you blocked specific things.  Well, that strategy didn't last very long.  And everyone finally knows that a firewall should deny all and then allow only the traffic that you know you want.



LEO:  Right.



STEVE:  Well, Microsoft got it backwards.  And unfortunately IE with scripting allows any ActiveX control, even if it's not supposed to be, if it was never intended to be a web control, it's by default you can invoke it.  So here's, you know, an Office component, this does happen to be a web-based component, an Office component that you probably don't need to use, you don't want websites to invoke, yet a bad one can.  And due to the fact that there's a remote code execution vulnerability in it, it allows your machine to be taken over remotely.  And it is now being maliciously exploited as we speak.



Microsoft has no fix for it.  My guess is they're not going to do an out-of-cycle patch.  They'll wait till August.  So if you need to be using IE, and if you might be viewing email that you don't control, or you're going to websites that you don't trust, then turning these kill bits on for sure is a good thing.  And after the patch you can turn them off again to get that functionality back.  So again, I hope our users have moved to Firefox, and they're only using IE for running Windows Update, which is where I finally am.



LEO:  It strikes me this is the most depressing show in history.  Now I can't use anything.  I can't use Firefox.  I can't use my iPhone.  I can't use IE.  Can't use Windows.  They all have unpatched, zero-day flaws.



STEVE:  It really is a problem.  And it's funny because as a science fiction buff I've - we've all read stories like this where people like Neo from "The Matrix" are, like, selling on the black market some sort of disk that does something.  And it's like, oh, come on.  Aren't we going to solve these problems?  It's like...



LEO:  I think not.



STEVE:  ...there's no sign that we're going to.  And I've got even more stuff, so.  I do have some good news.



LEO:  Oh, good, please.



STEVE:  Let's do good news...



LEO:  Cheer me up.



STEVE:  ...for a change.



LEO:  Okay.



STEVE:  Phorm - P-h-o-r-m - this for lack of a better term "heinous" marketing company, remember that we did a whole episode on the Phorm technology.  These are the people who were installing their equipment in ISPs' facilities, intercepting all of the ISPs' customers' web traffic, and inserting their own cookies into - masquerading as cookies from every site that people went to in order to establish a comprehensive identity that was pervasive and pernicious and that you just couldn't get rid of.



Because British Telecom, which is the No. 1 U.K. ISP, did a test of this secretly, without notifying any of their customers, when the word of this leaked out, it caused a huge uproar.  In fact, it turns out that the EU, the European Commission, has also begun to take legal steps against the U.K. government for its failure to take action against Phorm or BT for the two trials of the technology in '06 and '07, which they conducted without gaining customers' consent.  So, I mean, this has become a huge political problem.  British Telecom just formally announced that they are putting their work with Phorm on hold.  The BBC reported that, upon that announcement, the stock value of Phorm fell 43.16 percent.  And then...



LEO:  Woohoo!



STEVE:  Yes, and then...



LEO:  There is justice.



STEVE:  ...the No. 2 ISP in the U.K., which is an ISP called TalkTalk, they also announced shortly after BT did that they are dropping Phorm and pulling out of it.  And that kicked the shares down to a total of more than half of its value lost.  So it really, I mean, all of this bodes poorly for Phorm's future, which is one bright speck of news here in an otherwise gloomy podcast about security problems.



LEO:  Just don't tell me the Kindle's been hacked, that's all.  I just...



STEVE:  Well, there was a problem.



LEO:  Oh, no.  No, no, no.  I was thinking, I'm just going to sign off the 'Net and read books.  But I can't even do that now.



STEVE:  Well, you may find that the books you want to read are gone.



LEO:  Oh, yeah. Isn't that an interesting story.



STEVE:  Yes.  Amazon did something very controversial.  No one realized that Amazon was capable of removing books from the Kindle.  But Amazon can and did.  What they're saying is that somebody posted two of George Orwell's books, "Animal Farm" and "1984," onto somehow like a - they had some unauthorized party posted...



LEO:  Yeah, there's a self-publishing feature on the Kindle that I didn't know about, or on Amazon, yeah.



STEVE:  Right, exactly.  And apparently people bought copies of "Animal Farm" and "1984" for just 99 cents, not super expensive, and many people noted that it was a little bit ironic that it was George Orwell's "1984," the Big Brother book, that was then - that was removed from Kindles when the actual owner of the copyrighted content notified Amazon.  Amazon sent email out to people who had purchased it, saying, "We're sorry to notify you that this was put up on our site illegally.  We have removed the content from your Kindle, and we're going to refund your 99 cents."



It caused a big kerfuffle because people were upset with the idea that they didn't really have - they didn't have, like, control over their content.  Fred von Lohmann, who's a staff attorney for the Electronic Frontier Foundation, said, "There's an enormous difference between buying a book and buying a tethered media device," as he termed it.  He said, "And this incident really underscores that fact.  Consumers carry with them analog-world expectations."  And then he said, "It's not clear from the Kindle license agreement that Amazon has the right to delete purchased content."  He said, "I don't see that many loopholes."  He notes that the Kindle license agreement states, "Amazon grants you the nonexclusive right to keep a permanent copy of the applicable digital content."



LEO:  There you go.



STEVE:  "And to view, use, and display such digital content an unlimited number of times."  And so he says, "Well, maybe the term 'applicable' is the out that Amazon would use if it came down to it, saying that, well, illegally uploaded content is not applicable to our license; therefore the users don't have the right to maintain it and keep it and view it an unlimited number of times.



LEO:  Well, it may be moot because Amazon said, well, we're sorry, we'll never do it again.



STEVE:  Precisely.  Exactly.  Amazon said, well, in any event we've learned a lesson.  I don't know what they'll do in the future.  Maybe they would just pay the content holder the equivalent value.  That would have certainly caused much less problems and concerns.



LEO:  I came up with a solution, which would have been a good solution, which is to switch it for a legitimate copy.  Here's the problem.  Now, I don't know if this is confirmed.  But according to the Times, students who had notes attached, who were using it for class, lost the notes.



STEVE:  Oh, right.



LEO:  Now, that, I think, has to be illegal.  I mean, that's got to be a violation because you're deleting my content.



STEVE:  Because it's the users' own content that they've added to it would then be lost.



LEO:  And I haven't confirmed.  I thought the notes were separate.



STEVE:  I would think they are.  I think they are stored, well, certainly you can't be modifying the file.  So it would be a file of...



LEO:  A sidecar of some kind.



STEVE:  Well, it would be a file with pointers into the copyrighted content file.



LEO:  So that might just break it.



STEVE:  Because it's all encrypted in DRM.



LEO:  Right.  In any event, thank goodness they're not going to do it again.  Because...



STEVE:  No.



LEO:  There's got to be a better way.  I suggested that they send an email or they put it on the Kindle, they probably could do this, saying hey, you've got, you know, we found out this is not a legal copy.  We'd like to offer you free a replacement copy of "1984" and apologize.  And please delete it.  I mean, that's all they can do, really.



STEVE:  For no additional cost.  I mean, Amazon would eat the cost of however many copies...



LEO:  Well, they did that anyway because they reimbursed people.



STEVE:  Well, no.  They reimbursed them 99 cents.



LEO:  Oh, they didn't give them the full amount?



STEVE:  No.  Well, no.  But that was what they paid.



LEO:  Oh, okay.



STEVE:  They only paid 99 cents for this.



LEO:  Oh, I see, yeah.



STEVE:  And so they reimbursed them what they paid.  But imagine Amazon would say, you want this, fine.  We made a mistake by allowing this to be purchased for 99 cents.  You can now have the real one; or, frankly, just pay the copyright holder however many of the bad ones got downloaded.



LEO:  There you go.



STEVE:  Yeah.  In other news, older versions of McAfee have once again been destroying Windows.  We talked about this the first time it happened in May, so not that long ago, where an update to McAfee's virus scan misfired, wrongly discovering a "worm," unquote, in valid Windows system files, quarantined them, and caused Windows to crash.  And users could not get Windows to boot anymore because McAfee had said, no, these files are bad, you can't have them, they're infected, even though they were critical Windows system files.



Well, this happened at the beginning of the month, on July 3rd, obviously just before the Fourth of July.  With McAfee's DAT 5664 update, many people found that their Windows systems crashed.  And to me, Leo, this makes me just want Microsoft's Security Essentials solution for this all the more.  We talked about that a couple weeks ago.  Microsoft's in beta, 75,000 copies instantly downloaded.  The reviews have been stellar, by the way.  They continue to be stellar.



LEO:  I love it.



STEVE:  No false positives.  It updates as often as it needs to, maybe even as much as hourly in order to keep itself current.  From Microsoft, integrated well into Windows, not being a bigger problem than the problem itself, which here again we see an example of McAfee being...



LEO:  All the time, yeah.



STEVE:  Yeah.  I just can't wait.  I'm...



LEO:  Well, it's going to change.  I mean, McAfee and Symantec and everybody else are going to have to think of a new business.  I mean...



STEVE:  Yes.  They had a long time to make hay.  And it was absolutely foreseeable.  Just as it was foreseeable that Microsoft would add a firewall to Windows, it was foreseeable Microsoft would get into the antivirus / antimalware business themselves.  And the good news is, it's just going to be free.  It'll be the first AV that I ever run, and I'll run it everywhere, and I'll recommend it to everyone - unless there's any downsides that we learn about.  And of course we'll let our listeners know either way.



Okay.  Denial of service attacks on the U.S. and South Korean websites.  On July 4th, which I guess coincided with North Korea's July 4th missile launches...



LEO:  Right, and the day I arrived in China.



STEVE:  And the day you arrived in China.



LEO:  Completely coincidental.



STEVE:  A not hugely damaging but certainly disconcerting distributed denial of service attack was launched by - there's been some dispute about the number of PCs.  Some reports said 20,000.  But a Vietnam research organization that found the command-and-control servers and tracked them back estimated the number was 177,000 infected machines.  The U.S. Treasury Department, the Transportation Department, and the FTC all had their websites briefly taken down for various lengths of time.  Some experts felt that this wasn't a high-strength attack; and that, had these organizations had better networks, had they outsourced them, for example, distributed them using Akamai so that there wasn't a single point of attack, they would have been able to stay up.  I would imagine we'll see those kinds of changes come about as a result of this.



There were some bogus reports saying that this was actually triggered by or controlled by North Korea.  But that was later debunked.  What happened was, this thing was called W32.Dozer, which was actually a sort of a loose confederation of already known tools.  There was this W32.Dozer that was a so-called "dropper" that contained all the other components.  It was sent to users by email.  So this was a worm.  And the old Mytob agent that we've heard about before, W32.Mytob, that handled the mass mailing, gathered email addresses on the machines that it infected.  So Dozer dropped Mytob on the system.



And then there was another trojan and a variation of MyDoom.  MyDoom was what did the denial of service attacks on these machines.  So there was sort of this collection that would land on the machine, brought in through email.  If the user clicked the link to execute this Dozer, it would drop the other components out.  One of them would be the backdoor zombie that would then use eight different command-and-control machines that were later found.  And then another one of these components would rifle through the user's system, finding email addresses, and then mail itself out to all of the addresses that it could find in order to spread wormlike.



So that was on the 4th.  What was then found, upon analysis of this, is that there was some weird self-destruct code which you typically don't see in these sorts of tools.  There was a timer set to go off on July 10th.  So less than a week later, only six days later, in a weird sort of way, it would search the machine for 30 common file extensions - .doc, .pdf, .xls, basically user content files - copy them into an encrypted file, and then overwrite the copied files, as if it was quarantining and encrypting and, like, sequestering these specific user content files from the machine's owner.  Then it overwrote and blasted the master boot record on the drive, preventing the machine from booting.



So what was strange was that, after six days, basically it encrypted a whole bunch of files, it didn't destroy them, but it encrypted them and then prevented the machine from booting.  So it's like, I mean, it was puzzling security experts.  It's like, okay, well, what's the logic in this?  It wasn't at all clear.  Then four days after that, on the 14th, this Vietnamese security company that I mentioned, the Bach Khoa Internet Security, they tracked down eight command-and-control servers and then tracked down the single master server which was spreading its control out to those eight.  And that server was located in the U.K.  And that, again, uninformed press said, oh, well, this was based in the U.K.  It's like, no. 



LEO:  No.



STEVE:  We still don't know.  And as far as I know to this day there's been no confirmation of who was actually behind it.  The U.K. machine was doubtless just one other machine that got taken over, and then it was the distributor to the eight other command-and-control computers.  So that's the tune-up on what all these denial of service attacks were.



LEO:  And we have no idea where it came from.



STEVE:  No, none whatsoever.  I mean, which is not to say it's impossible because now that they found the machine in the U.K., if somebody tried to contact it again, then potentially you could track back.  But all you have to do is run through, like, The Onion Router network, the TOR network, and then it becomes impossible to backtrack that.  I mean, the TOR network, as we know, we did an episode on it, it's designed so that you can't backtrack the traffic through it.



LEO:  Well, and a good hacker, I mean, we've known this for years, does in effect the same thing by going multiple servers and multiple layers.



STEVE:  Through proxy servers and, yes, exactly.



LEO:  I mean, I doubt they use TOR.  But they do something like that.



STEVE:  Yup.



LEO:  By hand, yeah.



STEVE:  Yeah, they have a number of machines that they've compromised, and each one relays commands to the next one in the chain.  And they're spread around the world, so it's virtually impossible to get cooperation from all governments and carriers in a short order.  And it sounds like the whole thing was set to expire after a week anyway.  So it's all sort of moot.



LEO:  I wonder - and I wonder what the intent was.



STEVE:  It's just bizarre, yeah.



LEO:  You've got to figure there was some sub rosa communication between the hacker and these governments, that there's something else went on.  It's some sort of proof-of-concept kind of thing.



STEVE:  Yeah, it's like, okay, so why scan the machine for 30 different file extensions...



LEO:  Yeah, that's weird.



STEVE:  ...encrypt the files and bundle them up.  And then kill the machine.



LEO:  Yeah, it's very strange.



STEVE:  It's just weird.  It's like...



LEO:  It's almost like a demonstration, really.



STEVE:  Yeah, or, like, maybe some of this, you know, they seemed to be using a bunch of other components, like so maybe there was, I mean, it could have even been inadvertent that it had this strange side effect.



LEO:  Right.



STEVE:  One of the components had some behavior that the original designers didn't anticipate.



LEO:  Sometimes these guys aren't really that bright.  We may be giving them a lot of credit.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  In an interesting little turn of events, we've been following the trial of the guys who were running Pirate Bay.  And we know from talking about it before that they were found guilty of, not themselves of copyright infringement, but of essentially aiding and abetting the copyright infringement of the people who used their site.  They lost a lawsuit, were sentenced to each one year in prison, and also had to pay a fine, or were fined, at least, 30 million kronor, which is $3.9 million.



Well, Pirate Bay has been purchased, was purchased by an outfit called the Global Gaming Factory, GGF, who paid $60 million kronor, not maybe coincidentally two times the fine amount, for Pirate Bay.  What they've announced is they're going to go legit.  And I read several accounts of what they had said, and some interviews.  And I still can't figure out what it is they think they're going to do.  They say that they're going to introduce models, economic models that ensure that content providers and copyright owners get paid for content that is downloaded via the site.  And they say that they're going to - that it'll be a subscription service, so individuals, end-users, will have to - will pay some sort of monthly fee for access to the site.  But if the users allow their machines to be used, and they also refer to if the users submit content, then they'll receive reimbursement for that and a reduction of the monthly fees.  It sounds sort of screwy.



They also say that, like, ISPs that have really popular content sometimes get overloaded and can't deliver as much of the content as they want, so they're going to deploy some sort of peer-to-peer network in order to offload copyrighted content that ISPs would be providing.  Some accounts say that these guys have had a year-long relationship with some ISPs on a basis sort of like this.  So it's, anyway, it's not clear what they're going to do.  But Pirate Bay is apparently going to try to go legit with some sort of model.  Oh, and Kazaa, which is one of the earlier peer-to-peer networks, has said the same thing.  They're going to be coming out with a legal commercial system, trying I guess to leverage their past popularity.



LEO:  Hmm.



STEVE:  Weird.



LEO:  Yeah.  I don't know why it's worth 60 million.  Kronor.



STEVE:  Kronor.  $7.7 million.



LEO:  I guess - do they have ads on it?



STEVE:  I agree, I don't know exactly...



LEO:  How do you make money off this?



STEVE:  ...what it is that they think, I mean, certainly a huge percentage of the past success was that it was free.  And I think as soon as you say, oh, look, we're the same Pirate Bay, but now you have to pay every month...



LEO:  You're working with pirates.  I mean, the people who use it...



STEVE:  Exactly.



LEO:  ...are looking for free content.  And there's plenty of free choices.  They're not going to pay you any money.



STEVE:  Right, they're just going to go somewhere else.  Instantly.



LEO:  You've got the wrong audience.



STEVE:  Like, how fast can you click a different link?



LEO:  Yeah [laughing].



STEVE:  Yeah, I agree.



LEO:  Okay.



STEVE:  What is it that they think they're buying for their $7.7 million?  It makes no sense.



LEO:  Yeah.  I think basing a business model on getting pirates to pay is not going to work.



STEVE:  [Laughing] Okay.  So an interesting...



LEO:  They have ads, apparently.  We're showing our - we're showing we're just not with it and hip.  They have ads on Pirate Bay.  So maybe that's where they make their money.



STEVE:  Okay, well, I think the ad rates are going to drop, soon as they start...



LEO:  The ad rates can't be worth that much in the first place.



STEVE:  Yeah.  Goodness.



LEO:  Who clicks a link on Pirate Bay?  Oh, well, never mind.



STEVE:  Without holding their breath and being in a virtual machine.



LEO:  Yeah, exactly.



STEVE:  And washing your drive afterwards.  Okay.  So there's a group called the Messaging Anti-Abuse Working Group, MAAWG, which not coincidentally is the acronym and the URL, MAAWG.org.  They're sponsored by AOL, AT&T, Comcast, Cox, Yahoo!, Time Warner, Verizon, all the big names.  They've put out a report which is formally titled "A Look at Consumers' Awareness of Email Security and Practices."



LEO:  Oh, this is so depressing.



STEVE:  Or, quote, "Of course, I never reply to spam - except sometimes."



LEO:  This was the most depressing stat of the week.



STEVE:  Okay.  So a sample of 800 ordinary computer users in North America that this legitimate anti-abuse working group polled, 30 percent of these users said that they had clicked out of curiosity or mistake.  12 percent said they were actually interested in the advertised product or service.  And 8 percent said they did not believe it was likely that their computers would be infected with malware and recruited for use in sending spam.



LEO:  No, nobody would do that.



STEVE:  And so here's the problem, Leo.  We've got somewhere there are 12 percent of people who are interested in having their penis enlarged, in having their mortgage refinanced, in whatever it is that spam is now selling.  I'm a little bit out of the spam loop because, like John Dvorak, I get no spam any longer.  I've solved that problem.  So I don't know quite what is being delivered.  But 12 percent of people say, ooh, and click on the link.  Now, the problem is that the delivery cost of email is so low that 12 percent is, like, way more than there's necessary in order to make this spam economic model viable.



LEO:  Oh, gosh, yeah.  I thought it was one percent.  And even one percent is plenty to make it viable because it's essentially free to send out millions of messages.



STEVE:  Yes, especially when you commandeer other people's computers and their spambots for you.



LEO:  Right.  So if you - what's the cost, you know, a fraction of a cent at best.



STEVE:  It's nothing.  It's not measurable because it's not your bandwidth.  I mean, it's...



LEO:  Well, you would pay for the botnet, but that's, you know, $10,000 for, you know, infinite spam sending.



STEVE:  Well, okay.  So I wanted to let our users know about this.  If anyone's curious, there is a PDF you can download.  I think it's, like, 67 pages.  The entire content of this report is available and free and eye-opening.  It's at MAAWG.org.  And over in the right-hand column there is a link that is the - it's underneath - shoot, I had a note for exactly...



LEO:  There's a Quick Links link.



STEVE:  That's it, Quick Links.



LEO:  At the top, at least as we speak, it's the top item right there.



STEVE:  Yup, the top item under Quick Links over on the right is this PDF with some very disturbing stats because it looks like, you know, of 800 people polled, 12 percent said, "Yeah.  I like spam."



LEO:  I'm just shocked.  I thought it was much lower than that.



STEVE:  Well, it means we're never getting rid of it.



LEO:  Yeah.  Oh, yeah.  If it works, why stop?  I always wondered.  I thought, oh, how could this possibly work?  Well, I guess I was wrong.



STEVE:  Meanwhile, late in June, in an interesting conference on cyber warfare that took place in Estonia, like a global group of people concerned about cyber warfare issues who are deeply involved in this, including two unnamed U.S. government officials, were discussing the pros and cons of proactive attacks.  Two Ph.D. students at the University of Bonn in Germany have said that they've collected enough information about a quartet of well-established massive botnets that they could successfully attack and dismantle the malicious networks.



Now, we've talked about this many times, the fact that it is currently illegal for the good guys to be proactive, that is, we're only able to be reactive and to defend ourselves.  We can't do anything else.  Well, these two unnamed U.S. government officials said that they believe it is time to start creating policy in the U.S. that would allow for offensive cyber attacks.  So we may be seeing this changing in the future.  I mean, the problem is, essentially, the good guys' hands are tied.  The bad guys have all the leverage.  And even when security researchers know how to take down a net that is doing bad things, it's illegal for us to do so.  Can't do it.  So...



LEO:  Oh.  I don't understand that.



STEVE:  Well, I mean, the problem is that, if you modify someone's computer, even for what you regard as beneficial purposes, you've done so without their knowledge or permission.



LEO:  But can't you take down the server?



STEVE:  Well, that's also somebody's machine.  It's a much nastier machine, perhaps, but it's still...



LEO:  It's doing something illegal.  You could just go in and - I don't get it.



STEVE:  It's weird, though, that there are laws in other countries that are not even sure it's illegal.



LEO:  Yeah.  See, that's part of the problem.



STEVE:  Right.



LEO:  Well, we've got to fix that.  I mean, that's crazy.



STEVE:  I think it's being fixed.  It's going to be slow.  And again, we want to make sure we don't do the wrong thing because there's the possibility for abuse of these sorts of things.  Right now we're clearly erring on the side of hands-off and hope for the best.  But I guess, I mean, again, this seems to me like sci-fi.  It just boggles my mind that there's, like, major cyber warfare budgets and teams and facilities, and everyone's starting to take cyber warfare very, very seriously.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  I mean, I know I sound nave about it, and certainly I'm not nave about what can be done and how.  I guess to me it just seems so obvious that it's like, okay, well, fix your security.  Fix your firewalls.  Fix your iPhones.



LEO:  Seems like we have ways to do that.



STEVE:  Yeah.  Yeah.  Exactly.  And lastly, a group at Stanford, there's a Stanford security lab that will also be showing some very distressing news this weekend at the Black Hat conference.  They tested 21 different devices from 16 different manufacturers.  These are web-enabled gizmos - webcams, printers, network switches, photo frames, VoIP phones, remote management tools, all of these things - and, like, consumer routers, all of these things that are web-enabled, meaning that like so many peripherals now, they've got an Internet connection and a web interface.  They tested the vulnerability of 21 devices made by 16 different manufacturers.  There was not one that was not vulnerable to serious web-oriented problems.  For example, they were able to enter JavaScript commands into the logon prompts.



LEO:  Oh, boy.



STEVE:  And the device logged the log-on attempts.  So when the administrator brought up the log, the act of displaying the log replayed the JavaScript commands, as it would because now they were in a web page because the log was web-based.  And that allowed the commands to connect to a remote server and download malware.  They said that among the worst devices were network attached storage devices.  They enumerated five different classes of attacks, and they said that the NAS, the Network Attached Storage devices, were vulnerable to all five classes of attack.  For example, you could rename files to JavaScript strings.  There was no control over file naming in these.  And of course we all have long filenames now in our state-of-the-art file systems.  Well, long meaning JavaScript.  And so anytime this device attempted to display the filenames on a web page, again, you were running JavaScript.  So now there's scripting running in your directory listing, which is displayed on a web page, causing your browser to do whatever the JavaScript has said.  And it's running in the local context.  So even systems that have security saying don't allow remote sites to execute script, but of course we trust our self, well, now we can't trust our self.



LEO:  Great.



STEVE:  All these devices have been put out and created with effectively no awareness of the security implications of having this kind of power on an easy-to-use, easy-to-administer device.



LEO:  Hey, I've been looking at the iPhone hack that Charlie Miller's going to show this weekend.



STEVE:  Okay.



LEO:  And it looks like it's for 2.2.1, which is the previous version of the iPhone firmware.



STEVE:  Oh, I didn't see that anywhere.



LEO:  And he says that he hasn't, at least the articles I saw, doesn't know if it'll work with 3.0.  Now, there are a lot of older iPhones still running 2.2.1.  But it would sound like it would be a good reason for me, for instance, to upgrade my son Henry's iPhone to 3.0.  And any new iPhone sold, of course, has 3.0 on it.  Now, it's possible that this weekend he'll say it also affects - but he hasn't demonstrated it with 3.0.



STEVE:  Is Apple maintaining separate...



LEO:  No.  Not normally.  You can keep 2.1 on your system if you don't agree to update.  But the current version for all iPhones, all three versions of the hardware, is 3.0.



STEVE:  Okay.  And so, and is there any rationale for people not going to 3.0?



LEO:  Well, the reason Henry hasn't is because he - we jailbroke his iPhone.  So any update will reverse the jailbreak, and he'll have to rejailbreak it.  But I think we're just going to be doing that tonight.  So any - it sounds like that's a reason to move to 3.0, you know, not noticing, not paying attention, having a jailbroken phone you don't want to mess with, there are a variety of reasons you might not want to move to 3.0.  But it sounds like that's...



STEVE:  Right.



LEO:  This might be the reason to do it.  So it may, you know, I don't know if Apple fixed it in 3.0.  Or I'm sure they fixed a lot of holes.  And we won't know till this weekend.



STEVE:  Yup.



LEO:  Very interesting.



STEVE:  So there's our mega security news update, my friend.



LEO:  Wow.  Wow.  I'm trying not to be too glum here.  At least Phorm got it.



STEVE:  Well, yes, yes, yes, yes, exactly.  Phorm got what's coming to them.  And everybody else is scrambling around, trying to patch holes.



LEO:  Trying to patch holes.



STEVE:  Yeah.



LEO:  You're right, you know, it just isn't getting better.



STEVE:  No, it's not.  There's no sign that it's getting better.



LEO:  Really interesting.  And of course because now we know there's a financial, a strong financial incentive to hack systems, that's with 12 percent responding to spam, that's why you have seen all these exploits.



STEVE:  Yeah.  There's a facility that was found and recently publicized called Golden Cash, which is a clearinghouse, run apparently by a group in Russia, where bad guys are able to go to the site and present credentials of some sort and purchase batches of bots that they want to exploit for various purposes.  So, I mean, there's now a bazaar, essentially, a commerce system established for buying and selling bot fleets.



LEO:  Well, remember we talked about the BBC buying that bot fleet for, what was it, 10 grand?  It was cheap.



STEVE:  Right, right.



LEO:  Cheap.



STEVE:  Right.



LEO:  All right, Steve.  Hey, boy, we got caught up.  That's the good news.  Next week we answer people's questions.  Go to GRC.com/feedback to ask your questions.  Actually for the next two weeks we'll have lots of Q&A.



STEVE:  Yup.



LEO:  Of course GRC's a great place to go for SpinRite, the world's best hard drive maintenance utility.  You've got to have it if you've got a hard drive.



STEVE:  [Indiscernible]. 



LEO:  Yay.  And all the free stuff Steve gives away all the time, like ShieldsUP! and Shoot The Messenger, DCOMbobulator, the Perfect Passwords.  I actually put a link up on my Twitter account to an article about the Twitter hacks and whether your password might be susceptible, and the guy said, "Go to Steve's passwords page" - he mentioned your page specifically - "if you want a good password."  Get a good password.  That's GRC.com/passwords.  It's a long password.  It's not a memorable password.



STEVE:  No.



LEO:  But it's a good password.  And we will do this all again next week.  You can watch us do it live every Wednesday at 2:00 p.m. Eastern, 11:00 a.m. Pacific.  And I don't know what it is Chinese standard time, but that's the time I'm on right now.  And I'll get off of that by next week, I hope.



STEVE:  Get some sleep, my friend.  Get your bio clock adjusted.



LEO:  Thank you, Steve.



STEVE:  And we'll talk next week.



LEO:  See you then.



STEVE:  Thanks.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#207

DATE:		July 30, 2009

TITLE:		Listener  Feedback #71

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-207.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 207 for July 30, 2009:  Listener Feedback #71.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security.  Steve Gibson is here, of GRC.com, our security guru, man who discovered spyware, coined the term spyware, writes all those great security tools and of course is the creator of SpinRite, a fantastic hard drive maintenance utility that is a must-have.  Hey, Steve.  A good day to you.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  Episode 207.  This is the one before the last one of our fourth year.



LEO:  Our penultimate episode of the third year.



STEVE:  What?  No.  No.  We're nearing the end of the fourth year.  So...



LEO:  Yeah.  So penultimate episode of the fourth year.



STEVE:  Yes.



LEO:  Wow.



STEVE:  Yes.



LEO:  Holy camoly.  Wow, that's great.  Well, congratulations on four years.



STEVE:  Here, as I'm going through the mailbag, as I did for today's Q&A, so many people appreciate the fact that we're turning these out as reliably as we are.  I mean, they absolutely - they know we will go through any means necessary so that there's always a Security Now!, new Security Now! episode every week.  And so far we're batting a thousand.



LEO:  And credit to you, because it certainly isn't me.  I miss episodes of shows all the time.  No big deal.  But today we've got a good one.  We're going to catch up because last week, where we normally do Q&A, we didn't.  So we've got a bunch of questions and answers.



STEVE:  And a bunch of errata, really just a whole bunch of interesting stuff I know that our listeners are going to get a kick out of.



LEO:  Well, let's get underway.



STEVE:  Plow right in.  Well, first of all, you had news about the iPhone texting exploit that we talked about last week.



LEO:  Yes, indeed.  You know, this is - they call him Safari Charlie.  Charlie Miller has made his name cracking OS X.  Twice now he's won laptops in the PWN to OWN competition by finding exploits nobody knew about in OS X, and certainly that weren't patched.  So he claims he's found and will reveal on Thursday - so as you hear this, he may even be revealing it right now...



STEVE:  Turn off your phone.



LEO:  ...at the Black Hat conference, a technique, yeah.  Essentially, and one question that we had last week is, you know, he had said originally it affects 2.2.1.  He didn't say exactly it affects the latest version, 3.0; but he did say it affects all iPhones, which tells me it does in fact affect all iPhones.  He can send out a series of invisible SMS messages in his hack, ending with one that has a single square character.  And at that point he has absolute control of your phone.  He can make phone calls.  He can make money by sending text messages to premium services which will then get in your bill.



STEVE:  He can turn on the camera or the microphone.



LEO:  He's got complete control.



STEVE:  See where the phone is.  He can read out your GPS to find out where the phone is located.



LEO:  And the real scary thing is that no word from Apple on a patch.



STEVE:  No.



LEO:  They don't have a whole lot of time left.  You know, so Apple, please.  And one of the things Charlie says is if you get a text message with a square in it, turn off your phone right now.  That's the only fix.  He said somebody could pretty quickly take over every iPhone in the world with this patch.  The other point that he made which is kind of sad is that he's told Apple about this a long time ago.  He says, "I've given them more time to patch this than I've ever given a company to patch a bug."  So...



STEVE:  Well, and also the fact that they did the v3 rollout, knowing that this was a problem, and didn't fix it for v3.



LEO:  It's very scary, very frustrating.



STEVE:  Yeah.  And so what's the status on pushing versus pulling these patches?



LEO:  You know, I didn't find out.  I've never had a pushed patch.  It's always been pulled.  So...



STEVE:  You have to go get it and update it.



LEO:  ...that means you have to go to iTunes, yeah, you have to go to iTunes and synch.  And iTunes will say there's a patch, and then you have to accept it, and you have to install it.



STEVE:  Well, so what we can do for our iPhone-using listeners is just put them on alert that there's big news happening Thursday.  It's not clear whether there will be clear details about how to exploit this.  That is to say, it's not as if, when this is revealed, suddenly there will be exploits.  But enough has leaked out already that other people have good clues about where this problem lies.  So again, be on alert for updates from Apple and apply this ASAP.



LEO:  Incidentally, at the same talk they're going to reveal a vulnerability in Windows Mobile SMS.  So it sounds like SMS is a vector for attack and not, because it's such an old technology, not very well defended in any platform.



STEVE:  Well, it's hard to excuse it, really.  I mean, I would say it's a simple technology.  I mean, it's just text records of 160 characters maximum.  I mean, it's trivial.  And so, I mean, but the vulnerability is what it always is, which is you've got a communications buffer which is receiving data, and obviously there's parsing problems with displaying characters and fonts or who knows what their boundary conditions are that are being exercised.  But you have a device that's connected to the Internet, or in this case the telephone system, and it's able to receive something from somebody else that is able to exploit defects in the reception code.



LEO:  He discovered the Windows Mobile flaw on Monday, so it's not like Microsoft's had any time to respond to that one.  That doesn't sound as serious, either.  That's scary.



STEVE:  Well, we do have an interesting, out-of-cycle update from Microsoft.  By the time our listeners hear this on Thursday, the Tuesday update, which is the fourth Tuesday of the month - we normally have Microsoft patches, as I'm sure all of our listeners know, on the second Tuesday of the month.  And I made the comment last week that, due to the fact that the month began on Wednesday, this was the latest second Tuesday of the month possible.  Now we're at the fourth Tuesday of the month, and Microsoft has just released two critical patches.



Essentially what - and this is the first time we've run across this.  There's a patch to Internet Explorer, but almost more significantly is a patch to the Visual Studio tool set which is used for creating ActiveX controls.  What happened is, it turns out for quite a while there has been a bug in the so-called Active Template Library, ATL, which is one of the toolkits used in Visual Studio for producing ActiveX controls, which in turn are invokable by Internet Explorer.  The flaw in ATL, the Active Template Library, allows for kill bits to be ignored in ActiveX controls.



We've talked about kill bits often because this is the bit which can be set which prevents an ActiveX control from being invoked by Internet Explorer.  I was lamenting last week that Microsoft didn't default them to being disabled and then explicitly enabled when you knew that it was a control that should be, that made sense to be invokable by Internet Explorer.  Instead, dumbly, I mean, from a security standpoint, Microsoft has them all enabled by default, and so you kill them individually once you discover that they can be exploited.  I mean, it's just completely backwards.



But what's worse is that the toolkit from Microsoft has a flaw, meaning that all ActiveX controls that anyone has ever written using this flawed library contains the flaw, which now people have found a way to exploit.  Meaning that it's a way, after you turn on the kill bit, saying whoops, we found a vulnerability in this control, use the kill bit to prevent Internet Explorer from being able to invoke it, meaning that a website you visit is able to exploit you through that channel, now there's a way to ignore the kill bit because of the flaw in the Active Template Libraries.  So these two updates, MS09-034 and 035 got added, technically added to the second Tuesday of the month updates.  I think they went from, like, 21 through 33 or something through 33.  Now they've added 34 and 35.  So they're doing it as an update to this month's patch batch.



The first one is an update to IE that you definitely want to do because what that does is that prevents this flaw in the ATL from being exploited.  So by fixing Internet Explorer, what they've done is they've updated IE so that it renders these bugs non-problematical, even when you've got ActiveX controls that were built with a flawed ATL, the Active Template Library.  And 035 fixes the Active Template Library to remove the problem, even though Internet Explorer, once patched, will no longer allow that problem to be exploited.  So I'm seeing a little yellow shield down in my tray which has been there for a day or two.  I've not yet installed these because I'm not using IE for anything other than getting itself patched.  So basically that's sort of strange.  You use your browser only to patch itself.



LEO:  Well, and other parts of Windows.



STEVE:  But that's what I'm doing.  So I imagine that our listeners will have seen that.  Reboot may be necessary after installing this.  So find a time to do it, but do it because it will help keep you safe on the 'Net.  And Microsoft has that new weird Exploitability Index indicator, and they're calling this "Exploit Code Likely:  Functional code execution is easy and reliable to create."  So...



LEO:  Oh, geez.  It's nice of them to tell us.  It's easy.



STEVE:  Yeah.  Just to let you know, it's probably going to be a good thing to patch.



LEO:  Geez.  Easy and reliable.  That's something that Microsoft might want to shoot for.



STEVE:  Easy and reliable.  Wouldn't it be nice if it was just easy and reliable to use Windows, instead of rating the malware as easy and reliable to create.



LEO:  I think they're going to change that pretty quick.



STEVE:  Yeah.



LEO:  I don't think that language is right.



STEVE:  Literally the verbiage on their security page.



LEO:  They're going to have to fix that, I think.



STEVE:  Also I just wanted to note that Windows 7 was RTM, was Released to Manufacturing.



LEO:  Yes.



STEVE:  The Final Release Candidate is still available for free download, and you can get a key.



LEO:  You won't get the RTM version, though.



STEVE:  No.  They're not making the RTM version available except to their so-called "partners," you know, people like Dell and HP and so forth, who need to have it in order to begin making sure that they're going to be integrating it into their product flow.  End-users, though, I wanted to mention, can get the release candidate, which is free, and the security key.  We're expecting Windows 7 to be released in October.  But for me, at least, we know I'll be waiting until October of 2010 because, much as it is nice, it's new.  And new means bad.  So I know that there are people who are jumping on it.  Lots of people are excited.  But even so, it's not something I'm going to be jumping on because we'll wait for it to settle down.



So Adobe is back in trouble once again, in a couple ways.  There is a critical vulnerability, and this is unpatched, a critical vulnerability in the current versions of Flash Player, v9, which, well, yeah, Flash Player v9 and v10, for Windows, Mac, and Linux operating systems.  There's a vulnerable DLL that's the offplay.dll component, which is in Reader and Acrobat for Windows, Macintosh, and UNIX.  It definitely can be used to cause a crash, and potentially allows an attacker to take control of affected systems.  There are no patches available.  Adobe has said they're going to try to get something out by this week, by the end of this week, so like the end of the July-ish.  So keep an eye on Reader and Flash and Acrobat for updates.  Maybe have it checked.



Adobe also came under some fire for the downloadable most recent version of their Reader not being the patched one.  That is, it turns out they have an official protocol for the single-dot versions to be available for download.  But the two-dot versions, for example, 9.0 or 9.1 will be what you can download.  But if there's a 9.1.1 or 9.1.2, as is the case now, where there are vulnerabilities fixed in the two-dot, what you're downloading is still 9.1.  And you must then update its security after downloading it.  They're not making the fixed one the one that you download.  And so they're under some heat for that.  I wouldn't be surprised if they changed that policy since it means that you then need to wait for the player to update.



I think probably all of our listeners are security-conscious enough that when they install something like this, they immediately go under the Help menu and check for updates.  And they'll find, oh, look, there are some, from the thing I just freshly downloaded.  But the security community is upset that Adobe by policy is making a known vulnerable version downloadable from their site.



LEO:  It should check immediately and update immediately, automatically.



STEVE:  Yes, and it doesn't.



LEO:  Yeah, that's just weird.



STEVE:  Also in security news, Network Solutions, you probably heard, Leo, had a massive credit card breach.  More than half a million debit and credit card accounts, by their count 573,000 credit and debit card accounts over a three-month period, from about middle of March, March 12th through the beginning of June, were exposed.  It was - Network Solutions found malware on the eCommerce hosting servers...



LEO:  Inexcusable.



STEVE:  I know, that 4,343 hosted customers are using for their merchant and eCommerce websites.  These are typically, you know, your smaller mom-and-pop stores where it's just like, oh, yeah, set me up with eCommerce, one-click eCommerce, and I'll pay my monthly fee, and that'll get me a shopping cart, and I can sell things.  Well, unfortunately, malware has been there for three months recording every credit card transaction which these 4,343 customers have transacted.  Obviously this has been fixed now.



There's no clear widespread agreement from a legal standpoint on the reporting of this kind of breach.  I think about 43 states have some legislation which requires in the event of a breach like this that the people who are potential targets all be notified.  So Network Solutions has said on behalf of their 4,343 customers, their hosting customers, that they will take responsibility for notifying all of these 573,000-plus clients.  And they're making free TransUnion credit monitoring available for 12 months to allow the potential victims of this to keep an eye on their credit because of course this is potentially a serious privacy breach.



Now, there has not been any indication that the cards have been used.  It may very well be that they're in a pool waiting to be sold; they haven't actually been put into play at this point.  So, I mean, upon receiving a notification, if I were one of those 573,000 people, I'd call my credit card company and say, okay, we need to kill this card and change my number and issue me a new card, so that you avoid that.  Although, at least in the case of credit cards, not so for debit cards, you're indemnified against that.



So that's good.  And then in just recent breaking news it turns out that v9 of BIND, which as we know is the major DNS server on the Internet, it's just news happening today, on the 29th, it's been - ISC, the author and publisher and maintainer of BIND, have said that there is a way to crash master servers, master DNS servers running BIND v9.  There are fixes available.  Updates are available.  So anybody who's responsible who has a master, not a slave, DNS server on the 'Net may want to update to the latest one.  Essentially it involves an exploit that's been found in the so-called Dynamic Update Messages that the server can receive.  For example, in GRC's configuration, I have a master server which is private, and I've got packet filters which prevent there from being any public access to it.  So even though I'm using v9, I'm safe.



LEO:  Of course if they're using BIND, Level 3, you know, your hosting service is using BIND, then you're not safe.



STEVE:  No, I am because - and they are using BIND.  But they're...



LEO:  Or unpatched BIND, I should say.



STEVE:  Yeah, but they're running slave servers.  That is, their servers are slaves of mine.  So that periodically they, being a slave, check in with my server.



LEO:  Ah, so they're not the canonical servers; you are.



STEVE:  Exactly.  So they periodically check in with me for any updates.



LEO:  That's probably what we should do.  Because that's what happened to us yesterday.



STEVE:  And it's very convenient because it means that when I make a change, I'm able to push it to them instantly.  I'm able to send them a dynamic update message, and they immediately update themselves.



LEO:  And because you're not publicly visible, you're not hackable.



STEVE:  Exactly.



LEO:  That's a good - we should probably implement that because I believe, you know, our domain name servers at SoftLayer were brought down yesterday, I think, and really took us off the air.  Not only, I mean, all the servers were running.  If you knew the IP address, you could get there.  But if you didn't, the DNS didn't work.  And that just doesn't mean you couldn't get to TWiT or my blog.  You couldn't get the podcasts, either.  So iTunes got confused because iTunes can't see where the feeds are coming from.  So that's something we have to address, as well.  SoftLayer, by the way, this affected a lot of sites.



STEVE:  Yeah, well, everybody who is hosted by them.



LEO:  And Bear is telling me, our sysadmin is telling me that's part of what happened yesterday was this BIND flaw.



STEVE:  Ah, okay.  Well, I need to tell our listeners about something else which is really disturbing.  This was reported recently in CNET News.  And that is, Buy.com and Orbitz and other commercial sites have been linked to what they're calling "controversial marketers."  And I would say it's even worse than that.  Reading from the CNET report, which is probably the easiest thing for me to do, it says:  "Thousands of web shoppers have complained that 'mystery charges' are showing up on their credit card statements."



LEO:  Oh, boy.



STEVE:  "And have accused those who operate so-called 'web loyalty' programs of duping them into signing up.  As a result, the U.S. Senate Commerce Committee is investigating Vertrue, V-e-r-t-r-u-e, WebLoyalty, and Affinion, companies who make 'cash back' and coupon offers to consumers and charge those who enroll in their loyalty programs."



But here's what got me about this, Leo.  This is what stopped me cold, was that when you're, for example, at Buy.com, and you're moving through the purchasing process, at one point you get to an intercept page that says "Big $10 Off Coupon," and they're asking for an email address.  And that stops you from completing your purchase with Buy.com.  Many users just think, okay, well, what is this?  And they look at it, and it's like, okay.  Then they'll, like, put in a scrap or a spare or a throwaway email account just to get on with the purchase.  What they've done is to agree to this program.  And literally in the fine print it says that they will be charged for this service.  Now, the user may think, oh, that's not a problem because I'm not giving them my credit card information.  It turns out that this is a behind-the-scenes deal with companies like Buy.com that provide your eCommerce credit card information to this third party without any additional permission.  And in Buy.com...



LEO:  Oh.  Oh.



STEVE:  Yes.



LEO:  That's my credit card.  You mean they don't ask ahead of time?  They don't say do you mind if we share your credit card number with a third party?



STEVE:  Down in the Buy-com privacy statement...



LEO:  I'm not buying anything from them anymore.



STEVE:  I know.  It says, "We reserve the right to use or disclose your personally identifiable information for business reasons in whatever manner desired."



LEO:  But credit card?  Your credit?



STEVE:  Yes.  It says, "If you think that anyone who unwittingly signs up to one of these programs must be an eCommerce rookie and that it couldn't happen to someone as savvy as you, take care that your overconfidence doesn't cost you.  Josh Lowensohn, a 26-year-old CNET reporter and longtime Web shopper, this week found that a credit card he rarely uses was billed $12 in each of the past eight months by WebLoyalty."



LEO:  Oh, I've got to look at my cards.  Oh.



STEVE:  "Last November, after almost completing a purchase at Buy.com, Lowensohn was presented with an advertisement that asked him for his email address."  And they show a sample of this on the CNET page.  "He couldn't quickly find a way to get past the page and said he remembers thinking he would type in one of his rarely used email addresses just so he could complete his transaction.  Lowensohn was confident he couldn't lose anything because the advertiser didn't have his credit card information.  But WebLoyalty didn't need Lowensohn to charge his credit card.  WebLoyalty CEO Rick Fernandes said Buy.com - for a fee - enabled his company to charge Lowensohn directly."



LEO:  This is appalling.



STEVE:  It's phenomenal.  And so the next subheading is "Web Loyalty to Whom?"  "A 10-minute Google search turns up thousands of stories similar to Lowensohn's.  Apparently, many consumers are unaware that for years now, e-tailers such as Buy.com, Orbitz, Fandango, and hundreds of others have given web loyalty programs, also known as post-transaction marketers, access to their customers' credit cards.  Some online shoppers don't realize that when they enter their email addresses into these ads, they are opting into the programs and authorizing the charges."



LEO:  Unbelievable.  Shocking.



STEVE:  "Jeff Wisot, Buy.com exec, was quoted as saying, 'We have a longstanding relationship with WebLoyalty because we think they provide value to our customers.'"



Well, what's happening is, WebLoyalty is paying Buy.com behind the scenes for credit card information from people who purchase from Buy.com.



LEO:  Wow.  Wow.



STEVE:  So I just wanted to...



LEO:  I want a list of all the retailers, etailers doing this so that I can not use them.



STEVE:  I know.  I know.  I wanted to get...



LEO:  I'm stunned that they - I can see, you know, when I hear "personal information," I think email address.  I don't think my credit card information.



STEVE:  Yup.  And so people are finding charges on their cards, monthly charges being made from companies they never directly gave the information to.



LEO:  And what are these charges for?  What am I getting?



STEVE:  It's some sort of, like, coupon offers.  And then you start getting email spam from these people.



LEO:  And they charge me for this.



STEVE:  Yes.



LEO:  So, holy cow.  And they don't say they're going to charge you.  I mean, this seems like it's borderline illegal.



STEVE:  I'll send you the link, Leo, to the story, which you'll want to put in the Twitter feed and all so...



LEO:  I will.  I'm going to tell everybody about this one.  This is appalling.



STEVE:  Yeah, it's a long story with lots of information.  So...



LEO:  This is on CNET, huh?



STEVE:  Several pages on CNET.



LEO:  Thank you, CNET, for bringing this up.  I'm going to talk about it on the - in fact, let's get you on the radio show this weekend to talk about it.



STEVE:  That's a good idea because...



LEO:  Shocking.



STEVE:  ...it's a huge, much too broad a brush.



LEO:  Unbelievable.  Yeah.



STEVE:  In fact, try Googling "Buy.com, Orbitz linked to controversial marketers."



LEO:  Geez, Louise.



STEVE:  See if it comes up.



LEO:  I haven't used either of those in a while.  But I have to think that many others are doing this.



STEVE:  I've used Buy.com in the past.



LEO:  Yeah, in the past I have, yeah.  Oh, my goodness.  Well, that's kind of shocking.



STEVE:  Yes, in fact, if you put into Google "Buy.com, Orbitz linked to controversial marketers"...



LEO:  Yeah, no, I found it, yeah.



STEVE:  ...which is the title of the story, it comes right up.



LEO:  Wow.  That's a shocker.  Thank you, Steve, for bringing that one to our attention.  Hmm.  Orbitz has some comments on here, it sounds like.  I'll have to look, scroll down and see.  Greg Sandoval is good.  He's a smart guy, so, wow.



STEVE:  Yeah.  So that's our security news.



LEO:  There's one more, I just want to warn you.  This just crossed the wire, literally, from Wired News.  And thanks, Virgil, for posting this in our chatroom.  Two noted security professionals - you know, this week is the Halloween of security because of Black Hat coming up; right?  Black Hat and DEFCON right after it.



STEVE:  That's actually a good way of putting it, the Halloween of security.



LEO:  This is when the pranks begin.  Two noted security professionals were targeted this week by hackers who broke into their web pages, stole personal data, and posted it online on the eve of the Black Hat security conference.  Dan Kaminsky was one of them.



STEVE:  Whoops.



LEO:  Kevin Mitnick the other.



STEVE:  Ooh, goodness.



LEO:  They say, the intruders say they were hacked because they considered them to be poseurs who hype themselves and do little to increase security.  I disagree, at least in the case of Kaminsky.  I mean, he's been really, really great, most recently on this DNS hole.  But I have to say, maybe he needs to look at locking his site down.  Holy cow.  Anyway, I just thought you might want to know that security researchers are being targeted by Black Hat, ahead of Black Hat, to kind of bring attention to it, I guess.



STEVE:  That is interesting, indeed.



LEO:  Holy cow.  Mitnick says it's his webhost, and I'm moving.



STEVE:  Yeah.



LEO:  Geez, Louise.



STEVE:  I had a little bit of sci-fi news.  While reading through the mailbag I ran across a note from Scott in Glasgow, Scotland, who wrote.  He said, "Hi, Steve.  I'm a regular listener of Security Now!, love it.  You and Leo are fab.  I really also like your sci-fi reviews and had this one to share with you:  "Torchwood:  Children of Earth," produced by the BBC as a five-part miniseries, a spinoff from the main TV series, "Torchwood."  In my opinion, this five hours of sci-fi is the best production to come from the U.K. in the last 20 years.  Take a look.  Hopefully you will find yourself recommending it on the show.  Keep up the good work.  Scott.  P.S.:  Show aired in the U.K. on five consecutive nights starting on the 6th of July."



Well, I could not agree with Scott more.  I watched it last week when it was airing on BBC America, and it was spectacular.  It's available already on DVD.  Mine's on the way to me.  I would say that, if you're not a "Torchwood" fan, it's probably a little difficult to get into it.  But...



LEO:  You know, I started watching, like, in the middle of the season.  So I'm going to go back to the beginning.  I hear it's very good.



STEVE:  Yeah.  And, I mean, "Torchwood" is really fun also.  They had two seasons, both available now on Blu-Ray DVD, and "Children of Earth" is essentially a follow-up to the first two seasons of "Torchwood."  I really would recommend that you see the original series first to understand the back story. But "Children of Earth" was - it was really good.  I mean, it was just - it was really good sci-fi.



LEO:  Great.



STEVE:  You know, I mean, bad alien sort of sci-fi.  So, neat.



LEO:  Yeah, yeah, can't wait to see it, yeah.



STEVE:  And I just wanted to mention for the record, I know nothing about this, but the pilot airing this Sunday on ABC of "Defying Gravity" is airing.  It's, I don't know, again, anything the show.  But a bunch of people are cooped up on a space ship which is on an extended voyage from Earth to Venus, I think is where they're going.  And so I don't know if it's a reality show, or if it's sci-fi, or what it is.  But it looks like it's relating to extended space travel from Point A to Point B by slow caravan style.  No warp speed.  So I don't know what it is, but it's this Sunday evening on ABC in the U.S.  So I just wanted to make sure people who might be interested knew about it.  I mean, my TiVo will be recording it, and I'll see if it's any good.



LEO:  It's always worth a try.



STEVE:  And then a whole bunch of people that I ran across in our mailbag commented on jetlag.



LEO:  Yes.



STEVE:  And my favorite one that caught my attention was a subject line, "Fists with your toes as a travel stress reliever."  Bryce Shaskeen, Shaskink, Shas, Shasshinka...



LEO:  I'll take your word for it.



STEVE:  Bryce knows who he is.  He said, "Dear Steve and Leo.  The fists with your toes line is from 'Diehard.'"



LEO:  Right.  Our chatroom knew that right away, by the way.



STEVE:  Oh, okay.  It's about relieving travel-related stress, not jetlag.  And then he goes on to cite literally verbatim from the movie.  I don't know if he played it and transcribed it, or if he knows it by heart.



LEO:  You can probably find it on the web.



STEVE:  And then the Richard Gere scene that I was thinking of, where I was - remember I said I kind of have this picture of Richard Gere.  That was from 'Pretty Woman" where she's trying to get him to relax and to go for a walk in the park, and he takes his shoes and socks off, just like to not be so corporate and to walk around on the grass.  And so those were his bare feet, so.



LEO:  There you go.



STEVE:  Just in terms of errata, I thought that qualified.



LEO:  There you go.  Do you want to get started with our Q&A here?



STEVE:  I will.  I do have a beautiful little SpinRite story from Matthew in Fresno.  And the subject line, again, caught my eye:  "SpinRite saved my marriage."



LEO:  Okay.  Okay.



STEVE:  He says, "Dear Steve.  Just wanted to let you know that SpinRite saved my marriage.  My mother-in-law came to me in a massive panic.  Her laptop died with a BSOD, stating that a registry hive was corrupted.  And of course she had no backup.  She had lost all the pictures of our little girl that was just six weeks old.  With my wife peering over my shoulder like a boss on a deadline, I researched the error and found the numerous pages Microsoft's knowledge base articles on possible solutions.  Each solution required me to insert the XP CD and enter the Recovery Console and do a bunch of stuff to the file system where the registry is located.



"Of course, she didn't have an XP CD.  So I rummaged through all my CDs, desperately looking for an XP CD that would work.  Then I remembered SpinRite, and all those great stories you tell on Security Now!.  So I figured, hey, can't hurt to try."  And he says, "FYI, SpinRite was purchased as a site license where I work.  I hope it's okay to use it on my home computer."  Eh, not technically, but I thank you for the testimonial, so we'll call it even.  "I put the SpinRite CD in and let it run on Level 2.  It took a little over 17 minutes to finish and did not show any errors on the display.  So I figured it wasn't the hard drive.  I ejected the CD and rebooted the computer, just to see.  During the boot process, Windows ran a chkdsk - hmm, that was new - then rebooted again.  Then it finally booted into Windows with all our girl's pictures recovered, no registry hive problem."



LEO:  Hallelujah.



STEVE:  He said, "I was immediately surrounded by hugs from both my wife and my mother-in-law.  Thank you for this great product.  Matthew in Fresno."  And of course that...



LEO:  Wow.  And, now, back it up, Matthew.



STEVE:  That's, yeah, exactly, or tell your mother-in-law.  Explain about backups to Mommy Dearest.



LEO:  Wow.



STEVE:  And it's so often the case, again, I've said before, that SpinRite will apparently not do anything, that is, it can't report it because it's worked with the drive, recovered the problem, but the result was no error left behind.  It didn't, you know, it was able to perform the full correction, fix the problem, relocate the sector, everything's good again.  And so sometimes SpinRite doesn't get the credit that it deserves because it's unable to show it because it fixes it.  But in this case it did.



LEO:  Somebody wanted to know if SpinRite can be used on SCSI or SAS drives.



STEVE:  Absolutely.  Yes.



LEO:  It's the USB that kind of hides a lot of the information.  But SAS or SCSI is not so bad?



STEVE:  Yes, exactly.  I mean, SCSI provides a lot of information.  You want the most intimate connection you can get.  So if all you've got is a serial interface, well, that's the best it can do.  But we've heard, we've had reports of it fixing Network Attached Storage drives.  So it'll work at it until it is able to read the sector, or do whatever recovery it can.  So often it's able to.



LEO:  Now, this is going to air on Thursday, July 30th.  But tomorrow is Sysadmin Appreciation Day.  So I want to appreciate all the sysadmins out there, and especially our sysadmins, particularly Bear, who was working so hard yesterday when the DNS attacks occurred to get us back online.  And Gordon, and Colleen really is a sysadmin, too.  So thanks to everybody who's working on our servers.  And Happy Sysadmin Day to all of you.  Because I know a lot of sysadmins listen.  I bet most people who listen consider themselves their own system administrator, if not for others.



STEVE:  Yeah, exactly.



LEO:  Yeah. All right, Steve.  I have questions.



STEVE:  Our listeners have questions and comments, and we're going to hear them now.



LEO:  Starting with a long question.  You ready?



STEVE:  Yeah.



LEO:  Here we go.  FireXware, writing from somewhere in the frozen north - Canada - wrote with the subject "SpinRite and Security Now! got me a job and a new hard drive."  Hello.  I'm a Security Now! fanatic.  I started listening only a few months ago.  I finally caught up.  Wow, in a few months to listen to 207 episodes is pretty good.  Impressive.  I'm pleased to say I finally had a chance to use SpinRite in a real data recovery situation.  Being 16 years old - aw.



STEVE:  I know.



LEO:  I love that - and the only tech-savvy person in the house, Mom came to me with a laptop that wouldn't boot.  I turned it on, saw the Blue Screen of Death instantly.  I knew what to do.  I pulled out my copy of SpinRite, let it run on Level 2 for an hour or so, and to my mother's amazement the laptop booted like new.  This impressed her so much she wanted me to come into her office and help out with some other tech problems, also to develop some software for her to make her life at work easier for her team.



One of my tasks was to fix a laptop that would not connect to the network.  I saw the network was secured using the terrible WEP protocol.  This guy's been listening.  I asked Mom for the password.  And well, let's just say I started laughing harder than ever when I discovered their WEP key is the first five digits of the office phone number.  Oh, dear.  By the way, I was looking at what Dan Kaminsky's passwords were?  His root password on his system was five characters.  Five alphabetic characters.  Dan.  Anyway, sometimes even the smartest people do that.  So that makes me feel better because I do stupid things all the time.



I was so shocked, I started talking about security with my mom, who is the most tech-savvy person in the office.  I discovered every user used the same password, and it happened to be the password is the one first on the list of many of the password-cracking tools.  They have lists, you know, bad passwords.  No. 1 on the list.  Using the knowledge I gained from listening to your show, I wrote up a quick proposal that described the threats and vulnerabilities the network is susceptible to, and how to fix it.  After the manager of the company had read this, he hired me to fix the security holes.  16-year-old kid.



Today I've earned enough money working that I'm able to afford a new terabyte hard drive which I've been wanting for ages.  I will definitely be SpinRiting it periodically.  Thanks so much for your amazing piece of software and equally amazing source of security and insecurity knowledge.



I also have a question.  I love the concept of small is beautiful.  Every line of code I write goes by that motto.  I think that's good.  Functional and elegant.  I would love to learn how to program in Assembly language.  I understand the basic instructions and how the register and stacks work.  However, I'm confused by the infinite amount of flavors of Assembly language there are.  I would like to know which flavor is your personal favorite for writing on Windows machines, and if you know of any resources to hone my skills in developing a GUI application in Assembly.  Once again, thank you very much.  Wow, what a nice, nice letter.



STEVE:  I just really liked that.  I loved that he was 16 years old and out there getting going and doing the work.  To answer his question, he referred to, he says, "I love the concept of small is beautiful."  Well, that's the name, SIB.zip, of a little ZIP package that I have on GRC off of my own personal page at GRC.com, where I have all of the source for a simple, complete little Windows executable, with all the source code, written specifically as a little demo of here's a simple application written in Windows.  To answer his question, I'm using Microsoft's Assembler, MASM, M-A-S-M.  And there's a tremendously useful site, MASM32.org, that I would recommend to this listener and anyone who is interested in getting started.  They've put together a complete, essentially turnkey package of all the files that you need that you can download and install that sets you up to write Windows applications in Assembly language.



LEO:  So there's really - there's only one Assembly language.  What he's talking about is the Assembler.



STEVE:  Well, and actually the different Assemblers do have differences in the Assembly language.  There's one machine language.  So the actual machine language is fixed by the chip itself.  But you could have different ways of mapping, you know, ASCII Assembly language down to the binary of machine language.  So, for example, some assemblers use, for example, in an add instruction, you add two things where the second one is added to the first one.  But you could also, in Assembly language, express it where the first one is added to the second one.  So Assembly language can vary in terms of the way you express what you want the chip to do.



LEO:  That makes sense; right.



STEVE:  But it ends up always assembling...



LEO:  There's only one machine language.



STEVE:  ...[indiscernible] binary code.



LEO:  Yeah, yeah, yeah.  Although, you know, I mean, Intel has a specification for the Assembler code most people adhere to.  I mean, it all looks pretty much the same.



STEVE:  And that is exactly what MASM is.  If you look at Intel's PDFs, which are freely available and downloadable, their spec is what Microsoft implemented for MASM.



LEO:  It's MASM32.com.



STEVE:  Oh, dotcom, you're right, dotcom, not org.



LEO:  Actually, Bobcat, thank you for catching that.  Good catch in our chatroom.  They're so quick.  Chris in  Australia wonders about the new attack on AES-256.  Oh, I haven't heard about this.  I thought AES was really secure.  I'm sure you'll cover the new attack on AES that reduces the complexity for recovering an AES-256 key to 2^119 - okay.  I'm a little, feel a little bit reassured - and possibly less.  See Bruce Schneier's blog.  I've read that the attack does not affect AES-128.  Why is that?  And if this attack cannot be modified and applied against AES-128, does that mean that AES-128, with a complexity of 2^128, is now more secure, I guess, than AES-256, since 256 has been reduced to 2^119?  That makes sense.  Is 128 the way to go?



STEVE:  Well, okay.  Here's the problem.  There's been a lot of conversation over in the GRC newsgroups about the strength of AES.  And for example I already have a CryptoLink newsgroup that's been very active where people have been suggesting things and discussing things, and I'm working toward getting ready to start coding that.  And so people have said, well, gee, Steve, will CryptoLink support AES-256?  My original answer was no because there's just no need for it.  128 is so many bits long in key that, I mean, we're just - I have to always remind people that the numbers, like even though 128 is only twice as big as 64, in terms of the number of permutations of keys, every single bit you add doubles.  And when you double something 64 times, it belies the complexity that results.  So AES-128 is absolutely as safe as you could ever need.



But there is the U.S. government says that 192 and 256 are - they've got, like, ratings of secrecy.  I can't remember now what the designations are.  But it's like top secret, or super secret, or secret.  And just these are arbitrary, that's nonsense.  But that's the nature of some of the things that government does.  So since the technology is there, it's like, okay, why not let CryptoLink run in 128, 192, and 256, if that's what people want?  And so it's like, okay, fine.  So 256 is incredibly strong, I mean, like ridiculously strong.  It's there because we could do it.



And essentially the idea is - we did a whole podcast on the way the Rijndael cipher works.  Schneier agrees, Bruce Schneier agrees that this in no way weakens the use of AES-256 for encryption.  What this is, this attack is a subtle, purely theoretical weakening.  And the word "weaken," there's no way not to use the word.  But unfortunately it's the best word we have, but it does not convey the truth.  Bruce agrees that it is theoretical, and it will probably always remain theoretical.  It's way out in cipher land where the cryptographers operate.



And this is called a "related key attack," where if somebody had access to the keys, you could make small changes to the keys, changing only a few bits, and map how the so-called "key schedule" changes.  You may remember that in a symmetric cipher like AES there's a key setup where you feed it a key, it runs the key through a bunch of pseudorandom tables which are established by the definition of the cipher to create sort of a - it's also called "key expansion" sometimes.  You take a relatively small key.  You run it through these pseudorandom tables, and it expands that to a bunch of keying material.  And it's then you use the keying material for each round that you run the cipher through.  And AES has a number of different rounds, depending upon the length of the key.



Some earlier attacks, so-called "attacks," again, in quotes, were only applicable with so-called "reduced rounds," where you, okay, you didn't really use AES because AES specifies how many rounds to use.  You use the machinery of AES with a reduced number of rounds.  And again, this is a way that cryptographers, operating out in crypto land, have of sort of creeping towards an answer.  It's like, okay, they're just learning more about what this cipher does, what its characteristics are, how it acts, how it operates.  And so this related key attack says that there have been other related key attacks which have been more limited in scope.  This one is more general.  And the idea is we can take a key, make a few bits of change out of the 256 bits of the key, and track how those changes propagate through the expansion of the key and learn something about it.  And what we learn is that not as much changes as we were hoping.



So what you want in a so-called, like in a theoretically perfect cipher, is any changes in the bits of the key completely change the action of the cipher in a way that can't be predicted, can't be penetrated.  So this is purely, at this point, sort of a theoretical weakening such that it turns out that the 256-bit length is not as strong in the presence of somebody manipulating the key.  Okay.  The only time that might be useful is when the cipher is being used in a hash function where the data that you're hashing, depending upon the hashing algorithm, might provide input to the keying input of the cipher.



Remember that a cipher, if we view it as a black box, has a key, and then it's also got data.  So the data is the block width, or the block length of a cipher.  And the key length varies.  So it's only in the case where you have a use of the cipher where you might have control over the key or know what the key is that even then this represents any weakening.  But in all normal uses, for encryption, for example, in a VPN, or in SSL use of AES, there what is always secret is the key.  And no one monitoring the channel, no one trying to crack it, has access to the key.  The key is specifically what you're keeping secret.  So there's no ability - the protocol, as we've talked about SSL, for example, generates the key in a way that prevents anybody from controlling it.  The ends use pseudorandom generators to create their pieces of the key.  And then they communicate in a way such that no one monitoring this is able to get the key, let alone control it or change a few bits of it or do anything with it.



So this doesn't apply in any way to normal symmetric use of AES for encryption and decryption.  It's only theoretically interesting in cases for - really just for cryptographers.  So this is like way out in academic cryptography.  Because the words like "weakening" and "attack" are the way these guys talk in their academic papers, it generated some headlines.  And Bruce isn't worried.



LEO:  Good.



STEVE:  So that's the story with this AES attack.



LEO:  Good.  That's why we ask Steve these tough questions, so he can explain, it's okay, it's going to be all right.  Now, here's one about jetlag.  This show covers a wide range of topics, from sci-fi to jetlag to Vitamin D...



STEVE:  And I'm not even going to talk about Vitamin D until next week, Leo.



LEO:  Okay, good.



STEVE:  Although I did take my second test this morning, as I took my first test a week ago Wednesday.  I have my results from the first one.  But I'm going to wait till we have results from one week of me laying out in the sun.



LEO:  With a new technique.  Well, I'm drinking - somebody, the company called Balance sent me some Balance Water for Travelers that has all these Australian flowers dissolved in it:  she oak, grey spider, tall yellow top, crowea, bush iris, and mulla mulla.  So I don't know if this is going to help.  I'm still a little jetlagged.  I'm still waking up early in the morning.



Anyway, this is John Hughan in San Francisco.  He has a cure, he says, for jetlag:  I heard the two of you, especially Leo, sometimes have trouble with jetlag.  I'm going through a hellacious jetlag coming back from China.  But every time I go those long, you know, Australia was the same thing last year.  Those 15 time zones just will kill you.



STEVE:  Yeah, see, I don't move very far, so I'm not having that much problem with jetlag.



LEO:  That's a long way.



STEVE:  You're doing big chunks of the globe.



LEO:  I used to do Toronto every month.  That wasn't a problem.



STEVE:  No, no.



LEO:  I got a little tired coming...



STEVE:  And I did it with you.  We really didn't even notice.



LEO:  No.  Though I have to say, always harder recovering, coming West, or going East is harder than coming West.  In other words, coming back from China was worse than going to China.  Going to Europe is worse than coming back from Europe.  For me.  He says:  I wanted to mention a book  that I've used that has helped eliminate jetlag, no matter what direction I'm traveling in or how many time zones I've crossed.  I've done up to 10.  Evidently it's based on a 

handbook that the military uses, and it primarily involves eating certain kinds of foods at certain times starting a few days before the flight.  The book is called "Overcoming Jet Lag" by Charles F. Ehret, E-h-r-e-t.  You shouldn't have any problem finding it on Amazon or other booksellers.  See, the problem here, I want to see a double-blind study.  The problem is there's a huge mind component in this.



STEVE:  Sure.



LEO:  So all of these cures, as long as you believe they're going to work, are going to work.



STEVE:  Well, and you want them to work because you bought a book.  And so it's like, oh, you want the book to be right.  For what it's worth, we put "Overcoming Jet Lag" into Amazon search.  And sure enough, you can find a bunch of used copies of this for $4 and some odd cents.  It is available on Amazon for anyone who's curious.



LEO:  But of course after you spend all that time getting jus the right foods in ahead of time, I'm sure that helps, just because you've invested so much in it.  I would like to know more.  I'm going to do - I have to - you do your Vitamin D.  I'm going to do my jetlag study.



STEVE:  Okay.



LEO:  John Kennedy from Metairie, Louisiana asks Steve to touch the bleeding edge.  Yikes.  Hi, Steve.  I'm a long-time SpinRite customer and Security Now! listener.  On the Security Now! netcast, I often hear you comment that you do not use current software versions because they are unstable and unproven.  Some examples come to mind, your comments on sticking with XP and FireFox 3.5 even though - actually you didn't say 3.5.  You said 3.0, I think.



STEVE:  No, and he means not going to 3.5, even though 3.5.1 is available. 



LEO:  Oh, all right.



STEVE:  I think.



LEO:  You're using, just to be clear, XP and 3.0; right?



STEVE:  Yes, and happily so.  3.0.12.



LEO:  As a computer consultant and software developer for the past 25 years, I appreciate, respect and agree with your position.  From a consultant's perspective, I do not like my clients using the latest versions of products or patches for the same reasons you mention.  Patches.  When he says "patches," that worries me.  However, as a consultant I have responsibility to use and test the new versions of software and patches to insure their benefits and side effects, thus becoming the guinea pig.



As I listened to your latest - I'm the guinea pig here, by the way.  I use everything.  I like it new.  I like new, shiny stuff.  As I listen to your latest Security Now! episode, a thought hit me:  I wonder if Steve would consider breaking from his policy and providing review and analysis of version updates and patches.  Of course, by "breaking policy," I don't mean using these updates in your production environment.  I was thinking more in terms of using a virtual or test machine solely for evaluating updates.  I believe your perspective and the level of analysis you bring would be of tremendous benefit to your listeners.



Right now, I believe most of the information that surfaces with each software update is from a journalistic perspective.  It would be great to have technical information and review from a respected and trusted person such as yourself.  I always thought that's what journalism was supposed to do.  I think what he means is the journalists tend to be rah-rah about this stuff now.  Please give this some thought and consideration.  Thanks for your work on Security Now!.  Looking forward to your other works in progress.  Comments?



STEVE:  Well, if I didn't have a day job.



LEO:  [Laughing]  Yeah, who has time to do that?



STEVE:  We're talk- yes, we're talking about, I mean, I appreciate John's suggesting that maybe I would be a good person to do this.  And I have done it inadvertently, for example, when I made the mistake of updating my Windows XP to Service Pack 3, and it hurt me, and I told everybody ouch, be careful, I got hurt, don't you get hurt.  But those are expensive and inadvertent things for me.  I made the mistake of trusting a service pack which, you know, obviously is like a set of patches, as John was talking about.  The problem is these - generally these things are tested before Microsoft lets them go, for example, or Mozilla lets them go.  As far as anyone knows, they're releasing something that's working.  So it takes boundary conditions to find the problems.  It takes a large number of people, all pounding on it in different environments to find those situations where it may not work.



For example, Service Pack 3 worked for many people, most people, and other of my systems.  Not, unfortunately, just my main one.  And Microsoft's bugging me about it now all the time.  You really should install Service Pack 3.  It's like, you know, I tried that.  Didn't work for me.  So I would - conceptually I love the idea.  But there's just no practical way for me to run a production environment and a non-production environment because it's only by using these things that you find the problems, and by that point it's often too late.  So, and especially when we're talking about security.  I don't want to run with something which is potentially lowering my security because I'm proud of the fact that my defensive walls are as high and thick as they are, and that I'm able to get the work I need to get done, done, without things crawling in, and not having experiences like Dan Kaminsky.



LEO:  Dan Kaminsky, yeah.



STEVE:  Exactly.



LEO:  He says, if you go out on the battlefield, you're going to get shot.  So Steve says, I'm not fighting that battle.  I understand that.  What about, though, I want to...



STEVE:  Well, no, I've got my armor on.  And someone says, yeah, but...



LEO:  You're not going to take it off.



STEVE:  ...we want you to see if those bullets are pointy or not.



LEO:  Yeah, how do they work?  But it does make me nervous that he says "patches" because - and I understand this is an issue because...



STEVE:  Patches have hurt people.



LEO:  Yeah.  But at the same time, don't you run a pretty big risk by not applying those patches?



STEVE:  Yeah.  I do think there you begin to tip, you reach a tipping point where it's like, eh, it's probably better to patch and hold your breath.



LEO:  There's no perfect solution on this.  Steve doesn't use JavaScript.  I do.  There you go.  I'm just living on the cutting edge.  And by the way, you know, knock on wood, not been hacked yet.  Andrew McKinnon in Brisbane, Australia - although I'm worried about my iPhone in about 24 hours - wonders about his iPhone's Internet address:  Hi, Steve and Leo.  My question relates to the iPhone.  Basically, until a month ago, my iPhone was reading my IP address as 144.233.xxx.xxx.  However, on recent days it's been 10.1.xxx.xxx.  Am I right - I think I know the answer to this.  Am I right in assuming that my iPhone is now being proxied by my ISP as this seems a private address from a router, much like I find in my home netcomm.  Funny thing is my iPhone only does this in certain areas, and it's always on cell networks.  Oh, okay.  I thought he was using WiFi.  He says, no, I'm not using WiFi.  If my ISP is proxying my traffic, what's the purpose of this, and why do they only need to do it in certain areas?  Well, that's interesting.  Let me look at my iPhone IP address.  What's going on there, do you know?



STEVE:  Yeah, it's, I mean, it's nothing surprising.  In one case, that 144.233, his phone was given a public IP by...



LEO:  From the ISP.



STEVE:  Yeah, exactly, by whatever ISP and region he happened to be in.



LEO:  In this case his ISP is his wireless carrier, of course.



STEVE:  Exactly.  And in another case, located somewhere differently, he had a 10.1.xxx.xxx IP.  I know that when I was using - Verizon is my carrier, and I was using a wireless broadband card.  And in fact one of the problems I had with OpenVPN that caused me some concern was that - I think it might have been, in fact, when I was in Vancouver with you, Leo.  I received there a 10-dot IP address that was the same network subnet as I was using at home.  And so OpenVPN, that uses a routing table in order to route packets, was confused because it thought I was at home and wasn't able to route the packets out the VPN to my network at home.  So, and that was another one of the things that I said, oh, I'd have a better solution for that, and I'm going to write my own.  But all this is, basically, is an ISP who's got you behind NAT.  It's not necessarily a proxy, although it is also the case that some cellular systems will proxy, for example, web access, and that their web proxy is designed to deal with the presumably small screen of a telephone.  It may rescale images down.



LEO:  Right.



STEVE:  So it's minimizing its bandwidth.  It's not sending you a big, huge PNG file that then gets scaled in the phone. That's dumb.  Instead it's scaling it on a high-speed, high-performance server down to a small physical size, then sends a much smaller file down to your phone.  So there you are seeing web proxying for the benefit of an improved web surfing experience.  But in this case it looks like in one case you were behind NAT, and the other case you weren't.



LEO:  Yeah, I don't think the iPhone browser Safari does that web proxying.  We know Opera does, and a few other browsers.



STEVE:  Yep, and I know that I have the option on a Treo to do that or not, like to - they call it "extra web acceleration feature" or something like that.



LEO:  Right, right.  It's possible that your Internet service provider, your wireless provider does something like that.  That's an interesting question.  Why would it change from place to place?



STEVE:  Well, I think it's just different carrier setup in one location or another.  So it's just, you know, it says, like, okay, I mean, it really doesn't matter technically what your IP address is.  For example, you never really paid attention to it, Leo, and you're about as techie, you know, a user as there is.  So it's just my phone works, it's got an IP, the traffic's coming back to me.  Andrew was saying, hey, you know, why is it different and what does that mean?  And so, I mean, technically it means that they're just different setups for the way the traffic gets back to you.  One is back through a NAT, where certainly that 10.1, as we know, the 10.1.xxx.xxx, that address cannot go out on the public Internet because 10 is one of the nonroutable networks like 192.168 is a nonroutable network.  There is no - if packets were sent out on the 'Net that were destined for 10, or that came from 10, there's no way that the packets would ever get back to you because 10 is a reserved private IP space.  So as your phone's packets, which are coming from 10.1, go to your ISP, they are then NAT'd back to some public IP that allows them to go out on the 'Net, come back to that same point, and then get turned back into 10-dot as they cross through the wireless link back to your phone.



LEO:  Just as a router does.



STEVE:  Exactly like...



LEO:  It's a router.



STEVE:  Exactly, yes.  And we know, for example, there are even some cable providers that have their customers behind NAT.  So even cable modems sometimes get a private IP because the ISP presumably is running short of IP space and has NAT'd all of their clients, all of their customers.



LEO:  Question 6, Kevin Ghadyani from Overland Park, Kansas worries about the number of HTML errors and warnings on the Security Now! page of GRC.  Steve, when he runs it through the W3C validator he gets 13,853 errors and 24 warnings:  I thought you would've fixed yours because you're like that, but even MSN.com validates.  I'm extremely surprised to see this and hope you'll fix the errors over time.  I've never personally seen so many errors in my life.  I run a site, badmarkup, which I use to talk about this stuff.  And when I get some time this year, sometime in October, I'll be going around looking for this stuff.  Please don't let me have to discuss GRC on the site.  I think you should discuss GRC, Kevin.  Why are you getting all those errors?



STEVE:  Absolutely.  Well, this comes up from time to time.  We'll see postings in the newsgroup.  Somebody will have run a page, just because they have spare time, I guess, through the W3C validator, and it just explodes.  I mean, somewhere there's smoke coming out of a validator in Sweden or Stockholm or somewhere.



LEO:  I've never seen anything like it!  Yikes.



STEVE:  13,853 errors.  My pages are designed to work.  And, for example, there's all kinds of tricks that it's necessary to play in order to make things work on old and new browsers.  GRC's script-free menuing system, which was developed painfully over the course of many months with a huge bunch of testers in our newsgroup, manages to work beautifully on every web browser.  But it's a validation nightmare because of all the tricks I had to play in order to work around differences between web browsers.  If web browsers all worked correctly, then, yeah, one batch of HTMl would work everywhere.  My stuff is designed, not to validate, but instead, huh, to work.  And it does.



LEO:  Well, I mean, in theory the idea of validation is that it would work on all platforms that were compliant.  So is it the platforms aren't compliant, or that...



STEVE:  Yes, it's that there are subtle differences, for example, in the way Safari handles CSS from IE.  And so you can give the same code to two browsers, and it will look different.  And when you're trying to design something as tight as the menuing system, where spacing and positioning and, I mean, it really has to be geometrically perfect, it turns out you discover how nonstandard browsers are from one to the next.  I mean, remember that IE8 even has a list of sites where it falls back to IE7 because in IE8 they're more standards-compliant than they were in IE7, which breaks sites which were deliberately tuned to work under IE7.  So, you know, who's fault is that?



LEO:  Right.



STEVE:  I mean, I have - if someone does hold their breath and pinch their nose and stick the Security Now! page through the W3C Validator and actually look at the errors, they'll find they're not big things.



LEO:  What are they?



STEVE:  They're little things, like I put quotes around numbers in some cases where they're not supposed to be, or I used old margin callouts on image tags, which used to be supported, but aren't anymore.  



LEO:  That's what I thought it probably was, is that you're using HTML 1.1, for instance.  You're using an old HTML.



STEVE:  Yeah.  I code my stuff by hand rather than have some big prophylactic web authoring thing so that my code just looks like some horror.  If you've looked at some of these pages, you can't read them.  Mine is all legible because I wrote it in Notepad.  But I did it very carefully, and it works.  Doesn't validate worth beans.  But it runs on all browsers.



LEO:  You might be able to, I don't know...



STEVE:  Leo, you know what?



LEO:  You don't care.



STEVE:  I don't care.



LEO:  That's the bottom line.



STEVE:  I have so many more pressing...



LEO:  You might be able to put in your prologue code something that will tell the validator, oh, no, this is a valid 1.1...



STEVE:  If I just told it to buzz off.  Oh, no, you can't do that, either, Leo.  It breaks other things. 



LEO:  Moving along, Question 7, Mike V. in Greeley, Colorado.  He *really* wants security.  NOTE:  I am totally okay with you reading this on the show, he says.  Hey, Steve.  I'm only 14 - I love it, all the kids that listen - but I love your podcast, and every episode is a journey into the complex world of security.  I'll second that emotion.  I wish I could say that I've listened to every one of your shows, but I just started tuning in in March.  Well, come on.  Don't be a slacker, Mike.  You can just listen to a couple of hundred episodes all at once.  I have a system for mobile USB security.  I wanted to make sure it was totally safe.  I've encrypted all my files on my USB drive with TrueCrypt, with a password from your Perfect Passwords system.  Sounds good so far.



STEVE:  Yup.



LEO:  The password for that is stored in a text file on a drive, actually on the same drive, which I encrypted with 7-Zip, which is what you were recommending; right?



STEVE:  Yup.



LEO:  Oh, no, you recommended the PKWARE ZIP program.



STEVE:  Right, SecureZIP.



LEO:  SecureZIP.  The password for that zip file is another Perfect Password, which is stored in a text file on a separate thumb drive I always carry with me.  This is the problem with the Perfect Passwords, they're not memorable.  So you kind of have to write them down or store them somewhere.  So he's trying to get around this problem.  THAT text file is in a zip with a password that I've memorized.  So tell me, he says, am I going too far with this encryption?  I don't hang around computer hacker conventions too much - too much - but I am worried about people getting to my passwords through Firefox Portable and Google Chrome Portable.  Do you think this is a viable method, or is there a better way to make the USB drive 100 percent secure?  Thanks for the show.  Best wishes for the future.  Mike V.  Hmm.  Seems like it's inconvenient, I'll say that much.



STEVE:  Well, and actually it isn't that secure.  It sounds good.  Because he's got a whole bunch of the Perfect Password gobbledy-gook that he's sort of encrypted in a chain.  But the problem is, it's a chain.  And at this point 80,000 listeners know what that chain is.



LEO:  Right.



STEVE:  The end of the chain is a simple password that he memorized.  So really that defeats everything else.



LEO:  He should just use that simple password for TrueCrypt.



STEVE:  Well, any one of our listeners - well, no.  You don't want to use a simple password for TrueCrypt because that's the vulnerability of TrueCrypt, the only vulnerability, is brute force.  And so if he has a simple password for TrueCrypt, then it could be brute-forced.  The problem is, 80,000 people now know what his protocol is.  So there was some obscurity there until we read this on the show, which he's totally okay with.



LEO:  That's called, by the way, security through obscurity.  And maybe he's obfuscated it.  Maybe he doesn't really do it that way, or he left out a step, or...



STEVE:  Well, so the problem, though, is that the end of this chain, I mean, the reason I liked this question is that it's a perfect model for something that seems secure, but when you think about attacking it, it says whoops, wait a minute.  The end of that is a memorable, memorizable, simple password.  So everyone knows the protocol now who's listening to the show.  So all any of us would have to do is try to guess the password for the final zip...



LEO:  They'd have to have physical access to the other key, too. 



STEVE:  Excuse me?



LEO:  It's on a separate thumb drive, so they'd have to have some physical access, as well.



STEVE:  Right, right.  So we - but presumably, now that we know that, there's no protection for any of his so-called protocol that he has.  So we guessed the simple password to unzip that file.  That gives us the password for the 7-Zip, which we use to unzip the password for the TrueCrypt, and then we have the access to the USB drive.



LEO:  So he's really trying to make it obscure by complexity and obscurity as opposed to genuine security.



STEVE:  Correct.  And I would argue that...



LEO:  Well, what do you want him to do?  Memorize a Perfect Paper Password?



STEVE:  Or take the Perfect Paper Password, and then customize it in use.  So, for example, cut and paste it into TrueCrypt, and then make some changes to it that only he knows.  So he's essentially done a multifactor authentication.  By starting with the root of a Perfect Password, he's got something full of debris that cannot be brute-forced.  But by then making some changes, putting a couple extra characters in, in places that he memorizes, which is easy to do.  You've broken it so that you just can't use the Perfect Password.  You have to use the Perfect Password plus some changes that only he knows.



LEO:  Oh, that's clever.



STEVE:  And that's extremely secure.



LEO:  That's the problem, and this is the whole issue with secure passwords.  The more secure they are, the harder they are to remember.



STEVE:  Yeah, exactly.  And we have an interesting suggestion about that coming up.



LEO:  Oh, good.  Well, let's get to it.  I mean, sometime.  This is another 16 year old.  Question 8, Scott in Upstate New York makes a brilliant observation about Firefox Privacy:  I'm 16 years old, and I've been listening to Security Now! since Episode 25.  Your show has taught me everything I could ever want to know about security and how my computer and the Internet works, to boot.  Keep up the great work.  Anyway, a few episodes ago you discussed how Firefox remembers how you zoomed the page of a website you visited.  I had noticed this in the past, but I didn't know it was a "feature."  The question is, could this be a security or privacy concern?  Firefox retains the zoom setting even after you have cleared private data.  Therefore, it must be saving the websites you have zoomed somewhere.  This cache denies you the plausible deniability and privacy provided by clearing histories, cookies, et cetera.  I poked around about:config, but this sheds no light on my question.  So is it a security/privacy concern, or am I blowing it out of proportion?  By the way, no SpinRite yet.  My parents won't buy it until something fails.  But you can guess what I am going to do with my first paycheck.  Well, that's an interesting - boy, that's an interesting point.



STEVE:  It's brilliant.  I mean, that's why I said I think this is a brilliant observation.  So Scott has noted that, if you change the zoom level on a website, Firefox remembers it.  We talked about that as a feature.  He noted that that isn't forgotten when you clear your personal data.  And arguably, it should be because you lose, as he said, plausible deniability about never having been to the site before.



LEO:  So it's a per-page setting.  It's not global.  It's for every page you visit there's a different setting.



STEVE:  It's a per-site setting.



LEO:  Okay.



STEVE:  Yeah, per website.  Or maybe per page.  I think it's per domain.  I would imagine that's what Firefox would...



LEO:  In any event, it's somehow, somewhere, storing the name of a domain and your zoom settings.



STEVE:  Yes.  There was a really interesting privacy hack that went around maybe about a year ago where there was a way that JavaScript could test links to see whether you had visited them or not.  Remember how on many browsers a link that you have visited will be a different color.  And there was a way to get JavaScript, just by itself, to, like, check the color of a link that it itself created, sort of off-screen, and that allowed it to determine whether you had ever been to a given page.



LEO:  Wow.



STEVE:  So it was a really interesting privacy hack.  And this is sort of similar to that.  So I just wanted to give  Scott a tip of the hat.  I think that's, I mean, he's thinking like a security and privacy person.



LEO:  Now, we don't know where this information is stored or how accessible it is.



STEVE:  I haven't pursued it.  I just loved the question.  And I assume that, given the way this is written, looks like Scott knows what he's doing.  He talked about clearing the private data and realizing that Firefox remembered zoom settings, which said, oh, someone's been to this page before and changed the zoom.



LEO:  Yeah, they should clear that, as well, shouldn't they.



STEVE:  Yeah, they should.



LEO:  Yeah.  Patti Clark, who was, oh my goodness, an early CompuServe employee in Knoxville, Tennessee, remembers with us.  We were talking about our CompuServe email addresses.  I was listening to Episode 205 on Lempel and Ziv when my ears perked up on the CompuServe segment.  I spent most of the 1980s as an employee of CompuServe.  You were correct when mentioning that CompuServe was a time-sharing company, and H&R Block was their parent.  The computers behind the Consumer Information Service were DEC System 10s and 20s.  That's what they called - CompuServe was called CIS.



STEVE:  Right.



LEO:  I had the pleasure of working with one of the system programmers who had pulled together a handful of games and created the forum - precursor to bulletin boards and chat rooms - software.  The idea was indeed to do something with all of that computing power that was sitting mostly idle during the evening hours.  It surprised management when it took off and ultimately became what the company will be known for in history.  AOL bought CompuServe from H&R Block some time back.  Back then, modems started as 300 baud acoustic couplers - that's what I used to log onto CompuServe when I first started doing it - then later 1200 and 2400 baud modems were comparatively fast.  Everything was text-based.  Yeah.  We were on the "bleeding edge" when we brought email to larger corporations and the federal government.  Sorry, my reminiscent hat has slipped on.  Anyway, I enjoy your program, and I learn something new each week.  Thank you, Patti Clark.  75106,3139.



STEVE:  I just thought that was neat.



LEO:  Yeah.



STEVE:  And, you know, I don't know what it is, but the nostalgia factor for me, like remembering taking the Series 500 phone, that was the number of the standard blocky telephone that we had at the time, and pushing it down into the acoustic couplers.



LEO:  Yes, they had little suction, little kind of rubber things that you would - so it would seal the noise out.



STEVE:  Yup.



LEO:  Wow.  And 300 bits per second was the fastest that could go, that system could go.



STEVE:  Yeah.  I mean, and there your - that was 30 characters per second, and you could just sort of see it painting the line, the way they still do in, like, kind of hokey B-grade sci-fi movies where the text comes out slowly.



LEO:  That's how I played...



STEVE:  So very cool.



LEO:  ...Colossal Cave, Crowther and Woods' Adventure.  They had an extended Colossal Cave that I played quite a bit, many, many hours, on 30 characters a second.



David Cox in Colorado Springs reports Security Now! almost killed him.  Hi, Steve.  I began listening to Security Now! shortly after you and Leo began with Episode 1, while I was stationed in Cornwall, England with the U.S. Navy.  I drove one of those tiny Smart cars back then, you know, the poor man's Mercedes. It was called "Smart for Two," and they are slowly growing in popularity now here in the States.  Actually I got - I reserved one, and it came, and I said, nah, I'm not going to buy it.



STEVE:  Yeah.



LEO:  Kind of seemed a little dangerous.  Fantastic gas mileage; easy parking anywhere.  No, I haven't totally lost it.  There is actually a point to this ramble.  So I'm driving to work early one morning on those very small, windy English roads, listening to the latest Security Now! episode.  It was dark, rainy, foggy, and I was completely lost in the show.  Suddenly, less than 30 feet in front of me, a big lorry - a.k.a. a big-ass truck - went flying past me from right to left.  I had been driving this road for several years already, and I knew my turn was up there.  But as I said, at that time I wasn't in England driving to work. Rather I was sitting somewhere in Irvine at a Starbucks with my Venti Caramel Macchiato, totally engrossed in what Steve and Leo had to say about information systems security.  By the way, I was the Information Assurance Manager for my duty station at the time.  What a nice story.



STEVE:  Isn't that neat?



LEO:  So back on this wet road, in dark fog, I suddenly snapped to reality, yanked the steering wheel counter-clockwise as hard as I could, and miraculously found myself directly behind the truck that had woken me up from security school.  I don't know how the car didn't flip over, or how I avoided the oncoming traffic, or why my driving instincts were so damned good that one early morning.  All I know is I lived to listen to many more of your shows, which incidentally have since gotten me through the diagnoses of leukemia, a bone marrow transplant, and now lung disease and possible double lung transplant.  Oh, David, I'm sorry.  Your shows have kept me sane and given me something fun and informative to look forward to each week.  I for one applaud you for not missing a single episode.  I am also a loyal SpinRite owner and user.  It has saved my bacon a couple of times, although it didn't help Dad on his RAID-configured system.  I'm guessing operator error.  Well, keep up the great work, and I am really, really looking forward to CryptoLink!  As a side note, what do you know about DNSSEC?  It appears to be DNS with authentication added for increased security.  Maybe a short mention, or is there enough for a dedicated episode in the future?



STEVE:  Well, first of all, I just wanted to thank David for his story.  We get just such great mail in the mailbag from our listeners that it's just - I wanted to share some of these sometimes.  We did do an episode on DNSSEC.  It wasn't only dedicated to just that one topic.  It was something about Google.  It was, like, two topics in one show.  It's around Episode 161.  I did, I went...



LEO:  You can search it, and I'm sure you could find it, search the transcripts.



STEVE:  Yes.  I went to the Security Now! page.  We have a search box in the upper right.  Put in DNSSEC, there's two pages worth of hits.  One of them is me talking about, when Leo asks me, well, so what are we going to talk about next week, and that's when I talk about I use DNSSEC, and Elaine transcribed the acronym.  So it's around there.  It's Google something and DNS Security is the topic, is the formal title of the podcast.  And so by all means check it out because DNSSEC is coming.



LEO:  Yes.



STEVE:  Thank goodness.



LEO:  Not soon enough.  And that's thanks to Dan Kaminsky, by the way.  Robert Altman in Los Angeles - oh, no, I'm sorry, I was thinking of the director.  It's Robert Antman in Los Angeles has a thought about Perfect Passphrases:  Dear Steve.  Thanks for providing the Perfect Passwords service on your website.  This password generator - by the way, it's GRC.com/passwords, folks, GRC.com/passwords.  This password generator is perfect for many applications, such as generating a pseudorandom WPA password.  That's a really good use for it for your WiFi.  But it's not so perfect in other applications, such as generating a pseudorandom passphrase for typing into TrueCrypt, because - as we said - it's almost impossible, at least for me, to memorize this long string of random gibberish.  It's especially difficult if you plan on changing your passphrase periodically.  As an example, if I wanted a pseudorandom passphrase that provided 128 bits of entropy, and I restricted the character set to alphanumeric characters only - a-z, A-Z, 0-9 - the passphrase would have to be 22 characters long.  And he does the math:  (128/log2(26+26+10) = 21.4).  So here's an example.  I'm not going to read it.  Trust me, it's 22 characters of gibberish.



STEVE:  Yes.



LEO:  I claim it's much easier to remember a passphrase consisting of random words, random English words in my case.  Would you consider coding a Perfect Passphrase generator for your website?  Actually, you know, a lot of operating systems, I know Macintosh does this for you.  There are a lot of programs that'll do this for you.  Macintosh, you can ask it for a memorable password, and it'll give you kind of random language words with punctuation and stuff stuck in there.



STEVE:  Right.



LEO:  Anyway, he says:  The Second Edition of the Oxford English Dictionary contains entries for - as you know, Steve has this over his right, or left shoulder, right shoulder, so he knows this - 171,476 words. If you could obtain a list of the most common 65,536 English words, that's 2^16, you could then take 16-bit chunks of your pseudorandom number generator and use it as an index into the word list.  Oh, that's a good idea.  Display that word and repeat the process to produce the random passphrase.



For example, to provide a random passphrase with 128 bits of entropy, you'd only need eight words. that's 128/16, like, say, "decompose ironic humid fizzle muslin purchase guacamole mazeltov."  There, isn't that easy to memorize?  No.  I made that list by flipping open a dictionary and pointing at words at random.   There are some who would claim the use of a passphrase consisting of ordinary words is susceptible to a dictionary attack, but that is not necessarily true.  Provided that the words are chosen at random and you choose enough of them, a random list of words is every bit as secure as a random string of characters.



STEVE:  Well, he's exactly right.  I love the fact that it was, you know, you might say it was susceptible to a dictionary attack because of course that's where you got the words.



LEO:  Right.



STEVE:  Was from a dictionary.



LEO:  However, you'd have to do a lot of dictionary attacks.



STEVE:  I want to, again, I like this because he's completely right.  I mean, and his phrase - "decompose ironic humid fizzle muslin purchase guacamole mazeltov" - okay, that's 128 bits of entropy.  Given that the words - given that you start with 128-bit, high-quality, pseudorandom chunk of bits, you take them 16 bits at a time, use the 16 bits to select one word out of 64K words, you're going to get something that is absolutely strong.  It also, unfortunately, is a lot longer than a passphrase of gibberish because you're now using a word instead of 16 bits.  And as we know, 16 bits is two bytes.  Well, that's not two characters because characters don't occupy the whole 256-size alphabet.  But it's maybe three characters or four characters.  So you end up with something longer at the - I mean, you end up with something longer...



LEO:  And more memorable.



STEVE:  Maybe more memorable, but...



LEO:  Not a lot more memorable.



STEVE:  I guess it's, yeah, it's more memorable.  I would say that, again, given that you were going to - if you're going to write something down, write down some gibberish, and don't write down your personal modification.  This notion of making a modification to gibberish is very powerful because you get both complete protection from dictionary attack, and somebody looking at it has no idea how to turn it into your actual password.  So you can - and not even any idea how to guess how to turn it into your actual password.  That is, what customizations you make to it.  That's very simple for you to remember, yet nobody can glance at this 22 characters of gobbledy-gook and have any chance of memorizing it.  So in some senses it's stronger.



LEO:  Right.  Can I ask you - you may not want to reveal this.  But what do you, you know, you have to come up with passwords.  How do you do this?  You're not using those 64-byte crazy strings, are you?



STEVE:  I often do.



LEO:  For, like, websites and stuff?



STEVE:  I use my own Perfect Passwords for all kinds of things.  And then I - and I record them in a text file.



LEO:  But what about something you need to remember easily?  You don't have anything like that, huh?



STEVE:  Yeah, then I record them in a text file, which I protect.  Yeah, and then I have other algorithms that I use.  I've got different ways of assembling things.  We did, for anyone who's interested, who's joined the podcast late, some of the very first episodes of the podcast, back number 1, 2, 3, 4, we did a series on passwords that a lot of people really liked.



LEO:  Listen to that again, yeah, that's really good.  And just how to generate a good password, yeah.



STEVE:  Yes, I would really commend people to go check that out.



LEO:  That would be required...



STEVE:  It's where we got our roots, Leo, where we began.



LEO:  Yeah, required listening.  Might be worth, well, there's no point in redoing it.  People can just go back and listen to it.



STEVE:  It's there, yup.



LEO:  Last question.  Are you ready?  Jeff, hiding out somewhere in the U.S., doesn't want to blink.  "RFID in credit cards.  Should I run and not walk away?"  Steve, my Chase credit card was approaching its expiration date.  I 

received the new card in the mail.  My new card came with a feature called Blink,  a.k.a. an RFID chip.  Now, the average person thinks that waving a card in front of a terminal instead of swiping is the neatest thing since sliced bread.  But as an avid Security Now! listener, I'm not so sure about that.  How much am I at risk?  Should I wrap my card in foil or request a replacement without the RFID chip?  I don't mind having this Blink feature as 

long as I'm not at risk of losing everything in the "blink" of an eye.  Good point, Jeff.  What do you think about this?



STEVE:  I think it's the worst idea I have ever heard of.  I mean, it is - Visa has been doing this for a while.  They've got their little terminal where they've got some, I don't remember now what their marketing jargon is for it.  But the idea is you just bring your card near the reader.  The problem is, this RFID is a standard.  And you're able to send a magnetic pulse to the card, a little radio frequency burst which engages a wire-wound antenna, powers up the chip, and then it modulates, it uses the incoming power to modulate the impedance of this loop which the transmitter is able to sense.  Unfortunately, this is a standard.  And so potentially any other transmitter is able to poll your card while it's in your wallet in your back pocket.  I mean, I just can't imagine anything more ridiculously insecure than this.  It's phenomenal to me that this is something which has been allowed to happen.  And, I mean, if we keep doing the podcast long enough, Leo, we are going to be talking about breaches of security from RFID credit cards.



LEO:  Oh, yeah, definitely.



STEVE:  What I would recommend Jeff do is stick it in the microwave for about five seconds.  That will...



LEO:  You won't be able to wave it anymore, but...



STEVE:  ...nuke it.  That will nuke the RFID chip.  It won't hurt the mag stripe because that's oxide, which is not a conductor.  And you'll have an RFID that no longer "blinks" at you or anybody else.  Yet you'll still be able to use it and swipe it.  It's just crazy.



LEO:  You know, U.S. passports also have these RFIDs in them.



STEVE:  For what it's worth, ThinkGeek, one of our favorite sites, has a bunch of fun RFID things.



LEO:  You can get a wallet protector and so forth.



STEVE:  Yes.  If you go - and even a passport protector.



LEO:  Right.



STEVE:  Now, the good news is the passports were designed so that their covers will block the RF information.  So that a closed passport, as I understand it, if it's what I'm thinking of, a closed passport will not allow you to access its contents.  You have to open the passport in order to then have access to the RFID chip inside.  ThinkGeek is www.thinkgeek.com.  If you just put in their search box in the upper right "RFID," you get a page of fun stuff.  The first one is an interesting little kit.  I have two of them.  I've just not had any time to build them and play with them.  It's an RFID experimentation kit, $99, that has an interface board with a USB interface to a PC that allows you - and a whole bunch of different shape little funky RFID things.  I mean, even something you could implant in your arm if you were so inclined, and different shape RFID tags.  They all work with this because the RFID standard has been established.  And it would be one way to, like, literally, you could read out the RFID information in your credit card using this little experimentation kit.  And that would be also a way of verifying that five seconds in the microwave was enough to kill it.



LEO:  One of the people on the cruise with me is a security researcher, Shakil.  And he had a passport wallet to shield his RFID.  And actually it set off the machine because it's got metal in it.  And we were talking about it.  He said, one of the reasons I wear this is - and you can find this on YouTube.  Some security researchers demonstrated that it's possible to read these RFIDs in the passports from a distance.  And stupidly, the State Department has put in an identifier that says "U.S. Citizen" in it.  So the video that you'll see on YouTube is a bunch of people walking by a trash can, and the trash can explodes when a U.S. citizen walks by.  Not a difficult thing to do.  So Shakil, as soon as he saw that, said I think I'm going to get a passport holder here.  Yeah, this is something kind of incredible.



STEVE:  And for what it's worth, the other things on the ThinkGeek page are various types of shields.  There's a wallet shield, a passport shield, credit card shield, a bunch of different shields.  I mean, it just...



LEO:  Completely legal to do that, by the way.  You're still handing over the passport for them to read, for customs and immigration people to read.  And they can open it up.



STEVE:  Sure.



LEO:  But you don't have to be visible to the rest of the world.



STEVE:  No.  And again, that's the problem.  It's not the transaction that you intend.  It's the transaction that you don't intend.  And it is definitely possible to aim a focused radio beam at somebody and pick up the impedance change that the RFID chip is inducing at a distance.  So, I mean, this is not rocket science.  This is simple to do.  It's just nuts that this is something that people are thinking, oh, great, now I don't have to swipe my card anymore.  I can just walk past the teller.



LEO:  Credit cards, though, are inherently insecure.  I mean, you hand it to a waiter, and he wanders off with it for 10 minutes.  I mean, the whole idea of a credit card is not so secure.



STEVE:  That's a very good point, too.



LEO:  I mean, people, c'mon, we're giving it...



STEVE:  On the other hand, you know you're handing it to him.  You're still in the physical world, and you're able to assess the security.  There are certainly people you would not hand your credit card to.



LEO:  Like Vertrue.  Dale Poco has found the location in the  Firefox profile folder of the zoom settings, per page zoom settings.



STEVE:  Oh, cool.



LEO:  It's in a SQLite database.  So it is in the profile folder.  And you just have to find a file called places.sqlite.  And that's a standard, readable SQLite file that contains all the places you've been.  Aha.



STEVE:  Isn't that nice.



LEO:  Isn't that nice.  Okay.  Well, now we know.  Steve, a great episode.  Lots of information.  I really appreciate you taking the time to answer these questions.  We're going to do more questions next week; right?



STEVE:  Yes.  That will be the final episode of the fourth year of the podcast.  Another Q&A next week, and then we'll plow into our fifth year.



LEO:  Fifth year.  Amazing.



STEVE:  And I will have some news about Vitamin D.  I'm going to go take my clothes off now, Leo.



LEO:  Okay, okay.  We'll turn the cameras off.  You can find Steve at GRC.com, that's his website.  GRC.com/passwords for the passwords.  You'll also find the Security Now! page there with 16KB versions of the show for easy download, those of you who don't have the bandwidth, or the caps are getting in the way.  Also transcripts, great way to search and read what Steve's talking about, read along with the transcripts.  And all that great software that Steve does, much of it for free.  And his bread and butter, of course, his day job, SpinRite, the world's best hard drive maintenance utility.  It's a must-have if you have a hard drive.



STEVE:  It works.



LEO:  It works.  Steve, we'll talk to you next week.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#208

DATE:		August 6, 2009

TITLE:		Listener Feedback #72

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-208.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 208 for August 6, 2009:  Your questions, Steve's answers.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure - securing your operating system, securing your 'Net connection, fighting off bad guys and spyware, protecting your privacy.  And here he is, the czar of security, Mr. Steve Gibson.  I think I did, in fact, in my cabinet, make you the czar of security.



STEVE GIBSON:  I'm the security czar.  Well, I'll tell you, from all of the nonsense I hear about Washington, D.C.'s attempt to find a security czar, no one is applying.  They're, like, the gal that's been temporary is stepping down very politely because she wants to put pressure on the administration to find somebody to be the security czar.  But the people who are good enough to do that are also smart enough not to, you know, they're smart enough to know better.  Because apparently they've got no control over anything, not budget or management or staffing or anything.  They're just - and they're split between two different organizations.  I mean, it just sounds like a disastrous job, and probably more frustrating than anything.  And, like, why would anyone want to hurt themselves and who have, like, the ability to do that?



LEO:  A job with all the responsibility and none of the power.



STEVE:  Yes.



LEO:  This doesn't sound good.



STEVE:  This is just a lose, lose, lose.



LEO:  Yeah.  It's like being governor of California, another fine job you do not want.



STEVE:  Although I'm sure you know, you heard, that Clinton, Bill, went over to North Korea and brought back our two prisoners.



LEO:  I am so happy about that.



STEVE:  It was just so cool.  It caught me by surprise this morning.  First thing I saw is like, hey, very neat.



LEO:  We talked about it last night because they worked for Current.  Euna Lee was one of the reporters who worked at TechTV.  And...



STEVE:  Oh, you knew her?



LEO:  Yeah, well, I don't remember her, but I think I did know her.  But I, you know, there were a lot of people at TechTV.  I think she was an intern at the time.  But, yeah, and she worked at Current with Sarah Lane.  And Sarah was on net@night last night, and she said there's reporters on the street, but we don't want to celebrate until we see them get off the plane.  Well, they got off the lane.  And you know what kind of bugs...



STEVE:  They were flying into Burbank Airport for some reason, probably just to...



LEO:  Kind of odd, yeah.



STEVE:  Yeah.  Well, it was apparently a chartered plane.  So maybe that was the right place for it to land.



LEO:  Thank goodness, because these two women were convicted of spying and sentenced to hard labor.



STEVE:  Young women.



LEO:  Yeah.  Not a good outcome.  And so it's a great relief that - and, you know, kudos to President Clinton.  I think that's got to be a little scary to fly to North Korea.  You don't know what Kim Jong-il is going to do.  And so to fly into the lion's den and save those women, I think it's...



STEVE:  Yeah.  Well, apparently he - Madeleine Albright, his Secretary of State, did visit North Korea during his presidency.  So there was some sort of a sense of an olive branch.  And the presumption was that Kim Jong-il wanted some attention.  And so this gave him...



LEO:  Exactly.



STEVE:  He couldn't - to have any of our current administration go over would have been too much.



LEO:  Can't do that.



STEVE:  And so, I don't know, I think it was brilliant, in retrospect.  And thank goodness that's resolved.



LEO:  Whew.  Relief.  So today is a Q&A day.  That means...



STEVE:  We have - yes.  Because we had to change things around, two weeks ago we did the mega security update.  That pushed a Q&A out.  I wanted to - there was so much stuff backlogged in the GRC.com/feedback page, our mailbag, that I wanted to spend a couple of those.  And this is a big episode for us.  Actually this one is, and next one will be.  This is 208, which is four times 52.  Given that a year has 52 weeks, this is the end, this is the last episode of our fourth year.



LEO:  Wow.



STEVE:  So, yeah.



LEO:  And, you know, kudos to you because we know that because you can do the math.  There's no other show I think in the world that has done four years' worth of shows, 208 episodes, without break.  I mean, that's unheard of.  Not one rerun.



STEVE:  I found one message when I was going through the mail yesterday to prepare and select questions for today.  Someone asked me, I think it was a woman, said hey, you know, when Leo's on vacation, you're apparently not.  Do you ever take a vacation?  And first of all, when you're on vacation, I am, too, technically, because I'm not doing podcasts without you.  We do extra ones ahead of time so that we have podcasts to straddle any outage.  But I just - I truly love what I do so much that, if I were on vacation, I'm just annoyed about all the work I'm not getting done.  I just - I love computers and technology and, you know, life.  And so I'm on vacation all the time.  I'm on vacation right now, doing this with you.



LEO:  You know, they say that.  They say the only difference between a hobby and work is whether you like to do it.  There are people, I think Malcolm Gladwell talks about this in his book "Outliers," there are people who pay money to drive trucks and trains, even though that's a job for some people.



STEVE:  Right.



LEO:  For others, it's something they love so much that they'll pay to do it.  So I'm not saying I would pay to do this.  But I sure, even if I didn't have to, I think we'd be talking once a week one way or the other.  Hey, well, let's - so do you have security news and updates?



STEVE:  We've got news, we've got a little bit of errata, and we've got our Q&A.



LEO:  Steve Gibson, what is the latest security news?



STEVE:  Well, we have a bunch of follow-ups, interestingly enough, from last week.  We know, for example, that the iPhone was patched, exactly as we predicted, the day after the formal SMS hack of v3 and prior versions was made public.  So Apple finally got off the stick, I mean, I guess they were frantic for, you have to imagine, for a few weeks beforehand, since we knew about this problem a few weeks beforehand.  It was patched.  So if anybody has not been to iTunes recently, you definitely want to do that in order to update yourself to 3.0.1.



LEO:  Yes, and I did it immediately.  One point to make is, so far no reports, despite the fact that there was kind of a 24-hour, zero-day opportunity, no reports of exploits at this point.  That's good news.



STEVE:  Yeah.  Who knows whether...



LEO:  It could have happened because you may not know; right?



STEVE:  Correct.  If you didn't know, if you didn't update your phone - it seems to me that the intersection of reality needed to make this happen is relatively small.  Somebody would have to know your phone number, I mean, probably targeting you specifically, who also had the skill or ability to get this thing from the 'Net and perpetrate the hack.  So...



LEO:  I think going forward we and Microsoft and Apple and everybody should make the distinction between a completely theoretical attack, an attack that we know how to do but hasn't been in the wild, and then one that is actually out there in the wild.  Do they make that distinction?



STEVE:  Oh, yeah.  Normally there will be specifically, well, for example, one of the things we're going to talk about is that BIND has been fixed.  We talked about the master server update problem which could crash and potentially take over BIND servers, but it was only known to cause a crash, and that a fix is available.  But at the same time, that vulnerability is now being actively exploited on the 'Net to crash BIND servers.  So normally there is, certainly in the Microsoft case, they will say that exploits are in the wild and that this is something you really need to patch for that reason.



LEO:  Yeah.  And Apple doesn't do that.  In fact, Apple is very notoriously kind of tight-lipped about what their updates do.  I don't think, I don't remember anyway, when the 3.0.1 alerted me, it didn't say you must get this right now, there's a big SMS hack.  They just said here's an update.



STEVE:  Oh, by the way, yeah.



LEO:  I think they might - in their tech note I think they said this patch is the SMS vulnerability.  The irony is you still have to download the full firmware.  It's almost 300MB, even for this one little fix, which could have been a few bytes, I mean, who knows.  I wish they would reveal a little bit more about what they fixed.



STEVE:  Yeah.  Of course then the flipside is the more they, I mean, here we are worrying about after-the-patch attacks on people who have not been patched.  Even though Apple has said, hey, we fixed it, they're still not disclosing a lot.  So clearly they're wanting to keep a lid on this, recognizing that there is still an attack surface among those people who do not update for whatever reason, or until they update, until they next check in with iTunes or the word gets to them somehow.  So I guess I can understand that.  But it's this double-edged sword we have with security and vulnerability.  On one hand we want these companies to be open.  But to be open means unless there's a system like Microsoft has that is pushing these patches out, and Microsoft can be, oh, you know, fairly certain that the bulk of their customers are going to be updated because lord knows they don't make it easy not to get updated any longer. it is certainly a tradeoff you have to make.



LEO:  Yeah.



STEVE:  Firefox, my version 3 - I'm not at 3.5 yet, I'm still back at 3.0 - I was at 3.0.12.  It updated to 13.



LEO:  I noticed that, yeah.  Or mine up- oh, I'm sorry, go ahead.  Because 3.5 updated, too.



STEVE:  Well, 3.5 has gone to .1 a couple weeks ago.



LEO:  And now it's .2.



STEVE:  Okay.



LEO:  So you were right to hold off.



STEVE:  Yeah, well, there's an interesting hack which was revealed at the Black Hat conference, which is - I think it's the first question that we've got in our Q&A.  So I will cover it more then.  But I'm very pleased that Firefox instantly responded.  IE hasn't yet and is vulnerable.  But Mozilla immediately responded to that.  We'll discuss what that is in our first Q&A.  They also fixed a heap buffer overflow in their security certificate handling.  Firefox 3 had been bringing along sort of a flexible, regular expression-parsing approach to certificates that 3.5 never had.  3.5 used a more traditional sort of standard approach to parsing certificates.  It turns out there was a vulnerability in that older, longstanding, sort of inherited from the Netscape days parsing, which they've now fixed.



And there was a really interesting vulnerability that they have fixed that a security researcher, Juan Pablo Lopez Yacubian, reported, where an attacker could use, not surprisingly, JavaScript, to use the window-open JavaScript on an invalid URL, that is, a URL that you didn't mean, which looks similar to a legitimate URL.  Then they were able to use the document-write JavaScript to replace the content with what they wanted it to look like, like looking like eBay, for example, appearing to have it come from a spoofed location.  And then, if the spoofed document was created by a document with a valid SSL certificate, even though it was not where you thought you were going, the SSL indicators would carry over from the wrong document into the spoofed document.  The bottom line of all this was it allowed a typo, a typo that would take you to a site that used JavaScript, to replace the page and spoof the SSL correctness of what you mistyped, making you look like, for example, you were at PayPal, with all the indicators that your security certificate was valid.



LEO:  Ooh, ooh.



STEVE:  So the good news is, that's gone.  That's fixed in 3.0.13.  And these things were also fixed in 3.5.2 that you mentioned.  So Firefox is updated.  Anybody using Firefox probably already knows.  I found out this morning when I fired things up and logged in and got going.  It says, oh, we've got an update for you.  It's funny, too, because I depend upon my Firefox session manager remembering all the tabs I have open.  It just has sort of become a big database repository for me.  But I had two Firefox windows open at that moment.  And so I wasn't sure that it would remember them both.  So I had to, like, work through the tabs on one, although I could have dragged them all over to the other  because you can drag tabs across windows now.



LEO:  You still use that sidebar tab extension.



STEVE:  I'm liking it a lot, yes.  But now unfortunately my sidebar is scrolling because I've got so many tabs.



LEO:  [Laughing]



STEVE:  It's like, okay, I'll get around to this one of these days.



LEO:  You know, we had Kevin Rose on TWiT a few weeks ago.  And he said, okay, quick, tell us how many tabs you've got open.  And everybody on the show had, like, 20 tabs open.  So this sidebar tab thing is great.  But if you've got that scrolling, there's no help for you at all.  That must be, like, 60 or 70 tabs open.



STEVE:  Like I'll get around, I'll get back to that one of these days.



LEO:  The name of that, by the way, for people who want to know, is Tree Style Tab.



STEVE:  Yep, exactly.



LEO:  Steve recommended that a few weeks ago.



STEVE:  So we talked about BIND, which fixes are now available.  So anyone who is an admin responsible for their corporate DNS server, it's likely a master.  It probably didn't need to receive update messages, but there was a problem that was found, we talked about it last week.  I just wanted to let everyone know that patches are available.  So you're going to want to update your BIND to the current release and solve this problem.  And again, this is being actively exploited by creeps on the Internet.  All it really lets them do is crash people's DNS servers.  It's like, okay, well, oh, boy.  It's annoying, but people are doing it all over the place.



LEO:  Really.



STEVE:  So, yes.  You want to get yourself updated to prevent that from happening.  And in the Adobe Flash Player news, we talked about their problems last week, which were not fixed, but they had said they would be fixing them soon.  I chuckled a little bit because I'm sure our listeners will remember me rolling my eyes, figuratively for those who don't see video, but I was rolling my eyes...



LEO:  Literally.



STEVE:  Yes, when Adobe announced that they were going to be doing their - they were increasing their patching protocol or patching formality, going to be more responsive, and so they were going to do quarterly patches, whereas Microsoft does them monthly.  And I remember at the time saying, what?  I mean, that makes no sense at all.  We'll see how long this lasts.  Well, it didn't last even a quarter because they had some bad problems in 9.1, and they needed to update themselves immediately to 9.1.3, I think that's where they are, and v10.  Anyway, I wanted to make sure people knew that Flash Player updates for 9 and 10 are now available.  So you'll want to check and make sure you get updated.  And I did turn a machine on the other day that said, oh, we got an update for Flash.  It's like, okay, good.  It's time.  And I'd noted, you know, we've been talking about Adobe, like people will probably notice, every week, which is not what you want to be talking about.



LEO:  No kidding.



STEVE:  If you're the target of this conversation on a security podcast.  There's an editor of the SANS newsletter - which is an excellent, excellent SANS security newsletter - Stephen Northcutt, who's also the president of SANS Technology Institute; and they sometimes add little - their editors' comments to the bottom of their reports or problems.  And I got a kick out of his comment in this most recent newsletter this week.  He said, quote, "I think organizations should avoid Adobe if possible.  Adobe" - and this is not who you want to have saying this.



LEO:  No, SANS is highly respected.



STEVE:  Yes.  It says Adobe - he goes on, saying "Adobe security appears to be out of control."



LEO:  Oh, dear.



STEVE:  "And using their products seems to put your organization at risk.  Try to minimize your attack surface.  Limit the use of Adobe products whenever you can."  And it's like, ouch.



LEO:  Wow.  Wow.



STEVE:  Yeah, yeah.  Carnegie Mellon did a study which hit the news, which basically stated that in their relatively small survey, it was only about a hundred people, but apparently 55, meaning more than half, of the people that they watched encounter expired security certificates, ignored the expiration...



LEO:  I'm surprised it wasn't higher.



STEVE:  ...and went on anyway.



LEO:  Most people would just go, I don't know what this is.  Okay, I just want to surf.



STEVE:  That's exactly the problem is that people were confused by the notices, didn't really read them, just sort of said, uh, okay, whatever, and said what button do I push so that I can continue?  And it's funny, too, because, I mean, I saw that, I witnessed it myself firsthand.  You'll remember that GRC's own security certificate expired, to my extreme embarrassment, a few months ago, and I scrambled around.  I was set up at Starbucks in the morning when it came to my attention.  So I zipped home and had to go through, jump through hoops to get VeriSign to issue me an update, a renewal, as quickly as I could.  However, SpinRite sales continued even in the face of that security certificate being expired.  Now...



LEO:  Now, they're giving you credit card information, too.  I mean, it's not just a visit.



STEVE:  Yes, exactly.  It's not just go to Perfect Paper Passwords or Perfect Passwords and pick up a password.  It's I want to buy SpinRite, and I'm going to put in my credit card information into this site.  We might assume, however, that visitors to GRC are more sophisticated, and they were able to see, oh, look, it says here that Gibson's certificate expired yesterday, so I imagine he's scrambling around right now, as indeed I was, to get it caught up to date.  But people did push past that.  And there's now discussion about whether it should be possible in a browser to push past that because it's up to the browser's discretion to allow you to either disallow any SSL that has a certificate that is deemed invalid for any reason.  You know, certainly mismatching domain names, you never want to get past that.



But, I mean, I've encountered other people with certificates that expired just recently, and I've forgiven them because it's like, okay, I can see how that could happen.  I'm sure they're scrambling just as I was.  So it was interesting, though, that more than half of people, when they see an expired cert, will say okay, fine, I still want to do what I want to do.  So make an exception and move on.



LEO:  Never mind, yeah.



STEVE:  And then my very favorite story of the week comes to us from the Black Hat and DEFCON conferences in Las Vegas.



LEO:  Boy, it's been an adventure this week, hasn't it?



STEVE:  Oh, there was a ton of stuff.



LEO:  Oh, man.  Not just the iPhone thing.



STEVE:  What I loved was the fake ATM machine.



LEO:  Yeah.



STEVE:  Which was found during the DEFCON conference.



LEO:  Geez.



STEVE:  People were putting their credit cards, were like swiping their ATM card, putting in their PIN, and nothing was happening.  It wasn't giving them cash.  And then they thought...



LEO:  That's kind of a red flag.



STEVE:  Exactly.  And then the way it was discovered was that some, I mean, here we've got security-aware conference attendees.  Someone noticed that the black hole above the screen where normally the video camera would be didn't seem to have any lens reflection coming off of it.



LEO:  There's nothing in there.



STEVE:  So they shined a flashlight in and saw a PC sitting behind, literally sitting behind the screen, pretending to be an ATM.  And that was their clue that maybe this was a bogus ATM.  And the Secret Service came and took it away.



LEO:  Wow.  Wow.



STEVE:  So I got a kick out of that happening...



LEO:  How long was it there before they figured it out?  Do we know?



STEVE:  We don't know.  We don't know at what point it appeared.  It was placed near the security entrance - which, interestingly enough, had no security.  It's an area where there was a camera blackout.  For whatever reason, there weren't monitoring cameras that covered its location.  So someone snuck it in, and it sort of sat there, and no one really noticed it until it began not giving people money back.



LEO:  Wow.



STEVE:  So I have a couple little bits of errata.



LEO:  Can I give you one story that just broke?



STEVE:  Oh, yeah, yeah.



LEO:  Critical Windows 7 bug.



STEVE:  Oh, haven't heard of it.



LEO:  It's not a security issue exactly.  But it is what they call a "showstopper."



STEVE:  Uh-oh.  Oh, and so RTM is no longer RTM?



LEO:  Apparently not.  This affects the RTM build, 7600.16385.  Enterprise Desktop column.  Randall C. Kennedy at InfoWorld says a massive memory leak involving chkdsk, when you run chkdsk against a secondary drive, not the C drive but a secondary drive, using "/r," which means read and verify, in both 32-bit and 64-bit versions of Windows 7, Blue Screen of Death, out of physical memory.



STEVE:  Ooh.



LEO:  Damn.



STEVE:  Well, and you can't do a "/r" on the primary drive because it'll tell you that it's in use.



LEO:  Right, right.



STEVE:  And it'll ask you if you want to defer the chkdsk for the next time you reboot the machine so that it's able to briefly get exclusive use of the drive before Windows starts opening files and doing everything it does.



LEO:  So no idea if, you know, maybe if you do do that reboot and then do a "/r," if it does it on the main drive.  But it does do it on the secondary drives.



STEVE:  Wow.



LEO:  So I don't know what Microsoft's response is going to be.  But this is - a number of people are reporting this right now.



STEVE:  You know, I wouldn't be surprised if 7, and I don't know this at all for a fact, you and Paul probably do know because I've - it's going to be a long time before I'm messing with Windows 7 except as a curiosity.  But I noted that IE8 now, when you install it, it asks you, may I bring myself current with all security updates before we go any further?  And I wouldn't be at all surprised if that's Microsoft's new policy for when you install something, before it even starts it says, okay, hold on a second, I'm going to - who knows how long it's been since this particular code you've just used to set me up, how old that is.  I'm going to go ping Microsoft and see if there's anything I need to do right now before we even start.  So it could be that even though this is a problem with the RTM, that they can fix this in patch 00001 of Windows 7, and so no one will see it.  It will, immediately upon installing, it'll say, wait a second, we're going to update ourselves.  Oh, look, we found something.  It's like, okay.



LEO:  So, and by the way, I should point out that if you've got a memory leak that can cause that to happen, that often is a - isn't that often a first step in an exploit?  Maybe not.  It's not a good exploit.



STEVE:  Well, it's not even clear that that would actually - that doesn't sound to me like a memory leak.  That sounds like some allocation error maybe that's been misreported, for example.  If you used to try to run Windows 98 on a system with more than a gigabyte of memory - 98 was quite happy with 512MB, you'll remember.  And if you actually tried to run it on a system with more memory, it would say that you didn't have enough memory.  It would report "out of memory" error rather than "I don't know what to do with all this."  So it could just be a fluke of whatever's gone wrong is resulting in this particular problem.  It may well not be an out-of-memory error.  It just might be saying that it is.  So without really looking at it, it's hard to say.



LEO:  And I imagine that's an easy thing to fix.  I mean, it's not a kernel problem, probably.  Although Microsoft's saying it might be a driver issue.



STEVE:  I'm sure it's easy.  In fact, there was news about the - remember we talked last week about the big Microsoft glitch in the ATL, the Active Template Library, that had been part of Visual Studio for a long time, which meant that all of the ActiveX controls which were made with Visual Studio and this ATL, all had a problem.  It turns out it was a single ampersand bug.  There was an ampersand that was there that shouldn't have been that caused the whole problem.  They called it a typo.  It's like, okay, well, I guess a lot of bugs are typos.  But this Blue Screen of Death from running chkdsk might be something similar.  Who knows.  Whatever it is, it's obviously wrong.



LEO:  Yeah.  If you dereference a pointer, that could be a typo, but it also could be a programming error.



STEVE:  Yeah, exactly.  And that's what I'm thinking is going on with an ampersand.  So it's like, okay, well, they didn't know what they were - someone isn't happy about the ampersand, but that doesn't mean it's a typo.



LEO:  A typo, yeah.  So...



STEVE:  Well, one of our listeners was kind enough to point me to the scifi-az website, where...



LEO:  Our good friend...



STEVE:  ...Michael McCollum publishes his science fiction.  He posted a progress report last week, Monday before last, on the status of the third and final book in the Gibraltar series.  I love the series.  "Gibraltar Earth" was the first one; "Gibraltar Sun" is the second one; "Gibraltar Stars" will be the third one.  And he just posted an update to sort of let people know where things stand.  He just finished the first draft.  The book is...



LEO:  See, I'm holding off.  I started "Gibraltar Earth," and I thought, I'm going to wait till he finishes the trilogy.



STEVE:  I don't blame you.  I read "Earth."  Then when "Sun" came out I reread "Earth" and read "Sun."  And I've offered, and he has accepted, to edit the final book for him because when I have read through them, I have found typos.  And since I'm reading it, in this case, in a Palm, it's easy for me to mark the section and make a note.  So I've sent him, like, little corrections for his eBooks in the past.



LEO:  Can you get those on the Kindle?  Weren't you trying to help him do that?



STEVE:  Absolutely.  He's got it now in amazing variety of formats.  I mean, you can get it on your back molar format.



LEO:  I don't want to read it on my back molar.



STEVE:  Anything you've got, his stuff will read on.



LEO:  Oh, good.  Oh, good.



STEVE:  And so he's at 130,000 words.  And he's going to go through it now, he's going to reread it.  And what he's - the way he phrased it on his site, he said, 15 percent will be removed to, quote, "maintain dynamic tension" or, as he says, "to take out the boring parts."  And so he, too, he's going to reread "Earth" and "Sun" to, like, remind himself what they were.  Because this has been going on, this series straddles about 10 years.  So as he puts it on his site, he wants to remove any small discrepancies that creep in over the better part of a decade of writing a series.  So he's just going to make sure everything is consistent.  Because of course you know us geeks, we'll read it and go, hey, wait a minute, you said that the Plurion race drank this rather than - it's like, okay, fine.



LEO:  I can't imagine doing what he's doing.  I mean, and keeping track of all that.



STEVE:  Well, they're very complex plots.  I love his plots because they're - he is a nuclear engineer, literally.  And his - I find his books really fun.  I mean, they're not literature.  They're space opera.  But they're really engaging.  And he has created, he has set up a problem for the human race which I've never seen before in all the sci-fi that I've read, which is really interesting.  I mentioned before that there's a race called the Broa.  And they haven't stumbled on us yet, but they are a huge supremacy.  They just absorb any other cultures and alien races that they encounter, getting bigger in the process.  And we would immediately be enslaved if they knew about us.  And so this is a problem because it's by the merest coincidence of positioning that our radio hasn't - our expanding radiosphere hasn't yet touched them.  But and they've got listening posts scattered around because they're looking to acquire new species to take over.  So, oh, it's just - it's a spectacular space opera.



LEO:  Yeah, yeah.  And, well, I will go back to it.  I'm glad to know he's working on the third edition, or third volume.



STEVE:  Yup.  I will let you know...



LEO:  How do you like - have you been reading "Red Mars"?  What do you think of it?



STEVE:  I've got them all on my Kindle.  I just haven't had a chance to start.  I've been massively engaged in research elsewhere, which will be the topic for next week's podcast.  I also wanted to mention Sony is coming out with a pocket eBook reader at a sub-$200 price.  It's got a five-inch screen.  It's not very sub-$200, it's one dollar sub-200.  It's $199.  Supposed to be end of August.  And their store is up to about 100,000 books, whereas Amazon is at 330,000 books.  So Amazon still has a big lead.  Of course, Sony has access to all, to a million public domain books through Google and is also an open eBook format, whereas the Kindle is closed.  And finally, Apple is reportedly working on an eBook reader.



LEO:  Well, it's tablet.  We don't, you know, it's going to be more than an eBook reader.



STEVE:  Right.



LEO:  It's really like a big iPhone, I guess.



STEVE:  Well, and wouldn't that be...



LEO:  We don't know what it is.



STEVE:  I mean, can you imagine anything better than exactly being an iPhone, but really big format, and being a tablet running the Mac OS?  It's like, ooh.



LEO:  We may know soon.  I mean, there's debate over when it'll be announced.  But some say as soon as next month.



STEVE:  Oh, no kidding.



LEO:  Yeah.



STEVE:  Oh, good good good good.  Okay.  And one last thing, just this is - this came out of nowhere.  This was actually again from - oh, no, it was from Steve Bass.  And you know Steve.



LEO:  I know Steve, yeah.



STEVE:  Yes.  He's the ex-president of PIBMUG, the Pasadena IBM PC User Group.  He has a newsletter that he sends out from time to time.  And he often has a section of time wasters.  Well, this thing is a piece of - it runs in Flash.  And do not put this URL into your browser now, Leo, or I will lose you for the rest of the podcast.



LEO:  [Laughing]



STEVE:  It is just spectacular.  It's a toy, puzzle, beautiful thing:  www.playauditorium.com.



LEO:  This has been around for a while, actually.



STEVE:  Oh, has it.  I hadn't seen it before.  Just, oh, just spectacular.



LEO:  Yeah.  I've wasted a lot of time with it.



STEVE:  Yeah.  I will be, too, because it's exactly the kind of puzzle and toy that intrigues me because you're not in a hurry.  There's no time limit.  There's no clock counting down.  It seemed like there's multiple way to solve these puzzles.  As you stumble on and experiment with ways to solve them, you learn more about this.  It's just wonderful.  So I wanted to turn our listeners onto it:  www.playauditorium.com.



LEO:  It's kind of amazing what you can do with Flash; you know?



STEVE:  I'm very impressed with it.



LEO:  And it makes beautiful music.  I should play, well, you have to do it, you have to solve the problem before it'll make the music.  But once you do, it makes great music.



STEVE:  Yeah.



LEO:  Yeah.  It's really, really neat.



STEVE:  And so lastly, a fun SpinRite story provided to us by Juan Guevara Torres.  He says, "Hi, Steve.  I'm a Mac user, so I do not own a copy of SpinRite.  However, the other day I went to a computer store in Houston to get a new device for my network, following the Trust No One policy I've learned from Security Now!.  A poor fellow, a PC user and his wife, visibly worried about their data, was in the tech support department.  Since this person was ahead of me in line, I was able to overhear the following conversation."  He calls it "'The store's pseudotechnician' says, 'I'm sorry, sir, your hard drive has been damaged.  You will need to pay $299 for a technician to attempt to recover as much data as possible.  This is not a guarantee, but we can try.  And that does not include the new drive you will probably need, as well.'"



So the "poor fellow" is quoted as saying, "'But for that price, I can get a new drive, and what about my data?  So you're saying I might not recover all of it?'  The store's pseudotechnician replies, 'We will try.  But once again, it's not a guarantee.  Should I start filling out this work order for you?'  The wife of the poor fellow says, '$299?  I told you not to take your laptop on our trip.  Now your pictures are lost, and we'll be out 300 bucks for nothing.'  So losing data" - I guess this is now Juan editorializing.  "Losing data is bad; losing data and paying $299 is very bad; but there is nothing worse than having an upset wife about losing your data and paying $299.  That poor fellow was doomed to hear this story for the rest of his marriage, and maybe for life."



So now Juan says, "Listening to all the praise SpinRite users have been sharing with all of us in the podcast, I approached the couple and the technician.  I asked flat out, 'I would imagine the software you use for recovering data is SpinRite; correct?'  The pseudotechnician gave me a dirty look.  The couple looked at me with a little bit of WTF?  The technician answered, 'Yes, we use that software.  You know, it's a very complex process.'"



LEO:  Oh, yes.



STEVE:  Juan says, "'I'm sure it is,' I said.  Then I turned to the couple - still with the WTF look on their face, I might add - and I said, 'I'm sorry to just cut into the conversation.  However, the software the technician is talking about is available on the Internet for less than a hundred dollars.  I understand it's a very easy-to-use piece of software, as well.  So before paying $299, why don't you go to GRC.com and give it a try?  In any case, that's what they are going to do anyway.'  The poor fellow, with a slight smile on his face and a huge Texan accent, said, 'Thanks, Bud, I'll try it.'"  And then Juan finishes, saying, "'Here is my email.  Drop me a line and let me know how it worked,' I said.  So then he says, "Yesterday I got an email from the not-so-poor fellow anymore.  'Juan, thanks, Bud.  SpinRite did the trick.  Those 80-something dollars I paid saved my data, and I'm telling you, man, my marriage.'"



LEO:  Now, you don't guarantee that data will be recovered, we should say.



STEVE:  No.  We do guarantee that, if you're not happy with your purchase, we'll refund your money.



LEO:  Oh, I didn't know that.  That's good.



STEVE:  Absolutely, 100 percent, satisfaction guarantee.  Anybody who tries it and they're not happy, just let us know, we'll put the money back on your card.



LEO:  There's all sorts of reasons why your data might be lost that SpinRite - like if you erased it - that SpinRite's not going to find it.



STEVE:  Well, yeah.  Or if the platters have frozen, or the heads have fallen off, or it no longer spins at all.  I mean, there are limits to what software can do to repair hardware.  SpinRite pretty much pushes that all the way to the limit.  And again, if it doesn't work, we'll give your money back.



LEO:  And a large, a surprisingly large number, certainly the majority of problems can be fixed by SpinRite.  That's kind of the sweet spot of where hard drives have problems.



STEVE:  It really does work.



LEO:  Yeah.  All right.  We've got questions; Steve's got answers.  We're going to get to those questions and answers in just a second.  Steve, if you want to take a sip of water?



STEVE:  I'll sip my coffee.



LEO:  Sip your coffee, your triple, what is it, a venti, quad venti you got today?



STEVE:  It's two shots of espresso in a large - in a venti container.



LEO:  Oh, you're a lightweight.  You're a lightweight.  Alex Lindsay has got me drinking triple talls now, which is the smallest.



STEVE:  It's an Americano.  It's not - it's just hot water.



LEO:  Oh, you have an Americano, yeah.  Although they say - oh, but they make it with espresso, though.



STEVE:  They do.



LEO:  Because they say that brewed coffee, and I bet we're going to start a whole debate on that, but that brewed coffee has more caffeine...



STEVE:  Oh, it does.  Much more caffeine...



LEO:  ...than espresso.



STEVE:  ...than espresso.  The longer you roast the beans, that roasts the caffeine out.  And so even though it's a much stronger taste, it's actually less espresso.  I'm sorry, less caffeine is what I mean.



LEO:  Less caffeine.  Not that it doesn't get you going.



STEVE:  I like it.



LEO:  I had my triple tall today, and I'm feeling fine.



STEVE:  I don't need any more caffeine.



LEO:  No, I don't either.  Now, Mr. Steve Gibson...



STEVE:  Well, while you were reading that, Leo, I just bought a PDP-11.



LEO:  No.



STEVE:  Yeah, I just won an auction on eBay.



LEO:  [Laughing] I gave him a break, and what does he do?  He buys an obsolete mini computer.



STEVE:  Beautiful, for $225.94.



LEO:  Not a simulator, not a - this is the original.



STEVE:  It's a PDP-11, 1123, full height stand.  The description says "One complete digital DEC micro PDP-1123 system.  Amazingly, this unit was still being used in an office environment and was fully operational when shut down.  Everything inside the case is intact and untouched.  Dual front floppy drives and hard drive.  Maintenance log is included.  Rare find."



LEO:  Aren't you amazing.



STEVE:  $225.94.  So I scored on that one.



LEO:  How many do you have now?



STEVE:  About 15.



LEO:  What are you going to do?  Are you making a cluster?  What are you...



STEVE:  No, I'm just, you know, they might die.  I might, you know, you know how many Palm Pilots I have.



LEO:  Do you have them in the freezer?



STEVE:  Yeah.



LEO:  Well, it'd be kind of cool to line them up all on the wall, you know, and you could...



STEVE:  Well, they're all various types, makes, and models.  And someday I'm going to program them.



LEO:  Great.  I love it.



STEVE:  In the meantime, we're actually going to do a Q&A.



LEO:  A Q&A, yeah, now that you've scored.  Brian Mooney - Question 1, Mr. G. - in Springdale, Arkansas, brings news of a new SSL problem:  Steve, It looks like they've found another method to work around SSL.  And here I am saying how secure SSL is.  This isn't based on the faults in the encryption, but on faults in how browsers handle null characters.  And he's quoting an article in Mac World magazine from July saying the only "safe" browser is Firefox 3.5.  



"Frylock" also raises the issue, are SSL certs completely broken and useless?  He says:  Huge fan of the show since Episode 1, ran across this on Hackaday.com.  Does this not render SSL certificates useless?  Please, what's the story?



STEVE:  Oh, this is so wonderful, Leo.  This surfaced during the Black Hat conference in Las Vegas.  It turns out that a null character, that is, a zero, is - to give a little bit of background about how computers process strings for our listeners, a string, like "Now is the time for all good men to come to the aid of their country," a string in some languages, like you may remember Pascal, you had a byte for the length, it was the first character, that is, the first byte of the string was the length, and then you just had the characters that followed.



LEO:  Does anybody still do it that way?



STEVE:  No.



LEO:  They're all zero-terminated now, null-terminated.



STEVE:  Yes, because the problem with that was that you could not, in Pascal, the original UCSD Pascal, you could never have a string longer than 255 characters.



LEO:  Oh, because you only had a byte length to represent it.



STEVE:  Because you had a byte.  And so, you know, those designers back then said, well, that's plenty.



LEO:  No one will ever need more than that.



STEVE:  Exactly.  Now, what that allowed you to do was to have zeroes in the string because the zeroes didn't have any special meaning.



LEO:  Right.



STEVE:  Contemporary languages, like most notably C, there are so-called null-terminated strings, meaning that it's - a string is any collection of characters going on as long as it wants to until a zero byte, a so-called null character.  So strings are null-terminated, meaning that you read them until, you know, you follow the string character by character until you hit a zero, telling you, ah, I just hit the end of the string.  And in fact that characteristic is indirectly responsible for many of the security vulnerabilities we have because it turns out that it's one of the ways you're able to get exploits to, for example, copy code from one place to another and do your bidding is fancy uses of this null termination.  Well, it turns out that browsers, all browsers except at this point now Firefox 3 has been fixed, 3.5 was, and NSS, which is the Mozilla package that handles secure socket technology.  They fixed that, too.  But other browsers are stopping the parsing of the domain name in a security certificate at a null.  It's not very surprising.  That's sort of what you'd expect.  The problem is that the security certificate issuers are not looking at nulls in the domains that you apply for.  So here's the scenario.  This is wonderful.  You apply for a certificate for www.paypal.com[null].mymalicioussite.com.  So what that looks like to your certificate authority is you're asking for a subdomain certificate of mymalicioussite.com.  Much like, for example, I might - I did get, like, a certificate www.grc.com.  So it's GRC.com is the root domain; www is a subdomain, as we know, of GRC.com.  But in this case the subdomain is www.paypal.com[null], then mymaliciousdomain.com.  So since you control mymaliciousdomain.com, the certificate authority says, make sure that you want a certificate for this subdomain.  You say, yes, I would like one very much, please.  So they issue it to you.  Now you have a valid certificate for this funky domain.



The problem is that browsers, not knowing any better, stop at the first null they encounter.  Technically the second null in this case is the actual end of the domain name.  But the browser really can't even be faulted for not knowing that.  So now the one thing that you could normally not do with an SSL connection is a man-in-the-middle attack because there is no way for you, if you were able to use, for example, ARP spoofing or just splice yourself into a connection somehow, there's no way for you in the middle to pretend to have the valid certificate for PayPal.com because only PayPal has it, as long as certificate authorities do their job.



But now you can now do a man-in-the-middle attack.  So if you can arrange to intercept traffic, then as soon as you see somebody attempting to go to PayPal.com, you splice into that connection, and you return your certificate with the www.paypal.com[null] subdomain.  Since it was a valid certificate issued by a certificate authority, your browser checks their certificate, sees that it's valid.  Now it does a comparison of the domain you entered in the URL to the name on the certificate.  It stops at the first null, www.paypal.com matches, and it says yes.  You are connected to PayPal.com.  So it is a functioning, valid, SSL certificate-spoofing technique that is currently unpatched on any but Firefox browsers.



LEO:  Wow.



STEVE:  Really cool.  I mean, this is just a beautiful hack.



LEO:  Interesting.



STEVE:  You know, hats off for the guys who discovered this one.



LEO:  So how would you be bit?  You would go - you'd have to go to a malicious site to begin with that was posing as PayPal; right?



STEVE:  No.  This requires traffic interception.



LEO:  Oh, it's a man in the middle, yes, yes, yes.



STEVE:  So I don't want to - now having talked about how cool this is, I want to back the terror level off from all of our listeners because this isn't going to a malicious site.  This isn't - they're like, in order to do this, this is a man-in-the-middle attack.  So it's only somebody who can be filtering your traffic, who can be - now, for example open WiFi.  Open WiFi is prone to man in the middle because there's no encryption on your connection.  So this is a perfect example of something that ARP spoofing, which for example in a hotel that uses hubs instead of routers that we've talked about years ago, or in an open WiFi situation, you can imagine a toolkit where that could be developed.  I'm sure they're in the works right now.  It may well already be that Metasploit supports this because it doesn't take them long to do, to update their Metasploit framework for these kinds of things.



And this got everybody intrigued.  But it means that you have to have your traffic intercepted.  So absent that, there's no way that somebody could use this funky certificate.  You can imagine all the certificate authorities who also know about this are going to get on the ball and be careful not to issue domain names with null characters in them, and that very quickly all the browsers will be updated in order to be smarter about this.  So I think this will close fast.  But it's open at the moment, except for Firefox.



LEO:  And you probably don't have anything to worry about.



STEVE:  And you probably don't have anything to worry about.  I mean, it would really require someone have access to your traffic.  I would say, in the habits that most people have, nonsecured WiFi is the really - is the only obvious place where this could happen.  And frankly there it's trivial.



LEO:  Sparky is saying, what about a blended threat using a DNS spoof, perhaps?



STEVE:  That's a very good point.  That's another way of somebody getting you to go to the wrong site.  So if you - because normally the DNS spoof would take you to the wrong IP for what you thought you had entered.  Oh, wait, no, that wouldn't work because you would - your browser would think it was going - let me think.  Would that work or not?  The certificate - oh, yeah, that would work, absolutely.  Your browser thinks it's going to PayPal.com.  It goes to the wrong IP.



LEO:  But gets the certificate.



STEVE:  Yes.  The server there returns its valid certificate that's got PayPal.com on the front and mymaliciouswebsite.com on the back, and your browser would be completely happy with it.  So, yes, that's another - DNS spoofing does allow and support a man-in-the-middle attack.  But again, you know, that's still less common than anybody using open WiFi.  Which, I mean, I'm, in Southern California I'm surrounded by it.



LEO:  Oh, everybody, yeah.



STEVE:  Exactly.  People are annoyed that Starbucks makes you log on.  Of course, once you do it's still unencrypted.  So it might as well be open.  So, yeah, anyway, this is just very cool.  And I imagine we will see immediate updates for the SSL back-end components of all of the browsers just as quickly as they can deal with it.  And of course we'll let our listeners know.



LEO:  Question 2, Andrew H. in Texas says Microsoft Security Essentials not free for all:  Hey guys, sorry to be the bearer of bad news.  I think we said it was free.  Microsoft's Security Essentials is not free for commercial use.  According to the website, it says "for your home PC," and it will not run on Windows Server.  Also David Horwitz in Denver, Colorado says the same thing:  I really learn and enjoy your weekly podcast, Steve.  I'm using Microsoft Security Essentials beta, very happy with the usability of the product.  What is your ability, I'm sorry, your opinion of the product, and when will it be available without the beta label?  Thanks for all the good information.  David.  So, yeah.  It's not for commercial use.



STEVE:  Essentially what happens is Microsoft has taken their high-end corporate IT Microsoft Forefront product - that's where this came from.  That's Microsoft's big iron sort of formal corporate level.  They've been able to test it and round it out and make it work, develop all the signatures and patterns and really nail this thing down.  Then what they're doing is they're peeling off a sort of like a junior version of it, which will be available for home PC users.  They're deliberately crippling that, that is, the Security Essentials, so that it senses whether it's running on a - someone's attempting to run it on a server platform.  And it will not run on their Server versions of Windows.  Which Microsoft has done similar things like this before.



So I remain bullish on Security Essentials, to answer also David's question.  I am so excited that Microsoft is going to get into this.  The people, security researchers who have been looking at it, are very impressed...



LEO:  Good.



STEVE:  ...with its zero false-positive track record so far.



LEO:  Okay.  That's good.  But does it also - how accurate is it in finding viruses?



STEVE:  It's deadly accurate.



LEO:  Oh, that's excellent.



STEVE:  I mean, I think this puts everybody else in real trouble.  So, I mean, I'm not shedding a tear because I know, you know, I've got so many people who are just not that computer savvy.  And they'll be much happier, I mean, these are the people I can't drag away kicking and screaming from IE.  So it's like, okay, fine, stay there.  But just tell Microsoft you want Security Essentials.  And as far as I know it's going to be later this year.  So later in '09 it's supposed to be happening, out of beta.



LEO:  We've been talking about it on Windows Weekly.  And I just don't remember off the top of my head what the official date is.  But anyway, yeah, soon.



STEVE:  Good news, and we'll certainly let everyone know.  And it's the first AV I will use.  I just, you know, I've gotten along without one being careful.  But I'd like the idea of it being - the problem is, so many of these are just glommed onto Windows and cause more trouble than the virus, especially if you never get any.



LEO:  Right.  And, you know, I'm just saying - beta tests started June 23rd...



STEVE:  And immediately shut down because they offered 75,000, and it just sold out in less than a day.



LEO:  And all they say is by the end of calendar 2009, as you said.



STEVE:  Right.



LEO:  Question 3, Phil in Los Angeles wonders about cellular broadband security.  This is a good question:  Steve, I've recently started tethering my G1 phone to my laptop to get Internet when I'm not near a wireless connection.  I was wondering what are the security implications for doing this?  By tethering, or using something like the MiFi, which is the $60 a month EVDO solution...



STEVE:  I'll have one by the end of the day, Leo.



LEO:  I love it.  I love it.  Is the connection as unsafe as hardwiring my laptop to the Internet without a router?  If so, what should I be doing to keep my computer as safe as possible while tethering?  In the event you answer this question, please keep the response as simple and pedestrian as possible.  I'd like to understand the answer.  Me, too, Phil.



STEVE:  Okay, Phil.  There's many different areas of broadband security.  One is the idea of cracking the relatively - even more than relatively - the very weak encryption of the connection.  There are cracking devices around.  They're not common.  They're expensive.  But they exist, meaning that the "encryption," unquote, that is being used for our digital cellular connections today is not near the grade of encryption that is available everywhere. 



LEO:  Really.  Oh, I didn't know that.



STEVE:  Yeah, they used - remember the problem is that these standards were put in place when phones had calculator watch chips in them, you know, really low power technology is when these standards were put in place.  So now we're all carrying computers around in our pocket that decompress highly compressed MPEG-4 video at 30 frames per second.  I mean, these things have computing power just falling out of themselves.  But that wasn't the case back when these standards were built.



So, for example, there are multiple shift registers with prime numbers of bits which rotate in a circle, and the outputs are XORed in order to create a pseudorandom bit stream which is XORed with the digital data.  We know that if that pseudorandom bit stream was really high quality, really random, and could not be guessed, that XORing your digital data with that makes virtually uncrackable encryption.  I mean, it's very good encryption.  The problem is, if you just use some shift registers that everyone knows about - I mean, this is in the spec, it's in the standard.  They tried to keep it secret, which of course is the first bad sign.  They didn't want anyone to know.  But inevitably this information got loose.



And so they also used frequency hopping so that it's not - you don't just put up an antenna and suck this stuff in.  You need to be clever about tracking the frequency jumps that the digital signals make.  But that's all been done, too.  So there's that aspect of it.  But when he specifically asks relative to hardwiring an external router on his computer, that makes me think that he's talking in terms of, like, the attack, external attacks within the channel, which is itself not as secure as we would like, as I was just saying.  And I just realized I completely blew him out of the water because he wanted a simple and pedestrian answer, and I don't...



LEO:  I wasn't going to - I was going to let you finish, and then I was going to say, okay, now tell me the answer [laughter].



STEVE:  Okay.



LEO:  No, keep going with the technical one.  I think that that's important.



STEVE:  Okay, so...



LEO:  But then we'll get the bottom line after that.



STEVE:  So there's the one problem of someone actually cracking the wirelessness of your connection.  And that exists, but it's very, very slim.  Then there's the problem of you being on the Internet.  And so in that sense it doesn't matter how you're on the Internet.  In this case he's on the Internet using broadband cellular.



Now, there's two possibilities.  And we actually discussed these a little bit last week.  Remember there was a - someone wrote in and asked why do I sometimes have this IP, and it was like 142.something or other, meaning a public IP, and why do I sometimes have 10.something, which is a private IP?  So if you had a public IP, then it's very likely that any traffic out on the Internet can come to you.



If you are behind - if you have a private IP, like 10.something, then that means that someone somewhere, no doubt your ISP, your cellular broadband provider, has a NAT router, which is a NAT just like you might have.  It's not quite the same as yours because it's possible that other people on the cellular network could have access to you.  They also have a 10-dot IP.  So do you.  So there might be some visibility from one phone connection to the next, so it's not as private.  But at least you're protected from the public Internet behind a NAT router that doesn't know how to send traffic to you unless you've got a connection established to that external location.



So again, the problem is this isn't a simple, easy answer to - or easy question to answer, if you're going to broadly look at the implications of cellular broadband security.



LEO:  I guess the question is should I - are there any precautions I should take?  Should I stay away from banking?  What should I not do?



STEVE:  Okay.  If he talks about as unsafe as hardwiring his laptop to the Internet without a router...



LEO:  It's not that unsafe.



STEVE:  Then really the only thing a router is providing you is essentially a hardware firewall.  So you've got a software firewall in any computer you're now using.  The Macs have them, Windows has them, Linux machines have them.  So if you're behind your software firewall, since you're not concerned about malware in your machine messing with it, you're concerned about external threats getting in, you're safe.



LEO:  Okay.  But don't assume that every transaction is encrypted.  Or safely encrypted.



STEVE:  That's very much the case.  Well, you've got encryption on your broadband.



LEO:  Just weak encryption.



STEVE:  It's not state-of-the-art powerful.  It's not AES, SSL-style, or triple DES even.  I mean, it's weak encryption.  But it's way good enough so that it's very unlikely that anyone is going to be able to hack in and track your spectrum frequency jumping cellular phone all around.



LEO:  And they'd have to be going after you particularly?



STEVE:  There's now equipment which is very good about cracking this kind of stuff.  But it's very expensive.  It's not stuff that hobbyists have.



LEO:  Okay.  So I guess the pedestrian answer is you probably don't need to worry about it.  Theoretically it's a possibility.  But it would have to - it's a pretty high-end thing to do.



STEVE:  And wherever possible use SSL.  If you've got an SSL connection, then irrespective of everything else, even if they could hack into your frequency spectrum-hopping, pseudorandom stream-encrypted connection, then they hit real industry-strength encryption, and they don't go any further.



LEO:  I always, you know, of course your banking and all your purchases are probably SSL anyway.  But I try to - the one thing that really is a vulnerability it seems to me is your email.  If you're not sending that password encrypted, if you're not reading the email encrypted, you should.  And most email providers will let you do that.



STEVE:  Yup.



LEO:  John Jones in Wirral, U.K. is seeing red in Firefox:  Hi, Steve.  After having problems with some sites that I need to visit responding very sluggishly, I finally complained to the admin of one of those sites.  He said, "Well, you're using IE7.  That could be the problem."  He says his site was not meant to be used by such an old browser.  It's not that old.



STEVE:  No.



LEO:  Whilst I balked at the thought of IE7 being old, I thought, oh, well, what the heck.  I got the latest version of Firefox and have been forcing myself to use it after hearing that you are now exclusively, except for updates, doing the same.



STEVE:  Yup.



LEO:  The good news is all my sites are indeed much snappier now.  However, I have noticed something in Gmail that is bugging me.  I have my account settings to always use HTTPS.  This is exactly what we were just saying, which is he's using SSL when he logs in and reads his email in Gmail.  And when I initially log into my account, it shows HTTPS and the rest of the URL in green text as one would expect.  I'm safe.  But after a few minutes of maintaining my emails, I've noticed the text in the URL has gone to red.  It still says HTTPS, but now it's red.  If I right-click and view the page info it says, "Connection Partially Encrypted."  This is - I get this message a lot from IE, as well.  Well, this page is only partially encrypted.  You want to continue?  Doesn't tell you what part.



If I further click on Details it says, "Parts of the page you are viewing were not encrypted before being transmitted over the Internet.  Information sent over the Internet without encryption can be seen by other people while it's in transit.  The URL text never goes back to green until the next time I log in, but never stays green. What's going on?  Are my transmissions encrypted or not? 



STEVE:  Well, people who used to use IE may be familiar with the little popup that IE generates.  It says, "This page contains mixed content."



LEO:  Mixed content, yeah.



STEVE:  That's what they used to say.  And I can't diagnose what's going on with Gmail, but I can explain what this means.  It's probably not something to concern yourself with.  But my guess is there's a little glitch in Gmail somewhere.



LEO:  Well, I think I can answer.  I mean, I think some of the text that's sent by Gmail, perhaps the Google ads, they're not encrypting.  But I'm pretty certain your email is encrypted.



STEVE:  And that's why I'm suggesting that it's really not something to worry about.  Now, remember that the way a web page is built is that there's the main body of the page, which is the text typically that you get from the URL.  It says HTTPS, which is your assurance that that portion that is the original sort of text content is encrypted.  The problem is that when the browser receives that, it contains requests, other URLs to other stuff, for example, images and other components of the page.  They all, if they don't specify any HTTP://, that is, if it's a so-called relative URL, where for example it'll just say the URL is /images.google.com and then the name of the image, what the browser does is, it just says, oh, this is relative to the current page, meaning that whatever encryption the current page is using, that fetch for that asset, that image will also use.  So there you sort of automatically get all of the assets of the page fetched over the same encryption or not as the main page.



But if, as Leo suggests, for example, ads may be explicitly saying http:// and then the rest of the URL, that's telling the browser explicitly use nonsecured fetch for this particular asset, that is, it overrides the default for the page which is established by the URL of the page.  And that's where the red comes from in the page.



Now, the reason I'm hesitant to draw any really firm conclusions is that there's probably nowhere on Earth you find JavaScript so heavily used as at Google.  And lord only knows what, I mean, basically you're downloading a program when you are using Gmail which is getting more sophisticated by the month.  So, again, it's just impossible to know what this JavaScript is doing as you click around among pages and  things.  It feels to me like it loses synchronization or something gets lost where it was trying to hold onto initially, at least from John's explanation.  He says, after a while of maintaining my mail something goes red.



LEO:  I think UrbanWarsNet in our chatroom has actually hit the answer.  Some of the email you're getting probably is HTML and has relative links within it to unencrypted content.



STEVE:  Ah, that's exact- that would perfectly do it.



LEO:  Yeah.  Because if it were the Google ads, well, it would immediately go red.



STEVE:  Precisely.



LEO:  But if it's tied to various mail you're looking at, it might not go red until that kind of - you view that kind of mail.  And then all of a sudden, oh, yeah, well, part of this page is unencrypted.



STEVE:  Now, John, who asked the question, does say that once this happens, it never stops happening until he logs out.  So again, I think the idea from the guy in the chatroom, I mean, that makes sense.



LEO:  That makes sense, yeah.



STEVE:  But again, so much is going on with something like Gmail, which is just script land, that it's difficult.  My original explanation here sort of applies mostly to a generic typical web page.  These things are so automated now, it's difficult to know.  My guess is it's a bug.  That is, if you log out, and you log back in, and you're green again for a while, then something times out or something fetches something or refreshes or who knows what's going on.   But that's at least what the red means.



And again, I couldn't definitively say whether the textual content is safe or not.  One thing you could do if you were really curious and had the ability would be to monitor your packets.  I mean, put a packet monitor on and see what content it is as you move around from one mail to the next which is going over the wire in the clear.



LEO:  Yeah.  That's the problem is they don't tell - they browser doesn't - it says some of this is unencrypted.  They don't say which.  They don't say what.



STEVE:  I mean, with Gmail or anything on Google it's become a program.  I mean, it's a client-side program you're running.  It's not just a browser anymore.



LEO:  And UrbanWars said it would make sense that if it was the message it would stay red because now that that session has been  - some of it's unencrypted, it's not going to go green again.



STEVE:  Well, but if you went to a different - if you went, like, back to where you were before and looked at...



LEO:  The whole page is SSL.



STEVE:  Yeah, if you went to mail that didn't have any of those problems, you'd expect it to say, oh, look, now it's all encrypted again.  We just don't know.



LEO:  I don't think it's that smart.



STEVE:  But that's what it means.  It's not really - we don't know that it's really bad.  I think it's just a bug.



LEO:  Ryan in New York, two questions and a comment.  He says:  Hi, Steve.  I have two questions for you.  You've talked a lot about wireless encryption on your show.  Because of it I've always stayed on top of the latest wireless security measures for my home router.  Recently I bought a new router to upgrade to Wireless 802.11n.  After hooking up the router and making sure I can get online, the next thing I did was go to the wireless settings page, turning on WPA2 encryption.  That's when I noticed something I'd never seen or heard about before:  WPA-PSK [TKIP] + WPA2-PSK [AES].  I am not sure exactly what that means.  Does it use both forms of WPA to encrypt the signal?  It's got a plus.  And if so, how does that work, and why would I want to or not want to do that? 

 

Second question, a quickie.  My parents are fairly well-connected.  My mom just recently bought a laptop.  I've noticed that their passwords for email and other sites just make me cringe.  I have tried to explain to them why they should use better passwords, but they seem to either not care or don't want to bother with the hassle of - and I bet you this is it - remembering more complex passwords.  I'm not sure what to do.  I'm afraid that they use similar 

passwords on their bank accounts.  Is there any easy way to get them using passwords at least better than things like "qwerty" - I see a lot of people use passwords "asdf," which is the first four letters on the second row, I mean, it's like, come on - short of me writing a program that can manage their passwords for them? 

 

Thanks so much for the show, you have no idea how much help you have been for me in understanding computer science concepts before I actually learn them in class.  Many times you go more in depth and explain things much more clearly than some of my computer science teachers.  Please keep 

up the good work.  This show is more of a never-ending computer science and crypto course for me than a podcast.  You really should write a textbook or ten.  Signed Ryan in New York.



STEVE:  So, okay.  There are some routers which are offering sort of an either one of the above encryption.  So you could choose WPA-PSK using TKIP, or you can choose WPA2-PSK using AES, or you can choose both.  And the idea is that it would allow you, it would allow the router to accept connections from clients using either.  Now, if PSK, if the TKIP encryption were a lot weaker than AES, I would say you definitely don't want to choose that.  You would want to just use WPA2-PSK with AES.  But there's really nothing wrong with WPA-PSK with TKIP encryption.  It's lighter weight, requires less processing.  So it's really not a bad thing.



On the other hand, if you know that your devices you're going to want to use all support the latest generation, the so-called WPA2-PSK using AES encryption, then it's a tiny bit more secure to tell your router only allow connections with the best possible encryption.  I mean, in general security best practices that's certainly the case.  You only want to allow the most secure things.  You don't want to allow less secure fall backs.  Although in this case TKIP is fine as long as it's WPA and not WEP, which was the bad stuff.  So that's what that option is.  It lets the router accept connections using either of the encryptions, not forcing it to choose one or the other.  It lets the connecting device specify which it wants to use.  And again, if you know that the things you're connecting support AES encryption, I would choose it on the router, too.  It just makes more sense.  As for your folks, I don't know what to tell them.



LEO:  Make them listen to this show over and over and over.



STEVE:  Yeah, I just, you know, I can - this is the problem, is they could very well go about their whole lives using bad passwords and never have a problem.  We know that many people using bad passwords get hacked.  As a percentage, I don't know what percentage of people get hacked having bad passwords.  But for those of us who follow security and care about security and recognize that bad things really do happen to good people, using complex passwords makes us feel better and makes us more secure.  There's no doubt about it.  Whether your parents have enough security, it's just impossible for me to judge.  And I don't know, I mean, I don't have any magic elixir for suddenly getting them to care more.



LEO:  It really is the issue of making it easier to remember.  And that's why people use bad passwords because they can remember them.  And it's certainly no better to put post-it notes down the side of your screen with those hard-to-remember passwords.



STEVE:  You know what I would get?  I guess what I would suggest is, those of us who are really security conscious are good about not reusing the same password.  What I would - a compromise would be to come up with one really good password, that is, upper/lowercase, a few special symbols, maybe tie it into something in their lives like mix their date of births in with the alternating letters of their dog or something, something where you could say here's how I came up with this.  Just if you guys can memorize this, change everything that's qwerty right now over to this.  So maybe...



LEO:  Better than nothing.



STEVE:  Exactly.  So it's a compromise.  You tell them, just one unbreakable password.  You really ought to have different unbreakable passwords.  But that's - I really understand that's going too far.  So a good compromise is just one really good password that they would just memorize once.  You could quiz them over dinner.  Say okay, Mom, what is it?  And get them to switch over to it.  I think that's probably the best you can do.  And frankly, that's pretty good.



LEO:  You know what I use, and this might be simple enough for Mom and Dad to get using with it, I have a master password which, as you described, is that one password that's not a dictionary password.  It's easy to remember for me because it's an acronym for a long sentence.  And then I mix cases, and I put punctuation and stuff like that.  And then I use that master password with a website called SuperGenPass.  Have you ever seen this?  It does a hash between the master password and the top-level domain.



STEVE:  Right.



LEO:  So when I go to PayPal.com, I press - I have a bookmark on the top of my page that generates this password.  It'll ask me for the master password and then hash the master password, which is always the same...



STEVE:  And give you some gobbledygook.



LEO:  And it gives me really, really gobbledygook.  And that gobbledygook is the unique password for that page.  It's only used on that page.



STEVE:  Or for that domain.



LEO:  I'm sorry, that domain.



STEVE:  Right.



LEO:  But I can always regenerate it as long as I remember my master password.  And the bookmark does it for you automatically.  Then that way, when they go to a page, they press the button, it fills in the password for them.  You can even have it remember the password, which is probably not the most secure thing to do.  But so you always have unique passwords that are really good, strong passwords.  And all you have to remember is one password.  This is how I do it.  I mean, it's worked for me.  Doesn't work everywhere because some - and it has your favorite thing, JavaScript, running in the background.



STEVE:  It really - that ought to be just an add-on.  I mean, it's a perfect little thing.



LEO:  I think so, yeah.



STEVE:  Instead of having to go to - I don't like the idea of going to a third-party site and having them do that for me.



LEO:  Well, you don't.  You can download the JavaScript.



STEVE:  Oh, okay.



LEO:  Actually the JavaScript in my case - it depends on your browser.  IE won't do this, but Firefox will put the JavaScript in the bookmark.  So the JavaScript's running from the bookmark.



STEVE:  Okay.



LEO:  It's not a very complicated, I mean, you can look at the code.  And it can embed it in the bookmark.  So the bookmark just says what's the TLD, hash it with the master password, what's the master password, hash it, spit it out, and it actually fills in the password field automatically.  That's SuperGenPass.com.  And I think it's a good way to go; you know?  Anyway, that's my suggestion.  That's kind of in between what you were suggesting and true security, which would be using a 64-byte Perfect Password every time.



STEVE:  A nightmare.



LEO:  A different one every time.



STEVE:  And then a database to keep track of all that.



LEO:  Yeah.  Somebody's correcting me, yes, it's a "bookmarklet," not a bookmark.



STEVE:  Bookmarklet.



LEO:  Bookmarklet.  And it uses JavaScript.  Let's see here.  David Johnston in Sydney, Australia says thank you for talking about W3C validators.  He says thanks for bringing up - wait a minute, no no no, let's go back a little bit actually, speaking of W3C.  Kevin Ghadyani in Overland Park, Kansas was the guy who sent us in the message about the errors.



STEVE:  Exactly.



LEO:  He says:  Thanks so much for reading my question.  I've been listening since 2005 - which is I think when we started.



STEVE:  I think so.



LEO:  ...back when I was in college, and was extremely surprised to hear my question read on the air.  Thanks for discussing it.  I will cover GRC on BadMarkup.com.  Oh, it's his site.



STEVE:  Yup.



LEO:  But also explain your reasoning.  Fortunately for me, you have well-written show notes for referencing purposes.  Yes.  That's one thing Steve does really well.  Here's some personal bits.  While I'm not adept enough to program an entire blogging system myself just yet - as you have, Steve - my business's website and any future one I've been programming using PHP and Notepad++.  Had I not used PHP, I could understand how difficult making a site like GRC is.  I actually use PHP to change the CSS files I send to browsers, even changing the DOCTYPE and meta tags for older browsers 

like IE, which is why my site is even IE4 compliant, haha.  Other than Google Analytics, I run no JavaScript on my site and have a good policy to make it work on all browsers including mobile and Pocket PC devices.



I love what you've done with GRC.  Because of that, you're the main person I think of when I do web design.  I always tell people, "If Steve can do it without JavaScript, so can I."  Much with the way you program in Assembler, I try as hard as possible to use the most efficient methods in any sort of design I do because I know there's someone else out there who does them, too.  Thank you for such a great show.



STEVE:  Well, I liked that as a lead-in to - and remember, this guy was critical of the 13,000-some-odd errors on the Security Now! page.  And I said, yeah, okay, that's true.  I don't care.



LEO:  Because it's hand coded, baby.



STEVE:  Well, and, yes, and I'm not doing per-browser customization.  That's just not the approach I took.  I certainly could have used the User-Agent header in the request to determine what browser was pulling the page and then customized the page per browser.  But for me the pages are there, they do their job, and I'm fine with it.



LEO:  Yeah.  And that really is only practical, I think, if you're using JavaScript because you have to do if-thens and stuff like that.  It's hard to do in plain HTML.  So that segues to David's question...



STEVE:  Exactly.



LEO:  ...from Sydney, Australia, "Thanks for talking about W3C validators!"  Dear Steve, thank you for bringing up the topic of W3C.  W3C is the World Wide Web Consortium, by the way.  They're the ones who make the HTML standard.  It's run by Tim Berners-Lee, the guy who invented HTML.  Although I am an idealist and wish that every browser and site used compliant code, this just isn't the world we live in.  I, too, have been hand-coding sites for many years, pride myself on having sites that work on a very large range of browsers.  I'm so tired of having to defend my work in the face of W3C validators and those with just enough knowledge to run them.  So thank you for making me feel a little bit better.  That's nice.



STEVE:  And I thank David for making me feel a little bit better.  All of those of us who are out on the edge saying, eh, I don't validate, well, we're all together.



LEO:  You know, most sites don't validate.  Most don't have 13,000 errors, but most sites do not validate.



STEVE:  Per page.



LEO:  Per page.  That's quite a lot.  But most sites.  And very few sites will validate fully.



Kendall Bailey in Des Moines, Iowa uses Buy.com - we were talking about that.  In fact, I'm so glad, I wanted to thank you again for coming on the radio show this weekend.



STEVE:  Oh, yeah, it was perfect.  And you were right that it's a big issue.  We had - we got a bunch of email from people sharing their stories.



LEO:  This is that issue with some etailers like Buy, Orbitz, Flowers.com...



STEVE:  Fandango...



LEO:  Fandango, kind of colluding with these web - they call them web loyalty programs, but really it has nothing to do with loyalty, it has to do with money extraction, giving them your credit card and letting them very easily charge you without...



STEVE:  Well, selling them your credit card.



LEO:  Oh, yes.  They don't give it away for free.  Selling them your credit card because they say, well, you agreed to do it.  That's personal information.



STEVE:  It's in our fine print.  Don't you read the fine print?



LEO:  And these companies really kind of racking up charges without your knowledge because the fine print allowed them to just say, well, just give us an email address, and we'll charge you.  So I've been - I've used Buy.com exclusively with Google Checkout, says Kendall.  See, that's the solution because they don't have your credit card; right?



STEVE:  Mm-hmm.



LEO:  Never had any problem or coupon offers.  Thanks for mentioning the issue.  I'll be sure to watch out.  I use a Discover card secure online account number with Google Checkout.  Basically it's a single-vendor account number as opposed to a single-use number.  Now, we've talked about that.  PayPal offers that, as well.  Since all charges go through Google, it works for multiple Google Checkout sites.  So this is clever.  He's using one credit card.  That goes to Google.  Google then does the transaction with these other sites without giving up even that credit card.  and these other sites couldn't use the credit card.



STEVE:  They have nothing to sell.



LEO:  They've got nothing.  Since all charges go through  Google, it works for multiple Google Checkout accounts.  Buy.com is by far my most used etailer, but they don't have my email address or credit card, only my Google Checkout data.  And Google doesn't even have my full Discover account number.  So I hope I've covered myself as much as reasonable.  Have I?



STEVE:  Yeah, I think he has.  And the reason I wanted to bring this up was that you and I on the radio show after the podcast talked about this notion of using PayPal or Google Checkout.  I don't know if there's - are there any other third-party suppliers...



LEO:  There are a lot of them.  But those are the big two.



STEVE:  Yeah.  And I don't encounter others very often.  I'm happy to see more and more Google Checkout.  I like Google.



LEO:  I'd like to use Google.  I would.  I'd love to use Google all the time.



STEVE:  Yes.  And so I just wanted...



LEO:  Amazon is the third one.  It's very common.



STEVE:  Amazon as a - no kidding.



LEO:  Yeah.



STEVE:  So you go to a site that's not selling books or anything, and you can use Amazon in order to...



LEO:  I think so, yeah.



STEVE:  ...pursue your transaction.  Okay, I hadn't seen that.  But anyway, the idea being that the beauty of that is you're keeping your credit card information confidential from the site from which you're buying.  They've got a relationship with PayPal and Google Checkout, maybe with Amazon or whatever third party you're using to provide the assurance of payment.  And there's nothing for them to sell.  So they can be as loyal to the web as they want to be, and unfortunately get nothing but the purchase price, no money for selling your credit information to some third party.



LEO:  Matt Ridley in Appleton, Wisconsin wants to scold us.  He says:  Love the podcasts since I found them around Episode 150 or so.  Oh, you've got a lot to listen to, Matt.  In fact, I have to say that while we do cover topical stuff at the beginning of every show, most of what's in these shows is timeless.



STEVE:  Yes.



LEO:  If we're not talking about specific security flaws, a lot of what we're talking about is fundamentals that, you know, you can listen to Episode 1 and learn something that's useful today, even though it was four years ago.  However, I think I'm missing something.  After listening to the massive security update - that was 206, couple of episodes back - you and Leo commented at the end of the show you don't understand why we can't be proactive and take these bad computer clusters down.  We were talking about botnets, I guess.  You didn't reprimand the BBC - or didn't you reprimand the BBC just a month or two earlier for buying a botnet and, after researching it, notifying the users that they were part of a botnet, as being a violation of privacy?  What's the difference?  I completely agree we need to have something that can scout and clean these botnets - although the term "Skynet" seems to come to mind - but I fear the  same privacy rage as being a result.  Or am I missing what was being said about the proposed solution in the original story?  Yeah, I think he misunderstood us.



STEVE:  Yeah, he did.  We were not saying that we wish that it was...



LEO:  We didn't advocate taking these botnets down.



STEVE:  Exactly.  What we were saying was, we were talking about, in the future, we imagine that the laws will change.  There's pressure to get the laws to change because the bad guys have such an advantage over the white hats because the white hats, who know how to counterattack, how to disinfect, how to commandeer a botnet and shut it down, are unable to do so because even in the best interests of the Internet, the world, the people whose computers have been hacked, even though we're trying to help people, it's against the law.  We can't break the law.  The bad guys already are breaking the law.



So the problem is we need the law to change.  So our reprimanding the BBC for doing what they did was that they presented a notice on people's computers telling them that their machine was infected, and here's where you need to go in order to fix it.  While that was in the best interests of everyone, and I don't disagree with that at all, it was not legal.  And they got not just us, but many people were upset that that's what the BBC - and actually they did it through an affiliate security company and so brought some good, needed attention to this, but technically broke the law, at least what is U.S. law, in the process.



So what I'm bemoaning is that there's no level playing field at the moment between the bad guys and the good guys.  I mean, there almost never is.  But from a technology standpoint our hands are tied at the moment, the good guys' hands are tied, while the bad guys run around in circles and do whatever they want to.



LEO:  Well, and maybe appropriately tied.  I don't really think it's a great idea - that's vigilante justice, and I think it's probably not the ideal way to solve this problem.



STEVE:  Yes.



LEO:  I wanted to mention, and we forgot to mention this in the news update, and maybe next week we can talk about it.  One of the things demonstrated at Black Hat was something called a bootkit, which is a combination of a rootkit and a modification of the master boot record that allowed you to bypass TrueCrypt's full disk encryption.



STEVE:  Yup.  I know about it.  I looked at it, and it actually doesn't do that.



LEO:  Oh, good, okay.



STEVE:  Yes.  What it does is it installs some hooks into the system such that if you're using whole disk encryption, it's able to be a trojan even though you've got whole disk encryption.



LEO:  Oh, okay.  It doesn't unencrypt.



STEVE:  No.



LEO:  It launches itself before the encryption takes place.



STEVE:  Precisely.  It's able to hook - it only runs on BIOS, not EFI BIOSes, traditional BIOSes.  It hooks Interrupt 13, which is the disk BIOS interrupt.  And so the idea is it's malware you can get on your machine which gets on even though you're using TrueCrypt to protect your drive.  So but it's not bypassing TrueCrypt encryption at all.  It's just riding along and sneaking in and then staying alive after you've provided your password and decrypted your drive.



LEO:  Well, thank you for that update.  I'm glad I asked.  Question 10, we're going to talk about Fandango.  Justin Lowmaster in Oregon says:  I ordered some Fandango tickets before - Fandango lets you buy movie tickets - and likely never again now.  And yes, I had one of those coupon offers, the loyalty system, pop up.  I think there was an incentive, a "free" - huge quotation marks - movie ticket.  Oh, dear.  That's a lousy incentive.  Nine bucks, thank you.  I looked all over the page, found nothing mentioning a charge or a fee.  I signed up and, yes, I got a free ticket code, intending to cancel the service if I didn't want it.  Some time later I found an odd charge on my account. 



STEVE:  Whoops.



LEO:  I looked up the company and found a number and called them.  I got the service canceled.  I got the money refunded.  There was no hassle.  They know.  And nobody ever does this, so they can afford to be generous.



STEVE:  Exactly.



LEO:  It was indeed the offer I had signed up for at Fandango.  I had assumed I just missed the fact that I would be charged until I heard your Episode 207.  Thanks for letting me know I didn't miss a notice, it wasn't there.  While Fandango is a useful service, I think I'll take my chances at the box office instead of buying tickets online.  P.S.:  I just got SpinRite.  No miracle stories yet, but maybe someday.  No, maybe not.  Maybe you won't.  Maybe you don't need a miracle.  I'm just glad to have it at hand.



STEVE:  Well, if you run it from time to time, you won't need a miracle, exactly.



LEO:  It's a miracle avoidance system.  Think of it that way.  How do you like that?  By the way, another intermezzo, Apple has just released an update for Leopard, 10.5.8.  They don't mention any security fixes, but I am sure they're in there.  They do say it enhances stability, compatibility, and security of your Mac, so...



STEVE:  And that's always good.



LEO:  We don't know what, we don't know what...



STEVE:  But it does something.  So I just wanted to toss in Justin's comment.  Here was a listener who actually fell into the net of the web loyalty, had an authorized charge occurring on his card.  He didn't know it, but it apparently would have been periodic, that is, he subscribed to something.  So it may not have been a one-time charge.  But he jumped on it and got it reversed.  And as you said, Leo, they'll certainly not fight you on that.



LEO:  Would hope not.  I mean, geez.



STEVE:  Yeah.  And so this stuff really did - it does happen, and it did happen to a listener.



LEO:  Do you review your credit card statements every month carefully with a fine-tooth comb?



STEVE:  Sue actually does.  My bookkeeper does.  And so, and she asks me, she says, Steve, I need your receipts, because I pile them up in my wallet as I'm doing things, and also I'm printing them out when I buy things on the web.  And she matches up everything.  And there have been times when she's said, okay, I didn't get a receipt for this, and what's this charge, do you recognize this?  I go, oh, yeah, I know what that is.  So, yeah, I've got her watching.  And it's, you know, it comes in handy.



LEO:  I've got to start doing that.  Dan in Walpole, Massachusetts reports that his parents' computer got trojaned - again.  Dear Steve, my parents' computer has gotten infected by a trojan twice in the last six months.  First time they got Antivirus 2009.  That bit an awful lot of people.



STEVE:  Yeah, we talked about that.  35 million people.



LEO:  Was that the final count?  Holy-moly.



STEVE:  Yeah.



LEO:  I had them back up their data and restore from Dell's hidden restore partition.  I'm not sure how they got "owned" this time.  But they were getting pop-ups from "Home Antivirus 2010."



STEVE:  Well, it's nice that they updated the year.  They're staying ahead.



LEO:  He's done some research, he says that's usually installed by a trojan.  Maybe Malwarebytes can fix this - Malwarebytes.org is the place to go.  That does get rid of some of these versions.  And most - better probably yet is the Microsoft Malicious Software Removal Tool, MSRT.



STEVE:  Yep.



LEO:  But I suspect another backup and restore is in their future, he says.  They have antivirus software.  They have Windows Automatic Updates turned on.  I've explained to them they shouldn't click links or attachments in email.  I've installed Firefox.  I think they're still using IE, he says.  What else can I do to harden them against malware so they don't have to do a full restore every six months?  SandboxIE is going to be too hard for them.  So is a VM.  You know, you can't harden people against...



STEVE:  Bad habits.



LEO:  Yeah.  There, thank you.  I was going to say stupidity.  That's much nicer.



STEVE:  Yeah.  The only thing, I mean, the only thing I would think is he didn't mention what their email client is.  It sounds like if he's unable to pry them away from IE, they're almost certainly using some flavor of Outlook.



LEO:  Yeah, yeah.



STEVE:  Which uses the IE display control by default.  The only thing I could suggest, I mean, would be moving them to a non-Microsoft email client, maybe to Gmail through Firefox.  I wonder how they're using IE?  If he's installed Firefox, I would imagine it's now the default URL handler.  So when they click on links it's going to open Firefox.  Unless they're still using Outlook, in which case they're technically still using IE because it's what's viewing their mail.



So I would say to Dan, get them away from Outlook.  Outlook has traditionally and historically been probably the number one problem.  You could argue now that browsers are more of the target than mail.  But from the history that he's talking about it sounds like they just can't not click on things in email.  So to make that safer would be the thing, would be the next target of opportunity that I would try to go about changing.  Just switch them to something other than Outlook.  And maybe hide IE from them so that they're not able to get to it.  Put Firefox's icon where IE is and just say, no, folks, you really need to do this.  The other problem is it sounds like Dan's cleaning up their problems, and so it's really not a problem for them.  They may just be...



LEO:  They're not incented to do anything.



STEVE:  Exactly.  They're just casual computer users.  And it's like, "Oh, son, we've got a problem again.  Come over for dinner and fix our computer."  So Dan does.  Doesn't seem like it's causing them a huge problem.



LEO:  Nope.



STEVE:  But I'm sure glad he's on top of it because it could cause them a huge problem.



LEO:  You bet.  I guess, you know, the thing is we used to say don't click on links in email.  But now really anytime you get a popup that says "download something" or "fix this," that sounds like what's biting them.  They should, you know, think twice before you say, oh, thank you.



STEVE:  Well, yes.  In fact in both of those cases, both the Antivirus 2009 and Home Antivirus 2010, what happens is you go to a site, and it says, oh, scanning your computer for malware.  And it shows you the progress bar, and it says malware has been detected.  Click here to take care of it.  I mean, again, it sounds like there's an education problem.  His parents don't know any better.  So they're, oh, no, and they don't want to bother their son Dan.  And so they think they can handle this themselves.  Unfortunately, they've just gone down the wrong path.



LEO:  Maybe Dan sent it to us.  Thank you, Dan.  Antivirus 2010 is here.



STEVE:  Yay.



LEO:  What's maddening, and maybe they need a better antivirus, is that their antivirus isn't catching this.  Shouldn't it stop this behavior?  Seems like if it's got good heuristics it would notice this.  Anyway...



STEVE:  Yeah.  The problem, of course, is that's always a moving target.  They're always lagging behind.



LEO:  This is what I say on the radio show, that your software, your antivirus, your firewall, that's a second line of defense.  You are the real line of defense, and your behavior.



STEVE:  Right, right.



LEO:  David Stephens in Bloomington, Indiana wonders whether a VPN can be used to transport a virus.  Steve, I've been listening since Episode 1 of Security Now!.  I've learned so much from you and Leo in these four years.  I can't begin to thank you both enough for helping me learn so much about protecting myself and friends and family online.



Here's my question:  I was talking with my boss today, and we were wondering if a virus can travel through a VPN and infect a PC on the other end.  Her son recently had a very nasty virus infection on his PC that we think he got through a file he downloaded in Limewire.  Yeah, that sounds right.  I know, that was the first mistake.  My boss asked me today, if a virus from her son's PC was able to make the leap to her PC, would it be able to go through the VPN she's set up, back to her office, and then infect PCs there?  I thought that was a good question.  I don't know the answer.  I knew you would, though.  If this is a possibility, would simply putting an additional router in her home and segmenting off her PC do the trick?  Thanks for your help, Steve.  It's always appreciated.



STEVE:  Well, that's a great question.  And unfortunately the news is all bad.  It is certainly the case that a VPN would transport a virus, that is, it's not what it's designed to prevent.  It is essentially, like, providing a secure link between Mom's machine - which is sometimes on the home network.  But when the VPN is established, now the machine is on the corporate network and probably insulated from the home network.  So the threat model here is that when the VPN is not on, and Mom's machine is on the same LAN as her son's machine, there certainly are viruses that are LAN aware.  We've talked about them not long ago on this podcast, where there are things that propagate through Windows shares, that use the fact that they're behind the router and look for other machines on the network and jump over to them.  So that would allow an infection to jump within the LAN from one machine to the other.  And that is a frequent occurrence these days.  It's one of the ways that malware is propagating itself better because it knows that it's frequently going to have other machines that are there.



Then, when the VPN comes up, that machine which is now infected, it's essentially on the corporate LAN.  And so the same scenario recurs.  And what's worse, now we've got malware that we know is LAN-aware because that's how it infected this machine, Mom's machine, because it was LAN-aware.  So now it's on a huge LAN with all kinds of potential targets.



LEO:  Ooh, goody, goody, gum.



STEVE:  Exactly, it's just found nirvana.  So it uses its VPN connection, which is essentially it's protecting bad guys from getting in.  But once you're in, once you're on the corporate LAN, all the goodies are there and available.  So it's certainly the case that a corporation needs to protect itself - and this is a common occurrence - protect itself from infected traveling machines that connect by VPN into the LAN.  So this is a well-understood problem.



It's certainly the case that protecting Mom's computer when it's not LAN-linked into the corporate network is a good thing.  And we've talked about using multiple routers to segment a LAN so that machines can't see each other, so that you have an insecure and a secure LAN area.  And that's - we've done some podcasts on that.  So I would recommend that Dave takes a look back in time.  As you said, Leo, all of these things we've talked about are still surprisingly relevant.  You can almost wish they weren't so relevant any longer, but things have not gotten any better in the last four years.  And so that would probably solve the problem.



LEO:  Yeah, yeah.  Yeah, VPN just means it's the network.  You're just - you're expanding the network, that's all.



STEVE:  Exactly.



LEO:  All right.  So that's 12 questions.  But we do have one more side note.  And I thought we'd throw this one in at the end.  Dave Schuh in Maple Grove, Minnesota.  His subject is "Vitamin D - a great tangent."  I've been, by the way, yesterday intentionally did my rowing out on the deck at the gym so I'd get full sun.  And I even took my glasses off so the light would get in my eyes because you need Vitamin D in your eyeballs, too.  But we'll - I don't know if this makes a difference.  But let's find out.



I've listened since the beginning, and I hope you never stop doing the show, Steve.  Also a SpinRite owner.  I was very pleased to hear your take on Vitamin D, having been in the science field and following it for many years.  I'm a white male about your age, also starting to track my blood level, specifically summer versus winter.  I live in Minnesota, and for exercise I like to run.  So about six months of the year I can get my exposure without supplements.  And I agree with you that supplement amounts are very low.  So it will be interesting to see what level I can maintain during the frozen tundra months when I can't get outside.  The tangents you and Leo, by the way, go on are very enjoyable, like sci-fi. I would love to hear occasional updates on your Vitamin D research.  Thanks for the great show and all your hard work.  Dave.  Thank you, Dave.  So?  So?  I want to know.  What's the deal?



STEVE:  We're going to talk about it next week.



LEO:  Really?



STEVE:  The first episode of our fifth year.



LEO:  So why don't you tell folks, recap what you've been talking about.



STEVE:  What I have to say is that we've had a lot of people who've written in and said, love to hear about security.  It's called Security Now! for a reason, and certainly that will always be our focus.  From time to time things come up which are important.  I've been researching Vitamin D as a health hobbyist.  We all know I'm not a medical professional.  Packets are my passion, and Internet and security and coding.  But health is also a passion that I've only talked about glancingly from time to time.  But when I get into something I generally get in with both feet.  And I've read, oh, maybe 50 to 60 scientific journal articles now, and I am full to the brim with a bunch of information which has begun to sort of take form and is coherent and I think is really important.  I would argue that next week's  podcast will be the most important podcast we've ever produced.



LEO:  Really.



STEVE:  I really think so.



LEO:  Having nothing to do with security.



STEVE:  Having, for once, I mean, we're going to wander off the reservation.  But don't worry, we'll be back the week after.  But we're all human.  We all have bodies.  It is the case that from everything I've read, and I have - I'm putting together a page that'll be up next week. with links and PDFs for full documentation of everything that I've learned so people can go to the same source.  But it's very clear to me that the lag our medical system has is a problem in this instance.  This has come together in a way that I can also tell a story about how we evolved and where Caucasians came from and why.  And I believe that our listeners...



LEO:  Oh, this is good.  I'm going to tease this.  Next week:  Where Caucasians came from.



STEVE:  And why.



LEO:  And why.



STEVE:  Yes.  I mean, there's a story here.  There's an amazing amount of epidemiological research, which is only beginning to happen in the last few years.  And again, I'm not kidding when I say that for our listeners I think this will be the most important episode we've ever produced.



LEO:  Wow.  I can't wait to listen.  I'm very excited.



STEVE:  And I will spend more time producing this next episode than I have ever spent on any podcast before.  I just - I really sincerely believe it's important.  And I know our listeners care about us.  We care about them.  And believe me, I mean, I believe that one of the things people enjoy about the podcast, as we've read from time to time, that people appreciate the fact that I can explain complicated things in a way that they understand.  I may have let down our one listener earlier today who asked for a simple explanation of cellular broadband security.



LEO:  Okay.



STEVE:  But I understand pretty much the whole picture now, although I'm not a biologist or a trained medical professional.  I understand the whole picture of Vitamin D metabolism.  I'm going to explain it because it turns out to be important.  And I think our listeners will find it really fascinating.  Which is why they tune in.



LEO:  I'm sure they will.  We will.  And I should say upfront, and we'll say it again next week, you're not a - you're a scientist.  You're not a junk science - Steve is the least superstitious person I know.  So this is not going to be some airy fairy thing.  This is going to be based on research.



STEVE:  No, I mean, it's the Mayo Clinic, lots of references from the American Journal of Clinical Nutrition and the Journal of Nutrition and, I mean, serious science which has been done, which has just not come to light.  And the good news is dealing with the consequences of what I will describe is incredibly simple and inexpensive.



LEO:  And what we'll do, by the way, we'll still have the security news at the beginning and the errata at the beginning.  So you'll get that security fix.  And if you're not interested in the Vitamin D, although I think you will be, move along.  That's the beauty of a podcast.  You don't have to listen.



STEVE:  I would, yes, I will urge our listeners, I'll hook them in the first 10 minutes, I promise.  And I don't do fluff.  This will not be fluff.  This is important.



LEO:  Great.  I look forward to it.  Steve, thanks, as always.  A wonderful show, a great episode.  Thanks to all our correspondents.  If you have questions for Steve, GRC.com/feedback is the place to go, and we answer questions every other episode, every even episode, at least at the moment.  And of course at GRC.com you'll find the 16KB versions of the show for quick download, if you're bandwidth impaired.  There's a transcript.  It's very easy to download, read, and search, one of the reasons Steve does that.  Show notes are excellent there, too.  And of course all of Steve's great software, most of which is free - programs like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Perfect Passwords.  And there's one paid program out of all of that, that you must have there, and that's SpinRite, the world's finest, the only hard drive maintenance utility you will ever need.  GRC.com.  Steve, we'll see you next week.



STEVE:  Talk to you then, Leo.

	

Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#209

DATE:		August 13, 2009

TITLE:		Vitamin D

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-209.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo kick off the podcast's fifth year with a rare off-topic discussion of something Steve has been researching for the past eight weeks and passionately believes everyone needs to know about:  Vitamin D.  After next week's Q&A, the podcast will return to topics of Internet security.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 209 for August 13, 2009:  The Vitamin D Story.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure, privacy and such, with our great friend, mentor, and security guru, Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Well, usually that's what we cover.



LEO:  No security today?



STEVE:  Oh, no.  We've got a bunch of news, and we're going to run through the news of the week, things that are important and impacting our listeners.  But this is the first episode, this is #209, the first episode of year five.  And we're going to do something.



LEO:  Wow.



STEVE:  We're going to do something different this week, and only this week.  I don't want to worry and freak out our listeners.  But something has really come onto my radar that I almost feel I have an obligation just to share once.  You know, that's, I mean, I'm taking action on it with myself, my friends, my family, everyone who's important to me.  And so, you know, our listeners are important to me, and I want to, if nothing else, sort of plant a seed that may take root, that it may be a couple years from now when they hear something else, it's like, oh, now I know that's important.  Whereas, you know, they might tend to think, well, Gibson's not a doctor, so what does he know about this?  And I'm not.  I'm just sort of a health hobbyist.



LEO:  As we all should be, since it is our health.



STEVE:  Well, yes, exactly.  I stumbled on something which is, I think, very important.  I'm going to be - I'm not going to go overboard about it.  But I want to just spend this podcast so that I've said my piece.  And I'm going to, I mean, I've done two months' worth of research every day on the issue.  And I want to explain what's going on, run through some of the studies which have been done.  I've put together a page on GRC which covers this topic so that everything that I'm talking about I've got links to, so people can follow up and do additional research if they're so motivated.  If not, I completely understand.  You know, there's a whole spectrum of people, from people who just think, oh, well, whatever happens, happens; to people who are real interventionists and taking hundreds of supplements a day; and everything in between.  So what I can promise is, as always, a podcast which really, I believe, will be thought-provoking and interesting for anybody who has a body.



LEO:  Wow.  I can't wait.  But before then, is there any security news?



STEVE:  Oh, baby.



LEO:  [Laughing]  I noticed that my Macs all wanted to update today.



STEVE:  Yes.  You turned on your Mac.  I turned mine on earlier and got a big update.  What we were taken to by Apple was version 10.5.8.  Anything prior to that, whether Mac OS X or OS X Server, has some significant problems.  And in the past I've sort of stopped there.  But I thought that this was interesting enough, I want to just really quickly run through a brief itemization of what happened today, to give us - to give some balance and to draw some conclusions a little bit about what's going on with Apple.  So what was fixed?  There was a problem in the bzip2 library.  And this is coming from Apple's own page:  "Decompressing maliciously crafted data may lead to an unexpected application termination."  And it says, "An out-of-bounds memory access exists in bzip2."



LEO:  That's probably an open source library, I would imagine.



STEVE:  Yes.  "Opening a maliciously crafted compressed file may lead to an unexpected application termination.  This update addresses the issue by updating bzip2 to version 1.0.5."  Next, "CFNetwork:  A maliciously crafted website may control the displayed website URL in a certificate warning."  Their description is, "When Safari reaches a website via a 302 redirection, and a certificate warning is displayed, the warning will contain the original website URL instead of the current website URL."  Whoops.  "This may allow a maliciously crafted website that is reached via an open redirector on a user-trusted website to control the displayed website URL in a certificate warning.  This issue was addressed by returning the correct URL in the underlying CFNetwork layer."  Next, "ColorSync.  Impact:  Viewing a maliciously crafted image with an embedded ColorSync profile may lead to an unexpected application termination or arbitrary code execution.  A heap buffer overflow exists in the handling of images with an embedded ColorSync profile.  Opening a maliciously crafted image with an embedded ColorSync profile may lead to an unexpected application termination or arbitrary code execution.  This update addresses the issue by performing additional validation of ColorSync profiles.



"Core Types:  Issues are not warned before opening certain potentially unsafe content types.  This update extends the system's list of content types that will be flagged as potentially unsafe under certain circumstances, such as when they are downloaded from a web page.  While these content types are not automatically launched, if manually opened they could lead to the execution of a malicious JavaScript payload.  This update improves the system's ability to notify users before handling content types used by Safari."



There's a problem in the Dock.  "A person with physical access to a locked system may use four-finger Multi-Touch gestures.  The screensaver does not block four-finger Multi-Touch gestures, which may allow a person with physical access to a locked system to manage applications or use Expose.  This update addresses the issue by properly blocking Multi-Touch gestures when the screensaver is running.  This issue only affects systems with Multi-Touch trackpad."



RAW image problems:  "Viewing a maliciously crafted Canon RAW image may lead to an unexpected application termination or arbitrary code execution.  A stack buffer overflow exists in the handling of Canon RAW images.  Viewing a maliciously crafted Canon RAW Image may lead to an unexpected application termination or arbitrary code execution.  This update addresses the issue through improved bounds checking.  For Mac OS X v10.4 systems, this issue is already addressed with Digital Camera RAW Compatibility Update 2.6."



Then there was a bunch of problems in ImageIO.  "Viewing a maliciously crafted OpenEXR image may lead to an unexpected application termination or arbitrary code execution.  A heap buffer overflow exists in ImageIO's handling of OpenEXR images.  Viewing a maliciously crafted OpenEXR image may lead to an unexpected application termination or arbitrary code execution."  And we had another one of those, this time from an uninitialized memory access issue which exists in ImageIO's handling of OpenEXR images.  And then same thing again viewing a maliciously crafted OpenEXR image, multiple image integer overflows exist in ImageIO's handling of OpenEXR imagines.  And then even a fourth one, a buffer overflow exists in ImageIO's handling of EXIF metadata.  "Viewing a malicious crafted image may lead to an unexpected application termination or arbitrary code execution."  And a fifth one, "Processing a maliciously crafted PNG image may lead to an unexpected application termination or arbitrary code execution."  And here an uninitialized pointer exists in the handling of PNG images.  "Processing a maliciously crafted PNG image may lead to an unexpected application termination or arbitrary code execution."



In the kernel there's a problem with the handling of fcntl system calls which would allow a local user to overwrite kernel memory and execute arbitrary code with full system privileges.  So the update fixes that.  There's a denial of service problem in inetd-based launchd services which can cause it to stop accepting incoming connections under certain circumstances.  This update addresses that.  "A format string issue in the login window may lead to an unexpected application termination or arbitrary code execution."



There's a problem with MobileMe not removing credentials.  "A logic issue exists in the MobileMe preference pane.  Signing out of the preference pane does not delete all the credentials.  So a person with access to the local user account could continue to access any other system associated with the MobileMe account which had previously been signed in for that account."  So the update fixes that.



A problem with networking.  "Receiving a maliciously crafted AppleTalk response packet may lead to arbitrary code execution with system privileges or an unexpected system shutdown due to a buffer overflow that exists in the kernel's handling of AppleTalk response packages."  In networking also, "A synchronization issue exists in the handling of file descriptor sharing over local sockets."  So that's not such a big problem.



But finally, in XQuery, "Processing maliciously crafted XML content may lead to arbitrary code execution.  A buffer overflow exists in the handling of character classes in regular expressions in the Perl-compatible regular expressions, that is, the PCRE library used by XQuery.  "This may allow a remote attacker to execute arbitrary code via a regular expression containing a character class with a large number of characters with Unicode code points greater than 255."`  The update fixes that.  So there's a bundle of stuff that was just fixed all at once.  They feel less...



LEO:  That's how Apple does it, by the way.



STEVE:  Yes.  They feel less severe to me overall than the kind of things that Microsoft reports, although Apple does also tend to report less openly than Microsoft does.  They're not doing the complete level of full disclosure that Microsoft does.



LEO:  And they don't have that critical/important distinction and all of that stuff.  They just kind of say, this is what we fixed.



STEVE:  Yup.  And they do not disclose too much about it.



LEO:  In fact, they often don't even say that.  Yeah, they don't - in fact, I'm surprised you have that much detail, to be honest.



STEVE:  Right.  So I think we're seeing them opening up more.  Overall, things seem to be better.  But there are vulnerabilities that are beginning to surface from their use of open libraries.  There's another recently surfaced XML, broad XML exploit and problem that we'll talk about in a second.  So that takes care of Apple.



There was also a problem with Sun's Runtime Environment, the JRE, the Java Runtime Environment, and their development kit, the Java Development Kit.  So anyone using Sun's Runtime Environment ought to check in and get an update.  I know that normally it plants an icon down, in the case of Windows systems, it plants an icon down in the tray.  So it's possible to say, you know, check yourself and get updates.  And it's a critical problem that allows maliciously crafted web pages to trigger Java applets.  It leverages itself with Microsoft's Active Template Library, which was a problem we've talked about with Visual Studio, in order to execute ActiveX controls, and also involves display of JPEG images.  So there's a lot of things involved.  But it does affect Apple OS X, Apple's Mac OS X systems, Sun Solaris systems, many UNIX and Linux-based operating systems.  And of course Microsoft is no longer doing their own.  They're now saying, well, if you want it, get it from Sun.  So it affects Windows systems that have that installed, as well.



Microsoft gave us - we just crossed our second Tuesday of the month.  And they gave us their typical big batch of goodies.  One, two, three, four critical vulnerabilities in Office Web Components that allow remote code execution using a specially crafted web page.  Interesting, a vulnerability in Remote Desktop Connection, the standard Microsoft Remote Desktop system, which is used for displaying Windows desktops remotely and also in the, you know, I want help, I'll send you an invitation to access my computer mode.  In one mode it doesn't sound very secure.  It says the vulnerabilities could allow remote execution if an attacker successfully convinced a user of terminal services to connect to their malicious RDP, Remote Desktop Protocol, server.  Well, that seems unlikely.  Here, I need you to take over my computer and view my desktop.



LEO:  Come on in, guys.



STEVE:  Come on in, exactly.



LEO:  On the other hand, if you could get a script to execute that would make that do that, maybe that would be a problem.



STEVE:  Well, and that's Part 2 is, or, if a visitor visits a specially crafted website, then it's possible to exploit this through scripting that causes the same exploit.  So, yes, there is that also, which does seem to be much more problematical.  So that's why Microsoft gave it a "critical."  And it does allow them, you know, full takeover of your system.



There's also a new problem, which they fixed, or newly discovered, in Windows Media file processing, allowing remote code execution.  Quoting from Microsoft, "Two vulnerabilities could allow remote code execution if a user opened a specially crafted AVI file.  If a user is logged on with administrative user rights, an attacker who successfully exploited this vulnerability could take complete control of an affected system.  An attacker could then install programs; view, change, or delete data; or create new accounts with full user rights.  Users whose accounts are configured to have fewer user rights on the system could be less impacted than users who operate with administrative user rights."  So we're glad that's gone.



And then we've got what appears to be another fix to vulnerabilities in Microsoft's Active Template Library.  Remember that we talked about those problems several weeks ago.  And so this security update resolves several privately reported vulnerabilities in Microsoft's Active Template Library.  The vulnerabilities could allow remote code execution if a user loaded a specially crafted component or control hosted on a malicious website.  So, yes, this is different than the previous fix, which was where the Active Template Library was not honoring the kill bits, which is the - we've talked about this a number of times, is the way Microsoft prevents their ActiveX controls, which were never intended to be loaded by IE, from being honored and loaded by IE.  So but that - turns out there was a way around that.



LEO:  Whoops.



STEVE:  So that's been fixed previously.  And then there's four other just important vulnerabilities that I won't go into.  Basically it's the same advice as always, which is keep your Windows updated and currently patched.



We do have a substantial - I mentioned this earlier - a common library flaw in the XML library that a huge number of open source utilities and systems are using.  A Finnish security research group discovered flaws in the XML libraries used by, for example, Sun Microsystems' Apache and Python, which are consequently all known to be vulnerable because they have used this.  The discovery was made - we sort of talked about this approach before, also.  They used a program that they call CROSS, which is Codenomicon, which is the name of their firm, this Finnish security firm, Codenomicon Robust Open Source Software, CROSS.  It uses what they call "software fuzzers" to basically test the security of open source programs by throwing manipulated data at them, basically throwing all kinds of things at them and seeing if they crash.  And if they do, finding out what happened and whether there's a way to exploit that crash.



So they tested every open source library, and all were found to contain vulnerabilities, although the severity varied from one library to the next.  And quoting from them, they said the bugs are, quote, "related to the parsing of XML elements with unexpected byte values and recursive parentheses, which cause the program to access memory out of bounds, or to loop indefinitely.  And this is from the Finnish CERT, the Finnish version of Computer Emergency Response Team, that has been working with these guys to coordinate fixes among the different software providers.  They went on to say that there are libraries built on the C language which are at the highest risk because exploits can include the execution attacks in the libraries.  They said, quote, "Unfortunately, most libraries out there are written in C.  And thus errors such as stack overflows are not that uncommon.  When this is the case, exploitability depends on other anti-exploitation features that are available on the platform," such as ASLR, we've talked about before, Address Space Layout Randomization; DEP, Data Execution Prevention; NX bits, the No eXecute bits which are increasingly available; and so forth.



So what that means is that shortly we will expect updates to Apache and Python and, I mean, literally a whole raft of other tools that are using the XML common library and exposing the features of the library in a way that someone maliciously could use in order to crash or potentially commandeer the system that is using that.  So that's not good.



LEO:  Yeah.



STEVE:  I got a kick out of a new piece of scareware.  There's a fake Blue Screen of Death scareware.  Just thought I would advise our listeners.  And it's interesting because - oh, it was discovered by Sunbelt Software, our guys down, you know, Alex down in Florida.  It infects the system through fake codec and Flash Player update packages that have been planted on malicious sites.  But what's funny is that it displays on top of the Blue Screen of Death, it displays a red popup warning which directs people, saying we've scanned your system, we've found problems, this is why the Blue Screen of Death has occurred, press here in order to pursue a fix.



Well, you can't have a popup warning on top of a Blue Screen of Death.  I mean, that's like the fatal whole system lockup screen of last resort, when there's absolutely nothing Windows can do except drop you back into text mode and display this text page.  And you're hosed at that point.  So the idea, I mean, my sense is that our listeners are sophisticated enough to go, wait a minute, a Blue Screen of Death with a popup notice?  I don't think so.  But, you know, there's a certain class of people who may not understand that.  Although frankly I would wonder if less sophisticated users know what a BSOD is and why this particular screen would scare them.  But anyway, it exists.  So if our listeners run across other people who say, hey, I got a Blue Screen of Death, or that thing you talked to me about before, but it's got a red popup notice, what should I do?  It's like, oh, well, now we'll know what's going on.



And then in - we have two bits of interesting news.  Certainly what made the news since you and I have talked last, Leo, was the denial of service attack that caused a Twitter outage.



LEO:  Yes, yes.



STEVE:  For many hours.



LEO:  Boy, was that a fascinating story, too.



STEVE:  Yeah.  And of course it also took out, or, like, not to the same degree that Twitter was, but Facebook, YouTube, and LiveJournal were all affected.  And there was a lot of misinformation and people wondering what was going on or what the cause was.  Some people called it a denial of service attack, you know, like a botnet would launch.  I mean, it sort of seemed that way.  But later reports showed that there was a spam campaign that went out containing links to specific blog posts on Facebook, YouTube, and LiveJournal.  Oh, I mean, and primarily Twitter.  And so the theory was that people responding to the spam may have clicked the links, and so it was just a traditional overload of one specific server, presumably, where this one person's blog posts were located.  So maybe not a traditional botnet-based denial of service at all but just a whole bunch of people going to the same place.



And apparently Twitter's network is not as robust as, for example, Facebook, YouTube, and LiveJournal.  In fact, I read one report that said that Twitter, literally their DNS provider is DynDNS.com.  And it's like, what?  That's who they're using?  That's who Twitter uses for DNS?  That seems rather, you know, bush league to me.  So it sounds like maybe Twitter needs to spend some more money on their infrastructure.



LEO:  Their infrastructure is messed up big-time.



STEVE:  Yeah.



LEO:  Yeah.  And I think that this is not a good thing for them because when they go down like this - and by the way, they've been up and down ever since.  They were down again yesterday for the same reason.  It makes people kind of say, well, I guess I'm not going to be considering this a mission-critical application for me.



STEVE:  Well, and what's interesting, too, I mean, it's unlike websites where it's like, oh, I can't get there, I'll come back later.



LEO:  No, no, yeah.



STEVE:  I mean, Twitter is all about real-time interaction and flow.



LEO:  Yeah, exactly.



STEVE:  And what of course made the news was that lots of people have become minor Twitter addicts, and they get hooked on this constant flow of nonsense, frankly.



LEO:  Well, more to the point - I know you think it's nonsense.  It's not.  But more to the point, there are a lot of businesses that rely on this and have actually made it a part of their PR strategy.  There was one company that was going to do a product launch that morning.  And this is how Twitter plans to monetize, I mean, this is key to Twitter's future.



STEVE:  Ah.



LEO:  And if they can't provide a reliable system to do that, people are going to start using Facebook, which is sitting out there going, yeah, we were up.  We handled it.  Because they were attacked, too.



STEVE:  And does Facebook offer a Twitter compatible, I mean, a Twitter-like service?



LEO:  More and more so, yeah.  They're definitely moving in that direction.  And I think what's going to happen, I mean, this is a discussion for a different show, and we certainly talk a lot about it on other shows.  But it shows, though, that poor security or poor infrastructure or being attacked can really hurt a business, I mean, really can significantly impact a business.  And I think it will impact Twitter very much.



STEVE:  Well, and frankly, when this came to mind it was like, wow, I wonder if - first of all, it's a little bit surprising they hadn't been hit before.  They are, infrastructure-wise, apparently very vulnerable, so easy to take down.  And I was wondering, gee, I mean, again, I don't have any information about this, but whether they might have been - it doesn't look like they were - victims of some blackmail.  It's like, hey, you want to stay on the air, it's very important to you guys specifically, especially, to stay on the air.  We're going to knock you off unless you pay us.  So who knows.



And then my final bit of news comes from some researchers at UC Berkeley, who discovered from poking around that more than half of the Internet's top websites are now using Flash cookies to track users and store information about them, but that only four of those sites mention their use of Flash cookies in their privacy policies.  And just to refresh our users' memories, our listeners' memories, traditional cookies are browser cookies.  And probably everybody knows about them.  There's a UI that's very available and visible on browsers that allows you to manage your cookies, to delete them, to turn them into session cookies so that they're not persistent, to allow some sites to keep cookies and others not to and so forth.



Flash cookies are Adobe/Macromedia's own completely separate channel which allows data to be stored, surprisingly large amount of data actually per website, much more so than cookies, in a channel which is completely separate from your browser.  So it will be something that GRC will be addressing.  I've got a lot of research that's in the process of getting itself ready to come online, just needs more documentation about browser cookies for educating people.  And it has been pointed out to me a year ago, more than a year ago, that Flash cookies are on the rise.



Well, here we are now, more than half of the Internet sites are using Flash cookies.  The only reason they would be doing that is that they're no longer happy with the tracking they're getting from regular cookies.  And what that means is, since still all browsers default to having cookies enabled, since that was part of the original specification for the web was that a server can give a browser client a cookie, which it will then return in order to identify itself.  Well, users don't want to be tracked, so they're turning their browser cookies off.  But websites are not accepting their choice not to be tracked.  They're saying, well, we're going to track you anyway.  Even though you've disabled your browser cookies, we're going to be even more sneaky because our website requires Flash, and everybody pretty much has Flash who's on the 'Net now.  So where possible, we're going to give you an even stickier cookie through the Flash mechanism in order to hold onto you.  Which, you know, doesn't seem right, but that's what's going on.  More than half of the Internet's top sites.



LEO:  Wow.  All right, Steve.  Why, why, why are you so tan?  What's going on?



STEVE:  Well, okay.  To give a little bit of background here, everyone who's been listening to this podcast for years knows that I focus on code writing and computers and technology.  A hobby of mine, which I've become increasingly focused on as I've been aging, is health.  And in fact really, Leo, it began when I was flying up to visit you in Toronto and appear on Canadian TV with Rogers Cable.  I'd be at the airport and seeing people who were really, I mean, older than I, but not lots older than I, who were having trouble moving around.  They were already, like, being really careful standing up and sitting down, and moving slowly.



And I thought, okay.  I think at that point I was probably 50, or maybe even my very late 40s.  And today I'm 54.  And I remember just deciding, making a promise with myself that I am not going to be that person when I'm that age.  And I'm literally willing to do anything it takes, every single day, so that I'm able to jump around more or less as I am now as I continue aging.  And my focus is not on trying to live as long as I possibly can.  I'm really not very focused on that at all.  I don't care how long I live.  I mean, more is better.



But if you think of a chart that shows your quality of life over time, so that the horizontal axis is your life running from birth to death, and the vertical axis is how you feel, your physical well-being.  You can imagine somebody who just, like, I don't know, who smokes their whole life, who abuses alcohol and drugs, doesn't take care of himself, they might have a relatively, like, for example, a straight line decline from birth to death, where they just - they don't age well, and they're not having a great time toward the end of their life.  My goal would be to keep the slope of that line as horizontal as possible.  That is, keep health up as high as I can for as long as I can, and then to have it just drop off a cliff, kill me in a week when it's finally time.



But the point is that you want to, from a math standpoint, you want to maximize the area under that curve.  You want - because that's the most health you can have for the length of time that you're alive.  So my focus on health, which I've now had really to a much greater degree since I turned 50, because it was like, okay, I've got the time, I've virtualized GRC, my employees are working at home, I'm able to work with a great deal of freedom, I have - there's no excuse not to exercise, not to make sure I'm eating well, and not to do some research, since I've got the Internet now, we all do.  And it's just an amazing - it makes this information so much more available.  So I subscribe to a number of newsletters.  And I've been focused on various aspects of health.  I pretty much knew about cardio years and years ago and have tried to keep myself in shape.



And what happened, maybe about three months ago, was just sort of bumped on the radar screen were various mentions of Vitamin D, which was not something I'd ever looked at or thought about.  I was actually more aware of things like the B vitamins and their importance because modern food processing tends to kill off the B vitamins.  They're fragile.  So food is fortified basically to put back in what processing kills.  And I knew about E and C.  And but somehow Vitamin D had never - this is something I had never really looked at very much.  But I finally got to a point a couple months ago where it's like, okay, what's going on with this?



And so I began to poke around and do some reading.  And I thought, whoa, wait a minute, this is seeming much more significant than I recognized.  And probably about four weeks ago, so about four weeks into this, I decided that this was something that I really needed to understand.  And I also at some point figured I need to involve my family and friends and ultimately this podcast.  So just for one week I need to beg our listeners' indulgence.  I'm going to - I want to share what I have learned and see if, for the sake of information, maybe it will resonate with some people.  Maybe at some point in the future when other information surfaces they'll go, hey, wait a minute, I remember Steve talking about this.  He thought it was important.  These other people think it's important.  Maybe that will be enough to catalyze some thought.



So there's so much that's important about this.  First of all, there's a real problem with it in that it's not a vitamin at all.  Never was.



LEO:  Really.



STEVE:  Never has been.  It is a...



LEO:  What is a vitamin?  What is the definition of a vitamin?



STEVE:  By definition, a vitamin is something which you do not make endogenously.  That is, your body does not make it.  It's something that you must acquire through nutrition from outside sources.



LEO:  It's an amino acid, too, right, isn't that what it means?  Vital amino acid?  No, maybe not.



STEVE:  I don't know where the word comes from.  But I do know that it's got to be a dietary source.  Well, what happened was that it was discovered because of a chronic deficiency in an unknown substance.  As we became more industrialized and people moved from rural settings into cities, and especially as children were employed in buildings, like in factories, they began getting rickets, which is a severe underdevelopment of skeletal bones.  Now, what happened was that there was the discovery that cod liver oil cured this malady that children had.  And so for generations parents, mothers, would, like, force their kids to have a tablespoon of cod liver oil.



LEO:  I remember that from "The Three Stooges."  Or "Our Gang," yeah. "Our Gang," yeah.



STEVE:  Nasty, oily-tasting stuff.  You really don't want it.  Because it turns out that this thing called Vitamin D - and it's such a shame that it's been lumped in with the vitamins because it is a steroid hormone.



LEO:  Really.



STEVE:  It is a very - in fact, it is the most powerful steroid hormone in the human body.  It is so powerful that when measured, the units of measurement of the active form - and I'll explain what the metabolic process is in a second.  But the metabolic form is measured in picograms per milliliter.  That is, we have grams, then we have milligrams is a thousandth, micrograms is a millionth, nanograms is a billionth, picograms is a trillionth.  So it's on the order of 20 to 50 trillionths of a gram in our blood.  I mean, amazingly little of this goes a long way.  But it is found in almost no dietary sources.  That is, we cannot get D from our diet.  It turns out that fatty fish is a source of D.  But where it comes from, the way we get it, is from the sun.



And which I think is really interesting because the first known application for Vitamin D, and really the only place where it has received lots of attention, is in our body's calcium metabolism.  You know, it's generally felt that all life on earth came from the seas, first started in the oceans, evolved in the oceans, and then literally crawled out onto land and needed to adapt.  Well, the ocean is a rich calcium bath.  And so calcium is a fundamental component of the way we operate.  And our bodies, the human body manages and maintains the concentration of calcium to the best of its ability within relatively narrow margins.  We need to have enough calcium from our diet, which it's easy to get.  But you have to have Vitamin D in addition to calcium in order to build bone.  D is inextricably linked to calcium metabolism.  And so but for a long time, for hundreds of years, that's the only thing that we knew that it did.



Well, looking back at sort of early humanity, we also know that we evolved in sub-Saharan, equatorial East Africa.  That's where man, that's sort of the cradle of humankind.  It is believed that when we were coming out of being apes covered with fur, that as we evolved to be larger and have more muscle mass, we began to have a problem with cooling because we were generating, our larger muscles were generating too much heat.  So evaporative cooling wasn't - it was having a problem if we were covered with fur.  So we literally lost our fur in favor of skin and more evaporative capability.



The problem with that was that we were then being exposed to intense sunlight since our skin was no longer being protected by fur.  So what started out as being lighter skinned, we ended up developing a much more rich melanin content.  Melanin is the pigmentation in skin.  And so we ended up literally becoming black in order to deal with the constant powerful equatorial sun in East Africa.  And the blackness of our skin allowed us to tolerate the sun.



But ever since the beginning, we were also using sun, that is, the ultraviolet radiation, for fundamental chemical reactions which take place in our skin.  A precursor of cholesterol called 7-dehydrocholesterol, or 7-DHC, that exists in our skin in abundance in youth, and we lose it as we get increasingly older, that 7-dehydrocholesterol, when it is zapped by an ultraviolet photon, it converts, that 7-dehydrocholesterol is converted into an early form of what unfortunately we have labeled Vitamin D.  It's not stable in that form, and so it shortly changes its bonds around and just under thermal isomerization converts into something called cholecalciferol, which is the form of Vitamin D that you can also get in a supplement.  That's transported to our liver, where our liver changes it through a process known as hydroxylation into the Vitamin D which is measured in our bloodstream, something called 25-hydroxy Vitamin D.  And that's sort of the bulk storage form of this chemical.



Our kidneys takes it the next step further, hydroxylates it again, and turns it into this super potent steroid hormone.  Now, that's involved directly, it's that hormone which is involved with the regulation of calcium metabolism and our bones.  It turns out, though, that many other organ systems in our body also have the ability to deal directly with Vitamin D.  And this is the information which is finally, due to the advancing of our medical science, finally becoming clear to people.



I want to shift gears here for a second and run through a number of recent studies which have been done, just to give people some sense for the pervasiveness of the influence of this.  I have a - I'm holding a textbook, 450 pages, titled "Vitamin D:  Physiology, Molecular Biology, and Clinical Applications."  I've read so many journal articles and studies that I'm becoming sort of well-versed with the names of these people.  And in fact, if I look at a book, a popular text on Vitamin D, it's like, oh, yeah, I know where that chart came from, I remember seeing that chart in the original source material.



LEO:  Wow.



STEVE:  So this is Chapter 13, where he's talking about non-calcemic actions of 1,25 dihydroxy Vitamin D3.  Okay, that's the output from our liver, I'm sorry, the output from our kidney, the final stage, which is this powerful steroid hormone.  And he says, "Under historical perspective, when 1,25(OH)(2)D was discovered, it was assumed that specific Vitamin D receptors would be present in calcium-regulating organs, including the intestine, bone, and kidney.  In 1979, Stumpf et al...." and then he has a reference to the back of the chapter, where he talks about that study, "...reported on the localization of radiolabeled Vitamin D in Vitamin D-deficient tissues and found that the radiolabeled Vitamin D was localized in the nuclei of cells in the small intestine, kidney, and bone, exactly as expected.



"But remarkably, they also find, by autoradiographic analysis of frozen sections of tissues, that this radio-tagged Vitamin D was also present in cells in the gonads, thymus, pituitary gland, pancreas, stomach, breast, teeth, placenta, and skin.  This observation was the impetus for the identification of the Vitamin D receptors, called VDRs," and this is at the genetic level, "in all of these tissues, as well as in several tumor cell lines of leukemia, breast cancer, melanoma, squamous cell carcinoma, colon cancer, and prostate cancer.  VDR activity was also detected in cells related to immunity, including circulating monocytes, activated T and B lymphocytes, and macrophages," which is all part of the way our immune system functions.



So to give some sense for what is beginning to be understood, I've just jumped to Chapter 22 under "Epidemiology of Cancer Risk in Vitamin D."  It reads:  "A nested, case-controlled study was conducted using subjects from the Johns Hopkins Operation CLUE Cohort.  This cohort consisted of 25,620 health adult residents of Wash...."  Yeah, it does say "health adult."



LEO:  It should be healthy, obviously, yeah.



STEVE:  Yeah, "...healthy adult residents of Washington County, Maryland, who provided samples of serum, meaning their blood, between 1974 and 1975.  Serum samples were thawed for all cases of colon cancer."  So what happened is, decades later, the study was done.  So serum samples from back in '74/'75 "were thawed for all cases of colon cancer, and for two controls per case," meaning other people who did not have colon cancer, "and matched for age, race, sex, county of residence, and date of serum collection.  Sera," meaning plural of serum, blood samples, "were analyzed blindly for 25-hydroxy Vitamin D."  Okay, that's that main circulating Vitamin D, which is what's measured.  That's the output of the liver before it goes into the kidney.  That's sort of the storage form.  "Individuals whose 25-hydroxy Vitamin D levels were greater than 20 nanograms per milliliter," and I'll talk about these numbers in a second, get this, "greater than 20 nanograms per milliliter had one third the risk of colon cancer..."



LEO:  Wow, one third, wow.



STEVE:  "...one third the risk of colon cancer compared with those with lower concentrations."  Okay.  So there's one.  A different study, this is from the American Journal of Clinical Nutrition 2004, reads most - to give some context I'll sort of give a little more coming into this.



"Most humans depend on sun exposure to satisfy their requirements for Vitamin D.  Solar ultraviolet B photons," that is, UVB, "are absorbed by 7-dehydrocholesterol in the skin, leading to its transformation to pre-Vitamin D3, which is rapidly converted to Vitamin D3.  Season, latitude, time of day, skin pigmentation, aging, sunscreen use, and glass," that is, the presence of, you know, glass between you and the sun, since UVB is blocked by glass, "all influence the cutaneous production of Vitamin D3.  Once formed, Vitamin D3 is metabolized in the liver to 25-hydroxy Vitamin D, and then in the kidney to its biologically active form, 1,25(OH)(2)D.



"Vitamin D deficiency is an unrecognized epidemic among both children and adults in the United States.  Vitamin D deficiency not only causes rickets among children, but also precipitates and exacerbates osteoporosis among adults and causes the painful bone disease osteomalacia.  Vitamin D deficiency has been associated with increased risks of deadly cancers, cardiovascular disease, multiple sclerosis, rheumatoid arthritis, and Type I diabetes mellitus.  Maintaining blood concentrations of 25-hydroxy Vitamin D above 80 nanomoles per liter," which is, in the literature, sometimes they describe the concentration as nanomoles per liter, but often also as nanograms per milliliter.  The conversion is 2.5.  So 80 nanomoles per liter is about 30 nanograms per milliliter.



It says, "Not only is the maintenance important for maximizing intestinal calcium absorption, but also may be important for providing the extra renal 1-alpha hydroxylase that is present in most tissues to produce 1,25(OH)(2)D(3)."  What he's saying there is that this is necessary for Vitamin D to act directly on all these other tissues, rather than being used for calcium regulation, calcium homeostasis.  "Although chronic excessive exposure to sunlight increases the risk of non-melanoma skin cancer, the avoidance of all direct sun exposure increases the risk of Vitamin D deficiency, which can have serious consequences.  Monitoring serum 25-hydroxy Vitamin D concentrations yearly should help reveal Vitamin D deficiencies."



So that's sort of a bit of overview.  But here's another - this is titled "Prospective Study of Predictors of Vitamin D Status in Cancer Incidence and Mortality in Men."  And I'm going to skip the preamble and just - and I have all of this, I've got links to all of this on the page at GRC.  It says, "For multivariate models, an increment of 25 nanomoles per liter in predicted Vitamin D level was associated with a 17 percent reduction in total cancer incidence."  I lost my track here.  Oh, incidence.  And they go into the statistics, a 29 percent reduction in total cancer mortality with a relative risk of .71, that is, if you had an increase in serum D levels; and a 45 percent reduction in digestive system cancer mortality, 0.55.  And then they summarize, showing that the results were similar when they controlled further for body mass index and physical activity level.  So basically saying that when all other influences were removed, Vitamin D level in the blood had a direct bearing on cancer incidence.



And there's, like, studies which describe similarly that higher levels of Vitamin D are connected to lower levels of many different types of cancer - pancreatic, colon, rectal, stomach, prostate, lung, breast, bladder, uterine, esophageal, kidney, multiple myeloma, I mean, it just goes on and on and on.  There was one doctor who is at the Atascadero - he's an M.D. and psychiatrist at the Atascadero State Mental Hospital, John Cannell.  Because he knew that Vitamin D positively influenced mood, you know, we've all heard of seasonal affective disorder, where people get kind of moody and gloomy in the winter, not surprisingly, when there's much less exposure to sunlight and when the sun is at a greater angle, not as often or as much overhead.  It turns out that the atmosphere absorbs UVB.  And so if the sun is not almost directly overhead, you're not getting much Vitamin D.



So he had his ward on Vitamin D just for its psychological benefits.  A 'flu went through the hospital that was bad enough that wards needed to be quarantined.  He said - I've seen two interviews where he mentions how the ward to one side of him had such a 'flu outbreak that it was quarantined, the ward to the other side of him, and the ward across the hall, as well as on the floor below.  He knew that his patients had had social interactions with the inmates in the other wards and that the nurses were cross-covering his ward and the other wards.  So he figured that his people were similarly being exposed to this influenza.  Not one single patient that he was treating in his ward came down with the 'flu, despite the fact that it was epidemic and to the level of quarantining.  And now as a consequence everyone at Atascadero receives Vitamin D supplementation because of the strong evidence for its immunizational effect.



So I mentioned to you, when we were briefly talking about this last week, that there's even a theory now about where Caucasians came from because it is believed that humans evolved in Africa with deep, dark, melanin-rich skin, which balanced the strength of the equatorial sun.  Now we understand that this hormone, which unfortunately has been mislabeled a vitamin, which is I think largely responsible for a lot of people thinking, oh, well, you know, I probably get enough of this in my diet, I'm not going to worry about it, this hormone has always been generated by the sun's UVB interaction with our skin.  And as we evolved, our population grew, we began to migrate away from equatorial Africa, north.



What we now believe happened is that, as we left the equator, the UVB radiation that we evolved under - I mean, literally, just like oxygen, I mean, that important.  As I run through, I look at all these things that we are beginning to understand are relating to low levels of Vitamin D.  You might think, wait a minute, how can Vitamin D fix that?  Well, that's asking the question wrong.  It's that we always had much higher levels of Vitamin D in our blood than we do now because we evolved naked in the sun.  I mean, and even now, here we are in industrialized mode, basically living in dark UVB blackout caves called our homes and offices, where no UVB radiation gets in, where we're getting much less sunlight than we were even a couple hundred years ago, when we were out farming and getting exposure to the sun.



And of course unfortunately, even more recently, there's been a great public relations campaign warning about the dangers of skin cancer.  You must put on sunscreen when you go outside.  So there's actually been many other things even recently which have begun to happen which confuse people.  For example, autism, it's been noted that it's on the rise.  One theory is that, oh, well, we're just diagnosing it more.  We're more aware of it, so we're looking more closely.  However, what they have found is that the incidence of autism directly correlates with the latitude of the mother of autistic children during pregnancy.  The further away mothers are from the equator, the greater incidence of autism in their children.



LEO:  Now, correlation doesn't equal causation.



STEVE:  No, that's a very good point.  And that's something we have to keep in mind.  My favorite example of that is that - imagine that someone knew nothing about, you know, like an alien came down, knew nothing about the way we operate and was looking, was like watching the street, a random street in New York, and noticed that suddenly everyone put their umbrellas up and, oh, look, then windshield wipers all began going on the cars.  Well, if you didn't know any better, you didn't understand anything about what was really going on, you could say that raising umbrellas caused windshield wipers to go on.



LEO:  Right, right, right.



STEVE:  When in fact...



LEO:  It's the other way around.



STEVE:  It's completely different.  I mean, there's something else that is related.  But, and see, one of the problems with where we are - and, I mean, we're beginning to understand the significance.  The problem is that you cannot patent Vitamin D.  It is incredibly difficult to perform expensive studies.



LEO:  Right, there's no incentive to do this.



STEVE:  Yes, there is no financial incentive.  There was a study that was done - so it's left to universities and research hospitals that have limited funding, especially now.  There was a study between the years of 2000 and 2005 that took 1,179 women in Nebraska, which I think I recall is at 41 degrees north latitude.  This was a double-blind, randomized, placebo-controlled study.  That's the gold standard of studies.  It divided the women in half.  It gave half of them a placebo and calcium, and the other half 1,100 IU per day of Vitamin D and calcium.  If you ignore - oh, and these were all - in the year 2000, when this began, they were all, as far as anyone knew, cancer free.  If you ignore and throw out the first year of any cancers that were found, on the premise that those were already in the process of developing, during the rest of this study the women who were taking the Vitamin D plus calcium had 0.23 percent incidence of any type of cancer.  0.23.



LEO:  I presume that's well below normal.



STEVE:  Compared, no, I mean, compared to the other half of women.



LEO:  Oh, I see.



STEVE:  So if the other half of the women, you established their rate as 1.0, so it's less than one quarter the number of incidents of cancer.  So these studies exist.  They are being published by Harvard and conducted by Harvard, in the American Journal of Clinical Nutrition, I mean, not flaky, strange publications that no one's heard of, major fundamental research.  But the problem is, you can't patent Vitamin D.



The other problem is that the rate of production of Vitamin D as we age really falls of.  Now, I should mention something that I haven't said before, and that is that just this morning I had my fourth weekly test.  I didn't get in the mail my third results, which would have indicated where I was after my second week.  But what I did starting four weeks ago, I'm sorry, three weeks ago today, literally, was I had a reference Vitamin D level taken.  I knew, after all the research I was doing, that I was going to be putting myself on Vitamin D, to a much greater level of Vitamin D than is in my multivitamin.



One of the problems with supplementation, and there is a problem with supplementation, is that Vitamin D can be toxic in very high doses.  It is fat soluble, so it's not excreted from our body on an ongoing basis.  So like any fat-soluble vitamin, there's a concern that it will build up in your tissues over time.  Nobody has ever become Vitamin D toxic from sun exposure.  But it has been determined that, for example, half an hour in the sun will generate about 10,000 IU, 10,000 international units' worth of Vitamin D, which then over the course of a couple days enters your bloodstream.



Well, I knew that I was going to be starting - I was going to be adding some substantial Vitamin D to my daily regimen after all this research that I have done.  But I had no idea what my current Vitamin D level was.  And I wanted to play with generating it by the sun because once I started supplementing, once I added Vitamin D to my diet, well, I would never stop.  And there were other things that I had added where I was thinking, gee, I wish I'd taken a measure beforehand so I could know what it was before.  So I thought, let's sort of play with this.



So I found out to my tremendous shock that I am, or, well, am as far as I know even now, substantially deficient.  There's four levels of Vitamin D terminology that the medical community uses.  You have deficiency, then you have insufficiency, sufficiency, and toxicity.  So you obviously don't want to be toxic.  You don't want too much.  What you want is to be sufficient, and really neither insufficient nor deficient.  And I am deficient.  I mean, I'm...



LEO:  Really.



STEVE:  I have a great diet.  I eat lots of salads.  I like fish.  I sort of avoid meat.  I'm not afraid of it, but I'm doing everything I should.  I have regular annual checkups.  My cholesterol is where it should be, blood pressure is where it should be, a little higher than I would like it.  But it turns out that adequate levels of Vitamin D lowers blood pressure.  In fact, it turns out that there is a seasonal sine wave cycle of blood pressure.  The extent, the amplitude of the sine wave varies with latitude, and it is synchronized to the calendar.  It is well known that...



LEO:  Huh, wow.



STEVE:  ...blood pressure goes down in the summer and goes up in the winter.  It is also, of course, we know that people tend to get colds in the winter, and they get the 'flu in the winter.  Why?  Well, maybe, and we don't know this, but it's because our Vitamin D stores are depleted.  There was one study that attempted to demonstrate that watching too much television caused autism, that is, watching TV and autism were related.  And it's interesting because it turns out that the people who did the study didn't actually interview people for how much television they watched.  Instead they used the rainfall figures in the area.



LEO:  So they correlated it to rainfall, not TV watching.  That's just...



STEVE:  And they said, well, we don't really know how much TV kids are watching.  But probably if it's raining...



LEO:  Figure they're inside, yeah.



STEVE:  ...they're inside.  What they were inadvertently doing was they were measuring probably the amount of sun that these kids were getting.  And that's where the correlation was.  And in fact, when this was pointed out, they have revised their study in order to correct that.  So the proper level of Vitamin D is something which is still unknown, believe it or not.  The way the RDA, the Recommended Daily Allowance, was established was that because we really didn't know, the one thing we did know was that a tablespoon of cod liver oil would prevent rickets.  And since it had been given for so many generations, for so many years, and not caused a problem, they said, well, how much Vitamin D is in cod liver oil?  It turns out it's 400 IU.  So that's what they said, okay, we'll just say that that's the recommended daily allowance, 400 IU.



The problem is that being in the sun for half an hour supposedly generates 10,000 IU.  So substantially more.  And in fact, studies have been done of lifeguards, and farmers in Puerto Rico, that measure the actual level of Vitamin D they have in their blood.  And in this common term of nanograms per milliliter, they're in the order of 50 to 70.  So the current clinically accepted range is 32 to 100.  A hundred - I read the study, and I've got a link to it on my page, where the guy who did this, who set the 32 to 100, and you can read all about how it was established.  And he says, well, I just set 100 sort of arbitrarily because it's higher than we generally see in anybody who has a lot of constant sun exposure.  We don't know that it shouldn't be higher or that any higher level is toxic.  But it would seem that a hundred is sort of a good place because that's all we know at this point.



Anyway, my first test showed me at 23.6 nanograms per milliliter.  And a week later, after a week of sun, where I'm spending half an hour in noonday sun, completely exposed, I mean, 100 percent, baby, the way I was born, dropped to 21.3.  I'm guessing that this is just, you know, it's just the tolerance of the lab test.  I hoped by this time to have the results of the second week, which would be the third test.  And a week from now I should have the results after the third week of the fourth.



But for whatever reason, it doesn't look like I'm seeing any production.  In the studies I've read, when you do get sufficient sunlight, your Vitamin D level jumps up.  It does take many weeks for it to reach whatever maximum it's going to.  So it's sort of an exponential rise.  But I would have certainly expected to see something after seven days of regular exposure.  It looks to me like I'm unable to produce Vitamin D through being out in the sun.  It's disturbing to me that after five years with my internist, my doctor who was assigned to me, I mean, he was fast to give me a blood test and a so-called CBC, a complete blood count, to look at all of the things that are typically considered.  I know exactly what my HDL and LDL and triglycerides and all that stuff is.  He never checked my Vitamin D.  Now, maybe if something were, like, really off, like my blood calcium was off, he would have said, well, let's check your Vitamin D.



LEO:  That's what Dr. Mom was saying, is what about your serum ionized calcium?



STEVE:  Yeah.  And that's where it should be.  So maybe that...



LEO:  Interesting.



STEVE:  Maybe that would have brought him to do it.  But clearly I'm at a level now that is way low, based on current thought.  I would like to raise my 21 to something between 50 and 70, and somewhere, you know, like 60 being a goal.  And that's what I will likely begin doing.



LEO:  And you think that sunbathing is the key.



STEVE:  No, no, no.  Remember, this was just an experiment.  I only wanted...



LEO:  Because there's other risks associated with that, of course.



STEVE:  Well, yes.  There are three types, interestingly, there are three types of skin cancer.  You have squamous cell carcinoma, basal cell carcinoma, and malignant melanoma.  Malignant melanoma is the cancer that everyone worries about.  Interestingly, though, it generally appears on areas of the skin that are covered by clothing, probably because statistically most of us have more than the majority of our skin covered.  The squamous cell carcinoma and basal cell carcinoma is the kind that we see on our hands, arms, and face.  It's also the kind that your dermatologist can freeze off easily, and it's not a big deal as long as you've got someone looking at your skin from time to time, like your doctor takes a look at you to make sure that you don't have any of that.



So the UV radiation definitely damages skin.  It can be carcinogenic.  And it does generate Vitamin D.  What is believed is that, as we migrated away from the equator, because we are so dependent upon Vitamin D, that it became a powerful natural selection factor in our evolution.  And, you know, we know that our evolution took millions and millions of years.  It looks like from the studies that we've done, that as we left the equator and populations moved north up into Europe, that we depigmented in something like several tens of thousands of years, maybe like 50,000 years.  Because suddenly the high melanin content we had, which was protecting us from the sun at the equator, was also now blocking our ability to produce Vitamin D, which is a critical, I mean, an absolutely critical component, I believe, of human health.



We know when it's really low that you develop chronic problems with calcium management and bone.  Your body takes calcium from your bones to preferentially manage your blood calcium level because that's even more important.  So your bones represent essentially a calcium well, or a calcium repository that, if you don't have enough Vitamin D and/or calcium in your diet, there are mechanisms that'll pull calcium from your bones, which you don't want.  But now we're learning that it's very likely that this very powerful and necessary hormone has been incorporated into many other systems in our body.



And I imagine that many of us listening to this podcast are in the same position I was.  I mean, I'm not a sunbather.  I'm not out in the sun.  I actually, I mean, I get a little bit of sun.  I'm not afraid of it.  And I want to make sure I don't burn.  But the problem is that, again, we're in an information deficit because studying these things costs money.  And you can't patent the sun.  You can't patent sunlight.



LEO:  There's an analog because we know that salt is very good for treating a lot of things like cold sores and so forth.  But nobody's going to study that because salt is free and cheap and unpatentable.



STEVE:  But what's really interesting is there are Vitamin D analogs which the pharmaceutical companies are exploring.



LEO:  Sure, yeah.



STEVE:  Uh-huh.  They're making little tiny tweaks...



LEO:  You can make money on that.



STEVE:  Exactly, because that they can patent.  And in fact there are now some effective psoriasis medications which are all based on Vitamin D analogs.  So they tweaked the molecule a little bit.  There is a problem with high levels of Vitamin D because, as I mentioned, it is toxic in really high levels.  But they want to use the very powerful, the 1,25(OH)(2)D, which is what your kidney produces.  They have found that it is extremely good at fighting cancer.  The problem is, if you gave someone enough of it to fight cancer, it would turn you into limestone.  So that's not a good thing.



So what they're trying to do is they're trying to find a variant of this Vitamin D which will have the effects they want and mitigate the effects they don't.  If they can do that, then they can patent it and create a new drug.  I'm not averse at all to using the medical system, if I need to.  I'd much rather stay healthy, not need major surgical intervention of any kind.  And so Vitamin D will be part of my regimen going forward.



And the takeaway, I think, would be, for those listeners who have a doctor, who are the kinds of people who know what their cholesterol is and so forth, next time you go, say hey, let's find out what my Vitamin D level is.  And I'm sure that if my doctor knew that I was 21, he'd say, oh, I mean, even the blood test results shows the level, 32 to 100, and shows me as extremely low.  He would have said, oh, well, we probably need to put you on some Vitamin D, give you some Vitamin D supplementation, and we'll retest in 90 days.  There's no indication that it could hurt.  And my sense is it can only help.



LEO:  So you're going to start taking supplements.



STEVE:  Yes.  In fact, today.  I did my last - I've done my three weeks in the sun.  I don't have the results...



LEO:  I still like getting the sun, and now - I have Italian skin.  So, and of course I get checked every year for skin cancer.  But I like getting some sun.  I just - it feels good.



STEVE:  Well, it turns out that it also releases, being in the sun releases a - shoot.  It's a form of narcotic.



LEO:  Yay.  No wonder it feels so good.



STEVE:  No, I mean, again, it's not surprising, I mean, we were meant to be in the sun.  We evolved in the sun.  I think more than anything else from a...



LEO:  Yeah, it's a natural - it does, it feels good.  It feels like this is where I should be.  Same thing with the ocean.  I feel good when I'm at the ocean.  It's where I should be.



STEVE:  Well, and, I mean, we grew up with our parents saying, oh, go outside and get some sunshine, it's good for you.



LEO:  Not anymore.  Not anymore.



STEVE:  Not anymore.



LEO:  Oh, our kids are slathered with sunscreen.  They wear big bonnets.  I mean, they don't get the sun anymore.



STEVE:  Yeah.  I mean, so there really has been a change.  There is study after study that demonstrates that cancer, autism, allergies, diabetes, an amazing number of maladies have latitudinal correlations.  And they've even noticed, for example, that even at a high latitude, if you're at a high altitude, then the incidences of these problems drop because you've got less atmosphere between you and the sun.  And the other problem is, you cannot get sun that matters in the morning or in the afternoon.  It's got to be when the sun is almost directly overhead.



LEO:  Oh, that's interesting.



STEVE:  The reason is that there's this beautiful gap in atmospheric absorption, right through what we not surprisingly call the "visible spectrum."  And you know, we call it the visible spectrum because that's what we see.  But you'll notice we don't see in the ultraviolet.  I mean, the ultraviolet and the visible are, like, they're the same range of radiation.  We don't see in the ultraviolet because it's dark most of the time in the ultraviolet.  It's only briefly light for a few hours around noon.  And then the sun's angle becomes such that the UV radiation, the UVB, which is between 290 and about 320 nanometers, it's almost completely cut off.



So evolution would never give us vision which is only useful for a couple hours during the day.  Instead we see in the visible spectrum, which is not absorbed the way UVB is.  And so we're able to, for example, hunt by moonlight or see from the time the sun comes up to the time the sun sets, which is much more useful.  But at the same time, that visible radiation doesn't have the energy and doesn't have the wavelength to interact with us chemically the way UVB does.  So we need that UV radiation.



And again, I want to make sure that people understand, I'm not suggesting, I'm not promoting spending time in the sun.  I was about to say that I've read some studies, but again we're in a study deficit here, that say that by the age of 50 our ability to produce Vitamin D cutaneously, endogenously in our skin, has fallen by half; and that by the age of 65 it's down to 25 percent of what it was.  So you cannot get the D you need through sunlight.



And you did notice, maybe you weren't kidding, that I'm a little tanner.  I've been - I was looking at how much sun I was getting and whether I was tanning.  After three weeks of half an hour a day, I have tanned a bit.  Not too much.  But the problem is, tanning is a regulating mechanism.  Tanning is the production of this melanin polymer, which is 99.9 percent efficient at absorbing UVB.  Melanin absorbs UVB and turns it harmlessly into heat.  So it protects our skin from DNA damage.  Unfortunately, it also protects it from generating Vitamin D.



LEO:  Oh, interesting.



STEVE:  So here's the problem.  I'm clearly receiving enough sun because I'm adapting to it.  My skin is darkening, which is my body's attempt to down-regulate the amount of UVB radiation that I receive.  In the process, it's down-regulating my ability to produce Vitamin D.  So my point is that, as I get older, and what happens is we lose the cholesterol in our skin.  You know how, like, so-called, you get thin-skinned?  It is a loss of cholesterol in our skin which reduces our ability to produce Vitamin D, yet we're still going to be able to get tan.  You don't lose your ability to tan.  So what that says is that, when you're no longer young and able to produce as much Vitamin D as you did, no amount of sun can give it to you because your body is going to tan and down-regulate not only, well, down-regulate all the UVB that gets into your skin and to further cut off D.  So I think the only solution is to monitor your Vitamin D levels and supplement.



Now, the good news is, because it's not patented, because it's inexpensive to make, it's very inexpensive.  One of my favorite suppliers is a company called Now Foods.  And my favorite place for buying stuff is IHerb.com.  Great service, great delivery, very good prices.  Now Foods has a 5,000 IU Vitamin D which their label recommends you take one every three days.  Taking Vitamin D infrequently like that works because it has on the order of about a three- or four-week half-life in our body.  It lasts a long time because it's fat-soluble.  So our liver takes it up, and our fat tissues, all of our adipose tissues dissolve the Vitamin D.



It's very easy to swallow because remember how concentrated it is.  We're only talking about micrograms of D.  It's made in huge vats of olive oil because it's fat soluble.  So they start with a huge vat of olive oil, pour a carefully measured amount of Vitamin D in, then dissolve that Vitamin D, and then they produce these little tiny gel caps.  So 120 of those costs $8.80.  Well, if you take one every three days, that's a year's supply of Vitamin D in a useful dose.  That would be 1,666 IU per day.  The U.S. government has said even that 2,000 IU per day is an absolutely safe dose.  Many nutritionists feel that that's way too low.  But follow the label, and then you're getting a useful amount of Vitamin D for $8.80 for a year.



LEO:  Yeah, yeah.



STEVE:  I've looked at this stuff.  And if I had to take one thing, if I were - I was going to say on a desert island.  But even on a desert island, I don't think I can any longer make a sufficient amount of Vitamin D by being in the sun because I'm going to tan, and that's going to cut off what I would have been able to make.



LEO:  Is there a risk to supplementing?  Can you overdo it?



STEVE:  Yes.  The risk is at the high end.  And in fact this is the conundrum, is that our government has - our government does put D in stuff.



LEO:  Milk.



STEVE:  It puts D in milk.  And...



LEO:  Aren't we getting, because we're all drinking Starbucks, getting a lot more milk than ever before?



STEVE:  Well, here's the problem, is milk has actually gone out of fashion.  And we're not drinking the kind of milk we do.  Believe it or not, rickets has made a comeback in the last few years.



LEO:  That's unbelievable.



STEVE:  Because children are not drinking milk.  Parents are not...



LEO:  It's soda pop.



STEVE:  Exactly.  Exactly.  And sugary fruit drinks.  So the government mandates that 400 IU be put in a quart of milk.  And the problem is you would have to drink about 10 quarts of milk a day...



LEO:  Okay, I don't drink that much.



STEVE:  ...in order to get a physiologically useful amount of Vitamin D.  But here's the problem.  If the government - because this is a powerful steroid hormone.  If the government did...



LEO:  They can't put more in, yeah, yeah.



STEVE:  Exactly.  If the government did raise the levels of D that were in our food supply, there's a wide variation in the amount of different types of food that different people eat.  Maybe there is someone who drinks quarts of milk a day.



LEO:  So they could be doing themselves harm if they had to much of it.



STEVE:  If there was too much...



LEO:  If they were supplementing and they drank four quarts a day and they were getting out in the sun and on and on and on.



STEVE:  Yeah, I mean, I think that the only, I mean, the really responsible thing to do is to get a test.  You can buy your own, as I have been doing.



LEO:  Oh, really.  Oh, these aren't with your doctor.



STEVE:  No.



LEO:  Do you draw blood?  How do you get...



STEVE:  Oh, yeah.  I go to a lab every Wednesday morning, to LabCorp.  There's a group called Life Extension Foundation, LEF.org.  They offer retail blood testing services.  So you pay them, they mail you the forms, and then you take that to a lab nearby.  They take a vial of blood.  And then about five days later, normally - this was late in this third test, but normally it takes five days and you get the results.  And I think it's $67 for a nonmember, $47 for a member.  So if you were going to do several of these, I think membership is $75 a year, so you get a discount.



LEO:  See, I know what people listening - what I will do is, I'm not going to get tested.  I'm just going to go out and buy some Vitamin D tabs.  Is that a bad idea?



STEVE:  I don't think so.  As long as you follow the label, you cannot be toxic because...



LEO:  Don't overdo it.



STEVE:  ...for example, Walgreens will have 1,000 IU, and it'll probably say take one or two a day.  And follow the label, and you're fine.  This 5,000 IU from Now Foods says take one every three days.  Because, I mean, well, for example, because it has the half-life it does, some doctors will megadose their patients monthly, like give them 100,000 IU - but I'm not recommending that.  You absolutely would only do that under a doctor's care.  But my point is that you can take a large dose and then let it be acquired by your system and then used over time as your blood level drops.  It's just easier for me, for example, to do one every three days.  Or I will be monitoring my blood level, so I will probably take more because I'm wanting to find out what level I need to take in order to put my blood where it should be.



So again, ask your doctor for a Vitamin D test.  Get one for yourself.  Or think about getting some real D.  I should mention that there are two types of D that you can purchase.  There's D2, which is called ergocalciferol; or D3, which is cholecalciferol.  D3 is what we make.  Cholecalciferol is the only kind you really want to take.  It is essentially biologically identical to what we manufacture.  There is some concern, for example, I think it's not kosher, believe it or not, because it's made by irradiating the lanolin from lamb's wool.



Ergocalciferol is made from irradiating fungus.  So it's 100 percent plant based, but it's Vitamin D2.  And some studies have said that it only raises your Vitamin D levels about 25 percent as high as D3.  So D3, which is what we make when sun hits our skin, is substantially more effective than D2.  So I imagine what you would find, you know, for example, that this Now Foods Vitamin D is Vitamin D3.  Walgreens drugstores in their little health section, what you want to look for is the cholecalciferol.  And 1,000 mg per day is without question safe.  The U.S. government says that up to 2,000 is safe.  Nutritionists believe safe dosages are far higher.  I wouldn't go there unless you knew what your blood levels were, you want to make sure.  It is possible to be hypersensitive to Vitamin D.  There are some genetic conditions that could cause complications at much higher levels.



LEO:  Yeah, we should emphasize, we're not physicians.  You should check with your physician before you do anything.  And probably ask your physician what he thinks and get a D test.  Are there natural food sources?  I like to get this stuff from food.  Can I eat a lot of broccoli or something?



STEVE:  No.  That's just it, Leo.  It is not in our food supply.  It's interesting, the only way the Eskimos were able to keep their relatively high level of pigmentation is eating oily fish.  They have a diet high in fish, and fish is the only source.  Three and a half ounces of salmon has about, I think it's 380 IU of Vitamin D.  And again, there are studies that have been done that estimate we use about 4,000 IU a day.  I've seen numbers like 3,800, 4,000, something like that.  So again, you would need to be eating an awful lot of salmon, what, 35 ounces of salmon a day, which you might get tired of after a few days.



LEO:  And it might not be good for you for other reasons.



STEVE:  Exactly.  So also it turns out that cod liver oil is really not the best source.  It does give you Vitamin D.  It also contains the other fat soluble vitamin, Vitamin A.  And a lot of Vitamin A can be a problem.  And also Vitamin A genetically looks very much like Vitamin D, and there have been reports that say that A can block the positive effects of Vitamin D, that is, other than on calcium metabolism, where we know that it's effective.  So getting A in the form of beta-carotene is really what you want because your body is able to convert as much as it needs over to A.



Anyway, that's my readout on D.  I think it's important.  It's not a vitamin.  I think it's had a bad rap by being misnamed a vitamin by early, early medical science that didn't know what it was, but just said, oh, well, it's a nutritional thing because it's in cod liver oil.  In fact, it's not anywhere else in our diet because we evolved in the sunlight.  We need it, otherwise all kinds of things start not working as well as they should.



And there was in fact, it was funny, I was talking to some friends at Starbucks a week or two ago, and one of the people said they'd just seen a news blurb saying that 70 percent of U.S. children are Vitamin D deficient.  I mean, it is a problem.  But the conundrum is, because it is a powerful hormone, we can't put it in our food supply.  We weren't meant to get it really in our food supply.  There's barely enough now to prevent rickets, and it's not even doing that anymore because people aren't - they're staying away from dairy products more than they should.  But if we put a lot more in, then there'd be the possibility that people could reach toxic levels of it.



So, I mean, it needs to be done.  Young people in the sun is probably what you want to do, although there's a concern about skin cancer, which is to some degree warranted.  So I don't really see a way other than using supplements and doing it with care and wisely.  I think it's important.



LEO:  Steve Gibson.  You know, this is a little bit of a departure for the show, but I think a fascinating topic.  And I can see why you were anxious to share it with us.  Thank you.



STEVE:  Well, so I didn't give the web page.  I'm in the process, as I record this, of - I have a lot of it.  All the pages are assembled here at home.  I haven't yet put them up on the site.  But it'll just be GRC.com/health.



LEO:  All right.



STEVE:  And that will get anybody who wants to read this research.  I've captured PDFs of all of this.  They're all online.  People can poke around, read this for themselves.  And I hope maybe I've given, if nothing else, people something to think about.



LEO:  I'm going to run out and get some Vitamin D, I can tell you that right now.  Steve, thank you so much for joining us.  Steve's page is GRC.com.  That's where you'll find SpinRite, the world's finest hard drive maintenance and recovery program.  If he won't do it, I will, I'll plug it.  Also lots of great free stuff.  And by the time you hear this, probably, GRC.com/health for all the notes from this.



You'll also find, if you go to GRC, 16KB versions of this show, so you can, you know, for people who don't have a lot of bandwidth.  We've got transcripts you can share with friends.  It's all there at GRC.com.  We're here.  We do this show live, and you're invited to join us every Wednesday.  We do it around 2:00 p.m. Eastern time on live.twit.tv.  And of course you can download the show after the fact from iTunes and all the other podcast aggregators.  It's absolutely free.  But join us Wednesdays at 2:00 p.m., live.twit.tv.



STEVE:  One thing I did want to add is that to send me stuff is GRC.com/feedback.  And I would be very interested in any feedback that people have about this topic.  Next week is our Q&A.  I would imagine that, if there's sufficient interest in this, as will be demonstrated by feedback on the topic, that the Q&A will be wrapping up loose ends about this.



LEO:  Good.



STEVE:  Which would be great.



LEO:  Great.  Steve, have a sunny and lovely day.



STEVE:  Thanks, Leo.



LEO:  And we'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#210

DATE:		August 20, 2009

TITLE:		Listener Feedback #73

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-210.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 210 for August 20, 2009:  Listener Feedback #73.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers your security - very important - your privacy and all that stuff.  Steve Gibson is here, the man who discovered spyware, coined the term, created the first antispyware tool.  He's a security researcher and expert engineer, the creator of SpinRite, the world's best hard drive maintenance utility, and the owner of GRC.com, which is a great website full of wonderful tools.  And it's so great to see him in our fifth year now of Security Now!.



STEVE GIBSON:  Yay.



LEO:  At some point I will stop - I won't have to introduce you anymore.  I'll just - no.



STEVE:  Wonder when that will be.



LEO:  You know, Steve.



STEVE:  I don't think that's going to happen.



LEO:  It's good to say it, in case there's people, new people coming along.



STEVE:  Well, and we do know, yes, I know from the feedback that there are people who are discovering the podcast.  And they say, oh, yeah, this is the first one I listened to, or I just heard - I discovered you last month because my boss turned me onto it or something, and I owe him big-time kind of thing.  So there are people who, as you say, have not been here for all prior 209 times you've said that.



LEO:  Well, and that's really good because, if we weren't growing, we would be shrinking because, you know, there is some attrition.



STEVE:  There's attrition, yeah.



LEO:  So it's important that we get new listeners.



STEVE:  New blood.  New blood.



LEO:  In fact, if you like the show, tell your boss, tell your employees, spread the word.  Let people know they can hear the show.  They can watch it live.  We do it live every Wednesday at 2:00 p.m. Eastern, 11:00 a.m. Pacific on live.twit.tv.



STEVE:  Actually that's right now, Leo.



LEO:  Oh, my gosh, we'd better get going.



STEVE:  That's what we're doing.



LEO:  We release the show on Thursdays.



STEVE:  Hello.



LEO:  And we have a Q&A today; right?



STEVE:  We do.



LEO:  Yeah.  Some great questions from our audience, and Steve's answers.  But before we get to our questions and answers, do you have any updates?



STEVE:  Oh, we've got a bunch of security news and some errata, you betcha.  The big news probably, I think this - because it's been a relatively quiet week.  However, it was recently revealed that all Linux kernels based on the 2.4 and 2.6 series, since 2001, so over the last eight years, are vulnerable to a really bad privilege escalation attack.  Basically it allows anyone with restricted rights to get root on a Linux machine.  It turns out that it was discovered there were null pointer references in some rarely used protocol initialization structures in the kernel.  And an exploit is available, and it is being used, that is, I mean, it's...



LEO:  Oh, it's out there?



STEVE:  It's out there.  Debian has updated immediately.  Ubuntu has done the same.  There's nothing yet for Red Hat Enterprise, but they have published a workaround.  So I just wanted to let all of our Linux users know that it's definitely time to, based on what flavor of Linux you're using, check in with headquarters and see if they've got yet a fix for this.  I guess there's a whole bunch of different Ubuntu flavors, also - Xubuntu and all kinds of crazy prefixes on the front of that.  And they've responded.  So everyone is scrambling.  I mean, this is just like today and yesterday this is happening, when we're recording this on August 18th.



LEO:  This is huge.



STEVE:  Yes, or the 19th.  Yeah, it is big.  So it's - from what I can tell it's not a remote exploit.  That is, it's not like a protocol port.  It's a local...



LEO:  You have to have physical access.



STEVE:  Yes.



LEO:  Oh, that's a relief.



STEVE:  Yes, yes, yes.  So it's a way of writing code which uses not common protocols.  For example, AppleTalk, IPX, the old...



LEO:  That's the NetWare protocol.



STEVE:  ...NetWare protocol, exactly.  IrDA, the IR protocol, X.25, Bluetooth, a version of INET6, the IPv6 protocol, and ISDN.  So it turns out that, when you create a socket in UNIX or Linux, you specify the protocol the socket will have.  The protocol that you're going to use - for example, you would typically use IP protocol, IPv4 for standard IP communications - that protocol then defines which operations can be performed on the socket.  And if the operation is not defined for the protocol, you should have it pointing to a not-implemented procedure, basically.  So that if you try to execute that procedure, it just returns an error saying this particular operation is not implemented on this protocol.  It turns out that those not-implemented pointers are sometimes not filled in.  And this has been the case for eight years.  And somebody...



LEO:  Really.  For eight years.



STEVE:  For eight years.  And so somebody - so there is now an exploit that allows elevation to root.  That is, anybody can get root on any Linux that is - and they're all, I guess, based on the series 2.4 and 2.6.



LEO:  They all use the same kernels, yeah.



STEVE:  Exactly.  So for eight years it's been possible to do this.



LEO:  Holy mackerel.



STEVE:  It was just discovered and published.  So there's no need to have a fancy password to log in as root.  Anyone can get root on your Linux machine.  So it's something I imagine lots of Linux people will want to fix.



LEO:  But that's always less of a risk if you need physical access.  It's not like they can hack in from outside.



STEVE:  Yes, absolutely.  It's not...



LEO:  So, for instance, I'd be worried about my servers, which are all running Ubuntu.  But you'd have to be at the network center, and you'd have to get in there.



STEVE:  Yeah, exactly.  So the idea is, it's possible to write code which says - it creates a socket.  It says, okay, I want to use Bluetooth.  And then to execute a deliberately non-supported function against that Bluetooth protocol-defined socket, which will then, you know, causes problems because, instead of being returned - oh, this is not implemented on this socket - the return you get is something that allows you then to leverage this into a privileged escalation, and you're able to get root privileges.



LEO:  Right.  Of course we will update this.  But the fact is that it's less of an issue.



STEVE:  Yes.  Oh, I mean, if this were a remote exploit it'd be...



LEO:  Oh...



STEVE:  It would be the end of the world.



LEO:  Yeah, no kidding.  I mean...



STEVE:  That would be really bad.



LEO:  Anybody could take over any server.  I mean, it'd be awful.  Thank goodness, okay.



STEVE:  Yeah, yeah, yeah.  Also we spoke last week about the UC Berkeley researchers who got a lot of attention for their discovery, their research which indicated that more than half of the Internet's top websites were no longer relying on browser cookies to maintain state, but were using Flash cookies, which are a lot less well known than browser cookies, for which there's no easy button to push, there's no UI built into the Flash player, it's just sort of an embedded thing.  Whereas browsers, the user interface on the browser allows us to say, oh, I don't want to allow - I want to disallow third-party cookies, or I want to treat them as session cookies and so forth.



It turns out that a major provider of web analytics, a company called Quantcast, had been, for who knows how long, one of the services they were offering to their clients, Hulu being one that was mentioned, was to reinstate browser cookies that the user deliberately deleted by using the Flash cookies.



LEO:  Oh.  Cookie flash thing, yeah.



STEVE:  And we've talked about this a couple times.  The idea being that the user says, I want this to be a session cookie; I don't want you to remember me.  Well, Quantcast said, oh, guess what.  As a service, since we've got code running on the website, we'll use Flash cookies, which are stickier, to basically respawn any browser cookies that are deleted.  So the problem with that, of course, is that, as we know, and I'm annoyed by this because this is one of those things that unfortunately is opt-out that should be opt-in, the whole cookie deal, but all browsers still have third-party cookies enabled by default, which enables tracking, as we've described.  But for users to deliberately disable them, that would imply user intent.  That is, they didn't disable them by mistake.  They weren't disabled by default.  Someone had to say, I know what I'm doing; I don't want to be tracked.  And so for a company to come back and reinstate those where, you know, basically overriding the wishes of the owner who's visiting the website, seems really bad.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Well, the good news is, the day after this report came out, they stopped it.



LEO:  Good.



STEVE:  So I think they recognized preemptively that they were about to be in a world of hurt because people like us would be saying this company is doing this and it's really bad.  So they formally said, hey, we're not going to do that anymore.  People who delete their cookies are expressing their intent, so we're going to honor that intent.  It's like, well, good.



I don't know if you saw the story about Palm getting some heat about the Pre tracking?



LEO:  Oh, yeah.  It's phoning home.



STEVE:  Yeah.  And this is what surprised people.  Arguably, down in the fine print, it may say that that's okay.  But for our listeners who haven't heard, the Palm Pre turns out to be providing geolocation information about all Pre phones, even when you're not using location-based services.  Which was really the gotcha.  It's not that, you know, you can imagine that the phone is providing benefits based on GPS and standard state-of-the-art geolocation services.  The problem is, the Pre is sending back your location to the mothership continuously, whether you're using geolocation or not.



And it did bring up, though, a secondary aspect, which is - and I guess this is maybe not such a big deal.  But, for example, even the Apple iPhone, third-party apps are able to query the iPhone for its location.  And nothing prevents them from leaking that information back out to wherever they want to.



LEO:  The iPhone does say, "This third-party app wants to know your location.  Okay or not?"  So you're queried every single time.  Even if you say yes, the next time you launch the app it will ask you again.



STEVE:  Okay.  So at the OS, where the app is trying to say where is the phone, that brings up a dialogue that the app is unable to interfere with or suppress.



LEO:  Apparently.  I mean, it may be some bug.



STEVE:  So you're giving the app permission.



LEO:  Yes, exactly.  You have to give it explicit permission each and every time.



STEVE:  Right.



LEO:  Now, it is an interesting point, and somebody made this point when I talked about this on the radio show, that the phone company knows where you are.  It has all that information.  It may not have it as granularly because it's by cell site.



STEVE:  By cell tower, yes.



LEO:  As opposed to, you know, the longitude and latitude, which is accurate to a few meters.  But we kind of know that, and we accept that with the phone company.  For Palm to know that is a little much.  And Palm, by the way, while acknowledging it and apologizing, didn't say they were going to stop.



STEVE:  No.  They said that's part of what the phone does.



LEO:  It's what we do.  It makes it easier for you.



STEVE:  Yeah, in fact, it's funny.  You were talking about the comment raised about how cell companies know where you are, I mean, that's now - that's in the common culture enough so that when we see - we're watching TV or a movie or something, and somebody's on the cell phone, it's like, okay, hang up, hang up, take the battery out.  Don't you know they're going to track you?



LEO:  Right.



STEVE:  I mean, it's just - we all know that now.



LEO:  We know that, yeah.  But we don't assume that the handset manufacturer's keeping track of that.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  And you have to wonder why.  I mean, and they say, oh, it's part of all the value-add.  We're going to provide you services that are enhanced because, if we know where you are, we can tell you where the nearest pizza is or something.  I mean, okay.



LEO:  Hmm.  Hmm.



STEVE:  Yeah.  Real Networks, we talked about this about a year ago, has been fighting and continually losing their battle for their product called RealDVD.  RealDVD is a technology which allows people to copy DVDs to their computers.  It's supposed to make it easier for them to watch DVDs.  They're not able to duplicate them.  And they are still encrypted.  But Real Networks has contended that, hey, this is not a breach of anyone's copyright because it's still only viewable on the machine to which it's been copied, and how is that different that putting the disk into the machine's own DVD player and running a built-in DVD movie player app?  Unfortunately, Paramount, Sony, Universal, and Disney all disagree.  A temporary injunction has just been turned into a preliminary injunction, strengthening it, and essentially preventing Real from continuing to sell; well, they have been already prevented. But, I mean, this strengthens it to the point where the next step now is to go to trial.



So I just wanted to move us forward in this saga.  Apparently Real, in order to do this, did sign licensing agreements in order to access the DVD decrypto technology.  So they're a licensee, a formal licensee of that, as you'd expect.  And the argument is, well, you're breaching your license by doing this.  You are decrypting the DVD in a way that we're not happy with.  And so Real is having to defend themselves.



LEO:  Yeah.  Motion picture industry, as usual, not too happy with this kind of thing.



STEVE:  With any kind of use that they don't have complete control over.



LEO:  They essentially say you don't have the right to back it up.



STEVE:  Right.



LEO:  You can't even back it up.



STEVE:  And in another little bit of weird randomness, Twitter was found to be used controlling a botnet, not surprisingly.  A botnet was following a Twitter account.  And somebody was using Twitter, literally, sending tweets to Twitter.  And all of his bots were following him, and it's how he was - that was his command-and-control channel for the botnet.  This was discovered after the denial of service attack problems that we talked about last week.  A researcher looking closely realized there was some strange traffic on one channel, and they closed the account.  And apparently the same person was using Jaiku prior to that.



And it turns out that, increasingly, botnets are finding new and sort of unique ways of phoning home and staying in touch with their owners.  One that I thought was particularly interesting is that the botnet clients, the bots themselves, will issue strange search queries which would normally not turn up anything.  But the owner of the botnet fleet knows what search queries his bots are going to issue.  And so he can then create a website which the search engines will find and index, and then the weird queries result in hits against that site that allow the bots to find code to update themselves.



LEO:  It seems odd that you would do that in a public place like Twitter.  I mean, it's so much easier just to have an IRC server secretly running.  Twitter, it's so obvious, you know?



STEVE:  Yeah, exactly.



LEO:  He was discovered right away.



STEVE:  Exactly, because it's exactly the sort of little messages that are being broadcast by Twitter is that.



LEO:  Yeah.



STEVE:  So, I mean, it wasn't very inspired, and it didn't last very long.  They saw it, they closed it down, sorry.



LEO:  I like dumb hackers like that.  Give me more of them.



STEVE:  We wish everyone was a little slow.



LEO:  Yeah, those are the ones I want.



STEVE:  And next week's topic is going to be a nice, deep, serious, techie, you know, back to Security Now! style, a detailed look at hacking a voting machine, how it's done.  Because at the USENIX '09 eVoting Workshop, some researchers from a handful of universities revealed their research into how what was believed to be one of the least hackable eVoting machines, which is widely used in the U.S., how they managed to take it over.  And it's really interesting because it's not based on Linux or Windows or any of these, like, big OSes that would immediately make me just sort of sigh and wonder why this approach was taken.  The machine runs on a Z80 chip, and with a very small amount of code.  And what's really interesting is that it's a so-called "Harvard" architecture as opposed to the traditional architecture where instructions and data are all mixed together.  And we understand the danger of that because everything that we're hearing is how data is being misunderstood as instructions, and so data is being executed.



Well, the developers of this said, oh, not a problem.  We're going to create a really tight, small, beautiful little eVoting machine - and they did - where the hardware itself will prevent data from being executed.  That is, ROM, the code will be in ROM, and of course data will be in RAM.  And it will be impossible for the chip to execute commands out of RAM.  It can only execute the ROM that we provide.  And these guys found a way around that such that it is possible to change the outcome of voting.



LEO:  Wow.



STEVE:  So we're going to have fun next week with looking at exactly how that works.



In errata, I referred to, incorrectly and improperly, DynDNS as something that, I mean, I was wrong in thinking that it was sort of a hobbyist, not to take seriously DNS service.  I've run across it because it's possible, for example, to set up a DynDNS account and have your residential router stay synchronized so that you're able to create a domain name, a DynDNS domain name that will always point to the IP of your router to allow you to find it if your ISP, using DHCP, should assign your router a different IP.  Because as we know, while DHCP-assigned IPs are relatively static, they're not absolutely fixed.  So it's necessary to have some sort of a system that will be able to track the IP if it changes.  And I was - we were talking about Twitter and the fact that they use DynDNS.  And I said, oh, my goodness, I mean, get a real DNS service.



LEO:  Well, to your credit you said, "I read this"; "I'd heard this."  You didn't say "I know this for a fact."  I mean...



STEVE:  Right.  Well, it turns out that DynDNS has grown up a lot since I last saw them, and they have an enterprise-class service which is robust and strong and serious and solid.  And so the fact that Twitter is using that in no way weakens Twitter.  And in fact this was not an attack on DNS.  The reason - what I read was that there was an increase in traffic to DynDNS due to the attack.  But, I mean, that also follows because remember that the first thing that happens when you do a lookup of anything on the 'Net is you've got to get the IP address.  So if a whole bunch of clients were, as we now believe, essentially clicking on links on Twitter blogs, then all those clients would be referred, would have their DNS lookups performed by their DNS server that would query DynDNS to get the current IP of Twitter.  But it's not, literally, dynamic DNS because there is a whole other enterprise class service, you know, big iron DNS, which the same folks offer who offer the home router version with a very different targeted audience.



LEO:  Excellent.  Well, so our apologies.  And we've corrected that, yeah.



STEVE:  I keep hearing people in our feedback telling us they love our minor divergences from security.  One, of course, is our favorite, is sci-fi.  And so I have to just say that I loved Peter Jackson's "District 9."



LEO:  Yeah.  Now, don't - no spoilers because...



STEVE:  Oh, I'm not spoiling anything.  Oh, my...



LEO:  Yeah.  Because apparently it's best to know as little as possible before going in to see this movie.



STEVE:  It is a spectacular piece of work.



LEO:  I can't wait to see it, yeah.



STEVE:  So I wanted to - any of our listeners who are sci-fi people, I just wanted to say "District 9" is really good.  I mean, in a very different way.  I mean, I would say it blows the most recent "Star Trek" movie away.



LEO:  Wow.



STEVE:  Which I also loved.



LEO:  And that was an excellent movie.



STEVE:  Yeah, but it was - oh, okay, yes.  It was an excellent movie.  I loved it.  I'm glad we're going to have more "Star Trek" movies.  But "District 9" is in a class by itself.  I mean, it is fantastic science fiction.  So...



LEO:  I heard people say their reaction to this was the same as when they saw "The Matrix" the first time.  It was just like [small exclamation].



STEVE:  Yeah.



LEO:  I can't wait to see it.



STEVE:  It was, I mean, I went with a couple friends.  And we were just, like, turning and looking at each other with our mouths hanging open during the movie.  It was like, my god, this is good.  It was just - it was spectacular.



LEO:  I can't wait.



STEVE:  I also picked up a comment, I don't remember now why, but I was watching you, Leo, on the weekend, on your Tech Guy show.  And a caller was talking about their drive clicking.



LEO:  Yes.



STEVE:  And the drive was no longer working, and it was clicking.  And I hear that enough that I just wanted to address that briefly.  And this is not a pro-SpinRite story.  This is unfortunately something that's not SpinRite nor anything else except serious, serious drive repair can fix.  That clicking is what the drive does when it is arguably at or past life, unfortunately.



LEO:  Oh.



STEVE:  It is the - the drive will put the heads out on the surface and try to obtain a servo lock.  Which means it's looking for the special non-data servoing information which is now stored periodically around the track.  If you imagine two different signals which are out of phase, like a sine wave signal where from left to right that sine wave diminishes in strength.  And then there's another sine wave that's 180 degrees out of phase, meaning that its peaks and valleys are the reverse of the first one.  And its strength increases from left to right.  So that sort of creates almost sort of a "V" shape.  And imagine that the head running down the middle is now receiving both sine waves, the in-phase and the out-of-phase one.  Well, as it drifts off track, the signal it gets, which is the composite of both, will start to change.  And it can tell by which way the phase changes which direction it's off.  And so by moving back to the center and, like, nulling out these two competing sine waves, it's able to stay on track.



Well, that's a good visualization of how servoing works on contemporary drives.  And so those little servo bursts, as they're called, occur periodically, and they give the drive-servoing technology, the head-positioning technology, periodic updates on where it is as it moves along the track.  Well, the drive's ability to lock onto this servo information is, like, it's the first thing it does when it puts the heads out.  If it's unable to acquire that servo information, it'll wait a bit, and trying, moving the heads around, looking for it.  And if it can't, it retracts the heads in what's called a "recalibrate operation," and puts them out again.  That's the click you hear.



So that clicking is the drive's inability, essentially, to get itself going.  So what happens is, when you power the drive up, the platters spin up to speed, which causes the heads to begin flying over the surface.  And once the system sees that the platters are up to speed, it then sends the heads out in order to go to the first cylinder and obtain their servo lock.  If they can't, it retracts the heads, waits a little bit, and just tries again.  There's nothing else it can do.  And so what you hear is a clickitic, clickitic, clickitic, clickitic.



LEO:  Uh-huh, uh-huh.



STEVE:  And it's not until the drive achieves that servo lock that it then lights up the API, that is, it lights up the interface and says, "I'm online."  So essentially the drive is offline.  It's not - it isn't paying attention to its interface.  There's nothing any software can do.  There's nothing anything, anyone can do.  Sometimes this is where you put the drive in the refrigerator because that's an old-school approach.  But, I mean, you're literally - you don't have many boots left of this - on a drive that's doing that.



LEO:  Well, now, let's distinguish that between a drive that's having trouble reading a sector and trying over and over again.  That sounds a little bit like a clickety, too.  That's like an eh-eh, eh-eh, eh-eh. 



STEVE:  Yes.  There can be that.  And in fact SpinRite will generate that because one of the things that SpinRite does is it moves off in either direction to random distances and then comes back at the sector, hoping to get a slightly different head positioning to allow it to obtain a good read on the sector because all of this, there's like - there's a little bit of slop in all of this.  There's the drive, for example, in that servoing example, the drive doesn't recorrect its head position until the error signal is enough in one direction or the other to tell it that it's got to move the head back into the center.  So it's got to be a little bit off center before it knows to recenter.  So retrying, which is one of SpinRite's success strategies, often works.  But I guess there's a - it's a louder, sort of distinctive sound which you will hear shortly after you power up the system where the drive is just kind of going geklunkit, geklankit, geklankit, geklankit, geklankit.



LEO:  Hmm, that sound, yeah, yeah, I know that sound.  Yeah, yeah, yeah.  It's distinctive.  If you've not heard it before...



STEVE:  Yeah, and you don't ever want to hear it.



LEO:  Yeah.



STEVE:  But your caller did hear it.  And the problem is that drive has not declared itself online.  So the BIOS won't see it.  SpinRite won't see it.  Nothing will see it.  It's literally - it's not - it's ignoring the cable connections to the outside world.  It's just trying to get itself going.  And then it would turn around and say, okay, what do you want me to do?  It's just not even there.  And so if you had - if you can't get it not to do that, that is, if that's all it will do, even putting it in the refrigerator for a few hours and trying again, and you absolutely have to have the data, that's beyond SpinRite.  It's, like I said, it's not even - it's not online.  That's where you have to say, okay, and take it to a professional data recovery service that takes the drive apart, literally.  I mean, you're at that stage.  And that's typically lots of money.



LEO:  Very good.  Thanks for that clarification.



STEVE:  And that's all I have.



LEO:  [Laughing] And, I'm done.



STEVE:  We have a bunch of great reactions to last week's...



LEO:  I'll tell you, I've been taking Vitamin D every day since then.



STEVE:  Well, great.  There's something funny around in the middle of them that you're going to get a kick out of.  But it's true.  But so today I wanted to let people know we will, trust me, we'll be back to security big-time next week.  But reactions were phenomenal from last week.  And so I wanted to share those with our listeners today.



LEO:  And we do have a lot of security questions, too, so don't fear that.  Steve, you ready for some questions?



STEVE:  Absolutely, questions and feedback and comments.



LEO:  So, question number one, Anthony DiSante listening in Pennsylvania wrote to say the occasional off-topic shows are great, for example, Vitamin D:  Hi, Steve.  I'm a long-time listener of Security Now! and a couple of Leo's other shows, too.  This week I actually listened to my podcasts out of order, skipping MacBreak Weekly - what? - because I couldn't wait to hear about your Vitamin D research.  Thanks for sharing these kinds of non-security topics.  I'm sure I speak for many other listeners when I say that, after coming to know and love you as "the security guy" for so long, it's nice to see another side of you, while learning something interesting at the same time.  Speaking of off-topic stuff, is there anything exciting to report on the super-capacitor front?  Oh, yes.  That was an interesting subject we talked about some months ago.  Maybe it's time you started a second podcast:  "Vitamin D and Super-capacitors Now!"  Doesn't that roll off the tongue.  So, yeah, thank you.  I'm glad - and I've been taking my Vitamin D.  I've got my D3.



STEVE:  Yup.



LEO:  Poppin' that every day.



STEVE:  And I just wanted to say, I mean, I was - well, basically all the feedback that we received was about last week's episode, not surprisingly.  There were a couple grumpy people who said, hey, if I wanted to have a health podcast, I'd go subscribe to one.  I listen to Security Now! for security information, so stay on topic.  And it's like, okay.  I mean, I really do understand that.  And I want to reaffirm to everyone that this is a security podcast and that next week we'll be back to where we've always been for the last four years with more full-strength security stuff than ever.  At the same time, my hope was that this would be interesting and useful.  And from all the feedback that I got, I think we really scored there big-time.



To the degree that anything else like this happens again, I think I've sort of established my interest as a health hobbyist among our listeners.  I'll just make a reference in the errata time at the beginning of a podcast to go check out a certain page at GRC and leave it at that, trusting people to be able to do that if they choose to.  So I wanted to acknowledge the couple people who said, hey, they wished that we'd stayed on security topic.  At the same time, the response was phenomenal from everyone who said, wow, I didn't know what you told us about, and that's really why I listen is to learn things.  So I just wanted to acknowledge that.  And relative to supercapacitors, we'll certainly keep our eye on those and let our listeners know.



LEO:  But nothing to report so far.



STEVE:  Not at this point.



LEO:  There's still a few months left in the year.  They can still do it.  Eliezer Martinez in sunny and Vitamin D supercharged Puerto Rico says:  Great Vitamin D episode!   As a medical technologist - we are now called clinical laboratory scientists - I rate your Vitamin D episode A+.  Aside from a couple of small errors (technically, fungi does not equal plant) - yeah, of course not - you handled your dissertation on the subject like a science major.  It proves once again you really do your homework.  I'm impressed!



I don't think you are going to get any backlash for a non-security episode.  Not everyone who listens to Security Now! is a computer whiz, but everyone who listens is smart.  I would agree with that.  Funny how I am a lab professional with a computer hobby while you are a computer pro with a medical hobby.  Yeah, there you go.  Keep up the good work.  Don't hesitate to bring to our attention anything that's really important.  P.S.:  Is Vitamin D intake via HTTPS a feature of CryptoLink?  Just kidding.



STEVE:  So again, just I wanted to share some of the feedback with our listeners sort of generically and to thank everyone for having responded.



LEO:  Robert Wicks in Atlanta notes that Vitamin D is especially important for black people:  Steve, I wanted to let you know that your information on Vitamin D was very valuable, even for non-Caucasians.  I'm African American  and was unaware of the incredible importance of this hormone, although because of the skin pigment I'm at a greater risk of having an insufficient level of it than you are.  I am a UNIX sysadmin.  Sun is in short supply in the server room.  I would expect that.  Additionally, my wife recently had her thyroid removed and has had to take vitamin D and calcium supplements following her surgery.  We are going to have our blood checked and speak to our family doctor about all of us taking Vitamin D going forward.  That's great, Robert.  Thank you for what was, as you said, the most important podcast you've produced.  It is if, you know, if people are healthier because of it, that is pretty important.



STEVE:  Yes.  Again, we've never missed an episode.  And so I wanted to, to the degree necessary to explain to people why I went off topic, it's because I really - I ended up as a result of studying this for several months thinking, wow, this is just something, some information that I think everyone should have.  And from the feedback that we received that was all like this in various ways, I think the factual basis for what we were able to explain surprised a lot of people.



LEO:  Yeah, I think it's just fascinating.  Jim from Newfoundland, Canada has a comment about Vitamin D and rickets:  Hi, Steve.  Right now I'm listening to your latest Security Now! podcast.  Had to pause to send you this message when you mentioned the resurgence of rickets as a result of Vitamin D deficiency.  A few weeks ago I was watching a YouTube video by Pat Condell wherein he mentioned that more children were being born with rickets to Muslim women who don't get enough sun on their skin due to wearing the full body covering called the "burka," which only leaves the eyes and hands uncovered.  I have included links to the video and the article he references in support of that claim.



I appreciate that you have deviated to a certain degree from the standard security format.  I think it's good you've done so.  Geeks can oftentimes have much more exposure to light from a computer monitor than from the sun.  So your advice should be taken as a word to the wise.  In order for us to keep the body's security defenses in good protective order to guard against infection or breakdown and help extend the mean time between failure of the bodily system, your advice on Vitamin D should really not be considered a deviation from format at all, but merely sage advice on patching a known system vulnerability.  I like that.  May I suggest you tack on a 15-second reminder to the end of each podcast just to remind us to get out in the sunlight for 15 to 30 minutes of exposure to natural light that we need to keep fit?  Thanks to both you and Leo for valuing listeners enough to pass on this health concern.



STEVE:  Well, I'm not going to be bothering our listeners all the time about it.  You know, Leo, you do well at tossing in reminders like that.  So I'll let you do that when you think it might be important.  I did run across a lot of comment in the research specifically about Saudi Arabian women and the extra problem that they have because of the burkas, that they're literally, even when they're outside, not getting any incidental sunlight.  And not surprisingly, I mean, we learned that age decreases our skin's ability to make D; that sun is, you know, exposure to UVB from sunlight is essentially the only natural source, aside from some food sources, but that's only really fatty fish; and that lacking the sun and sufficient youthful skin, there's no source for D.  Yet it's, as we know, not a vitamin.  It's an important hormone for our body.  And so the more, for example, computer guys are inside, as some of our comments have written, receiving radiation from a monitor and not from the sun, the less opportunity we have to make that.  And it can get really critical.



LEO:  All right.  We have time for one more.  Normally we would do 12 questions, but these are all Vitamin D questions, so we'll hold them for another time, another day.



STEVE:  Or not.  I think we're done with Vitamin D at this point.  I don't want to...



LEO:  You got a lot of mail about this.  It's obviously an interesting - a topic that's interesting to you.



STEVE:  It was a phenomenal response.  I mean, hundreds of responses.  And so, yes.  But I think we've done it.  People know where to find some more about it.



LEO:  You get the idea, folks.  Yeah, yeah.  Well, actually that's a question from Phill, Phill Moore in Sydney.  He's wondering about a book called "The Vitamin D Cure."  I was reading a blog post by a personal trainer named Tony Gentilcore - good name for a personal trainer - and he recommended everyone should read "The Vitamin D Cure" by James E. Dowd, M.D.  After last week's podcast, I figure this is right up your alley.  Thanks for all the great work.  Do you know that book?



STEVE:  I do know it.  I own the book.  And it was the first book I stumbled on.  And what happened was I was reading the book.  There were lots of references in the literature to studies.  And it was - but for me, I really wanted to go to the source material, which is what our listeners heard from me last week.  So I began digging into the actual research.  I ended up finding a book that I like a lot more than "The Vitamin D Cure."  It's called "The Vitamin D Prescription."  I have a picture of it and a link to it on the GRC.com/health Vitamin D page.  And that's the book I would recommend, for example if our listeners have family members or relatives or something who might be interested in reading something.  It is very well written.  And basically it exactly follows the literature.  So it's sort of a gentle, nice introduction to the topic, which is a real-world reflection of what all the research is.  And I think that's my favorite book of all to recommend to people who would want to turn on to this.



LEO:  Say it again, say the name?



STEVE:  It's called "The Vitamin D Prescription."



LEO:  Okay.  I'm sure that's in bookstores.  There's been a lot of talk about this all around, in general.  People are very interested in this.



STEVE:  I think we're probably at the tip of a so-called tipping point, where a lot of - it's beginning to get buzz.  It's in the news.  It's just it's so annoying that a blood test is really the only way to know where you stand, I mean, because people tend to shy away from medical procedures.  No one wants, I mean, I'm doing it every week, forcing myself to because I'm really wanting to experiment with sun production in my skin.  And it's not fun to be stuck with a needle.



LEO:  No.



STEVE:  And it's just it's too bad there isn't a better way to know.  But it's funny, many people prefer not to know.  And I completely understand that, too, because you can sort of say, oh, well, I'm probably getting enough.  But I was hit with this low number, it's like, whoa, okay.  I am a computer geek who goes from one cave to another and never gets much exposure to the sun.



LEO:  Yeah.  Me, too.



STEVE:  So, yeah.  Anyway, I'm glad that we've sort of alerted our listeners to it.  We will be back to security, full speed ahead, next week with a really neat episode about the inner workings of what looked like a bulletproof eVoting machine and how it turned out not to be.



LEO:  Yeah, there's another one where I'm just - eVoting.  Boy, the more I...



STEVE:  It just makes you nervous.



LEO:  Yeah, yeah.  It's funny because you expect people like you and me who just love technology would be jumping on this bandwagon.  And every technologist I talk to, the more you know about technology, the more you realize what a bad idea this is.



STEVE:  Yeah.  On the other hand, you've got hanging chad and dimpled cards.  So it's like, that doesn't seem to be a good solution.  Although, arguably, the eVoting problem can be much more sweeping because - in the same way that anything in the physical world is pretty much restricted to just that one instance.  If a particular machine had wide, really widespread adoption, and it turned out to be vulnerable and exploitable, as so far many of these have, that's a huge problem.



LEO:  Yeah.  Well, Steve, great stuff, as always.  I look forward to next week.  We'll be talking about voting machines.  If you want to know more, you know where to find him, GRC.com.  And the Vitamin D stuff is at GRC.com/health.  All the links are there.  And we'll - that'll be it on that.  Except I do want you to report back when you get the final results.



STEVE:  Absolutely.  Will do.



LEO:  I'd like to know how that's going.  But next week voting machines.  GRC.com for SpinRite, the world's best hard drive maintenance and recovery utility for all those great freebies that Steve gives you, like Wizmo and DCOMbobulator, ShieldsUP!, we can't forget that.  It's all there:  16KB versions of the show; transcriptions, too.  GRC, that's short for Gibson Research Corporation, dot com.  Steve, we'll see you again next week.



STEVE:  And as always, GRC.com/feedback...



LEO:  Oh, yes.



STEVE:  ...for all of your ideas, questions, comments, suggestions for future shows and so forth.



LEO:  Very good.



STEVE:  Talk to you then, Leo.



LEO:  Bye bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#211

DATE:		August 27, 2009

TITLE:		Voting Machine Hacking

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-211.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo describe the inner workings of one of the best designed and apparently most secure electronic voting machines - currently in use in the United States - and how a group of university researchers  hacked it without any outside information to create a 100% stealth vote stealing system.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 211 for August 27, 2009:  Hacking Electronic Voting Machines.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all the things you need to know about keeping yourself secure on the Internet.  Our guru of security, the man in charge, Mr. Steve Gibson of GRC.com.  Steve is a security wiz, the man who discovered spyware, coined the term, has written many useful free security utilities, and has done this show for four years, on our fifth year now.  Steve, good to see you.



STEVE GIBSON:  Yes, and today it's the security of, or lack of security of, voting.



LEO:  Oh, man, is that a topic.



STEVE:  Oh, and this is going to upset people, Leo.  I mean, this is pretty scary stuff.



LEO:  You know, we've been - nobody's proposing that we do electronic voting, are they?



STEVE:  Well, we have electronic voting.  For the last...



LEO:  Oh, this is the stuff we're using now, the Diebold stuff?



STEVE:  Yeah.  In this case they're machines from Sequoia which have been reverse-engineered.  And we're going to look this week in detail at what the vulnerability was and how it was leveraged into a demonstration that allows vote stealing in this class of machine.  And so the problem is, I mean, everyone's concerned about, like, Internet voting.  Eh, you know, whoa, slow down, we know we don't want to go there with viruses and malware and everything.  But this is...



LEO:  But we're not talking about that.



STEVE:  Yeah, this is the machines where you interact with them electronically - spinning a dial, pressing a button, whatever.  Some people have paper printed sheets where they're like we used to do tests in college where you use a number whatever it is, No. 3 pencil and fill in the dot, and then they just use basically an optical mark reader in order to tally the vote.



LEO:  Right, that's how we vote.  That's how California votes.  Right?



STEVE:  Well, not down here in Southern California.  I'm looking at an LCD screen with a big wheel.  And I spin the wheel and then punch the - and it's all electronic.



LEO:  Oh, so you have these machines.



STEVE:  Well, yes.  There are - and like the Diebold and Sequoia, there are all kinds of different machines.  These particular machines are still in use.  Well, currently in use.  I don't think after this report gets a lot of air that anyone's going to feel comfortable using them.  But I'll tell the story of how they were procured, and when, and where they're in use.  And I really think this is going to be interesting for people because, using some good reverse-engineering techniques, but a lot of computer, fundamental computer technology that we're going to go into in this hour, it turns out it's possible for someone to sneak in the night before, play some games with each machine, and leave them in a state such that they no longer accurately record the votes that they are registered through their UI.



LEO:  Oh, man.



STEVE:  It's bad.



LEO:  So let's talk - do we have security updates?  Security news?



STEVE:  Yeah, we have some, and a little bit of errata.  And I have sort of a fun, different SpinRite story than I've ever told before.  It was a very quiet week in security.  Thank goodness we have one every so often.  I only have two items.  One is just sort of strange.  The U.S. Department of Agriculture has begun enforcing a policy which bans the use of any web browser other than Microsoft's Internet Explorer.  Want me to say that again [laughing]?



LEO:  I'm stunned.



STEVE:  One of their units, the Cooperative State Research, Education, and Extension Service, they say that they are following the so-called Federal Desktop Core Configuration Guide, which is a 2008 government-wide policy administered by the Office of Management and Budget, the OMB, which requires that agencies standardize operating system and browser settings to prevent security breaches.  And so their logic is that Internet Explorer is the only browser which allows remote configuration and lockdown and management.  So they have, I mean, this policy's been around, but it hasn't been enforced.  They're now enforcing it, removing any non-IE browser.  Specifically Firefox was mentioned in the news story.



LEO:  What?



STEVE:  Because...



LEO:  Well, I understand standardizing because then you can have standard policies and procedures.  So if you have a bunch of different browsers, maybe they don't want to support them all.  Yeah?



STEVE:  Yeah.  I mean, now, this caused a lot of problems.  For one thing, they maintain websites.  And so their webmasters are no longer able to use non-IE browsers which visitors to their website use.



LEO:  So they can't validate them.



STEVE:  Exactly.  They were depending upon using these other browsers to make sure that their sites worked in non-IE browsers.  So it's not clear how this is going to fall out.  But, and people have said, wait a minute, you know, does the Federal Desktop Core Configuration specify that you can only use IE?  And the answer is no, it doesn't.  So it's feeling like there's been some overzealousness on the part of the IT people in this Cooperative State Research, Education, and Extension Service.  But at the moment that's the policy, and people are no longer able to use anything but IE.  Which is, you know, we know how feel about IE.  I mean, I'd be really chagrinned if anyone told me I couldn't use Firefox because I'm, frankly, due to the add-ons and the additional features and controls I have, I can do much more with Firefox.  I have more control over my Internet usage experience and, frankly, more security than if I'm using IE.



LEO:  That's because you use NoScript and stuff.  But, I mean, people use - you for a long time used IE.



STEVE:  I did.



LEO:  And believed it could be made secure.  And that was a long time ago.



STEVE:  Yes.  I went - I had to jump through hoops, though.  I used IE's zone system, and I locked down the Internet zone, and then I manually added sites that I trusted to my trusted zone.  And those had less security associated with them.  So it was possible to do.  But Firefox just makes it much easier.  So it's not only NoScript.  But, for example, I use a little cookie manager that allows me to have all my cookies treated as session cookies, so they're forgotten constantly, unless I say, oh, this is one where when I come back I want to be remembered.  Like I want to have eBay remember, and PayPal and so forth, so I don't have to go through all the log-in every time.  So it's done on a selective basis.  But again, it seems to me like a real step backwards for any government agency to mandate the use of any one browser, if for no other reason it's a lack of choice where choice enhances security instead of limiting it.  But from a management standpoint, I can see that it's tough to support something as heterogeneous as our PC industry has become.



LEO:  Yeah.  It's interesting.



STEVE:  The other...



LEO:  Just the Agriculture Department, though.  It's not government wide.



STEVE:  Right, just USDA.  And it's just - actually it's just even - it's just a unit of the USDA.  So not even all the Department of Agriculture, who have a somewhat less than illustrious security history themselves.  So it's just this one group.  And maybe this is going to shine a bright light on it; and then the powers that be will say, wait a minute, this was a mistake.  But at the moment it did float up to the top of the security news for the week.



The other thing just came across the radar from a report that I'm a little - I'm certainly interested, but I'm a little skeptical.  The original story is in the German version of the Financial Times, which, you know, I can't read.  But it was picked up and reported by The Register (theregister.co.uk).  They've got a lot of good news.  They're a little sketchy sometimes.  They tend to be a little flamboyant and loose with the facts.  So, and I haven't seen this anywhere else.  I looked for it.  I couldn't find anybody else picking up on it.  But the news is that the Chaos Computer Club, which is an established, known hacking group, have said that within a month or two they will issue a public demo and release code so that anyone equipped with a laptop and an antenna can listen to GSM phone calls.  And the story is that GSM has been cracked.



LEO:  Wow.



STEVE:  Now, it's funny because we were talking about this, I think in a Q&A either last week or a couple weeks ago, where someone was asking, am I secure with using a cellular broadband connection?  And I was saying that, yeah, probably, but that this is old encryption that was based on shift register technology to generate pseudorandom bitstreams which are XORed with the plaintext to create ciphertext, and that they were relying on trade secret information, not disclosing the lengths of these different, you know, they're like prime number length shift registers that spin around.  Their outputs are XORed into the final bitstream.  And that creates the encrypted text.  And at the other end this same pattern is used to decrypt it.



You know, we're well versed now, our Security Now! listeners, in the notion of a pseudorandom data stream being XORed with, exclusive ORed, with the plaintext to create ciphertext.  Well, this has apparently been cracked.  So I just wanted to raise that note.  I will keep track of this.  And I'm sure, if this is the case, it's going to surface on a lot of other security sites and will make a lot more news.  This just happened.  And I went to the Financial Times article, but saw that it was all in German and said, well, okay, let's wait for other people to translate this.  I would feel more comfortable knowing, seeing the details of what this Chaos Computer Club is claiming.  And The Register tended to be a little more effervescent about it than I would like.



LEO:  Yeah, yeah.



STEVE:  But it'll certainly be big news if, depending upon what flavor and level of GSM has been cracked, this is not good.



LEO:  Yeah, because I'm GSM.  I'm sure you are.  I mean, GSM is T-Mobile and AT&T.  It's everybody with an iPhone.  It's not Verizon or Sprint.



STEVE:  Correct.  That's CDMA.



LEO:  Doesn't affect them, yeah.



STEVE:  Yup.  And then my little bit of errata is I did want to just put on the radar for our sci-fi fans that Apple now has on their site, Apple.com, trailers for the upcoming James Cameron movie in December, "Avatar."



LEO:  Yeah.  People are really excited about this.



STEVE:  And oh, Leo.  I mean, it looks a little bit too much like unicorns and fairies to me from the...



LEO:  There is that element.



STEVE:  It's weird, yes.  And so I was thinking, well, Mark Thompson, who likes those things, he'll probably get a kick out of that.  But it also looked like it's good sci-fi, as well, so.  Have you seen the trailer?



LEO:  No.  I'm going right now to Apple to see it.



STEVE:  Yes, it's...



LEO:  I've heard a little bit about it.  One of the things he's kind of interested in doing is he believes all movies will be CGI soon; right?  So a lot of this is fully computer-generated.



STEVE:  Yes.  He's mixing live actors and CG, I mean, substantially.  And that's my - I guess if I had a complaint, it's that from this preview that...



LEO:  It looks like it's a cartoon in some areas.



STEVE:  It goes.  It looks a little cartoon-y.  It's not - it doesn't have the - just that real edge that we're used to seeing.  But I think it's because he's had to bring in, I mean, like these are not - these sets that they're on don't exist.



LEO:  They're all green screen.



STEVE:  They're all synthetic sets.



LEO:  Yeah, yeah.



STEVE:  Yeah.  So anyway...



LEO:  Well, this is the future of moviemaking.  I don't know if it's the - by the way, James Cameron also thinks all movies will be 3D soon.  So he's kind of bought into this whole notion.  I guess there's stuff you can do in CGI that you just can't do any other way.  



STEVE:  Yeah, I mean, there's a scene in the trailer where a little helicopter is flying in this large space with sort of really neat sort of floating dirt mountains.



LEO:  Right.



STEVE:  And I don't know how you do that...



LEO:  You can't, yeah.



STEVE:  ...except to do it all in computer-generated imagery.  So, yeah, I don't know.  Have you seen any of the new 3D movies?  I have not.  And so I don't...



LEO:  No.  And I can't because I have mono vision.  I don't have...



STEVE:  Your brain doesn't merge the two...



LEO:  Yeah.  So I can't really tell 3D, unfortunately.  So I will never appreciate it.  I hope it doesn't take off because then it means I'm not going to enjoy movies much anymore.  They'd better provide a 1D or 2D version for oldsters like me.



STEVE:  It'll be interesting.  The problem is, I know that there's a "Final Destination" movie coming out in 3D.  I liked the "Final Destination" movies.  Something about the plot lines just sort of appealed to me.  But this one is - it's where the car tire is smacking you in the face.  I mean, it's overdone.  It's not just sort of subtle where you can forget that it's 3D and find yourself immersed in it.  Instead they're taking advantage of, like, you know, poking sticks out of the screen at you...



LEO:  Right.  I don't like that.  It's gimmicky when they do.  It's gimmicky.



STEVE:  Yeah, exactly.



LEO:  But I guess he feels, and he's probably right, that the future is more immersive, more realistic.  And of course if you're using computers to generate it, it can be very, very authentic 3D.



STEVE:  Oh, it could be spectacular.  The problem is that, as we know, in order to generate 3D you need to give each eye, each of your eyes its own image.  And that's been challenging.  One approach has been the blue-green, I'm sorry, the red-blue glasses, where you use tinting of the two different images and separate them that way so that one eye sees red that's filtered out by the blue, and the other sees blue that's filtered out by the red.  But then you've got a problem with color.  The alternative is to use high-speed shuttering where each eye is seeing alternative frames on the screen.  And that's very expensive because now the whole audience has to have some sort of electronic gadgetry that they're wearing in order to separate the images.  So, challenging.



LEO:  By the way, somebody pointed out, absolutely, as usual, I'm U.S.-centric, that GSM may only be used by AT&T, T-Mobile in the U.S., but it's used worldwide on almost all phone systems.



STEVE:  Well, yeah, exactly.  It is the global standard.



LEO:  Yeah.  So I apologize.  I didn't mean to sound U.S.-centric there.  Yes, everybody uses it worldwide.



STEVE:  And a note was forwarded to me about a month and a  half ago that I had actually on my Starbucks machine and wanted to share because it was sort of an interesting story.  It was forwarded to me by Sue, my office manager/bookkeeper, from someone named Sean.  He said, "Hello.  My name is Sean.  I went to a flea market, and there was a man selling SpinRite for $80.  I asked him how can he sell it.  He told me he has a special deal worked out with you, so I bought a copy."



LEO:  Oh, boy.



STEVE:  "It was a few days later when I got home to run the program.  And when I did, I saw that it was registered to" - and then there's a person's name here - "with a serial number of" - and then he gives the serial number.  And so he was reporting this to our office at our sales email account.  He says, "I drove the 30 miles back to the flea market, only to find that the person selling what was clearly an illegal copy of SpinRite was gone.  I have not used the product.  I do not want to do that to you.  And you never know if someone has stuffed something extra in it, like some bad guys do.  The thing that bugs me is that I saved up for three months to get the $80, and I should have just gone to your site, but I did not."



LEO:  Oh, I feel bad.



STEVE:  "I will destroy this copy and try to save the money again and get it from your site this time.  You and Leo are doing a great job.  You both provide very useful information that, when followed, will keep us very safe.  Thank you to both of you."  Well, Sue answered him and said she was sorry to hear what happened, and also blind copied me on it because she's known me for 22 years.



LEO:  Yeah, I know you, too.  And I know exactly what you did.



STEVE:  So I replied.  I said, "I'm sorry to hear that you were sucked into that scam, and I'm certainly annoyed that some loser is making money from people - he has your $80 - by illegally selling our software that was licensed to someone else.  But I'm also not happy with the idea of you needing to spend another $89 to purchase a legitimate copy from us.  After all, although we do need to sell SpinRite to support everything we do, our cost to develop and support a copy of SpinRite is relatively low.  Therefore, in a minute or two you'll receive a note directly from GRC's eCommerce system, which I'm able to securely access from Starbucks thanks to our Perfect Paper Passwords system, which you probably know about from the Security Now! podcast.  The email you receive will be a receipt for a no-charge copy of SpinRite, licensed this time to you by name.  And the links in the receipt can be used to download your own personal copy now and forever more.  Thanks for your note and for your support of GRC.  All the best."



LEO:  Oh, thank you, Steve.  I knew, I knew that was going to be the answer.



STEVE:  Oh, yeah, I mean, it sounds like he is a neat kid, and I appreciated him letting us know that this had happened.  And but no way was I going to have him save up and buy another copy.



LEO:  There's nothing you could do about that other copy, I guess.  You can't...



STEVE:  Well, and I, you know, that's the nature of software.  I mean, we know that it's high margin.  We know that some is going to get stolen and pirated.  What happened was, I mean, we know this copy.  We know that person's name.  When I first came out with the software distribution system, I was giving people an encoded URL that they could use forever, with the instructions "Make sure you never let loose of this."  People were using download managers, which were behind their back spying on them and reporting the URLs they used for downloading software to a central database.



LEO:  You're kidding.



STEVE:  No.  This is going on.  I mean, download managers are doing this.



LEO:  Oh, my goodness.  Do you know which manager it was?



STEVE:  I did at the time.  This has been years ago now.



LEO:  Oh, that's appalling.  I had no idea.



STEVE:  Yeah.  In fact, there was, like, the idea was it was supposed to be a service, that you could then go to this and 

see what other people were downloading and use their URLs to download it yourself.



LEO:  Oh, my god.



STEVE:  And so three or four copies, three or four of SpinRite 6's first users were using these download managers.  We quickly learned that these copies had gotten loose.  And so we marked them in the eCommerce system to kill them so that they could not be used, they couldn't be downloaded anymore, and they couldn't be used for upgrades.  But they were loose anyway.  We contacted these people, told them about the problem.  They, you can imagine how horrified they were to know that everything they downloaded was being sent back to the mothership somewhere and being searchable in a third-party database.



So anyway, so we fixed the problem.  And I changed the way our eCommerce system works so that the download links are good for literally one time.  The act of clicking on it kills that code, so it cannot be used again.  And if you don't use it within about five minutes, it expires.  And it's easy.  You just get another one from us.  You can get them anytime you want, as many as you want.  But so that solved the problem, but not before a few got away from us.  And those are the ones that are floating around the 'Net, and we see them from time to time.  So it's like, oh, well, that's the way things go.



LEO:  That's shocking.  You know, I remember we did this - this is how long this has been going on.  On The Screensavers we had Avi Rubin, security researcher, come on and show us - this must have been six years ago - how electronic voting machines could be compromised.  He's been telling Diebold and the other companies about this for six years, and it's still a mess.



STEVE:  Yeah.  The thing that appealed to me about this particular story is that this machine was very well designed.  We've talked often about the mispurposing of operating systems, the idea of using Windows in a checkout stand in a supermarket or in an ATM machine, because it's a huge, complex, massive operating system with all kinds of bells and whistles.  And every bell and whistle you have has to be exactly correctly designed, or there's a potential for exploitation.



So when I hear that a voting machine is using Windows, or even Linux, I mean, people say it needs to be open source so that it can all be perused.  Well, I completely agree that where voting is concerned, you ought to really have people taking a look at the code and understanding it.  But I object to the idea of building basically a simple application, I mean, electronic voting is trivial.  There's nothing to it.  It's display some names and select one of them and record that.  The idea, frankly, that you would use any operating system is offensive to me because it's overkill, and it's overkill in a way that can definitely hurt you.  I mean, look at the security problems, for example, that Apple has had as a consequence of the third-party open source software that they've got bundled with the Mac.  Many times it's not code that Apple wrote, it's just - it's public libraries that are out there, they're open source, but we know that doesn't mean that they're secure.  It means that there's a better opportunity for analyzing them, seeing what's going on.



But for me the idea solution would be a very small, very lightweight solution for voting where the code is also open source, that is, many researchers have looked at it and tried to find ways around it, yet there just isn't anything there you don't need.  So, I mean, there's just so many opportunities when you have a huge operating system.  So what I'm going to talk about today is a - is exactly that.  It is a very beautifully designed, tight little voting machine which is the kind of thing, exactly, that I would recommend people come up with for this kind of solution.  It uses an 8-bit Z80 processor.



LEO:  Wow.  Blast from the past.



STEVE:  Yes, the Zilog Z80, which was a sort of a superset clone of the original Intel 8080 processor.  It has a 16-bit address bus, so we know that 16 bits gives us access to 64K of addressing space.  What happened is - oh, and this machine is called the Sequoia AVC Advantage.  It is still in use in New Jersey, Louisiana, and other places.  The machines specifically are version 5.00D.  And they were originally purchased in 1997 by Buncombe County, North Carolina.  They were purchased for $5,200 each.  In January of '07, so after a 10-year life, they were retired, these particular ones, the ones that are no longer in service, were retired from use and auctioned off on a government auction website where a researcher at Princeton, Andrew Appel, purchased a lot of five of these machines for a grand total of $82.



LEO:  Just for fun.  He just wanted them for fun.



STEVE:  So what is that, $13 or $14 apiece, he gets these used voting machines.  The problem is, they're in use elsewhere in the country.  So now he has them and says, okay, how secure are these things, which I've got now five copies of, which are in use elsewhere in the country?  So a bunch of guys from UC San Diego, Princeton, and University of Michigan - and their names, Ed Felten is among them, they're well-known security researchers, academic types - they decide they're going to analyze this machine.



Now, what's interesting about the machine is it really was designed by people who did, I'm convinced, the best they could to come up with a secure solution.  The total machine is this Zilog Z80, which can address 64K of memory.  But they needed more than that much code to do all the different things that the machine had to do.  So it contains three 64K ROMs, and each of these ROMs is divided into quarters.  So there's four 16K pieces per ROM.  And instructions that the Zilog chip can execute cause various quarters, these various quarters of these ROMs, to be mapped into the address space of the Z80.  This is something that's been done for years whenever systems outgrow their address space.



For example, people may remember, anyone who was using DOS in the old days remembers EMM, the extended expanded memory system.  Actually I think it was Lotus that - I think it was LIM, wasn't that the acronym, Lotus, Intel, and Microsoft.  What happened was spreadsheets got bigger than the 640K that the PC could handle.  The PC had a 640K, actually it was a megabyte, but the top chunk of it was used by the BIOS and video and I/O space.  So you're able to put 640K of RAM in the original PC and XT in order to fill it out to its full size because remember that Bill Gates famously told us that, oh...



LEO:  Nobody'll ever need more than...



STEVE:  Oh, that's 10 times more than an Apple II has, so obviously that's plenty.  So what happened was spreadsheets were very popular.  They were getting big.  So it was necessary to somehow add more data space to the PCs.  So you could then buy basically a RAM add-in card, which used a technology exactly like this little voting machine used, called bank switching, where there's like a huge amount of RAM, and you could cause pieces of it, a bank at a time, to be accessible in a certain address range that was within this 640K space.  So you'd basically swap in and out chunks of a much larger memory.  You couldn't, there just weren't enough addressing bits to uniquely address as much RAM as you now had in your machine.  So you could sort of do them a bank at a time, a piece at a time.  And so the Lotus 1-2-3 spreadsheet, an API was created to allow this to be done, to be accessed in a standard way.  And this allowed your data to occupy much more space than the system was able to access at one time by sort of swapping these things in and out.



So this little voting machine, this Sequoia AVC Advantage, uses that.  What it did was it took its 64K, and one quarter of one of those 64K ROMs was its so-called BIOS, which was always mapped into the address space starting at the beginning.  So zero to 16K.  Then any other one of the 16K chunks in these three 64K ROMs could be mapped into the second 16K space.  That left 32K for RAM.  And so the first 32K was ROM.  And the second 32K was RAM, thus making up the full 64K, 16 bits' worth, that this little Z80 chip could access.  I mean, everything about this is cool so far.  Then they went one step further.  Because they knew this was a voting machine, security was paramount.  They made it so that it was impossible to execute code from RAM.  They thought, there's no way, there's no reason that anyone has a legitimate reason for executing code from RAM.  So...



LEO:  That's correct.  That's right.



STEVE:  Absolutely right.  And we know what a problem that is for our computers.  I mean, all the buffer overflows and running code on the stack and running code in data buffers, this is the problem we have today.  And 20 years ago, when this thing was first designed, the engineers said, let's just prohibit that with hardware, something no one can get around.  So they added hardware which any attempt to execute out of that lower 32K, any attempt to fetch an instruction from the RAM, that upper RAM half of the instruction area of the addressing region, immediately causes a halt of the system.  It just locks up.  It actually, there's something called a "non-maskable interrupt," an NMI, which chips at the time had, that I think we still have them in our current hardware, that is an interrupt, a hardware interrupt that nothing can block.  It can't be masked off by software.  And it caused a hard jump into the BIOS to put an error code on the LCD display, and then it did a halt.  So it's just there was - these guys understood that this kind of security was important.



So the researchers took one of these machines and held it up, held the circuit board up to a bright light.  It was just a two-layer circuit board.  So if you shine a bright light through the circuit board - because it's just made out of, it's not plastic, it's fiberglass - you're able to see the traces on both sides of the circuit board.  Typically one side traces run horizontally, the other side they run vertically.  And so, and they knew what the chips were.  So they came up with a schematic for this.  They also knew what the instruction set of the Z80 was.  And so they dumped out the three ROMs so that they could see what the code was.  Basically they reverse-engineered the machine. But reverse-engineering something which is secure shouldn't be a problem.  You know, we've talked about security by obscurity.  So the idea would be that this could be in the public domain, and it shouldn't make it any less secure because you don't want to rely on what people don't know for your security.



LEO:  Right.



STEVE:  We've talked about that often.



LEO:  Plus it's great to have other eyes looking at it.  That can be a real value.



STEVE:  Oh, believe me.  What these guys did, I'm sure if the engineers are still around who designed this machine and paid so much, put so much evident care and concern into security, they're just shaking their heads because here we have hardware that will not execute any code other than what was provided.  So no kind of code injection can be used.



Okay.  Now we need to talk a little bit about the way stack machines work.  The notion of a stack was an innovation which occurred to someone, I'm not sure where in the development of computer evolution.  But, for example, my old favorite little dinky 12-bit PDP-8 did not have this notion originally of a stack.  So when you wanted to execute a subroutine - a subroutine just sort of being a piece of code that many different places in the program might want to run.  So the idea is, instead of repeating that code throughout the program, you only have it in one location.  And different places in the program are able to execute that subroutine, the idea being that the subroutine does whatever it does.  And when it's done, it returns to the instruction after the one that called it, that invoked it.



And by being able to go back to where it was called from, instead of, for example, always going back to the same place, if it goes back to where it was called from, then you can call it from anywhere you want, knowing that once it's done it'll come back to you, and you can continue doing what you were doing.  So you need some way of knowing where you were called from, that is, the subroutine needs a way of knowing where it was called from in order to go back there.



Well, before stacks were created, and the solution that the PDP-8 used, was the first word of the subroutine was always left blank.  And when the subroutine was called, the computer would put the address of the instruction after the one that called it into the top of the subroutine.  So it would sort of just be stuck there.  Then the subroutine would do whatever it does.  And when it's all done, it would jump to the location stored at the front of it.  And that would take it back to where it was called from.



Well, that was an elegant solution, and it was the only one we had at the time.  But there was a problem with that.  And that is, you couldn't have reentrant code.  That is to say that, for example, not only could the subroutine not call itself, because if it called itself it would overwrite the return address at the top of it with another return address, but it couldn't call any other code that might have some reason for calling it.  That is, you could never nest subroutines.  Which ended up being a real problem as programs got more complicated because it just - you had to really understand what your program's flow was and make sure that there was no way that a subroutine could ever execute code where anywhere downstream it could get called again prior to it returning.



So the innovation of a stack was tremendous for computer science.  The idea was that, instead of storing the return instruction in the code of the subroutine, instead we would have sort of a separate scratchpad which would automatically, I want to say, grow.  I'm trying to think of how to describe it.  It would automatically accept values and return values in a last-in, first-out mode, a so-called LIFO, meaning that if you put a value in, that's the value you get out.  And as you take values out, they come out in the reverse order that you put them in, in very much like a stack.  If you could imagine, if you imagine something that's called a stack, for example, like a stack of plates, where if you put plates on the stack, the stack grows.  And as you take plates off, you're getting them in the reverse order.



So what happens is, with a stack-oriented machine, which is what everything is using now, it's such a successful and popular concept that when a subroutine was called, the return address was placed on the stack, and the subroutine would do what it does, and then a special instruction, a return instruction, would always take the value that's on the top of the stack, which would have been the last one placed on the stack, and return to there.  So the beauty of that is that, if that subroutine called some other code that ended up calling back to the subroutine, well, this all just gets stuck on the stack.  So as the return instructions are executed at the end of each subroutine, the values are popped off the stack in the reverse order, and everything works.  Everything sort of comes back just exactly the way it's supposed to.



So the Z80 was a stack-oriented machine.  And so the designers took advantage of its stack orientation in order to write their code.  So the problem was that from a hacking standpoint it's not possible for us to provide any code because the only code we can provide would be in RAM.  But we could provide pointers to code in ROM.  So what these hackers cleverly realized is that there was, spread throughout the code for this voting machine, were subroutines, all ending in a return instruction.  And they didn't want necessarily to do what these subroutines did.  But they looked at the last few instructions prior to the return instruction and said, okay, is that useful for something?  Is the little bit at the end of the subroutine useful?  What does that do?



Well, it turns out that they wrote some code to look for all the return bytes.  In the Zilog Z80 instruction set, a return instruction is a C9 in hex.  These are all 8-bit instructions.  A C9 is a return instruction.  So they found all the C9s that were in ROM.  And then they looked at the instructions just in front of those C9s to see what those do.  And what they were trying to do was come up with a corpus, come up with a collection of useful things where they could jump to the near, just near the end of the subroutine and get a little bit of work done.  Not a whole bunch.  Just add something to the accumulator.  Maybe subtract two values.  Or put something somewhere in memory.  Just little bits of work which happened to be at the end of all the subroutines, all the various subroutines that existed in this code.



One of the cool things from their standpoint about the Z80 is that every single byte is an instruction.  It was back in the day where we had 8-bit bytes.  So you had 256 possible instructions.  And in the Z80 it was completely dense.  That is to say, this map of 256 possible instructions was completely full.  There were no invalid instructions.  There were no privileged instructions.  On more advanced machines like the Pentiums and PowerPCs and so forth, they have much larger instruction sets that won't fit in a single byte anymore.  So many times there's areas of sort of ranges of instructions which are illegal.  They're just not defined.  They're for the future.  They just didn't need all of the instruction space.  And in other cases there are so-called privileged instructions, for example, which are powerful, which only the operating system running in the kernel, but not the user, is able to execute.



So for example in a Windows environment or in a Linux or UNIX environment, the user processes cannot actually do I/O.  You can't access the physical hardware port because if you allowed that to happen, then users would have too much power.  Instead you have to ask the operating system to do those things on your behalf, and it manages conflicts between programs that way.  So this is the way things have evolved.  But back in the days of the Zilog Z80, there was no notion of privileged instructions.  What that means is that any data in this ROM that they had access to could be instructions.  Even if they weren't meant to be, if they were never - if they were just like regions of data that happened to have C9, for example, in them, then the things in front of these return instructions could be executed.  Nothing would generate an error.  Nothing would blow up.  Nothing would go wrong.



So what the researchers did was they found all these little return instructions, and they analyzed the work being done just before the return.  Because what they realized they could do is come up with a stack which doesn't have code on it because the stack is in RAM, and we know that we can't execute out of RAM.  But we can have pointers in the stack into subroutines.  And when the subroutine returns, it'll come back and get the next pointer from the stack.  Because that's how stack machines work.



So what they did was they aggregated sets of little tiny bits of work at the end of all these different subroutines into what they called "gadgets."  And a gadget would do a defined thing, like it would add two values together.  It would subtract one from another.  It would perform a nonconditional jump or a conditional, a branching jump.  Or it would do all the various things that programmers want to do.  They were able to come up with little tiny fragments of work which when aggregated together created a complete pseudo instruction set.  And it was what's called...



LEO:  That's quite clever.



STEVE:  Oh, it's so clever.  And it's what's called Turing complete.  Remember we've talked about Alan Turing, the cryptographer, and the guy who gave us the Turing machine.  This whole notion of computability, Alan Turing really researched and brought to the world.  The definition of a Turing complete computation engine is one that can compute anything else that a Turing complete machine can compute.  So what these guys did was, they defined their own instruction set, which was Turing complete, meaning they could do anything they wanted.  And this is what...



LEO:  That's amazing.



STEVE:  I love that these guys were academicians because they really pushed this probably further than they had to.  But they just wanted to say, we can do this.  So in looking at the disassembled code, there were very few buffer overruns.  But they found one.  They found one in one part of the file system that had been defined.  And they realized that there was a way they could get about 12 bytes onto the stack.  They could gain a foothold.  Now, that wasn't enough to do much, but they didn't need much because they were able - there was one error that they found in the file system where, if they made a funky file, then they could get the thing, the code that was interpreting the file, to put some data on the stack.



This would normally never be a problem.  These machines weren't networked.  They were standalone.  They had two cartridge slots on them.  One was the so-called "results" cartridge, which was - they're battery backed-up static RAM cartridges.  And the other one was an auxiliary cartridge.  Which could be - and these could also be mapped into the address space of the processor.  So they realized that they could put in a specially designed cartridge where the file system of the cartridge - and they reverse-engineered all of this.  I think they said it took - they're guessing it took about 16 man months.



LEO:  Oh, man.



STEVE:  So if you had 16 people, that's one month.  If you had eight people, that's two months.  So, but remember, this is a voting machine in use today.  So they figured how they could - basically the protocol was somebody the night before the election, where these machines are going to be used, goes into the voting place, pulls out the results cartridge just a little bit to dislodge it from its mounting.  There's a plastic security loop which runs through holes in the cartridge to prevent it from falling out and, frankly, to prevent it from being removed.  But it turns out that the holes are big enough you could pull the cartridge just out so that it's no longer making electrical contact.



The auxiliary cartridge was empty because there was none necessary.  It was sort of an add-on, upgradeable feature, but wasn't used.  They were able to plug their cartridge in, turn the machine on, and when the machine saw that the auxiliary cartridge was in place, it would load one of the files in the file system which they had prepared.  That, because their file was deliberately made incorrectly, but from looking at the reverse, from looking at the disassembly of the code, they figured out where there was a fault in the processing of the file system.  And again, this is so easy to do because even the developers, if you showed them that there was this problem, the developers could say, well, but yeah, but we're making the files.  So we know how to interpret them, and we're not going to make a bad file.  And they could also say, and even if someone did, they can't execute their code.  Because these are RAM cartridges that are in the RAM space, and they won't execute code because we made sure only our ROMs could execute code.  In the hardware.  No way around it.



So they'd turn the machine on with their special funky cartridge plugged into the empty auxiliary slot, go to the main menu, tell it to load from the auxiliary cartridge.  That allows them to get their special file in, which trips up the file system interpreter in a way that lets 12 bytes end up on the stack.  And that gives them a foothold.  Those 12 bytes are pointers into existing ROM code, the end of subroutines, just little fragments, a few instructions at the end that they've figured out how to knit together.  And that then loads additional code, which gets them into the machine.



And once they get this corpus collected, they have the ability to do anything.  They then - the attacker pushes the power switch.  It turns out that it's a soft power switch.  It's a power switch which is read by the software, just like all of our consumer electronics.  I mean, an iPhone, anything you've got in your pocket running on batteries, these are soft power switches.  You're typically not actually disconnecting anything.  I don't know if people have noticed, but if you do take the battery out, it takes much longer for it to run down than it does if it's just, quote, "off," because they're not actually ever off anymore.  So this is like that, a soft power switch, which then their code fakes this machine being turned off.  It blanks the displays, turns off the LEDs, blanks out the LCD.



The one thing they say they didn't succeed in doing, and it's like, well, we decided we did a good enough job, was they did not and could not turn off the LCD backlight.  So there was one little bit of hint was that the LCD was still backlit.  But otherwise this thing pretended to be powered off and asleep.  And the machines have a 16-hour backup battery which was part of the spec for the voting machine, so that you could still vote even in the event of a power outage.  So even if the machines were then unplugged, or if they hadn't been yet deployed for use the next morning, in the next morning's election, they would survive the night prior to being put into use.  So the code was there.  When the machines were turned back on they exactly emulated the normal startup sequence.



Now, the beauty is that they had access to all the ROM that actually does the work.  So if the machine - you know, the ROM that would do the normal good work.  So they were able to call all of the ROM routines for doing normal election operating appearance.  And in their demo what they did was, once the election was over, and the menu was used to end the voting, they took half of the number of votes given to the second person on the ballot and gave them to the first person.  So they just moved them over.  I mean, they could do anything, any logic you wanted about what percentage of what votes go to who and so forth.  But just for their demo purpose they said, okay, just to show that we can actually do vote stealing, we'll take half the number of votes that the second person on the ballot got and subtract those and put them in the first person.  And then all the other accounting that was in the machine they balanced out so that everything worked.



So from standing way back from this, this is a matter of you approach the machine sometime before the election.  You slip your cart- you pull the cartridge, you dislodge the good election results cartridge.  You slip your hacker cartridge into the unoccupied adjacent slot, turn the power on, do a couple things on the menu, turn the power off, pull your cartridge out, go to the next machine, do the same thing.  Go to the next machine, same thing.  You have corrupted the results from these voting machines which are currently in use in the United States.



LEO:  Wow.  Now, a couple of points.  One, they had the source code.



STEVE:  No.



LEO:  They didn't have the source code.



STEVE:  That's the beauty.  And they make a point of saying prior efforts at subverting voting machines have had the advantage of information that was not publicly available.



LEO:  Right, right.



STEVE:  Like the source.  They had no source.



LEO:  Oh, man.



STEVE:  They had nothing but purchasing five of these for $82.



LEO:  Wow.  And this is one, the Sequoia machine is just one.  There are other machines which also have been shown to be hacked, hackable.



STEVE:  Yes, in fact, I don't know if any have been shown not to be.



LEO:  Yeah, I think it's the other way around, you're right.



STEVE:  I mean, it's - the problem is that, I mean, I loved this particular machine because it's the way it should be done.



LEO:  It was smart.



STEVE:  It's a tiny little 8-bit processor.  It doesn't take anything to count votes, to turn some LEDs on and show something.  I mean, we had that back on our Atari videogames.  I mean, it takes nothing to be a voting machine.  Yet traditionally, or I should say contemporarily, we've got Linux and UNIX and Windows, god help us, and compilers and networking and so much opportunity for something that I regard as about as mission-critical as anything could ever be.  And certainly the stakes are high.  I mean, there are people, certainly not people we know, hopefully, but who would actually do this.



LEO:  Oh, yeah.



STEVE:  Who would, if they could, they would actually feel that they had a moral right, or they just maybe don't even have morals.  I don't know.  But they would think, hey, if I can, I want my man to win, no matter what.  And unfortunately...



LEO:  Yeah.  Or foreign governments or, I mean, there are people with sufficient resources to do this.



STEVE:  Yes.



LEO:  Absolutely.



STEVE:  And that was the point that was made here, is 16 man months is nothing.  And buying five of these for 82 bucks from a government auction site, I mean, these are available to private citizens.  And it was from having no information about these machines, they were able to completely take them over, build their own Turing complete pseudo instruction set, then use the existing code as their own subroutines to save them from having to recode the whole thing, I mean, the  machine knew how to be a voting machine.  Yet they just - they shimmed themselves in and did it in such a clever way that they got around this fundamental limitation that only code in ROM could be executed.  They just used...



LEO:  That's the amazing thing.



STEVE:  ...little fragments that were already there and knit them all together.



LEO:  That's the truly remarkable and slick thing.



STEVE:  Isn't that cool?  That's, like, wonderful.



LEO:  Yeah.  And that's so slick.  Wow.



STEVE:  Oh, and the other thing, they had one more thing, they had a routine in there called "pet" because there was a watchdog timer as part of this.  The idea being a watchdog timer is something in many embedded computer systems.  The idea is it's a hardware timer, and it makes sure that the system isn't hung or isn't misbehaving.  And so what happens is, in the regular software loop that the machine is in, every so often it sort of just - it resets this timer before the timer has had a chance to time out.  And when the timer times out, it also yanks on the so-called NMI, the non-maskable interrupt, to say hey, something is wrong, wake up.  Because the idea would be that the machine would have frozen so that the software wasn't running.  Well, while their code was in control, there was nothing ticking and preventing this watchdog, the watchdog timer from expiring.  So they had a little bit of subroutine they called the "pet" to pet the watchdog, to keep it happy.



LEO:  [Laughing] It just shows you how smart people are.  I like it that these guys are good guys, not the bad guys.



STEVE:  Well, yes.  And this kind of news helps to keep our politicians aware, and certainly our citizenry aware, that we really need to decide how we're going to move forward.  Are we going to allow voting machines to be insanely complex so that no person on earth can testify to their security?  The new ones are that way.  I mean, no one can testify to Windows or Linux or UNIX's security.  We know on this podcast we're constantly bombarded with serious problems in these systems because they're so complex.  Complexity is the enemy of security.



So I say something super simple like this, which you then open up to everybody and let guys like this use this level of cleverness and say, oh, we found a way around this.  And we'll end up with something bulletproof in no time.  The problem is we're still a profit-based system, and we've got independent companies saying, oh, no, our voting machines are completely secure, and you have to pay us this much money to get them.  And we're not going to tell you what's inside.



LEO:  Yeah.  Well, I just have the feeling that we shouldn't be doing electronic voting of any kind.



STEVE:  I really do like the idea of just filling in the bubbles with your No. 3 pencil and running it through a scanner.  And then you've got - and you keep all of those.  And then you do - you take them somewhere else and run them through different machines to make sure that the numbers come out the same.



LEO:  Although I suppose any counting machine can be subverted.  So aren't we at risk no matter what?



STEVE:  Yeah.  I mean, it's...



LEO:  I mean, anything can be subverted.  So maybe the key is just to really do this, which is do these kind of studies and get the word out and work harder on making this stuff good.  The code seems like it shouldn't be so complicated that you could write it without a buffer overrun.  I mean...



STEVE:  I agree.



LEO:  ...it can't be that complicated.



STEVE:  I agree.



LEO:  So maybe we just need to concentrate on coding it better.



STEVE:  It is the case that it was our old friend the buffer overflow in one routine where it would have normally never caused a problem, where they said, ah, we can get a foothold.  And now we know by using little fragments of existing code that we can knit ourselves into existence.  That's just wonderful.



LEO:  And failing that, they would have no way in.  Right?



STEVE:  Correct.  They could have said - they would have sat there frustrated, saying, well, we've developed a complete pseudo machine language using - by the way, this notion of, like, a whole list of subroutines, that's called "threaded code."  Threading is what, like, for example, the language Forth was a threaded compiled code system where the actual program was just a series of subroutine calls.  And in this case these were little micro subroutines, a few little instructions at the end of existing subroutines that they were able to figure out how to build a complete machine from.



But you're right.  Without a foothold, they would not have been able to get that.  Although the system was clearly designed without this notion in mind.  In the paper that these guys wrote, they made the point that 20 years ago, in '88, when this was first designed, I mean, nothing wrong with it being 20 years old.  I'm here to tell you that sometimes good stuff is the secure stuff.



LEO:  Yeah.



STEVE:  Back then, no one had heard of the so-called "return-oriented programming."  That's the - there's this notion, it's called "return to libc" is sometimes how it's known, or return-oriented programming.  No one had ever thought about that.  No one had come up with this idea.  So 20 years later this concept arose.  And so the researchers made the point that something like a voting machine, with a useful lifetime of X decades, its security has to stretch throughout its entire lifetime.  They made the point, for example, that cartridges containing RAM would have had to be a certain physical size back then.  But now we could put a whole supercomputer system in what was a RAM cartridge back then.  And so they had to be robust against that kind of evolution in the fundamental computing technology, too.



LEO:  Wow.



STEVE:  Just a cool story.



LEO:  Yeah, really great, really great.  Fascinating stuff.  Well, thank you for bringing it to our attention; you know?  Wow.  And I guess there really isn't much moral to be taken from this except that we have to test these things very, very thoroughly before we even consider using them.



STEVE:  Yeah, exactly.  I would say skepticism is, you know, healthy skepticism is what you want to have.  Again, the idea that these guys are performing this kind of reverse engineering, creating a demonstrable vote-stealing result, using machines which are currently in service in the United States for elections, that's got to hit the radar screens of politicians and the committees that decide what's allowable conduct, what's allowable for the technology we're going to be using for voting.



LEO:  Great stuff.  What a good show.  What an interesting story.  Next week we answer questions.



STEVE:  Yup.



LEO:  So if you've got questions about this or other subjects or want to raise some issues, I know a number of people in the chatroom were saying, well, is IE8 really less secure than Firefox?  So I'm sure we'll get some questions about that.  Here's how you get back to Steve.  You just go to GRC.com/feedback and fill out the feedback form.



STEVE:  Please do.



LEO:  Steve will collect your questions, and we'll have some answers next week.  You can also, when you're visiting GRC, of course, get some great stuff.  There's all sorts of wonderful useful security utilities - ShieldsUP!, Wizmo, DCOMbobulator, Shoot The Messenger, and of course Steve's bread and butter, don't forget the great SpinRite, the world's best disk maintenance utility, available right there, and only there.  Right?



STEVE:  Hopefully not at your local flea market.



LEO:  Not sold in any store.  GRC.com.  We probably should have been saying this all along.  Do not buy it from a flea market.



STEVE:  Well, you may get more than fleas.



LEO:  Yeah.  Steve, thanks so much.  Great to talk to you.  We'll talk again next week.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#212

DATE:		September 3, 2009

TITLE:		Listener Feedback #74

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-212.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 212 for September 3, 2009:  Your questions, Steve's answers #74.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security and privacy oriented, online and off.  As long as it has to do with your computer, I guess, not with peeping Toms looking through the window.  We don't help you with that.



STEVE GIBSON:  No.



LEO:  Steve Gibson is here.  He's the man at GRC.com.



STEVE:  That's outside of our scope.



LEO:  We haven't yet, anyway.



STEVE:  Yeah.



LEO:  Never say never.  Steve is the majordomo at GRC, the Gibson Research Corporation.  They do that great SpinRite program and all sorts of great free - they.  You.



STEVE:  They.  I was going to say "they," the great unwashed masses of GRC.  Yes.



LEO:  Well, what was - how big?  At one point GRC had...



STEVE:  Too many people.  We had 23.  And I just was pulling what little hair I have out.  It was - I was just a babysitter.  And I thought, this is not, I mean, I remember years later running across an outline that I had prepared.  It was in the outlining program called Grandview, which I used to love.  And it was an outline about a meeting that we had about how to have meetings.  And I thought, my god, even our meetings were having meetings.  That's all I did was have meetings.  I hated it.  You know, I like to argue with the bits and write the code and come up with solutions and things.  And I was paying everybody to do that for me.  And I thought, well, wait a minute.  I've given up the thing I like doing the most, so...



LEO:  Well, I watch, you know, I watch and learn, try to learn from that lesson.  You know, very interested.  I've never been an entrepreneur or businessman before.  And so I pay very close attention to what you say about that because we're growing.  You know we have six employees now.  And I don't want to ever get to the point where I'm going to a lot of meetings.



STEVE:  Well, what I realized at one point, for a while it was exciting to have employees.  It's like, whoa, look at all these people who are part of my team.  And I definitely miss the camaraderie, the...



LEO:  Yeah, we've got that here.



STEVE:  There was so - there was a really neat synergy among people.  You know, people would come up with wacky things, I mean, it really wasn't aimed at clear productivity. It was just fun.  It was just social.  It was nice that, you know, I chose smart people, and so it's fun to be around a bunch of smart people.  That's it's own reward.  But I also at one point realized, hey, it's not how much money moves through,  it's how much money stays behind.



LEO:  [Laughing]  I haven't learned that yet.



STEVE:  Yeah, yeah.



LEO:  I'm moving a lot of money through.



STEVE:  And so...



LEO:  Not keeping any of it.



STEVE:  And so I realized, yeah, it's really - it's heady to look at all the payables and receivables and look at the big numbers.  But if it just kind of moves on past and you wave at it as it's going by, it's like, well, okay.  That's exciting.  That's a big stream.  But you'd like to fill up your own reservoir sometime, so...



LEO:  Well, but there's - and when you're building a business, revenue gives you more things you can do.  And that's kind of where we're - I feel like we're at the building stage still.



STEVE:  Certainly have clout that way, yes.



LEO:  And so the revenue helps us, you know, improve the studio, add more people.  And as long as adding more people adds more revenue - see, really kind of it's - I feel like it's leveraged what we can do, what I can do personally by having extra - these people are so great.  They help me.  And then also we can play laser tag now.  We have a team.



STEVE:  Well, for me the best thing that ever happened was the Internet because...



LEO:  Yeah.  You can virtualize it.



STEVE:  You know, receivables went away.  I used to have two people who spent all their time just trying to get us paid.  Because we were using big national and in some cases international distributors.  And their contract said "Net 90," but they actually paid about 180 if we were lucky.  So we were waiting half a year to get money from them, and then they'd send back, quote, "damaged," unquote, damaged goods.  I mean, Egghead had a return policy where they'd take back any software.  So people would buy a copy of SpinRite off the shelf and take it home, use it, and then say, well, you know, I think I'm done with it now.  And they'd take it back and say, "I decided I don't want this."  And so, you know, and then it was an opened box, which Egghead had return privileges for.  So it would go back up the stream to the distributor.  And then they would, like, send back huge boxes of destroyed product that it looked like elephants had had a party on them.  And so I thought, okay, there's just got to be a better way.



Well, the Internet happened.  And so by being able to automate this whole process, I've been able to - now I've got two people, Sue and Greg, who handle the accounting, bookkeeping, operations stuff on Sue's side, and dealing with all of our customers, the tech support needs, on Greg's side.  And I just kind of get to move the technology forward.  I just - this is it.  I mean, this is just paradise for me.  And by virtualizing, by shutting down offices - they both work out of offices at their home - I'm able to save some money after all of this.  So it works.



LEO:  Yeah.  You're smart.  You're smart.  I hope I learn this lesson.  I love it because I talk to you and people like Jason Calacanis, who've been there ahead of me.  And I listen with great, you know, great interest to your lessons.



STEVE:  Well, and I'll tell you, it does take some discipline.  I'm approached from time to time, as you might imagine, by people who have really interesting ideas.  They offer seductive alternative lives.  And I think, you know, what I have now is perfect.  Do not mess with perfect.  So I generally politely decline.  I say, ah, well, that really sounds good, but I'm not your guy.



LEO:  Saying no is more important, is a better skill than saying yes.  I agree with you on that one.  I have to learn a little bit of that.  So we've got a Q&A episode today.



STEVE:  We do.



LEO:  Questions from our audience that we're going to answer.



STEVE:  Some amazing news.  Everybody, I'm sure you've had - you've seen it in the news, the news of this new WPA/TKIP hack.



LEO:  Yes.  I really want to know about that because I've talked - like you, whenever that happens, I get all the emails saying, is this true?  Is it safe?  And in the past these cracks have been less dangerous than the headline might imply.  I don't know about this one, though.  We'll find out.



STEVE:  Oh, even more so.  This is so bizarrely theoretical, it's like, okay, just wander off to whatever hotspot you want and don't worry.



LEO:  Okay, good.



STEVE:  Yeah.  And we have a bunch of fun and interesting errata.  And then, of course, our Q&A.



LEO:  So I guess we should start, Steve, with errata.



STEVE:  Well, news.



LEO:  News?  Okay.



STEVE:  We've got not too much.  VMware Workstation was updated to 6.5.3.



LEO:  They had a big conference in San Francisco, so they probably announced it then, yeah?



STEVE:  Yeah, well, this was mostly just - it was, well, the main motivation was probably they had - that they had the libpng problem in their code.  So they updated, you know, we talked about that a few weeks ago.  There was some overflow problems, not surprisingly, in image processing, PNG images in libpng.  They updated internally to 1.2.35 and incorporated that into their 6.5.3.  They also now offer full support for the Ubuntu 9.04 client.



LEO:  Good.



STEVE:  So people who are using that flavor of Linux will be glad that they've got additional support.  And there's also a ton of just other stuff.  As I read through the list of all the other things, it's like, oh, well, that would be handy.  Things like NAT, the NAT translation mode doesn't work on newer Windows clients.  Oh, well, so that - it does now, but it didn't in 6.5.2, which is what I had previously.  So it's like, okay, well, that's handy to have.  And all kinds of other things that affect a smaller subset of their total users.  So definitely worth updating to 6.5.3, which is the current, as of couple days ago, version of VMware Workstation.  Also we've got a new Chrome.  The Chrome browser from Google is now at 2.0.172.43.



LEO:  [Laughing]  2.0.172.43.



STEVE:  Stardate, yes.



LEO:  That's ridiculous.



STEVE:  [Laughing]  What I found most interesting about this is that a severe flaw was found in V8, which is the open-source JavaScript engine that Google has been developing and is excited about that makes Chrome run so fast.  But the problem was there was a way that you could - that JavaScript could be used to access unauthorized memory and also potentially execute code that is in the user's system.  What I loved about it was that it was found and reported by Mozilla security.  And I thought, well, that was nice of the Mozilla people to let Google know, I mean, a competing browser.  Not that Google's - not that Mozilla's in much danger.



LEO:  They use different engines, though; don't they?



STEVE:  Well, in fact I wondered if this meant that maybe Mozilla was taking a look at...



LEO:  WebKit.



STEVE:  ...the V8 engine, thinking, oh, you know, maybe we ought to move that over into Firefox.  Who knows.



LEO:  Coulda had a V8.



STEVE:  [Laughing]  And then there are some other reasons to update Chrome.  There were some flaws found in the xml2 library.  Oh, and the other cool thing is Chrome decided to formally no longer allow MD2 and MD4 hashes, which we know are compromised, in SSL certificates.  So with this update you will not be able, you will simply not...



LEO:  Wow, that's good.



STEVE:  ...be able to connect - yeah, it is - not be able to connect...



LEO:  Do other browsers allow that?



STEVE:  They're still allowing it.



LEO:  Wow.



STEVE:  Yeah, I mean, it would be nice even to have a notification.  But then your typical user, what are they going to do when they get some notice that says, well, the hash this site is using is technically not secure and could be compromised.  We don't know that it is.  We don't think it is.  But then we wouldn't be able to tell if it were.  What's a typical user going to do?  Just their head's going to explode.  So Chrome has just decided to say, no, we're going to go the security route.  And the cool thing is, well, if Chrome had a bigger market share, I think they're about 3 percent right now of market share on the Internet, so still not a huge factor.  But it will certainly put some pressure on sites to update their certificates, if they're still using an MD4 hash.



LEO:  They just started putting out a version for the Mac that's at least somewhat stable.



STEVE:  You know, and I fired up a VM in order to go to Chrome and look at it.  It's so pretty.  It's just...



LEO:  [Laughing]  They have - I don't know if they - they must have this on PC's themes.  Because they have themes on the Mac.  They have, like, grass and all those sorts of different...



STEVE:  I just, you know, I look at it, I go, "That's so pretty."  But I'm not using it.  I'm just...



LEO:  I like Chrome.  It's fast, it's pretty.  But Fire- you know, it's interesting because some people are starting to think that Firefox is the new Internet Explorer, that with 3.5 it started to get a little bogged down; you know?



STEVE:  Oh, you mean - oh, I see.  You mean slowing down and getting...



LEO:  Slowing down, buggy, issues.  And I think that people are looking more and more toward Chrome as an alternative.



STEVE:  It's funny, isn't it, that, I mean, it can happen to anybody.



LEO:  Sure.



STEVE:  We used to have lightweight personal firewalls.  Now look what they've become.  I mean, you dread loading one of those things on your machine.  That's why I can't wait for Microsoft's forthcoming AV solution.  It's like, oh, good, thank you very much.  And we have one really bizarre story.  I just thought this one - I saw this pass by on my radar, it's like, whoa, isn't that odd.  U.S. state offices, typically governors' offices, have been receiving HP laptops they'd never ordered.



LEO:  I wonder from whom?



STEVE:  Isn't that interesting?  In one case, West Virginia's governor, looks like Joe Manchin, received five unasked for, never ordered, HP laptops.



LEO:  Hmm, completely loaded with the latest software.



STEVE:  Well, precisely.  I mean, and what's interesting is this has been - there are other, 10 other instances - four were delivered, six were intercepted - of other government, U.S. government offices spread around the country, just receiving an HP laptop.  Here you go.



LEO:  Wow.



STEVE:  And, I mean, no one at this point - they have not been analyzed.  There's no news of what they contain.



LEO:  But I see the FBI is investigating.



STEVE:  Oh, yeah, yeah.  The FBI is on it because they're thinking, wait a minute, what is the story with this?  And the assumption is that security is now enough of a factor, people are trained not to click on links in email, the idea being that the traditional ways of getting inside the perimeter are no longer succeeding enough, that now people are saying, well, let's just send them a laptop, all set to phone home, and see if somebody who's inside the perimeter, the security perimeter, fires it up; and, if so, that gives us a foothold inside the network.  So isn't that...



LEO:  [Laughing]  That's a trap, somebody said in the chatroom.



STEVE:  It's just amazing.



LEO:  Admiral Ackbar says, "It's a trap."



STEVE:  Don't turn it on.



LEO:  No.



STEVE:  Now, I did, I have to say that when I heard they were HP laptops I was thinking, well, how could you tell if there was any malware installed?



LEO:  There's so much other crap in there.



STEVE:  Oh, my goodness, yes.  I mean, HP is the worst laptop I know of in terms of gunk all being preinstalled.



LEO:  They, like a lot of kind of consumer-grade systems - I think of Gateway - have those background downloader/uploader fix programs running all the time.  So they're always phoning home.



STEVE:  Oh, there's stuff going on.  I mean, and all of the trial ware.  Things are expiring and telling you, well, after your two months of using Betty's Flower Shop program, don't you want to purchase it?  Uh, what?  No.  How do I get this off of here?



LEO:  Now, theoretical question.  Could they reimage the drives, just format it and would be okay?  Or is it possible to hide something?  I guess you could hide something in the keyboards, a keystroke logger, or something in BIOS; right?



STEVE:  Yeah, that's a very good point.  You could go, if you're physically delivering a computer, that's a very good point, Leo, you could do all kinds of extra sneaky things to the hardware that goes beyond what your typical drive-by malware download could do.  That seems like, you know, a little overly sophisticated.  But, I mean, yeah, for example, you could have an extra radio.



LEO:  A transmitter, yeah.



STEVE:  An extra WiFi system or something.  Anything could be in there.  So it's definitely creepy.  And I would argue probably that people who don't order equipment and receive stuff should be skeptical.  So I thought this was really interesting.  Also it appears, and I haven't looked at it closely yet, but that there's a lot more information has surfaced since we mentioned it tentatively last week.  I was a little skeptical when only the Register.co.uk had talked about this crack of GSM, the cell phone network technology.  That's the topic for next week.  We will do - I said next week's TID, which is Topic In Depth.



LEO:  Oh, good.  I like that.  That's a new - that's our new - and now [vocal fanfare], the Topic In Depth.  It's like CNN.  I'll get what's-his-name to record something for us.



STEVE:  Sort of a nice announcement.



LEO:  This is Topic In Depth.



STEVE:  Okay.  But...



LEO:  We're going to talk about ESM cracking?



STEVE:  GSM, next week, cracking GSM, which of course is a big deal because it's one of the encrypted technologies which we're using for cell phones, the other one being CDMA.  And I have said a number of times that I was not satisfied with the encryption of cell phone technology.  If you search back in our transcripts you'll find me having said that a number of times.  And whoops, sure enough, here it is.  Apparently if you - someone with a laptop and a special receiver is able to do what we imagine only the NSA previous to this could do.  And they certainly have been able to for some time because the technology just wasn't that good.  So we will talk about that next week.



The big, big, big issue that has happened between last week and this week, which so many people wrote in about, is what happened with WPA, that is, the traditional WiFi technology.  Remember that WPA has two different types of encryption.  It has the old-style TKIP encryption based on the RC4 cipher, and then also state-of-the-art encryption using the AES cipher.  We did a whole podcast a while back about an exploit of the TKIP encryption which allowed a 15-minute-long decryption of a short packet if the access point supported quality of service, QoS.  And the idea was that QoS, a quality of service access point, had multiple packet queues.  And the reason this took 15 minutes was that, if you upset the access point with wrong guesses too often, that is, more than two within a certain time window, like a minute, then the access point would decide, oh, I'm being hacked, and it would shut down and rekey everybody.  Which would cause you to lose the work you had done up to that point.  So you had to - you had to make sure you didn't guess twice within a one-minute sliding window.  And so that's why it took 15 minutes, because you needed at most 15 or 16 guesses which would probably be wrong in order to perform this particular attack.



So the big news of this new attack is you - and what the authors state is that it is no longer necessary to have quality of service support on the access point.  And it's like, okay, well, so what else?  Well, it turns out that what they've done is even sort of more theoretical because what it requires is a condition of the radio reception, which seems unlikely to occur without, like, some tremendous amount of work, which is that, strangely enough, the access point and the user who you're attacking cannot be within radio range of each other.



LEO:  [Laughing]  Wait a minute.



STEVE:  It's like, okay.  So the attacker has to literally be a man in the middle, meaning their radio has to be the link between the access point and the user.



LEO:  So you're posing as the user.



STEVE:  So, well, I mean, but physically, I mean, physically the radios of the two endpoints, the access point and the user, cannot be within range of each other, or this won't work.  So the attacker is literally the intermediary radio link passing the traffic, acting as a relay, passing the traffic back and forth.  But this doesn't work if the endpoints are within radio range.  So it's like, okay, fine.  So now what?



So basically this is essentially the same attack, but you're using the fact that the endpoints can't hear each other, radio-wise, to obtain the equivalent of what you got with the quality of service queues, that is to say there's - and if listeners have questions and really want to know about this, we did discuss the way RC4 and WEP works when we talked about how badly broken WEP had become.  One of the problems with WEP, with W-E-P, Wired Equivalent Privacy, is that's the original WiFi standard that you just really don't want to use anymore because it's over as far as its security goes because it was so poorly designed in the beginning.  There's something called an IV, the Initialization Vector, which typically is just a counter.  And every packet which is enciphered, that is, encrypted, uses the next larger IV, initialization vector.  And that's required because the way the encryption works, it's not secure unless you have this initialization vector which is used sort of to seed the encryption for every single packet.



Well, one of the things that WEP never did was to insist on initialization vectors incrementing.  That is, you could take a packet and hack it, and meanwhile the access point is spitting out more packets with incrementing initialization vectors.  So you could then take the packet you had intercepted and decrypt it and then retransmit it to the access point, which even though its initialization vector was now old and technically expired, the access point didn't enforce the currency of initialization vectors.  Well, that was fixed in WPA.  So one of the nice things about WPA is that no access point will accept an initialization vector that is older than any that it has already accepted.  So the initialization vectors must be monotonically increasing in value over time.



LEO:  Have to be in sequence.



STEVE:  They have to be in sequence, thank you.  That says it more easily.



LEO:  Or monotonically in time.



STEVE:  An out-of-sequence initialization vector is just ignored.  It's thrown away.  It's like, okay, well, we're not sure where this came from, but we're ignoring it.  So the multiple queues in a quality of service supporting access point have independent initialization vectors.  And so you're able to use one of the queues that's, like, way behind in order to play games with the encryption and the key, which is uniform among all of the queues.  So that - so the fact that you had multiple queues meant that you had desynchronized initialization vectors because they were - these initialization vector counters were per queue.



Okay.  So that was the wedge which the first group cleverly exploited.  Now this newer approach says, okay, if we're literally the man in the middle from a radio link standpoint, then we're not passively - we're not passively listening.  We're able to get a packet and mess with it before we send it on, meaning that the other end hasn't seen the larger initialization vector yet.  So they're able to literally, to use the fact that they have sort of preemptive access to the traffic in order to perform the exploit.



The problem is that after all of this you still have nothing any more worrisome than what we had before, which is that you could only decrypt very short packets where you know most of the content, that is, you know what the plaintext will be.  Well, that pretty much limits you to ARP packets.  And in their paper they only talk about ARP exploits.  And what worried people was that the title was "Useful Decryption in Less Than a Minute."  Well, 37 percent, I think it's 36.9 percent of the packets could be decrypted in about a minute because of some optimizations they found.  For example, they were able to nail down some other bytes in the ARP packet as a consequence of knowing the IP of the access point, since they have to be a member of the access point to be doing this radio traffic transfer.



So they did some clever things.  But all you end up being able to do is spoof a single very short ARP packet in that length of time because you already know most of the data.  You do not - and this is the critical part - you do not get the key.  This doesn't crack the WEP key - or, sorry, the WPA key.  It only allows you to determine on, for a given short packet, you are able to determine the cipher bitstream which allows you to basically change the ARP packet to something else.  Oh, and during this time the other end is blacked out.  That is, you can't forward that packet while you're doing it.



So they've got this other fancy business where normal-sized packets that are carrying non-ARP payload, they have to let - they have to, like, bridge those through to keep the user from knowing what's going on while they suspend the ARP packet for a minute.  So, I mean, there's all these criteria, and the fact that they have to be out of radio range from each other.  That is, the endpoint that you're hacking can't be within radio range of the access point.  They have to rely on you to be the forwarder.  So it's extremely sort of theoretical and okay, good to know, but it doesn't mean anybody has to run away screaming and worrying that WPA has been hacked.



The lesson from this is what we've seen time and again - and I'm sure listeners, long-term listeners of the podcast have seen this - and that is that, as something begins to get weakened, additional sort of chinks are found in its armor.  So this is a reason to move from the TKIP cipher, which is sometimes referred to as WPA, over to the use of AES, sometimes referred to as WPA2, although that's really not an official designation, as we've mentioned when we've talked about this stuff before.



So nothing big to worry about, in my opinion.  But further pressure on abandoning the RC4 cipher, because being an XOR-based cipher it does allow the so-called key stream to be reverse engineered.  For short packets we're beginning to see this more and more.  Who knows what's next?  Better just to be away from it in case anybody comes up with something really bad.



LEO:  And just to reiterate, it's the same thing we said last time:  Use AES.



STEVE:  Yeah.



LEO:  Which I have already done on all my WPA systems.



STEVE:  Yeah.  The only reason I could imagine someone might not is if they had some piece of equipment which didn't support AES, and they were saying, well, okay, TKIP is all I can really use because I have to have this piece of equipment on my network.  And I would say, okay, just recognize that it's not as secure.  It still seems pretty good.  But it's not clear what we're going to have come along tomorrow.  Certainly as long as anything that happens is public, we'll let our listeners know.  But, yes, use AES unless you really can't.  And maybe even consider give any devices that can't use AES their own access point running TKIP so that at least they're not part of the same network.



LEO:  That's what I did when I had to use WEP for some older hardware, just have a kind of standalone WEP router out there.



STEVE:  Yup.  And again, if you can, isolate it from your internal network because you don't want somebody to crack that and then have access to your LAN.



LEO:  Right.  If I put that outside a WPA router, in other words, have the WPA/AES router be my main router, and then attached to it have a WEP router, does that isolate it?  Or a TKIP router?  Does that isolate it?



STEVE:  I would, if you had one additional router...



LEO:  You need three to do this.



STEVE:  Yeah.  Because of ARP spoofing problems.  You don't want to let somebody be able to spoof ARP in order to intercept all of your inner network's traffic, which they would be able to do if they were able to see ARP traffic.  So routers do not transit ARP traffic.  They don't bridge ARP.  They don't have to because they're maintaining separate networks on either side.  So that's the one thing you would need to do is to have one more router between that and your WEP, your untrusted WiFi, because of the possibility of ARP spoofing.



LEO:  And is it, on your base station, your access point, is it usually pretty clear which is AES and which is TKIP?  Does it say AES?



STEVE:  Yeah [tentatively].  The problem is it's really fuzzy nomenclature.  In fact, we talked about a router that would allow both, it was TKIP plus AES, and then there was also just an AES.  Well, that's what you'd want to use unless for some reason you needed both.  And the idea was, it's like, hey, a feature that the router had was that you could use either.  Well, you probably don't want that.  You want to stay away from TKIP.  So unfortunately there just is - the nomenclature used is not standardized, and it is fuzzy.  But most users, I think, if you look at the settings, and maybe you look at the corresponding help guide, you just want - you want the strongest you can get.  But if it allows you to have both, you do not - you want to stay away from TKIP and not have that also.



LEO:  Got it.



STEVE:  In errata, there's been some interesting news about ultracapacitors.  We talked, an episode that many of our listeners have said they enjoyed as one of our rare sort of off-topic episodes, we talked about the whole idea, which fascinated me from a physics standpoint, about the company EEStor, I think they're down in Texas, who have a technology that they've been working on for a number of years that's got some impressive venture capital folks behind it, venture capital folks who don't tend to make mistakes.  It sort of leaked out that they had let, that EEStor had let a contract out to a company called Polarity, and that Polarity had been given the job of using Polarity's high voltage-to-low voltage converter technology to be integrated into the so-called EESU, which is the name for EEStor's capacitor-based battery.



Checking out, I did a little browsing around, and Polarity, the company, looks very legitimate.  Their little news page says that in '09 they were awarded follow-on production contract for the Navy's SPS-49 radar upgrade.  Also in '09 they were awarded development contract for next-generation TWT Test Sets for Teledyne MEC, whatever that is.  And then on their little news page it says 2009 awarded contract from EEStor to integrate Polarity's high-power HV to LV, which is high voltage to low voltage, converter into EEStor's EESU, that will be used in Zenn Motor Company's small to medium-sized electric car.



And then there was a - they were also awarded a contract, a Varian contract for high-powered solid-state modulators and so forth.  So look into the company, it looks very real.  And associated with some comments that were made is the assumption that in September or October there's going to be a big announcement.  So we may be close to seeing one of these things actually working, which would just be spectacular, in my opinion.



We'll just remind our users, or our listeners, that the whole technology here, the idea is that you have a capacitor that is extremely large in terms of its capacitance, and at the same time is able to store a tremendously high voltage without it shorting out or breaking down because the amount of power that is stored goes up with the square of the voltage that the capacitors can be charged to.  So you need both extremely high voltage and high capacity.  And potentially we end up with a tremendous breakthrough in energy storage.  Which, you know, could affect all of our lives, since we're all carrying things around now that have batteries, and batteries are annoying in so many different ways.



LEO:  So this is exciting.  You think maybe in the next couple of months we're going to see something.



STEVE:  I think we're going to see something, yeah.  I mean, I glommed onto this originally, as we all know, because it was like, ooh, this is, I mean, this is like the answer, if they can build these.  And we may be close to seeing production of this, which would be great.



One other little blurb I got a kick out of was someone pointed me, a friend actually, to - we've talked about RISCs and CISCs, RISCs being Reduced Instruction Set Computers and CISCs being Complex Instruction Set Computers.  It turns out there's such a thing called an OISC.



LEO:  What's that?



STEVE:  Thank you, Leo.  That was your cue.



LEO:  [Laughing]  Wait a minute.  Let me think if I can figure that out.  OISC.  Well, we know it's Instruction Set Computer.  Origami?  Optional?  I don't know.  What?



STEVE:  I love it.  It's One Instruction Set Computer.



LEO:  Well, that's about as reduced as you can get.



STEVE:  And what I love about it is, if you have one instruction, you don't need an opcode.



LEO:  Yes.  Just keep doing what you're doing.  How can you have a One Instruction Set Computer?



STEVE:  And it's Turing complete.



LEO:  No, it's not.



STEVE:  Remember we talked about the voting machine last week and how they had come up with a whole bunch of gadgets by using the code at the end of existing subroutines in order to execute their own code, and that they had enough of them that they had created a Turing complete computer such that they could do anything any other computer could do.  Well, it turns out that you can have a one-instruction computer which is Turing complete.



LEO:  No.



STEVE:  There are various choices of instruction.  But the typical one, the instruction is subtract and conditional branch.  So it's a three...



LEO:  So that's two instructions, though.



STEVE:  Well, no, no, no.  It's one instruction.  So what it does is, you have three parameters.



LEO:  Okay.



STEVE:  It subtracts the second parameter from the first.  And then if the value is negative, it branches to where the third - to the address of the third parameter.  So that's the instruction.  Subtract and conditional branch.  And so I see what you mean.  Technically you could call it maybe two instructions.



LEO:  It's one big instruction.



STEVE:  It's one big instruction.



LEO:  Okay.



STEVE:  And the way you solve, I thought - there are several clever things about this.  The way you solve the, well, what if I don't want to branch, is, well, the branch target is the next instruction.  So if you don't want to branch, you just say, well, the branch is the following instruction.



LEO:  Keep going.



STEVE:  So whether it branches or not, it ends up at the next instruction.



LEO:  But it can't really do any work.



STEVE:  Well, it actually does.  It's all - you can, from that one instruction, you can synthesize anything.



LEO:  Really.



STEVE:  For example, because think about it, like you need subtraction as opposed to addition because, if you subtract in the right way, that is equivalent to addition.  And you can perform logical operations.  You can basically get this to do everything you want.  For anyone who's curious, Wikipedia has a great page on OISC computers.  People have built them.  Someone actually built one out of hardware and programmed it to do things.  And there's emulators and simulators and - so this is not a brand new concept.  It's something that's been around for a while.  I just got a big kick out of it.  The one-instruction computer.  And mostly what I loved is, like, well, you don't need an opcode.  Starting off, right off the bat, no opcode because you don't need to tell it which instruction to execute.  It executes the only one it's got, over and over and over.



LEO:  Neat.



STEVE:  And I mentioned, we were talking about 3D technology, and a whole bunch of users wrote in because I was talking about how, well, one way or another you need to give each of our eyes a separate image.  I talked about the red-green glasses and the notion of LCD, high-speed LCD shutters flickering.  And of course the other technology is polarized glasses, where - and I don't know, probably people who listen to this podcast have messed around with traditional polarized glasses where, you know, as you rotate the lens against the other one, you can see it, like, black out and then come back?  Well, those are linearly polarized glasses.



So one approach that had been used was that a special screen is needed, a silverized screen which will not scrambled the polarization as it reflects the projected light back to the viewer.  So you have a projector which puts out the two images that are bound for people's left and right eyes with polarized light that is 90 degrees off axis from each other, like one is vertically polarized; the other is horizontally polarized.  And the glasses are the same.  The problem with that is you have to hold your head exactly...



LEO:  Straight.



STEVE:  ...exactly straight, exactly.



LEO:  Yeah.



STEVE:  Otherwise, as you tilt your head, you see bleed from the wrong polarity.



LEO:  Although I imagine it's self-correcting because it starts to look weird as your head tilts.  So you...



STEVE:  Yes.  And in fact what has been found is that people quickly learn, I mean, as they turn their head they go, oh, whoops, you know, and so they quickly adapt.  Okay, now, here's the part that hurts my head, is that I can understand, the idea of vertical and horizontal polarization.  I mean, I've, in the old days of Polaroid sunglasses, I would take two lenses and rotate them, and you could see how it would black out, and then you'd rotate them 90 degrees, and now you can see through; okay?  There's a different kind of polarization called "circular" polarization.  And...



LEO:  Yeah.  I have that in filters, you know, in camera filters.  You have circularly polarized lenses.



STEVE:  Okay.  Well, you can have clockwise circular...



LEO:  Right.



STEVE:  ...polarization and counterclockwise circular polarization.  And they block each other out.  Which blows my mind.  Because the way the current 3D technology works is there's a digital projector with a special thing in front of it which at many times a second, 144 times per second, so also many times per frame that it's transmitting, this thing is flipping back and forth the polarization, the circular polarization between clockwise and counterclockwise at the same time that the image is being changed.



So this light goes down and hits the silvered screen, which has to have a special screen.  You can't use the old-style, glass-beaded screen because those screens do not respect the polarization.  They scramble the polarization upon reflection.  So you have to have a special screen.  Then what comes back to the user is the two separate images, circularly polarized with different spins, however that works.  And they're wearing glasses with the matching circular polarized filters.



LEO:  I love it.



STEVE:  So now they can turn their heads, and it doesn't matter.  And I cannot conceptually get how that works.  But it does.



LEO:  You know, photographers are familiar with this because you can buy filters that are circularly polarized filters.  And I've even seen demos, you can look on YouTube, where somebody has a polarized filter on a screen, and then as - and one of these filters, puts it in front of a camera and rotates it, and it darkens or lightens, depending on the rotation.  So...



STEVE:  Well, but it wouldn't.  That's the problem.  What you described, I'm familiar with, a linearly polarized filter.  But this circularly polarized filter wouldn't lighten or darken with rotation.



LEO:  Well, it only does if it's canceling waves.  So if you have a - it takes two filters; right?  So it's canceling because, as the rotation goes, it's canceling the other filter.  So you're putting them out of sync.



STEVE:  I don't know.  This sounds to me like it would not change as you rotate the filter.



LEO:  Okay.  You're right.  Because now that I think, it'd be a linearly polarized filter that would because it would go out of sync with the waves.



STEVE:  Yes.  And so this is somehow all on and all off.  It wants circularly polarized clockwise light, and all of the counterclockwise light it blocks out.



LEO:  Yup.



STEVE:  Like, that's just so cool.  But again, I can't get my brain around how it does that.  But, I mean, I can't think of an analogy, I guess, that fits.



LEO:  I think a circular polarizer on a camera is different.  You're right.  I think it's got linear polarization in it.



STEVE:  Two last things in our errata.  There's news about one of my favorite sci-fi authors, our friend Michael McCollum at Scifi-AZ.com, whose books I love.  Leo, I respect your decision not to read unfinished multivolume series because it's extremely frustrating.



LEO:  It's so hard.



STEVE:  Oh, and especially, for example, when we did "Pandora's Star," and talk about a cliffhanger, I mean, you were just left thinking, oh, my god, when are we going to get Part 2?  And of course none of Peter - I don't think Peter Hamilton's ever written a short book.  So, you know, a huge investment.  And then you're left hanging.  Well, the news is that Michael will have the proof copy of the final book in the Gibraltar Series to me on Saturday.  He sent me email, I think it was Friday of last week.  And he said, "Hey, Steve, I've heard through the podcast listeners that you're still interested in having a look at editing this text when I'm finished with it."  And remember that I had mentioned a couple weeks ago that one of our listeners had noted that Michael had updated his page on his website, saying a few months from now.  Well, he said that his reread went much faster than expected.  And so upon hearing that on Friday, I said, "Yes, I'm absolutely interested in editing book three.  I'd like to get a copy of book two for the Kindle," because I know that his site now offers eBooks in virtually every format ever known.  I mean, it's just amazing how many different formats.  And he said, "Well, I've got news.  It's on Amazon."



LEO:  Wow.



STEVE:  And so he said, "I'd be happy to reimburse you for the cost.  But you can get it instantly for your Kindle from Amazon."  And I said, "I don't want reimbursement.  I'm happy to do this."  So I ordered it from Amazon and - both the first and second book, which were instantly delivered.



Then I learned something very cool, which I had never had occasion to learn.  It only affects people who have multiple Kindles on a single account.  But I've always sort of wondered about the synchronized deal.  And it really works beautifully.  Because what I learned is, I can read on my stair climber, which is a breakthrough.  So I have the DX, the big-screen Kindle, rubber-banded now to my stair climber's console, which I can no longer see.  It covers it up, but I really don't need to see.  And so I've been having my hour-plus-long workouts just gleefully reading.  And so this is going to allow me to get to the Kim Stanley Robinson, is that the guy, Kim Stanley - the Mars...



LEO:  Yes, the Mars - Red, Blue, and "Green Mars," yeah.



STEVE:  Yes.  It'll allow me, because now I have time to read because instead of...



LEO:  On the stair climber.



STEVE:  On the stair climber.  And what's cool is that Amazon beautifully synchronizes.  They don't have any problem with the same novel being loaded into multiple Kindles on a single account.



LEO:  Oh, that's good to know.  And when you get to page X on one, the other jumps to page X.



STEVE:  Well, so what happens is, I'll be reading along for 66 minutes, typically, or plus that, because I normally like to finish whatever aspect I'm in on the stair climber, and I just stop.  Then I take my little Kindle, K2, to dinner with me.  When I turn it on, up pops a little, I mean, all by itself, it pops up a notice, says, oh, you are currently at the following location in Steve's DX Kindle.



LEO:  That's neat.



STEVE:  Would you like to move there in this Kindle?  And so, I mean, so they're formally saying we have no problem with a person having multiple Kindles and the same books on multiple Kindles, which I never really...



LEO:  I can't see why they would.



STEVE:  Yeah.



LEO:  I mean, it's just more money for them.  But, no, the iPhone app does that, too.  And so I kind of knew this because they have a Kindle iPhone app, and it will also synchronize with your Kindle standalone.  So I guess they're just extending that feature across all Kindle platforms.  That makes sense, yeah.



STEVE:  Yeah, it's very neat.  So I did want to tell our listeners, anyone who has enjoyed Michael's books, anyone who is waiting for Book 3, I don't know from the time I'm through with it how long it'll take him to publish it electronically.  I wouldn't think very long.  If anyone, like Leo, has been abstaining from getting into the Gibraltar series for fear that they'd hit the end of the books that were in print or available, yet - and then not have the story ended, fear not because I don't think it's more than a few weeks before number three is done.  And, oh.  And so I did read number two again to sort of remember where we had left our hero.



LEO:  That's my problem.  That's my problem.  I have to reread it to catch up.



STEVE:  Yes.  And so I reread number one when number two came out.  And I was tempted to reread them both, but I wasn't sure if I had time.  Turns out I did have time.  But it's just a - I will say again, the Gibraltar series is an intriguing plot.  I just - I like his work.  It's not insanely long and infinitely detailed the way Peter Hamilton's are, where you end up with a massively complex world you're holding in your head.  Michael's tends to be more directed toward a plot line.  So it's a little thin on unnecessary characterization and unnecessary detail, but it's hard sci-fi at its best.



I'm rereading "The Sails of Tau Ceti" at the moment because I just - now I have to wait for Book 3 to get ready.  And I was just - I was loving his description of light sails and the use of light sails for braking and how we use electrostatic fields to gather the hydrogen, interstellar hydrogen and funnel it in.  And, I mean, it's just - it's great sci-fi.  So I'm looking forward to the Kim Stanley Robinson stuff because you have said that it's very much that way, too.



LEO:  Yeah, oh, yeah, yeah.  It's all about technology and a lot of hard science in it.  I love hard sci-fi.



STEVE:  And lastly, I just got the ThinkGeek email today, and I always just browse through it to see if there's anything that grabs me.  Well, they were announcing a bunch of new T-shirts.  And ThinkGeek.com has a bunch of T-shirts.  I ordered some of this one that I just loved.  And I thought I've got to tell our listeners because I know there are geeks like us who are kind of curmudgeon-y, who for this T-shirt, there's just never been a more perfect T-shirt.  It's black, and it has one word, in big, uppercase letters with a period, in white.  The word is "NO."



LEO:  We were just talking about that at the beginning of the show, learning to say no.



STEVE:  Just N-O.



LEO:  No.



STEVE:  I just love a black T-shirt that just says no, period.



LEO:  No.  I will not.



STEVE:  Just don't, you know...



LEO:  Don't ask me.



STEVE:  And people, of course, will ask - it'll be a conversation starter, too, because people will say, "No what?"  Ask me a question.



LEO:  Anything.  No anything.



STEVE:  Anyway, I loved it, so.



LEO:  I'm going to have to find that one.  I see a "No Comment."  I see "There's no place like 127.0.0.1," which is one of my favorites.



STEVE:  Yup, that's an old one.



LEO:  "No, I will not fix your computer."  But one that just says no, no to everything.



STEVE:  It's just perfect.



LEO:  They're great.  I love them, really nice people.



STEVE:  Yeah.



LEO:  Do you want to do a SpinRite letter or...



STEVE:  I don't see the need.  Everyone listening...



LEO:  Just buy it.



STEVE:  ...knows that SpinRite solves problems, fixes drives.  A number of our Q&A people mention SpinRite appreciatively.  So I thought, ah, that's fine.



LEO:  Oh, I found it.  I'm going to put a link in the show notes.



STEVE:  N-O.  Isn't it perfect?



LEO:  They call it "the shirt of ultimate disambiguation" [laughing].  Yes, that's true.  There's just no ambiguity.



STEVE:  It's big.  It's just NO.



LEO:  No.



STEVE:  I just think it's perfect.  It's a perfect geek shirt.



LEO:  All right, Steve.  Are you ready?



STEVE:  Ready.



LEO:  For questions from the audience [trumpeting].  Starting with Craig in Chicago, who is sounding and seeming rather desperate.  He says:  Hi, Steve.  I sent this a few times now that iPig is no longer offering its service, and I need to use my computer in hotspots.  I guess iPig was a hotspot VPN type service.  Listening to you and Leo, I know I need a VPN, but I can't afford a server.  I'm not up to speed on running it.  I'm waiting for your VPN service, Steve.



But in the meantime I need a service.  I came across this:  HotspotShield.com.  They offer SSL connect like iPig, but I only trust it if you, Steve, give it an okay.  I've been a paid user of SpinRite since the mid-'80s.  It's been a lifesaver.  That's a long time.  It's been a lifesaver.  It's 25 years.  Please tell us if using Hotspot Shield is okay, and then at least I can relax until your VPN is out.  And of course I can't wait until you're offering it.  Thanks; and Leo, thanks for your great service.  Please respond to this.  I think there's others needing a VPN solution.  Hotspot Shield.  Have you - are you familiar with these guys?



STEVE:  Well, first of all, Craig, I hope you're listening to this because, Leo, I don't know how many times he has submitted this.



LEO:  Oh, dear.



STEVE:  But every time I look there's this message from Craig.  And he hasn't provided me with his email address, so I haven't been able to say, okay, message received, we're going to take care of this.  And so it's just over and over and over.  So Craig, got it.  Here's your answer.



I don't know them, so I went to take a look.  And the first thing I see is some raves from CNN and PC Mag and a couple other publications, and say, okay, well, that's something.  And all there is is just press this to download.  It's like, okay, wait a minute, what's - who's this company?



LEO:  Press this to download.



STEVE:  Why is this a free service?  So down at the bottom is AnchorFree.  So I go to AnchorFree and find AnchorFree.  And it's like, okay, here's a little more information.  This is where this Hotspot Shield is coming from.  And poke around a little bit.  And then I sort of see, okay, somehow this is advertiser supported.



LEO:  Oh, boy.



STEVE:  Hmm.  How does that work?  So then I go to the advertiser page.  And I will share with our listeners, because this is a perfect example of a little bit of simple security research anyone can do.  And so the headline says, "Advertise on the AnchorFree Media Network."



LEO:  No no no no no no no.



STEVE:  "Advertise to AnchorFree users."  Okay.  "Advertise to AnchorFree users who are always connected while on the go.  They seek out WiFi, shop for the latest technologies, use VoIP for making calls, and look for mobile connectivity, all while using AnchorFree for security and privacy" - [clearing throat] privacy, privacy - "while surfing the 'Net."



LEO:  And you can have access to them.



STEVE:  Oh, exactly.



LEO:  And they're yours.



STEVE:  Oh, wait, it gets better.  It gets better.  This is just the warm-up.  They are - because we've got contextual advertising happening here in a minute.  We know what that means.  "They are today's broadband ber-user, and we can touch them."



LEO:  Oh, dear.



STEVE:  Not only, yeah, touch them whether...



LEO:  Don't touch me.



STEVE:  ...they want to be touched there or not.



LEO:  Don't touch me there.



STEVE:  Don't touch me there.  "Not only that, we offer something truly defining in online advertising.  We provide our users security and privacy while enabling brands to target contextually relevant advertising campaigns to some of the most tech-savvy users online.  AnchorFree's technology enables ad placements across any one or more of the domains that are visited by our users."



Okay.  That's enough of this.  I mean, I've answered my question.  Our listeners now understand that what this means is that what you do and where you go is being tracked and monitored and contextualized so that they can choose - apparently they're doing interstitial, actually it somewhere does talk about interstitial advertising.  So they're monitoring the websites you visit, and they are changing in some fashion the content of the pages you download to insert their own ads.  And that's why this "VPN," unquote, solution is free.  That's their model for making it free.  So...



LEO:  Now, I think, though, to be fair, we do a lot of ad-supported free stuff.  Our stuff is ad-supported free.  They do disclose; right?



STEVE:  I think it's probably very clear that anyone using this service...



LEO:  Is going to see ads.



STEVE:  ...will quickly realize that this is what they're doing.  So you're right.  My outrage is, I guess, at the idea that anything is changing the data in my link.  That is, in order to be displaying their ads from their advertisers, then my web browsing is being filtered by them.  So, yes, Leo, I think it's entirely fair to say, hey, but the service is free.  So that's...



LEO:  Right.  I mean, Google's free.  There's a lot of free stuff.



STEVE:  Yes.



LEO:  That is ad supported.  So...



STEVE:  Yes.



LEO:  I guess the most important thing is disclosure, a strong privacy policy that you can read, and it is - this is something I wish...



STEVE:  And I have to say, I did read the fine print on their privacy policy, and it is entirely one-sided.  I mean...



LEO:  Yeah.  Well, there you go.



STEVE:  In fact, it didn't even seem to really apply to them that much.  It's like they got somebody else's privacy policy.



LEO:  And that's the other thing.  An independent third party auditing it would be nice, like a trustee or somebody.  I mean, we're going to be - I think more and more you're going to see this kind of thing.  I mean, this is a model for all broadcasting.  It's ad-supported free broadcasting.  And as it migrates to the Internet, I mean, we obviously don't collect any information about our users.  It would be hard for us to do so, and I certainly have no desire to do so.  But I can see, you know, I can see that that's happening.  So in this case you're saying stay away.



STEVE:  Well, no.  I guess I'm saying Craig wanted my approval, and I can't give it to a VPN product which is doing this.



LEO:  Right.



STEVE:  I guess I would, if it were some sort of a - I mean, to me a VPN almost seems sacrosanct.  It's like...



LEO:  I agree, yeah.



STEVE:  It's like, "Do not mess with my data."  And here's a company that says, "We're messing with your data."  You're using a VPN.  We're securing you until you get to our servers.  So we are securing your hotspot connection through an SSL link.  We understand that technology.  That's probably bulletproof.  But once we have your data, and we've decrypted it, we're going to modify it to suit our needs in return for the service that we're providing you.  And to me it's like, eh, don't think I like that so much.



LEO:  So no approval.



STEVE:  Yeah.



LEO:  No seal of approval.



STEVE:  No.  There are - there's HotSpotVPN.  That's a service that we know and like.  It's not free, but it's not expensive.  And whereas iPig was free, this HotSpotVPN is not free, but very good.  It's based on the OpenVPN client and server technology.  It's one we've looked at and known about for years.  So if someone wants something to use, HotSpotVPN is a service that we've looked at and that is not very expensive.  And we've talked about it in the past.  You could go to - if you went to GRC, the Security Now! page, and did a search for HotSpotVPN, search for that string, you'll find that we've mentioned it and talked about it in a great deal of detail in the past.



LEO:  Yeah.  And both you and I use it.



STEVE:  Have.



LEO:  Or have, yeah.  I don't travel anymore.  I don't need it.



STEVE:  Right.



LEO:  Question number two, Flash cookies from Bob Carneim in Oak Ridge, Tennessee:  Hi, guys.  I try to stay ahead of the curve.  I've been deleting Flash cookies for, well, probably a couple of years now using the Advanced settings panel of the Flash plug-in.  And you can do that if you go to any Flash video, YouTube, for instance.  Right-click on it, select Settings, click the Advanced tab, and you can see right there you can modify that.  He says:  But what's next?  What tracking method is out there I don't know about yet?  What comes after Flash cookies?



STEVE:  Well, I just sort of liked the question because it evidenced a maturity of sort of recognition that, if it's not one thing, it's another.  I mean, we've gone from browser cookies, now there's Flash cookies.  Of course the problem is that we're - over in the Internet Explorer world, we know that ActiveX controls are provided for all kinds of purposes and could easily have their own tracking technology embedded in.  In fact, there is something called user persistence objects, or something like that.  It's something I've got on my list of tracking technologies to track down and haven't yet.  But there very well may be other things coming along.



My hope is that the outrage caused by this kind of undisclosed opt-out approach - we know, for example, when we were talking about the report that came out a few weeks back, the researchers, I think they were at UC Berkeley, who noted that more than half of the most popular sites on the Internet were now using Flash cookies because browser cookies had proven too easy to disable.  So they were being deliberately sneaky and using something else to hold onto people.



Now, you could also argue that, for example, a bank wants to be able to maintain log-in information, and that users might naively disable their browser cookies and then no longer be able to use the banking site.  So the banking site is just, like, trying to help users to have an experience that they need because they have to have cookies enabled in order to use the site.  And they get, like, more tech support problems because people have disabled cookies, and now the site doesn't work.  Well, it's like, okay, I mean, there's a dilemma.  There's tension between what users want and what the web server-side services want.  But this is all sort of part of the immaturity of this technology.



What I hope is happening is that our legislators are beginning to wake up to this issue, and there's signs that they are, such that we'll be protected legally from whatever comes next by having some sort of dialogue where what's going on is explained to us.  The Flash problem is that it's something no one expects.  It's sort of out of the blue.  When you hear about Flash also spying on you, it's like, uh, what?  What are you talking about?  I turned cookies off.  No, you didn't turn Flash cookies off.  Those are a whole different cookie.



LEO:  It's a whole different kind of cookie.



STEVE:  Whole different kind of cookie.



LEO:  They're always working.  I mean, you know, you're exactly right.  You know they're working on something.  They're always going to be working on something.



STEVE:  Yeah.



LEO:  You know, this is - and again, I mean, I would just say that there are good reasons to - my bank wants to preserve information about me so I don't have to always jump through a lot of hoops to log in.  You've used this computer before?  Okay.  We'll let you get in.



STEVE:  Right.  And it's funny, too, because the sad thing might be that we wouldn't have a unified solution.  That is, it might be that a bank would be reduced to requiring their own plug-in in order - that would be run by your browser in order to provide static state information for your browsing session.  Well, that would be sad because your bank would need one, or all of your banks would need one.  Then eBay would need one, and Amazon would need one, and you'd end up with this big mess of individual plug-ins that your browser ends up lugging around because we were never able to agree upon...



LEO:  Right, right.



STEVE:  ...a clean, uniform, opt-in solution.  So instead you were opting in to individual plug-ins, which just was causing a real problem.  And it would be sad if that's where we end up with.  But I could see us heading there.



LEO:  Yeah.  Yeah, we need some mechanism.



STEVE:  Yes.



LEO:  Not completely unreasonable to have something that we can do.



STEVE:  No, it's absolutely required because, as we know, browsing is a stateless act.  You ask for this page, and then that's the last the server knows about you.  You then click on a link, well, it needs to know that that's you clicking on the link, not somebody else clicking on the link.  And there's no persistent connection.  Normally it's a stateless event.  So something has to provide some state information on a per-browser page transaction basis.  So cookies used to do that.  Flash cookies are doing that now.  But we're incrementally disabling these things, which is going to end up causing a problem for the very real need we have to maintain state.



I mean, I like the fact now that I've got cookies flushing in Firefox, and a simple little cookie manager where I just say, no, the site I'm on, eBay or Amazon or whatever, where I've logged in, I want this site to be able to leave persistent cookies so that when I come back the next day it says, oh, Steve, hi, just log in anyway to make sure that it's still you, not somebody else using your machine, but we assume it is you.  And, for example, with eBay you can say keep me logged in for all day, in which case you're able to use it without having to continually reverify who you are.



LEO:  Question three from Bill Barnes in Charlotte.  I guess that's Charlotte, North Carolina.  He says:  I'm wondering about punching holes in the wall.  I frequently need to get to a computer from the Internet.  Okay.  I figure, all right, I know who needs access, I'll let them in.  Then I open a port in my router, point it at one computer, and open the same port in the computer's firewall.  Port forwarding, it's called.



STEVE:  Yes.



LEO:  Then someone challenged me about opening that port in the firewall:  "Isn't that an access point the bad guys can get through?"  Without considering it deeply, I figured an open port was like a CIA phone number.  Someone randomly dials a number, the lady answers with a challenge - 41357.  If the caller is unable to provide the correct reply code word, she hangs up.  That's the end of the attack.  Am I wrong?



STEVE:  Well, this was an interesting question because what Bill is saying is that he's opening services to the Internet, so that he, wherever he is, and sadly any hackers, wherever they are, are able to access the service running on the machine on his network.  So the router that would normally block and provide good security for unsolicited incoming traffic, the problem is, it's blocking Bill, who wants to connect to a service running on his computer.  So Bill says no to the router, open this port, and if anything comes into this port, send it to this IP behind the router to this computer.



Then, as we know, for example, your typical personal computer today, whether it's a Mac or Windows or Linux, has a firewall.  Well, that's going to stop it again because it's going to be an unsolicited incoming packet.  So again you need to say to the firewall running on the computer, no, allow something coming inbound on this port to come on in.  So now what's happened is, any traffic out on the internet is able to get all the way into the service running on the computer.



The problem is, everyone on the 'Net has access.  So now you've got the issue of, okay, so I have to log in to get to this computer.  However, in the best case that's true.  History has not demonstrated, unfortunately, that that is the case.  For example, just this week there is news of an IIS, that's Microsoft's Internet server, the FTP service running in IIS is vulnerable to attack.  So, and IIS is the so-called personal web server that you can turn on and configure in Windows XP Professional, for example.  And you can use it locally.  But in Bill's scenario he would have mapped the FTP ports through to his machine.



So normally you have to log into an FTP server.  Unfortunately, it turns out you don't have to log into Microsoft's.  So this happens to be a perfect example of, yes, you'd like to have your CIA lady challenging you, a challenge-response or some sort of log-in.  In the best world, that's what you've got.  The problem is that time and again we run across mistakes in the coding of that log-in or challenge-response password system that can allow somebody unauthorized to connect to you.



In my opinion, the only safe way to handle this is if, for example, Bill was at work, and he knows his work's network, then you allow a selective opening of the port.  You say, allow incoming connections only from this IP range into my local network.  The beauty of that for, for example, TCP connections, like FTP uses in this example, is you cannot spoof the IP of an incoming TCP packet and have it succeed.  You can make up an IP address, but then in the connection-establishing TCP handshake, the responding packet will go to the IP you spoofed, not back to the spoofer.  So that's extremely good security.



But it does narrow Bill's freedom.  For example, he would only be able to access the service running on his machine at home from prespecified IP ranges, which, again, the huge security is random hackers scanning the 'Net.  For example, you can imagine right now, with this known vulnerability in IIS, there's an uptick of people scanning for FTP ports, hoping to find exposed IIS FTP services that they can immediately use to compromise the service behind.  You don't want to be exposed to that on an ongoing basis.



So my feeling is punching holes in the wall indiscriminately can be a very dangerous thing to do.  And maybe what you want to do, if it fits your need, is not have that hole punched through to a main machine on your LAN.  Have it go to the so-called DMZ, to some machine which is isolated from the network, that might be able to give you some of the freedom that you want or that you need, but if somebody compromised it you'd be less damaged.  Although even that is creepy even to say.



LEO:  Never creepy to say.



STEVE:  Yeah.  So anyway, Bill ends up saying, "Am I wrong?"  It's like, well, it's dangerous.  You absolutely need to recognize that it's dangerous.  Because vulnerabilities are being found in these sorts of services all the time.  And unless you can restrict the port range from which you're making a connection, which does give you very good security, I just think it's too freaky.  It's just too frightening.  That's really where you want a VPN.



LEO:  Opening a server, anytime you open a server on your system you're opening yourself up.



STEVE:  Yes.



LEO:  And you rely on the security that the server provides.



STEVE:  Yes.  And history teaches us that that's not a good thing.



LEO:  But nevertheless, people do it all the time.  I mean, I have FTP servers running on my NAS, and we port-forward over to it.  But we have a log-in.  And we just hope that the FTP daemon is secure, and you keep an eye on the updates and all sorts of stuff.  Because otherwise, I mean, look.  I have a web server running.  Not on my local network, but it's running on my - it may be even a more critical network, if I think about it.  So we just trust that we're locking it down.  Bear's always looking at security holes, and you harden it, and you do the best you can.



STEVE:  Yup.



LEO:  Joe Dorward in Bracknell Forest, England echoes a common question:  Steve, going back over the parents and passwords issue, where people who just don't get it - like elderly parents or whatever - can't be induced to care and take greater precautions.  We had a question about that a few weeks ago.  I remember you've mentioned in the past that writing down a really good password is better than memorizing a poor one, and something about assessing the threat vector before devising a solution.



Seems to me, then, that parents, or people in general accessing the Internet from their homes, are safe enough writing down a very good password, even putting a post-it note on the screen, on the assumption there's a higher risk of somebody guessing a weak password over the Internet than there is of someone seeing the good password written down in their home.  We can't expect most people to adopt a more secure way of life if it's not easy.  So getting them to write down good passwords, unless you give them YubiKeys or something, is a pretty good solution, and better than having them use "password" as their password.  He makes a good point.



STEVE:  Yeah.  I think it's a very good point because you do have the danger over the 'Net of somebody having the opportunity to guess a weak password.  And you could argue that, okay, written down on a post-it note, there's just not that much physical exposure to their written-down password.  I would add, and the reason I wanted to bring this up, is that Joe made a very good point, and I wanted to add one more thing, though, that I did say before, just to make sure it's heard.  And that is, make a change to the password you write down.  Deliberately do something to it.  Swap the first and last character.  Add something of your own, either to the end or to the beginning.  Because you can combine the thing that you've written down, which is bizarre, with special characters and punctuation marks and things, and then always remember to do something custom to it that's easy to remember.  And in fact, if you forget, and you put in the password exactly as it is, it'll get rejected, and you go, oh, that's right, I have to add my special incantation to it.



LEO:  Right.



STEVE:  Then you've really got the best of both worlds.  You've got something nonguessable, but the part you remember can be guessable because the concatenation of those won't be.  And that's a perfect, I think, compromise for people like people's parents who don't want to do separate passwords for everything and so forth.



LEO:  Yeah, that's kind of what I do.  I don't want to talk too much about how I do it.



STEVE:  No,  not supposed to.



LEO:  Yeah, that's kind of what I do.  And I have - and this is what parents won't do - secure password stores.  And so I wouldn't write them on post-it notes.  I keep a secure password store which has its own master password.  And that's pretty - and that's kind of the same idea.  It's just a hard one to get Mom and Dad to do.



STEVE:  Yeah.



LEO:  Or whoever.  And Mom and Dad, if you're the tech literate person in your family, I apologize.  To get the kids to do, let's put it that way.



STEVE:  No disrespect intended.



LEO:  No disrespect intended at all.  Paul Bye in Rochester, Minnesota is being annoyed by DNS results being altered by ISPs.  We've talked about this many times before.  He says:  Dear Steve, I thought I'd pass this along as you and your listeners of Security Now! might find it interesting.  You've discussed this topic on previous shows.  I don't remember you ever mentioning this one in particular.



My ISP, Charter Communications, it's a cable company, recently made changes to their DNS so that, like many other ISP-hosted DNS servers, if you put in a hostname, and there's a DNS miss, the hostname isn't in their database, they return an address to their own, quote, "helpful" search page, saying did you mean so and so?  I could live with being rerouted to the search page when I'm browsing.  It's annoying, but it doesn't cause any major harm.  The problem I and so many other people probably have is that this is altering the fundamental way DNS is supposed to work and causing all TCP/IP-based programs that depend on DNS to fail.



The first major problem I hit after this change is trying to connect to my company's network with their VPN client, something I depend on heavily to do my work.  I can still connect okay.  But now when I type in a hostname that is on the internal company network, but not visible to the outside Internet world, Charter's DNS server doesn't find the hostname, and then returns their search page IP address.  Now, obviously this breaks the VPN.  So far the only way I've been able to get around this is either manually editing my connection settings to put the VPN-specific DNS IP addresses, which I then have to switch back after I disconnect, so that's inconvenient, or go find some DNS servers that don't behave this way.



You've recommended OpenDNS in the past.  I'm sad to say they're doing the same sort of thing.  They are.  I'll vouch for that because I use OpenDNS.  I finally found a post indicating the existence of some publicly available, strong, stable servers that do DNS correctly.  And he found this on the DonationCoder forums.  We have a longer link which I'll put in the show notes.  He says he's switched to those for now.  I plan on setting up my own DNS server after hearing that you do this as well, but I thought listeners might want to know about the ones mentioned in this forum post as I found them to be really good and high performing.



Thanks so much to you and Leo for the show.  I've been a listener since day one.  Look forward to every Thursday when a new episode is available.  So what's the deal on this?  I didn't realize it could break a VPN.



STEVE:  Sure.  And in fact mostly it's there are problems with non-web protocols because some of these are not very selective.  I happen to - I don't know if I would call myself the world's foremost expert on this at the moment.  But the DNS benchmark, which is ever so close to being released, and we'll be talking about it before long, has explicit handling and detection of DNS servers that do this.  And we've discovered that this is a - "we" meaning myself and the people who are in the GRC.dns newsgroup at GRC.  We've discovered that this is something which is becoming more and more common.



I did want to mention, just for the sake of completeness, to Paul that you can create an account with OpenDNS, and you can turn that behavior off.  The other thing that's happening is ISPs who are generally moving towards this are also generally providing an opt-out option.  So that I might suggest that he check with Charter and see if there's a way to turn this off.  Because most ISPs are being made sensitive to this because savvy users are saying, wait a minute, I don't want your darn search page coming up.  I want an error, for whatever reason.  And so it might very well be, I don't know in the case of Charter directly.  There's one big ISP, as you were reading this I was trying to remember the name, I think the name begins with C-o-m, can't remember the name of it, though.  Anyway...



LEO:  You're joking; right?



STEVE:  Comcast.



LEO:  There you go.



STEVE:  That's the one.  No, I was just drawing a blank.



LEO:  Okay.



STEVE:  You know, I'm getting old.



LEO:  I wasn't sure if you were just being cagey or actually had forgotten.



STEVE:  No, Comcast is now doing this, too.  And they're beginning to spread this across the country.



LEO:  Of course you know why they do this.  They make money.  They put ads on that page.



STEVE:  Absolutely.  It's like, whoops, sorry, you've made a typo, heh heh heh, but look at this.  Maybe you want to buy one of these.  It's like, no, thank you, I just want my error, please.  Now, the link that he provided, I followed the link, curious whether he knew about DNS servers I didn't know about.  Because one of the cool things that the benchmark, the forthcoming benchmark from me does, is it has, I've forgotten now, like a bunch, maybe a hundred?  Maybe it's not a hundred.  It's a lot.  We have a big - I have a - it knows about a huge number of publicly available DNS servers.  And it compares their performance to your DNS server's.  And the idea being that it may be that your ISP has slower DNS servers than are available publicly.  So by changing to these publicly available servers, you get better performance for all your Internet stuff.



It's going to be a very cool app.  It also tests for and warns you if your ISP servers or any of the public ones, like OpenDNS, are doing this DNS redirection, because that's something you would probably want to be made aware of.  So it is the case, for example, with Comcast that you can configure theirs not to do this.  So I would suggest that maybe Charter's is the same.  But I was saying that on this forum, the IPs they gave was very familiar to people who have been using non-ISP DNS servers:  4.2.2.1 through 4.2.2.6.  Those are Level 3 servers, which...



LEO:  Oh, I thought it was Verizon.  That's Level 3, okay.



STEVE:  Yeah.  Maybe it is.  I think there was some - there might have been some ownership change because now you say that I...



LEO:  Let me ping it and see.



STEVE:  Well, actually, and not surprisingly, my DNS benchmark determines the ownership of all of the DNS servers that it finds.



LEO:  It's still Level 3.



STEVE:  Okay, still Level 3.  I thought so.  Anyway, so...



LEO:  And they don't mind if you do that?



STEVE:  Well, they're open to the public.  And, I mean, I've seen the IPs given around a lot.  The problem is they're not quite as stable and reliable as you might think.  And once again, the DNS benchmark, which will be free when I get it documented, basically it's finished, I just need to get the documentation done because it's got so many bells and whistles in it.  It's even able to determine the reliability of all of the DNS servers from your vantage point and in addition to ranking their performance in a number of different parameters.  It's turned out to be very cool.  And it's where months of my time has gone because I think it's going to end up being so important.



But our users have found that these Level 3 servers are not as reliable as they thought.  And specifically some of them don't - it uses a technology called "anycast," where you have fixed IPs that hopefully find a DNS server that's local to you.  But it turns out that some, I think .3, for example, is problematical for, like, a lot of people.  But anyway, we will be talking about this in more detail in the future, soon as I get the benchmark documentation finished.  In the meantime, I would suggest that people who are seeing this behavior check on their ISP's pages to see if there's a way they can configure this behavior off, if they don't see it as a benefit.



LEO:  Is it only VPNs that have a problem with this?  Are there other...



STEVE:  No.  It would be any technology.  See, the idea is your system on your behalf looks up an IP.  If it is not found, then you receive an IP instead for a web page which is the search results.  Well, what that means is that any programs, other than a web browser, are going to get really confused by this.  A web browser will show you the page that the search engine provides.  However, other things, like an FTP client, a chat client, I mean, anything essentially else, will get this IP which is bogus, and they'll try to connect to it.



LEO:  You get an HTTP page, yeah, so it does - I mean an HTML page which you can't interpret.  What's this?



STEVE:  Yeah, exactly.  And so they don't get - if instead they received an error message, a DNS error, then they could present you with a dialogue box, which they probably are configured to do so, saying hey, you just typed in a chat URL that's incorrect.  Instead they assume that the IP is correctly mapped to the URL, I mean, it really does break DNS.  The purists, the old curmudgeons among us, are upset with this because it breaks DNS.  This is not the way DNS works.  Yet it's a creeping, as you said, it is a revenue source that ISPs are increasingly waking up to and going, hey, we can do that, too.  Let's get our little piece of the pie.



LEO:  And, you know, I think it's not completely disingenuous of them to say it also is better for users because they don't get a 404, they get something more useful back.  You know, the mom-and-pop thing.  But, now, if it breaks everything but HTTP, that's not a good thing.



STEVE:  And it's interesting because my probe in the DNS benchmark, it was originally doing a test for www.subdomain.something.com, and looking to verify that an error was returned.  It turned out that there were some smarter ISPs which would look to see whether you had www or not.  But that was causing me to miss some redirections.  So then I changed my code to remove the www and just look for domain.com, like bogusdomain.com, and verify that we got back an error.  And so that's the way it had been for a couple months.  Then somebody - we realized that there were - yet another iteration was that that would not return the error, but the www would.  So now the benchmark is doing both.  So anyway, we'll be talking about this in more detail when I'm ready to unveil the benchmark to our listeners, which is just a matter of me having a little time to get it documented.  But the technology is in place.



LEO:  Rorx points out that this is really something more appropriate for the web browser to do than the DNS to do.  The web browser, like Internet Explorer, can come back with an MSN page and say, oh, no, you meant this.



STEVE:  That's a beautiful, a beautiful example.  That puts the responsibility where it ought to be so that you're not crippling all the other applications on your machine that don't know how to interpret an IP address coming back that's wrong to a question they ask.



LEO:  Problem is Comcast makes no money on that.



STEVE:  Right.



LEO:  Here's a question, I guess for me, from Rod Duckworth in Sydney, Australia.  He wants to know about old shows.  He says:  Steve, you won't remember me, but I have spoken to you on the phone a couple of times some years back re SpinRite.  I'm a long-time  user.  Always loved SpinRite.  Thank you.  I have owned an IT company called Hi-Speed Networking in Sydney, Australia for some 20 years now.  I employ about 15 people and have been using SpinRite since the first available version.  I'm licensed up to v6.  I've also been listening to Security Now! since Episode 1, as I'm always on your site, keeping abreast of what's happening, using ShieldsUP! when I'm on-site at clients, as I, too, specialize in IT security and ethical hacking.



By the way, not now, but I have some ripper SpinRite testimonials and stories that I'll send you at some stage for Security Now! that'll be fantastic for you when I get around to writing them down.  However, what I wanted to know was, although I can download all the old versions of podcasts via your website in MP3 mode, iTunes only lets me go back 20 or so.  I'll explain why that is, by the way.  Although I can - it's not iTunes, it's us.  I can and have got these audio files from your site.  They won't load into iTunes as a podcast as such.  Okay.



See, I had some time off from Security Now! some time back due to personal issues that occupied my life for a while.  I haven't actually missed listening, it's just I don't have as many of them as - I don't have all the shows as podcasts.  He also says:  I occasionally get over to Long Beach.  That's a long trip from Australia.



STEVE:  Yeah.



LEO:  So next time I'm in there I'm going to pop into Starbucks and have a coffee with you and thank you personally for the podcast and SpinRite.  Meantime, how can I point my iTunes at a podcast source that has all the episodes in podcast format for me to download via iTunes?  Is there any way?  Also, you mind if I put the MP3 on my site in a secure members area?



So let me explain what goes on.  iTunes is dumb.  It doesn't know anything.  We don't make our feed longer than 20 shows on any of the shows because, as the feed - we could have every show in there.  But the feed, the RSS for the feed would be hundreds and hundreds of kilobytes.  Probably a megabyte if I put all the shows.  Then that means every time you check the RSS, which could be several times a day...



STEVE:  Ah, you download the entire file.



LEO:  Download the entire file.  Which is considerable bandwidth for us and for you, especially if you're in Australia and you have bandwidth caps.  There's no - I don't see any reason to offer a megabyte or two megabyte RSS feed.  So the RSS feed, and I think this was really the intent of RSS, you know, you look at RSS feeds from websites, for instance, they don't have everything ever published on the website.  It's just the most recent X articles.  In our case it's the most recent 20 podcasts.  And that's what iTunes is using.  Now, if you keep iTunes running all the time, it will update that, and you'll, you know, if you've been running iTunes and had the subscription to Security Now! since day one, your iTunes will contain a listing of all the shows.  Because it just updates the listing.  But the most recent RSS feed only contains 20 shows.



Now, he has a separate issue, which is when he downloads them from - I'm not sure why this is happening - from your site - try it from our site.  I'm not sure if there's a difference.  But those shows are not, he says, showing up as podcasts.  You can go into iTunes and say in the info setting this is a podcast, check a box.  What that does is it puts it in the podcast folder.  It changes how synchronization occurs.  It also makes it a spoken word file, which means instead of starting at the beginning each time it bookmarks where you left off and went back to that point.



STEVE:  Ooh, that sounds like a good option to have.



LEO:  Yeah.  I mean, it's the same with audio books.  It's just a checkbox on iTunes, I'm pretty sure.  They used to make it a very obscure tag, kind of an iTunes-specific tag.  But now it's just a checkbox.  So that's all you need to do.  Download them, import them into iTunes, select them all, get info, check the box that says these are podcasts.  It'll treat them properly from then on.



You know, you can get any show.  Every show on our network is available through the TWiT website directly, if you know the naming scheme.  It's always TWiT.tv slash the initials of the show, in this case "sn," followed by the show number.  So this show, which is, what, Episode 212, is at TWiT.tv/sn212.  And it goes all the way back to sn1, sn2, sn3.  So they're all there.  They're all - and in fact, if you look at the naming scheme from our server, you could even do this automatically with a little script because we don't change - the file naming scheme is always the same.  So if you look at our file naming scheme, which is a little longer because it goes to CacheFly, or no, I'm sorry, it's from AOL, isn't it.  So it's AOL, and then there's a redirect in there, blah blah blah.  But if you look at that, the only thing that ever changes is the show number.  So you could just manipulate the show numbers, and you can get any file directly.  You could write a cURL script that would step through them all and download them all at once.  So they're all there on the server, but the RSS feed never contains all the shows.  It just would be horrendous.



STEVE:  Yeah, that makes absolute sense.  I wanted to make one comment.  He asks if we mind if he puts the MP3 on his site in a secure members area.  And the only downside for us of that is that we would not get credit for the count of those downloads.



LEO:  Yeah, we prefer you didn't.



STEVE:  It's better for us if you copy the links because then the link does route through Podtrac so that they're able to count the number, and that way they know how many people are listening.  And then our sponsors are able to say, oh, this podcast has this number of listeners, it's worth this much to us. 



LEO:  Right.



STEVE:  And that makes it worth that much to us.



LEO:  Technically our license, we use a Creative Commons noncommercial attribution share alike, allows you really to do anything you want with the podcast.  Because we're really more interested in people getting it out there.



STEVE:  And sharing it.



LEO:  Yeah, and sharing it.  But we'd ask as a courtesy, if you are going to put it on your web page, use the link that we use, which you'll see starts with Podtrac.com.  And all that happens is Podtrac, every time the show is downloaded from any source at all, a little counter increments.  Podtrac does - I should say in the interests of, since you guys are all smart and understand this stuff, in the interests of full disclosure, Podtrac has a IP database of unique IP addresses.  And we are trying, for advertisers purposes, you could download it 20 times.  We only count that as once.  So it's counting unique addresses from the IP.  But we don't in fact save your IP address.  There's no log.  We're not saying who's downloading it.  We just do that, compare it to an IP database...



STEVE:  It's only to get an honest count.



LEO:  It's to get an honest, unique count.  So when we say, for instance, 80,000 people listen to this show, it's not 80,000 downloads.  In fact the download number is probably three or 400,000.  It's 80,000 unique listeners.  So, and that's something advertisers of course want us to do.  A lot of shows will give out their download numbers because they're way inflated.  We don't do that.  So that explains it all.  We don't and can't stop you from doing that, but we'd ask you if you would to please just put the link.  We don't mind the bandwidth.  We've got the bandwidth.



STEVE:  Well, and in fact there's a nice compromise, too.  I would say if for some reason you're worried that the MP3 files will ever go away, you could certainly keep a local copy of them, but use our links for users to access them.  So that if they ever went away, I don't know why they ever would, but then you've got your own backup copy.  But the live access uses our links so that the counters get incremented.



LEO:  Yeah.  I don't think they're ever going to go away.



STEVE:  I don't think so.



LEO:  I guess AOL, which provides our bandwidth, could at some point stop hosting, and they might have to move to another location.  But I will do my best to make sure that the podcasts continue.



STEVE:  Well, and I'm insulated from that.  My technology that I've got, I actually have a switch in the registry of the server.  I just turn it off, and everything gets hosted locally.  So it's just a matter of, if that ever happens, I just change a switch, and my own redirection gets shut down.  So I'm prepared for that eventuality, as well.



LEO:  Great.



STEVE:  Yeah.



LEO:  Question seven, from John Prince in Somerset, UK.  He had a disquieting dialogue with Netgear about this WPA crack we were talking about?



STEVE:  Yeah.



LEO:  Hello, Steve.  As an avid listener to Security Now! since the beginning, Episode 1, I know you'll be discussing this matter on the show.  I thought you might be interested in the reply I received from Netgear about my own router, which is only a couple of years old.  I realize that this vulnerability is not in the wild just yet, but I thought I'd make inquiries now rather than get into panic mode at a later stage.  Seems a shame that they have to wash their hands of responsibility for their product, and that I may have to fork out hard-earned cash to replace a piece of equipment which is in otherwise good order.  If you have any advice in the matter, I'm sure I and all your other listeners would be most interested in hearing it.  P.S.:  If I have to replace my router, I doubt this company will now be my first choice as a supplier.



Here's the reply from Netgear:  "Thank you for choosing Netgear.  My name is Amandeep, and I will be your support engineer.  I appreciate the opportunity to assist you.  Regarding your concern, please note that the DG834Gv2 is an end-of-life product, and there are no further updates planned for the router."  He said it was only two years old, so that's pretty quick.



"Therefore, in order to get the WPA2 security on your network, I would request you to please upgrade your router with a new one."  Then he gave some newer model numbers.  "I believe this answers your query.  If you need any further help, please email us back, et cetera, et cetera."  Well, that's interesting.  Two years old, you'd think they'd have WPA2 in it.



STEVE:  That's what I'm curious about.  I mean, that's one of the things is that, if it's really only a few years old, that's certainly long enough for them to have, I mean, for them to have before now updated.  I mean, even if it were a couple years old and it were - say that it was four years old, well, WPA2's been around, like when the router was a couple years old, to get itself updated.  One possibility, strange as it seems, is that maybe it's unable, the hardware is unable to handle AES encryption.  It is the case that TKIP encryption of the less capable WPA is easier on hardware.



John asked for some advice.  And the one thing you could do is use one of the routers that has an open alternative firmware.  And that's going to inherently give you, I think, really good longevity because the open software community will keep it current and keep it patched and keep adding features to it.  As the state of the art moves forward, I would tend to think you're much better off with that approach, if you're unwilling to continually march forward with the obsolete hardware problem.  I mean, it's annoying that they're saying, well, it's end of life.  At the same point, you can understand that they're spitting out so many different routers constantly, which is another problem that's sort of annoying, is that they're having to just discontinue support for the older ones.



LEO:  Right.  Yeah, firmware would be easy enough to do.  But, look, every company has to make this decision at some point.  It's expensive.



STEVE:  Exactly.



LEO:  You can't support everything you've ever made.



STEVE:  Exactly.



LEO:  But two years does seem a little short.



STEVE:  Yeah.



LEO:  Last question.  Grant McMillan in Brisbane, Australia wonders about decrypting today's data trivially in the future.  Now, this is a good question.  I like this.  Hi, Steve.  Given the exponential growth in computing power these days it seems that any encryption method used today could eventually be cracked quite easily.  Will it be possible for a person to record packets today with the intention of cracking them once it's trivial in years or even decades from now?  Thanks for the great podcast.  That's a very good point.  I mean, computer power doubles every 18 months.



STEVE:  Yeah, it's a great point.  And what I liked about the question was notice that he talks about recording packets today.  That is to say that, rather than ignoring the packets today because we can't decrypt them, save them.  They're encrypted, but save them.  Because it may very well be that, as we move forward - and we're seeing examples of this all the time.  For example, we just talked about how we're no longer going to use MD4, or Google's Chrome is no longer going to allow MD4 signatures on SSL certificates for browser surfing because now we know that there's some chance in some situations that it's possible to forge certificates in order to forge the identities of the endpoints that you're connecting to with SSL.  So the idea is that we're obsoleting those and replacing those with newer technology.



Well, there's no way to obsolete encrypted data which you have stored because you've saved it.  And so at some point in the future it may be that AES encryption is weakened, and that the world, for example, moves away from it to something else.  Well, any traffic that is current at the time will follow that migration to the stronger cipher.  But old traffic, which may not any longer be used in real time, but if you saved it in a safe somewhere, in an archive, at this point in the future it's like, ah.  Now, finally, I can essentially turn back the clock.  It's like having a time machine going back to stuff you had saved and for some reason felt or had reason to believe was very valuable, and now you can decrypt it.  So it's a really great question.



One of the things that came up in last week's episode about voting machines was the notion, and in the researcher's mind they were exactly focused on this problem, that is, this design of this voting machine was 20 years old.  How had it survived the evolution of technology during that 20 years?  And, for example, this whole concept of return-oriented programming that we talked about, that had been in - that was invented relatively recently.  So they couldn't really protect against something that they couldn't anticipate.



And similarly, the point was made in their article that RAM at the time, these RAM cartridges, these voting cartridges, had static RAM with batteries in them and didn't have very much RAM because physically RAM was much bigger then than it is now.  But that now you could imagine an entirely different technology.  In something the size of that cartridge which was barely able to hold RAM, you could put a whole Cray supercomputer in a cartridge of that size using today's technology.



So the question is, did the technology then, was it designed to be robust enough to survive during its application, during its use lifetime, can it survive all the forward motion of technological progress during that time.  And that's really not something we've talked about before, but that is, it's a really great question.  And it is absolutely foremost in the minds of people who think about what's the vulnerability.  It's not just today, but it's either - it's technology which is locked in place today needing to survive during the technology's youthful lifetime.  But the notion of saving encrypted data today on the off chance that some point in the future it will be decryptable, that's also very important.



LEO:  Yeah.



STEVE:  Great question.



LEO:  Yeah.  So assume that at some point - but maybe you won't care in a hundred years.



STEVE:  Well, the downside, or the counter factor to that is he says, "Hi, Steve.  Given the exponential growth in computing power...."  Well, I will remind our listeners again that, even though it's so easy to add bits - oh, look we just added some bits to this key - every bit you add is exponential growth.  Every bit doubles the number of possible combinations of the key.  And so that's exponential.  And we're saying that, okay, today a 64-bit key is probably not safe.  A 128-bit key, okay.  So we go, wait, we only doubled the length.  We only made it - we only added 64 bits.  But oh, my God, that is so much stronger than 64 bits.  So it's deceptive how little we need to lengthen symmetric cipher keys in order to dramatically, that is, exponentially increase their strength.  So when you go to 256 bits, forget about it.



LEO:  So that's - I've often, you know, people have said should you - 1024 is plenty.  Why should you use 2048?  There's a good reason.  Not for now.



STEVE:  Yes.  It's not for today.



LEO:  Yes, 1024 is plenty.



STEVE:  Yes.  But it's not for today, it's for tomorrow.



LEO:  Yeah.  That's really interesting.  Very, very interesting.  Well, Steve, we've come to the end of this fabulation of fabulous questions.  I just made that word up.



STEVE:  Uh, yeah.  Confabulation would not be a made-up word.



LEO:  Confabulation.  Conflagration.  Next week, GSM cracking.



STEVE:  Yes.



LEO:  Should be a lot of fun.  Our Topic In Depth.



STEVE:  TID, Topic In Depth.



LEO:  Meanwhile, if you want this show or any of the past 212 episodes, you can get those from Steve's site.  He has 16KB versions available for quick download.  Quality goes down, but at least they're small.  He also has transcripts, which are even quicker downloads, and a great way to kind of search and follow and figure out what's going on.  Those are all at GRC.com.  If you want to ask a question for future feedback episodes, it's GRC.com/feedback.  And of course don't forget SpinRite's there, and all of the great software that Steve does.  Most of it is free.  And certainly SpinRite is well worth the money.  If you've got a hard drive, you really should have SpinRite to keep it running in tiptop shape.



STEVE:  Sooner or later you're probably going to need it.



LEO:  You bet.  GRC.com, the Gibson Research Corporation.  And Steve, we'll see you next week for another great episode of Security Now!.



STEVE:  Absolutely.  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#213

DATE:		September 10, 2009

TITLE:		Cracking GSM Cellphones

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-213.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the state of GSM (Global System of Mobile communications) cracking.  Steve shows where to purchase the required hardware, from where to download the software, and just how easy and practical it has become to "crack" the old and very weak "security" employed by the three billion cellphones now in worldwide use.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 213 for September 10, 2009:  Cracking GSM.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure and peaceful and calm, and all things insecure and horrible and nightmarish.  And one guy does it all.  He's our expert on security, the one and only Steve Gibson of the Gibson Research Corporation, GRC.com.  Hey, Steve, how are you today?



STEVE GIBSON:  Well, Leo, you know we almost didn't have this podcast.



LEO:  What?



STEVE:  Yeah.



LEO:  Did you almost get run over by a bus?



STEVE:  No, I almost didn't finish Michael McCollum's newest book in time.



LEO:  Were you reading feverishly?  So you read the third volume of the Gibraltar series in less than a week.



STEVE:  Well, he gave it to me - I got it Friday afternoon.  So that's where Labor Day Weekend went.



LEO:  You read it in three days.



STEVE:  And, well, I couldn't put it down, literally.



LEO:  Oh, it's that good.



STEVE:  I mean, yesterday morning from 7:00 to 10:30 I read, and my eyes were a little wet at several points.  I mean, it's...



LEO:  You cried?  Oh...



STEVE:  Well, it's - he does some good character development, and you care about these people, and it's...



LEO:  Oh, that's neat.



STEVE:  It's just spectacular.



LEO:  Oh, I can't wait.



STEVE:  I mean, it's everything I want in hard sci-fi.  It's just great.  So, and I found enough little typos, I could sort of see, you know, like when you go and rewrite a sentence, you scan it, and you leave an 's because it used to be possessive and now it's no longer, or you get the tense wrong on part of it.  So I'm a slow, careful reader.  And I found a bunch of stuff, I mean, enough that it was probably worth his while having me read it.  And so it's, as of yesterday evening, it's back to him.  And I don't know what his turnaround for turning it into an eBook will be.  But, I mean, it's one now.  It seems pretty ready to go.



LEO:  What's the name of it?  Gibraltar...



STEVE:  "Gibraltar Stars" is the third in the trilogy.  The first one was "Gibraltar Earth," "Gibraltar Sun," and then "Gibraltar Stars." And what I like about it so much is, as with all of his things, there are really unique constructions.  Obviously, it's fiction, so it's contrived.  But he stays very faithful to the rules he sets up.  One of the things that really bugged me about "Star Trek:  The Next Generation" was Q, that ridiculous, omnipotent alien.  Because if you have someone who's omnipotent, why even bother?



LEO:  It's just a plot device.  It's like...



STEVE:  Yeah.  Well, it's a cheat.  He could just blink you wherever you wants to blink you or do anything to you.  It's like, okay, now suddenly, if there aren't any rules, then you don't have any problems.



LEO:  It's a total cheat.



STEVE:  And so Michael McCollum establishes a universe with limitations and then always builds really intriguing plots around them where you're sitting there thinking, oh, god, okay.  What are we going to do now?  God.  Anyway, I don't want to say too much because I just - I can't recommend it highly enough.  And I have had enough feedback from people who have heard us talking about him and Peter Hamilton and our other, the other authors that we like so much, that they've been turned on to this stuff and really enjoyed the read.  So anyway, this trilogy is finished, and it's really great.  And we can have a podcast now.



LEO:  That's good.  Lucky thing you finished it.



STEVE:  Yeah.



LEO:  We're going to cover - today we're going to cover something you promised last week, which was cracking GSM?



STEVE:  And we've had people send feedback, wondering about this.  And we've even read Q&As where people are saying, hey, you know, if I use a cellular modem...



LEO:  How safe is it?  How safe is it?



STEVE:  ...just by itself, how safe is it?  And I've known that fundamentally it wasn't safe because I've sort of felt, I mean, I sort of moved through this domain.  And I remember seeing somewhere that the encryption was based on three shift registers, which immediately says oh, goodness.  And now I know exactly how bad it is, and we're going to talk about it today.  Basically I'm glad I'm over on Verizon with - and not using GSM.  It's completely cracked.  It's completely broken.



LEO:  So any bad buy could listen in on your conversations.



STEVE:  And not for much money.  It turns out - oh, I meant to tell you before we started recording, but you can do it now:  www.ettus.com is the group that offer a beautiful, I mean, just spectacular technology, cute little software programmable radio receiving set.



LEO:  Oh, neat.



STEVE:  It's based on the GNU Radio project that John Gilmore has funded for about a third of a million dollars.  And basically after a day of sitting here doing the research, if I had any inclination, everything that I need to listen in on someone's cellphone conversation, all the software, it's all open source, it's beautifully designed, you can program it from Python or C, everything is there to do it.  And you need about a thousand dollars for the radio receiver equipment, and then any PC.  It's just - it's done.



LEO:  Oh, man.  You know, I remember talking...



STEVE:  And it's not like...



LEO:  Go ahead.



STEVE:  ...hundreds of thousands of dollars or corporate or government level.  That's just not the case.



LEO:  I remember talking to Woz some time ago.  He used to like to sit and listen to, what was it, he had a little receiver, he would listen to cellphone conversations, I think, or maybe - oh, no, it was long distance calls coming over satellites, unencrypted over satellites.  And he would just tune in and listen to the calls.  Sounds like this is almost as easy.



STEVE:  Well, and back in the day, before we went digital, when we had analog cellphones, I did run across a little scanner, and you could turn it on, and you would only hear one side of the conversation because they were on, the transmitter and receiver, on different frequencies.  But it was really embarrassing what you heard.  It was like, oh, goodness, I hope this guy's wife isn't listening to this.



LEO:  Yeah, exactly.



STEVE:  I mean, it was really - it was just out there in the open.  And in fact I refuse to have important conversations with my attorneys over the cellphone because I knew firsthand that it just wasn't secure.  And we'll talk about the various, well, in detail about the technology, why this is so badly broken now and what it means in terms of practical attack scenarios.



LEO:  Oh, that's shocking.  All right.  We're going to get to that in just a second.  Before we do, any errata or security news?  I guess this is the second Tuesday of the month, isn't it.



STEVE:  Well, yeah.  We're recording a day earlier than we normally do in order to make room for the Mac event which is happening on, what, on the 9th, I guess.



LEO:  Yeah, 09/09/09, yeah.



STEVE:  Is that going to be the tablet, or more iPods?



LEO:  Nobody knows, of course, because Apple doesn't say.  But the general consensus seems to be the tablet will be next year.  These will be just iPods.



STEVE:  Yeah, that's sort of what I heard, too.  So, yes.  We're standing on Tuesday.  And as of half an hour ago I checked Microsoft's advanced bulletin notification deal.  And all they've got is their very generic, five really bad problems, all remote code execution attacks.



LEO:  Oh, boy.



STEVE:  Microsoft has acknowledged what we talked about last week, which was this problem with IIS and the FTP vulnerability.  So I want to reiterate to all of our listeners, anyone who's, for example, got IIS, which is the web server with FTP that's installed, you know, the so-called "personal web service," which it's very possible to have running even if you're not some big corporation who's serving these things.  FTP is vulnerable for remote attack.  So you absolutely want to shut that down.  Microsoft is not expected to have a fix for it by today.  As far as we know it's not one of these five critical bulletins because it's happened much too quickly for them to respond.  They have said they will fix it as soon as they have a patch available, meaning probably an out-of-cycle patch because this is potentially a big enough problem that they're not going to let this thing languish for long.  But as we're recording this, we're expecting five critical bulletins from Microsoft.



LEO:  I've got them, if you want me to read just the headlines of them.



STEVE:  Oh, sure.



LEO:  Vulnerability in Jscript scripting engine, your favorite, scripting.



STEVE:  JavaScript.



LEO:  Love that.  Vulnerability in DHTML editing component, ActiveX control.  This is another remote code execution.  Vulnerabilities in Windows Media format.  Oh, that's not good.  Could allow remote code execution.  Vulnerabilities in TCP/IP.



STEVE:  Ooh.  Okay.



LEO:  Privately reported vulnerabilities in TCP/IP.  The vulnerabilities allow remote code execution if an attacker sends specially crafted packets over the network to a computer with a listening service.



STEVE:  Oh, goodness.  That's way [indiscernible].



LEO:  Firewall will protect you.  Okay, firewall...



STEVE:  Well, yeah, if you've got one.



LEO:  They say firewall best practices and standard default firewall configurations can help protect networks.



STEVE:  Interesting.  I can't wait, well, we'll definitely have some news about that next week when I know what's going on with that because that sounds really important.



LEO:  This is Windows Vista, Server 2008, also important for 2000 SP 4, Windows Server 2003.



STEVE:  Wow.



LEO:  And finally, vulnerability in wireless LAN autoconfig service could allow remote code execution.  We've been telling people to remove that anyway.  That had a problem before.



STEVE:  And it's just dumb.  It's one of these things that it's always upset me that Microsoft has this stuff turned on by default, even though the majority of users, just like Universal Plug & Play, the majority of users aren't using it and don't need it.  But it's there just in case.  And, whoops, it's vulnerable.



LEO:  Almost all of these look like they're Vista specific.



STEVE:  That's interesting.  And so - it's interesting because, before we began recording, you were asking me hypothetically whether I expected, now that we have Windows 7 with its presumably enhanced security, if these problems are going to be going away.  And my reaction was, uh, I don't think so.  I mean, and so here's Vista that's got new problems in it.



LEO:  Yeah.  Almost all of these are critical for Vista.  Now, I don't think - I don't know.  Do they push patches yet for 7?



STEVE:  I do know that when you install a new 7 it automatically, I mean, there's already updates for it, even though it's not been released.  I have installed the RTM, the Release To Manufacturing version.  And immediately upon getting it going, it's like, okay, let's go do some updates.  Oh, here they are.



LEO:  Right.  And we do get updates.  But I think those are not part of the second Tuesday cycle yet.



STEVE:  Oh, absolutely not.  I don't expect that to happen until it is, in fact, released.



LEO:  Okay.  Wow.



STEVE:  Well, now, wait a minute.  That's - I'm trying to remember whether I got updates.  I think if you have Windows 7 running, then the system says, oh, you're a Windows 7 user.  You're an early bird, but here's your updates.  So I think it's part of - I think it's already running.



LEO:  Maybe they are doing it, yeah.  Well, we're only a month away.



STEVE:  Yes.  Time flies.



LEO:  Wow.



STEVE:  Also I wanted to mention to any users of OpenOffice that multiple vulnerabilities have been disclosed in the Word.doc format.  They are remote execution, remote code execution attacks.  So I know that people who have, like, said, okay, we're not going to follow Microsoft any longer with Office, we're going to go to OpenOffice, and it's a beautiful piece of work, there are problems there.  And patches are available.  So if you're an OpenOffice user, it's time to go check for updates and keep yourself current because you want to make sure that those don't get you.  Although I think the attack target size is smaller for OpenOffice users than for, like, Microsoft Office users.  But still, everyone's trying to exploit these things these days.



Also the latest update to the Mac OS, so-called Snow Leopard update, which brings us to version 10.6.  We were down in the 10.5s up until now.  So we knock up to that second digit.  And what's in the news is that, unfortunately, when you do bring yourself up to 10.6 with Snow Leopard, it brings along a known vulnerable previous version of Adobe/Macromedia Flash Player, which it installs, which is known to be insecure.



LEO:  And downgrades you, even if you have an updated version.



STEVE:  Precisely.  It overwrites the current version with an older one which is known to be insecure.  So I wanted to let our listeners know that they're going to want to update Flash after installing Snow Leopard in order to fix that.



LEO:  Yeah.  There's a bit of debate over whether that was a good practice or not.



STEVE:  Which?



LEO:  Well, the problem is the Adobe patch came out two weeks before they went gold on the Snow Leopard.



STEVE:  Right.



LEO:  So they, I think completely reasonably, said, well, we haven't had time to test this.



STEVE:  I don't disagree.  You can easily imagine that they had basically a ready-to-go, release-to-manufacturing build and image.  And it's like, okay, well, look, we'll just let Flash update itself afterwards.



LEO:  And then what we don't know is how necessary it was to downgrade the existing version of Flash.  I guess that depends on the installer and how the upgrade was performed.



STEVE:  Exactly.  I was going to say that, to my mind, it wasn't deliberate.  They were just probably overwriting everything in the system with their own stuff.  And so they said, okay, let's just - we're installing OS X 10.6.  Stomp on whatever's here and replace it with stuff that is what we now think is current.  And in this case it wasn't current.



LEO:  Yeah.  So no harm, no foul now because you know about it.  And I presume Apple will push a - I don't know.  Maybe Apple won't.  I think they think this is Adobe's issue.



STEVE:  Oh, yeah.  I would say it's Adobe's issue.  And of course Flash does inform its users from time to time.  I would just say if you're able to - if you know you're potentially a victim of this, then it's worth updating to the latest version of Flash after you have installed Snow Leopard since it will have moved you back a bit.  And again, I don't think it's - it's not the end of the world.  It's not like a flaw in TCP.  So, you know...



LEO:  Well, there are exploits.  There are exploits out there.  One thing, and this is a side note, but I think a really great side note, Firefox in its latest version...



STEVE:  Mm-hmm.  That was my next point, Leo.



LEO:  I'll let you go.  Because it happened to me, and I was so pleased.



STEVE:  Yeah.  Currently in beta, both the v3.0 chain and the 3.5 chain, upgrade chain of Firefox, the next versions will begin warning users if their version of the Flash plug-in is out of date.  So Firefox is beginning to take responsibility, at least in the case of Flash, like a major high-usage plug-in, for making sure that it's current, sort of as an extra benefit, an extra security benefit for its users, which I think is very cool.



LEO:  Yeah.  That is really nice.  And again, not their responsibility.  But since you're the browser, and you know what's going on, why not?



STEVE:  Yeah.  And I had no errata this week.  I did have just a fun little SpinRite anecdote to share with our listeners.  It was a subject that we received through our sales email titled "A Note of Appreciation." He said, "Dear Steve and Co." - this is someone whose name is Barnett.  He said, "I purchased SpinRite 6 back in December of '07."  So, wow, two and a half years ago.  "And up until" - actually two and three quarters years ago - "up until this week I really didn't find a need for it.  We had a terrible thunderstorm come through here Monday.  And while we didn't take a direct hit, apparently the bolts" - I guess he means the bolts of lightning - "were close enough to produce EMF in the network wiring.  The damage was limited to one router and a very important server.  Apparently the surge got through the UPS and scrambled the boot volume enough to fill the event log with disk alerts.  A closer look revealed that the bad sector table on the disk itself was damaged.  I have good backups, but it takes forever to restore that large box.  So I gave SpinRite a shot at it first.  I set SpinRite to Level 4 and just let it run.  Six hours later, SpinRite reported success.  The stats in SpinRite showed that there were 1,310 bad sectors recovered."



LEO:  Oh.  Is that a lot?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  That's, I mean, to have - I mean, SpinRite can be recovering sectors, but my guess is that this bolt of lightning sort of tipped the machine over, but that it was already close to having problems.  To me that feels like long-term accumulated problems that SpinRite came along and said, well, I'm glad you're running me now.  Let's fix all of this stuff.  So he says, "I rebooted the box, and it's been purring like a kitten ever since.  As you can imagine, I'm one very happy user."



LEO:  Yay.



STEVE:  So, yeah.  Another fun story.



LEO:  Yay, that's really great news.  All right, we're going to talk about, in just a second, we're going to talk about getting - cracking GSM.



STEVE:  Switching back to land lines.



LEO:  Yeah.  That might be the subtext, the subtitle:  Why you don't want to use a cellphone for anything important.  So this is - this applies to current GSM phones; right?  This is not...



STEVE:  Yeah.  GSM, well, it applies to the world.



LEO:  Every, yeah, because everybody uses it.



STEVE:  The acronym is Global System for Mobile.  That's GSM, Global System for Mobile communications, GSM.



LEO:  Okay.



STEVE:  It currently has three billion users worldwide.  GSM has 80 percent of the cellphone market spread through 200 countries.  There's a GSM alliance that are the group that sort of hold the spec and manage the spec.  Everything about this is worrisome.  I mean, from day one, the fact that they were keeping this algorithm, their cipher, a secret, rather than allowing it to be exposed publicly, tells you, I mean, it was like the first thing to worry about.  We've talked often about the dangers of relying on security through obscurity.  It's not that some obscurity can't also be useful.  But relying on the obscurity is something you never want because nothing remains obscure forever.



Especially, and we've also talked about this, when every single cellphone user has a handset which is able to decrypt GSM.  I mean, by definition.  It's just like DVD players running in your living room that are decrypting Blu-Ray.  Well, that didn't last very long, Blu-Ray encryption.  Similarly, everyone with a cellphone is holding the technology to do the decryption because it has to in order for them to have the conversation.  So it wasn't long before the so-called cipher algorithm in GSM was reverse engineered.



And we've also talked, for example, about the problems that WEP, the Wired Equivalent Privacy, the original oldest version of the WiFi cipher had.  The problem was that it was designed at a time when we didn't have today's level of RAM, CPU power, power-saving technology.  So the designers deliberately came up with an algorithm-sparse approach.  And unfortunately, GSM was designed back with that same philosophy in that same era.  Because it's an old spec.  It's back from the '80s.



The idea is, again, very much like WiFi, or like WEP's WiFi, it is a pseudorandom bitstream cipher, meaning that it's not a block cipher.  And we've talked about various types of crypto many times in the past.  It's not a block cipher where you take a block of bits, and a sophisticated algorithm turns it into another block of bits where there's no way on examining it to see what the transform is between those.  Instead, this is an XORing approach where you have a generator of pseudorandom data where, bit by bit, you XOR, you exclusive OR the output of this generator with the data you want to encrypt.



And when you, as we've also said before, when you do that, when you exclusive OR, essentially you are pseudorandomly flipping the bits of the so-called plaintext to create the ciphertext.  Then the person at the other end is able to generate exactly the same pseudorandom bitstream, so they flip the bits.  And exactly the same bits that you flipped, they flip back; which, again, takes that ciphertext and returns it to plaintext, that is, decrypts it.  So it's conceptually simple.  And if you have a source of really good pseudorandom bits, that is, if the pseudorandom data generator is high quality, there's really nothing wrong with it except that there are problems with so-called known plaintext attacks.  And we've talked about this actually just recently when we were talking about the attacks on WiFi, the sort of the slowly encroaching attacks.  Remember two weeks ago we talked about the TKIP - I guess it was last week.



LEO:  Yeah.



STEVE:  The TKIP attacks where they rely on the fact that the attacker knows some of the bytes in the packet.  Well, if you know what the bytes in the packet are, and you know what the ciphertext is, since the relationship is just an exclusive OR, you can exclusive OR what you know and what you see as ciphered and get the key stream out of that.  So this whole XORing is just not a very secure way, fundamentally not a secure way to do things.  But it's incredibly inexpensive.  It takes a few transistors, literally, to perform an exclusive OR operation.  So it's because it's so economical in terms of hardware implementation - and even, if you did it in software, the same thing - that it tends to get used by older technologies.



So where do we get - well, first of all, I want to say that what happened in the news recently that we talked about a couple weeks ago that caused me to say, okay, I'm finally going to talk about GSM, was there was this news that some - that within a couple months there was going to be publicly available, open source technology to allow anyone to decrypt cellphone conversations.  Well, that may well happen.  But what's annoying to this hacker group is that these problems have been known for a decade and have been pooh-poohed.  And in fact this GSM Alliance is still pooh-poohing these issues.  In response to this recent news story, they said among other things that this would require the construction of a large lookup table of approximately two terabytes.  This is equivalent to the amount of data contained in a 20-kilometer-high pile of books, they said.



LEO:  Oh, yeah.  And of course we'll be using books to store those tables.



STEVE:  And monks to transcribe the data.



LEO:  What the hell?  That's just FUD.  Or what's the opposite of FUD?



STEVE:  Well, exactly.  And I'm thinking, two terabytes.  Then I think about your Cottage up there.



LEO:  I'm just looking at one hard drive, it's two terabytes.



STEVE:  Exactly.



LEO:  C'mon.



STEVE:  And then they said that - they said, "However, before a practical attack could be attempted, the GSM call has to be identified and recorded from the radio interface.  So far, this aspect of the methodology has not been explained in any detail, and we strongly suspect the team developing the intercept approach has underestimated its practical complexity."  So when I saw that, I said, okay, let's - and I wanted for our own listeners to sort of bring this home, to make this real.  It's like, okay, how do you get this stuff out of the air?  Because of course before we can start deciphering anything, we have to have something to decipher.  And we've all got cellphones, but they don't have digital interfaces that send their bitstreams out.



Well, it turns out all of that work has been done for us, Leo.  There's an incredibly cool technology called a USRP -  I love it that you would tend to say "usurp" - the USRP, the Universal Software Radio Peripheral.  It's produced by a company called Ettus.  That's the guy's last name.  So www.ettus.com will take you to his site.  It's open hardware in the same spirit as open software, meaning that he's just producing it, not making a ton of money, but doing all of the hardware engineering work for people who don't want to do it themselves.  But somebody who wanted to save some money and had the ability could certainly do that, as well.



It's a hardware platform, literally, about a seven-inch by seven-inch square circuit board.  The first iteration, the USRP 1, or just USRP, had a USB 2 interface.  You can then get daughter boards that span various ranges of radio frequencies.  And this thing runs all the way from zero, that is, from DC essentially, to 5.9 GHz.  So that's everything you could want.  You can use it to experiment with GPS signals that are at a couple gigahertz, with AM through WiFi and beyond.  This is a general purpose radio transceiving peripheral.  The second version has a gigabit Ethernet interface rather than USB 2.0 because they wanted to be able to operate at larger bandwidths and so have a greater data flow in and out of this board.



The first one costs $700.  The second one is $1,400.  So we're no longer talking hundreds of thousands of dollars and arcane hardware and stuff that only large corporations and governments can afford.  You can go on their site.  You can click the button, "Buy This."  Then they have daughter boards which configure it for different ranges of frequencies, and there's documentation about which one you want for GSM.  So you get one of those.  And then you get an antenna with a cord, and you plug it into your laptop.  So...



LEO:  Is this legal?



STEVE:  Everything is legal, even decrypting your own conversations, just not somebody else's.



LEO:  So buying the equipment and recording the calls is completely legal.



STEVE:  Buying it, yeah, buying it, the knowledge, the ciphers, every stage of this is legal unless you decrypt somebody else's conversation.  And of course you wouldn't want to do that by mistake.  So this notion that this is difficult to do just no longer holds any water.



There's also a fantastic project called the GNU Radio project.  John Gilmore has invested about a third of a million dollars in funding this.  It is a general purpose software radio project developing all of the modules that go behind this piece of hardware.  It's, of course, open source also.  Lots of people contributing and doing all kinds of cool stuff.  So, for example, I mean, you literally could build your own GPS system.



There's a company called Path Intelligence which uses this board, the software from the GNU Radio project, to track people in shopping malls, to aggregate data about the foot traffic patterns.  They have a couple of these radios stationed around the mall.  And by using literally the timing information from all the cellphones that everybody in the mall is walking around with, they're able to track individual people.  And they, of course, don't care who these people are.  But cellphones are generating their little handshake with the cell towers constantly.  So that allows them, for example, to see how many, like how much traffic the various restrooms get, who stands in front of what window for how long, how many people go up the stairs versus go up the elevator or the escalator.  And so they're able to basically track individual people using this technology.



So again, we're now at the hobby level.  We're at the level where the hobbyist with a couple thousand dollars can - needs to know nothing about radio and even hardware.  And even all of the preprocessing steps for demultiplexing the data and analyzing it and performing spectrum analysis and finding the channels and everything, all of that's been done.  There's even some people have taken - they're not at the GPL licensing, but they are - so they're proprietary licenses, but free, but they're open source and free for personal use, where turnkey packages to pull all this data together have been produced.  There's even one which abstracts this USRP, this Universal Software Radio Peripheral, making it look like a network device so that Wireshark, our favorite packet capture utility, is able to  capture GSM packets and decode them and show you all the bits and all the protocols and everything going on in a stream that you capture.



So, I mean, we're way far along in making this possible.  In my opinion, this GSM Alliance is - they're saying what they have to say politically; but, if they really believe what they're saying, that they're in serious denial because this is no longer James Bond government-level sci-fi stuff.  It would be entirely possible for a company who wanted to do some surveillance of a competitor to equip a van with some of this equipment, spending only tens of thousands of dollars, park it across the street from a competitor, aim their antennas at the competitor's building, and spend a day just streaming in, sucking in all of the cellphone traffic that is being transacted by the employees within the building, and then drive the van off and decrypt those conversations offline afterwards and find out what was being said.  I mean, it is no longer difficult to do.  It's entirely possible.



So the problem is that, not surprisingly, this is old technology which was built to be safe enough then.  One of the other concepts that we've talked about several times in the last few weeks is this - in fact, it started with this notion of how long was a voting machine secure.  We talked about the idea that security has a lifetime.  And you'll remember that one of the questions we dealt with in the Q&A last week was some guy said, well, if I stored something that was encrypted today, then waited 10 years or 20 years, assuming that that encrypted data was still valuable, what happens if decryption technology and cracking technology get so much better in the intervening decades that I can then decrypt something from history that's valuable that I wasn't able to decrypt at the time that it was current?



LEO:  We had that question last week, didn't we.



STEVE:  Yup.  It's a really good question.  And so similarly, here when we talk about this GSM Alliance's pooh-poohing the idea that you would need two terabytes of data, well, back in 1980 that was, you know, terabytes, it's like, wait a minute, how many zeroes is that?  Now you're, like, using those things for doorstops, Leo, those drives.  So we have seen an increase in the practicality of attacks.



Now, the technology that GSM uses for generating pseudorandom data is unfortunately weak.  And they did rely on it being kept secret, which of course is not something you can rely on.  All these secrets are going to get out over time.  There were assumptions over the years about the exact algorithm which were locked up in the silicon of chips.  And at one point someone physically reverse-engineered the algorithm from the chips and figured out exactly what was going on.  And it uses a technique that we've never talked about before.  It's a so-called Linear Feedback Shift Register, LFSR.



The idea is you have a - first of all, a shift register is a sort of a - you can think of it visually as a long string of bits contained in a hardware register.  And when, on the event of a so-called clock pulse, this shift register moves all of the bits, the ones and zeroes, one place to either the right or left, depending upon whether it's shifting right or shifting left.  But for the purpose of this, let's imagine that this is shifting to the right.  So you have a string of little bit cells.  Upon receiving a clock pulse, every one and zero moves one cell to the right.



Well, you need something to fill the gap that was open.  That is, if the bit in the first position on the far left moved to the second position, then you need to decide whether now what is the first bit of the shift register is going to be a one or a zero.  What they do is they take some few bits stationed in various places in the shift register and exclusive OR those bits.  So often, for example, it's the last three, like the far right bits of the shift register, the last three bits.  They will be exclusive ORed, meaning that if you, like, if you count up the number of ones in the last three positions, if it's an odd number, then the result is a one.  And if it's an even number, or zero, then the result is a zero.  And so you feed that back into the front of the shift register.



Well, this is - it's an approach that's been known for a long time.  It's - once upon a time, before we had really  mature cryptography, it was - people looked at that and said, oh, wow, we're never going to be able to figure out what those bits are doing.  The idea being that when you set the shift register up, and then you run it, that is, you clock it and clock it and clock it, there's a complex pattern of bits that ends up getting shifted into the front of the shift register.  And after 19 clocks, for example, in the case of a shift register that was 19 bits long, well, then you begin to get bits at the end that scramble up what goes in the beginning.  And before long it gets pretty complex.



So what GSM uses is three of these shift registers.  One is 19 bits long.  The second is 22 bits long.  And the third is 23 bits long.  So you've got three different shift registers.  It's important that the period of the shift register, that is, the length of the shift register are different.  And they're different in a complex way.  This 19, 22, and 23, they came out of, you know, because 19 and 23 are both prime numbers, so they're going to have a very long period before - if you imagine these sort of rotating around before they come back into their original synchronization.  So the problem is that what seemed really complex in 1980 and, like, oh, no one's ever going to figure this out, modern cryptographic analysis just looks at it and says, okay, what are we going to do after lunch?  Because this is just not difficult to deal with at all.



The people that are doing the cryptography have come up with a whole bunch of approaches for attacking this.  There's all kinds of weaknesses in the way this works.  The system, by coincidence, 19 plus 22 plus 23, that is, the sum of the lengths, is exactly 64.  So one of the problems is that the entire state of the shift registers at any time has only 64 bits of complexity.  Well, we know that that's no longer enough complexity.  We're to the point with modern computing technology and modern storage and using, for example, the graphics processing units in graphics cards, 64 bits is worrisome.



It turns out that it is possible to use precomputation attacks against this pseudorandom generator.  We've talked about precomputation attacks before, the so-called rainbow tables.  A precomputation attack is one where you do a lot of work ahead of time to generate some tables which you're able to then use afterwards to essentially reverse an unreversible function.  For example, rainbow tables have been used with hash functions where, as we know, with a hash function you feed a bunch of stuff in, and you end up with a result.  Well, for example, if you were to hash a whole bunch of common passwords, you would end up with a rainbow table of the results of the hashing, so you simply - you look for the value you're searching for in the rainbow table, and it tells you what the input was that gave you that value.



Turns out that the same kind of thing can be done with this GSM stream cipher.  There's a precomputation attack.  And it was published thoroughly, completely, in 2003.  A bunch of researchers laid it all out.  They said, here's how we cracked GSM.  We can either have - I think they had, like, a time-complexity tradeoff.  You'd have to listen to two minutes of GSM cellphone traffic, and then you could crack the key that was used to encrypt this.  After two minutes you could crack it in one second.  Or if you listen to two seconds of GSM cellphone traffic, then you can crack it in two minutes.  So if you have more input data, takes less time; less input data, more time.  And they use then tables exactly like we were talking about, basically precomputation tables, the so-called two terabytes that the GSM Alliance was pooh-poohing and saying, well, you know, no one's ever going to be able to produce this.



Well, this cracking gang is putting together a project, very much like the SETI@home project, where a bunch of people who've got unused graphics cards, they have code that runs on the NVIDIA chipset graphics, running 32 threads in the graphics card, doing precomputation attacks, putting together essentially these tables, which will then, once they're assembled, be freely available to anyone.  They haven't really done any breakthrough work themselves.  I congratulate them on taking the theoretical papers and making them practical.  But, and they understand this, too.  What they'll be putting together is the network and the facility for making this available.



And right now you're able to download this stuff and run it on your machine and join the network and begin cranking out this data.  I mean, this is happening today.  So it's very clear that even if you didn't go for the distributed hobbyist level approach, that any major corporation that had any need, certainly any government, can now crack GSM.  You're able to, due to the availability of this kind of inexpensive hardware, you can just suck in all of the GSM channels that are active in a given area, just stream them onto hard drives, and then crack them at your leisure.



LEO:  At your leisure, yeah.  Record them now, crack later.



STEVE:  Yeah.  I mean, it is absolutely the case that we've got - we're using old technology, and storage and processing power has advanced to the point that it no longer provides us protection.



LEO:  Well, and in the GSM Alliance's defense, I mean, obviously nobody's going to put them in a book.  What they're probably trying to say is it's still a bit of a chore.  It's not something that some guy with a scanner down the street can do.



STEVE:  It's certainly the case, you're right, it's not like you buy a scanner at Radio Shack, and you turn it on, and you listen to random conversations.  So at this point you have to have some motivation to do it.  There are other attacks which do not require this kind of table.  I don't want to get into the details of it just because it's really complex.  But, for example, if you knew somebody who was using a GSM phone, and you wanted to crack them, you're able to pretend to be a cell tower to their phone.  If you monitor them, initiating a conversation, the way the GSM handshake functions is that the cell tower comes up with a 128-bit, pseudorandom, one-time token.  It gives it to the customer and says, using the preshared key - in the SIM card is a 128-bit preshared key.  The cell tower, who knows the customer's account, knows what SIM card they have with the preshared key.  So the cell tower gives them a 128-bit token, which is a one-time token, says use your preshared key to encrypt this that I've given you, and give me the result to prove that you're you.



So there's an authentication phase.  And unfortunately the same data is used to produce the session key, which is a big mistake.  You never want to use the same data for authentication and encryption, which is a mistake that GSM has unfortunately made.  And that's a weakness because it allows someone who's listening to that - this random number that comes from the cell tower is in the clear.  So if you're listening to that conversation, you can then subsequently appear to be a cell tower.



There is no protection against re-use, which is another big problem.  We know about the problems of re-use.  So you can pretend to be a cell tower, give the same key to the user, and cause them, since their preshared key is static, you give them the same challenge, essentially, in this challenge handshake.  They will generate the same session key, which now you have.  And so you're now able to decrypt a conversation that you had previously without any use of two terabytes of tables.



There's, like, all kinds of problems.  As I was reading through the research that's been done about attack after attack after attack on the GSM system, you just sit there sort of with your head in your hands thinking, oh, my goodness.  If I were the person who designed this, and I was reading where the state of the art is today in cracking this, I'd just be thinking, whoa, I'm embarrassed.  But they did the best job they could at the time with the resources that they had.



LEO:  Whoa, I'm embarrassed.  I'm embarrassed for you, man.



STEVE:  I'm embarrassed, oh.



LEO:  It's so sad.



STEVE:  Oh, don't tell anybody else you were the guys that did this.



LEO:  But as you point out, how long ago was this?  20 years ago?  I mean...



STEVE:  Yeah.



LEO:  As you point out, it might have been okay then.  The idea of a two-terabyte table then might have been, you know, considered...



STEVE:  Oh, it was - oh, my god, back then, Leo, we had paper cards, right, and paper tape and, well, I guess we were beyond that a little bit.  But we had, what, 10MB was a big deal.  Now we're, you know, you're streaming terabytes of data out of your facility.  I've got terabytes.  We all have terabytes.  It's just that there's been so much change in the technology from then to now that I cut these guys some slack.



The problem is, we're all still using, what is it, three billion people in 200 countries, 80 percent of the cellphone market is GSM, globally.  And it's no longer safe.  Yes, absolutely.  I don't think anybody is going to be spying on their neighbors or caring what random conversations are.  But if people depended upon it for real security, that becomes a problem.  And we've only talked about voice stuff.  But all this applies to SMS.  So, for example, there are banks which are now, as we know, using cellphones and SMS tokens for security.  And they're not safe.



LEO:  I use them all the time.



STEVE:  Yeah.



LEO:  That's how I log into my bank.  I ask them to send me a token.



STEVE:  And again, what's the chance that some random person is going to be going after you?  I agree it's slim.  But targeted attacks, I wouldn't be surprised if, before long, we begin to see reports of GSM cellphone technology succumbing to specific targeted attacks.  It could happen.



LEO:  Yeah.  Well, and you hit the nail on the head when you said this is the kind of thing a government or a business might do, as opposed to Steve Wozniak.



STEVE:  Well, hobbyists, motivated hobbyists certainly now have this within their grasp because all the hardware exists.  You go to a website; you order the stuff.  All the software's open source.  The project will be making these rainbow tables available.  There's all kinds of more active attacks, not just passive decryption attacks, but active man-in-the-middle sorts of attacks that GSM is also vulnerable to that I didn't even talk about.  It's just it's absolutely not something that you could rely on.  So at this point I would say to our listener who asked last week about GSM, or about cellphone Internet, I would say, well, this is where you really want to have your own encryption riding on that channel.  You want to have your own tunnel, like an SSL connection or a VPN, that will protect you from any kind of snooping.  Because otherwise you might as well be using WEP, unencrypted WiFi.



LEO:  Right.  What is your sense of other technologies that are used right now?  CDMA primarily?



STEVE:  I remember something similar about CDMA.  I haven't looked at it closely for comparison.  Like you, I'm curious now to see whether it's the same.  But in this research I was just focused on GSM because I wanted to follow up on the news of what these guys had done.  And it turns out what they - all they're really doing is they're taking six-year-old research from 2003, and they're saying, okay, the papers are published.  Everyone's still ignoring this.  Let's make some noise.  Let's wake people up to this problem because someone ought to do that.  And that's really, I mean, that's the goal of this group is not to foster piracy and hacking, but basically to challenge this GSM Alliance and say, folks, you've got to get your acts together here because this is not secure, and you're in denial.



LEO:  You have your heads in the sand.



STEVE:  Yup.



LEO:  How about data?  We're talking about voice communications.  Data goes over a different channel; right?



STEVE:  Well, data is using the same system.  The GPRS is the packet radio technology.  And it unfortunately uses all the same cipher and the same keys.



LEO:  Oh, wow.



STEVE:  One of the things that you're able to do, one of the other attacks is interesting.  There is a weaker version of the cipher.  There's multiple versions of the stream cipher.  The stream cipher is called A5.  The authentication algorithm is known as A3.  And the key agreement algorithm is A8.  Well, this A5 stream cipher can - there are variations.  There's A5/0, which says no encryption, just in the clear.  There's A5/1, which was the original strong encryption, but it had export restrictions placed on it.  So as a consequence, phones also support A5/2, which is a deliberately weakened, exportable encryption.



So get this, Leo, because this also bears on some of the things we've talked about in the past.  Even though you may have a phone using the A5/1 strong encryption, it also supports A5/2.  Because what if you happened to roam to a carrier that wasn't supporting strong encryption?  Well, the phone would downgrade itself to A5/2.  Well, it turns out there are active attacks which can be perpetrated where you ping somebody's phone and feign that you're only able to support the /2, the weak encryption, which is much easier to crack than the strong encryption.  What we've been talking about is the strongest encryption available.  And so you can essentially get the phone to downgrade itself, but A5/1 and /2 use the same keys.  So you're able to get the phone to run a weaker cipher, which is much easier to crack, and then you're able to gain access to its key.



LEO:  Wow.



STEVE:  So, I mean, it's very badly broken.  It's absolutely not something that we could consider secure.  It is far, far shy of state-of-the-art, the kind of state-of-the-art crypto that we're used to having in everything else we do.



LEO:  You might have had a hint of that when they gave President Obama a special NSA-encrypted phone to use, that maybe perhaps the government knew there was, you know, some issue.



STEVE:  Yeah.  And, well, they knew it because they have a closet full of equipment which is listening in on everyone's cellphone conversations.



LEO:  Right.  They can crack it, so we might assume the other guys can, too.



STEVE:  And it's worth mentioning, too, that all of this is only the in-the-air cipher.  That is, if our government wanted to listen in on our phone calls - I guess we know that after 9/11 that was being done - it's much easier to just wait until the cell tower has performed all of the decryption and turned this back into analog signals and pick it up there.  I mean, you could certainly do that.



The problem, of course, is, as with everything, we've talked about this in the context of WiFi many times, wireless is tempting because this stuff is in the air.  And so there are, like I said, you park a van across the street from your competitor's office and suck in all of the cellphone conversations going on and see what you can glean.  Who knows what you'll overhear?  It's just it's not the case that it's as insecure as analog.  But you absolutely should never depend upon its security, I mean, in any place where you've got super high valuable conversation and there's some reason to believe somebody else might love to know what you're talking about.



LEO:  Especially if you're sending your bank key over your SMS uplink.



STEVE:  Yeah.  And again, it's also worth mentioning that you could just use a big parabolic microphone, parabolic reflector and a microphone, and listen to somebody who's in visual range.  You might not hear the other side of the conversation, but you would get theirs.  So there are other sort of analog, real-world ways to do this.



LEO:  Gosh, yes.  And...



STEVE:  But it's certainly the case...



LEO:  ...I presume that we're moving to newer technologies anyway over time.  And really mostly, I mean, look, you're not going to redesign GSM and retrofit all the towers and retrofit all the phones.  That's not going to happen.



STEVE:  That's the problem.  Now, 3G is a stronger technology.  But the problem is the phones are all able to fall back to the earlier technology, and that provides a backdoor for the encryption.  What you'd really want to do is be able to tell your phone, for example, no longer allow any weak encryption.



LEO:  Oh, that's good.



STEVE:  Unfortunately, the phones are just open, and they're designed to roam and to work wherever they happen to find themselves.



LEO:  When there's a secure phone, like the NSA-encrypted phone that the President uses, they probably use the same GSM or CDMA frequencies and channels and technologies, but they encrypt the data.  They scramble it.



STEVE:  Yes, exactly.  They're running an encrypted tunnel inside of the regular carrier.



LEO:  Got it.



STEVE:  So if somebody decrypts that, all they're still going to get is highly encrypted...



LEO:  Gibberish.



STEVE:  ...really, really pseudorandom noise.  Just gibberish, yes.  And they'll have no way to go any further.  They're blocked by the tunnel that is running inside of the GSM channel.



LEO:  But of course as with VPN or a scrambler technology, both ends have to support it.  And that's why it's not generally used.



STEVE:  Well, not only do both ends have to support it, but again, once it comes out the other end, all of that encryption has been stripped off, and it's back to plaintext again.



LEO:  Right, right.



STEVE:  So part of the mitigating aspect of this is, okay, so what's someone really going to do who wants to know what you're talking about?  Maybe they're just going to be in the booth next to you with their ear cocked with, exactly, just overhearing your conversation in the old analog world.



LEO:  Just listen.  Steve, great, really an interesting subject.  Fascinating.  And of course ties in, if some of this stuff like rainbow tables leaves you scratching your head, we've covered all of the fundamental technologies in previous episodes.



STEVE:  Yup.



LEO:  So you can go back, and I know that there are now 212 and this one, so 213 episodes.  That's a lot of listening.  But you can go back and look at rainbow tables.  We talked about that.  We talked about XORing in the past.  We've talked about crypto in general.  So you can really get a fundamental education on all this stuff from previous episodes.



STEVE:  Well, and we do have the transcripts at GRC, and a search for the transcripts.  So you could put in "rainbow tables" or "XOR" into the search...



LEO:  Exactly.



STEVE:  ...and quickly find those instances where we've talked about this stuff before.



LEO:  Steve, as always, a pleasure.  You'll find the transcripts, the 16KB versions of the show, the show notes and more at Steve's site, GRC.com.  That's also where you'll find SpinRite, the absolute must-have, there is but one, hard drive maintenance utility, the one to get.  And, by the way, recovery, too, as kind of a side effect of it.  It does a great job.  And all of his freebies, lots of security information and lots of programs like ShieldsUP! and Shoot The Messenger, DCOMbobulator and Wizmo, it's all at GRC, Gibson Research Corp., GRC.com.



And we'll be back - normally we record on Wednesdays.  So if you want to watch us live at live.TWiT.tv, tune in at 2:00 p.m. Eastern time, 11:00 a.m. Pacific time, Wednesdays, 1800 UTC.  And you can watch the show then.  And then of course we offer it the next day, on Thursdays, iTunes and Zune and other downloads, as a podcast.  So anybody can get it who has podcatching implements, including Listen on the Android phone.  You can find out more about that at TWiT.tv/sn.  All the protocols are there.  Steve, thank you so much.



STEVE:  Next week we will do our 75th Q&A.



LEO:  Wow.



STEVE:  So anyone who has questions, please by all means go to GRC.com/feedback and tell me what's on your mind, what you want to hear about, topics, suggestions, questions, and things that I've skipped over or forgot to mention, so forth.  And we'll deal with them next week.



LEO:  And this just in, Windows 7 updates were just pushed out, and one of our chatters is downloading them now.  So that answers the question.  Second Tuesdays for everybody now.



STEVE:  Thought that was the case.  And we will talk next week about what happened in the world of Microsoft updates.  I want to find out what that TCP/IP flaw is.  That sounds like a bad one.  So we'll have the news of that next week.



LEO:  Thank you, Steve.  Thank you all for joining us.



STEVE:  Thanks, Leo.



LEO:  We'll see you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#214

DATE:		September 17, 2009

TITLE:		Listener Feedback #75

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-214.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



It's time for Security Now! with Steve Gibson, Episode 214 for September 17, 2009:  Listener Feedback #75.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things secure - privacy, computers, the Internet, all of that stuff.  And our guru of security is here in his locked-down fortress somewhere in Southern California, Mr. Steve Gibson of the Gibson Research Corporation.



STEVE GIBSON:  Yes, Leo, it's great to be back with you again, as always.



LEO:  Good to see you.  I love - for those of you watching the video portion of our show, you'll see Steve's T-shirt.  He bought the T-shirt he talked about a couple of weeks ago.



STEVE:  It just says "NO."



LEO:  No.  With a period.  Which makes it very emphatic.  Not an exclamation mark.  Just a period.  No.  Just no.



STEVE:  No, unh-unh.



LEO:  Does it say anything on the back?



STEVE:  No, it doesn't.  In fact, some people have, like, walked around me in circles wondering if there was, like, some clue.



LEO:  What's the question, yeah.



STEVE:  Some clue to the no-ness.  And it's like, no.  It's just, you know, will I fix your computer?  No.



LEO:  No.  Will not, no.



STEVE:  No.  No.



LEO:  And no matter what you ask, the answer is no.



STEVE:  Yeah.  It's the crusty old curmudgeon T-shirt.  I like it.  Cranky.  It's the John Dvorak.



LEO:  Just exactly what - why is it, when you say "crusty old curmudgeon," the name John C. Dvorak leaps to mind?



STEVE:  I was at a UCI lecture last night about the future of inquiry-based science education in K through college.



LEO:  Oh, interesting.  Oh, how fascinating.



STEVE:  Really interesting talk about, you know, just in general, unfortunately, that this country is - sort of has an anti-science orientation now, where it's - I don't know if it's that back in the '50s scientists over-promised things.  I think that people want easy answers for complex problems, and complex problems often don't have easy answers.  So demagoguery, which purports to give you an easy answer, is more appealing than complex, value-based, evidence-based, non-black-and-white answers.  Anyway, it's a really interesting lecture.  And the friend that I was with saw the T-shirt.  And he said, "So what's with the shirt?"  And I said, "It's the cranky old curmudgeon shirt."  And he said, "Well, I know you think you are, and I know you think I am.  But you're not."  It's like, okay, well, guess he didn't buy it, no.



LEO:  You're not a cranky old curmudgeon.



STEVE:  No, I'm not, really.  It's just...



LEO:  In fact, if anything, I'd say you're an optimist and an enthusiast.



STEVE:  Yeah, it's what makes this sort of funny, I think.  My own...



LEO:  You probably say yes far more than you would like to care to admit.



STEVE:  It's my own joke.



LEO:  Yes.



STEVE:  Yeah.



LEO:  Well, I think it's kind of neat that you go to lectures at UC Irvine and study up on stuff.  I mean, you could just sit back and read sci-fi all day.  But no.  You're expanding your mind.



STEVE:  Nice to know what's going on out there, yeah.



LEO:  My question, I wonder, I mean, I certainly recognize that anti-scientific bent.  My question is, is this new?  We interviewed on Dr. Kiki's Science Hour the author, I wonder if this is the guy who was speaking, of "Unscientific America"?  Was it him who was talking?



STEVE:  No.  He's sort of a politician/educator who spent about 14 years in Washington.  I mean, and he is a scientist.  At one point in the Q&A afterward someone asked him something.  And his immediate response was, well, I'm not aware of that.  Do you have - is there any evidence to substantiate that?



LEO:  Oh, I love that.  That's a good question.



STEVE:  Oh, it was wonderful.  It was like - and frankly, I mean, he had no patience for talk radio and talking heads arguing with each other.  I mean, he really saw sort of - he just came back, he explained that two days ago he'd been in China, and he was meeting with some of the top political management people in China on the topic of health and healthcare.  One of them said that they weren't really sure what was going to work, but they were doing something one way over in this province and a different way over in that province...



LEO:  Yeah.  They experiment.  It's really interesting how they work there.



STEVE:  Well, and he said that most of the management of China, for lack of a better word, are engineers, that the upper level political infrastructure are a bunch of engineers, and that they're applying scientific principles rather than just...



LEO:  Interesting.



STEVE:  ...than arguably maybe large corporate lobby-driven politics, which seems to be what our system has fallen into.



LEO:  Not that they're the paragons of virtue there.



STEVE:  No, there's lots of problems, too.



LEO:  Just don't be an ethnic minority, everything's fine.  But I do have to say that it's a very big country.  And I don't know how one manages a country of 1.3 billion people spread over that kind of land mass anyway.  It's a very difficult thing to even contemplate, especially with a planned economy.  Must be very, very difficult.  But I just think of - and I think back to the '20s when you had people like Aimee Semple McPherson, we had these radio demagogues.  It's not - it kind of seems to be a strain in American life.



STEVE:  Well, one of the points that he made that really...



LEO:  The Scopes Trial.



STEVE:  One of the points that he made with me that really stuck was he said that the science textbooks that we're using have about - the way he phrased it, about 1,600 - he didn't use the word "jargon."  I can't remember exactly what his term was.  But 1,600 words that are used in textbooks which are unfamiliar to the kids reading them.  And his point was - and he used the word "analyze" as an example.  The word "analyze."  And at home that word is not in use.  It's not being used.



And so what's happening is, kids are opening these textbooks which were written by well-meaning educating authors.  But they're fundamentally using words like "process" and "analyze," which there is no context for, unfortunately, in the mind of the reader.  So the message is not getting through.  And there was a sense of his own frustration that there wasn't enough educational substrate from the home bringing kids into the school, so that it was difficult for them to get any traction with the material that they were being offered.  So sort of this concern about the dumbing down of the populace.



LEO:  Right.  Well, certainly always something to pay attention to, that's for sure.



STEVE:  And not a problem we have here with our listeners.



LEO:  No.  In fact, this show is challenging for almost everybody who listens.  But that's - you know, your brain will grow if you listen.  So today's a Q&A day.



STEVE:  Yup.



LEO:  214, it's even, mod 2.  So we have questions.  Do we have any security news or updates?



STEVE:  Got a bunch of stuff, yeah.  Remember that last week, just as we were recording, because we were recording a day early in order to move the recording out of the way of the big Mac event, the iPod fiesta, that we knew that this was - that was going to be the second Tuesday of the month, and Microsoft was releasing things.  While we were recording you had looked them up because they had been published just as we were going live and recording.  And the thing that I stuck on among those that you enumerated was a bad, apparently bad TCP/IP flaw that was going to be fixed.



LEO:  Right.



STEVE:  Well, it turns out that this was something we have covered in the past, that surfaced last year when it was sort of repopularized, although it was originally discovered in '05, so four years ago.  And that was the Sockstress problem, the idea that there was a denial of service attack, generally powerful, that required low bandwidth, not a flooding, just completely overwhelm some spot of the Internet with huge amount of inbound traffic, but rather this was taking advantage of some of the inherent proper functioning of the TCP protocol where there's something called the TCP window, which is sent, or as they use the term, "advertised," whenever one end is acknowledging the receipt of data to the other.  There's this TCP window which says, oh, and by the way, this is how much buffer space I currently have that allows the other end to asynchronously send ahead.  That is, it's one of the ways that TCP so gracefully and nicely deals with the delay of packet traveling across the Internet.  If it was necessary for each end to acknowledge the receipt of every single packet, then the round trip time would limit the amount of data, the rate of data that you could send.  Because if one end sent a packet and then waited for confirmation of its receipt, then that would obviously be a big problem.



So the designers who understood this, this whole notion of packets moving from router to router between end points, they said, okay, we need a way of allowing us to send ahead, to like know how much we can send and not need everything acknowledged, not need to wait for this roundtrip time from the destination and back to the source.  So they created this notion of a window where the recipient is constantly saying, okay, here's how much buffer space I've got.  So the way it works is, it's a guarantee of how much can be sent at the time that that window is received by the sender.  The sender looks and says, oh, okay, good.  The other end is claiming that he's got 16K, so I can send - I know I can send at least that much safely without there being any problem.



Well, what happens is, if the other end says, oh, hold on a second, I have no space, I'm full right now, then the sender is blocked from sending anything.  And then if no additional change occurs, the sender will periodically send what's called a "window probe," send an acknowledgment to traffic that's already been received.  And that induces the other end to acknowledge that and in the process get an update on the window status, hopefully finding that some new buffer space has been made available.  So this is fundamental to the way TCP has always worked.  And it's something that just sort of wasn't really on anyone's radar until this notion - it was really just sort of a repopularization of an old problem, the whole Sockstress that we talked about, about a year ago.



So it turns out that that's what Microsoft just fixed.  And they didn't fix it on their older OSes.  Their claim is that the stack, the TCP/IP protocol stack, as the term is used, in Windows 2000 is too old.  It doesn't have the required flexibility.  And in fact that's also the case, I believe, on XP.  So it's not until Windows 2003, Vista, 2008 Server, and Windows 7 that they've got whatever it is that they're doing in those stacks.  My sense is that Microsoft just figured, well, it's old.  Here we are in 2009.  We're not going to worry about 2000 anymore.  And so they did not fix that.  There is no fix for that.  In order to fix it, you would need some sort of third-party firewall box or something on the outside of the server essentially being a prophylactic to protect the server against this kind of attack.



So Microsoft fixed it.  Cisco also fixed it.  And this is still an outstanding problem.  Until, I mean, it's tricky to deal with because you need some sort of an overseer because it's legal for the other end to say I've got no buffer space.  So you just can't drop a connection that says that.  You need to detect that there's malicious intent, which you would detect by a succession of connections from the same IP, all saying that they've got no buffer space.  And at some point, in sort of an overseer mode, you'd look at all of the connections you had coming into your server and say, wait a minute, something looks fishy here.  And then you would proactively drop those connections and probably blacklist that IP so that it was no longer allowed to obtain any connections to the server.  Or maybe just terminate the oldest ones and allow it to keep making new ones, which would prevent there from ever being a buildup.  So that was the issue that came to my attention when you enumerated the problems that were fixed in last week's update.



LEO:  Okay.  All right.



STEVE:  Apple, we talked about Snow Leopard v10.6 and how it was downgrading the version of Flash Player, Adobe's Flash Player, that it installed.  And you probably know the Snow Leopard has been updated almost immediately to 10.6.1 to incorporate the latest version of Adobe's Flash Player.  So Apple responded very quickly to that.  It was obviously an easy thing for them to do and something that was likely an oversight or - it certainly generated a lot of press.  And so they responded to it immediately.



Firefox has also been updated.  It's now - the 3.5 version thread is now at 3.5.3.  And the 3.0 version thread is at 3.0.14.  So any Firefox users, you may want to just check to make sure that, you know, just check for any updates, and Firefox will let you know.  And it's just, you know, your standard security fixes and stability improvements.



I did move a couple of my machines, Leo, from 3.0, where I had been sort of stubbornly staying, over to 3.5 because a couple times Firefox was saying, hey, we've got something really new here, and what's wrong with you?  I thought, okay, fine, I'll give it a try.  And it's working just fine.  And I did discover that when I reinstalled the various add-ons that I like to use, with a little bit of jiggering I was able to get them to work under 3.5.  So I'm able to use 3.5 and have the various add-ons that I like.



LEO:  Yeah.  Yeah, I love 3.5.



STEVE:  And something interesting happened.  I don't know if you had picked up the news about a major incursion into Apache Software Foundation.



LEO:  Uh-oh.



STEVE:  Yeah.  This is...



LEO:  Everybody uses this for their web server.



STEVE:  Well, yeah, it's not that - it's not the web server itself.  It was their network got hacked.  The Apache Software Foundation network got hacked.  What happened was, the exploit that we talked about several months ago in Linux, the kernel-level privilege escalation, privilege elevation exploit, that was a local root exploit, was used on - and this is really interesting, I mean, the way this attack happened.  It was used against sort of a off-the-mainstream, sort of ancillary server, ApacheCon.com, A-p-a-c-h-e-C-o-n, which is the server for the Apache Software Foundation Conference.  And it was DV35.ApacheCon.com that was running an unpatched version of the CentOS, Linux CentOS, which still had that vulnerability that had never been patched.



So some bad guys were able to get into that.  They fully compromised the machine, got root, destroyed the logs, which meant that for the Apache guys, figuring out what had happened exactly was challenging.  Then they used an SSH key which belonged to the backup account to gain access to the main server, which was People.Apache.org.  And so there was a, sort of on the subsidiary machine was a - it had backup privileges on this main machine that allowed them to get the SSH key.  And the machine that they got it to was what Apache calls a "staging server."



So what happens is there's like a staging server for their software, and then a regularly scheduled rsync process copies the staging server to the production server.  So they were able to compromise the staging server and install CGI scripts, which they added to the document root folders.  And then when rsync happened, even though they had no access to it, that put all of the changes that they had made to the staging server onto the main Apache.org public server.  And the CGIs allowed the bad guys to obtain remote shells.



So the Apache Software Foundation guys said, you know, our software, our source code is fine.  We've determined the limits of this incursion.  And they were very open about it.  In fact, the security community has congratulated them with being so open about these are the things that we did right; these were the things that we did wrong.  Interestingly, one of the things that they felt - that turned out coincidentally to be right is that they do not have a homogeneous server farm.  They have a heterogeneous server farm.  They've got Linux, they've got Sun, they've got...



LEO:  And that's a good thing; right?



STEVE:  They've got Free, yes, they have FreeBSD.



LEO:  It's not a monoculture, yeah.



STEVE:  Exactly.  And so it was the fact that they had a FreeBSD 7 system that did not have this problem, and the Sun didn't.  Only this one sort of off-to-the-side Linux machine did, even though there still was a route in.  And I think for our listeners that's sort of the coolest thing is that - well, I mean, cool in an unfortunate fashion - is that even though you get a little bit of foothold off on some machine on the side, once you're there, then that machine on the side may have some sort of privileges or view into some other machine.  And little by little you sort of gain entry into the main network, which is exactly how this happened.



So the Apache guys, I think, are to be complemented for saying, okay, this is what happened.  This is how it was done.  And so what they did was, one by one, they actually went completely offline.  They brought their systems down.  They did have mirror servers, so they were able to bring up sort of a backup presence while they took a good, long, hard look at all of the machines that might have been infected.  And then one by one, once they were sure that those machines were clean, they brought them back up online and learned some valuable lessons about how to be better safe in the event that one machine in their network gets compromised.



And, for example, they use these CGI scripts to dynamically generate the web pages that people visit.  And what they found in looking closely was that they had the ExecCGI enabled globally, even though it was not being used globally.  And had, for example, it only been enabled where it was needed, this exploit would not have been possible.  So...



LEO:  That's a common error on a lot of web servers, actually.



STEVE:  Yeah.  Again, it's sort of - it's a little bit like the old approach that firewalls took of being open, and then selectively closing problems, instead of the other way, which the modern approach is that you close everything, and then you selectively open only those services and ports that you know you need.  So I thought that was interesting.  Also The New York Times got hit with a JavaScript-based scareware attack.



LEO:  Yeah, I saw this.  Oof.



STEVE:  Yup.  And it's interesting because it's a problem that, again, was foreseeable.  The New York Times, like many other websites, are serving ads from a third-party server.  We've talked about this often.  It's the way cookies are used to track people is the much-maligned DoubleClick.net company are an active server of ads.  Well, if bad guys are allowed to submit ads to third parties, those then get served to some public server.  And unfortunately it's possible to have scripting in an ad, of all things.  And that was then - it was scaring people, popping up a window, redirecting them to some other server that popped up a window and said, oh, you've got some bad stuff on your system.  It's infected with malware.  Click here to scan, and we'll take care of you.  And of course it was 100 percent malicious.  And so The New York Times is going to be modifying their own behavior and somehow coming up with some way to control the ads, which they obviously didn't have before.



LEO:  It was interesting because the people who were doing the malware posed as - I believe it was Vonage.  The New York Times won't say, but the reports are they were posing as a legitimate company, and I believe it was Vonage, for a whole week, putting what would appear to be normal-looking ads up for a whole week and then...



STEVE:  Oh, to establish a baseline.



LEO:  Exactly.  So they were paying good money out for ads for something they didn't even own.  And then the weekend hits, when I guess they figure, well, nobody - there'd be less oversight on the weekend.



STEVE:  Ah.



LEO:  That's when they stuck it in.  It's very interesting.  And, you know, I talked about it on the radio show because on Sunday the Times put up this warning.  And it was still happening when they put up the warning.  It took them a while to get rid of it.  So a very, yeah, sneaky - these guys are sneaky.



STEVE:  Yeah.  I mean, we can count on that in the future.



LEO:  Well, you remember it happened at MySpace.  There was malware put in one of the rotating ad banners because a lot of these guys have automated ad systems running, but it can submit an ad; you know?



STEVE:  Exactly.  So you just post the ad, and it's automatically accepted, and it goes into a bin and is rotated through all the websites that are clients of that provider.



LEO:  It's pretty obviously a bad idea.



STEVE:  Bad idea.  Not secure.



LEO:  No.



STEVE:  Adobe has announced that they're going to be delaying their quarterly update from the 8th of September to October 13th.  So of course that passed by already.  But they would have normally done it on the 8th, and they're going to be moving it to October 13th because this Microsoft Active Template Library, that ATL problem which has been so pervasive and has bitten so many people, has also bitten Adobe.  And so we will be seeing an update to Reader and Acrobat and, I would imagine, Flash come next month.  But it won't be Adobe's regularly scheduled quarterly update.  And you know how I feel about that.  I mean, it just seems so ridiculous that that's the approach...



LEO:  Quarterly is not often enough.



STEVE:  No.  And they have - they've already had several emergency updates.  We talked about how, well, that didn't even last a quarter.



LEO:  The minute they announced it, pretty much.



STEVE:  Yeah, yeah.  And in something a little creepy, there was another story that came across my radar.  There's some web-monitoring software which is available at retail under the brand Sentry and FamilySafe.  It's produced by a company called EchoMetrix.  Deborah Yao, reporting for the Associated Press, learned that this company, who makes this consumer retail web-monitoring software, is reading the private chats of the children that are being filtered by this...



LEO:  Terrible.



STEVE:  ...in Yahoo!, MSN, AOL, and other services, and selling the information from that to third parties.



LEO:  Oh, my goodness.



STEVE:  So, and in recognition that there are federal privacy laws to protect anyone under the age of 13, in the fine print it says that in recognition of federal privacy laws, data on kids, on children under 13, it says the agreement states that the company has, quote, "a parent's permission to share the information" if the user is a child under age 13.  Which just - several of the people who responded to this said that this one of the creepiest things they had seen in a long time.



And there is no mention of this in the licensing agreement.  The agreement states that the company reserves the right to pass along data to, quote, "trusted partners," unquote, and that the confidentiality agreements with those partners prohibits them from sharing the information with others.  But still, they are selling this information to third parties.  And there's nothing in the relationship that the typical end-using consumer has with EchoMetrix, this company selling Sentry and FamilySafe, makes that clear.  There's some provision to opt out if you go to their website, but not in the UI of the software at all.



LEO:  Ugh.



STEVE:  Creepy.



LEO:  Yeah.  Oh, that's just appalling.  Man, I think of how the parents must feel on that.  That's terrible.



STEVE:  Well, hope the word gets around because it's the wrong thing to do.  I did have sort of an interesting little SpinRite story that I thought people would get a kick out of, also because this person who asked to remain anonymous works in the cancer center of a major university medical center.  And I guess he first tweeted because his note was, "Just thought I would retweet what I sent out today on Twitter."  And so I guess what he said on Twitter was, "Computer gods bless SpinRite.  Boss's PC fixed."



LEO:  Yay.



STEVE:  "Into which volcano must I throw a virgin?  Where do I find a virgin?"  And I guess that used up his 140 characters.



LEO:  That's 140 characters.  But a good use of those 140 characters. 



STEVE:  And so then he said the story beyond 140 characters continues.  He said, "Steve, yesterday while the boss was out of town I stopped in his office to do the weekly check on his PC, make sure his mailbox was not filling up, run the monthly Windows patch push tested and packaged by our IS staff ahead of time, but refused as an automatic push by my boss who, like me, is old enough to remember these pushes causing problems."  He said, "It's been years, but he's the boss.  I ran the push, and the computer locked up.  Doing a Ctrl-Alt-Del forced a reboot, and it went into Blue Screen of Death."  And so he says, "A+ certified I may be.  My main job is systems management, not PC maintenance.  And more to the point, especially not on my boss's PC.  He keeps all his documents and stuff on the hard drive."  And says, parens, "(He is old and remembers...."



LEO:  Hey, I resent that.



STEVE:  "(He is old and remembers server crashes, too.)"  Apparently where he lost all the stuff that he had on the server.



LEO:  Yeah, I remember that, too.



STEVE:  Yeah, I remember that.



LEO:  I remember service crashes.



STEVE:  And he says, "More terrifyingly, I realized he had turned off the remote backup I had installed for him, apparently because it slows down his PC.  I called in the institutional techs, but none of their full-time professional diagnostic repair tools and tricks could get around the Blue Screen of Death.  We also did all the standard ones - last known good boot and last known good configuration - and could not even reinstall the OS because it would not recognize the existing XP SP3.  We are a, quote, 'Reimage first, ask questions later shop here,' except in cases...."



LEO:  Which is probably a good policy.  Except for data.



STEVE:  Yeah.  Except, exactly, except - and he says, "...excepting cases like this, so this was not surprising.  To my relief, we were able to slave the drive to another machine, so I was able to get his data onto another hard drive.  To be fair to Microsoft," he also noted that "some of the motherboard's capacitors looked bad, and that might have been the real source of the problem."  Sounds like he changed tense there on me, but anyway.  So he said, "Either way, I still faced having my boss come home the next day with no PC.  I got out a laptop and began very roughly configuring it for him, knowing it would lack most of his specialized software.  But as the tech finished his last effort, I remembered the copy of SpinRite I had purchased for myself."  He says, "I've used it one time when it was unable to help a very dead drive, and another time when it saved the day, but mainly use it for my home preventative maintenance.  It was time to go home, the end of the day.  So I popped in my copy of SpinRite and left it saying it was going to take seven hours to run.  I went home worrying if I was going to have a job the next day."



LEO:  Oh, boy.



STEVE:  "Set my alarm early..."



LEO:  Oh, poor guy.



STEVE:  "...to beat the boss in to work, and literally dreamed about the problem several times."



LEO:  Oh.



STEVE:  He said, parens "(All the dreams could be called nightmares.)  When I arrived, SpinRite said that it had completed.  There was one unrecoverable sector.  I booted and was amazed to see everything back to normal and running.  Needless to say, due to the leaky capacitors, I am trying to get him a new PC before anything else happens, and I am backing up until it is safely installed."  And then what I love was his final little note.  He said - remember that he works for a cancer center in a major university medical center.  He said, "P.S.:  Everyone here is as crazy about Vitamin D as you are."



LEO:  Really.



STEVE:  And then he said, "Withhold name if used, please."



LEO:  I wonder why.  Do they make Vitamin D, do you think?



STEVE:  No, because it's such a strong anti-cancer agent.



LEO:  Oh, and they're anti- of course.



STEVE:  They're a cancer center.



LEO:  Cancer center, yeah.



STEVE:  Yup.



LEO:  So they know.  That's very interesting.  By the way, we've been looking at ratings.  And the ratings for that Vitamin D episode were about, let's see, almost double.  So I don't know whether - what I suspect has happened is that people who listen to Security Now! on a regular basis shared it with people who don't listen to Security Now!, but might be interested in Vitamin D.  Because it just - the numbers on that thing were through the roof.



STEVE:  You know, Leo, we both thought I was a little crazed when I did the Q&A the week after, all about Vitamin D.  But I was in this, sort of this fog because I got an unbelievable amount of feedback.  I mean, it was just...



LEO:  Yeah.  You were on the right track, absolutely.



STEVE:  It was crazy, you know, so...



LEO:  I mean, it's not something we want to do every...



STEVE:  No.



LEO:  It's not a vitamin show.  But at the same time I think, you know, everybody trusts you.  They know that you're very level-headed.  You're not a faddist.  And you do the research.  So when you were saying all this stuff, I think people shared that, they must have, like crazy.



STEVE:  Yeah.  Well, and I had hoped to bring the same level of scientific pursuit to it that I normally exercise in my own life.  And anyway, so it was valuable, and I was really glad we did it.



LEO:  Well done.  Shall we move to the questions and answers?  Because I have some good ones for you.



STEVE:  Yes, you do.  I happen to know.



LEO:  You picked them, yes.  No surprise to you, Mr. Gibson.  Starting with question one, an anonymous GSM provider - hmm, phone company - in the UK, in England.  We did an episode, of course, last week on GSM cracking.  He or she responded:  Hi, Steve.  I just listened to your podcast on GSM cracking.  I work for a 3G operator, and we are very - underscored, capitalized, and bolded - aware and wary of the issues with GSM's 2G vulnerabilities.  I thought your assessment was mostly fair.  So here are a couple of additional points:



Data GPRS - the packet radio service that kind of predates 3G data - doesn't use A5/1 - or as they say in the UK, A5 stroke 1 - it uses GEA/1.  And yes, this is similar in structure to A5/1, but this would require a different rainbow table computation.  Still vulnerable to rainbow tables, I guess.



STEVE:  Yup.



LEO:  The design of GSM security was to give a similar level of privacy as is provided by the wired network.  Where does that sound familiar?  Oh, yeah, Wired Encryption Protocol.



STEVE:  Uh-huh.  Doesn't that ring bells.



LEO:  Oh, that rings a bell.  So your attack on a competitor has been achievable in the past.  All you'd have to do is open the manhole outside the building and tap into the analog wires, or the T1 - or E1 as they call it in Europe.  Okay.  Okay.  That's, you know, they're setting a standard.  A low standard, admittedly, but they're setting a standard.  



Fixing the problem:  GSM was designed with the ability to add new algorithms, so a total of seven algorithms are possible.  About three years ago the GSM Association published A5/3 and has been moving this forward, albeit at a frustratingly slow pace.  In our defense, it's hard to get 400-plus operators and many phone manufacturers to spend money on some theoretical threat.  That's reasonable.  That's really what's difficult about all of this is legacy hardware.  We even, I think, addressed that.



Even with the current publicity, there will be operators, most operators probably, who will not implement A5/3 as this will cost them money.  It's hard enough to convince the big European operators to spend money on implementing this.  Happy for you to read this on your podcast provided you don't mention my name.  And we did not.



STEVE:  Yeah, so this is, I mean, this is the problem we have is here's a direct message from a listener who is with a GSM provider, who acknowledges that, while more security is available, it is expensive for systems to be fit with it, to be retrofitted.  Consumers' devices have to be upgraded at the same time, synchronously.  He also, I loved how he talked about how, well, it's like Wired Equivalent Privacy.  We only designed it to be as secure as the wire would be.  And as we all know, you could tap wires if you wanted to.  So this really wasn't meant to be super-encrypted security anyway.  Just hard enough that, unless you were a government, you couldn't listen in on people's phone calls.



And it turns out, as we know, as technology has moved, because this is now so old, it's become increasingly feasible for people to have a few terabytes of rainbow tables built and stored, which suddenly makes the cryptography substantially weaker.  And other James Bond-like sci-fi technology, like having a software-programmable radio, well, you can order those on the Internet now and download the software to make it work.  So it's just become too accessible.



LEO:  Right.



STEVE:  And as he says, moving forward, the problem is this is probably enough encryption for most people.  And remember that when analog cell phones weren't encrypted at all, people still used them.  I mean, they used them like crazy.



LEO:  Yeah.  Yeah.  I remember people, well, we talked about it last week.  I remember people just having scanners and listening in; you know?



STEVE:  Yes, yes.  I have done it.  I mean, it just - you turn the scanner on, and you're listening to someone's phone conversations, like whoa, that's a little too easy, yeah.



LEO:  Austin Clark in Menomonee Falls, Wisconsin wants cookie management.  Who doesn't?  Steve, for the second week you mentioned your favorite Firefox cookie manager, but never gave us its name.  I'm sure you're driving a number of  your listeners like me crazy.  Could you either tell everyone on the next show; or, if you don't want to promote it, could you at least email me the name?  It could be our little secret.  What is the name?



STEVE:  Okay.  The name is just - it's just called Permit Cookies.



LEO:  Permit Cookies.



STEVE:  Permit Cookies.  And I need to warn people that it is the most feature-lean cookie manager there is.



LEO:  Much like the name.



STEVE:  It's why I like it.  In fact, some listeners recommended other cookie managers, and I thought, oh, okay, I'll see.  And they're just - they've got more bells and whistles than I want.  The way I have Firefox configured is I have it set to allow third-party cookies just for the sake of not breaking anything, but to remove all cookies whenever the browser session restarts, which is one of the options in the standard - under the privacy tab in Firefox.  So no cookies, either first-party or third-party, are ever kept permanently.  But then that's, of course, inconvenient because you'd like some sites to remember you.  I don't want to have to go reauthenticate to Amazon every time, or eBay, or PayPal, or so forth.  So it's nice if specific sites that I trust are allowed to create permanent cookies.



And so what I use, I use this Permit Cookies, little add-on.  It just puts a little tiny little "C," C as in cookie, down in the Firefox tray.  And when I'm at a site that I want to remember me, it's just a matter of right-clicking on that and saying trust this site.  And so it's a simple UI into an existing dialogue in Firefox.  That is, I could go into Tools, Options, Privacy, and make that site an exception.  But that's many more steps.  The other thing is that the little "C" will turn green if the site I am on is in my exceptions list.  So it's easy for me to see, oh, yeah, okay, that's - I'm trusting this site.  Typically, most of the sites I go to, I'm not.  So everything works fine while I'm there.  And as long as I'm using the browser.  But there's no long-term accumulation that's like this infinite accumulation of cookies that you normally have since I use this delete them or keep them only for the current session option.



Now, Permit Cookies, if you put Permit Cookies into the add-on finder, it will - it's not in the first one that comes up.  You have to say "show me all."  Then it's on a page on the Mozilla site.  And it says that it is not compatible with 3.5.  And so it just - you can't even install it from there.  But in fact it is.  And if you go to the author's website, and there's a link there, he's got a whole bunch of little add-ons that he's written for Firefox.  And a ways down is just this little simple Permit Cookies.  So it's as simple and easy to use as could be.  And I did come back to it from the more fancy cookie managers because there's really nothing I want to do more than that.



I just want to say, you know, me, I'm the lowest common denominator guy, writing things in Assembly language and wanting it to be simple and clean and not slow down my Firefox and not require infinite updates.  This thing's never been updated.  Well, I mean, it's at 0.6.2, I think, is the version of it.  But it's not like NoScript.  Every time I restart Firefox, oh, we've got a new version for you.  It's like, okay, wonderful.



So that's the thing I use.  I really like it.  I recommend it.  It's minimal, minimal, minimal.  But it just - it allows my Firefox to remember the sites that I want to.  Otherwise cookies are all sort of session cookies, even the first-party cookies, that are constantly flushed whenever I restart Firefox.  So works great for me.



LEO:  So just to recap, you turn off cookies completely.



STEVE:  No, no, no.  I...



LEO:  You block all cookies and then use this to unblock the trusted sites.  Is that - did I misunderstand you?



STEVE:  No.



LEO:  Oh, okay.



STEVE:  Yeah, Firefox has a neat option.  I'm going to go under the Tools menu to Options.  And you click the Privacy tab.



LEO:  Okay.



STEVE:  And under Cookies I have enabled "Accept cookies from sites," and I have enabled "Accept third-party cookies."  But the next option down is "Keep until."  And so the normal option is "Keep until they expire."  And I've chosen "Keep until I close Firefox."



LEO:  Okay.



STEVE:  And so the beauty of that is nothing is stored permanently on this system.  But over to the right there's an exceptions button.  And if I look at my exceptions, I've got Amazon, Blackberry, eBay, GRC, UPS, and a couple others.



LEO:  But those were added by the plug-in.



STEVE:  Yes.



LEO:  Got it.



STEVE:  Now, you can add them manually, if you didn't want to use the little plug-in.  But it takes just more steps.



LEO:  So the plug-in explains this, how to do this?  I mean, this is the way you're supposed to do it?



STEVE:  No.  That's why I...



LEO:  Oh, good.  I'll put this in the show notes, in that case.



STEVE:  The plug-in is so generic, all the plug-in does is simply allow you - see, it knows what site you're on.  So you're just able to say block or allow the current site.  Just that simple.  And so it just sort of makes it easier to put domain exceptions into Firefox.  But in order to make the rest of this work, you have to go and configure it the way I have.



LEO:  Got it.



STEVE:  Which is to say, allow first-party and third-party, but then set them to keep them until I close Firefox.



LEO:  So that's interesting.  So you've told us in the past to disable third-party cookies.



STEVE:  Yeah.  And, for example, on IE, that doesn't have an option like this, I think that still makes more sense.  And I could disable third-party cookies except that here there's no long-term tracking happening because they're all being washed away whenever I close Firefox.



LEO:  Right.  I'm looking at my Firefox settings.  



STEVE:  But look at your cookies.  If I look at my - oh, I'm sorry.  Look at your exceptions.  I have, like, 10.  There's only 10 sites that I want to remember me on an ongoing basis.  And they're able to.  Nothing else can.  Everything else just gets thrown away.



LEO:  I like this.  This seems like the best of all worlds, best of all possible worlds for cookies.



STEVE:  I think it's very clean.  And...



LEO:  And stuff works while you're browsing.



STEVE:  Right.



LEO:  But it just doesn't remember anything about your previous session once you've closed it unless you explicitly say, "I want this one."



STEVE:  Precisely.  So it's exactly what you want.  It's an opt-in approach which is extremely lightweight.



LEO:  Now, it looks like, unfortunately, Firefox has changed their setup in 3.5 so that this - you can't do this anymore.  At least I can't figure out how to do it.



STEVE:  Right, I'm still in - on the one I was looking at, I'm at 3.0.14.



LEO:  Because I go to Privacy, and it's all about history now.  And, boy, they've really messed this up.  Gosh darn them.



STEVE:  I do have 3.5 running on a couple machines.  I'll take a look at it and make a note to see if I can see a way to do the same thing for next week.



LEO:  And I'll put this in the show notes.  We'll put this in the wiki.  And as always, what we do - this is a new thing that we do is I have a FriendFeed room that I start for every show.  It's on FriendFeed.com/twit-conversations.  And as we talk, I put links in here so that I have links.  So if you want - if you're listening live, and you want to get that information, it's there.  But we'll also take that information and then put it into the - we'll put it into the wiki.  And I'm sure you'll put it in your show notes, as well.  So people can get the show notes at GRC.com, as well.



Okay.  Moving right along.  Mateus Del Bianco in Brazil wonders about GSM cloning:  Hi, Steve.  Listening to the podcast, the last episode on GSM cracking, got me wondering, how easy is it to clone someone's cell phone over the air?  Now, cell phone cloning was a technique used for a long time, I don't know if it was pre-GSM, but as a way to kind of, you know, steal their phone, in effect.  I can accept that GSM is secure, and I don't mind someone listening to my conversations, but I do mind if someone can use my line.  Is GSM cloning possible?  What about if someone has physical access to the SIM card?  How hard is it to obtain that 128-bit preshared key you talked about?  All good questions.



STEVE:  Well, I didn't - the reason I wanted to share Mateus's question is, it is absolutely one of the consequences of the cracking of GSM is the ability to clone.  It was given in several of the examples of the papers that I read when I was doing the research on this.  If you have physical access to the SIM card, it's relatively trivial, using current technology, to crack the algorithm.  There's something, it's called COMP128, which is the authentication algorithm, which by default has been used by most providers.  It was given as an example in the original GSM spec.  And while not everyone has to use it, that's what everyone has ended up using because it was just sort of, here, here's an example of an authentication algorithm that you can use with GSM.  And everyone said oh, okay, fine, we'll use it.



The problem is, it's very old, and it has been badly cracked by cryptographers who understand the weakness of it.  So it is absolutely possible for somebody with a radio to basically ping somebody's phone.  And they don't even know who they are.  So you would, like, for example, you're in a coffee shop, and this person with a laptop and a strange-looking antenna and a little box to the side of their laptop has a strange grin on their face because they're pretending to be cell towers to every phone within range and are able to ping the phone and acquire the shared secret that is that 128-bit key that the subscriber has locked up in their SIM card, and after that be able to impersonate that person's phone.



LEO:  Wow.  It's easy.



STEVE:  So it absolutely is one of the consequences of this cracking that we're talking about.



LEO:  Wow.  And to go back, thanks to our chatroom, to go back to our question about Firefox...



STEVE:  Oh, Firefox?



LEO:  It turns out that, if you go to the Privacy section, it looks like it's a very simple section.  Firefox will remember history, never remember history.  And then there's a use custom settings for history that gives you access to all of those previous settings that we've seen before - accept cookies from site, accept third-party cookies.  And then you just change this "Keep until" to "I close Firefox."  And that's all you do.



STEVE:  Beautiful.



LEO:  Yeah.  And then there's also a clear history when Firefox closes.  But that's kind of separate from cookies; right? 



STEVE:  Yes, yes.



LEO:  We don't have to worry about that.  Thank you to the chatroom.  Once again, they're good.  They're real good.



STEVE:  And just to reiterate, although nowhere does it say, even on the author's site, that Permit Cookies does run under 3.5, I am running it under 3.5, and it works beautifully.



LEO:  Great.



STEVE:  So it just - there's no problem with it.



LEO:  Excellent.  Moving to question four, Dax Mars, which is a great name, it sounds like a science fiction name, visiting earth via second life - I guess it is a science fiction name.  Quick question:  Would I be insane to try running my own web server for my website?  Cash is short.  My hosting is up for renewal.  My ISP's personal web space is very limited and not very reliable, and I'd rather spend the money elsewhere.  I'm thinking Windows 2000 or XP on an old PC with Apache for Windows.  What do you think, Steve?



STEVE:  I thought this was a really great question because it incorporates this issue of whether things have just become so crazy on the Internet that it is impossible for just a private citizen, an individual who doesn't have a huge IT staff and security people and all of the paraphernalia that any large organization will that wants to have an Internet presence, is it possible for just a random guy to set up a website and have it be practical?  And obviously he's asking us because security of that is an issue.



LEO:  Right, right.



STEVE:  And it really is a good question.  I would shy away from Windows, that is, he's suggesting Win2K or XP on an old PC, using Apache for Windows.  If I were doing this, I would use the securest version of UNIX available.  I would use NetBSD or FreeBSD.  And you can run Apache on that.  There's a little bit of a learning curve.  But either of those runs beautifully on the oldest PC you can find.  It is just simple to do.  And they're going to be state of the art.  They're going to be very secure.  And Apache is Apache, whether it's on Windows or on UNIX.  If you also install the SMB support under UNIX, then it's very easy to look at your file system over on the UNIX machine from within the Windows browser, that is, you're able to - it's just another machine on your Windows network where you're able to open it up and look at it.  It's the way I manage my UNIX machines, is they have SMB running on them.  And that allows me to see the entire drive.  Just like I'm using file and printer sharing, where I'm looking at other drives on my own internal network, I'm looking at UNIX that way.  And of course we configure UNIX with text files.  So it's very simple and practical.



The only problem, of course, is that you've got now a server deliberately exposed to the Internet.  And the danger is that a bad guy could somehow use some compromise on the server in order to get root on the server, gain access beyond just being a casual web surfer, and then have access to your internal network.  So this is where my suggestion of multiple routers comes in, the idea being to put the server on an upstream router and then protect your network behind a router which is located inside the network that the server's on, very much - it's not as much like the consumer grade of DMZ, where anything coming in goes to that IP.  You really don't want that.  You only want to allow web services to be mapped to the IP of that server.



But we've talked about using multiple NAT routers several times.  And I would use that approach.  And then I think you're probably pretty safe.  I mean, it's sad that in this day and age it's just not easy to put a website up on the Internet and be able to do things.  But the fact is, I mean, look at all of the problems we're continually seeing with this stuff.  It really is difficult.



And the other little bit of advice I would have is absolutely, as much as possible, resist the temptation to make it more complex than it has to be.  If you don't need SQL server, don't put it in.  If you don't need PHP or any of the fancy scripting technologies, don't put them in.  Those tend to be where today's problems are, more than just in the core web services.  The core web services stuff that just serves up simple web pages are pretty solid and pretty stable now.  It's all that extra fancy stuff that people are adding that we tend to see the leverages that allow people to gain a foothold inside a server.



So I think, yes, I think doing it carefully, minimizing your install - arranging to isolate the server's network from the rest of your network I would absolutely do.  I would never have the server on the same network as mine.  It makes administration of it a little more painful.  But most people aren't changing the pages on their server all the time anyway.  And then I think, you know, basically you've got a web server for free.  No web hosting, no ISP or anything.



You do want to make sure that your ISP allows you to host a server.  That is, you want to make sure that they're not blocking port 80.  We know that many ISPs are now blocking the file-sharing ports, those that Windows use.  Some are blocking port 25 to prevent spam from illicit SMTP servers on port 25.  You do want to make sure that 40, I mean, sorry, port 80 and 443 are enabled if you want - 443 if you wanted to do SSL connections, but at least port 80.  You can run a server, of course, on an alternative port like 8080.  But that's not convenient for people because that's not what their web browser is going to use by default.  So I would say yes.  It's not easy.  It's unfortunate that it's not easy.  But it's certainly doable.



LEO:  Yeah, and there might be - it's now all of a sudden, because you're running a server, you have to kind of keep an eye on holes and exploits and make sure you're patching it regularly.  And I don't know - Windows now becomes a vulnerable target, as well.  A lot of people would prefer FreeBSD or something more secure than Windows.



STEVE:  And isn't it sad, Leo, that, I mean, it's just not easy for someone to run a web server.  Like...



LEO:  Yes.



STEVE:  Like once upon a time.



LEO:  Yeah, I mean, we used to do that.  Anytime you run a server, it's not just the web.  An FTP server, anytime you run a server, even a Windows Media server, you're always kind of now opening up a little vulnerability.  I like the idea of isolating it using the routers.  You also may have issues with your - if you don't have a static IP address.  And then you have to use things like DynDNS to redirect because otherwise people don't know where to go if your address changes regularly.  There are all sorts of little issues.



STEVE:  Yeah, in order to publish a domain name whose IP will change as your machine's IP changes, to the degree that it might.



LEO:  Yeah.  Question five, Tim in Rancho Cucamonga - oh, I love saying that - Rancho Cucamonga, California wonders about a router's password strength:  Hi, Steve.  I hear a lot about having a strong wireless passphrase, but what about the password that lets you into the router setup?  The same password that will let you see the wireless passphrase unencrypted.  If I use your Perfect Password maker for my wireless passphrase, then a relatively weak password to get into the router, isn't the router's less robust password the weak link?  Or am I missing something?  Should I use a Perfect Password generated by your site for the router setup, as well?  Thanks, Steve.  Great show.



STEVE:  I thought that was a great question because we've talked a little bit - we've talked extensively about the only current vulnerability known for the strongest WiFi is guessing the password.  That is, there is still that vulnerability.  That is the only problem that we currently know, for example, with WPA encryption, which is not using TKIP as its cipher, but is using AES, which is what you want to use when you can.  Sometimes that's called WPA2, although that's really not the official name.  But given that you're using the best wireless encryption available, the only known vulnerability is just guessing the password.  And that is an offline attack, meaning that data can be captured and then taken home somewhere and pounded on by as much technology as is available, trying every possible password.



LEO:  But don't they need physical access to the router to do that?



STEVE:  No, no, no.  No, here I'm talking about just about cracking the WPA.



LEO:  Oh, the WPA, yeah, right, right.



STEVE:  Yeah, the WPA password in the air.  So we know that, and we've talked extensively about, the fact that that wants to be as unguessable as possible.  So Tim is exactly right, that if you had an attack on the router's password, that is, the administration password, username and password for the router, then if that were dramatically weaker, and if you had access to it - and that's the point you were making, Leo - then there'd be a problem.



So we know there's the issue of WAN-side management.  And one of the first things you want to do is make sure that your router is not manageable from the WAN, from the Wide Area Network, that is, from the outside, from the Internet.  I don't think in this day and age there are still routers that ship with that enabled by default.  I sure hope not.  It's just incredibly worrisome and insecure to expose the management interface, even behind a username and password.  I just can't think of a good reason to do it unless you really, really need to administer routers remotely over the Internet, in which case there it's extremely important that you use a strong username and password because nothing is restricting someone from just sitting on that connection and guessing username and password day in and day out until - hopefully they're never able to guess it.  But when they do, they'd be able to log in.



But assuming that web-side management is not enabled, then the only vulnerability would be somehow accessing what is now typically a web browser interface from inside the LAN, which is the point you're making, Leo, is how would a bad guy get onto the LAN?  And the good news is, unless there's malicious software running on a machine, it's probably not possible.  You've got the catch-22 of the wireless aspect of getting on the LAN, which is if you had the wireless password, then that would get you on the LAN, giving you an opportunity to break the router's administration password.  But assuming a strong WiFi password, you don't have that password until you break the router's administrative password, that as Tim said would give you in-the-clear access to the WiFi password.



So the danger - and this is something we have talked about before - is, like, for example, leaving the router's admin passwords alone.  We now know there's malware that you can get on your system that is smart enough, they contain all the username and passwords for all the routers out there.  And it will attempt to log into your router explicitly for this purpose.  In this case it's not trying to steal your WiFi password.  Normally it's trying to access your router in order to open ports in order to allow remote access into your network.  So we know that it's important that you change your admin and username away from the manufacturer's default because there's definitely malware roaming around the world that knows, if it can get into your computer, it would love to take over your router.  And that's the first step to doing so.



So Tim's right.  It's not a huge problem because it's not something anyone - no one has access to your admin username and password, given that you've got WAN access turned off, the Wide Area Network access turned off.  So they don't have access to your network as long as your WiFi password is good, and we're presuming it's good, and we're looking for the weakest link.  But it's certainly worth making it as robust as you can.  And certainly use another one of the Perfect Passwords from GRC.  That's going to give you complete pseudorandom protection.



LEO:  I've seen a number of routers that have, as you call it, WAN administration turned on by default.  Which is shocking.



STEVE:  No kidding, yeah.



LEO:  And we talked before, and I think I talk about this on the radio show a lot about the things that you need to do when you get a new router - change the default name, change the default password, turn off WAN administration...



STEVE:  Oh, of course.



LEO:  ...turn off Universal Plug & Play.



STEVE:  Yes.



LEO:  I think those are the - oh, and turn on, if it's wireless, turn on WPA2.



STEVE:  Yes.



LEO:  Those are the five things, and you're secure.  But you've got to - if it's on by default...



STEVE:  Yeah, you just cannot take it home and plug it in.  And it's very distressing, Leo, if there's still routers that have WAN admin on.  I mean, nobody needs it.  Sure, maybe there are applications where some Soho IT admin wants to manage the routers of a few friends or something.  But your typical end-user is plugging in a router to have the features of the router inside their LAN.  Never do they need to get to it from the outside.



LEO:  Right.  Yeah, it's crazy.  But, you know, this comes from the day when they would turn everything on so that they wouldn't get any support calls.



STEVE:  Yup.



LEO:  And now fortunately I think most of the new routers are really being very smart and careful about telling people, this is what you need to do, walking them through it.  They've changed their defaults.  And I think that's all good.  I notice the Ident port, for instance, is - and this is thanks to you and ShieldsUP! - by default is turned off.



STEVE:  ShieldsUP! probably put pressure on it, yes.



LEO:  Chris in Iron Mountain, Michigan brings you the - wait a minute, no.  I don't want to jump ahead.  We've got a New Zealand question.  Gary McCleery - then I'll get to Chris - in Oamaru, New Zealand, a Kiwi, wonders about proxy servers:  Hi, Steve and Leo.  Greetings from New Zealand.  You're probably saying, "Where the heck is New Zealand?"  No, in fact we all know where New Zealand is ever since "The Lord of the Rings."  I run the school library as well as help look after the servers, desktops, and teacher laptops.  Never a dull moment.  Everyone accesses the Internet via an external proxy server.  I think that's a good thing to do.  Some of the students use other online proxy servers to access sites that have been blocked.  Shame on you.



STEVE:  Uh-huh.



LEO:  But of course it's a high school, and high school kids know how to do this.



STEVE:  They're going to find a way.



LEO:  Yeah.  Certain sites are blocked to provide a certain level of protection.  My question is, can the use of these other proxy servers allow viruses, trojans, and other bad stuff onto our servers, or do the proxy servers simply mask the address of the sites the students are trying to access?  Can our computers be compromised by the use of these proxy servers?  Now, that's a great question.  Love your podcast, been listening for years, always learning heaps from them.  Keep up the good work.  I'd like to know the answer to this.



STEVE:  Yeah.  Okay.  So a proxy server, as we know, is sort of a way station.  Instead of the client going directly out to a remote web server, the clients within such networks are configured to use an intermediary server, a so-called proxy server.  So that the client makes its connection, its TCP connection, to that proxy server, and then submits its request to the proxy server, which then turns around, and it generates the request outside to the Internet at large.  And the process is pretty quick.  It's not something for which there's lots of overhead.  It's a little more overhead than not using one.



The one tip, I've never mentioned this before, but Internet Explorer defaults to looking for a proxy server whenever you start it up.  And whenever I go to someone's machine who's using IE, and I launch it, and it, like, sits there for a while, I think, oh, they haven't turned that off.  And it's easy to change the configuration if you - most typical end users in homes and small offices are not using proxy servers.  Yet IE has it turned on by default.  It has proxy server, automatic proxy server discovery, which stalls...



LEO:  It's slow, yeah.



STEVE:  Every time you start IE...



LEO:  Hate that.



STEVE:  ...if that's turned on.  So that's just a tip to our listeners, anyone still using IE, and I hope there's only maybe one or two of you that haven't been listening to the podcast that long, because even I have finally switched over to Firefox.  IE can be made much faster to start up if you just go down in the Internet connections dialogue and turn off "Automatically look for proxy servers."  And from then on it's just way faster to get yourself going with IE.



So anyway, this intermediary is the one that then performs the connection.  Well, the proxy server can have a number of functions.  And in Gary's school in New Zealand, I guess in the library - or he runs the school library - but in the school's network they're doing other things than just proxying.  They've got content filtering software which has a whole list of domains which are blacklisted that the kids that are using this proxy server for their connections are unable to access.  And corporations certainly do this also.  They may just block off, for example, all the social networking sites because their employees are spending too much time during the day poking around in Facebook and MySpace and Tweet and Twitter and who knows what.



LEO:  No, that's exactly what they block at my kids' school - Facebook, Twitter, all that stuff, yeah.  They don't want them messing around.



STEVE:  And so another thing that such servers could do is, and may do, is malware protection.  They may perform some level of malware filtering.  We talked about the Astaro Security Gateway for years here.  And one of the features it offered was that it would be automatically synchronized by Astaro, and it would filter things coming and going so that your whole network behind there was protected.  So similarly, it might well be that the school's proxy server is offering protection from malware and trojans, as Gary asks.  However, if the students are being clever and not using the school's proxy server, but reconfiguring their clients to use some different proxy server, as I understand it he's saying can the use of these other proxy servers allow viruses, trojans, and other bad stuff to get into our network.



And the answer is yes because there isn't anything about the proxy server that performs any kind, by definition, any kind of filtering.  It's additional features of a proxy server that may be doing that.  The school's main proxy server, the authorized one, may be doing that.  It may be, though, that other proxy servers would not be.  So it's definitely something to keep in mind.  If the kids are getting around the security and sort of the formal channel for accessing the 'Net, it may be that they're getting around more than just the school's filtering.  They may be getting around the school's AV technology, which could represent a problem for the school.



LEO:  Interesting.  The software that they use at my kid's school, I know because I've tried to get around it, because I've been on the campus, and I want to tweet, also knows about proxy servers and seems to catch a lot of the most common proxies.  But I'm sure, you know how teenagers are, they probably have figured out a way around that, too.



Oops, I jumped ahead a little bit.  We've got another one.  Poojan Wagh in Chicago, Illinois wonders whether security in hardware is a bad idea.  He says:  I was thinking about the security in GSM, and it seems to me the problem is that such hardware-reliant security implementations have the difficulty that they can't be modified in the future.  They're stuck in the hardware.  That's what happened with the DVD.  It was part of the spec, and you couldn't change it once the CSS was broken.  It was, that's it.  Anyway, perhaps it's generally a bad idea to put security in hardware because of this limitation.  Once it's in, you can't change it in the future.  That also seems to be the case with 802.11's WEP, the shortcomings of which was inherited apparently by WPA-TKIP.



Now, one could make the case that back when GSM was being invented, they didn't have the capability of putting security in software.  Couldn't one make the counter-case that maybe it would be better to live with no security rather than the false illusion of security and leave the true security as a software option later?  After all, when the hardware security gets broken, software has to come along and fix it anyway.  Your thoughts, Steve?  Is hardware-based security for long-term standard products generally too risky?



STEVE:  It's really a good question.  And reading it, I had to think about that for a while.  It's like, well, is there anything fundamentally bad about security implementation in hardware?  And I don't think so.  It's probably the case that hardware - at any given point in time, hardware offers greater security than software, in two ways.  It is generally much faster to implement security algorithms in hardware.  That is, you can take an algorithm that's in software, and you can cast it into gates which, running at the speed of light, at electricity, can much more quickly process the fixed algorithm than software, which is inherently flexible.  The power of software is it's soft.  The power of hardware is that it can be very much faster.  So for a given algorithm, putting that into hardware allows it to be far faster, or it will allow you to have a much more powerful algorithm at the same speed, thus potentially more security.  So I really think that at any given point in time, hardware gives you more security.



Now, as he mentions, though, hardware is also fixed.  That is, the gain that you got by locking it into hardware is its speed.  Also note that it also makes it unchangeable, which is a good thing for security.  Many of the problems we have with our software today is the softness of it.  If we had technology that was locked in place, for example, email clients and web browsers that were in ROM and could not be modified, then they would arguably be much more secure than what we have now, where they're inherently infectable.  So thinking about this, I don't really - I don't see a tremendous benefit for keeping things in software because, again, exactly as he suggests, if we had that as a requirement, because we would lose the performance edge of hardware, then we would have no security at all during that intervening time; whereas the extra leverage, the extra speed and power that hardware gives us allows us to have security where we otherwise would not.



Certainly we see example after example with, for example, as he states, WEP and also GSM, where this legacy hardware is now holding us back.  We've got the power to do better security, and it's difficult to move forward.  But I guess the flipside would be not having any security at all during that time, and I don't think that's - I think that's worse, as opposed to being better.



LEO:  Yeah.  And often you have a combination of hardware and software; or, I mean, there's ways to patch it.  The original Xbox had hardware security built into it and was cracked almost immediately by Bunnie Huang at MIT.  And then I think Microsoft used it as a learning tool, and Xbox 360 I don't think has been cracked.  I don't think their mod chips were.  So they learned what not to do.  And it's hardware secure.  Most hardware devices have hardware security; right?



STEVE:  Yes.  And I think that at this point, I mean, sure, once upon a time, 20 years ago, we didn't really have a mature understanding of crypto.  We didn't have algorithms.  We were using pseudorandom bitstreams and XORing them.  And now we have this rich understanding of how that's bad and why that's bad.  So I think those are legacy problems that have been solved, and we're now at the point where we've got sufficient technology and speed that it's really no longer an issue.  We don't have to choose.  We've got algorithms that are strong enough, whether we implement them in hardware or software, to carry us hundreds of years into the future.



LEO:  Good.  Yay.  I guess.  Our last question is actually our Tip of the Week.  Our Way Cool Tip of the Week.



STEVE:  Oh, yeah.



LEO:  Way cool.  This is Chris in Iron Mountain, Michigan with the Way Cool Tip of the Week.  He calls it a Cool Google Feature:  Safe Browsing Diagnostic Report.  Steve, I was doing some unusual Google searching when I stumbled across a really cool page, maybe feature on Google.  It's called "Google Safe Browsing" diagnostic page.  I have no idea how to access it through Google's own site, but I've been actively using the site through a direct link which is a little long, but I'm going to give it to you anyway, and we'll put it in show notes.



STEVE:  Yes, you have to, Leo.  This is so cool.  Our listeners are going to go nuts over this.



LEO:  It's google.com/safebrowsing, that's all one word, lowercase, /diagnostic?site=, and then you put the URL.  Don't put the HTTP, just the URL.  So he gives as an example google.com/safebrowsing/diagnostic?site=grc.com.  And it brings up a malware diagnostic report of the site referencing the last 90 days.  So when he did your site, he said it's currently not listed as being suspicious, and of the 10 pages it tested on your site, "0 page(s) resulted in malicious software being downloaded and installed without user consent."  On sites that do have malicious content - I wonder what The New York Times site says right now.



STEVE:  I put it in, and it found it.



LEO:  Oh, interesting.



STEVE:  Yes.  And you're clean, and BitGravity is not.



LEO:  Really.



STEVE:  Yeah, this is just too cool, Leo.



LEO:  On sites that do have malicious content, it'll give statistics as to what type of malicious software it found, and how many there were of each type.  Because Google has to index these sites all the time.



STEVE:  Yeah, so it's looking.



LEO:  So if there's malware, it'll see it.  For example, if I were to check out Tripod.com, I get the results, "Of the 6,400 pages we tested on the site over the past 90 days, 224 page(s) resulted in malicious software being downloaded and installed without user consent.... Malicious software includes 227 trojan(s), 187 scripting exploit(s), 61 exploit(s). Successful infection resulted in an average of 1 new process on the target machine."  Wow.  He says:  Hope this is something new and unknown to you.  I've not heard of this particular page before, but have seen the warning screens Google pops up every now and then if you are trying to get to a potentially dangerous site that pops up on a Google search.  Both Microsoft and Google maintain databases of malware sites.  I guess this is coming from that.



STEVE:  Yes.  And again, our listeners are going to go nuts.  You know, it's just google.com/safebrowsing/diagnostic?site= and then the domain name.



LEO:  This is so cool.



STEVE:  And I've put in The New York Times, and it found malware on The New York Times.  I put in BitGravity, just kind of, you know, out of nowhere.  And it's like, whoops, there have been some problems there.  Google has found malicious content there.



LEO:  And this comes from sites being compromised, whether there's a server error or a...



STEVE:  Really anything.  It's Google's search engines pulled pages and looked for malicious content for whatever reason, in an ad, in a blog that had been inserted through cross-site scripting, I mean, whatever the source, the idea being that if a user's browser went there, the user would be in trouble.



LEO:  Wow.



STEVE:  And this is just - it's so neat to just try out different...



LEO:  I'm putting all my sites in there.  I want to make sure I'm not - wow.



STEVE:  Yeah.  Yeah, and again, New York Times came up.  I think it found one problem there, and it found a few on BitGravity.  And so it maintains a 90-day history and shows you the statistics for the last 90 days.  And this qualifies as a cool tip, a way cool tip of the week.



LEO:  So cool.  I'm going through all my sites right now.  Let's see what Twitter, just out of curiosity...



STEVE:  Ooh, good.



LEO:  Twitter.com.  Of the 3,885 pages we tested, 0 pages resulted in malicious software.



STEVE:  Wow.



LEO:  Malicious software has never been found.  That's pretty good.



STEVE:  Try Facebook.



LEO:  Ooh, yeah.  Facebook.  I know, well, I don't know.  One time, Facebook.  One page resulted in malicious software.  Intermediaries distributing malware to visitors at site included [mancrushonmcflea.com ph].  Wow.  This is really interesting.  Let's try MySpace.  That's got to be a...



STEVE:  A nest.



LEO:  68 pages in malicious software.  76 scripting exploits, 4 trojans, 1 worm.



STEVE & LEO:  And a partridge in a pear tree.



LEO:  Wow, that is great.  I think people are going to spend the rest of the day entering sites into this.



STEVE:  I think so.  It's just too fun to have an instant report on what has been found on popular and unpopular sites.



LEO:  Thank you, Google.  I'm putting this in my Google show.



STEVE:  This is a keeper.



LEO:  This'll be my Google Tip of the Week because that's a great one.  Wow.  And thank you to Chris in Iron Mountain, Michigan for that way cool tip of the week.



STEVE:  Yup.



LEO:  And thank you for sharing it with us.



STEVE:  Absolutely.  We've got great listeners.  They go to GRC.com/feedback and send me the things they're thinking about, questions they've got, ideas they have for shows and whatever's on their mind.  And I really appreciate it.



LEO:  That's it.  We'll be back next week.  Do you know what you're going to talk about next week?



STEVE:  Don't know yet.



LEO:  It's a surprise.



STEVE:  We'll let the world determine it for us.



LEO:  You know, there's never really a dearth of subject matter.



STEVE:  There's never a dull moment, Leo.



LEO:  Steve Gibson is the man in charge at GRC.com, the Gibson Research Corporation, the company that gives you the great SpinRite, the world's best hard drive recovery and maintenance utility.  It's a must-have.  If you've got a hard drive, you need SpinRite.  You'll also find at GRC.com a lot of great free stuff.  Of course Shoot The Messenger, DCOMbobulator, Wizmo, the very famous ShieldsUP!.  And you'll find this show, GRC.com/securitynow.  You'll find 16KB versions, the little tiny ones for quick download.  You'll find transcripts, which makes it very easy to search the entire show.  We've got to do that on all the shows.  It's such a good idea.  Steve's show notes and more.  And of course he's got great security forums there, as well.  Highly recommended.  GRC.com.  Steve, we'll see you again next week.



STEVE:  Okay, Leo.



LEO:  Safe surfing to you.



STEVE:  Thanks very much.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#215

DATE:		September 24, 2009

TITLE:		Security Maxims

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-215.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the first portion of a collection of pithy and apropos "Security Maxims" that were assembled by a member of the Argonne Vulnerability Assessment Team at the Nuclear Engineering Division of the Argonne National Laboratory, U.S. Department of Energy.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 215 for September 24, 2009:  Security Maxims.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, everybody's favorite show about protecting yourself online.  And here he is, the guru of security, the man of the hour, Mr. Steve Gibson of GRC.com.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be back with you again, as always.



LEO:  Nice to have you.



STEVE:  Yeah, we've got a really - some fun content this week.  I mean, we always have various flavors of fun.  This is something we've never done before.  A couple months ago I ran across - and frankly I can't remember whether I stumbled on it, or a listener might have said, hey, check this out.  So if I got it from someone, I apologize for not acknowledging them.  But it was a page of what this author called his "security maxims."  I looked up "maxim" in the dictionary to get the exact definition, and it's defined as "a succinct formulation of a fundamental principle, general truth, or rule of conduct."  And this guy is Roger Johnston, who's got his Ph.D. and also his CPP credential, which is Certificate of Protection Professional.



LEO:  Oh, I never heard of that.  That's cool.



STEVE:  He's with the Argonne Vulnerability Assessment Team, the Nuclear Engineering Division of the Argonne National Laboratory, which is a division of the U.S. Department of Energy.  So these are...



LEO:  You know, that's interesting.  Because the Department of Energy was the one who created CERT, the Computer Emergency Response Team.  I mean, they have been, until recently, they've really been carrying the torch for security in the government, the national government.



STEVE:  Right.  Well, you know, someone's got to do it.



LEO:  Yeah.  And I guess if they have nukes, they probably - it's as good them as anybody.



STEVE:  And so a couple months ago I wrote to Roger.  And I said, hey, you know, I kind of wanted to get a little background.  I thought this would be a really fun thing for you and, well, for us to discuss just sort of interactively, to go through these really fun sort of succinct, pithy maxims in the context of everything that we've been discussing for the last couple years.  So I said, hey, I wanted to get a little more background, where did these come from and so forth.



And he wrote back, he said, "Steve.  The most recent list of maxims is attached."  And so he sent those in his response.  And he said, "Most of the maxims are my creations over the last several years or so.  Being a vulnerability assessor for physical security makes one pretty cynical.  Or maybe you need to be cynical to see security problems.  Or maybe both are true.  Anyway, these maxims were developed partially out of frustration at seeing the same kinds of problems over and over again.  They're offered partially tongue-in-cheek, but partially not, since they are more or less true."  And actually I think they're very true.  I think they're just wonderful.



And he said, "Oddly, cybersecurity people get more excited about these maxims than physical security people, although they were really developed more with physical security in mind.  Over the last couple of years security professionals who liked the maxims would offer some of their own.  If I liked their suggestions, I tacked them onto the list."  So we're going to today discuss - and we've got so many, we won't get them all into this podcast.  But that's fine because it's just sort of something fun we'll bring out from time to time and dust off and continue going through the list.



LEO:  How many are there?



STEVE:  There's a ton.



LEO:  There's six pages I'm looking at right here.



STEVE:  No, no.  You just have the first chunk.  I've got more...



LEO:  Oh, there's more.



STEVE:  Oh, yeah.  Because I thought, okay, we're never going to get through this many.  So we'll do as many as we can in a reasonable amount of time.  And then at some point in the future I'll say, hey, we're going to do Security Maxims Part 2.  Because I think people are going to get a big kick out of them.



LEO:  This is good.  So we aren't just going to give you the maxim.  I know Steve.  You're going to tell us what it means, how to implement it...



STEVE:  Oh, exactly.  I wanted to break them down...



LEO:  ...what the implications, yeah, I think that's great.



STEVE:  ...give examples, discuss each one, exactly.



LEO:  Love that idea.  Well, before we get there, we have to mention our sponsor.  And I know you probably have security news and errata to cover, as well.  So let's...



STEVE:  We do.  And I've got some bad news about what happens when you try to spy on your girlfriend.



LEO:  I don't know if that's bad news or good news.  I guess it depends if you're the boyfriend or the girlfriend.



STEVE:  Well, if you're the hospital where she works, it's bad news.



LEO:  Oh, boy.  All right, Steverino.  Any news?  Any security news you want to talk...



STEVE:  Well, we do have some news.  I think I've mentioned - I know I've mentioned a couple times over the last few weeks some people have written in saying, hey, Steve, we think you're being a little unfairly rough on Microsoft.  And it's like, okay, maybe.  I'll keep that in mind.  But I did run across Apple's news about their September 10th update, their security update 2009...



LEO:  2009...



STEVE:  ...dash 005.  And Apple is notoriously close-mouthed about what's going on.  In fact, their formal statement on their update site is, "For the protection of our customers, Apple does not disclose, discuss, or confirm security issues until a full investigation has occurred and any necessary patches or releases are available.  To learn more about Apple's product security, see Apple product security website."  So that sort of has the effect of obscuring a little bit about what's going on because when the details come out afterwards, it's afterwards.  So it's no longer newsy.  But what struck me was that I really think we're very rapidly approaching, if we're not already at, the point of being able to say that the Mac is no more secure than Windows.  That is, than Windows-based machines.



For example - and this is just a brief summary.  I thought, well, I could go over the details, but it would just be going on forever.  So in summary of what Apple slid into the Mac OS without giving any details a couple weeks ago, there was a buffer overflow error in their handling of alias files that could have resulted in remote code execution.  There's a memory corruption error in Resource Manager in its handling of resource forks that could have resulted in either application termination or remote code execution.  Multiple vulnerabilities identified in the ClamAV which was distributed only with the Mac OS X Server systems, but several of those vulnerabilities could lead to remote code execution.  An integer overflow error in the handling of images with an embedded ColorSync profile.  And actually we've seen those before in Mac OS security updates.



An integer overflow error in core graphics, the way it processes PDF files, that could result, if you opened a PDF, in remote code execution.  A heap overflow error in the core graphics caused by drawing long text strings.  A null pointer dereference error in CUPS, which is the Common Unix Printing System that the Mac uses.  A heap overflow error  in the USB back end for CUPS.  Multiple vulnerabilities in Adobe's Flash Player plug-in, which, okay, is not Mac's fault, but it was there.  And some of those could have led to remote code execution.



Multiple memory corruption errors in Image I/O subsystem in the way it handles Pixar film-encoded TIFF images.  A design issue in the Launch Services system which can cause an unsafe file to be opened automatically.  A design issue in Launch Services, as a result of which there's no warning while attempting to open a downloaded content which is unsafe.  An implementation issue in MySQL that might lead to an escalation of privilege.  Multiple vulnerabilities have been identified in their PHP - again, not Apple's fault, but a component that they were including with, you know, open source that can result in remote code execution.  An error in Samba as it fails to perform adequate checks, thereby leading to unexpected sharing of folders.  And finally, a cross-site scripting error in their wiki server in the way it handles requests that have non-UTF-8 encoding.



So this sort of all got fixed, which is good.  But, I mean, given what we've been seeing over the last year, I would say that - and in fact our security maxims are going to be substantiating this because we'll recognize sort of the standard common wisdom of that - I would say that the Mac is pretty much at a par with Windows.  That is, that as a consequence of the reality of the difficulty of security, how complex modern operating systems are, whether from Microsoft or Apple or the open source community, mistakes get made.  And bad guys, the more they look, the more mistakes they find.  And we're really seeing an increase in the rate at which problems are being found in the Mac.  Not, I think, because there are more problems than there were, but because we're looking more closely.  You know, there are more Macs, and more people are using them.  The bad guys have them.  And as we said before, malicious people can't find mistakes in systems they don't have.  They find them in the machines that they're able to inspect closely.  So...



LEO:  One thing I'd point out is more than half of the ones you talked about, CUPS and Samba and ClamAV and PHP and many, many more of those you talked about are open source projects.



STEVE:  Right.



LEO:  Because Darwin is open source, and much of the software that runs on Macs are open source.  So you're going to - the same exact thing you just said can be said about Linux and open source operating systems.  In fact, it could be said about every operating system.



STEVE:  Correct.  And that's my point is that...



LEO:  Well, and the reason I bring it up is that for a long time Windows advocates have pointed to Linux and said, look at all the patches in Linux software.  And I think that that's kind of an unfair critique.  If software is being patched, and openly being patched because of problems being found, that doesn't mean that - all software is bad, but it doesn't mean that this software is worse than other software.  In fact, it means it's being patched more quickly.  You could make the counter case that a closed-source system like Macintosh or more likely Windows, they may know about many, many more vulnerabilities that aren't being patched.  So your vulnerability count could be lower.  It does not mean you're safer.  Could mean quite the contrary.



STEVE:  Yeah, and in fact I would argue that it's probably impossible to make a meaningful comparison, to answer...



LEO:  Exactly.  Exactly.



STEVE:  I mean, people, all of the fan boys in any camp want to say theirs is worse than ours, ours is better than theirs.  But I don't know that you can make, I mean, the problem is, this is not black and white.  All of this is grey.



LEO:  Yeah, I'm just saying that counting vulnerabilities, as you're just saying, is kind of meaningless.  It doesn't say anything one way or another.



STEVE:  Right.  I completely agree.



LEO:  I guess what you could derive from it is what you did derive from it, which is people are looking more closely and finding more.  But we don't know.  It could also be Apple's revealing more, and it never did before; or Apple never patched stuff before, and there was this stuff.  That's my sense.  In fact, Apple's been criticized for a long time by open source advocates for having a lot of older open source software on their system that has known vulnerabilities and not responding to that.



STEVE:  Right.  But I guess certainly what we do know empirically is there seems to be a much more continual flow of updates now.



LEO:  Thank goodness.



STEVE:  Yes.



LEO:  That's the way it ought to be; right?



STEVE:  Exactly.  Yup, these things are getting fixed as they're being found.



LEO:  I think a lot of users, like to my radio show, get concerned when they see all these patches.  It implies there's something bad going on.  Oh, my gosh, that software is horrible.  And it doesn't necessarily mean that.



STEVE:  No.  I would say all it means is that people are looking more closely and finding things that need fixing.  Which is the case in any system, exactly as you said.  Speaking of which, I had an interesting little statistical tidbit.  Remember we talked either last week or the week before about how the new versions of Firefox were going to be automatically notifying their users if the Flash, if the Adobe/Macromedia Flash plug-in was out of date.  In the first week of doing so, 10 million Firefox users clicked through and updated their version of Flash.



LEO:  It's kind of mind-boggling, the numbers; isn't it?



STEVE:  10 million.  Apparently the normal click-through is something like three or four percent.  And this time it was 30-some percent.  I mean, it was a huge success.  It turns out that apparently 75 percent of Firefox users were running outdated versions of Flash.



LEO:  Wow.



STEVE:  And so Mozilla considers this campaign...



LEO:  Victory, yes.



STEVE:  ...to be a tremendous success.  And they are planning to partner with the providers of other popular plug-ins to do the same, basically to mature Mozilla so that it will be continually aware of updates, sort of on behalf of plug-in manufacturers, and let people know that there's a new version available.  So I thought it was really interesting that there was, I mean, this was a huge win really for everyone.



And it sort of does sort of represent what we're seeing in terms of the operating system and web-based ecosystem where the browser is becoming the platform.  The browser is where you run applications.  It's where you - the way you interact with the Internet is more and more through the browser, rather than through lots of independent standalone apps.  So here's the browser needing, sort of much like an operating system, to become responsible for the security of the user's experience, which means indirectly the browser that is containing these plug-ins is having to become - is fortunately taking more and more responsibility for the safety overall of the content that it delivers.



LEO:  Constant debate, who's responsible; right?



STEVE:  Yes.  Everyone wants to point fingers.  I'm really impressed that Firefox said, okay, we're going to step up and let people know if they've got old versions of Flash.



LEO:  And you wonder, how does Adobe feel about this?  Good or bad?



STEVE:  I would think just...



LEO:  They ought to feel good; right?



STEVE:  Yes, yes.



LEO:  But in some ways it's an indictment of them for not doing it themselves.



STEVE:  Well, it's funny because I noticed that on some of my machines I've got an InstallShield Update Manager.  And I'm Mr. Minimalist.  I want as little stuff running around in my machine as possible.  And so I'm a little annoyed that there's an InstallShield Update Manager.  But it does tend to aggregate the updates of several different disparate products which have used InstallShield to install themselves.  And it's like, okay, well, I guess that's better maybe than each one of them independently needing to be running something all the time to check and see.



I think the best model from my standpoint is when you run something, to have it at that time, if you've configured it to do so, check to see if there's a newer version of itself.  And also, of course, check to see when the last time was that it looked, so it's not always looking.  And many programs now say, yes, check for updates, and no more often than once a week, or once a month, or you're able to configure that.  Which I think that's a nice compromise.  But clearly this new model of we're connected, and software is able to check in with itself, is where we're headed.  And in fact I've implemented exactly that facility now with my stuff.  We'll see that for the first time in this ever-forthcoming DNS benchmark.



LEO:  Okay [laughing].  Stop teasing us.



STEVE:  I just got thrown a curveball.  Somebody was commenting that they wanted to get all-green status, but their servers were rearranging themselves from one run of the benchmark to the next.  So now I've just finished adding an awareness of statistical significance to the difference in timings so that the benchmark will - it takes the standard deviation of all the samples and does a statistical significance calculation to determine if, okay, yes, the average of these samples was a little faster than the average of those.  But based on the spread of samples that we obtained, we can't say with greater than 95 percent certainty that it's a statistically significant difference.  So it does all that now, too.  So I'll get finished with it one of these days, and we'll do a podcast on it.



LEO:  No hurry.



STEVE:  Meanwhile...



LEO:  Take your time.



STEVE:  Meanwhile, Robert McMillan, reporting for Computerworld, carried an interesting story that caught my attention.  A 35-year-old man in Avon Lake, Ohio named Scott Graham has his tail between his legs at the moment, and in fact he's set to plead guilty to federal network spying charges.  He purchased for $115 a program called SpyAgent, which he sent to his ex-girlfriend's Yahoo! email account.



LEO:  Creepazoid.



STEVE:  Yes.  He wanted to spy on his ex-girlfriend.



LEO:  Jerk.



STEVE:  Unfortunately, she works in the local hospital's pediatric cardiac surgery department.  And as a consequence you could also argue of the hospital's lack of sufficient security, she used her web browser, went to Yahoo! email, opened her email and installed SpyAgent into the machine at the hospital's pediatric cardiac surgery department, creating among other things a regulatory nightmare for the hospital because then, over the course of about two weeks, the spyware on her machine emailed to Scott Graham, the creepy ex-boyfriend, more than a thousand screen captures of what was going on on this sensitive machine, including details of medical procedures, diagnostic notes, and other confidential information relating to 62 different hospital patients.  He also obtained email and financial records for four other hospital employees.  So he's now facing $33,000 in damages from the hospital and a maximum sentence of five years in prison.  So anyway, I...



LEO:  Good.



STEVE:  Well, yeah.



LEO:  Geez.



STEVE:  Yeah.  And, I mean...



LEO:  So that's - that's illegal to do that.  Even though people sell this product, it's illegal to...



STEVE:  And it's amazing to me that people can sell this product.  They say, oh, it's for parents to keep an eye on their children and the way they're using the computer.  And it's like, okay...



LEO:  But they know perfectly well that's not the only people who use it.



STEVE:  Yes.  I mean, I would venture to guess that 99 percent of the purchases and use of this kind of a creepy tool is for this kind of application.  And of course this is - so his intention was that she would run this from her machine at home, infect her machine at home, and then he'd be able to figure out if she was dating somebody else or who knows what this creep's plans were.



LEO:  I hope they slap the wrist of the hospital security person, though, as well.



STEVE:  Well, that's, I mean, this is a very good point, is the fact that she was going to a public email service, downloaded and installed this thing.  Who knows what the actual protocol was for it.  But clearly it's packaged so that it will get itself installed in exactly the scenario you want to - to the degree that you want it installed anywhere, you want to be able to control where it's installed.  And this spyware was invited into this hospital's pediatric cardiac surgery department and created problems for everybody.



LEO:  Not so good.



STEVE:  Not so good.



LEO:  Not so good.



STEVE:  I did want to mention that there is an unpatched vulnerability in Microsoft's SMB version 2.  SMB is the Server Message Blocks protocol.  It's the general Windows file and printer sharing protocol which is used now for, like, much more than just file and printer sharing under Windows.  Their newer version, which appeared first in Vista and is also in the current pre-release of Windows 7, has a known vulnerability which has not been patched.  Now, I doubt that this is really a problem for anybody because for this to be a problem you would have to have that port, ports 139 and 445, which are the default ports for this service, or actually the only ports for this service, you'd have to have them open and exposed to bad guys, which would mean you'd have to have them deliberately open through the firewall running on the Windows machine.  And assuming that you're behind a router, you'd have to have those mapped through so that you could access those ports and this SMB service remotely.  So that seems unlikely to me.



But it's certainly possible that somebody running Vista could have said, oh, well, I've got a really good password and username on my machine.  It's crucial for me to be able to do file sharing or printer sharing remotely.  So they may well have mapped these ports through.  So if that's the case, I wanted to point people at a Microsoft security advisory.  There is no patch for this.  But you can disable in the registry only the v2 enhancements.  And that's where the problem is.  So if you were still doing and needed to do this unwise thing of leaving those ports openly exposed, I mean, these ports have been a disaster from day one of Microsoft's platform on the Internet.  I mean, it's...



LEO:  Isn't this how you got into the whole business?



STEVE:  Yes.  It what brought me into Windows and Internet security.  And it's why I created ShieldsUP! was to bring an awareness of this so...



LEO:  People had their filesharing ports, just everybody had it just turned on.



STEVE:  Yeah.



LEO:  And it was just - you could see everything.



STEVE:  There were no personal firewalls.  This was pre-router.  This is when, god help us, people just plugged their Windows machines directly onto the Internet.



LEO:  Look, I can print from anywhere.



STEVE:  Oh, yeah, look at that.



LEO:  Look at that.



STEVE:  People's printers would, like, be spitting out random spoof pages because somebody thought, oh, this will be fun, we'll print on this random machine that's been exposed.  So anyway, Security Advisory - god help anybody who's doing this, but just for the sake of informing everyone - Security Advisory 975497.



LEO:  Okay.



STEVE:  Again, that's 975497.  If you have to have these ports open, if you refuse to use a VPN, OpenVPN or something, if you - even port filtering.  You should, for example, I mean, I have these ports exposed, but they're locked to the IP address of respective networks so nobody can see them.  They're absolutely nonresponsive.  It's only when you are at the IP that is permitted that there's any acceptance of packets.  And they can't be spoofed because these are TCP connections.  So my system is super tightly locked down.  But it is possible to filter these so that you're only able to see these ports from a known IP or range of IPs, which is very good, strong security.  But just having it wide open, it's like, okay, well, you get what you deserve.  But it is possible at least to disable v2 using this security advisory.  And I would absolutely recommend it.



Also I just wanted to mention the blurb in the news recently, Leo, about the FCC's proposed actions on the issue of Net Neutrality.



LEO:  Okay, yes, because Monday the FCC announced this.  Julius Genachowski said we're going to impose rules requiring this.



STEVE:  Yeah, it's apparently a contentious issue.  I can't remember the name of the female senator, the Republican senator from Texas...



LEO:  Kay Bailey Hutchison, yeah.



STEVE:  Kay Bailey Hutchison has already introduced legislation to block this.  So we've never talked about Net Neutrality.  Doesn't really bear on security.  So it's like, eh, okay, that's sort of off topic for us.  But it is something that continues to surface over and over again.  You remember that back in the day, as they say, this was an issue with AOL because people were hooking up to AOL and leaving their telephone connections up 24/7, often for days or weeks at a time.  And the argument was that AOL was getting a free ride on the carrier's connections.  Basically the phones were never - phone lines were never meant to be used this way.  And so the issue was, well, wait a minute, how is this fair for some users of the phone system to make a free local call in perpetuity, essentially, tying up this system, using it in a way that was really - it wasn't designed to be used for.  And the argument was, of course, that AOL was getting a free ride on this transit that was owned by other public utilities.



And so here we are again looking at these same issues as companies like Google and Microsoft are, the argument goes, trying to take unfair advantage of the broadband services by causing them to be used in a way that they weren't designed to be.  And of course the EFF and proponents of Net Neutrality argue, wait a minute, it's fundamentally wrong for some services being carried over the Internet to be charged differently than other services.  It ought to just be kept neutral.  So, you know.



LEO:  You know, it's funny, we were talking about it on TWiT a little bit.  And Dvorak was saying...



STEVE:  I would have loved to have heard John rant.



LEO:  Well, I'm a, you know, I believe in Net Neutrality, especially if you've - part of the problem with it is the name.  It really should be phrased "antidiscrimination on the 'Net," and then it makes a little more sense to people.  We're talking about not discriminating, preventing discrimination on the 'Net.



STEVE:  Well, and for example, not rate limiting certain types of traffic.



LEO:  Right.



STEVE:  Where we've seen ISPs dropping connections that they determined were bulk file-sharing connections.



LEO:  But Dvorak pointed out, and it's true, that there are arguments on both sides.  And one of the arguments against it is that you're making a regulation to fight something that's not really happening.  And I'm sure that Kay Bailey Hutchison's point is, well, the market should really determine this, not the government.  The problem is we don't really have real competition among Internet service providers.  In many areas you only have one or two.  So you don't - there is no market.



STEVE:  Right.  I've got Cox Cable.  Like it or not, that's my cable supplier.



LEO:  Right, right.  So on balance I think it's the right thing to do.  I can understand why people say, oh, do we need another government agency, another...



STEVE:  More regulation.



LEO:  More regulation.  But I think that it's probably a good idea to at least put a flag in the sand and say, you know, you can't do this, guys.



STEVE:  Well, and maybe just lay down some guidelines.



LEO:  Right, what can you do, yeah.



STEVE:  For the FCC to say, okay, look.  Here's the status of this argument.  This is what we think about it.



LEO:  Yeah, yeah.



STEVE:  I just want to briefly mention, many people have written asking what's going on with me and my Vitamin D blood levels.



LEO:  Yes.



STEVE:  And what I learned from literally testing every single week was the variation in the testing accuracy was completely masking what was going on.  So it was annoying.  Basically I was testing too often.  It's a little bit of a misnomer.  The results come back with one decimal point.  So it's like 22.2, 29.7, as if that decimal point had any meaning whatsoever.  What I saw was that from week to week there was, like, a plus or minus 5, I would guess, variation.  I mean, like, as in 5.0.  So this notion of giving me three digits of accuracy was ridiculous.  And it was chewing up my arm in the process, too.



So I just decided I would be checking in monthly to see what was going on.  We never did tell our listeners that because there was some reason to believe that it was wrong to bathe immediately after coming in from the sun, because you'd literally wash the Vitamin D that had been synthesized in your skin out of your skin, that I also did the experiment of deliberately not bathing, not showering at all with soap for a week to see if that made any difference.  And the fact is, it was after that week that I was, for the first time ever, no longer deficient in my Vitamin D level.  But that wasn't even - that wasn't clear with any scientific accuracy because the next week I was.



So there's a huge variation in the test.  It's very inaccurate, or relatively so.  So I will, over the course of a much longer baseline, be checking now only every four weeks.  And I'm going to be checking at the end of the month to see where I am.  I am now supplementing.  The whole put-me-in-the-sun thing was just to see whether I could get - just to see the effect of being in the sun.  And unfortunately I wasn't willing to do that over the course of month after month after month.  I thought, well, if I could do it over the course of a few weeks, that would be fun.  But it's hard for me to hold still for half an hour.



LEO:  I can imagine.  All that coffee inside you, for one thing.  No, I'm glad to hear that.  I've been supplementing with D ever since.  I just think it's not worth taking a chance on that one.



STEVE:  Oh, I agree.  In fact, I had set up - I wanted to read a couple letters that were just anecdotal, and I want to say evidence, but they're not evidence.  They were just anecdotal events which argue about the pro-immune system effects of D.  It's sort of on people's radar as we approach wintertime and this H1N1 'flu concern.  And of course the anecdotal evidence is that D is very good for your immune system.  And there was a clinic where, I think it was in Wisconsin, where during an H1N1 'flu spike there were two doctors in a clinic.  One who wrote the letter had all of her patients on D just because she was in Wisconsin - I think her name was Ellie.  She was in Wisconsin, and she believed that D was important.  The other doctor with whom she shared this clinic wasn't D-aware and wasn't doing anything.



During this spike they were once having coffee, and he commented that one out of ten of his patients had been tested positive for H1N1, and none of hers.  Zero.  So again, that's not scientifically accurate, I mean, it doesn't prove anything statistically.  But I'm more of an expert on statistics than I was last week before I wrote all this new code for the DNS benchmark.  But again, it's another data point on the radar.  I'm glad I'm aware of this, and all my friends and family are now.  And everyone's taking their little - I call it the little drop of sunshine.



LEO:  Yeah, yeah.



STEVE:  But it's a little yellow capsule of olive oil, basically.  And I did have a really fun SpinRite success story to share.  I love it when a letter that we receive starts out, "Wow, what a product."



LEO:  Always a good way to start.



STEVE:  Wow, what a product.  Justin, who didn't give me his last name, wrote.  He says, "I've been an administrator off and on for the past 12 years."  And he - I guess he means IT administrator.  "So I've seen a fair share of crashed hard drives.  I've seen how much money it can take to restore valuable data, and it's never cheap," he put in all caps.  He said, "My uncle called me a while back to see if I could maybe get some data off his crashed hard drive because he did not have the money to have it professionally done.  The drive sounded like it was a tin can of nuts and bolts when it ran," which really sounds quite frightening.  And he says, "And I told him it was unlikely that I would be able to do anything with it.  I got estimates from a few of the big name hard drive restoration companies, and the total was to be in excess of a thousand dollars, no matter who I talked to, and with no guarantee of success.



"I've heard of your product before, but for whatever reason I just didn't imagine that it could resolve the problem this drive was having.  But last night I figured, what the heck.  So I purchased and downloaded your product and easily created my boot disk and was quickly underway to see if this crashed drive could be accessed just one more time."  Of course, that's what everybody wants.  It's like, oh, my god, I'm sorry...



LEO:  Just once more, yeah, please.



STEVE:  Just [indiscernible] to me one last time.



LEO:  One more time.



STEVE:  I promise I'll get all the data off I need.  So he says, "It took 14 hours to complete the task because of how bad of shape the disk was in.  As a matter of fact, as I watched SpinRite's progress screen and noticed all of the bad sectors that it was turning up, I just knew that it was worth a shot because there was no way" - well, he says, "I just knew that it was worth a shot, but there was no way I'm getting data off of this drive.  Well, as I write this now, I'm copying all of the wanted data off the old drive, onto a new drive!  I am absolutely amazed that this worked on a drive that sounded the way this one did.  And for 90 bucks?  Too cheap.  This drive was barely even recognizable in the system BIOS, much less accessible in Windows.  Windows would freeze just trying to boot off a good disk while this bad disk was attached as a secondary.  That's how bad this disk was messed up.  It would mess everything else up.  Thank you, guys.  My uncle will now have all of his data returned, most of which was irreplaceable pictures of his family, children and grandchildren, et cetera, et cetera, data that is priceless.  Good job.  Justin."



LEO:  Fantastic.



STEVE:  Yeah.  Love it.



LEO:  That's a nice - that's a nice story.  I like that.  All right, Steve, I'm ready.  I've got security maxims all queued up.



STEVE:  These are great.  I think, as I said at the top of the show, they're compiled by a guy who's been living and breathing security for a long time.  We'll find some references to a well-known cybersecurity guru, Bruce Schneier, in here.



LEO:  Love Bruce, yeah.



STEVE:  And there's a - I think what these reflect, as we'll see as we go through them, is a philosophy that many of our listeners I'm sure have grown to understand and probably even adopt.  From all the feedback that we get, when people say I aced my security exam, I've learned more about security from the podcast than I did in college, blah blah blah, I mean, there's a - it's sort of hard to describe, but a clear, discernible approach which I guess for lack of a better word involves skepticism about the assumptions of things being secure.



LEO:  Well, that's your maxim, Trust No One.



STEVE:  Yeah, TNO is - exactly.



LEO:  That's all you really need to know.  That's the starting point.



STEVE:  That's a good starting point.  And we'll see that reflected though these, also.



LEO:  Well, let's start with Maxim #1, the Infinity Maxim.  You want me to read it, or...



STEVE:  Yeah, why don't you, and then we'll comment.



LEO:  Okay.  So again, these are from Roger Johnston, who is a CPP at the Argonne Vulnerability Assessment Team, Nuclear Engineering Division, Argonne National Lab, DOE.  This guy protects us and protects those nukes.  So I'm glad...



STEVE:  Yeah.



LEO:  I'm glad he's [indiscernible].



STEVE:  These are sort of his pithy distillations of fundamental truths about the nature, the fundamental nature of security.



LEO:  Infinity Maxim, and you kind of referred to this earlier, there are an unlimited number of security vulnerabilities for any given security device, system, or program, most of which will never be discovered, either by the bad guys or the good guys.  Now, should I read his comment, too?  Or is that...



STEVE:  Yeah, I think his comments are normally good, too.  So, yeah.



LEO:  All right.  I'll include that.  We think this because we always find new vulnerabilities when we look at the same security device, system, or program a second or third time, and because we always find vulnerabilities that others miss, and vice versa.



STEVE:  And you're right, I think; so this is his Infinity Maxim, meaning that everything is insecure basically.



LEO:  Nothing's secure, yeah.



STEVE:  Exactly, that fundamentally, the closer you look, the more you find.  And so the presumption of security - it's a little bit about I think there's - certainly we see all around us instances of denial.  It's easy to say, oh, yeah, we got security, mostly because we want to say we've got security.  And so it's hard to argue until you hold up in someone's face where there's a problem, and they go, oh, okay, we'll just fix that, and now we've got security.  Eh, no.  Let's look some more, and we'll find some more problems.



LEO:  It's not exactly a mathematical proof.  But it does, it kind of stands to reason just empirically that every time you look, you find another one.



STEVE:  Maybe it's that, like from a standpoint of entropy, randomness, it's more difficult to construct than it is to destruct.



LEO:  Yes.



STEVE:  That is, it's much more difficult to order and organize than it is to disorder and disorganize.  And breaching security, breaking security is fundamentally about destroying something.  It's about bringing randomness back to a system that was trying to be ordered against it.  And so it's fundamentally an uphill battle.



LEO:  Yeah, yeah.  Impossible.  Maxim #2, the Thanks for Nothin' Maxim.  Thanks for nuttin'.  A vulnerability assessment that finds no vulnerabilities, or even only a few, is worthless and wrong.



STEVE:  I like the "Thanks for Nothin'."



LEO:  Thanks for nothin'.



STEVE:  So someone says, okay, I want you to assess our security.  And they come back and say, ah, perfect, you've got perfect security.



LEO:  That's not what I want to hear.



STEVE:  Thanks for nothin'.  How much did we pay you for that?



LEO:  It's perfect.  There is no such thing.  The Arrogance Maxim:  The easy of defeating a security device or system is proportional to how confident/arrogant the designer, manufacturer, or user is about it, and how often they use words like "impossible," as in "impossible to crack," or "tamper-proof."



STEVE:  Yeah, the Arrogance Maxim, I love that.  It's like...



LEO:  Yeah, it's so true.



STEVE:  Well, and it's funny, too, because if you listen to the words that security people use, like if you listen to the way Bruce Schneier talks, I mean, he'll never - you couldn't make him say, no, it's invulnerable, or there are no vulnerabilities.  Always the word "known" is there, no known vulnerabilities.  There's nothing that we know about it that is vulnerable, or currently vulnerable or, well, we know what the theoretical problem is, but it's unlikely before the universe ends that that will be a problem.  I mean, there's always a caveat because, if you're security aware, you recognize that, I mean, the reality of the need for lack of arrogance.  I mean, arrogance will get you in trouble faster than anything else. 



LEO:  At best, I mean, it's probabilistic.  At best you could say there's a probability that it's secure.  That's the most you could hope for.  And you do that all the time.  I'll try to pin you down and say, well, this makes it secure; right?  And you'll say, well...



STEVE:  More secure.



LEO:  More secure.



STEVE:  Or maybe.



LEO:  Maxim #4 ties right into that:  Be Afraid, Be Very Afraid.  If you're not running scared, you have bad security or a bad security product.  And his comment is fear is a good vaccine against both arrogance and ignorance.  



STEVE:  Yeah, I think that's a very good point.  I mean, while I am coding CryptoLink, there will be nothing on my mind more than the fear that I'm going to make a mistake.  I mean, I'll be about as far away from arrogance as I could imagine.  I'll be looking at every single thing I do, line of code, algorithm, protocol, just like I hope, I hope, I hope this is right.  Yeah.



LEO:  Well, this is almost a corollary then.  The So We're in Agreement Maxim says, if you're happy with your security, so are the bad guys.



STEVE:  I love that.  That's great.



LEO:  Ignorance is Bliss Maxim:  The confidence that people have in security is inversely proportional to how much they know about it.  It's true.  Doing this show has made me much more scared than ever before.  And his comment is, security looks easy if you've never taken the time to think carefully about it.



STEVE:  Yeah.  And I think if anything else, you're right, Leo, that's what this podcast over the years has helped to imbue our audience with is this, again, ignorance was bliss.  They're no longer ignorant.  And now they really have a much greater appreciation for how hard security is.



LEO:  Yeah.  Sometimes, though, you kind of wish you could go back.  Everything's safe.



STEVE:  Exactly.  It was just nicer.  You could sleep at night.



LEO:  It's all fine.  Everything's going to be fine.  Here's the Weakest Link Maxim:  The efficacy of security is determined more by what is done wrong than by what is done right.  He says the comment here, because the bad guys typically attack deliberately and intelligently, not randomly.  Now, you're going to have to explain this one.



STEVE:  Well, a perfect example we talked about a few weeks ago with the vulnerability that was found in the use of the MD5 hash which was used to sign the security certificates for SSL.  So the point is, there was this little, tiny, really hard to deal with or to leverage, microscopic flaw in this powerful, sophisticated, interlinked, beautiful technology for guaranteeing the identity of someone you were connecting to.  And because the guys who were attacking this managed to come up with a way that they could control some aspect of a slight defect, I mean, arguably, okay, this is not a problem defect.  They've turned it into one.  So the weakest link in this whole chain brought the whole thing down.  It really is the case.  It is, unfortunately, no matter how good the security of your entire system is, the bad guys are looking, and as he points out in the comment, not randomly, but they're looking for some entry point, the weakest link.  And that weakest link determines the security of the entire system.  And again, it's another example of why this is just so fundamentally difficult.



LEO:  Yeah.  That makes sense.



STEVE:  It's not like, well, it's not fair.  We want it to be the average security.



LEO:  Right, right.



STEVE:  It's like, sorry.



LEO:  We worked so hard on this.



STEVE:  Yeah.  Doesn't work that way.



LEO:  We did almost everything right.  High-Tech Maxim:  The amount of careful thinking that has gone into a given security device, system, or program is inversely proportional to the amount of high technology it uses.  So in security, apparently, high technology is often taken as a license to stop thinking critically.



STEVE:  I think that's really interesting.  It's like, now wait a minute, we have geometric folded space quantum entanglement encryption.  It's like, uh-huh, but didn't you leave the back door open?



LEO:  But it's high tech.  It's high tech.



STEVE:  Exactly.  Sometimes this notion of, like, using all this fancy stuff, and it's like, oh, look how fancy that is.  Look at all the little blinky lights, all those lights...



[Talking simultaneously]



STEVE:  Just get a big padlock.



LEO:  That's kind of a universal thing, you know, in society.  Oh, it's modern.  It must be better.  Oh, it's high tech, it must be better.  Oh, it's digital, it must be better.



STEVE:  And frankly, we're all stuck on this, I mean, I chastise myself for wanting the latest version of the software.



LEO:  Yes.



STEVE:  I mean, we're always - we're sort of feeling like, oh, maybe the next one will be better, hoping that it's like it won't hang or it won't crash.  I don't even mean security flaws.  I just mean there's this - we're stuck on this gravy train of updates, wanting the latest and the greatest, thinking that the latest is the greatest.



LEO:  Yeah.  Boy, that's exactly it, isn't it.  Latest does not mean greatest.  In fact, in security it's the opposite.



STEVE:  Yeah, I'm using...



LEO:  Mature means safer.



STEVE:  I'm using Studio 7 of Pinnacle for video editing, even though they're at 12 or something...



LEO:  They are at 12.



STEVE:  ...because it was the best.  And I'm using an old HP, not 35, an HP-21, I think it is, the old scientific calculator, which is really old now.  But it was the best.  And Paint Shop Pro, I use version 5, I think, which is like - because they went too far.  They added too much junk to it, and it slowed it down, and it became a problem.  So, like, okay, no.  I'm just going to stay with what I have.



LEO:  That's often true in software, isn't it.



STEVE:  Yeah.



LEO:  Maxim #10, the Dr. Who Maxim.  It's in quotes, so I'm thinking this must be a quote from Dr. Who.



STEVE:  Yes, it was.



LEO:  "The more sophisticated the technology, the more vulnerable it is to primitive attack.  People often overlook the obvious."  It's like the Death Star.  There was this one...



STEVE:  Yeah, that little hole...



LEO:  ...little mistake in the whole thing.



STEVE:  Right, but looking at the size of this planetary attack thing, it's like, oh, my god, what are we going to do?



LEO:  And there was one little attack vector.



STEVE:  Yup.



LEO:  This is the Low-Tech Maxim:  Low-tech attacks work, even against high-tech devices and systems.  Comment:  So don't get too worked up about high-tech attacks.



STEVE:  You know, it's sort of...



LEO:  Well, social engineering is often the way people get into stuff.  You can spend a lot of time on getting the right algorithm, but then somebody asks you what your password is, and you tell them.



STEVE:  Or, like, imagine, when I think of low-tech attacks work even against high-tech devices, I think, you know, here's the alarm system, and you just take the batteries out.



LEO:  Yeah [laughing].



STEVE:  It's like, oh, whoops.  All fancy, but now it's just powered down.



LEO:  Oh, these are so good.  This is refreshing because it really - it reminds us of stuff we always have known, but you just forget.



STEVE:  Yup.



LEO:  Or of things that you do unconsciously that you really ought to remember.  Maxim #12 he calls Schneier's Maxim #1 or, a.k.a., the Don't Wet Your Pants Maxim.  The more excited people are about a given security technology, the less they understand, one, that technology; and, two, their own security problems.  Comment...



STEVE:  I thought that was fun.



LEO:  Yeah.



STEVE:  And so the more excited they are.  So again it's like, oh, we've got gazillion-bit encryption.  Isn't that great?  It's like, uh, okay, calm down.  That's, you know, maybe better than gazillion-minus-one-bit encryption.



LEO:  Right.



STEVE:  But it's not that clear that this really solves the problem.  Or that that is the problem that needs to be solved.  You know, we've seen so many examples over the years of really good technology being misapplied, and the bad guys just slip right around it.  They're excited because they realize there's a simple way to solve the problem.



LEO:  Maxim #13, the Too Good Maxim:  If a given security product, technology, vendor, or technique sounds too good to be true, it is.  And it probably sucks big-time [laughing].



STEVE:  This makes me think of all of the ridiculous claims about some random, homegrown encryption algorithm.



LEO:  Yeah, yeah.



STEVE:  And thank goodness we're seeing that less now.  But you still encounter it from time to time.  Some website will say, oh, my 13-year-old son came up with this amazing encryption technology, and so that's what we're using.  It's like...



LEO:  Oh, boy.



STEVE:  Thanks anyway.



LEO:  Oh, boy.  Maxim #14, Schneier's Maxim #2, the Control Freaks Maxim:  Control - oh, I know this one.  Control will usually get confused with security.  Even when control doesn't get confused with security, lots of people and organizations will use security - oh, this is the corollary.  That's Schneier's Maxim, Control Freaks Maxim.  And really Johnston's corollary is, even when control doesn't get confused with security, lots of people and organizations will use security as an excuse to grab control.



STEVE:  Yup.



LEO:  Mm-hmm.



STEVE:  So I love that.  It is absolutely the case, that is, this issue of control getting confused with security.  Many, many people believe that, for example, bolting things down is a replacement for, or actually equivalent to, security.  And it's just not the case.  You'll often have, for example, in a corporate environment, the security people being unnecessarily controlling and still having security problems because control doesn't automatically bring high levels of security.



LEO:  The TSA leaps to mind here.



STEVE:  Uh-huh.



LEO:  Where, you know, they make you take off your shoes as you go through airport security.  I don't know if that enhances security.  It enhances control.



STEVE:  And actually we're going to get to a specific maxim that talks about the security theater and...



LEO:  The theater of security, yeah.



STEVE:  The theater of security.



LEO:  Yeah, Bruce Schneier talks about that lot, actually.  This is a big hot button for him.  Maxim #15, Father Knows Best Maxim:  The amount that non-security senior managers in any organization know about security is inversely proportional to, one, how easy they think security is; and, two, how much they will micromanage security and invent arbitrary rules.  Another control maxim, yup.



STEVE:  And again, it's this - there's a problem with senior management that doesn't know anything about security and, consequently, thinks it's easy and doesn't understand why...



LEO:  Right.  Oh, what's so hard?



STEVE:  Yeah, exactly.  It's like, oh, well, you know, what are you making such a big deal about all this?  It's obviously just easy.  Just go do your security job.  Okay.



LEO:  If you were just doing your job, none of this would have happened.  This is Big Heads Maxim:  The farther up the chain of command a non-security manager can be found, the more likely he or she thinks that they understand security, and that security is easy.



STEVE:  Sort of the Peter Principle of security.



LEO:  Yeah, they rise to the top, don't they.



STEVE:  Yeah.  Love that.



LEO:  Voltaire - oh, I'm sorry.  I'll get to Voltaire's Maxim in a second.  This is the Huh Maxim:  When a nonsecurity senior manager, bureaucrat, or government official talks publicly about security, he or she will usually say something stupid, unrealistic, inaccurate, and/or nave.



STEVE:  Yeah.  So that's just nonsecurity people who are being asked security questions, who basically sort of make it up as they go along.



LEO:  That leads us to Voltaire's Maxim:  Common sense isn't all that common.  He says real world security blunders are often stunningly dumb.  And in defense of managers, they often come from so-called security experts, too.  This can go both ways; you know?  It's not just the upper-level people that can do incredibly stupid things.  We're all capable of it.  We all have a blind spot here or there.



STEVE:  Yeah, I think that's really true.



LEO:  Yeah.  And really arrogances can get you in big trouble of thinking, well, I know better than they do, or they're just foolish.  Here's the Yippee Maxim:  There are effective, simple, and low-cost countermeasures, or at least partial countermeasures, to most vulnerabilities.  You think that's true?



STEVE:  Well, he - okay, now, this, I think, does apply more to the physical security world than to the cybersecurity world.  So this is an example of where I would argue that physical and cybersecurity diverge a little bit.  So he's, like, thinking, okay, if you've got something really valuable, just stick it in a safe that's secure instead of surrounding it with radar fields and motion sensors and all this where it's all fancy; but it's like, okay, just keep it out of sight, lock it up, for example, in physical security terms.



LEO:  Yeah, very straightforward.



STEVE:  So I think it is very often the case that people get themselves all wound up in very complex scenarios where it's like, wait a minute, you know, your grandmother would have just solved it this way.  Oh, yeah, and that works.



LEO:  You know, there's a corollary there, the Bond Villain Corollary, where the more complex the device designed to kill James Bond, the more likely he will escape.  Right?



STEVE:  Right.  Or that might be the Roadrunner Maxim, also.



LEO:  Yes, the Roadrunner Maxim, yeah.  Here's the Arg Maxim, and it's not Talk Like a Pirate Day:  But users, manufacturers, managers, and bureaucrats will be reluctant to implement these effective, simple, and low-cost countermeasures for reasons of inertia, pride, bureaucracy, fear, wishful thinking, and/or cognitive dissonance.



STEVE:  And I might add to that list, or previous investment.



LEO:  Yes.



STEVE:  It can very often be that people become invested - and I guess that would be inertia and pride.  They become invested in a particular solution, and someone comes along and says, yeah, but just do that.  It's like, oh, no, no, no, no, we have - this is version 3, and we paid a lot of money for this.  So that's what we're going to use.



LEO:  You know, we've gotten through 20, which is only half of this first chunk.  Maybe it would be a good time to stop here because I don't want to use them all up.  These are great.  And I also don't want people to get in a blur about all of them because they're so good, it's kind of good to think about it a little bit.



STEVE:  Perfect.  Let's - we will hold the balance for a future episode, Security Maxims Part II.



LEO:  20 security maxims from Roger Johnston, who deserves a lot of credit for these.  But I tell you, anybody who's worked in security, I just can hear their voices.  They know these.  These are well known by people who've had to deal with this for a long time.  And it's good to share this with the rest of us.



STEVE:  Well, it's funny, too, as I'm scanning ahead and thinking, oh, okay, I can't wait till we get to the other ones, so...



LEO:  Well, we're going to have to do this again.



STEVE:  We'll do that again.



LEO:  Steve, always a pleasure.  Steve Gibson is the author of a great program for hard drive maintenance and recovery, SpinRite.  You must have this.  Go to GRC.com, that's his website, and get a copy for yourself.  And you know what I told somebody on the radio, and I just want to make sure I didn't say this incorrectly, he was having a problem that really sounded like a SpinRite - that SpinRite could solve it.  And but I said, you know, there are a variety of problems you can have.  There's hardware problems.  SpinRite's not a - can't fix a broken, busted head or frozen bearings.  And then there are file system problems.  SpinRite doesn't really work at the level of the file system.  So but it sounds like this guy had just kind of classic symptoms.  I said it sounds like SpinRite's going to do it.  But I told him you have a 30-day money-back guarantee, do you not?



STEVE:  No.  It's no day limit.



LEO:  Unlimited money-back guarantee.



STEVE:  It really is.  I mean, I don't ever want...



LEO:  You should make it 30 days.



STEVE:  I don't ever want anyone to feel like they made a mistake buying SpinRite.  And so I don't want anyone - I would not want anyone's money who...



LEO:  That's perfect.



STEVE:  ...thought that they regretted their purchase.  I mean, we don't have a demo because there's really no way to demo it.  It fixes the problem when you run it.



LEO:  You're done.  The demo's done.  Right.



STEVE:  Yeah.  So I didn't want to have it, like, time limited or expiring or anything.  So instead we just give you your money back.  If for whatever reason, with no questions asked, you're not happy, we'll give you your money back.



LEO:  Well, good.  That's what I told him.



STEVE:  And not even 30 days.  I mean, maybe five years would be pushing it a little bit.



LEO:  We had a - didn't you - we had a guy a couple months ago or a couple weeks ago who said, yeah, it was like five years later.  Yeah, there's a limit.  That's why I said 30 days.  But anyway.  You could try.



STEVE:  It's really, again, I would not want any - I would never keep anyone's money who wasn't happy with SpinRite.



LEO:  Doesn't work for you...



STEVE:  We'll guarantee your satisfaction.



LEO:  ...your money back.



STEVE:  Just a flat-out satisfaction guarantee.  And most of the time, I mean, we've run across situations that seemed to be file system related.  There was one just the other day where it wouldn't - some customer reported that he had to soften chkdsk's running by doing a /i option on chkdsk, which told it don't check the indexes, the NTFS file system indexes so closely.  And he said, you know, do you think - does that sound like something SpinRite would fix?  And I said, you know, technically no.  But I'm always surprised by, literally, I mean, as the author I'm surprised by what SpinRite does.  It surprises me.  So I guarantee you that, if it doesn't fix it, you can have your money back.  And he wrote back later, he says, well, I don't know why, but it fixed it.  So I go, okay.



LEO:  Well, what it tells me is that most of the time the problems are hard drives' bad sectors, as opposed to a cosmic ray hitting the file allocation table or the index tables or, you know...



STEVE:  Well, yes.  And especially with the NTFS file system.  It is a file system that has a lot of redundancy in it.



LEO:  Ah.



STEVE:  So it's not like the FAT file system that was always getting lost clusters.  Remember the old lost clusters problem.



LEO:  Oh, horrible, horrible, yeah.



STEVE:  And so the FAT file system tends to be structurally more robust.  So you don't often have structural problems unless they are caused by physical problems.



LEO:  Right.



STEVE:  So when you fix the physical problems, what looked like a structure problem gets fixed in the process.



LEO:  That's why it's worth trying.  GRC.com.  And while you're there, by the way, check out ShieldsUP!, all the free programs Steve offers.  He's very generous with his time and his software.  Some great stuff on there.  And of course the great security forums.  In fact, we'll be doing questions next week.  So if you want to leave a question about anything we talked about on the show, or something you've heard, you can go to GRC.com/feedback and leave a question there.  We'll get to some of your questions in the next episode.  Steve, always a great pleasure.



STEVE:  Talk to you soon.  Actually, talk to you next week.



LEO:  Next week, on Security Now!.



STEVE:  Okay, Leo.  Thanks.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#216

DATE:		October 1, 2009

TITLE:		Listener Feedback #76

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-216.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 216 for October 1, 2009:  Listener Feedback #76.



It's time for Security Now!, the show that covers all things secure and security-wise, protecting yourself online with Mr. Steve Gibson, the king of security, the guy who discovered spyware, coined the term, wrote the first antispyware program, has ever since been writing great free utilities for all of us to protect us, and for the last four years has been educating us.  Episode 216.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  In our fifth year of broadcast excellence.



STEVE:  And apparently no sign of slowing down because the industry keeps throwing new, bizarre things at us that are fun to share.  So, yes.



LEO:  Oh, I tell you.



STEVE:  It's not getting any better.



LEO:  We've got a good Q&A.  Our listeners are really good at coming up with questions for Steve, and he'll be answering those.  Our 76th feedback episode.  I'm sure we have secure - and in fact I know we have security news.



STEVE:  Yup.



LEO:  In just a little bit.  And probably some errata, as well.  Real quickly, before we get to the errata, let me mention our friends at GoToMyPC, who - it's really our friends at Citrix.  You and I, Steve, were talking, it was kind of fun, about the good old days of trade shows and the late-lamented COMDEX.



STEVE:  Yeah.  I remember when the text used to scroll up the screen, Leo.



LEO:  Yeah, those were the days.



STEVE:  Those green screens.



LEO:  Those were the great old days.  So I was just - I was thinking, because you said COMDEX really was, you know, it was the big computer show, which went out of business about four or five years ago.  We're going to go to CES, that's why I asked you, and we're going to be broadcasting from there.  But it's not the same.



STEVE:  Oh, cool, cool.



LEO:  Yeah, it's not, it's not the same.  COMDEX was computers.  CES is everything.  But I remember, as you said, you would hang out with Gates and...



STEVE:  And Ballmer and Philippe Kahn and, I mean, lots of people who, you know, the contemporary PC industry has forgotten.



LEO:  Absolutely.  Absolutely.  And it reminded me of a guy that I met, that Gina Smith introduced me to, probably it was in 1996 or '97, Ed Yakabuchi.  You remember Ed at all?



STEVE:  Oh, of course.



LEO:  Great guy.



STEVE:  Yeah.



LEO:  I mean, one of the - he reminds me of Philippe Kahn, one of the - just a big, vibrant, exciting guy.  He was the founder of Citrix.  He actually worked for IBM.  And I believe it was he, you know, the joke at the time was that IBM wrote Windows NT for Microsoft while Microsoft was writing OS/2 for IBM.  They were kind of - they traded engineers.  So he was working on the NT team and while doing that really created, you know, learned about the kernel and became an expert in remote access.  He wrote the original remote access stuff for RDP.  Actually I think Microsoft licensed RDP from his company, Citrix.



STEVE:  That's correct, Microsoft did get the original remote desktop code from Citrix.



LEO:  From Citrix, yeah.  Citrix was the company, the remote access company.  They've grown.  They've expanded.  They've produced not only high-end enterprise solutions, but also consumer solutions.



STEVE:  Well, I'm wondering why you're going to Dubai.  You didn't...



LEO:  I didn't tell you that, did I.



STEVE:  No.



LEO:  I am speaking at TEDx Dubai, which is a great honor.  You know, TED is the big conference in Long Beach, down your way.



STEVE:  Right.



LEO:  This is a - they do a franchise, so they're all over the world.  They just had one in Toronto.  And when Giorgio wrote to me - I don't say his last name because I don't want to mispronounce it.  He's Italian, but he lives in Dubai, as a lot of people in Dubai are expats.  Giorgio Ungania - I hope I'm saying that right, Giorgio - organized TEDx Dubai.  And I'm going to be speaking there on the 10th.



STEVE:  Cool.



LEO:  So Jennifer and I fly out Tuesday.  It takes - it's a long flight.  I think it's 15 or 16 hours.  We'll arrive - we'll leave Tuesday afternoon, arrive Wednesday night in Dubai.  And but I can't wait.  I've never been there.  I'm dying to see it.  And then Saturday I speak, and then Monday I fly back, and I'll be here next - the following week.  But so next week it'll be Alex Lindsay doing the show.



STEVE:  Right.  I've heard lots of things about Dubai.  Like it's got 90 percent of the world's super tall skyscraper cranes because they had to, like, ship all the cranes to Dubai to make the buildings, the place is growing so fast.



LEO:  It was just the desert, you know, it was a very - and they've just, you know, poured tons of money into it to make it kind of this global business marketplace.  They have the world's tallest building, the Burj, just opened, like just opened.  So I'll be able to see that.  I'll go up there.



STEVE:  Yes.  I think it is, it's just massive money.  It's just money, money, money, money.



LEO:  Yeah, it's a lot of money.  So I can't - it's going to be great.  And really full of expats, people from all over the world there.  It's become kind of this, you know, it's like the marketplace, the global marketplace.  People just kind of go there.  So, you know, it's continuing in my world journeys to see the interesting new places to be.  So I couldn't say no.  I can't wait.



STEVE:  Yeah, cool.



LEO:  It's going to be fun.  So let's - should we do the security news before we get - go too far [indiscernible]?



STEVE:  Oh, of course, of course.  Many listeners wrote in to bring my attention to Carbonite's license agreement.  And I wasn't sure whether we had gotten carried away in talking about the level of security and encryption that they apply.  But, you know, they're a sponsor.  They have been a sponsor of the show.



LEO:  Yeah.  They told me, and I'm going by what they told me, that they told me that they use AES-256 on the local machine and then SSL to upload.  Is that not the case?



STEVE:  Well, what's the case is that they can decrypt it.



LEO:  Really.



STEVE:  And that's what's important is that their license says that if they believe there's child pornography, or if they're under a government subpoena for whatever - or if they need to for technical support reasons to make sure their stuff is working, they have the ability to decrypt the data.  Now, I assumed that because one of the features is you're able to log on from elsewhere on the Internet and get access to your backed-up files.



LEO:  Right.



STEVE:  Well, that means that they have to be able to decrypt it and send it.



LEO:  They must have the key, yeah, yeah, yeah, yeah.



STEVE:  Yeah.  So anyway, I wanted to make sure that we were clear about that caveat.  I mean, the benefit is for a certain class of user.  It's transparent and in the background and easy.  And it protects you from your hard drive cracking, or crashing, rather.  But it is the fact, it is the case that they would have the ability, they have the key, the encryption key used for your data being stored.  And a bunch of our listeners who are on the ball, and of course that's why they're listeners...



LEO:  Right on, yeah.



STEVE:  ...checked that and said, whoa, wait a minute, just make sure that that is...



LEO:  So I correct - I'll correct myself because I went too far.  They didn't tell me that.  I was just reading into it.  But of course you're right.  They would have had - they would have to have the key to be able to send you a clear copy.



STEVE:  Exactly.  If you log in somewhere else, then they would have to be able to do it.  And it's interesting, their agreement says that, if you do that, then your data will be sent in the clear.  And it's like, whoa, wait a minute.  I would think that would be SSL-encrypted so that it wouldn't transit in the clear.  But their paragraph 15 at the bottom does state that, if you access your data from another location other than your main machine, then it won't enjoy the encryption that they normally apply.  And so you acknowledge that, you know, you're allowing that to happen.  So...



LEO:  Yeah, I mean, I would check and see if it's HTTPS.  It may still be HTTPS.  You know how lawyers are.  They want to hedge everything, just in case.



STEVE:  Yup, yup, cover themselves.



LEO:  So, you know, and I think probably - I would bet they for legal reasons don't want - they do want to be able to respond to subpoenas.  But this is, if you're worried about that, that's why you use TrueCrypt or something else where you and only you have the key.



STEVE:  Well, for what it's worth, yes.  I mean, that's why I...



LEO:  You could also TrueCrypt before you upload it, if you want.



STEVE:  No.  Because their system runs autonomously.  They explain that they look at the files, they examine the headers, I mean, they're looking into your data on your machine to, like, make sure the file size is right, look for changes.  They may be doing checksums or something.



LEO:  Oh, they'd have to do that, you're right, otherwise they wouldn't know if it was new or not.



STEVE:  Right.  So they're doing autonomous, you know, in the background work.  I'm a Jungle Disk user because - and we had the author on the show.  I know exactly how it works, where only I have the key.  So Amazon with their S3 data storage service, they're storing completely pseudorandom data that they have absolutely - that is completely opaque to them.  So I'm comfortable with that.  But it's a more techie and not an automatic solution.  So again, I think there's certainly...



LEO:  It's also more expensive.  You pay the price.  If you have the same amount of data, you're going to pay more.



STEVE:  Yeah.  I think, you know, there's certainly a class of user for whom Carbonite makes absolute sense.  So I think - but I just - I did want to respond to our listeners and make it very clear that it would take a court order, but that that can be done at their end.



LEO:  Well, I found - I learned this week that the same thing is true of Twitter.  We had a little incident with somebody posting death threats on Twitter and tried to get the information.  I was just hoping I could just send a note to Twitter saying, you know, just tell me if the kid's - this person's in California, so I know if I should worry.  And they said no, you can't, we need a - you need a court order.  So we contacted the local police.  He's getting a court order.  But, and that's how it's - I guess that's how it's supposed to be.  I think that that's kind of the normal circumstance for most of this stuff.



STEVE:  Well, and for example, once upon a time, years ago, there was someone who I knew was nearby sending denial of service noise at GRC.



LEO:  Right, right, I remember that, yeah.



STEVE:  And so I could tell from their IP that they were a local Cox Cable customer.  And I had some contacts here with the local FBI.  And I said hey, you know, I've found these four machines.  I'm sure it's not anybody who owns the machine.  They just have some junk on their machine.  And so they had to produce a subpoena to allow Cox to tell them the owners of those IPs.  And then they called and said, hey, we've got a person we work with who would like to come take a look at your machine.  You probably don't know it, but it's infected with some stuff, and wouldn't you like that fixed?  And so they said, oh my goodness, we had no idea.



You know, it's funny, too, because the kids were complaining they could no longer burn CDs because the machine was so - it was so overrun with junk.  I mean, it took, like, an hour to boot because it was the war of the malware, it's like who was going to play king of the hill inside the machine just every time it booted.  It was a disaster.  And they were using Kazaa back in the day.  They were like, well, we like free music.  It's like, oh, yeah, I bet you do.



LEO:  Well, very - yeah.  And in fact I got the - we also talked - I talked to the FBI in San Francisco, too, so.



STEVE:  Yeah.



LEO:  I guess if it's on the Internet they count it as interstate or a federal thing despite [indiscernible].



STEVE:  Yeah.  Well, and in general, I mean, the thing to look at is that these companies that have records, they want to be protected against their customers suing them for disclosing the information.  So, for example, in my case, even though Cox would have happily, I mean, it wasn't like they were trying to hide the information, but they have an agreement with their customers to maintain their customers' privacy.  So the company has to ask for the - has to literally say, please make us give you this data.  They have to ask to be compelled to do it so that they're able then to say to the customer...



LEO:  Privacy.  You have privacy.



STEVE:  We were subpoenaed.  We had no choice.  And again, for example, that's why this paragraph 15 of the Carbonite agreement says if we are subpoenaed, we will turn over your data.  Just, you know, FYI.



So the top of the news is for me very exciting.  Yesterday, which is - or day before yesterday, given that the podcast is released on Thursdays, that is to say, Tuesday the 29th of [September], Microsoft Security Essentials was released.  That's - and you can just put Microsoft Security Essentials into Google, or it's Microsoft.com/security_essentials.  And this is the awaited first Microsoft free antivirus and antimalware scanning and monitoring overall prevention utility from Microsoft that I'm very excited about.  I like the idea that it is small and lightweight.  I like that it's from Microsoft, so I have the sense that it'll integrate properly with Windows and won't be in the way.  It's not going to be jumping up and down, trying to get my attention and reminding me that it's time to re-up my license or anything.  All of the reviews that have been done so far have been positive.



Having watched it, the one thing I can say is in full system scan mode, it makes SpinRite look fast.  It is very slow.  Now, its speed is a function of the type of file it's looking at.  I've noticed that it just whizzes through a block of JPEG image files.  Boy, when it hits an EXE or a DLL or something executable, it spends some time.  Now, I think that was the right choice because, first of all, you're not having to do a full system scan all the time.  You want to do, I would say, that once when you first install it because then it's able to look at changes and new things coming into your system and check them incrementally, in which case it's not a problem.



The benefit of it being so slow is that it is being thorough, and it is not generating false positives.  You can imagine with Microsoft being as security, well, as customer support shy as they are, you know, we've talked many times how unfortunately Microsoft leaves things turned on by default because they don't want people calling them, asking them how to turn them on.  So they're just on.  Well, the last thing Microsoft wants is a technology which is going to be generating false positive alerts.  And many of the looser, faster heuristic technologies do have the problem of generating false positives.  Every few months our support email starts getting reports that some random piece of my freeware, which hasn't changed in a decade, suddenly has spyware in it.  It's like, no, it doesn't.  



LEO:  Do you think there's something about your software that lends itself to that?  Or why is it?



STEVE:  No, I hear about it from everybody.  Mark Thompson has the same thing happen.



LEO:  Everybody, okay.



STEVE:  The problem is, these scanners are trying to be very fast, and they're trying to be sensitive enough, but not too sensitive.  Microsoft has clearly taken a different approach, where they're really affirmatively identifying, rather than just sort of scanning across the top and saying, oh, look, this might be a problem.



LEO:  It's a much slower scanner than most.  I mean...



STEVE:  Oh, it's painfully slow.



LEO:  Even the, quote, "quick scan" is slow.



STEVE:  Like I said, it makes SpinRite look fast.  SpinRite is known for taking its time and being thorough.  And this thing is really slow.  But again, you would do the full, deep scan, I would say, once upon installing it.  Then you can set it up with a schedule, and it is watching your system on the fly.  I'm just excited about this because I've got friends who for the last couple months I've said, like someone will buy a computer and say, hey, I got some notice that Trend Micro wants to bill me $39.95.  I'd say, okay, just hold on.  In a couple months there's going to be something from Microsoft which is free, free, free, free.



Now, we'll remember that this is only for the client machines, not server platforms.  They have their full-strength commercial product from which this is descended for their server platforms.  But for all of us running XP and Vista and Windows 7, here's I think going to be a great solution.  Now, I've only looked at it at this level at this point.  I've got the next four weeks of Security Now! shows mapped out.  So, and in fact we're going to have John Graham-Cumming come on in three weeks...



LEO:  Oh, good.  Oh, great.



STEVE:  ...and talk about in great detail JavaScript, which he knows inside and out, and he gave a presentation about it in a recent virus conference.  So I said oh, John, Leo and I need to have you on.  So he's agreed to do that.



LEO:  Fantastic.



STEVE:  And so it'll be the week after the Q&A following that one.  I will have had time to really spend a lot more time and will do certainly a podcast about this.



LEO:  Do you think this is going to put the commercial antiviruses out of business?  I can't imagine, why would anybody - of course there have been free antiviruses for a long time, and that hasn't put the commercial guys out of business.  But this one's from Microsoft.



STEVE:  Yeah.  And I - for example, there really isn't a commercial competitor for Internet Explorer.  There are free competitors for Internet Explorer, but not a commercial browser.  I think it would be - it'd be hard to sell one, you know, for money.  I think this changes the game.  I think that Microsoft gave everybody a long run, that is, in the AV world.  But if this is as good as it seems to be, and it doesn't cause problems, and it updates multiple times a day, it uses the current connected always model, I just - I know that it's what I'm going to recommend to all of my own friends who are - who I just sort of try not to get involved with their computers because I don't want to be their go-to guy.  But they know they should be doing something.  And I think this just solves the problem.



So I would say, if a person has an existing relationship with an AV company, they're comfortable with it, they like it, they've gotten to know it, they know its quirks and so forth, they may be inclined, for the sake of inertia, just to stay there.  But I would be surprised, if a new machine started to try to charge you money for the AV that was preinstalled for 90 days, and then it wants money from you, I'd be surprised if people didn't say, wait a minute, is that what I should do?  Or should I just say remove this and install Microsoft's free one?  Before long the world will be out that Microsoft provides this.  Microsoft has solved this problem.  And I think that changes the game.



LEO:  Right, well, good.  I mean, who better to than Microsoft?



STEVE:  And I like it because it's lightweight.  I mean, here I am with my cookie manager that the only thing it does, my little Permit Cookies extension for Firefox, is it just brings up a little lame little dialogue that says allow or disallow.  I mean, that's all I want.  So I always prefer a tight minimal solution.  And from what I've seen, that's what Microsoft has given us.  Because they're not having to compete with the major AV players.  I look at, for example, how ZoneAlarm - or Zone Labs destroyed Zone Alarm by having to compete with Symantec and their Norton Suite and had to put everything but the kitchen sink, in fact I think maybe that's an option in the firewall.  It's just they ruined a good personal firewall, and it just became a horrible thing.  So I really like the idea.



LEO:  Well, there's two parts, I guess, to an antivirus.  One is the scanner, usually doing that by signatures; right?  And the other is heuristics, where it's looking for bad behavior.  Does this do both of those?



STEVE:  Don't know yet.



LEO:  See, that's the problem.  We don't know how good the scanner is.  We don't know how sophisticated the heuristics are.  I'd like to see some tests on that, although it's very hard to test, of course.



STEVE:  Well, a lot of tests have been done.



LEO:  Oh, they have, okay.



STEVE:  And Microsoft has come out on top.



LEO:  Oh, good.  All right.



STEVE:  I mean, it's like as good as anything else, from everything I've seen.



LEO:  That's all that matters.



STEVE:  I know.  I think it's a win.  So...



LEO:  Where did they get this?  Is this a rewrite of OneCare, of the giant antivirus that they bought?  Or is this something...



STEVE:  Yes.



LEO:  It is.



STEVE:  It's their - it's a - I don't know how to characterize it.  Not really a rewrite.  It is the engine behind their commercial product, their mainstream commercial product.  And so they spun out this free one after proving the technology.  It's like, okay, we got it nailed.  Now we're confident that we can - because they recognize that it is going to be a hit.  They opened the beta, and they were providing 75,000 downloads, and they closed it partway through the first day because just everyone went nuts for it.  And I've been waiting for it.



I'm excited.  I think this is - this changes the game in the same way that, for example, that Microsoft having a really good firewall in their products do.  Now, their firewall does not do outbound monitoring; so some would argue, well, it's not really good because it doesn't do that.  But it's like, well, if you're careful about not letting anything in, then you probably have the security you need.  And this will help prevent things from getting in.



LEO:  It makes sense they'd release this right, as it is, a couple of weeks before the release of Windows 7.  They've got now an anti - pretty much a complete security suite.  Windows 7 implements User Access Control and other security features.  It sounds like that 7 might be really the holy grail, which is a version of Windows that just is not prone to this stuff.  I hope.  We hope.



STEVE:  Well, to hear Paul talking about - it wasn't Paul, it was a Mac person who was saying of Windows 7 that this was good enough that he was kind of finding himself thinking, wow, I could actually use this.



LEO:  Oh, yeah.  I love it.  I mean, I'll probably still use a Mac as my personal computer, but I love Windows 7.  I think it's the best version of Windows they've ever done.  And a thing to remember is that the key really to protecting against infections is widespread antivirus use.  It's like vaccination.  The more people that are running antivirus is that damps down the spread of the antivirus; right?



STEVE:  Very good point because it is machines that are infected that are actively working to infect others.



LEO:  Right.  So by giving away - I wish they'd install the darn thing.  I guess they feel like they can't do that to their partners.  But it should come with this.



STEVE:  Just give it time.  This always starts this way.  And then it'll just be built in.  It'll just be like, look, we've got - you can't not have automatic updates now.  You have to fight Microsoft to get control of that.



LEO:  And look what a boon Service Pack 2 was for XP because it turned on the firewall.



STEVE:  Right.



LEO:  That in itself was a huge improvement.



STEVE:  It was everything, just to block that, yes.



LEO:  I think this will be comparable to that.  I hope.



STEVE:  I think so, too.  This is really big.



LEO:  Right.



STEVE:  The only other security news I had - it was a quiet week - was just a little tiny mention.  This is not a big deal at all.  But I know that the VLC Media Player is popular for a lot of users who like to have a third-party, more format-expansive media player.  And there are a bunch of multiple buffer overrun vulnerabilities that exist in everything up to and including version 1.0.1.  So anyone using VLC, again, I don't even think that the attack surface is very big on this.  Who's going to create a piece of media specifically hoping that you're running it under VLC Media Player?  But I just did want to mention that there is an update to that.  Otherwise it's been very, very quiet on the security front.  I'm sure in a couple weeks we will, when we get to the second Tuesday of October, things will pick up, and we'll have some more news.  But that's it for now.



LEO:  That's good news.  I like that.



STEVE:  And then I had one really fun little short SpinRite story that caught my eye.  Actually I encountered it just this morning when I was running through the mailbag, looking for our Q&A questions.  The subject was "SpinRite saved our lawsuit."  And I thought, okay, well, there's one I haven't heard before.  And so, and he asked me to leave his name out if I read this on the air.  So he said - but he's located in Minneapolis, Minnesota.  He said, "Hi, Steve.  Thought I'd say how awesome SpinRite is.  I needed to copy some .pst files" - which is really interesting, too, because my homeowner association was sued by a bunch of homeowners who were disgruntled, and all the members of the board were using Outlook.  And they all came to me because unfortunately I had been identified, I'd been uncloaked as someone who understood computers.  And they were all needing - the attorneys all needed everyone's email dialogues that were related to the last X number of years of their service on the board.  And so it's like, okay, so I had to figure out how to do that.



And so he said, "I needed to copy some .pst files from the CEO's laptop for some discovery our lawyers wanted.  When I tried to back up his main file, I kept getting a CRC - Cyclic Redundancy Check - error.  After working the lump out of my throat, I tried creating another .pst file to copy the email into.  But that failed with the same error.  So I pulled out the SpinRite disk.  I know management gave me a hard time when I needed to buy four licenses..." - because the way that works is a single license allows the licensee, the user, to use it on any machines that they own, any machines and hard drives.  But we ask people to have four licenses for, like, we call it the "corporate site license," to then use it, for example, on all the machines within a corporation.  And so he says, "...but I told them it was worth it and that it is a good product.  Thank goodness I was right.  After running it on Level 2 for an hour, the original file copied without any problem.  Thank you so much.  P.S.:  Please don't use my name on the air if you read this."



LEO:  That's great.



STEVE:  So thanks for the positive feedback.



LEO:  Good news.



STEVE:  As always.



LEO:  SpinRite saves the day.



STEVE:  And in an hour this time, instead of a year.



LEO:  Yeah, we should mention that.  The time varies depending on how bad the drive is, right, what kind of shape the drive's in.



STEVE:  Yes.  It can - and in fact it's funny, too, because SpinRite estimates, continually estimates how much longer it has to run based on how far it's gotten, given how much time it's had so far.  So it assumes that the whole drive is going to be exactly like what it has seen so far, which is often not the case.  It's very often the case that the drive may have some problems at the beginning, which is why it's Blue Screen of Deathing and having - can't get booted or whatever.  But then after working through those, it just takes off like a bat out of hell.  So people say, wait a minute, it says it's going to finish in the year 2020.  It's like, no, calm down, it's probably just hit a rough spot right off the bat which has caused it to project its completion time as not in your lifetime.  But it'll - as soon as it gets past that, it fixes its estimate and then starts getting much more accurate.  So that's good.



LEO:  Well, we're going to get to 10 of your questions - we've got some great ones - in just a second.  But I do want to mention Audible.com.  Have you watched the new "FlashForward" yet?  Are you interested in this show?



STEVE:  I don't think so.  I saw the previews, and it's like, eh.  And I tried to watch "Defying Gravity" for a while, which was the summer sci-fi show.  And it was like, eh, this is just too much soap opera in space for me, so...



LEO:  I'm not a big, as you know, and we've talked about this before, I'm not a big fan of sci-fi on TV.  I just feel like they never give it the budget or the time that it needs.



STEVE:  Oh, except for...



LEO:  "Stargate," I know, you like...



STEVE:  "Fringe," "Fringe," "Fringe."



LEO:  And "Fringe," no, I will watch that when that comes out on DVD.



STEVE:  Oh, it's so fun.  And we have a new "Stargate" this Friday, in fact.  I'm glad you mentioned...



LEO:  I saw that, yeah.



STEVE:  Yeah, "Stargate Universe."  I know nothing about it, but it is premiering this Friday, the day after the podcast.  So we should let all of our listeners know - I'm sure they do now - that "Stargate Universe," which is, you know, the Stargate franchise I've really, really enjoyed.  It's a little cartoon-y sometimes, but fun.  But, oh, "Fringe" is just always delightful.



LEO:  "Fringe" is kind of like "X-Files"; right?



STEVE:  Yeah, it's very much so.  In fact, it's funny, in an episode last week, the premiere episode of this new season, they were - there was a Senate Finance Committee meeting where they were going to cut off the funding for the Fringe Division.  And the guy said, he said, "You know, we've spent so much money in these X-Files and this Fringe Division."  I thought that was really great.



LEO:  That's a nice touch.



STEVE:  Yeah.



LEO:  I like that.  That's a really nice touch.  Well, the reason I brought it up, for those who do want to watch "FlashForward," I guess the plot of this is that humanity goes to sleep and just has, like, a vision of 20 years ahead of time and then comes back.  And now everybody knows what's going to happen for the next 20 years.



STEVE:  Everybody in the world has a two-and-a-half-minute blank-out where they see into the future, except some people apparently see nothing.  And that's - they're worried.  Does that mean I'm not going to be around in there or what?



LEO:  Right, right.  Well, it's based on a novel.  And, see, to me, if you get inspired by the show, and you want to, you know, you say, oh, I like this, I say read the novel because...



STEVE:  Oh, because it's always going to be better.



LEO:  I think it's always going to be better.



STEVE:  Yeah.



LEO:  I mean, I can't think of anything where the original book that it was based on isn't better.



I have for you, in my hands, a passel of questions.  Are you ready, Mr. G?



STEVE:  I am.



LEO:  All right.  Starting with Brian Dort from Alpena, Michigan.  Brian says he's got some news about PayPal's multifactor authentication, which we have spent many, many moons talking about:  Steve and Leo, I'm another long-time listener since Episode 1 of Security Now!, also a happy SpinRite owner.  It has saved many hard drives for me.  I now have a USB thumb drive with SpinRite loaded on it - oh, that's a good idea, I didn't know you could do that.



STEVE:  Yeah.  SpinRite will set up a USB thumb drive as a bootable drive.  And then you can put any other files on it that you want to.  But when you boot that thumb drive, SpinRite just takes over and runs.



LEO:  Brilliant.



STEVE:  Yeah.



LEO:  Couple years back, after Episode 103 on the PayPal security key - that football that we talked about - I ordered one for myself and immediately started using it.  By the way, as a side note, I gave the football to our business manager, so she has it now.



STEVE:  Good.



LEO:  She's got the football, like the atomic football.  Since then it's worked perfectly until one recent day I pressed the button to receive my token, and nothing happened.  My assumption is the battery died.  No worries, though.  I can log onto PayPal, answer a few questions, and order another.  This time, emulating the master - he means you, Steve.



STEVE:  I think he does.



LEO:  I ordered three, with the intention of placing two in the freezer for future needs.  Well, they're only five bucks each.  Why not?  To my surprise, when they arrived, the dongle was not to be found.  Instead a thin, credit card-size security key was found.  It has a circle that says "Press" on the front, along with an eInk type of display that shows the number.  I'm going to pull mine out because I have the same exact thing.



STEVE:  As do I, in my wallet.



LEO:  Yeah.  I know what he's talking about.  At first I thought this was a great thing.  It fits in my wallet easily, and I usually have my wallet with me, more than I have my keys with me.  However, after using this new format for a short period of time, I'm convinced that PayPal has made another mistake.  My first one stopped working after about one month, probably due to me sitting on the security key while it's in my wallet.  The second one continues to work, but one day PayPal wouldn't even recognize it.  In fact, when I called PayPal, the customer service rep said it wouldn't work because I didn't buy it from PayPal, even though I did.  In fact, their logo is plastered on the front.  She sent me the new security key, and I'll try to get this one working.  I asked about the football-shaped dongle that used to be available and was told they don't sell them anymore, only these new credit card formats.  I hope you and Leo get back to reality sometime soon; okay?  I don't know what that means.  Can you - care to explain?  I've been using this, but I got this one.  This is the VIP thing that you and I have talked about from VeriSign.  But I presume that's what PayPal is now distributing, something like this; right?



STEVE:  Yes.  I thought this was interesting.  Apparently what happened is that the footballs are dying, and the batteries, as he says, are dying.  Now, I have one of each.  And I've got the football next to me, which I use every couple days.  Now I'm a little anxious about whether it's going to die because that would be a problem.  Although I do also have the credit card format.  Now, remember that the football, I think the problem with the battery life on the football is that it has a clock in it which is running all the time, even when we're not pressing the button.  Pressing the button basically just causes it to perform a little calculation based on the current time of day and then display the code, which is valid for 30 seconds, and it changes every 30 seconds.



The credit card approach has the advantage of consuming zero power.  And even when it - so when you press the little "Press Here" button, it briefly fires it up, and it produces an incremental next code which is not based on time, but which is based strictly on a cryptographic sequence.  So there's a counter which is driving a cryptographic algorithm based on a secret key which it knows and which the authenticating agent at the other side - and VeriSign is behind all of this.  VeriSign is the technology that PayPal uses, and VeriSign provides the gateway.  So this is exactly the credit card that we've talked about before.



I've never had mine die.  Mine's in my wallet, too.  When I take it out, I notice it does have sort of a slight curve to it.  And I think, well, okay, it seems to be working just fine.  So anyway, I just wanted to apprise our listeners of the fact that that's what's going on, that PayPal has apparently backed out of the football that we've talked about and enjoyed in favor of this credit card, probably because it's got a greater lifetime.  This little clock is running in the football whether you're using it or not, whereas the credit card probably lasts many more years.



LEO:  I've been sitting on this for a long time.  I keep this in my wallet, the credit card, and it's been pretty reliable.  So...



STEVE:  Yeah, I do, too.



LEO:  Yeah.  Hmm.  But we got ours, well, I guess this is the same.  Ours say VeriSign, not PayPal.  And you can use it with PayPal.  Maybe that's another solution.  People might want to go to the VIP program at VeriSign and get that one and use it with PayPal.  You can use that one with PayPal.  Not with eBay, oddly enough.



STEVE:  Yeah, it is odd.  I don't - I'm not quite sure how they're hooked together.



LEO:  What PayPal's been doing lately, which I prefer, frankly, is sending me a text message on my phone.  So you can add a cell phone to your authentication means and have it - and then when you log into PayPal it'll say, well, what do you want to use - your football, the card - and now three devices - football, the card, or the cell phone.  And now I just always say cell phone, just send me a text message, because I always have it with me.



STEVE:  Right.



LEO:  And that works fine.



STEVE:  Right.



LEO:  Maybe that's, in the long run - in fact, before your football dies, set up your cell phone to do that.



STEVE:  Well, and what's interesting, too, is if somebody were to choose that who was trying to pretend to be you and log onto PayPal...



LEO:  I'd get a notice.



STEVE:  You'd get a call.



LEO:  Yeah.



STEVE:  Yeah, and it's like, wait a minute, why am I receiving a confirmation code from PayPal?  I'm not trying to log in.



LEO:  There's not much you can do about it.  Somebody's - I get at least once a week a French language email from somebody trying to get my Gmail account because my name is French.  And obviously somebody thinks that's their account, even though it's not.  And it must drive them - I'm sure it's driving them crazy.  I keep sending email, I never get it.  Yeah, because it's the wrong email.  I'm getting it.  And so it is a warning.  But what are you going to do?  Question number - let's see.  Oh, I jumped ahead there.  Wait a minute.  Hold on.



STEVE:  That's...



LEO:  Oh, no, you didn't - you jumped ahead.



STEVE:  I did?



LEO:  You went from one to four.  Unless I've made a terrible mistake.  Oh, I see what happened here.



STEVE:  I've got a page two.  I mean, I have a Question 2.



LEO:  My pages are all messed up.  Question 2, Zane Killingsworth.  Is that correct?



STEVE:  Yes.



LEO:  From Dawsonville, Georgia, wants help securing a new PC.  He says:  Hi.  Hello.  I'm a young PC enthusiast who is getting a new PC in the near future, and I want help with what security software I should get.  Well, I think we now know what the answer is going to be.  But I thought I was fine with Norton's 360 [gasp] until I started putting a lot of files on my desktop and read the book "Little Brother" by Cory Doctorow.  I was so shocked by my lack of security that I tried to put Paranoid Linux on my PC.  I didn't know there was such a distro.  That's funny.  But since the book used a version of it on a future Xbox, I thought that, like almost everything in the book, it was real, but it was just a little startup that died.  I guess there is no Paranoid Linux.



Since then I've listened to every Security Now! podcast to try to be more secure.  Also very happy to say that because of my listening I've helped my school.  I'm home schooled and take science classes out of my home at a local small school for homeschoolers.  I helped them determine that their WiFi network was compromised and helped them pick a new, more secure WiFi router.  Yay.  So help me pick a better solution for security, for antivirus, and what other software I need.  Steve?



STEVE:  Well, in the beginning of Zane's note he - it felt to me like he had gotten himself overly concerned.



LEO:  Yes.



STEVE:  And so I wanted to address that because I do see that in email and in our newsgroups, you know, people who really, it's like the concern for security is consuming their life.  They're afraid to go out of the house, or only want to do so between the hours of 11:00 and 1:00 when they're sure that the sun won't set too quickly on them.  And it's - so I just wanted to address that, the issue of it being possible to be so concerned about security that you're not having any fun anymore.  And this should be fun.



All of the evidence indicates that there are agencies and individuals and groups that are taking advantage of mistakes being made in the design of our computer technology as it exists today for their own advantage, and hurting other people in the process.  There's a story that I'm going to share next week about a company, a construction company that is suing a bank because they feel that the bank's security, like the log-on security wasn't good enough, and $588,000 was stolen from their account as a consequence.  So, I mean, these things do happen.  But you really do want to keep some balance, I think.



So the idea of not using Windows in favor of something called Paranoid Linux, I mean, I know that there are people who enjoy being this focused on security.  But I wouldn't ever promote the notion that it's necessary to be this focused on it because you still want to be able to have the freedom to do what you want to do.  I mean, it's a little bit like you, Leo, having a problem with NoScript, or like turning scripting off.  There we're sort of in a gray zone.  You need to be able to see sites in general that you're reviewing, running the way they're meant to by the bulk of the population who do have scripting on; whereas I and many Security Now! listeners have said, wait a minute, I need a little more control.  I'm going to turn scripting on selectively.  When I notice that there seems to be something wrong, then I'll permit a site to operate.  So again, you could have somebody who refuses to ever run scripting.  But then, arguably, sites that you need or want to use won't work at all.  So I'm thinking, okay, compromise.  Yes, unfortunately, scripting is a mixed blessing; but it's one that we need.



So anyway, I just sort of wanted to respond to Zane's, he uses the word "paranoia," and say, look, you know, don't get yourself too scared about this.  I hope that we strike a balance here during this last 216 podcasts of saying, look, here's the issues; here's the facts.  We want to let everyone decide for themselves where they fall in the spectrum of really concerned and not concerned at all.



LEO:  It's very easy to get paranoid about this stuff.



STEVE:  Which, not surprisingly, takes us to our third question.



LEO:  And by the way, just to answer his question about what security package, I think it's pretty clear from our conversation at the beginning of the show that Microsoft Security Essentials would be the right choice.  Yes?



STEVE:  Until we know otherwise, yes.  I don't want to say anything until the jury's in or out or back or wherever the jury's going to go.  But, yes, I have high hopes.



LEO:  So far, so good.



STEVE:  Yes.



LEO:  John in Ontario, yes, this is the next one, says - Ontario, California, by the way - says we're "so silly."  Steve and Leo, we have been using Mac OS 9 since 1998 with an open IP address.  We are now on OS X.  We have 12 Macs on this via Verizon, each with its own public IP address.  Always have, for over 10 years now.  We have no protection of any kind, yet have never, ever been hacked.  I think all this paranoia about hacking is just that:  paranoia.  And you and Leo just propagate it, the fear factor.  And furthermore, why would any of us need your advice?  After all, we're not harboring nuclear secrets or planned attacks on some geographic location.  Would you two just get real?  Wow.  I'm hurt.



STEVE:  Well.  There's the other side of the spectrum.



LEO:  [Laughing]



STEVE:  I thought...



LEO:  That's kind of head in the sand.



STEVE:  This really anchors both ends.  Well, first of all, I would comment that OS X has a firewall, and it's turned on.  And so you do have, automatically, protection from incoming threats.  He's obviously not behind a NAT router.  He says he's got individual IPs for each of the machines, and so each machine has a public IP, and it's out there on the 'Net.  And that he's been doing this for, what, the last 10 years?  I think that's great.  I would feel...



LEO:  It's kind of - I would liken it to somebody who says, you know, I never go to the doctor, and I've never had any vaccinations, and I'm just fine.



STEVE:  Yes.



LEO:  Until you're not.



STEVE:  Yes.  And here I am saying, yes, but if you take a little Vitamin D every day, the statistics show that you have much better prospects for the future.



LEO:  Right.  You're fine until you get hacked.  And then, you know...



STEVE:  Yeah.  I mean, it absolutely is the case that these problems are real.  If you put a Windows machine on the 'Net with its own IP, with nothing protecting it, it will get commandeered.  Security researchers do the experiments.  There's just so much junk on the Internet.  Now, it's true that he's in a better position with Macs than he is with PCs today.  But we know that that's also a moving target, that as Macs become more popular we're seeing a greater incidence of acknowledged potential problems with Macs.  So...



LEO:  I should point out, though, that if he had done this with a Windows 98 machine he would indubitably have been hacked at this point.  Yes?



STEVE:  And may not have known it.



LEO:  May not know it.  And may be hacked now, we don't know it.



STEVE:  Exactly.  I mean, it's difficult to say.  It's clear, you know, we talked last week about what's the relative security of different OSes and agreed that they're all soft.  They're all softer than we wish they were.  They've all got problems, a different nature of problems, different sorts of problems.  The open source model has some.  The closed source model has its.  They're different.  But fundamentally, complex software is going to have a problem with security, and complex software is what we have in all of these systems today.  John's got very sophisticated software in his systems.



So I don't know really how to respond to him except that I would feel, with everything I know, extremely uncomfortable with machines that weren't behind a NAT router, that weren't behind - I guess I'm just - I'm used to it.  I know how that technology works.  I like the idea that it's protecting me from the outside.  I know what's out there.



Am I paranoid?  Well, it's certainly the case that millions of machines, Windows machines, were infected by the Conficker worm.  I mean, we absolutely know that.  It's taken down whole systems of hospitals over in England.  And that's not illusory; that's real.  And we've - people are having their machines infected by their actions as they click on links in email all the time.  I mean, on several occasions I've had to spend a long weekend scraping stuff off of people's machines.  And in some cases, there was one, a female friend of mine from Starbucks, about six months ago I referred to it, that I just - I looked at it for a while, and it was clearly just beyond recovery.  So I formatted the disk and set it up for her, and she's now using Eudora and Firefox because I decided, okay, let's try to prevent this from happening again.



So these things really are out there.  I'm glad John hasn't been bitten by one yet.  And I hope if it does happen, it's not bad because he clearly believes that - for some reason he's listening to the podcast.  But he believes that we're sort of a self-fulfilling prophecy.  And I don't think that's the case.  We happened because of the need, not creating the need.



LEO:  I wouldn't feel too defensive.  And in his defense, and this is kind of like we talked about with the last question, there certainly is - it can happen that people listen and go agh-agh-agh and just feel terrified and become an agoraphobic.  And we're not trying to do that, either.  I think...



STEVE:  Right.



LEO:  ..the idea is reasoned information about the risks, and you be the judge.  We're not, well, first of all, we should say we gain nothing.  Neither of us make a security program that we sell.  We gain nothing by you being afraid.  We don't work for an antivirus company.  So we're - and I'm not the security expert, Steve is.  But I'll speak for you, Steve.  You're just getting the information out there.



STEVE:  Well, and I really do think we maintain a balance.



LEO:  We certainly try, yeah.



STEVE:  I think this is not the, oh, go screaming for the hills paranoia podcast.



LEO:  And I'm the guy who says, eh, what the heck, I'm not - I'm going to run scripting.  I'm not going to - you know.



STEVE:  And the fact is today on a Mac you're safer than today on a Windows machine.



LEO:  Oh, yeah.



STEVE:  There's no doubt about it.



LEO:  No question about that.



STEVE:  Yup.



LEO:  Bob in Connecticut wants to know if we have seen and have had a response to an article.  He says:  I'm a longtime listener, love the podcast.  Have you seen anything on this one-time password being defeated?  Here's a link to the occurrence I read about.  The title of the article, it's on TechnologyReview.com, which is - is that the MIT Technology Review?



STEVE:  Yes, yes.



LEO:  That's a good journal.  The title is "Real-Time Hackers Foil Two-Factor Security."



STEVE:  And a person who we both know as an author, Leo, Robert Lemos...



LEO:  Oh, okay.



STEVE:  ...wrote the article.  So this is MIT's Technology Review magazine.  And I wanted to highlight it because, first of all, it's really interesting, and it's a perfect topic for us to discuss, and many of our listeners are apparently reading this or saw the link and said, hey, what about this, because we've talked so often about the strength of multifactor security.



LEO:  Right.



STEVE:  And so the subtitle is "One-time passwords are vulnerable to new hacking techniques."  And so Robert Lemos writes, he says:  "In mid-July, an account manager at Ferma, a construction firm in Mountain View, California, logged in to the company's bank account to pay bills, using a one-time password to make the transactions more secure."  That is, to log in.



"Yet the manager's computer had a hitchhiker.  A forensic analysis performed later would reveal that an earlier visit to another website had allowed a malicious program to invade his computer.  While the manager issued legitimate payments, the program" - behind his back - "initiated 27 transactions to various bank accounts, siphoning off $447,000 in a matter of minutes.  'They not only got into my system here, they were able to ascertain how much they could draw, so they drew the limit,' says Roy Ferrari, Ferma's president.



"The theft happened despite Ferma's use of a one-time password, a six-digit code issued by a small electronic device every 30 or 60 seconds."  Well, we know what that is.  "Online thieves have adapted to this additional security by creating special programs - real-time Trojan horses - that can issue transactions to a bank while the account holder is online, turning the one-time password into a weak link in the financial security chain.  'I think it's a broken model,' Ferrari says.



Security experts say that banks and consumers alike need to adapt - that banks should offer their account holders more security and consumers should take more steps to stay secure, especially protecting the computers they use for financial transactions.



"'We have to fundamentally rethink how customers interact with their banks online,' says Joe Stewart, director of malware research for security firm SecureWorks in Atlanta, Georgia.  'Putting all the issues with the technology aside, if [attackers] can run their code on your system, they can do anything you can do on your computer.  They can become you.'"



So, and I'm not going to read the rest of the story because we've got the gist of it.  So what happened was that an infected machine went online.  And the software was clearly sophisticated enough, it used the fact that a one-time password had authenticated the session, the log-on session to - and this is amazing to me that this is, I mean, it's clearly possible, but that you would - that this manager would happen to have software that understood how to perform transactions behind his back using the credentials, the transient log-on credentials that he had established.  I mean, it's chilling.  And so again I would say to our prior questioner, [John] in Ontario, California, who thinks this is all paranoid, that, well, this stuff really does happen.  So it's interesting because the title for next week's podcast is already "The Fundamentally Broken Browser Model."



LEO:  Oh, boy.  Can't wait.



STEVE:  Because that's what we'll be talking about when you're in Dubai, Leo, is that - because there was another presentation at the Black Hat conference recently in D.C.  that I haven't been able to get out of my mind because it talks about breaking SSL, and it really doesn't do that.  It leverages the fundamentally broken model of using a web browser for these sorts of things.  And that really is the problem.



For example, if there was more granularity in the security transaction, for example, if you not only had to use the one-time password to log on, but you had to use it every single time you performed a transaction, well, then this particular breach would have been prevented because this breach was hijacking the user's current state, their logged-on state, and performing this work at the same time in the background that they were doing other things with their bank.  But this does highlight the level of sophistication that we've now arisen to.  I don't think this - I would be a little less harsh in criticizing multifactor authentication except that this does say to us, if this is the level of sophistication, then we need to push multifactor authentication even closer to what we're trying to authenticate.



The problem was, this was being used to authenticate the session.  It's clear that, in the presence of this kind of malware, we need to authenticate the transaction and get closer to what it actually is we're trying to protect.  We're trying to protect the transactions, plural.  So we're assuming that the fact that they're wrapped in an authenticated session provides that protection.  Well, this demonstrates that assumption is no longer valid.  Now we need a per transaction authentication, which is a little more annoying.  But if you've got the football right there, and you want that level of protection, if the bank said do you want to authenticate per transaction or per session, now you know you say per transaction.  I want to have to - I want to challenge every single time I do something.



LEO:  I suppose there's still a window, though, even if you're doing it per transaction.  I mean, as long as there's 30 seconds, if their system is quick enough they can sneak in there while you're authenticating.



STEVE:  Yeah.  You'd have to, I mean, I'd have to think about that, whether something could, I mean, it would be authenticating - you'd need something at your end that the malware couldn't get to that was tied to the details of the transaction.  So you're basically - you provided the details of the transaction.  Then the other end said, okay, I need you to sign the details of that transaction in a way that the malware could not sign its own transaction, which would be different from yours.  So there are certainly ways to do this.  But again, it's like, whoa, this clearly ups the ante.



LEO:  Yeah.  Very interesting.



STEVE:  And it's being done.  Malware out there, we now know, is becoming that good.  And so it does say, what the article went on to mention was that banks needed to provide consumers with, like, secure computers.  It's like, well, okay.  How's that going to work?  It's not clear how we get there from here.



LEO:  It's really, that just shows how determined and clever bad guys are.



STEVE:  Well, and this - actually this does set me up.  I didn't - I ran across this in preparing today's Q&A.  But, I mean, this sets me up for next week's discussion of the fact that, unfortunately, convenient as it is - remember, this all kind of happened to us.  We had browsers that were going to allow us to look at static websites.  And then it's like, oh, we can submit information.  We can use forms and the "get" and the "post" commands to send stuff back.  Suddenly now it's interactive.  And then the banking said, oh, we really don't want to see you because it's expensive for us to hire tellers.  So we're going to automate all this and put this online.  And besides, we've been told that SSL is safe.  Well, yeah.  SSL is safe.  Well, we know that there are caveats even there.  But so the problem is this notion of using something as convenient as a web browser is really broken.  And next week we're going to talk about some very clever approaches that demonstrate just how broken it is.



LEO:  Yikes.



STEVE:  Yeah.



LEO:  Question 5, Jacob Theobald in San Francisco.  He wonders about the security of Internet Explorer tabs.  Oh, I'm sorry.  No, no, of the IE Tabs Firefox plug-in.  That puts IE in Firefox.



STEVE:  Right.



LEO:  Recently, by the way, I don't know if you saw this, Google put Chrome inside of IE, saying IE's never going to support HTML 5 well enough for us to use Google Wave, so we're just going to put a plug-in that puts Chrome in there.  For people who want to keep using IE, but not give up Firefox, this is the same in the other direction.  Hi, Steve and Leo.  I've been wanting to ask this for a while but never got around to it.  I've been using this IE Tabs Firefox add-on.  From the looks of it, it can switch a specific tab to use the IE engine to view web pages, if you're in a case where you need IE, like Windows Update, for instance.  Could any security vulnerabilities that affect IE affect Firefox through the use of this add-on?



STEVE:  Absolutely.



LEO:  Yeah.



STEVE:  This is exactly like the problem of using the HTML viewer, which is IE, in Microsoft Outlook email, the infamous preview pane where you just select the email and it comes up in the preview pane.  That's all it takes, if you happen to be viewing malicious email, for something to get a foothold in your machine.  The idea is that, and this is Microsoft's whole - it started with OLE and became ActiveX.  The idea is that the application has become basically sort of a window, literally a window frame and controls surrounding the code which displays the content.  So essentially what Firefox is doing with the - or I should say the IE Tabs add-in to Firefox is doing is it's instantiating, creating an instance of the full Internet Explorer viewer that just happens to be wrapped with Firefox's borders and controls and window dressing, rather than IE's.  But it's in no way more secure.  It's sort of the lowest common denominator approach.  So, yes, I can see the appeal.



So my advice would be use it as little as possible.  Use it for Windows Update and only for websites that you trust that won't run in Firefox.  I have IE, even though I'm exclusively using Firefox now, I use IE to run Windows Update, and that's it.  And very rarely I'll see some site that just is really badly written that absolutely requires IE.  And, I mean, I call it badly written because they're really restricting themselves to a subset of the Internet.  Firefox is increasing its market share all the time, and for good reason.  So, yes, it's absolutely you are vulnerable to all IE vulnerabilities if anything uses that IE ActiveX control, whether it's email or any other browser who says, oh, look, you get the benefits of both.  It's like, well, and the liabilities of both.



LEO:  Right.  Of course IE's always running on all Windows machines.  So that's why, if you look at HTML email or anything, it's always there.  The engine's always there.  Hard to get away from it.  Moving right along to our next...



STEVE:  It's not in my system, Leo.



LEO:  How do you get rid of it?



STEVE:  I just - I use Eudora, which doesn't use the process at all.



LEO:  Oh, I see.  Yeah, but IE, if you've got Windows, the rendering engine is there at all times.  And it's kind of hard - I'll give you an example.  It's kind of hard to know when it's being used.  Quicken, for a long time, Intuit - and may still, for this matter - would embed an IE window inside its Quicken so that you could see online data from the Intuit website.



STEVE:  Yup, and in fact there have been programs that will say "Requires Internet Explorer v6 to be installed in your machine," in order for something entirely non-web browser-y to work because they're relying on that component.  So anyway, I wouldn't say that it's always running.  But it's certainly the case that it has the ability to pop up, literally, when you're not expecting it.



LEO:  Yeah.  It's almost always running.  Well, okay, I'll give you another example.  When you're using Explorer to explore the hard drive, and you enter in a URL in that Explorer window, it will then open the web page.



STEVE:  Ah, yeah.



LEO:  Isn't Explorer, I mean, I don't know what the difference is, IE and Explorer.



STEVE:  Well, they're very different.  So...



LEO:  Okay, so it's just the rendering engine just says, oh, never mind, I'm going to use IE instead to do this.



STEVE:  Right.



LEO:  Okay.  They're different programs.



STEVE:  Right.



LEO:  But they have a direct link.



STEVE:  They do.



LEO:  Donald Burr in Santa Maria, California has some feedback to our answer, "Should I run my own server?"  Remember we talked about that a couple weeks ago.  Well, in fact he says...



STEVE:  Two weeks.



LEO:  Two weeks ago.  In your Listener Feedback #75 episode you answered Dax Mars' question - I love that name; and he says, and I love it, too - about running his own server at home.  Your response recommended going with the most secure distribution of a UNIX-like operating system and specifically mentioned NetBSD or FreeBSD.  While I agree with the overall concept of shying away from Windows, I would instead recommend that he goes with a Linux distribution, specifically one based around Debian's package management system.  There is, for example, a version of Ubuntu specifically tailored for servers that would be ideal for this.



One of the most important things that a person as a server administrator needs to do is to keep up on software updates.  I'm sure you'll agree with me on that.  However, unless I'm mistaken, updating a BSD system is difficult and involves having to rebuild the kernel, user space tools, et cetera, and even for an intermediate-level user can prove to be a daunting undertaking.



Debian-based distributions, on the other hand, have a very easy way of upgrading the system involving only two shell commands, apt-get update and then apt-get upgrade.  These two simple commands will download the latest version of all Linux tools, including any third-party programs you may have installed like Apache web server or MySQL database.  The Debian and Ubuntu folks are very proactive when it comes to incorporating the latest security fixes into their packages.  Just my two cents.  Love the show.  Love that SpinRite.  It has saved my bacon on more occasions than I can count.  So that's a good point.  But there'll be a debate over this, I think.



STEVE:  I think it's a very good point.  Well, the issue of OS is religious.  Everybody has their own, for their own reason.  And so I wanted to share Donald's recommendation.  And I don't disagree.  I mean, I've used Debian Linux, and I like the packet manager that Debian has.  And obviously Ubuntu is a very popular solution, as well.  So one thing that I might add is that for a non-UNIX or Linux user, someone who's moving from Windows, all of this stuff is a lot less obvious and easy to use than Windows is.  And so one thing that may - I mean, I guess I feel a little bit like it's six of one, half a dozen of the other.  Except if you've got some friends who have a bias or experience, it could ease the transition a lot to say, well, what are you guys using?  I'd like to use the same thing so I have someone I can call when I have a question.



LEO:  Right.  Yeah, that's, of course, true.  But was it you or was it, no, I think it might be Randal Schwartz who prefers - he says the most secure network operating system is NetBSD, or I can't remember.



STEVE:  Well, and that takes us into Question #7.



LEO:  Oh, well, let's move along, then.  Let's move along.  OpenBSD.  Randal says OpenBSD.  He's in our chatroom.  He's getting ready for Floss Weekly.



STEVE:  Then he's going to like Question #7.



LEO:  All right.  Donald, no, that was Donald.  This is Bob Carneim in Oak Ridge, Tennessee.  What do you have against Theo?  Okay.  I should have read that.  I'm just listening to the latest Episode 214.  At one point you recommend running a web server on the securest version of UNIX available.  I certainly agree with that, especially versus any Windows OS.  But you only mentioned NetBSD and FreeBSD.  What about OpenBSD?



A little while ago I did research on what OS to try to use for some applications where security is particularly important.  I eliminated Windows, I eliminated Mac OS, and I eliminated Linux.  I don't think I need to explain any of that decision-making process.  I thought about Sun's offerings - Solaris, I guess - but decided that, since I'm a Mac guy, I'd probably have an easier time acclimating to one of the BSDs (Berkeley Software Distribution).  I read the mission statements for the big three:  FreeBSD is all about getting everything to work, lots of applications ported to FreeBSD, lots of device drivers, that sort of thing.  NetBSD is mainly about working on anything.  You could probably install it on an abacus, he says.  Finally, OpenBSD claims itself to be, among other things, secure by default.



That last statement caught my interest.  I read about what they claim to try to do - specially and strictly formatted code that makes it easier to audit, and auditing code for correctness and security even before a flaw or exploit is known.  That's the attitude I was looking for and wish everyone had, and I didn't see any reports that OpenBSD was not doing as they claimed, so I'm going with it.  It's a little more difficult to do certain things; but I, like probably most Security Now! listeners, understand that it's necessary to give up a little bit - sometimes a lot - of convenience for the sake of security.  I don't consider that a hardship.  The classic example is that, when you enable Apache in the default install, it runs chrooted - so does BIND, by the way - so creating dynamic, database-driven websites takes an extra bit of planning and work.



Anyway, I'm not associated with the project other than as a user, and I don't know Theo.  Theo, by the way, is the guy who wrote it.  But so far I think OpenBSD is great.  Should I maybe not?  Is their claim of proactive security all hype?  What have you heard?  Should I panic?  Argh!  Thanks.



STEVE:  Well, it's interesting because his comment parallels some dialogue that popped up immediately in the GRC newsgroup, the Security Now! newsgroup, saying, hey, wait a minute, what about OpenBSD, Steve?  Why didn't you talk about that?  And again, it's just a matter of familiarity, which by no means means I wanted to slight OpenBSD.  I just ended up first using FreeBSD, and that's where I'm comfortable.  And I've looked at NetBSD and just sort of haven't gotten around to OpenBSD.  I haven't needed to.  But I absolutely wanted to give it its due and its moment in the sun.  And apparently Randal Schwartz is an OpenBSD advocate, also.



LEO:  Yes.



STEVE:  So that says a lot for it.



LEO:  We've had this conversation, Randal and I.  And I think that - I'm trying to remember, and I've asked Randal.  But as I remember, there have been two exploits, two exploits total, since OpenBSD was created.



STEVE:  Which is a phenomenally low number.



LEO:  That's amazing.



STEVE:  Yeah.



LEO:  So that kind of obviates the whole need for patching.  And remember, patching - if you've got exploits, you've got to patch.  But patches as frequently as not, I think, introduce other exploits.  So patching isn't the magic panacea, either.  It would be like...



STEVE:  Patching, yes, patching is something that unfortunately we've all become abused into accepting.  But it doesn't, I mean, you'd much rather have something that didn't need it than something that was like, oh, look how often we're patching.  Aren't we wonderful.  It's like, okay.



LEO:  Right.  Patching can just introduce some new problems.



STEVE:  Absolutely.



LEO:  So OpenBSD, yeah, I think that everywhere I've heard, that's kind of the - everybody says, yeah, it's true.  Leo's got it right.



STEVE:  So by no means did I mean to exclude it by having just said, when I did, FreeBSD or NetBSD.  Open BSD.



LEO:  Right.  Emil in Denmark, our Question #8, found an overlooked feature in TrueCrypt:  Hi, Steve and Leo.  I think I found a feature in TrueCrypt you have not previously mentioned in Security Now!:  TrueCrypt => Settings => Preferences => More Settings => System Encryption.  When preboot authentication is configured, the log-in screen says "TrueCrypt Boot Loader" and asks you to enter your password.  With this menu item you can change this however you like so that no text appears at all.  Or you can write a short custom message such as - I like this one.



STEVE:  I love this.



LEO:  "Missing Operating System."  I guess you could even write your password as the message in case you forget it, but that's not a good idea.  It could still be technically possible for an attacker to prove that TrueCrypt is installed on the drive, but I think this is a cool feature, perhaps even worth mentioning in the show.  What a great idea.



STEVE:  I just - I thought it was so clever, I mean, all of us who have used computers for a long time are, you know, we see our life pass before our eyes when you boot the system and it comes up "Missing Operating System."  It's like, oh, what now.  Or sometimes you'll move a drive to a different machine, and it'll be the wrong - it'll be a primary on one machine and a secondary on the other.  So there are various reasons you can get that.  But frankly, if I turned a machine on, and it said "TrueCrypt Boot Loader," I'd go, oh, okay, now I know...



LEO:  Now I know something.



STEVE:  Yeah.  And again, where no one is endorsing security through obscurity, this isn't that because you still have all the security that you would have if it loudly proclaimed itself to be TrueCrypt Boot Loader, but instead you've just sort of thrown everybody right off the scent by saying "Missing Operating System."  It's like, ohhh.  It's like, don't even bother going any further.



LEO:  There's a difference between security through obscurity and not giving people more information than they need.  That's why you say stealth your ports.



STEVE:  Right.



LEO:  Why volunteer information?  Why volunteer that TrueCrypt's installed?  In fact...



STEVE:  I have a buddy who's got his WiFi router's SSID set, the beacon that you can see whenever you browse, like, WiFi in your area, he has it set to NORAD Missile Command or something.



LEO:  Now, that could go both ways.  That might encourage somebody to try to break in.



STEVE:  I just think someone says, oh, crap, I'm not going to touch that.  They're going to get me.  So I just like "Missing Operating System."  That's classic.  That's just beautiful.  I wanted to give Emil a little nod of the head for that one.



LEO:  That's really good.  Bobcat in our chatroom says his TrueCrypt login, boot login is "NT Loader Is Missing."  Another good one.  Make it look as much like the real thing; right?  Paul Dove in Hampton, UK, Question #9, our penultimate question, is using WAN router administration.  Oh, we were talking about disabling that.  And we said, well, who would use that?  Who would ever...



STEVE:  Who would ever want that?



LEO:  And in fact he's quoting you from Episode 214 saying, "It's very distressing, Leo, if there are still routers that have WAN admin on.  I mean, nobody needs it."  Well, Paul says, I have three routers connected in a Y with a WPA router on one branch of the Y - this is what we talked about as the way to do WEP securely.



STEVE:  Yup, the ultimate WiFi security.



LEO:  So he's got WPA on one, WEP router on the other, and then they are connected, the two of them, to a third router.  He says:  I only have the WEP router so my kids can connect their Nintendo DS.  That's exactly why you do it.



STEVE:  Yup.



LEO:  I would never want to connect any PC to this router, so I have it set to WAN admin so that I can change settings by accessing it externally.  But I'm still behind the router and firewall at the base of the Y.  And when I'm accessing the settings this way I don't think there's any way data can get from the WEP device to my main WPA network.  Am I safe?



STEVE:  I thought that was a really interesting and great reaction.



LEO:  It's a good use, yup.



STEVE:  Yes.  He is certainly safe.  What you don't want is the Internet to have access to your WAN admin because without other provisions there's nothing to prevent someone from just pounding away on its login, trying to get in.  But here he's using - he's got WAN admin on one of his internal or interior routers, so that he's able to access it from outside of the WEP protected network but still inside his own local area network because that's inside the router which is interfacing that Y to the Internet.



So, yeah, I thought that was a great reason, and he should be completely comfortable with that.  There's no way bad guys can get to his WAN interface.  And certainly no way anybody on the WEP side can get to it, either.  So it being enabled is fine.



Although you definitely want to make sure that you've got a very strong password on your LAN side login for the WEP router because we know how broken WEP is.  And so by catching some packets while your kids are using their Nintendo DS, they would be able to get the WEP key, and that would allow them to try to log into the WEP router on the LAN side using the web interface.  So you would absolutely want to protect that.



LEO:  It's already more broken just because it's using WEP than WAN administration; right?  I mean...



STEVE:  Right, right.  That's a very good point.  That's a good way of looking at it.  That's the bigger concern than the WAN side being exposed, which is only exposed internally.  So I thought that was very clever.



LEO:  Good.  Our last question, Steve, from Dave and Max in the UK.  And they want to know, can we watch Security Now! after it's been broadcast?  I know you guys broadcast it live.  Yes, we do.  We do it every Wednesday at 2:00 p.m. Eastern.



STEVE:  Actually, Leo, that's right now.



LEO:  Oh, yeah.  11:00 a.m. Pacific, which is 1800 British standard, actually British daylight time.  But is there any way I can watch the episode after it's been recorded?  We're in UK, so due to the time difference we're unable to watch Security Now! live.  I'm sure other listeners would like to watch live after it's been recorded.  So keep up the good work.  Well, I have good news on that count.



STEVE:  This was one for you, Leo.



LEO:  And we're kind of pre-announcing it.  So it's not ready yet.  Right now, the way we do Security Now!, we do record it live.  And as with all our shows, you can watch that live recording.  You know, think of it as a spy cam into my studio, although it's a little fancier than that.  And we in fact replay it again and again later in the day.  So Wednesday evening and - Steve, Steve, Steve.  Steve's playing with the camera now.  Wednesday evening and Thursday in the early morning hours you can probably catch it with other shows being rerun.  But that's not very satisfactory.  So some of our viewers have for the last year been capturing the Flash and putting it on their website, with our permission and encouragement:  ODTV.me.  ODTV.me.  So you can, in fact, go back and watch reruns there.  But we're about to announce, in a couple of weeks, at Blog World we're going to announce this...



STEVE:  What, what, what, what, what?



LEO:  That we're going to offer video of this show and our top five shows, and then slowly roll out video of all the shows, both for download on iTunes or whatever you use for your podcatcher, the Zune, you can watch it on the Zune HD.  That will be one way you can get it.  But we're also working with a company called Mediafly.  They're going to put it on the Roku box.  I know you know about the Roku Netflix player.  So you'll be able to watch us.  And I think - again, this is a pre-announce, so I probably shouldn't even say this.  But I think you'll be able to watch both live or after the fact, so on that Roku box.  And then we're going to slowly roll it out on a lot of platforms.



And my hope is, my plan is that, on whatever platform it rolls out, whether it's your portable phone, your television, your TiVo, whatever, that you'll both be able to watch what's currently live or what was live, so that you have kind of the choice.  You know, you can either - it's like on-demand or live.  So that you would be, Dave and Max, you'd be able to go there, and you'd say, well, I missed the live broadcast, but I want to see it again, and be able to press a button and be able to watch it.  Now, Roku's not available in the UK, but this is coming your way soon.



And we're rejiggering everything to make this possible and spending a lot of money.  We have to get a SAN device.  We're going to change all of our editing from just audio editing to audio and video editing in Final Cut.  We've had our little - our squirrels, Colleen and Erik and Tony, working like crazy to get this ready.  And we hope to have it ready in the next few weeks.  So we'll let you know when that is available.  But, yeah, this will be - I'm pretty sure this will be one of the shows that we roll out right away.  I can't remember what the list is.  But it's certainly on the list.



STEVE:  Where is Security Now! in the ranking?  Because once upon a time TWiT was number one and...



LEO:  TWiT's number one.



STEVE:  ...we were number two.  Are we still?



LEO:  You were the - this was the second show.  No, I think it's TWiT, MacBreak Weekly and Windows Weekly in a close tie, Net@Nite and Security Now! in a tie for third place, and then - actually, you know, TWiG, our newest show, is now I think in third place.



STEVE:  Wow.



LEO:  It's going up very fast, yeah.



STEVE:  And that's This Week in Google?



LEO:  Yeah.  Yeah.  And that's because of the subject matter, but also because of our host.  We have Gina Trapani and Jeff Jarvis are so good and have lots of fans in their own right.



STEVE:  She's neat.  I saw a replay of that.  I'm thinking, okay, who is this, and what show is this?



LEO:  She created Lifehacker.  I mean, Gina is like, you would love her.  She's a programmer.  She's a productivity guru.  Just a great person.  She lives in San Diego, kind of down your way.



STEVE:  Yeah, she's neat.



LEO:  Yeah.  So it's my goal to do two things.  I think in the long run, I mean, the audio podcasts are what got us started, and they still pay all the bills.  But in the long run it's my goal to create a 24-hour kind of CNN for geeks that all of our shows would be part of, and additional shows, you know, almost 24/7, as close to that as we can get.



STEVE:  And would always there be live streaming?  Or could it be that it would end up just being download on demand shows?



LEO:  I want to keep doing live streaming because I think that the idea of being able to just go somewhere and press a button and whatever's on you watch, and that would make us more - for instance, in about 20 minutes we're going to check in, at 1:00 o'clock we're going to check in with The New York Times and see what they're working today.  So I want to be - I want to have a live kind of network that, whatever's going on, you're always kind of apprised of what's right now because people like live.  But at the same time we realize that, if we do it live, everybody's gotten conditioned to being able to TiVo everything on television.  So we've got to make it, you know, some way for you to be able to get the stuff after the fact.  So we'll make - that's really what's going on here.  That's why we're doing the downloads.



STEVE:  I think it's perfect.  It sounds like it's - those bases are covered, Leo.



LEO:  Well, it's a project.  It's quite an investment financially and in terms of manpower.  You know we've got - there's now seven full-time people working here, and a goodly number of part-timers.  So it's expanding very rapidly.  But I won't ever be as big as - you are the cautionary tale on getting too big.  I don't ever want to be so big that I have to go to meetings all day.



STEVE:  No, especially when your meetings have meetings.



LEO:  There is a staff meeting now, in about 15 minutes, however.  We now have a staff meeting.  Of course, when you say all hands, we can fit around a small round table.  So it's not so bad.



STEVE:  That's good.  Well, we're going to talk next in two weeks, since you're going to be in some big, high, highest building in the world in Dubai when Alex Lindsay and I are talking about the fundamentally broken browser model.



LEO:  Oh, that'll be fascinating.  And then I'll be back in time for Q&A #77.



STEVE:  Yup.  And then we're going to do a really neat episode about the innards of JavaScript...



LEO:  Oh, that's going to be fun.



STEVE:  ...and its fundamental problems with our friend John Graham-Cumming.



LEO:  Creator of "The Geek Atlas."



STEVE:  Yeah.



LEO:  He's the guy, too, when we interviewed him on TWiT, who got the apology from the British government for Alan Turing's prosecution.  Really neat guy.



STEVE:  Very cool.



LEO:  Love John.  So that's going to be fun.  I can't wait for that.  Steve, always a pleasure.  Don't forget, Steve's at GRC.com.  That's the place to go to get your copy of SpinRite and all those free, wonderful utilities that Steve is just cranking out all the time.  GRC, that's short for Gibson Research Corporation, GRC.com.  And if you go to GRC.com/feedback, you can give Steve questions for future episodes.



STEVE:  Please do.



LEO:  Yeah.  You can also get 16KB versions of this show for the bandwidth impaired, full transcripts, and show notes there, as well as on our wiki - wiki.twit.tv - and our  FriendFeed conversation pit.  That's FriendFeed.com/twit-conversations.  Follow along there in real-time.  And our chatroom.  Let's not leave that out, as long as I'm giving you everybody - IRC.twit.tv.  Steve, we'll see you next - I won't, but everybody else will see you next week.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#217

DATE:		October 8, 2009

TITLE:		The Fundamentally Broken Browser Model

SPEAKERS:	Steve Gibson & Alex Lindsay

SOURCE FILE:	http://media.GRC.com/sn/SN-217.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Alex discuss the serious security problems created by the way SSL connections are specified by non-secured web pages, and how easily a "man in the middle" attack can compromise this amazingly weak web-based security.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



ALEX LINDSAY:  This is Security Now! with Steve Gibson, Episode 217 for October 8, 2009:  The Broken Browser Model.



LEO:  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



ALEX:  Welcome back, ladies and gentlemen, to Security Now!.  I'm Alex Lindsay, sitting in for Leo.  And of course we are here with the security guru, in an undisclosed location in Southern California, Steve Gibson.



STEVE GIBSON:  Hey, Alex.



ALEX:  Hey, how you doing?



STEVE:  Great.  Great to be with you this week.  And it's fun to have, for the first time ever in our history - every time in the past, when Leo was going to take a sabbatical or go on a cruise or something, we've doubled up and recorded episodes in advance.  This is the first time I've had a co-host, or a different co-host than Leo.  So...



ALEX:  I'm pretty excited to be here.  I'm excited to give this a shot.  Let me tell you, you look marvelous, marvelous.



STEVE:  Well, of course you and I know each other well.  We've sat on the sets of various of Leo's shows through the years, I guess both in Vancouver and in Toronto.  So that works.



ALEX:  Absolutely.  And what do we have on the docket for today?



STEVE:  Well, a really interesting thing has sort of been on my mind.  I mentioned it briefly last week.  A hacker who goes by the acronym, or not the acronym, the moniker of Moxie Marlinspike...



ALEX:  Whoo.



STEVE:  ...gave a presentation which I think he somewhat erroneously titled "New Tricks for Defeating SSL in Practice."  This was at the Black Hat conference in DC.  And ever since I ran across it, it's sort of just been haunting me.  And I've been wanting to share with Security Now! listeners what it was that he presented because sort of within this, if you sort of take some of the window dressing off, there really is a fundamental problem with the way we're doing security through Internet browsers.



And so I would rename this, and in fact this is the title of today's episode, "The Broken Browser Model," because the way security is sort of brought to play creates some vulnerabilities.  And so I want to go into it in detail.  It builds on, as many of our episodes do, many of the things we've laid down before, which I'll review briefly to sort of create a foundation.  But then I'm going to sort of take us through the way it's possible for people who believe they're securely logging in, securely providing credit card numbers, and doing those things with no vulnerabilities, that is, not taking advantage of any defects or any problems, but actually just taking advantage of how the browser model is fundamentally not really secure allows all that information to be captured by a third party.  So I think it's going to be a good hour here.



ALEX:  So now, early on, back to our regular scheduled program, we've got security news.



STEVE:  Yeah.  There's a couple interesting things have happened in the last week.  First of all, a sort of a run-of-the-mill, what we seem to be talking about constantly are buffer overruns.



ALEX:  Right.



STEVE:  The Google Chrome browser has been updated to v3.0.195.25.  All prior versions are vulnerable to a problem that was found, apparently through examining the open source code, because of course Chrome is an open source browser, so the code is available to people.  There's - it's called the dtoa.  It converts strings to floating point.  And so there's an exploit that has been found that has been made public for the Google Chrome browser.  So I don't know how many of our listeners are active users of the browser.  Apparently it's currently rated fourth in popularity.  But that doesn't mean, like, it's got 25 percent of the market.  The popularity of the top two browsers, IE and Firefox, commands most of the browser market share.  And I'm not even sure who's number three.  I guess probably Safari, thanks to Apple.



ALEX:  Yeah, I think that Safari is number three.



STEVE:  Yeah.  And so Chrome is an also-ran.  But for anybody who is using it - you know, it's funny.  When I fire it up in order to install the updates like this, I look at it, and I think, wow, it really is pretty.  I mean, it's just a pretty - especially under Windows.  It's just a pretty-looking browser.  But I don't know, there's nothing compelling about it for me.  I'm well converted over to Firefox.



And in fact that sort of leads us into our other news.  There is an update for any Blackberry users who are using the Blackberry software 4.5 through 4.7.  You may want to check to see whether RIM has an update for you.  They have fixed a defect that we're now going to talk about.  We've actually talked about it more than nine weeks ago, more than two months ago, a problem with a null character occurring in a security certificate.  The good news is that the Blackberry browsers are being updated now to fix that.  The bad news is that just three days ago, this last Monday, a fake PayPal certificate was posted on the Internet which allows SSL connections, Secure Socket Layer connections, to be spoofed, that is, like with various sorts of phishing attacks, using this fraudulent certificate.



ALEX:  So you can think you're paying through PayPal, and you're really paying - you're really connecting to somebody else.



STEVE:  Well, exactly.  And in fact this is - what's disturbing about this is that this is more than two months old.  This is a defect that originally affected all Windows browsers.  Microsoft still to this day, more than nine weeks after this went public, has not fixed this.  The problem still exists in their own CryptoAPI library, which is a shared component of Windows that IE, Apple Safari running on Windows, and Chrome all use.  So today IE, Safari on Windows, and Chrome are all vulnerable to this.



What's interesting is that Firefox, both version chains of Firefox, the 3.0 and the 3.5, fixed it within a couple days.  And there was also the problem, even in the Mac OS X originally, but Apple fixed it a couple weeks later.  So this has long been fixed for Firefox under Windows and Safari under OS X.  But even now, more than two months later, has not been fixed for IE, Apple Safari under Windows, and Chrome.  And now we have this fake PayPal certificate that is being circulated on the Internet that essentially, if it's used, you can actually establish an SSL connection to what looks like PayPal.  We talked about this a couple months ago, to remind our listeners.



The idea is that the way strings are stored in pretty much all modern operating systems is it's just a sequence of bytes that ends with a null byte, that is, a zero byte.  They're so-called null terminated strings.  Strings historically have been stored in various different formats.  Pascal was famous for storing the length of the string as the first byte, which was convenient for all kinds of reasons.  The problem was that a byte can only be 0 to 255.  So Pascal strings could never be longer than 255 characters.  So that was sort of fixed by saying, wait a minute, we'll just allow a string to be any length, but terminate it with a null.  Well, of course that has had disastrous security consequences.  That whole null terminated string issue, while it's very convenient for programmers to sort of scan until you hit a null, that's largely responsible for all the buffer overrun problems we have today.



ALEX:  Now, is part of that giving a hacker an idea of what to look for?



STEVE:  Well, it's more that the operating system will just read bytes until it hits zero.  And it'll do that blindly.  So if you tell it to, like, copy one string to somewhere else, it will copy as much as you give it until it hits a null character.  So it creates this, like, all kinds of opportunities for exploitation.  What's interesting about this particular null - it's call the "null prefix vulnerability" in certificates - is that you can create a certificate, www.paypal.com null, that is, a zero, and then anything else you want, like mymachine.secure.net.  And so the certificate is actually for the secure.net domain.  And certificate issuers will issue certificates to the secure.net domain.  And then if you embed a null between sort of your own machine name, www.paypal.com, the browsers, while they're parsing the name on the certificate, they stop at the first null.  Which is the way strings are processed in our modern operating systems.  So it's not a surprise that they do this.  But you absolutely don't want that behavior in this particular instance.



ALEX:  Right.



STEVE:  So anyway, so essentially this is a bad problem.  Microsoft has not responded.  And as of three days ago there is this known fraudulent PayPal very spoofable certificate floating around the 'Net.  And of course the big question is, okay, we know about the PayPal cert.  What other ones have been issued that we don't know about?



ALEX:  Right.



STEVE:  So essentially the takeaway from this is, at the moment you cannot trust, that is, a Windows user cannot trust any Windows browser other than Firefox.  The Firefox guys fixed this.  They took responsibility away from the underlying Windows platform and fixed it themselves within days.



ALEX:  So, now, so Apple could fix it, for instance, on Safari.  They just - they would need to - but right now they're relying too much on the Windows framework?



STEVE:  Exactly.  They're using - there's a shared library called the CryptoAPI that IE, Safari on Windows, and Chrome all just assume the underlying framework is reliable.  They're all using it.  And as a consequence, today they're all vulnerable.  And so Apple did fix it in OS X immediately, but haven't done so on Safari under Windows, probably presuming that this is, you know, hey, this is not our fault.  This is a Windows problem.  The problem is that it makes all browsers except Firefox untrustworthy, I mean, completely untrustworthy, for making secure connections until Microsoft finally fixes it.  Which maybe they'll do so soon.  I hope so.  



ALEX:  Yeah.  Well, it seems like, I mean, it really - wow.  That's a huge bug.  It seems like, I mean...



STEVE:  It's just a huge problem.



ALEX:  It's not like a little thing.  Any time you start talking about money, you know, we get concerned.



STEVE:  Yeah.  Well, and again, Microsoft has said, oh, our engineers are looking at the problem, and we're analyzing it.  And as soon as we have a resolution to it, we'll issue a fix.  It's like, guys, fix it now.  And, I mean, I'm not at all happy that this PayPal certificate has gotten loose because there's no question people will be compromised by it.  We can hope, though, that this ups the pressure on Microsoft, which apparently they're not feeling sufficiently enough to address this.  But, I mean, this is a real problem.  And it's difficult to understand how it's so difficult to fix.  It's a simple, obvious, anyone can explain it to someone else and go, ooh, that's not the way it should work.  Let's fix that.  It's just not a difficult thing for them to do.



ALEX:  Interesting.



STEVE:  So in other news, well, that's basically all the security news we have for the week.



ALEX:  Right.



STEVE:  I did have something that I forgot to tell our listeners last week, which conveniently was October 1st, which was the release date of the third book in a trilogy that this podcast has followed.  There's an author that we like, Michael McCollum, who has a website, Scifi-AZ.com, where he publishes a tremendous set of science fiction books which are also available in eBook, all kinds of eBook formats.  I had some communication with him this week because I sent email to him saying, oh, shoot, I forgot to mention that in last week's Security Now!.  So I said I wrote - didn't write it down, so it didn't get remembered when we were doing the podcast.  So I said I'm writing it down this time.  I will not forget again.



And he said, well, actually, he said sales of the third book in the trilogy - this is the Gibraltar trilogy, starts with "Gibraltar Earth," then "Gibraltar Sun," and "Gibraltar Stars."  So I just wanted to let our listeners know, for anyone who is waiting to hear that the third book in the trilogy has been published, it's now been out for a week.  He did say that, interestingly, eBook sales were really even stronger than paperback sales.  He prints and publishes and binds his own paperbacks.



I actually had the privilege of editing, or I should say proofreading, the final book before its publication and found just a handful of little typos here and there, the kind of things that the person who writes it can never, you know, proof their own work because their brain just scans across it and sees what they expect to see.  It takes somebody else to look at it.  So I was able to give him some help with that.



And then Leo and I have long been fans of eBook readers.  Of course we buy anything that happens.  And I had mentioned a few weeks ago that I was sort of excited about Sony's so-called Pocket eReader, which they were reputed to be coming out with at the beginning of the month because it had a five-inch screen.  And while I think that's probably on the small side, the idea of something like an eBook reader that you could literally put in your pocket- although people argue, wait a minute, my iPhone has an eReader in it, and it's even Kindle compatible, or Amazon compatible.  So I've got an eBook in my pocket.  At the same time, Sony uses the eInk technology, which is the same thing that the Kindles use.



So I was excited until I saw it because in my, yeah, in my imagination a pocket eBook that had a five-inch screen would be very much like the iPhone, where looking at it, it would be all screen.  And then maybe they'd have the UI sort of on the edges somewhere.  So you could hold it and, like, click an edge-mounted button or something.  And that I could see putting in your pocket.



Well, having seen now the so-called, well, it's the Model No. PRS-300, it is at a very good price.  It's $199.  So it's nice that we're seeing the price of these come down.  The problem is that it is very much like the same UI as the other eBook readers so far and like the other Sonys, where you've got a bunch of controls down the right-hand side of the eInk screen, and then a whole bunch of control surface below the screen.  So in other words, you've got a smaller screen, but so much margin UI that it ends up being big again.  And I don't know whose pocket it fits in, but not mine.



ALEX:  I still find myself, every time I pick up any of these eReaders, I want to go like this.  And I just - the text doesn't move.



STEVE:  Yeah, yeah.  Well, and I just, for me, I'm a Kindle lover.  And I'm a little - I do like the way the iPhone's screen UI functions.  And I think if a UI is going to use a touchscreen, it's got to be really responsive.



ALEX:  Yeah.



STEVE:  There's a company called Plastic Logic that is also in the game now with a touchscreen-based reader.  I haven't seen it, haven't purchased one, never had the opportunity to look at it.  And it's got a large screen.  But it's got no controls because it uses the screen as the UI.  And I'm like, uh, okay.  I hope that works.  I'm really not a fan, I think, of touching the screen.  I like the idea of holding the book exactly the way Amazon has finally done it, that is, the Kindle does it, where you've got your hands on the button.  And with, you know, almost subconsciously you just will the screen to change, and a slight movement, a slight twitch of your hand causes that to happen, instead of having to move my hand into the screen area.  That's my reading area.  I don't know that I want to be reaching in there in order to change the page.  So I think the jury's out on that.



ALEX:  Yeah.  I just like the fact that, when you have touchscreens, you just get a lot more - you get a smaller device that has more screen real estate.  And I think that's what, you know, it's that tradeoff.  And I'm really happy with it.  I mean, I find the biggest thing when I look at a Kindle is there's just so much extra stuff around it.  And I'm just used to a device that just has a screen.



STEVE:  Yes, a really spare UI.  And in fact, I don't know if you've seen, I'm sure you have, like some of the mockups of the we-dream-of-it Apple iPad?



ALEX:  Yeah.



STEVE:  Oh, my god, there's one that just looks like this beautiful slate that is, I mean, it looks like nothing other than they took an iPhone and stretched it out, which of course is what the guy did in Photoshop in order to make this mockup.  But, oh, it just - it's lying there.  You can just sort of imagine yourself flicking the screen and the pages scroll.  And, you know, we've heard a lot about what Jobs is reputedly doing, I mean, like, really the noise he's making, of course, he always makes a lot of noise, but this is going to fundamentally change the way print is handled.  And it's like, okay, Steve, well, that's good.  I hope you do.



ALEX:  I hope it's in color.



STEVE:  Oh, yes, yes, yes, yes.



ALEX:  You probably, you know, this is becoming This Week in eReaders.  Which I think would be a great show, by the way.  I think it's something that we should talk to Leo about.



STEVE:  Yup.  Well, in fact we have spent a lot of time on it because we're readers.  Audible is a sponsor, although of course eBooks are not audible, although a lot of the eBooks do have audio players built in, so you can certainly use them with Audible content.



ALEX:  Well, I think there's going to be some - I think there's some convergence there, too.  I think that we're going to end up, I think, I'm really interesting in having Audible books that have visuals that's connected to what I'm listening to.



STEVE:  That would be cool, yup.



ALEX:  I think, you know, that's another step.  Because right when we start getting - start using an iPhone or start using an iPad or start using whatever we end up using that has interactive, that can do video, that can do all these other things at the same time, there's an interactive experience that, you know, we're not getting to yet.  I mean, the way we're using eBooks in my opinion right now is kind of like when we started with film cameras.  What we did is we started shooting people onstage.  Like, that's what we used a film camera for a hundred years ago.  And then we realized, you know, we could do this - we don't have to do it the same way we used to.  You know, we could start adding - we could start moving the camera around.  And we could shoot the scenes out of order.  And we could put the camera on a big stick and move it around.  And before we know it we completely shattered all the rules that we had with stage.  And I think that that's, you know, we're just at the very beginning of experimenting with that with text on these little screens.



STEVE:  Well, and I guess, like, for example, what you're saying is that books don't necessarily have to be as linear as they have always been because you could do things like follow - a book could be written with several different plot sequences where you go, like, follow a character in this direction, and then somehow it takes responsibility for making sure that you know about this other thing happening and sort of, like...



ALEX:  Well, I've talked to a lot of writers who just - who are aghast at that idea.  They want to control the story experience.  But I do think that there is a real opportunity when I'm reading, there's so many things that when I'm reading something, or more importantly when I'm listening to something, that it would be great to just see images, stills, and possibly video, and possibly, you know, all these other things that are just kind of set up to go along when we hit this part of the text.



There's a book that I wish was in Audible, which is called "Africa:  Biography of a Continent."  And I always think of all the imagery that could be, you know, done while he's talking about the history of how Africa was designed, I mean, not designed, but built.  Or, I mean, how it, you know, it was generated through the tectonic plates and, you know, so on and so forth.  And that's the kind of stuff that I would love to see, you know, mixed with this whole process.



STEVE:  Yeah, yeah.  Well, because there's a lot of stuff that's difficult to visualize, that in just an audio stream is tough to convey.



ALEX:  Yeah, absolutely.



STEVE:  Well, I do have a fun little SpinRite 6 success story, sent to us from a Jeffrey Morse, who just sent email to our tech support email.  And he said, "Steve, I wanted to congratulate you on what in my opinion is one of the best data recovery utilities available.  About a week ago my mother's computer would not boot.  And when attempting to run the Recovery Console, the system crashed with an unmountable boot volume BSoD," the infamous Blue Screen of Death that so many Windows are people are used to, unfortunately, or have been abused by.  He said, "Some three years' worth of digital camera photos from her architectural leaded glass business were seemingly lost for good.  So I decided to give SpinRite 6 a try.



"At first it had a lot of trouble getting past the damaged area of the drive, which included the partition table.  So I took it out of her system.  And since mine had an external SATA card, I hooked it up and rebooted with SpinRite 6 bootable CD which I had made.  After four hours it had found a total of 30 damaged sectors, seven of which were not completely recovered, but all the others were.  But it was enough that I was able to retrieve all the pictures, 2.4 GB worth, from the drive.  Thanks again, Steve.  I would definitely recommend SpinRite 6 to anyone who finds themselves in a similar situation."



ALEX:  Oh, that's just terrifying.



STEVE:  Well, yes.  It's funny, too, because as Leo and I have commented, drives have come down a lot in price, so that SpinRite at $89 is more expensive than...



ALEX:  Drives.



STEVE:  ...than typical drives that it's being used to recover.  But of course the point is, it's not the drive that you're trying to save any longer.  It's the data.  The data is what's so valuable because, as drives have increased in size, people have begun storing all this media on them.  And the problem is the drive worked the first day, and it worked yesterday and the day before.  But you wake up one really bad morning and you find, whoa, wait a minute, where is all my data?



ALEX:  I've had those mornings.  I've had those afternoons, and I've had those evenings.  You know, where you have a drive that just, you know, starts clunking.  Or just something's missing.  And the alternative is much worse.  I mean, I have sent drives into DriveSavers, or brought them in.  And you're looking at two, $3,000 for them sometimes to do exactly what you're going to do.  That's the first line of defense that they're going to do before they start looking at the hardware, like tearing apart your drive, is seeing if they can do a software solution that's going to fix it, which is exactly what this is.  Or not maybe exactly, but similar to this process.



STEVE:  Well, we know from people who used to work in various data recovery companies that running SpinRite is typically the first thing they do.



ALEX:  Right.



STEVE:  So they give that a try because it's, I mean, it's zero manpower.  They get to charge X amount of dollars, typically with plenty of zeroes on the end of it, for just letting a machine run off on the side somewhere, running SpinRite, doing whatever it's going to be able to do as their first thing.  Maybe that's all it ever takes, and they still charge the customer some X with a lot of zeroes on the end of it to get the data back, or to hand it over to them on DVDs or whatever format.  So, yeah.



ALEX:  Yeah, no, and I - in the office our saying is that no file exists until it exists in two places.



STEVE:  Exactly.



ALEX:  And literally, every time we shoot something, that's all we care about.  We buy - and we go with the RAW drives.  We go through a couple terabytes a week of RAW drives.  And everything's in two copies immediately.  And we always record - we always, when we make those duplications, we never copy the copy.  So when we're recording a source, like if we record a whole bunch of data, we record from the source to the copy, and then we record from the source to the second copy again.



STEVE:  Exactly.  You never want to - you don't want a second-generation copy.  You want multiple first-generation copies.



ALEX:  Exactly.



STEVE:  Yup.



ALEX:  So anyway, food for thought.  And Steve?  What do we have coming up here now?



STEVE:  Okay.  So this follows on from a really good presentation at the Black Hat conference.  I want to give Moxie Marlinspike the props that he deserves for sort of pulling this together.  I think this is the sort of thing that arises when a hacker spends some time thinking about how can we get around perfectly working security systems.  Years before...



ALEX:  So this isn't really - we're not talking about a bug here.  What we're really talking about is just a feature problem.



STEVE:  Well, exactly.  Well, we're talking about a fundamentally broken model, that is, a model that we're all using every day, which you could argue should never be used the way it is being used.  So whereas...



ALEX:  That's pretty much the case, that's pretty much the case for the entire web; isn't it?  I mean, the HTML - HTML was never designed to do what it's doing now.



STEVE:  It's certainly the case, I absolutely agree with you, that HTML, even the acronym is something that should never be exposed to end users.  I mean, the idea that there's http://, I mean, that's about as hostile to my mother as anything could be.  Yet she has to look at that.  She has to deal with that.  That's unfortunately inserted itself into her life and in the lives of all these other people who've been literally, I mean, forced onto the Internet because that's where everything is now.



ALEX:  Well, we didn't have to originally.  I remember I used to be part of Prodigy many, many moons ago.  And then there was AOL, and all of these were safe little areas for home users to kind of go into that.  But as, of course, as the web blew up, it just kind of we, you know, a lot of us left that.



STEVE:  Right.  Well, in fact, Mom's email account - she was also an early AOL user, although I don't know whether it's deliberate or not, but she calls it sometimes AWOL because she's just not happy with it.  Okay.  So earlier in this episode we were talking about this null character vulnerability, which is clearly a defect in the way SSL certificates are being parsed.  What I want to talk about today, though, is not that.  It is, if everything else is working correctly, how can a bad guy still break into SSL connections, essentially, or effectively, while not actually doing so, but with the same consequence.



So what Moxie noted at the beginning of his speech I think was really astute.  And that is that most people don't directly deal with SSL connections.  That is, they're not putting in typically https://www.something.  Typically people will, for example, just put in PayPal.com.  And in fact some of our web browsers, like Firefox, are becoming smart enough that, if PayPal.com doesn't resolve to an IP, the browser itself will try www.paypal.com because that's probably going to be valid if PayPal.com isn't.



But in any event, what we end up with, then, is up in the URL bar, then, we see the final URL:  http://www.paypal.com and then a whole bunch of gobbledy-gook that, unfortunately, again, sort of due to the evolution of the browser needing to hold on to individual users and their sessions, oftentimes is just impenetrable, random-looking numbers and symbols and stuff in the URL.  Again, not something that you would ever really want to expose users to, but there it is.



ALEX:  Right.



STEVE:  So one of the things that we've talked about is that the way a browser and a remote web server work is in a query/response model, where the browser asks for a page in a connection to the remote server.  The remote server provides that page, which the browser then parses.  And more often than not, I mean, virtually now all the time, it's not pure text.  There's going to be window dressing, ads, menus, buttons, all kinds of stuff.  So those all require follow-on accesses back to that server, or maybe other servers, in order to fully assemble all the pieces of that finished page.  So when login happens, when you're at a site that wants you to log in, some sites will bring you to a secure page where you're filling in the form, like, you know, username and password and so forth.



ALEX:  And this is where you're typically going to look for the little lock.



STEVE:  Exactly.  But as our listeners know, it's not necessary for sites to give you a secure page to fill in the form because that's not the part that needs the security.  That is, when that page comes to you, it's got a blank form on it.  You fill in the fields.  And it's when you click the button, that's the event that requires the secure connection because sort of the way we bootstrapped sending information back to a web server, which was really not part of the original model.  The idea was you would click links, and you'd just get these pages, and you'd follow these links around, and you'd be looking at pages.



Well, of course we needed suddenly much more interaction.  We wanted to be able to be posting information, posting into forums and blogs and leaving comments behind and so forth. So the way this has been done is by encapsulating that information in a query, that is, sort of in a pseudo request to the server, which it understands as the receipt of information.  So the key that Moxie noted is that users generally don't worry about the switching in and out of an SSL connection.  We just assume that, if I'm at a PayPal login - and in fact a PayPal login screen is not secure.



ALEX:  Well, on the Windows we've already established that; right?  Forever.



STEVE:  Exactly.  It's the button you click that you assume is going to do the secure transfer.  But we've sort of given responsibility for that to the website.  We assume that the page it's given us will have an https URL on the Submit button for the form, which will bring up a secure connection in order to carry our data which we don't want anybody to be able to be monitoring surreptitiously in the background.  So it'll bring up an SSL tunnel to encrypt it so that no one who is either passively listening or may have inserted themselves into our communication is able to determine what data we're submitting.



ALEX:  But of course that's depending on where they insert themselves; right?



STEVE:  Well, so, yes.  So we understand what this model is.  So there is a means for inserting one's self into pretty much any Ethernet network, which we've also discussed in the past.  And I'll sort of go through a quick review to sort of reestablish that.  There's something called an ARP spoofing attack.  The way packets are routed on an Ethernet network, that is, a network that is inherently going to be a LAN, so it's within a local area network, so it's within your home or in your office or in a hotel or even in an open wireless environment, or for that matter in an encrypted wireless environment.  The way packets are routed is that the various interfaces, the Ethernet interfaces, all have a unique IP address.



They also have a unique MAC address, which is sort of the physical hardware identity of that card, that interface, on the Ethernet.  But we're routing so-called IP traffic, Internet Protocol traffic, which uses IP addresses.  It does not use MAC addresses.  So what's been created is a table, the MAC address table, which associates an IP address with its corresponding MAC address, so that when...



ALEX:  So it's saying that I've got a bunch of IPs, and these are all connected to this MAC, to this computer.



STEVE:  Exactly.



ALEX:  So when it says this is secure, it's assuming that every one of those IP addresses is connected to that computer, once it's established that.



STEVE:  Well, yeah.  It's a mapping between the IP addresses sort of in the environment and the physical interfaces that have those IP addresses assigned.



ALEX:  So it's basically, like, tying those IPs down to the hardware.



STEVE:  Exactly, to the...



ALEX:  So they can be anywhere.  Those IPs could be anywhere.  They could be on any server.  And it's saying all of these IPs belong to this computer.



STEVE:  Well, it's saying that, within the network, this IP is being handled by this particular MAC address, which is an interface on, like, it might be on the gateway.  It might be on a server.  It might be on the user's machine.  So, okay.  So it is absolutely possible, and not even difficult, for a third party that has access to the Ethernet to insert themselves into the communication link between, for example, another user and the gateway.  This ARP traffic is well understood.  ARP spoofing has - there's plenty of tools for doing this.  Essentially, you're able to tell the gateway that your MAC address has an IP that it doesn't.  That is, there's no prevention for that in the protocol.  You're able to insert your own entry into the gateway's ARP table so that, when the gateway wants to send a packet to user A, it actually goes to user B.  So there's no prevention for inserting ARP packets into these ARP tables.  And similarly...



ALEX:  And this isn't really - this is not a hardware problem.  This is really an issue of dealing with just the absolute what has to happen with the browser to go back and forth.



STEVE:  Well, actually it's even lower than that.  It's this was designed with no security in mind.  This was designed, you know, Bob Metcalfe, who did Ethernet at the Palo Alto Research Center, this was his original architecture for the way the Ethernet works.  And so this was - this all predates any issue, any concern with security.  So any user on an Ethernet can arrange to insert their MAC address into the ARP tables of any other machines on the Ethernet.  And what that means is that gateway traffic coming into the network bound for the proper user can instead be sent to the Ethernet interface of somebody malicious.  And when they receive that, they can then, knowing which user they have intercepted, they can then forward that packet traffic to that user so that the user sees no interruption, sees nothing wrong except that their traffic has bounced once through somebody else on that Ethernet before getting to them.  I mean, classic man in the middle.



By inserting these ARP table entries, a malicious person has inserted themselves into the conversation.  And by doing the same thing to that user's ARP table, that is, by replacing the MAC address of the gateway with their own MAC address, when the valid user sends traffic back to the IP of the gateway, their table, their ARP table believes that it's the wrong MAC address.  So instead it addresses the Ethernet packet back to the hostile man in the middle, who then forwards it on to the gateway.  So that allows anybody who's on the same Ethernet essentially to easily insert themselves into the conversation.



Now, this has been - this is a well-known, longstanding problem.  We have - we've developed actually on this podcast a defense against this on wireless networks using multiple routers, sort of a Y configuration of routers, because ARP traffic, well, because ARP spoofing is a serious danger.  And ARP traffic is inherently constrained within a single LAN.  And when you have routers, routers are essentially routing between LANs.  That's what a router is doing is it's routing packets between LANs.  So they end up blocking ARP packets, and they provide virtually un-bypassable protection against this kind of ARP spoofing.  But within a network, within an Ethernet, there's no protection for that.



So in any open WiFi scenario, you know, you go to Starbucks, you go to any open hotspot where you've got so-called "free WiFi access," everybody is on the same LAN.  Somebody could be sitting with a laptop and editing people's ARP tables in order to intercept their communications.  Well, the good news is, SSL, the Secure Sockets Layer, prevents them from intercepting encrypted communications.  That is, because there is no way for them, even though they're able to listen to the communication as it goes by, the way the SSL handshake is structured, even if they're there in the middle, they are unable to acquire the key, the secret key, the SSL session key which is negotiated by the valid client and the valid server at the remote end.



So SSL itself is safe and prevents this kind of man-in-the-middle attack from working.  But Moxie's point, that users essentially have the responsibility of switching in and out of SSL handled for them by the remote server is how this man-in-the-middle attack gets leveraged.  And here's how it happens.



So you're in an open WiFi hotspot and using your machine, minding your own business.  You decide you want to log in to PayPal.  And this is not using any fraudulent certificates.  This is, I mean, log into any secure site, doesn't matter what it is, with all the security systems working the way they should.  We're not exploiting any defects here.  So you go to www.paypal.com.  Well, that's a nonsecure page, http://www.paypal.com.  Which you may or may not pay attention to.  But over on the left it says, okay, log in securely.  And the page that you received has a Submit button which you just assume is an https URL.



But the bad guy in the middle, who's filtering your traffic, who's, like, who's arranged to receive all the packets you send out and receive all the packets coming back in before you get them, he's got some software running on there which simply strips out the https, that strips out the "s" from the URLs that it finds embedded in the pages you received.  So what you receive from - what you see when you are looking at this PayPal login screen, is the PayPal login screen, just the way the PayPal server sent it to you.  But web pages don't have any sort of signatures on them.  They don't have a CRC or an MD5 checksum or an SHA-1.  The web pages themselves have no security on them.  So we're assuming that the web page we've received has not been modified.  But there's nothing to prevent its modification.



So that's one serious problem with the web browser model.  What this means is that this man in the middle can remove the "s" from the https, which is unseen because it's part of the web page, and it's just there sort of hiding behind the button.  So you now put in your username and your password, and you click the login button.  What you have sent is again intercepted by this man in the middle.  The man in the middle has retained - this little software, which does exist, it's been written, this software remembers that it removed the "s" from this particular URL.  So when it sees the user requesting that URL, it adds the "s" back in and forwards the request.  But what it received from the user is a non-SSL query because the "s" was removed from the Submit button.  So the man in the middle has access to the secure, the so-called "secured data," and then forwarded the request onto the server over a regular SSL connection.



So the remote end that is the PayPal server sees what it expects, which is a secure submission of the login data, and accepts it.  Except that it was not secure for the first leg of its trip between the valid user and the spy who's sitting in the middle.  They just captured what you wish was secured PayPal information.



ALEX:  Steve, is there a point where you can see this?  So you're not seeing the https?  So in that first area where you're logging in, if you look up, and you don't see the https, you could be being spoofed?



STEVE:  Well, and so that's the key.  Many sites do not give you an https form.  They give you an https query.  That is, so normally, like, literally, www.paypal.com, the page you look at is not already secure, typically.  Now, it's absolutely the case that an astute user could detect that they did not receive a secure page in return.  But first of all, by that time, it's too late.  The person in the middle got their login information before they noticed that the page that they received was not secure.  Because if you make a secure query, you're going to have a secure, like, login confirmation page come back.  So an astute user could say, wait a minute, I didn't just get switched into secure mode.



But Moxie also came up with a solution for that, which is the favicon that we're so used to seeing, you know, the little Google "G," or basically the website's logo is now often carried in front of the URL.  Well, there's nothing to prevent this person who's intercepted the communication from replacing it with a little padlock, a little golden padlock.  So even though it's not the same thing that the site actually prevents, we're used to seeing this little padlock and equating it with security.  So this is not something that's going to fool somebody who is hypervigilant; who is, like, really looking at everything.  On the other hand, most people aren't.  I know my mom isn't.  She's logging in.  She's just sort of chortling along, assuming that the other side is taking responsibility for the security of anything it asks her.  After all, they're the ones asking her to log on.  So they'd better make sure that that's a secure process.



The problem is that, because of this fundamentally broken browser model, the idea that we're leveraging technology that was never designed for this, this was sort of all a kludge that people came up with.  It's like, wait a minute, how do we allow secure logons?  Oh, I know.  We'll just - we'll make the Submit button be https, and that will set up an SSL connection.  And it's like, well, yes.  If the page you receive is valid, if it's got the https in the Submit button, that'll work.  But if there's any scenario that allows that page to be edited on the way to you, then the page you get won't have the secure submission.



ALEX:  And there's no way for you to know that for sure because the thing is, is that no one requires it.  So that there's a lot of these sites that it's not - and it's an ease-of-use thing, I imagine, of not having you go through it.  Why would they not go through this first process of making sure that it's https?



STEVE:  Right.  Right.  And in fact it's - there's two things there.  First of all, the bad guy in the middle is still using https to the remote end.  So the server sees the secure side that it's expecting to because the bad guy has restored the URLs as they're going back out to the server, even though he stripped those as they were coming in to the innocent user.  So the server sees that.  What you really need is something we do not have, which is you need the browser, the user's browser to insist that any pages coming in be secure.  And there is no provision for that in our current model.  That is, the server can insist that it be getting secure connections.  But the user's browser inherently, the model is, takes whatever it's given.



And there's no provision for the browser insisting that https is used universally with PayPal, for example.  And there's some reason for this historically.  Back in the old days, back when we had 386 processors, the establishment of an SSL connection was costly in terms of computer resources.  It does involve a public key crypto process which is probably one of the most expensive in terms of processing power things to do.  So for that reason, in general, connections to servers are not secure, or secured, unless there's a specific need for them to be so.  And that's generally, for example, just during the logon process.



For example, we've talked about, for example, Google Mail.  If you go to - if you just go to Gmail.com you get an unsecure page.  You log in, and you are briefly secured; but Gmail drops you back to a nonsecured connection.  If you manually go https://gmail.com, then Google will respect the fact that you asked for a secure starting of the dialogue, and so it'll leave you that way.  And so your whole Gmail dialogue with Google is secure.  But up until recently there was no option.  Now they have an option where you can configure Gmail to say I always want a secure connection whenever I'm logged onto Google.  But that's only happened in the last couple months.



ALEX:  Is this the same for PayPal?  So, I mean, you can force a secure connection?



STEVE:  You know, I haven't tried with PayPal.  But certainly it's not the case for, like, everybody else.  I mean, like normally what happens is that the way the programmers of the web server and website set things up was they'll do a secure connection only when necessary, only when they expect something that is dangerous to be happening.  And then they will move you back into a nonsecure connection because traditionally it was very expensive to maintain secure connections.



ALEX:  Well, is it expensive on both ends, for both the user and the server?



STEVE:  Well, exactly.  And that's the point, is it's the concentration effect that individual end users could all be negotiating these SSL connections with no problem.  But a server that's handling tens of thousands of connections per second, suddenly it ends up just collapsing.  So the good news is, servers today, processors today are far faster.  This is why there are so-called "SSL accelerators."  You can buy SSL hardware that does this very expensive public key handshake in hardware to offload the burden from the server software because it's traditionally been so expensive.



So anyway, so the point I really wanted to make was, I wanted to sort of take our listeners through this very feasible scenario.  Moxie, whose name is really not Moxie Marlinspike, did create a tool which does this, which exists on the Internet.  He set it up in a WiFi hotspot, intercepted ARP packets, and performed ARP spoofing to insert himself into connections.  During a 24-hour period of time, he intercepted 114 logins to Yahoo.com, 50 logins to Gmail, 42 to Ticketmaster.com, 14 to RapidShare.com, 13 to Hotmail, nine to PayPal, nine to LinkedIn, three to Facebook.  And so in that 24-hour period he captured 117 separate email account logons; 16 credit card numbers along with all of the subsidiary, you know, expiration date and security code and everything, users' names, passwords, everything required to use those cards; nine secure PayPal logins; and over 300 other miscellaneous secure logins, using this tool.



ALEX:  Wow.  This is, I mean, this is really a catastrophic problem.



STEVE:  Well, yes.  I mean, this is why the browser model, I mean, this notion of using a web browser as if it were a secure interface is fundamentally broken.



ALEX:  Is the answer 'Net applications?  Like for instance when I'm on my - is it more secure, for instance, if I'm on my iPhone, and I'm using the Bank of America application that they have that is going to connect me to Bank of America, is that more secure as a standalone application than going to Bank of America's website?



STEVE:  I would say yes.  I would say that, I mean, given that it's been implemented correctly, the fact that it's not using the traditional browser model, but it will certainly be, if it's a standalone application which will have brought up its own secure encrypted connection, and then everything it's doing is through that.  One of the problems is the browser is so ubiquitous, there's all kinds of ways to hook into it and monitor what it's doing.  I mean, we see, like, toolbars being installed that we really didn't ask for.  Well, you know, these toolbars or add-ons have their hooks deep into the browser.  So this idea that we're treating a web browser as if it is trustable is fundamentally, I mean, it is intrinsically broken.  It's just, it's really...



ALEX:  I mean, is there a solution?  Is there something that can be done on either end to make sure that this isn't happening?



STEVE:  The only thing that I can think, I mean, and as I've been thinking about this ever since it became so clear how, as you said, how bad this is, as I was saying, is if we had the ability to tell the browser never, ever, ever allow nonsecured connections to PayPal, that is, I do not want to receive a page from PayPal that is not over SSL, because the key to this particular vulnerability is that a nonsecure page, even one, one nonsecure page that was edited could then edit everything else about our interaction with PayPal.



Now, you would need PayPal, that is, the PayPal server to agree to always have a secure connection.  There are some servers that will not accept, you know, where you can't just arbitrarily use https on any random page of theirs.  They'll like, they'll either say this page doesn't exist, or they may bounce you back to https.  Many of these systems are trying to minimize their burden, so they're moving users back to http when they don't have to be over a secure connection because it is still more expensive than not to create these SSL connections.  So that would have to change.  And our browser, we'd have to be able to instruct our browser, the following sites - PayPal, BoA, Facebook, Amazon, and on and on and on, sort of a list of, like, golden sites where we absolutely insist on the pages being secure.  But what would really be good is if we just did away with nonsecure browser connections.  Just...



ALEX:  Right.  Or have it tell you every single time, like assume you force an https, and assume that that's what I'm going to get; and if I don't get that, tell me.



STEVE:  Exactly.



ALEX:  Tell me, you know, give me, you know, heads-up, I can't go there securely.



STEVE:  Yeah.  And that would be completely unworkable today.  But that's - something has to happen.



ALEX:  Now, is that specifically from a processing point of view?  Or just be unworkable to have millions of people asking for a secure connection all the time?



STEVE:  You know, it's a good question.  I really don't know what the, like, quantitatively what it would mean to Amazon or Facebook or Twitter, for example, any of these sites, if all of their connections were SSL.  I don't really have a quantitative sense for it.  I know that it's a greater burden.  But I don't, well, okay.  Several things have happened.  HTTP 1.0 was the original spec.  And in that spec a browser always dropped its connection when it was done.  So it would make a request, it would receive the result over that request, and then disconnect.  And then for everything else it would make - it would create a new connection, make the request, and then disconnect.



One of the changes in HTTP 1.0, because it was recognized that this was dumb, if we had a lot of transactions back and forth as we walked around interacting with a single site, why keep bringing up and dropping these connections?  So the HTTP 1.0 model, and that's a little agreement in the query that the browser makes that says I'm using what protocol version, and so all browsers now support HTTP 1.1, it'll say this is what I'm using.  And in one of the headers they'll say, I'm willing to keep this alive.  And so it's a keep-alive header.  So the server says, oh, whew, thank you.  And so the spec says that a client, a web client, can and will have a maximum of two connections at a time to the remote server.  And it's able to reuse them.  So the client is able to send a stream of queries down those connections and receive a disambiguated stream of responses back.  So in that model it's much less expensive to establish two connections which are SSL because now they're persistent.



Now, while you're on that site, roaming around their pages, there's no more negotiating being done.  And in fact, because of this expense, some of the newer versions of the SSL protocol allows a reuse of the credentials which have been negotiated.  We did a podcast a few months back where we dissected SSL in detail.  And one of the cool aspects of it is, if both ends agree, and both ends still have the credentials that were painfully and expensively negotiated recently, they both still have them in their caches, then with both of their endpoints in agreement they're able to bring up a connection without going through the public key crypto overhead again.



So there's been so much progress that I'm skeptical that it would really be that big a problem if servers required that kind of operation.  I wrote GRC's eCommerce system from scratch because I'd never written one before, and I incorporated these kinds of things.  The first page you get where you're looking at a form must be, it is secure.  And the server enforces that security.  So it absolutely insists that anytime you're in the eCommerce system you're going to be secure.  But even doing that, still, I mean, nothing prevents this exploit from being functional because the bad guy in the middle would be able to establish a secure connection just like he would to any other website.  So the web server at the other end is fooled.  And it takes - the only indication is that diligence on the part of the user to notice, wait a minute, I don't see security here.



ALEX:  But still, but even if you're diligent, it's already too late when you figure it out.



STEVE:  Precisely.  Because it's not until you get the result from submitting that insecure data that it's like, oh, crap, wait a minute, and at that point it's too late.  The bad guy's got your credit card information.



ALEX:  Yeah.  And there's not really any strong solution other than changing the way this all works.



STEVE:  Yes, that's why...



ALEX:  Like there's nothing someone could do tomorrow; there's nothing I can do tomorrow.  It is simply - now, is this once again a - it's either fixing that or more of these 'Net applications.  I mean, I know one thing that's interesting with my iPhone is that I prefer - I'm finding, I came to the conclusion, I realized earlier this week that I had 360 applications which somehow I had accumulated on my iPhone.  And...



STEVE:  You and Leo.



ALEX:  Yeah, I just - people send me stuff, and I go, oh, yeah, yeah, yeah, I'll buy it; you know?  And it's 99 cents, you know, it's less than a coffee.  So but what I end up with is all these applications.  And I'd rather be [indiscernible] Bank of America.  And it's not, for me it hasn't been a secure issue - until now - but it's been mostly a - it's just more convenient.  The interface is designed for the way that I want to interact.  It's designed for what I want to do, and it's faster.  But now I think that I'm going to be using my Bank of America iPhone app more often than ever going up to my website.



STEVE:  Yeah.  I think that's, I mean, I think that's an extremely good point.  The downside of the browser being non-trustworthy is that it might force a proliferation of individual applications.  And none of us want - I hate installing applications on my machine because they're just, you know, it's one more opportunity for something to go wrong, library collisions, and my add/remove list ends up being so long it takes, like, a half an hour to populate it when I bring up Add/Remove Programs because there's just so much junk on my machine.  I love the idea of being able to use a web browser as sort of a universal generic interface to web stuff.  And what we've got to do is fix this fundamentally broken model of web browser security.  It is just - it is not correct right now.  It is not something we can trust.



ALEX:  Right.  And, because, I mean, if this doesn't get fixed quickly, it gets to a point where no one can trust eCommerce on the web.  If people and when people start to exploit this, this is going to become something that takes away that basic trust.  It's like walking into a bank and not knowing who you can talk to.



STEVE:  Exactly.



ALEX:  That is truly frightening.



STEVE:  So when you're using GRC and my eCommerce system, make sure you've got a secure page because I do bring up security prior to ever asking for any information.  So it's easy to verify that you're getting a secure page.  If you've got - and if you're getting a secure page, then the buttons on that secure page cannot have been modified because nobody is able to intercept that.  So if you're using an eCommerce system like mine, where the form you're filling out is SSL secured, then everything that follows on from that is also going to be wrapped in the SSL security because all of the Submit buttons will still be secure because no one could have changed them.  The vulnerability is using a site that doesn't put you into SSL first because then the buttons that you're using to submit could have had that edited out.  And that's the problem.  There's, I mean it would be...



ALEX:  When I log in to Bank of America, actually, I have two logins.  I have my initial login and a second login.  Is that part of managing that?  Or does that matter?



STEVE:  The problem is...



ALEX:  It's already cut its way through.  It doesn't matter at that point.



STEVE:  Exactly.  If the first thing you do is, on a page, if you're ever being asked for information on a page that isn't already SSL, that's the vulnerability.  So any form you get, when you're first being asked to log in, if you insist that that is SSL encrypted, then you know it could not have been edited for this kind of exploit.  Unfortunately, so many sites don't do that.  We're just - we're taking for granted that the button will be SSL when we click on it.



ALEX:  Is the only answer, I mean, in the short term for a user is to try to force an https connection?



STEVE:  Yes.



ALEX:  So at least go up there, when you're going to Amazon or when you're going to Gmail or going - whatever it is, at least try to type that in, rather than just http?



STEVE:  Yes.  And in fact, so Moxie's point was that we generally allow the web server at the other end to decide when we're going to get security and when we're not.  And so we trust them.  So most people really aren't watching whether they're secure or not.  And the problem, of course, is that unless you are vigilant, then it's easy to fill out a form, assuming that the submission of it will be secure.  So exactly as you say, what you want to do is make sure that the form you're filling out came to you over SSL, meaning that the URL you're looking at up in the browser's bar is https, and the browser's real security indicator, not little, like, padlock in the URL which, you know, Moxie cleverly figured he could use the favicon in order to change that.  But you want the actual padlock to say, yeah, this is a secure page where you're putting your information in.



ALEX:  Before you start typing.



STEVE:  Before you, exactly, before you start typing.  But that's a lot to ask from my mother.



ALEX:  Well, and that's the whole thing.  I mean, like anything else, a lot of these types of processes is kind of like, you know, the cheetah isn't looking for the fastest wildebeest, it's looking for the slowest one [laughter].



STEVE:  Yes, that's a very good point.



ALEX:  Yeah, so that's who these guys are usually catching.  It's not us, you know, in this show, unless we, you know, it's our family that isn't paying as much attention.



STEVE:  Yup.  So the takeaway for our listeners and everybody else is make sure the form you're filling out is secure.  If it's not, exactly as you said, Alex, try to make it secure.  Try to go up and put an "s" in that http to see if you can get it to be secure because, if not, you don't know where your data is going when you click the Submit button.



ALEX:  Wow.  That's both something that is important for all of us to hear, but something that I don't know if I really wanted to hear.  I kind of...



STEVE:  It's sobering, yeah.



ALEX:  Very sobering.



STEVE:  It really is.



ALEX:  I'm going to change the way I - I mean, because a lot of times I'll tell people, you know, people ask if you're going to use a credit card online, and I always think that the credit card is more secure.  Up until today, I thought it more secure for me to give it to you online than to call somebody.  I always worry about, you know, you talk on the phone, I don't know what that person's writing it down on.  I don't know where it's going.  I don't know what's going on on the phone line.  So I always thought that online was actually more secure than even giving my credit card to a waiter...



STEVE:  Exactly, paying for a meal, exactly.  There goes my credit card.  It wandered off with someone who doesn't speak English very well.  So it's like, okay, well, I hope this works.



ALEX:  Right.  Could you get into a situation where you had an agreement, I mean, this is kind of where maybe Google Checkout or something like that, where I get into a situation where I put that in once, and once I'm in that, and not go through all the security stuff, and then I'm not actually putting my information in again, you know, when I go to different websites.  You know, when I'm going to different eCommerce websites.



STEVE:  Well, the problem is whatever it is the user is doing to authenticate themselves.



ALEX:  To validate, yeah.



STEVE:  Yeah.  Now, one good thing is that we've also talked about any kind of one-time password system.  For example, PayPal has the one-time, like the little eInk credit cards where you log in and you are asked for a six-digit code.  Only you know the six-digit code because you are in physical possession of the card.  Well, what that does is, it means that your log-in credentials cannot be used later, but they can be used then.



And so we talked about this last week, there actually have been attacks now, and I'm going to cover this in more detail in a future Security Now! episode because I've tracked down the trojan that's able to do this.  There is the ability now to ride on your login session and do other banking work behind your back without you knowing it.  So that even defeats the one-time password approach because bad stuff can happen while you're doing good stuff in the foreground, without your knowledge.



So, yeah, I mean, but to answer your broader question, whatever you do to authenticate, you may not be - if you don't have to give your credit card information again because the website stored it, well, that's good.  But if you just log in with your username and password, then somebody else can, too.  So there's nothing to prevent somebody else from impersonating whatever it was you just did that authenticated yourself, assuming that you do that again to reauthenticate yourself.  Somebody else who captured that information can do the same thing.  And we saw from those statistics that Moxie's little spy that ran for 24 hours sucked in 16 credit card numbers with all of the accoutrements, everything necessary to charge against people's credit cards.  It's really frightening.



ALEX:  Terrifying.  I mean, I'm definitely going to be - I know that the rest of the week I'm going to be forcing https connections and just seeing where I - what I can trust.



STEVE:  Yeah, it'll be interesting to just do the experiment; right.



ALEX:  It seems like for us, at least, in the know now, thanks to you, that what there is to do is to start pressuring, for me, like Amazon and the handful, if I can't get an https, is to make requests of that and to let people know that we're not going to - I think as this news gets out I think you end up with people not using sites.  I think it seems like a natural reaction.  These sites are going to have to allow, at least allow one, if not force it, allow an https.  So for those of us who know what we're doing, we can force that issue.



STEVE:  Well, and to deal with the problem of vigilance, I mean, that's really, I mean, it comes down to the user being responsible, at this point.  And I'd really like to offload that to the browser.  So that if there was a way, like for example imagine a Firefox add-in which, if it was possible for sites that we use a lot, like PayPal, Amazon, Facebook, Twitter and so forth, if it's possible for them to accept https for everything, then we want to tell the browser, good.  Make every URL I submit to this site, please add the "s" for me.  Make it secure so I don't have to worry about it constantly any longer.  Because it's so easy.  I mean, you're distracted.  You're in a hurry.  And all it takes is one situation where you slip up, and your information has escaped. 



ALEX:  Wow, yeah.  And once it's out of the bag, it's out of the bag.  And for a lot of us, if people aren't doing - if they're using the same password too many times, or using all those other things, it can not just be your credit card or your access to Amazon.  For a lot of people who get lazy and don't want to try to remember a long string or don't want to try to remember new passwords, this could be opening up everything.



STEVE:  Well, and it allows you to be impersonated.  So imagine, for example, that as social networking grows, many people are putting a whole bunch of importance behind their profile on Facebook.  So this allows somebody else to log in as you and impersonate you in a social networking environment and do lord knows what kind of damage.



ALEX:  Right.  Yeah, when I try to do Amazon.com, I get the - this connection is untrusted.  When I do the https.  So it's frightening.



STEVE:  Yup.



ALEX:  Well, thank you very much, Steve.  I think I can thank you.



STEVE:  Sorry to ruin your day, Alex.



ALEX:  Thank you for the sobering information.  I'm not sure, I mean, I was going to buy a bunch of stuff.  Now I think I'm just going to...



STEVE:  Yeah.  It's possible to be safe, like I said, like if you - my eCommerce site insists on giving you a secure form.  But if the user sees that the form they're filling out is secure, you're safe.  Otherwise you don't know what, you don't know where that page came from because it's only SSL that protects you against spoofing.  So somebody who inserts themselves in the middle anywhere, may not even just in your own WiFi caf, but in a hotel scenario, or maybe somebody spliced into the line downstream of the ISP.  I mean, the potential for exploitation is huge.



ALEX:  So can people find more information at GRC.com?  Do you have anything up there, or...



STEVE:  Well, we have the Security Now! - GRC.com/securitynow is where this podcast is.  We do a 16KB version, as Leo says, for the bandwidth impaired.  I also have Elaine doing transcripts every week, our illustrious transcriber.  So she will be transcribing this with shaking hands.



ALEX:  Yeah, exactly.



STEVE:  We'll get this posted.  And next week is going to be our Q&A episode.  So I want to encourage people by all means, even responding to this podcast specifically if they're interested, to send their feedback to GRC.com/feedback.  I'll read their mail, and we'll address their questions next week.



ALEX:  Thanks, Steve.  Steve Gibson, once again, GRC.com.  And thank you all for watching Security Now!.



STEVE:  Thanks, Alex.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#218

DATE:		October 15, 2009

TITLE:		Listener Feedback #77

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-218.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



This is Security Now! with Steve Gibson, Episode 218 for October 15, 2009:  Q&A #77.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



It's time for Security Now!, the show that covers all things security oriented, like your privacy, browsers, hackers, bad guys.  Steve Gibson's the man in the know, the head at the Gibson Research Corporation, GRC.com, creator of SpinRite, discoverer of spyware, and our esteemed host for the last four years plus.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Sorry I wasn't here last week.  I hear it was a scary show.



STEVE:  Well, we did.  We frightened a lot of people.  Not, you know, not, I think, unduly.  We had twice the normal amount of feedback from people who wanted basically clarification of different types about specifics of what we discussed last week.  So today's Q&A, we have a few random things.  But largely I did, because we got, like, literally twice as many submissions of questions, I wanted to spend some more time to clarify some of the finer points of this.  And, you know, unfortunately you missed last week's episode.  So this will give us a chance to catch you up on this because it's pretty significant.  And I think we're going to be touching on this aspect of what I called last week "The Broken Browser Model" somewhat here and there in the future because it is, it's a fundamental aspect of the way we're using the Internet today, which as we'll see is not very secure.



So we've got a bunch of security news.  Get this.  The largest Microsoft second Tuesday of the month update ever.  There's never been more things fixed at once.  And the good news is we've talked about several of these things that have been fixed previously, waiting for Microsoft to catch up.  And this is their catch-up Tuesday.  So lots of things caught up.  Some other random security news.  A really sort of interesting fun SpinRite story.  And then some great questions that'll help to clarify some of what we discussed last week.



LEO:  It's kind of ironic that we all think that things are getting better and better, and you should need fewer and fewer patches, and yet there's more and more patches.



STEVE:  Well, remember...



LEO:  Seems like it's the wrong direction.



STEVE:  Well, things are getting more complicated.  And as we've often said, complexity is the enemy of security because the more complex something is - I think, you know, it seems natural that things are getting more complicated.  And techies enjoy complexity, I think, for its own sake.  So you just, as things get more complicated, there's more opportunity for mistakes.  And the security always is the weakest link in the chain.  Well, the more links you have in the chain, the longer the chain is, the more opportunity there is for someone to miss a weak link.  And then of course the bad guys spend all their time looking for the weak links.  We just hope the chain holds together.  So it really, it is, in many ways security is a much tougher battle than the way people use software, which is, oh, it's working fine.  That's all I need is it to be working.  Well, no.  With security it needs to be working perfectly.  And I mean with a capital "P."



LEO:  Yeah, yeah.  Do you think Windows 7, which is due out in a week, will change everything?



STEVE:  No.  It's new.  It's bad.  New is bad.



LEO:  [Laughing] I love - you're so - you're so conservative.  It's new.  I don't like it.



STEVE:  Look at the evidence.  XP was - remember Ballmer was jumping around, saying it was going to be the most secure Windows that had ever been made.  And it turned out it was the biggest disaster they'd ever had.



LEO:  True, true.



STEVE:  It's new.



LEO:  True, true.



STEVE:  It's new, it's bad.



LEO:  Well, we've got questions.  You've got answers.  So what's the latest?  Do you want to do security news?



STEVE:  Yeah.  Well, we've got some.  As I said at the top of the show, the big news of the week is the biggest ever mega monthly update from Microsoft.  We talked about the SMB v2 vulnerability a couple weeks ago, which was a concern for the newer Windows clients which support v2 of SMB.  There was the possibility of remote code execution.  That was fixed.  They fixed multiple vulnerabilities, critical vulnerabilities in the Windows Media Runtime, also in Windows Media Player.  IE got four critical vulnerabilities fixed.



LEO:  Geez.



STEVE:  Oh, we're just warming up here.  The ActiveX Killbits was updated.  Remember that that's the thing which prevents ActiveX controls from being instantiated or invoked by Internet Explorer.  So those were updated so that fewer things on the system could be misused.  They finally fixed this ATL, the Active Template Library problem.  That was a bug in their library which meant that all programmers around who were using the ATL system to create ActiveX controls were inadvertently creating vulnerable ActiveX controls.  So that's been fixed so that anyone who now compiles using the Active Template Library, which is one of the tools Microsoft provides for creating ActiveX controls, will no longer be creating inherently exploitable and commonly exploitable, that is, with an exploit that everyone knows about, ActiveX control.  So that was finally fixed.



Multiple vulnerabilities were fixed in the .NET system which is becoming an increasingly popular programming model for using Windows.  Multiple GDI+ vulnerabilities, which is the enhanced Graphics Device Interface library used by pretty much everything.  We talked a few weeks ago about the problem with Microsoft's web browser, IIS, and its FTP server, warning any of our listeners who did have a publicly exposed FTP service running on IIS to think twice about that.  That got fixed.  There was a vulnerability in their indexing service that they fixed, Windows kernel elevation service that they fixed.



And finally the biggie of the month, that we've been waiting for, which we've talked about several times now, is they had the problem with null bytes embedded in certificates which allowed spoofing of SSL certificates.  It turns out that another little bit of news is that this was shown by our friend Moxie Marlinspike, who brought to the world's attention the fact that you could create a certificate with the name www.paypal.com and a null character, that is, a zero, and other web domain like mymachine.insecuresite.com.  You could, because the certificate was really being issued to insecuresite.com, you could get a certificate authority to run through the automated process to give you such a certificate.



The problem was that, if you used that certificate, the web browsers would only parse the name up to the null character because the so-called null-terminated strings is the modern way of storing strings of characters.  So we talked about this months ago where the original Pascal means for storing a string was for the first byte to be the number of characters in the string, that is, the length of the string, followed by those characters.  The problem was that allocating a byte for that meant that strings could never be longer than 255 characters, which is the maximum value you could store in a byte.  So that approach was abandoned in favor of so-called null-terminated strings.



But the problem with that is it's one of the sources of major vulnerabilities in buffer overruns and so forth that are assuming, they're, like, scanning a string, waiting for the null.  But if a bad guy can put in their own code that doesn't contain any nulls and then, like, store that where a string is expected, that's the source of many of these problems.  So Moxie publicized a similar vulnerability.



Well, Microsoft finally fixed it with the update two days ago, on the second Tuesday of the month, which was two days prior to this podcast on Thursday.  And until then IE and the web-based version of Safari and Chrome, Google's Chrome browser, all which used and were dependent upon this Crypto API, which finally got fixed - and this has taken a long time.  This vulnerability's been out there and known for a long time.  Firefox fixed it promptly themselves.  So even Firefox on Windows had not been vulnerable.  Finally now nothing is.



But in an interesting related little tidbit, PayPal suspended Moxie Marlinspike's donation account, apparently out of some fit of pique with him over having created this certificate.  What happened was that somebody else created one which was then made freely available on the Internet, posted on various sites and in various security blogs, as a further demonstration.  Moxie in his presentation showed this as a proof of concept but, being responsible, did not use it to create a certificate that was then made public.  Somebody else did.  And PayPal suspended Moxie's account because he had on his page a donation to support the use of his SSL sniff utility.  And PayPal said, well, we don't encourage or, you know, it's a breach of our terms of service to collect money to support a program being used to deliberately promote insecurity.  So that was a little disappointing.  I don't know how long that's going to stay the case.  But that's something I just picked up on a couple days ago.



It is time for people to check the currency of their Adobe Acrobat Reader and Acrobat program.  There are targeted attacks now against - that are occurring for people who open a PDF file using Acrobat v9.1.3.  Apparently 9.2 was supposed to be made available.  And I did check - I'm still using 8, so I never was under the problem with this vulnerability.  But anyone using 9, supposedly Adobe did their monthly update, also on the second Tuesday of the month - I'm sorry, their quarterly update.  In Adobe's case it's a quarterly update, not monthly.  Although, as we've already seen, they've not been holding to that at all because they've had so many problems that they've had to be addressing.



LEO:  They had 29 fixes yesterday [laughing].



STEVE:  Yes.



LEO:  Well, that just shows you, if you hold onto them long enough, you can really build up quite a backlog.



STEVE:  Which is why it's just nuts, this idea of doing this every three months.  It's like, what are you guys thinking?  And they said in their original policy that, well, we want to let people know when we're going to be doing updates.  It's like, okay, well, as we know, several have been so bad they haven't been able to wait.  And then they have like this huge batch that they fix at one time.



And the problem is, when we say "targeted attacks," what that means is that there's a known problem.  And rather than just in the wild problems, specific people are being fed malicious PDFs.  Like executives in corporations or in banking firms are being targeted with known email addresses and letters written specifically to induce them, sort of based on knowing who they are, to open this PDF.  And when that happens, malware gets installed.  So, I mean, it's interesting that, you know, here's Adobe being reluctant and slow to fix these problems, yet they're a vector of really significant security threat.  So...



LEO:  And everybody has it.



STEVE:  Yes, exactly.



LEO:  On Windows, anyway.  You don't need it on the Mac.  But on Windows everyone does.



STEVE:  Exactly.  It's a very, very common application, in order to be able to read PDFs.  Comcast has started doing something interesting.  They've opened a pilot test in Denver.  And I'm of two minds about this.  They call it Comcast Constant Guard.  And what they're doing is doing 24/7 traffic analysis monitoring of...



LEO:  To protect you.  It's to protect you.



STEVE:  ...of their subscribers.  And...



LEO:  For your own good.



STEVE:  And then doing a browser intercept, which is I think the controversial thing.



LEO:  Oh, dear.



STEVE:  Now, they say that they've been doing traffic monitoring and notifying their customers, their ISP subscribers, by phone for the last two years.  Well, I think that's preferable because - and apparently they report that their subscribers to Comcast love being notified that they've got malware on their computer.  So you get a call, a phone call from a Comcast person saying hi, this is your cable provider.  We wanted to let you know that your computer is evidencing a traffic pattern on the Internet that gives us strong suspicions, strong reason to believe that it's infected with something.  So go to the following URL, and you can get instructions for free how to remove what it is that we believe you've been infected with.



What they're now doing is, they say because of the extreme popularity of this - of course it's expensive for them to have their people phoning their subscribers - they're going to automate this with a browser intercept.  Which, eh, is a mixed blessing.  It means that when you are surfing somewhere, some server at Adobe that is - I'm sorry, not at Adobe, at Comcast.  Some server at Comcast, because they're your ISP, they are in your traffic stream, your traffic is transiting across their equipment, they will give you a - presumably return a redirect or just give your browser content different than what it's expecting, which is an intercept page notifying you that you've got malware on your computer, they believe, that the traffic analysis that their systems have generated lead them to believe there's some bad stuff on your computer.  Click the following link to go and take care of it.  And apparently you can push past that if you choose not to, that is, it's not a you can't do anything on the Internet until you fix it.  But it is intercepting your use of the Internet.



LEO:  That's what worries me.  Because, you know, Comcast was before using that software from Canada to watch for BitTorrent.  And I worry that this is a backdoor way to kind of, we're protecting you, but also we'd like to see what else you're doing online.



STEVE:  Well, yes.  And it's funny because this takes us - it's a perfect segue into the next thing I wanted to mention, which is that an Australian ISP, iiNet, has been taken to court by a consortium of movie companies who have sued this ISP for not disconnecting subscribers based on the movie companies' say-so.  There is a so-called "safe harbor provision" in Australia that protects ISPs as long as they take "reasonable" actions to prevent copyright infringement.  Well, I mean, this is one of the problems with laws that are written broadly, you know, what is "reasonable"?  Now we have to go to court to have an interpretation of what that means.



The Australian ISP, iiNet, is saying, look, an allegation of infringement is different from a proof of infringement.  They're saying to the movie companies, you take these infringing subscribers of ours to court, prove that they are infringing your copyrights, and we'd be delighted to disconnect them.  We'll jump up and down to disconnect them.  But we're not going to disconnect anybody based on your allegation that they're infringing, just because you say so.  So it's an interesting question which - and it'll be interesting to see how the court decides this because, again, this is - we've already covered in the past this general move by, in the U.S. case, the MPAA that has said as a policy they are no longer going to go directly after the end-user infringers.  Instead they're going to work with ISPs to somehow discipline these guys.  And so here we have a case where this is not working out so well, where the ISP is saying we need a reason, we need good cause to disconnect users.  And in our opinion the movie industry's statement that the following users have copy-protected content and are distributing it is insufficient grounds.  If you prove it, that's fine.  Not if you just claim it.



LEO:  Interesting.  I mean, we have the same kind of a takedown rule in the states, of course.  But generally what happens is they write a letter to the ISP saying, you know, this guy is stealing from us.  And the ISP then warns the person - I've seen this happen time and time again - saying stop stealing.



STEVE:  Stop doing it.



LEO:  And usually they give them a few strikes.



STEVE:  Yes.



LEO:  So that's interesting.  I'll watch this with interest.



STEVE:  Yeah.  Be interesting to see how it goes.  I have two little bits of errata.  One is that a couple users wrote in to say they cringe every time they hear me say Mac OS X.  And I have to say...



LEO:  Notice I don't correct you on that.



STEVE:  I noticed that.  And you always say OS 10.  And I thought, well, okay.  Finally I'm going to get a clue, here.  OS 10, period.  So I've seen the light.



LEO:  You know why I don't correct you?  This is actually something newspapers and other journalistic endeavors always have to deal with, is do you go with the commercial typography?  Remember CNET was C, a bar, Net capitalized, lowercase and stuff.



STEVE:  And how, yeah, how do you pronounce that?



LEO:  Well, and it's not even - in a newspaper it's not an issue of pronunciation.  It's an issue of - here's a really good one.  Do you put the exclamation mark in Yahoo!?



STEVE:  Right.



LEO:  Many journalists believe that's commercial speech, and you just put Yahoo without an exclamation mark.  But Yahoo! would say, no, no, that's our trademark is Yahoo exclamation mark.  We want the full thing.  And so I think - I don't - look, it reads Mac OS X.  It's doing Apple's - it's carrying water for Apple to say, no, no, that's 10.  You read it any way you want.  It's not, you know, we're not here to advertise for Apple.  So it's an "X" on the page.  You can say "X."  It's not incorrect.



STEVE:  And so someone said, well, clearly when it was OS 9, it was OS 9.  Now, if they went to XI, I'm not going to go OS XI every time.  I would probably say, I would get a clue, say okay, OS 11.  But anyway, so...



LEO:  Yeah, you know, a lot of people say OS X.  I don't have any problem with you doing that or I would have said something.



STEVE:  Well, thank you, Leo.  I'm going to be going - I'm going to try to correct myself and say OS 10 from now on.  Even though somehow, I mean, even now knowing it, I just look at it, and I want to say OS X.  So...



LEO:  It's an X.



STEVE:  I've got to shake the habit.  I discovered something interesting the other day.  Some stuff wasn't working that I expected to have working.  And I discovered that installing Microsoft Security Essentials replaced my hosts.ini file.



LEO:  [Gasping] Interesting.



STEVE:  Yes.  And not surprising, but I thought I would just bring that to the attention of our listeners.  We've talked often about the hosts, how the hosts file can be used to redirect DNS lookup.  And there are people that maintain hosts files that you can download.  It's a very handy way of just ever keeping your computer from asking for a specific domain name.  You're able to assign it to 127.0.0.1 or 0000, whatever you want, an IP that doesn't go anywhere, essentially.  And your computer by convention, this has been the case ever since UNIX first got put on the Internet, the hosts file is checked for domain names prior to any DNS lookups being made.



So I had a bunch of things.  In this case some of them were privacy and security related, but also I was just sort of using it as a poor man's DNS server to redirect a bunch of strange domains that I use internally.  And that broke.  And I was scratching my head for a long time until I remembered, wait a minute.  Didn't I put this in the hosts file?  And I looked there, and it had been - mine had been renamed to .bak.  And the date of the new one was the date I installed Microsoft Security Essentials.  And Microsoft Security Essentials had a note I thought was very nice, they put a note in there to say that that's where this hosts file came from.  So it wasn't at all a mystery to me.  It told me.  But I thought, okay, well, it would have been a little nicer if they'd made a popup or something that said, hey, we noticed you've customized your hosts file.



Part of installing Security Essentials, because this could be maliciously changed rather than deliberately changed by you - and this of course is why they do it.  Malware has been known to make changes to hosts files.  And so Microsoft is...



LEO:  That's true, that's true.



STEVE:  ...putting it back to something - basically they nulled it out.  They removed - there were no fancy changes they made.  They just put it back to the original one, which does nothing.  It's there, but it's got no entries in it, essentially, just a bunch of commented lines.  So...



LEO:  Do they make it read-only?



STEVE:  Good question.



LEO:  I guess that'd be easy for malware to change, though.



STEVE:  Mine was.  So, yeah, I mean, that wouldn't slow down malware very much.  So, yeah.  So anyway, I got a kick out of that.  I thought I'd just bring it up to our listeners' attention, for anybody else who was using a hosts file and installed Microsoft Security Essentials.  And I got a fun SpinRite note.  The subject line, this was sent through our sales email from an Andy Kinsey in Haddington, Scotland, UK.  And he said, "SpinRite saves SALON."  And he had "salon" all in capitals.  And I'm thinking, well, I don't think he means the magazine or the website or anything.  But it caused me to read it.



He said, "Hi, Steve.  I want to thank you so much for SpinRite and what it did over last night.  Friday was my day off.  I have a job, and I freelance technical and web design.  Anyway, I was called at 9:00 a.m." - apparently on his day off - "by a client whose computer wouldn't boot.  The machine was the till," as he put it, "was the till and had three years of accounts on it.  For some reason my web design client hadn't externalized backups nor looked after the machine at all."  So I think what he's saying is that his responsibility was not this salon's front counter cash register till, but they called him because he was a technical guy that did their web design.



So he said, "When I got there, the hard drive had no signs of life.  I took it out and attempted to manually power it via my cables and USB devices.  No win.  I was at a loss and began the long, laborious process of indexing the backups and attempting some kind of recovery as there was no access to the hard drive."  So I guess they had non-recent backups or something.  He said, "Through USB in my other machine, it was visible, but no access was given, nor any indication of its size.  It was only some hours later I had the brain wave," as he put it, "SpinRite could help.  So I went to your site, bought the software, put it on my USB, and stuck it in the machine with its dead hard drive.  I ran SpinRite.  Some 18 hours later SpinRite was complete.  I removed my USB and waited in anticipation.  Two minutes later I booted the machine with bated breath.  It worked.  I was in.  I immediately took a copy of all the data and backups to my external USB drive.  I rebooted the machine again, and it was bricked.  I knew it would be.  I've never seen a hard drive in such state."



So basically SpinRite brought it back, literally, for its last gasp.  And he did the right thing because this drive was in such bad shape, as he said, he immediately pulled the data off of it and got everything.  He said, "Anyway, we managed to find another system and reinstall everything, including all the data.  It took another day to get it all sorted, so two days of work.  Whilst this was going on, the manager was calling around, trying to get another system.  The cheapest was 5,000 pounds per year, money this salon can't afford.  They border on extinction every day, never mind having to find 5K.  Thanks solely to spending $89 for SpinRite, the salon was able to use what it had and is still in business.  Thank you, Steve.  You saved the salon."



LEO:  Wow.  Now maybe they'll do better backups.



STEVE:  That was cool.  And I think they probably got a lesson.  They probably learned a lesson in the process.



LEO:  SpinRite is probably that, you know, it's that little window of opportunity between success and failure.  And it probably has taught a lot of people a lot of lessons.



STEVE:  Yeah, yeah.  I mean, I think you're right.  It's like just if I could only have my drive back one last time, I promise I will be good from now on.



LEO:  It's the answer to that prayer, please, just one more time.



STEVE:  It's a little bit of a time machine.  Just, you know, it's just turn the clock back one day.  I just need yesterday again.



LEO:  Leo said I should back up.  All right.  Let's - we've got questions for you.



STEVE:  Yes, we do.



LEO:  And we can get right to them, starting with Andrew Branagan, in Carteret, New Jersey.  This has to do with what we were talking about earlier, Adobe's Patch Tuesday.  He says it's a Patch Tuesday headache:  Good Wednesday morning, Steve.  We record the show on Wednesday, so that's apt.  Just wanted to point out that, even though Adobe did release their quarterly update, they're not making it easy to distribute.  They're dragging their feet on releasing an .msi - you know, those are the Windows installer packages for version 9.2.  When you go to their site and enter your information to get a distributable copy of the software, they send you a link which contains version 9.0.  Just thought you might want to incorporate this into the security news today.  Looking forward to the show.  Nice.  Well, maybe they'll fix that by the time we get this on the air.



STEVE:  We can hope so.  But I did want to give a heads-up to our users that of course there's the sort of the slipstream automatic update approach that you get when you use your Reader or Acrobat and tell it to look for updates.  That's just the update that Adobe normally provides.  There is, however, for people who want a so-called redistributable update, where you get the actual file itself in, as you said, an .msi format, which you can then yourself individually run on different machines.  It's probably just an oversight.  Maybe - I mentioned that it was Wednesday morning because, as of our recording of this, 24 hours from the time Adobe released this, it's still not fixed.  So I just wanted to point out to our listeners to make sure, if you're using that, that you're getting the 9.2 fix from Adobe and not this older, retro version that you definitely don't want.



LEO:  Question 2 and Question 3 in one big ball.  Starting with Patrick McAuley in Guelph - near Toronto - Canada.  He has a man-in-the-middle question for you, Steve:  I'm not really a techie, but I've been listening to Security Now! for a couple of years now.  I've learned a lot about keeping myself safe online.  Last week's show with Alex subbing for Leo was a great one, but a bit scary as you revealed how someone can get between me and an apparently secure login screen to capture IDs, passwords, et cetera.  Were you talking about click fraud?



STEVE:  Nope.



LEO:  That's another one.



STEVE:  We'll get through this in a second, yeah.



LEO:  One thing that was not clear to me was whether this loophole only occurs if the man in the middle has somehow gotten access to my LAN, or if it's a danger on any Internet connection.  Right now I'm on your site from my home computer, connected to my router by cable.  I don't think there's any way someone can get access to this LAN.  So am I safe?  And further, if I use my notebook to connect to my router wirelessly, using WPA encryption, am I safe there?



And Ted Lind in Woodstock, Illinois had a similar broken SSL question:  I want to make sure I understood you correctly, Steve.  The man-in-the-middle attack you described requires the bad guy to be on your local area network.  If I'm using SSL to do a bank transaction, I'm connected to my private network using WPA2 and one of your really long passwords.  It's my understanding that this is still secure because the man in the middle cannot get through the router.  Both my wired and wireless computers should not be vulnerable to this attack on my home network.  Am I right?  Also if I'm on a public network, but the first thing I do is set up a connection with Hotspot VPN, is this also a secure way to do an SSL transaction?  Love TWiT; love Security Now!.  My car radio is constantly tuned to one of Leo's podcasts.  Also a SpinRite owner.  Thank you, Ted.  So this I want to hear because I didn't hear everything you talked about on the episode.  Obviously I'm going to have to go back and listen to it.



STEVE:  It was a good one.



LEO:  Yeah.



STEVE:  So here's the - I've been thinking about it in the intervening week.  And I think I have a simpler way of describing the problem.  The example I gave was a specific instance using ARP spoofing, which we've talked about in the past, in any local area network scenario, to allow someone to intercept traffic to users of the network, thus creating the man in the middle.  The focus of the podcast, though, which we titled "The Badly Broken Browser Model," was it noticed that, if you were logging on from a nonsecure page, that you could not trust the form that you were using to accept username and password because, if the page was nonsecured, then a man in the middle could have intercepted the page and, for example, taken the "s" off the https on the form's Submit button so that the submission would not be secure, which would allow that man in the middle to intercept and acquire the login data or whatever it was you were submitting to the site that you were connecting to.  So the idea being the broken thing about the browser model is that there's nothing that protects the content of the pages we're receiving from a remote server from being edited on the fly unless it's secure, unless the content that's delivered is secure.



But we've talked about how pages you submit, pages that you use to provide information don't really have to be secure.  It's your clicking of the button, it's the submission of the information that needs to be secure.  However, as we looked at last week, that's not the case if you have somebody clever in the middle.  And what Moxie brought up and made very clear during his Black Hat presentation was that somebody in the middle could deliberately edit pages which you were receiving from a secure site to quietly drop the security.



And so the example I gave was in a public, for example, in a public WiFi scenario, in a hotspot, where you were inherently using an open LAN, I mean, it's a LAN, an Ethernet LAN, which is very sniffable and where ARP spoofing can be used to insert a man in the middle.  And last week we described the statistics of the number of secure logons, PayPal logons, credit card numbers, very common logons that he acquired doing this during a 24-hour sniffing period.  So it's extremely effective.  So now to answer both of these listeners' questions and many similar questions that people submitted, any man in the middle, that is, a person at any point between you and the website you are connected to, has the ability to do this.



So the one example I gave was a LAN scenario in WiFi.  These guys were asking about what about their personal local area networks.  Well, the point to remember is that anyone anywhere between you and the remote server.  So certainly the location of greatest vulnerability is probably the network closest to you.  But in theory somebody who had some malicious intent anywhere in the traffic pattern, upstream of the ISP, downstream of the ISP, at any of the routers along the way, anywhere in the stream, someone could insert themselves and perform this kind of filtering.



So the thing that SSL connections are designed to achieve is end-to-end, that is, endpoint-to-endpoint privacy and authentication.  And so the beauty of SSL is it does protect you from man-in-the-middle attacks anywhere, anywhere between those two endpoints.  You need to make sure that you actually have connected to the remote server.  We talked earlier in this podcast about that null, the null character in the middle of a deliberately malicious certificate that could spoof you so you thought you were at PayPal, but you were actually at another site, but your browser and the system would only see www.paypal.com.  So there was no way, looking at that, for you to tell that that wasn't where you were.  Microsoft fixed that with day before yesterday's mega security update.  So that's a good thing.



That's been a glaring hole.  But the problem is that any time you receive a page from a remote server which is not over SSL, you don't know that it wasn't modified.  That's the focus.  Anytime you receive a page that is not over SSL, a man in the middle occurring anywhere could have changed it so that you cannot rely on it.  Now, several people...



LEO:  But that almost seems trivial to point out.



STEVE:  Well, it is except that...



LEO:  I mean, of course my Internet service provider and every server along the way can modify that page.



STEVE:  Okay.  And so of course the point is that, if someone did so, you would have no way of knowing that, when you submit your username and password or your credit card information, that the button you're pressing is not SSL, or isn't SSL to some malicious party.  And so that's really, I mean, that's what, at its core, that's what we made very clear last week is that you have to, in order to trust form-based submissions, the form itself has to be delivered to you over an SSL connection.  It's really not sufficient to trust that the button will be SSL because, if the form itself is not secured, then anyone could have changed it.  And so what we were making very clear is that those changes completely bust the security model.  Basically people are using browsers.  We've adopted a model which sort of works, but which is really not secure.



LEO:  Okay.  It doesn't, I have to say, that doesn't terrify me.  But if it terrifies you, okay.  It's good to be aware.  Question 3, Jean-Matthieu Bourgeot in Tarare, France had an interesting idea for securing public WiFi hotspots.  He says:  Hi, Steve and Leo.  Listener from day one, love the show, been learning so much with you guys, blah bah blah.  Here's an idea for securing public WiFi hotspots that came to mind.  Not sure if it'd work.



On public WiFi hotspots, users obviously do not need to have their computers be able to directly talk to each other just as if they were on an office LAN.  Usually you're talking to the outside world, not to the guy sitting next to you.  The fact is that all the computers are on the same LAN, and therefore, as you just said, are prone to ARP spoofing or OS exploit attacks, et cetera.  If the WiFi hotspot's DHCP server would assign IP addresses belonging to different subnets - oh, this is interesting - to every new computer, so 192.168.0.10, then .1.10, then .2.10 and so on, would this - I don't know if that's a different subnet, though; is it?  Would this prevent many of the possible via-the-LAN attacks?  Also, this solution would be very cheap to implement by just changing the DHCP server's behavior.  What do you think?



STEVE:  Well, it was an interesting idea.  We're familiar with the idea that, for example, if you have a net mask - which the net mask is used to create subnets.  So a netmask of 255.255.255.0 would say that the network number is contained in the first three bytes, or first three groupings, and that the machine within the network is in the fourth one, the last one.  And so then the idea would be, if you were to assign each machine on the WiFi system its own subnet, so that they weren't - so that no two machines were on the same subnet, would that give you more security?  And the answer is, well, it would give you some little bit more security.  But it would not give you any protection from, like, from strong hacking.



The way any Ethernet works, Ethernet is addressed based on MAC addresses.  And the ARP table, as we did discuss last week because we did a little bit of review of how ARP spoofing works, the ARP table associates IPs to MAC addresses.  So that the packets which come into the gateway, for example, inbound to the hotspot, the ARP table in the gateway looks at the packet based on its IP addressing and sees which MAC address owns that IP on the LAN, and then the packet is routed based on the MAC address.



So the problem is that subnetting is sort of a - it's a logical addressing layer on top of the physical addressing layer, which is MAC-based.  But if you were doing any, for example, promiscuous sniffing, where you had a WiFi adapter, and they're readily purchasable, which allows you to sniff all the packets on the hotspot, it would see all the packets in all the subnets that were using that WiFi.  So it does not provide you any useful security.



LEO:  Damn.  Seemed like such a good idea.



STEVE:  It's a neat - it's a neat idea.



LEO:  Jason Learmouth in Sydney, Australia writes.  He's got some thoughts about the broken - I don't want to call it the broken browser model because I think that's confusing.  It's the broken browser paradigm.  Let's use that.



STEVE:  Okay.



LEO:  Because browser model means something else to programmers.  Steve and Leo, I listened with great interest to your discussions on the state of play with secure browser sessions and the session hijack trojan out there, stealing people's money.  Steve, you mentioned in one of your listener feedbacks that the authentication needs to be moved closer to the transaction.  While I agree this would fix the problem for now, I expect it would only be a matter of time before attackers moved closer to the transaction, as well.  Discrete applications were suggested as a way to offer a secure connection-based solution.  Steve correctly pointed  out we have enough stuff installed on our computers already.  The browser is very convenient.



So maybe - I think this is actually a good idea - the browser could run an application based on Java or some similar technology to provide the best of both worlds.  I've seen some SSL VPN providers - I think GoToMyPC does this, and GoToMeeting - download a Java app to create a tunnel to the network.  That's exactly how Citrix works.  I believe Google uses this type of technology in its Docs product, which offers very near real-time document collaboration.  There must be - I don't know if Google's doing that with Wave.  I don't think so.  There must be some two-way traffic there beyond just http.  They're using - actually they're using the Jabber protocol.



But anyway:  What about Jungle Disk?  It encrypts before sending data to the cloud through an SSL tunnel.  How does that avoid being vulnerable to attacks?  Or does it?  Could a site offer a local application to the user that would handle all the security, authentication, and encryption through its own persistent connection without requiring a local install?  Love the show, happy to hear my name on the show if you feel like reading this.  Thanks, Jason.



STEVE:  Well, that is, I think, as you say, Leo, it's a fundamentally good idea.



LEO:  Of course you have to trust Java.  But barring an exploit in Java.



STEVE:  Right.  Now, it is also essentially what we've been talking about with some level of disparagement about all this ActiveX stuff.  You know, ActiveX is an application which is transparently run by the browser.  Microsoft, recognizing the fundamental security problem with that, has in recent versions of IE, and Firefox does, too, warning users that this page wants to execute an ActiveX control, you know, do you want to proceed?



So I do think that the notion of using the browser to encapsulate an application which is provided to the user in a transparent way, which exists in sort of transient form on their machine, which they don't have to separately download and install and manage, which won't clutter up their Add/Remove Programs list with an infinite number of individual applications for everyone you want to have a secure transaction with, I think that makes a lot of sense.  And if the remote system then refused not to - if it refused to operate without its own dialogue with its own application, then it would in fact be able to create the kind of containment that we're looking for which is fundamentally more safe and secure than the transaction-based, sort of fundamentally dangerous model that we've so far been using with our browsers.  So, yeah, I think it's a good idea.



LEO:  Great.  Question 5, Dale Willer in Kansas City asks about ARP spoofing on a home network.  In Episode 217, the last episode, "The Broken Browser Model," it wasn't clear that the ARP spoofing attack, if the ARP spoofing attack and the scenario presented in that episode is a threat on a home LAN behind a router.  My first impression was it's only a threat at public hotspots such as airports, Starbucks, et cetera.  Later on I wasn't so sure.  Please clarify.  Also one way to protect against this at a public hotspot, always use your VPN if you have one; right?



STEVE:  Yeah.  I put this in here because I wanted to make sure as I was going through these that I didn't forget to mention that...



LEO:  Because we already answered the first part.



STEVE:  Exactly.  I wanted to make sure I didn't forget to mention, because many people asked this.  They were seeing the example I gave last week in a public setting and wondered about what's happening in a home setting.  So, I mean, ARP spoofing is much less likely in a LAN.  It's somewhat more possible in a wireless environment.  But it is definitely the case that, if you're using a VPN, or you somehow have a persistent SSL connection, which is what a VPN would provide, or which is what a custom app running in the browser would create, then you really have nothing to worry about because a good VPN and/or SSL technology provides authentication of the endpoint and privacy so that no one in the middle has any opportunity to do anything bad to you.  So the worst that ARP spoofing could do would be to keep you from getting a connection.  But it would not be able to allow someone to intercept what you're doing.



LEO:  Perfect.  John Clayton in Billings, Montana reports that Astaro has upgraded their free home use licenses.  We love Astaro.  We talk about them all the time.  Hi, Steve and Leo.  Know that Astaro is one of our longest and most loyal advertisers on the show and thought your listeners might be interested in this news.  For the longest time I had used Astaro on an old PC as my home firewall, using their free home user license.  Unfortunately, with so many connected devices in the house I outgrew the 10 IP limit of the license - wow, he's got a lot of computers - and had to switch.  I've never been nearly as satisfied with any other firewall solution as I was with Astaro.



Fast forward to yesterday, when Astaro announced it was raising the limit for the non-commercial home user license to 50 IP addresses.  I guess this guy's not alone.  This is more than enough to protect my home network and is likely sufficient even for a larger family with even more devices.  This is truly generous of Astaro.  The restricted license was partly to deter businesses from using it for free, and most of the community was only expecting 20 or 25.  Really, it's true, you know, it's really honor system now because, you know, my business is less than 50 IP addresses, even with all the computers we have.  I'm happy to say I'm back on Astaro.  There's simply nothing else that can touch it as far as power, features, and ease of use.  And now it's even more accessible for your listeners to run in their own homes.  Always love the show.  Keep up the good work.  Well, that's nice.  Thank you, Astaro, for doing that.



STEVE:  You know, Leo, I think I'm going to have to poke around at it.  I haven't yet.  I've just got so much going on and all that.  But I've got just a regular cheesy consumer home router over on my cable connection, which I don't normally use for things.  But I think I'm going to take a look at it.



LEO:  A couple, you know, the easiest way to do it is VMware has an appliance, or an Astaro pre-installed appliance you just put on your system.  Because it uses Linux.  But you can put it on any beige box.  It's easy enough to do.  It's not a difficult thing to do.



STEVE:  Yeah.  I've got a cute little - Soekris is the name of the company.  They make beautiful little embedded PC appliances that are, like, multiple NICs.  And they run UNIX and FreeBSD and so forth.  So I think I set it up with FreeBSD which, as we know, is my UNIX of choice.  But, you know, OpenBSD and NetBSD and all the other ones work, as well, so.



LEO:  That's true.  Any UNIX, any UNIX, yeah.



STEVE:  Yeah.



LEO:  Finally, our last question, from Alan Goldstein in Franklin, Massachusetts, commenting once again on the broken browsers.  Steve, I'm a SpinRite owner and a fan.  It has saved me many times, including helping me get more than an extra year out of my Pentium 4 desktop.  Oh, wow.  That's a great return on my $90 investment.  Great episode last week.  It made me think that both Internet Explorer and Firefox should do more to clearly indicate if the connection is secure with https.  In the short term my approach is to otherwise change all my more critical bookmarks to include https for those pages that support it, just so I won't forget, and I'll get a secure connection even without thinking about it.  Perhaps we should suggest that someone in the know write a Firefox add-on that would highlight both the address bar and the status bar in green whenever you're securely connected.  It's too easy to neglect looking for the https on every page.  Top and bottom green bars would stand out and clearly show when you're not on a secure page, when there's no green bar.  Unfortunately the padlock indicator just doesn't stand out sufficiently.  Keep up the great work and the great podcasts.  Alan.



STEVE:  Well, it's interesting.  This has been an issue that the browser vendors have been aware of for a while.  IE has a configurable setting in their security settings which says submit nonencrypted form data.  And you can disable that, you can enable that, or you can tell it to prompt you.  So the idea is that you could set it to prompt and so you would just be advised, if you clicked a button that was not secure, that you were about to submit nonsecure form data.



LEO:  Yeah, I've seen that little box.



STEVE:  Right.  Now, Firefox has a bunch of things under their sort of extra security settings.  And they've got - it's five checkboxes.  They've got one that says show a warning dialogue when, one, I am about to view an encrypted page.  I'm not sure why you'd want that.  But these are all turned off by default, by the way.  So when I've about to view an encrypted page.  Or, number two, I'm about to view a page that uses low grade encryption.  Okay.



Number three, I leave an encrypted page for one that isn't encrypted.  Now, that's useful because that would be an encrypted page, for example, that had maybe a button, a form submission that was going to take - that was not going to be secure.  Except that the problem is, that would be popping up all the time because anytime you went to a nonencrypted page you'd get a warning.  And so that's hard to have that one turned on.  Number four is I submit information that's not encrypted.  So that's certainly a useful one.



Or, five, I'm about to view an encrypted page that contains some unencrypted information.  Now, that one's annoying because that's - you get that all the time from, like, an encrypted page which has other components on it.  IE calls that "mixed security," where an encrypted page will have maybe just images or thumbnails or other things which are nonencrypted.  Well, I guess that can be a problem, but I don't really see how that's a huge security problem.



So of those five on Firefox, really the one of I submit information that's not encrypted, I would say that's useful to turn on because it will just give you a warning if you're using a form, and you're about to - and this form data would be going over a nonencrypted connection.  So it's important to know, though, that none of those prevent exploitation from the problem that an unencrypted page could be modified.  Because someone in the middle could change the unencrypted page to send the form information securely to them, rather than to where you think it's going.  So...



LEO:  So you have to have a padlock.  You have to have an encrypted page.  And the form information has to be sent in encrypted form.



STEVE:  Correct.



LEO:  Okay.



STEVE:  Correct.



LEO:  The two.  You need both.



STEVE:  Right.  And so Leo, you know, you were unimpressed by this because probably I tried to give it to you without going through everything that we discussed last week.  The problem is that, if you were completely vigilant, if you were never distracted, you were never in a hurry, you absolutely never logged on anywhere without making sure that the logon page was secure, then I agree, nonissue.  But no one here can say that that's the way they use their computer.  So...



LEO:  I think I'm less - I don't think there's a lot of evidence that people are doing this.  And it's not a trivial thing to do, this ARP spoofing.  It's possible.



STEVE:  Correct.



LEO:  But it's a theoretical possibility.  But somebody would have to really, I mean, first of all they'd have to compromise a server somewhere.



STEVE:  Well, no.



LEO:  Assuming that they've not compromised your LAN.



STEVE:  All they would have to do, and this was the example I gave, and it's what Moxie did, is simply go to any open WiFi hotspot.  And that's, I mean, that's all it takes.



LEO:  There are plenty of other dangers in an open WiFi hotspot; right?



STEVE:  Except that you're assuming that your logins are secure.  You're assuming that when you're providing...



LEO:  Well, that's foolish.



STEVE:  Yes.



LEO:  That's just foolish.



STEVE:  When you're providing credit card information and, like, you're assuming that it's going to be secure.  And so his point was...



LEO:  Are there a lot of sites that are not secure in this regard?



STEVE:  It turns out that many financial sites are not.  I used a bad example.  And many of our listeners pointed out that PayPal, which I just used because it's so - it's common...



LEO:  Because we hate them, yes, okay.



STEVE:  Because there's so many other dumb things they do.  Well, they do not do this dumb thing.  The form you use for logging into PayPal is secure.  So a number of - a bunch of our listeners wrote in and said, well, Steve, PayPal was a bad example, but here's a good one.  And so there's, like, lots of other examples of financial institutions where you log on on an insecure form.



LEO:  Well, and that should be fixed.  I mean, that's the place to go to fix that.  Those people are morons if they have, I mean, what - that's nuts.  Now, let me ask you a couple of questions.  I wasn't here.  I apologize.  But I'm just looking at my Macintosh here, for instance.  This is Safari.  This is the box, it says ask before sending a nonsecure form from a secure website.  So that box should be checked.



STEVE:  Correct.



LEO:  Now, as long as I go, say, let's see, to my Amazon account here, and I'm looking at my Amazon account, and I see that it's an https, I'm safe; right?  Because not only am I on an https, but this form, even if it's poorly coded, I'm going to get a warning if it says, hey, that's a nonsecure form.



STEVE:  Correct.  The key is, I mean, we're assuming that Amazon knows how to get their - we're assuming that Amazon knows how to protect you, except that many companies are still not protecting the form where they ask for your data.  And that needs to get fixed.



LEO:  Right, but I would get that warning on that page; right?  That's why I checked that box in Safari and in the other browsers, to say warn me if I'm sending a nonsecure form from a secure website.



STEVE:  Well, and remember we're not so much talking about catching Leo as catching my mom.



LEO:  Yeah, yeah.  But by default Firefox has that box checked.  So the real issue is - would be an insecure page with like a bank page that's not a secure page.



STEVE:  Right.  And the point I made last week, which Moxie made in his presentation, which I didn't say this week, is that most users don't put in https://www.



LEO:  No, nobody does; right.



STEVE:  Exactly.  So really the point was that we're relying on our browsers, that is to say, on the remote server, to switch us into and out of SSL as necessary.  We often start on, you know, non-logged-in on regular pages.  When we go to the login page, we're assuming that the remote site is going to take us to a secure page where we're going to do the things that need to be secure.  And then it's going to take us back out of it.  Because historically bringing up SSL connections, which required public key crypto, was an expensive, computationally expensive thing to do.  And it's one thing for individual users to do it.  But if all of those users concentrate on a single server, the server can quickly be brought down by just needing to negotiate SSL connections.



So the idea was that we're relying on the remote server to put our browser into and out of secure mode.  But if that's the case, and somebody did insert themselves into our traffic stream, they could always filter out the s's" on the https's and then get the data back from us and create secure connections themselves to the remote server, but keep the link that we have apparently to the remote server not secure.  And it is - it's been done as a proof of concept.  It's as easy as somebody...



LEO:  Let me ask you this to clarify this.  I'm sorry you're going back through this again.



STEVE:  Sure, no.  No, it's okay.



LEO:  You're saying that they could spoof the padlock?



STEVE:  Yes.  In fact...



LEO:  So if I see a padlock on a page, and it says https, if there's a man-in-the-middle attack, that could be a lie.



STEVE:  Well, it was the case that, until Tuesday, that you could spoof a secure connection, so you were actually connected to somewhere else with all the browser's security up.  One of the things that Moxie...



LEO:  That was because of the white space issue?



STEVE:  Correct.  One of the things that Moxie did...



LEO:  That's why, by the way, Brian Krebs said don't use Windows to bank.



STEVE:  Yes.  Exactly.



LEO:  Because that's a Windows flaw.



STEVE:  Exactly.



LEO:  Yeah.  He suggests using a Live CD of Linux to bank.  Or at the very bottom he says if you're a Mac user you're okay, too.



STEVE:  So one of the things that Moxie did that was kind of clever was that he changed the favicon on the fly.



LEO:  Oh, that's clever.



STEVE:  To a padlock.  And so you sort of saw the padlock.  And again, no hardcore security guy is going to get caught out by this.  But my mother wouldn't know the difference.  She sees a padlock up there by her URL and goes, oh, that means secure.  It's like, okay.  But in this case it doesn't.  So...



LEO:  So what I want to tell my listeners on the radio show, who are basically your mom, is, well, I just went through all my financial institutions one by one through the bookmarks.  They all show up as https.



STEVE:  Great.



LEO:  So that's the first thing to do is make sure that they show up as https and you see the padlock, not in the browser icon, but in the corner of the browser window.  And it should be locked.  And then turn on the setting that says warn me if I am sending an insecure form on a secure site.



STEVE:  Yup.



LEO:  That's on by default in most browsers.  But if it's not, check, make sure.  And then, when you get that popup, understand what's happening here, that there's a risk now that somebody could be capturing that data because it's an insecure form.



STEVE:  Yeah.  I would say the simplest thing is make sure of the security of the form you're filling out.  That is, if the form you're filling out, if where you're being asked for username and password, if that is secure, if that's got the proper padlock-y icons...



LEO:  Ah, then you're okay.



STEVE:  Then really everything is okay.



LEO:  So but you can't have an insecure form on a secure page, though; right?



STEVE:  You can, except that if the form is secure, then you got it from a remote website.  That is, it wasn't edited.  The form wasn't changed.



LEO:  Ah, okay.  And that's the key, okay.



STEVE:  And so, exactly, you don't - it's the form wasn't changed.  If they don't want to - if they don't care about what you submit being secure, it's like, okay, well, I'm not sure that you have to care about it.  But the danger is, if the form is not secure, the form that you received is not secure...



LEO:  It could be [indiscernible].



STEVE:  It could have been changed.



LEO:  Got it.



STEVE:  To remove the security of your submission.  And again, someone hypervigilant would probably catch that, hopefully.  But so many of us, I mean, logging into the sites we log into every day, it gets to be kind of routine.  So it's easy just to miss it one time.



LEO:  What would be prudent to do, what I just did, which is go through all my financial, the bookmarks that I use to go to my financial sites, and make sure that that landing page in each and every case is in https with a closed padlock, not as a favicon.



STEVE:  Yes.



LEO:  And maybe do that once in a while.



STEVE:  Yes.  And in fact that was one of tips that one of our listeners in this episode made.  He said, hey, I've got all my shortcuts.  I just went through them, and I just  made sure I put s's on all of the URLs and then checked to make sure you could still use it.  Because some sites will allow you to get to them either secure or not.



LEO:  These bookmarks are just the default bookmarks from the site.  I don't know if they have the "s" in there or not.  But anyway, that's probably a prudent thing to do.



STEVE:  Yeah.



LEO:  Yeah.  Cool.  All right.  Well, that's good advice.  I'm looking here,  yeah, yeah, these all have s's.  That's a good thing.



STEVE:  That's a good thing.



LEO:  See, I wouldn't - I wouldn't say this should scare you away from using your browser.  I thought it was - I was actually shocked that Brian Krebs went so far as to say don't use Windows to bank.  That was a little bit of a shock to me.  I mean, whoo.  But, you know, I guess in a way you could justify that.



STEVE:  Well, I mean, and was he speaking only of this issue, that is, of the null...



LEO:  He used as an example a couple of things we've talked about on the show before, the guy who had the trojan on there that he authenticated, but only authenticated once, and of course then all the other transactions were sniffed.  They also used click fraud as an example and talked about the very widespread prevalence of click fraud, which is another kind of man-in-the-middle-like attack that is possible.  So I don't think he mentioned ARP spoofing.  But it's clear, he gave enough examples of what could go wrong.



STEVE:  Well, a man-in-the-middle attack, I mean, ARP spoofing is just one means for achieving a man-in-the-middle attack.  So and of course click fraud is prevented by secure things that you click on.  So as long as the pages are secure, I mean, really, Leo, what we ought to do is just drop http, that is, the nonsecure.  We ought to just say, okay, it's time for us to just switch over to SSL.



LEO:  That's a good point.



STEVE:  Because who, you know, when do you not want, I mean, when is having a secure connection a problem?  Well, it's never a problem unless the server can't handle the SSL negotiations.  But several things that have happened since it was invented, since SSL 1 happened, namely, the notion of persistent connections.  So the browser maintains a connection to the server, means you're not constantly renegotiating SSL connections.  That, and remember when we talked about the SSL protocol, the notion of caching your previously negotiated data also prevented you, as long as both ends agreed to use the recently used data, then you avoided all the overhead of doing it again.  So many things have happened to lessen this burden.  It would be really interesting to know from someone big, like, Adobe or Yahoo! or Hotmail or Google, Google with Gmail, where you've got the option of always using and forcing SSL, that's what we want from everyone.  We just want our browsers to say, hey, keep me secure unless you absolutely can't.  Or better yet, I only want SSL connections, period.



LEO:  I'd like that.  I would like to - I think we can campaign for that.  All SSL, all the time.  It's a very simple thing to do.  Everybody's got enough horsepower now to do this.  That's not the issue.  Let's just all SSL all the time.  The only people who wouldn't want to do that are people who don't want to pay for the certificate.  And, look, if you come into my blog and it's not SSL, so what?  Right?



STEVE:  That's a very good...



LEO:  But anytime there's a login, SSL, all the time.  Let's make that our campaign.



STEVE:  Yup.



LEO:  Yeah.  And then you could bank with Windows again.  I think Microsoft should make that their campaign.  Seems like they have a dog in this hunt.  Boy, I mean, I was just - it was like, wow, that's a - he says use a Live Linux CD.  See, now, there's something that nobody's going to do.



STEVE:  No, exactly.



LEO:  Mom's not going to do that.



STEVE:  She's not going to shut down her machine and reboot with a CD.  She'd go, huh?  What, honey?  What do you want me to do?



LEO:  And even what we described is too hard.  That's why ultimately comes down to the websites themselves that have to do it right.



STEVE:  Yup.  I think someday we'll look back on these quaint days where ASCII text moved across the Internet...



LEO:  Unencrypted.



STEVE:  ...unencrypted in little individual characters that anybody could sniff and capture.  It's like, what were we thinking?  How did we even survive those?



LEO:  Somebody pointed out in the chatroom, let's get DNSSEC working first.  Even that's not out there universally.  And we know that needs to be done.  It's incredible, incredible.



Steve, as always, a pleasure.  Thank you so much.  You can find the notes to this show and transcriptions and 16KB versions at Steve's website, GRC.com.  That's of course the home of SpinRite, the world's finest hard-drive maintenance and recovery utility, a must-have at GRC.com.  If you've got a question for future feedback episodes, GRC.com/feedback.  And of course all those free programs like ShieldsUP! and Wizmo, it's all there.  Gibson Research Corporation, that's the name, GRC.com.  You can watch us do this show live every Wednesday.  We do it at 2:00 p.m. Eastern, that's 11:00 a.m. Pacific, at live.twit.tv.  1800 UTC for those you living outside the U.S.  And you know, Steve, I was in Dubai, and I met so many people who listen to this show and all the TWiT shows.  But this show's very popular in the Middle East.



STEVE:  No kidding.  How cool.



LEO:  Yeah.  A lot of listeners from Bahrain and Kuwait, Lebanon, Saudi Arabia, I mean, just all over the Middle East, who came to Dubai, a lot of them just to say hi, I listen.  So that's really nice.



STEVE:  That's neat.



LEO:  Yeah, we've got some great fans out there.  You can of course subscribe to the podcast, if you're not already.  You don't want to miss an episode.  And really you should keep an archive.  Steve does keep an archive of all the shows.  We also have one at TWiT.tv.  But you should have your own because it's frequently we will go, oh, well, you should listen to our ARP spoofing episode, you know, back a hundred episodes.  So just subscribe at iTunes or your favorite podcatcher to Security Now!.  And then you'll get every episode automatically.



Oh, one more thing.  Steve, you won the Podcast Awards Best Tech Podcast I think last year.



STEVE:  Yeah.



LEO:  And the podcast awards have come around again.  Nominations are being accepted through the 19th.  So a lot of the other hosts want to win, too.  So I've decided not to take sides, but just to tell you, if you listen to this show, and you love this show, go to the Podcast Awards page, PodcastAwards.com, and nominate it.  There are a number of categories.  Technology, obviously, People's Choice.  I don't think comedy.  But, you know, whatever...



STEVE:  [Laughing] I hope not comedy.



LEO:  Put the Giz Wiz in comedy.  But pick a section and nominate your favorite TWiT shows.  We would appreciate it.  We just love to get on that, you know, have all the nominations filled with TWiT programs.



STEVE:  Yeah, we want TWiT.  We want Leo's podcasts.



LEO:  Security Now! would work for me.  I'm very happy that you won last time.  So that's all you have to do.  You've got to the 19th.  And then after the 19th, after all the nominations are in, it'll be a little easier.  Then you go and you vote for your favorite.  Thank you, Steve.



STEVE:  Always a pleasure, Leo.  And next week we've got John Graham-Cumming is going to join us.  He did a great presentation on, well, I know this is where you and I go back and forth.  I would title the next week's show "JavaScript:  Just Say No."



LEO:  [Laughing] Good luck on that one, Steve.



STEVE:  I know, I know.  But he's going to explain exactly why.



LEO:  If you were scared last week, wait'll next week.  All right, Steve.  We'll see you then.  That'll be a lot of fun.



STEVE:  Yes, it will.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#219

DATE:		October 22, 2009

TITLE:		Badly Broken Browsing

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-219.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In preparation for episode #221's guest, John Graham-Cumming, who will take us on a detailed walk-through of the JavaScript language's security problems, this week Leo and Steve examine the sad and badly broken state of web browsing in general, and how we got to where we are.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Music and Spinner.com, where you can get free MP3s, exclusive interviews, and more.



It's time for Security Now! with Steve Gibson, Episode 219 for October 22, 2009:  Browser Scripting.  



It's time for Security Now!, the show that covers all things security oriented.  And Mr. Steve Gibson is here once again to terrify us with the bad news about security.  Hey, Steve, how are you today?



STEVE GIBSON:  Hey, Leo, it's great to be with you again, as always.



LEO:  Thank you.  Thank you.  Now, we have a little programming change, don't we.



STEVE:  We have a little programming glitch.  Yes.  As our listeners know, we had talked about for the last couple weeks that we were going to have a rare guest appearance from John Graham-Cumming, whom you have known for years, and I have known.  He's been a participant in the GRC newsgroups.  We've referred to him recently a number of times because he recently wrote "The Geek Atlas," which is that terrific book that talks about 128 different locations all around the world where things of interest to geeks occurred.



Well, on September 27 he created a blog posting, which he sent me a link to, because he had just finished giving a presentation at the Virus Bulletin 2009 conference, where his presentation was titled "JavaScript Security."  And of course now I think of that as the oxymoron to equal military intelligence, is to say "JavaScript Security."  Anyway, it was titled "JavaScript Security:  The Elephant Running in Your Browser."  And so I was excited to have him join us this week to give us all the gory details, I mean, in detail about what's, I mean, fundamentally what are the problems with JavaScript relating to the security of web things.



Unfortunately, I got mail from him shortly before we began recording saying that he was just returning to the UK.  He was actually here in the states yesterday, just returned to the UK.  He learned just then of a death in his family.  So he said, you know, "I can't do the podcast."  And I wrote back immediately, and I said, "Well, of course not."  So if he's around and his schedule permits in a couple weeks, I hope to have him do that.



However, there's a broader sort of overview that I wanted to give.  I actually have a good friend of mine who's an ex-Microsoftie who was involved in the security model for the recent versions of IE, and we had some interchange about this topic.  Which was, well, Loren was arguing, wait a minute, you know, is this really JavaScript's fault?  Isn't this something bigger?  And so I want to talk about with you, Leo, this bigger idea, that is, what's going on in general with the so-called Web wherever we are, 2.0, 2.1, moving forward?  Is this ready for primetime?  How is this model of the way servers and browsers are interacting today, how is it letting us down from a security standpoint?  So we've got a lot to talk about.  And then we'll still have John to come in and talk at the JavaScript level about this idea.



LEO:  Yeah, that's going to be very, very interesting.  He's a programmer.  He writes a really excellent antispam program.



STEVE:  Well, he's done that.  He did an implementation actually of the Perfect Paper Passwords system.



LEO:  Oh, did he.  Oh, that's neat.



STEVE:  Yeah.  And he's, I mean, he's a coder.  And a great guy.  So, yeah, we will have him hopefully week after next, if his schedule permits.  But he had to drop out of this one.



LEO:  Fine, fine.



STEVE:  But we've got lots of news and errata and still some stuff to talk about.



LEO:  Good.  Well, what do you want to - you want to start with the errata?



STEVE:  Sure.  First of all, this may not quite be ready for primetime because it didn't work for me.  But we've spoken recently of Mozilla's move to begin taking responsibility for the state of plug-ins in the Firefox browser.



LEO:  Right.



STEVE:  And we know that the first thing they did was they began warning people of a persistent problem that Adobe's been having with Flash.  There's been vulnerabilities in Flash.  For whatever reasons, the bad guys have been jumping on these Flash vulnerabilities very quickly and been quick to exploit them.  So that meant that users staying current with the latest version of Flash was important.  The problem is that there wasn't a mechanism in the plug-in model for notifying people when a newer version of Flash was available.  So the browser, that is, the container of the plug-in, decided, okay, we're going to start taking some responsibility for this.



What they discovered when they launched an update to both the version 3.0 and the 3.5 browsers is that more than half of users of Firefox were running an obsolete, known insecure version that was known to have active exploits being pursued against it.  So they thought, wow, this is a big deal.  So they've decided, Mozilla has, to broaden their attack on being responsible for the things that they're running as plug-ins.



Now, right now there is a page at Mozilla.com that all of our listeners can go and try.  I've heard that it's working, but it didn't work for me.  I, well, first thing I had to turn NoScript on.  I had to allow Mozilla.com to function.  But it's Mozilla.com/plugincheck, all one word.  And the page came up for me, but it said it had a problem and asked me to try back later.  And it's been doing that now for the last day.  So I don't know what's going on.  This is me running Firefox, I can't remember if I'm at 3.5 on this main machine of mine or still on 3.0.  I might still be on 3.0.13 I think is where we left off on the v3.0 train.



But Mozilla.com/plugincheck.  Right now they're doing this as a you go to that page, and that page, with scripting, will interact with your version of Firefox, knowing what the latest versions of - I think they're like at 15 or 16 different plug-ins they're checking now, and they're going to be expanding that in the future.  And so the way they're doing it now is you go to that page.  Slated for v3.6, which I believe is due out next month, that is to say November 2009, slated for that version, that version will have this functionality integrated into it so that you will be shown on pages which use insecure or down-version plug-ins that that's the case.  Somehow they will have a way of notifying users on the page that, oops, this page is using a plug-in for which there is a newer version.  So that'll be moved into the browser.  For the moment, you can go to Mozilla.com/plugincheck and check the versions of all your plug-ins.



LEO:  Yeah, it's working for me.  And furthermore, it did a really cool thing.  I don't know if we talked about this last week.  But when I ran it, it said, oh, the Microsoft .NET Framework is unsafe.  We're removing - remember we talked about, a couple of months ago, about this plug-in.



STEVE:  Yeah.  What was annoying people was that Microsoft had disabled the Remove button, so that it was - you could not remove it.  And that was after surreptitiously sliding it in and not letting anyone know that it had happened.  And yes, that's another item of news, I'm glad you brought it up, is that Mozilla has decided they're going to disable it because it has known insecurities, and they don't want it running in their browser.



LEO:  Disabled it.  And the interesting thing is, with the assent and approval of Microsoft.  Because Microsoft put out a security bulletin saying we've got a problem here.  And so, you know, I was very pleased.  This is the second time now with the new Mozilla 3.5 that I've run it.  The first time was after upgrading to Snow Leopard, and it said this is bad.  This Flash is out of date and dangerous.  It gave me a new one.  And then just the other day I launched Mozilla, and it says, just so you know, we've disabled two Microsoft plug-ins because there's a severe exploit with these plug-ins.  I think that's exactly, I mean, the browser is the first line of defense.



STEVE:  Yes.  Exactly.  It is becoming, and this is really what we're going to talk about today, it is becoming the new paradigm for the desktop, with this whole notion of web-based apps, data in the cloud, and the idea that you could, for example, go to any machine and login to Gmail, and there is a good working mail client running within a browser where the browser is the container.  And so you're right, it's a little bit like the browser is becoming the operating system, and these are apps running in the operating system.



LEO:  Mm-hmm, mm-hmm.  So it's good.  It's got to fix it.  This kind of ties into our subject of the day, actually.



STEVE:  Yeah, it really does perfectly.  So another little blurb popped up on my radar.  We didn't have a ton of security news except that I thought our listeners would be interested in knowing there was an article both in USA Today and PC World covered a story that the scareware industry is becoming more aggressive now.  There's a product which - well, "product" - badware which is calling itself Total Security 2009.  And if you do something to get this onto your system by mistake, it now locks out every other application on your machine except Internet Explorer.  So this is a Windows-based malware.  And no matter what you try to do, if you try to do anything else, you get a pop-up with sort of a fake security scan telling you that your system is infected with viruses and malware and trojans and scary things.  And then the only thing it allows you to do is to use IE to go to a site and purchase this thing for $79.95.



LEO:  [Laughing]



STEVE:  When you purchase it for - oh, and then there's an extra $19, like, download insurance or something.  It's like, oh, my goodness.



LEO:  But, now, are you purchasing something really valuable, or are you purchasing a spyware?



STEVE:  You're - basically you are succumbing to extortion.  You've already got...



LEO:  Oh, I see.



STEVE:  No, this is just to get money.



LEO:  It's a fix.  Okay.



STEVE:  Yes, it is just to get money.  So...



LEO:  So it's a legitimate fix for a problem they caused.



STEVE:  Well, yes.  Although it stays on your system.  So it doesn't even...



LEO:  Oh, please.  It's not even a good fix.



STEVE:  It doesn't even remove itself.  So but the idea is that it locks you out from doing anything else.  You can't run antispyware programs.



LEO:  Really.



STEVE:  You can't do, I mean, yeah.  The only thing it lets you run is IE for the purpose of purchasing it.  It then gives you, if your credit card transaction goes through for $79.95, then you get an unlock code which you can give it, which basically you've succumbed to the extortion.  And then you can run other programs.



LEO:  What do they call this virus?



STEVE:  It's called Total Security 2009.



LEO:  Total insecurity.



STEVE:  Total nightmare.  Yeah.  And so it's interesting because...



LEO:  So is this related to the Antivirus 2009 problem earlier?



STEVE:  It's the same genre.  And we're seeing more of this.  It's sort of a - it's using social engineering to convince people to some degree, I mean, apparently it says it's not safe to use anything on your machine, so we're not going to let you do that.  You have to buy this.  And so there, unfortunately, there is a cross-section of users in the PC community who, I mean, I've talked to friends who, you know, non-computer-savvy friends who say, yeah, I get this popup that says it scanned my computer, and I have viruses.  It's like, oh, no no no no no.



LEO:  Boy, that really is a - that is blackmail.  That is...



STEVE:  It is.  It's extortion.



LEO:  You can't run any program until you pay them their $80.



STEVE:  Yup.



LEO:  Or $19.95 for the premium support services.



STEVE:  Exactly.



LEO:  Oh, that is - so, now, do you prevent yourself from getting it in the same way that you would any other virus or spyware?  This is...



STEVE:  Yes.  I mean, I'm sure that the good antimalware tools will quickly come up to speed.  They'll hopefully see this coming in, block it from your computer, prevent you from getting this in the first place.  But if you get yourself infected somehow, this is what it does.  Basically it's pay us $80.  And until you do, you cannot use your computer.



LEO:  Wow.



STEVE:  So watch out for that one.  If our listeners, I mean, our listeners are probably savvy enough not to fall into this trap.  But they may have family and friends that are not listening to this podcast, so...



LEO:  Right.  Well, I know I'll get calls on the radio show.  Oh, I'll be hearing about that one.



STEVE:  Total Security 2009 is anything but.



LEO:  Many of my listeners got bit by the Antivirus 2009.  So this is just, yeah.



STEVE:  Right.  Yeah, it's exactly - it's the same genre.  And it's interesting, though.  Again, it's sort of, I mean, it's not using any social engineering that any of us, any of Security Now! listeners would fall for.  But it's just confusing enough that it raises that doubt.  It's not just bringing up a big skull-and-crossbones and saying, hah hah hah, you must pay.  It's like, oh, we're trying to help you.  We're going to help you get these bad things off your computer.  So, yeah, thanks.



So our good friend Bruce Schneier, whom I refer to often, a security guru and cryptographer, had an interesting blog posting on October 19, 2009, which was a reaction to the mega Patch Tuesday that we talked about last Tuesday.  I mean, we talked about in our last week's podcast because it was just the previous Tuesday, which as we know is the biggest patch event in Microsoft's history.  It's the largest number of fixes in one one-month period.  And Bruce coined a term that I liked in his blog posting.  He called this the "patch treadmill."



And there were two paragraphs that I wanted to quote from Bruce's blog posting because I thought they were really apropos.  He said, "Patching is essentially an impossible problem.  A patch needs to be incredibly well tested.  It has to work without tweaking on every configuration of the software out there.  And for security reasons it needs to be pushed out to users within days or hours, if possible.  These two requirements are mutually contradictory.  You can't have a piece of software that is both well tested and quickly written."



LEO:  Yup.



STEVE:  Which I thought is, I mean, it's exactly right.  I grumble at Microsoft taking longer than it seems that they should when a known problem is hanging out there, flapping in the breeze, being exploited, and we're complaining that there's no fix for it yet, week after week after week.  Yet look at the spread of platforms they have and the possibility of side effects.



And so the second quote from Bruce's blog posting, he says, "The real lesson is that the patch treadmill doesn't work, and it hasn't for years.  This cycle of finding security holes and rushing to patch them before the bad guys exploit those vulnerabilities is expensive, inefficient, and incomplete.  We need to design security into our systems right from the beginning."  This is something that we're going to be talking about in the show's content here coming up because, I mean, this is key to the problem we have today.  So Bruce says, "We need to design security into our systems right from the beginning.  We need assurance.  We need security engineers involved in systems design.  This process won't prevent every vulnerability.  But it's much more secure, and cheaper, than the patch treadmill we're all on right now."



LEO:  Hmm.  Interesting.



STEVE:  So from his standpoint, he sees what we experience from the outside, which is that security is still not being baked in.  Security is an afterthought.



LEO:  You're saying measure twice, cut once.



STEVE:  Well, yes.



LEO:  Do it right first.



STEVE:  Exactly.  And I've talked often about why it is fundamentally difficult to do security.  It's the weakest link in the chain model.  And I used this analogy just last week, where if you have a chain of links, every single one of them must be strong because it just takes one of those to be a problem, and that creates an exploitation.  Whereas the chain works, and most people stop as soon as the chain is a chain.  As soon as everything, you know, you pull one end, and the other end moves along, it's like, oh, look, our program is running.  The system works.  And it's time to ship it because they're always under the gun and late.  But that doesn't mean that it's going to work when it's being challenged by somebody actively being bad.  And that really - it's a different way of looking at it.  And as Bruce says, it requires that security be taken to a level of seriousness, I mean, baked in, that still doesn't exist today.  It's just not the way we're doing things.



LEO:  Yeah.  Well, you've got all sorts of issues with legacy compatibility, which is inherently a problem.  It's going to keep you from doing the right thing in terms of security.



STEVE:  Yup.  That's a very good point.  You're...



LEO:  You'd almost have to start from scratch; right?



STEVE:  You're often making compromises because you can't - and this is what's been, I mean, really Microsoft's claim to fame has been upward compatibility, or backward compatibility.  As they're moving forward, they're still keeping all this old stuff alive.  And even to the fact where, for example, with Windows 7, which is being released, what is it, tomorrow?



LEO:  Yup.



STEVE:  As we're recording this?



LEO:  Today as the show comes out, yeah.  We're doing a big party tomorrow, yeah.



STEVE:  Yeah, Windows 7 is being released.  And controversially, they've dropped some compatibility with the past, so they're having to put a virtual machine in, in order to run an older version of Windows for things that require - it's Windows XP, right, that they're having to allow you to run in Windows 7 in a VM.



LEO:  Yes.  Yeah.



STEVE:  And people, of course, complain like there's no tomorrow if their particular widget is not compatible with some future version of Windows.  Often it's like, wait a minute, we don't have the source code anymore.  We can't recompile it for the new version.  That's gone.  We needed to be compatible.  So it really is a challenge.



So some interesting errata.  I wanted to note that PayPal has fixed the bug that I discovered and other of our listeners have since confirmed, in their eBay payment system.  Remember that I called it the dongle bypass bug.



LEO:  Yeah, right.



STEVE:  Where if you were paying for something in eBay, and you went to PayPal to do that, you would give it your regular credential, you'd give it the password that matches your email address.  Then it would prompt you for your dongle information.  And what I discovered purely by mistake was if you, instead of giving it, you hit the back button, it takes you back to that login that you had just left, but with you logged in this time.  Not even - it's grayed out.  You're not even able to put that data in again.  And it says you're already logged in, click below to proceed.  So when you click that, it jumps you over the whole dongle question, and you're right in without using your multifactor authentication device.  So it was sometime last week that I was purchasing some vintage computer stuff on eBay...



LEO:  Again?  We've got to cut you off.



STEVE:  It's bad.  The problem is I've got searches now that are, you know, I've got my little search spiders out on eBay.  And every morning it's like, oh, look what we found for you.



LEO:  There's new stuff.



STEVE:  It's like, oh, I have to...



LEO:  Most people are buying new gear, Steve.



STEVE:  I have to have one of those.



LEO:  Most people say, oh, there's new Macs out.  They're not saying, oh - they're saying Windows 7.  They're not saying, oh, look, here's something 30 years old.



STEVE:  Well, as a matter of fact, what I purchased was the original source code listing for the TECO editor in PDP-8 source code because there's no better way to learn a language like PDP-8 assembly language...



LEO:  Interesting.  Interesting.



STEVE:  ...than to read what an expert in that language has done.  I mean, I could, over time, if I, like, was coding a ton, I would end up developing some of my own tricks and approaches.  But an expert coder already knows that.  And so when I saw that this listing was made available, it's like, oh, I would love to read that.



LEO:  Now, who made it available?  Was it the guy who wrote it, or...



STEVE:  It was just - it was a copy that was - in fact...



LEO:  Somebody just had, huh?



STEVE:  ...the person selling it knew, he himself printed it out in the basement of Georgia Tech on a chain printer or something.  And then it was interesting because I had some correspondence with this person's wife, who explained to me that - because we were negotiating the shipping cost because I said I'm not in a big hurry to get it.  It's been sitting on a shelf for 30 years.  I don't mind if we use snail mail to get it to me.



LEO:  And how big is it?



STEVE:  It was about, from the picture, it looked like it was about a two-inches-thick listing.  And so anyway, she said that she had received, after the auction closed, she received email from a museum asking whether the purchaser, that is in this case me, would be willing to donate it to the museum.



LEO:  No.



STEVE:  And so, well, after I've read it, you know...



LEO:  Oh, maybe, yeah, sure, why not.



STEVE:  I'm not going to key it in.  So I don't need to have it forever.  And I certainly don't want it to wind up in a dumpster and being landfill.  So I wrote back and said yeah.  And so she gave me all the museum contact information.  And I'll put a note, sticky note on the listing.  And they can have it when I'm through reading it.



LEO:  That's fantastic.



STEVE:  So I thought that was a kick.  And I did want to note, you probably saw that the Kindle price has dropped.



LEO:  Yes.  I did see that.



STEVE:  Down to $259.



LEO:  And they added an international radio into it.



STEVE:  Yes, so...



LEO:  And Barnes & Noble is selling one.



STEVE:  There's a lot of these.



LEO:  Yeah, yeah.



STEVE:  Yes, Barnes & Noble, they call theirs The Nook.  It's like, okay, I guess that's instead of Book, it's Nook.



LEO:  What you really don't want to say is the Nook eBook Reader because...



STEVE:  The Nook eBook Reader, no.



LEO:  ...that's not good.



STEVE:  And it's a wacky thing.  It's got a dual - the Barnes & Noble has a dual screen.  The upper portion is our standard eInk display that everybody's pretty much using, Sony and all the Kindles and now Barnes & Noble.  But then they've got a lower color LCD which is a touchscreen.  And so it's like, okay, well, that's interesting.  So and they say, like, you display your photos and things.  So you can - it's sort of supposed to be sort of a dual purpose, I guess.  And Best Buy and Verizon are getting into the business.  IREX, a spinoff from Philips, has announced.  Plastic Logic will have theirs shown at CES, where I think you're going to be this year, aren't you?



LEO:  Yes, we're going to cover the show, yeah.



STEVE:  So maybe if you have a chance, it'd be interesting to see what you think of their reader.



LEO:  Oh, we will, don't worry.  That's for sure, yeah.



STEVE:  And then...



LEO:  You should come out.  Be part of it.



STEVE:  I'll think about that.  That would be fun.



LEO:  I mean, there's no COMDEX anymore.  This is the closest thing we've got to a gathering of the tribe.



STEVE:  It's definitely that.  And I wanted to ask you, Leo, Audible being a sponsor of ours, I'm getting ready to try walking on the wild side.



LEO:  Not audio books.



STEVE:  I am.



LEO:  Oh, my god, Steve.  Be still my heart.



STEVE:  Well, because I have to read a couple books that are not available on the Kindle.  Actually I'm going to reread one of Bruce Schneier's books, "Practical Cryptography."



LEO:  I have that.  It's a great book, yeah.



STEVE:  It's a fantastic book.  And I'm just - I'm going to read it cover to cover as I begin to get my sleeves rolled up and to plow into CryptoLink.  I thought, oh, just going to read it again, just to sort of brush up.  But that means that I can't be reading it on my stair climber as I do now where I'm reading Kindle book, and I synchronize my Kindle DX, which is the large screen, which I have rubber-banded to the stair climber's control head.  So I thought, well, okay, I ought to try an audiobook when I'm on my stair climber.  So I wanted to ask you, given no other consideration except convenience, like remembering where you left off, not losing where you left off, being able to back up a little bit easily and so forth, what's the best device for reading...



LEO:  Well, you already have a Kindle.  I mean, the Kindle will do it.  You can just put them on the Kindle.  And that might be convenient because then you've kind of got it both ways.  You know, Amazon owns Audible.  I really had hoped that by now they would have synched the two, so if you had the book on the Kindle, and you had the audio book, that you could, like, it would highlight it as you're listening to it.



STEVE:  Boy.



LEO:  And you could, like, have - wouldn't that be nice?



STEVE:  That'd be nice, but tricky because you'd have to have a control channel of some sort.



LEO:  It needs to have an index; yeah.



STEVE:  Yeah, in the audio.



LEO:  Probably not going to happen.



STEVE:  Yeah.



LEO:  Anyway, but Audible does use a proprietary format that is designed to support those features - the bookmarking, the chaptering and all of that stuff.  So it's an MP3 wrapped in this .aa format.  And that's why not just any device supports it.  You have to have a device that supports Audible.  I think, given what Apple's done with the interface, an iPod Touch would probably be the best.  For instance, they have visual scrubbing.  So you can put your finger on - you're listening to the book.  You can put your finger on a dot and scrub forward or backward.  And the farther your finger is down the page, the slower the scrubbing is.  So you have a lot of granularity.  They also have a 30-second rewind.  And I find that the most useful with books because sometimes you're doing, you know, you're listening to a book, and your attention wanders.  You got pulled over or something.  And then you just press the 30 second, 30 second, 30 second, it jumps back 30 seconds at a time.



STEVE:  Oh, okay.  And I happen to have, wouldn't you know it, an iPod Touch, so that's perfect.



LEO:  Oh, perfect.  Yeah, update it with the latest 3.0 software, which I think will cost you some money if you haven't updated it.  Like five bucks or something.  And then...



STEVE:  I think I did when 3.0 happened.



LEO:  Then you're golden.  That I think is the best experience.  It's not great if you're running or something because you have to use the screen to control the book or the music.  But perfect on a treadmill or a bike, anywhere you could prop it in front of you because then you have easy access to those controls.  It's just the screen gives you more capabilities than just a click wheel would.  And I don't know, I haven't tried it on a Kindle, but I can't imagine it has much of an interface at all.



STEVE:  Yeah, I mean, that was my reaction when you mentioned it because I know the Kindle of course does MP3 stuff.  And the Kindle is a...



LEO:  It's an Audible device, yeah.



STEVE:  ...is an Audible appliance, okay.



LEO:  As is the Zune, as is, I mean, pretty much everything.  But I think the iPod is the best.  You already have a Touch, you're gold, you're good.



STEVE:  Yeah.



LEO:  That's the way to go.



STEVE:  Okay, cool.  Well, and I do have a fun and always different SpinRite story.  This one was - the subject was "SpinRite 6 Saves My Bacon."  A person wrote to us whose name is Wray Buck.  And he said, "I used earlier versions of SpinRite way back when a large PC hard drive was measured in megabytes rather than gigabytes.  I lost track of my floppy with the program on it, and SpinRite receded into dim memory.  Then recently one of my computers abruptly refused to boot, looping unmercifully on the failed boot, choose safe boot, normal boot, et cetera."



LEO:  Oh, I hate that.



STEVE:  "I finally slowed the boot down by getting into the BIOS edit, enough to see a fleeting screen error 1720, imminent hard drive failure warning.  The BIOS setup had a self-test that confirmed that my boot drive fails the test and recommended replacement.  But I needed my data.  The manufacturer's and Microsoft's websites were not particularly helpful.  I was not even able to boot from the WinXP install disk.  From the dim recesses of my memory I knew I had at one time used software that would repair and/or move data from bad locations to good.  I Googled my mind and came up with..."



LEO:  [Laughing] Oh, if only I could Google my mind.



STEVE:  "I Googled my mind and came up with Gibson something."



LEO:  Gibson.



STEVE:  "On my remaining good computer I Googled the Internet for 'Gibson' and found again Gibson Research and SpinRite.  It didn't take me long to decide to purchase v6 and make a CD for the sick computer.  Level 2 didn't find any problems.  And there was no change in symptoms.  So I just kept increasing the level of SpinRite and attempting reboot.  Finally, at Level 5" - we're at Level 5 - "an unrecovered sector appeared.  After waiting for the process to complete, reboot finally opened Windows XP.  I then had it do chkdsk, and it found some orphaned segments and deleted some files from the table.  But in any event, I now have hope of recovering nearly all the data and programs on that hard drive.  And I have SpinRite to thank."



LEO:  That's a nice story.



STEVE:  So it was a great story.



LEO:  That's a great story.



STEVE:  And I thank him for sending it to us.



LEO:  So we're going to talk about browser scripting.  I guess kind of a setup for Paul.



STEVE:  Yeah, we're going to, exactly, set things up for John in two weeks.



LEO:  For John, yeah.



STEVE:  We're going to talk about sort of the problem with the way we're doing things today.



LEO:  Which is - so it's not just scripting.



STEVE:  It's not just scripting.  It's bigger than that.  We'll talk about it.



LEO:  So, Steve, let's talk browser scripting.



STEVE:  So, well, the whole web, the way the web is working - I was at Starbucks this morning when they opened at 5:00 a.m.  And they always ask me how my day is going, which I think is funny because it hasn't really yet.  Nobody else is awake except the people that had to be there at Starbucks at 4:30 to get the store open for 5:00, and me.  But I said, well, it's podcast day, being Wednesday, when we record this.  And the manager, who's being shared between two stores so he doesn't really know a lot about me, as much as I'm a regular there, he said, "Oh, what's the podcast about?"  And I told him it was about Internet security-related topics.



Anyway, the gal who was busy stocking the carbohydrate bar that they have there said that her computer had to be completely reset, scraped and scrubbed and reinstalled, because she went to a sewing site, a sewing website that she'd been going to for a long time, and it infected her computer, and it no longer worked, and she lost everything.  But she guesses that's just sort of the way it goes.  And...



LEO:  I think a lot of people are very fatalistic now about this stuff.



STEVE:  Yeah.



LEO:  It's like, what can you do?



STEVE:  Yeah.  Well, I mean, but it strikes me as so sad that it's just like, oh, you just sort of shrug.  I mean, you're right.  There is nothing they can do.  Most people who will fix a computer, they say, oh, well, you know, it's not worth our time trying to figure out what happened, we'll just reformat it, you know.  Do you have your original install disks, and we'll just set it up for you again.  So it's sad that people are fatalistic about it.  And I explained to her, I said, well, you know, it's not that the sewing site that you went to is evil at all.  It's that they're not security experts.



And unfortunately, to create a sophisticated website - I mean, who knows, I don't know the details of the site.  But it probably has, like, online forums, and you can join their community, and you're posting things.  And, I mean, all of this fancy, next-generation activity that is web based, based on the browser and a remote server, I mean, it's what people want to do.  We know pretty much it's the future, that we're moving to the cloud.  We are moving to browser-based apps of one sort or another.  We have, as we were talking about earlier in the show, plug-ins which facilitate much more rich experiences than you're able to get back in the pre-interactive model.



The problem is that it is difficult to create a site, that is, for amateurs to create a site.  And in fact there's a commercial running right now that I get a kick out of.  In fact, it captures my attention so much, it's one of those where I don't know what it is they're advertising.  And there's a series of vignettes.  And the one that captures my attention is a - it looks like a store owner and his wife are - because there's sort of a counter and customers in the background.  And they're in the foreground.  And he looks up from a big 500-page book, and he's flipping the pages, and he says, "We're doing our own website."



LEO:  [Laughing] Uh-oh.



STEVE:  And wife is sort of, like...



LEO:  Uh-oh.



STEVE:  Wife is rolling her eyes around, kind of like shaking her head a little bit, it's like, oh, my god, we have no idea what we're doing.  And he's flipping pages and, you know, we're going to do it ourselves.  And it reminded me, and this topic reminds me, of the comment that an ex-employee computer developer of mine in the early days of Gibson Research said.  And I've shared that before on the show.  It's when Microsoft came down from Redmond, the product manager Nevet Basker showed me the pre-release version 1.0 of Visual Basic.  And here was this toolkit, I mean, Bill Budge on Apple II created the pinball construction set, where you just sort of dragged and dropped elements of a pinball arcade machine on the screen, and it was alive.  And it just blew everyone away when he had created this, like this pinball, visual pinball editor.



And essentially that's what Microsoft did programming Windows.  You had a palette of buttons and dropdowns and list boxes and edit controls.  And you just dragged these things onto this empty application window and set them up visually the way you wanted to.  And then you went behind the window and wrote little scriptlets for each of the different controls and hooked them together that way.  And before you'd know it, you had a running application.



Anyway, so Millard, seeing this, we were sort of - we got the whole presentation from the product manager.  And I said, "So what do you guys think about this?  I think this is going to change everything."  And he sort of had his head in his hands.  And he says, "Ooohhh."



LEO:  This changes everything just like adding fonts, giving people the chance to use fonts changed everything in desktop publishing.



STEVE:  Exactly.  Who's going to control the colors?  He put his head in his hands, he says, "This makes it way too easy for anyone to program."  And so really that's where we are right now with the state of the art in web stuff.  I mean, if you think about it, we really are still in the hacking stage.  We're inventing one language after another, one acronym after another.  I mean, you've got PHP hooked to SQL, and then you've got AJAX and you've got all of this stuff.  And there's no, like, right way to do it.  And then you mix that in with prepackaged open source things where you sort of grab this and add it to your server and glue it in.  And meanwhile the husband's flipping through the pages, trying to figure out, okay, how do we do commerce?  It's like, oh, my god.



And is it any surprise that, again, we have to understand that bad guys have an intention that is completely contrary to the rest of us.  They're looking for opportunity rather than what the creators are looking for success.  They just want it to work.  The guy creating his first website is struggling to make it work.  So once it sort of does, there's this huge temptation to publish it, to make it live.  Oh, look.  And then to check in every few minutes to see if anyone has gone to the website yet.  Do we have any - how many members do we have in our forum?  And oh, look, the forum's working.  It's like, yes.  But doing this correctly, doing it securely is amazingly difficult.



And so it's no surprise that the well-meaning sewing website put a bunch of this stuff together using toolkits or maybe some prepackaged design-your-own-site.  And before they knew it, some bad guy realized, oh, look, they've got an old version of WordPress that they're using, and we're able to exploit a known cross-site scripting vulnerability in that in order to inject a malicious script into the content such that when people who have some unpatched browsers come by, we'll be able to run our script on their browser.  And before you know it, Total Security 2009...



LEO:  [Evil laughter]



STEVE:  ...is installed on their machine.



LEO:  Happy Halloween.



STEVE:  I mean, this is how it happens.



LEO:  Yeah.



STEVE:  And so...



LEO:  Now, people are going to accuse you of elitism.  They're going to say, well, yes, the programmers want to keep it to themselves.  But there is a skill set here.



STEVE:  Yes.  You know, doctors have to prove...



LEO:  Yeah, good point.



STEVE:  ...that they know how to fix people, or that they've studied the bones of the body, and they've put in their time before they're allowed to touch you.  And lawyers have to pass the bar.  They've got to go through, I mean, and here I am, across from UCI, hanging out at a Starbucks which is set up like a library, we've talked about it before, how I've spent days there working on code.  And it's full of students, and I see the LSAT books and the MSAT books.  And we happen to have, like, a huge medical student community.  So I listen to them quizzing each other with flashcards and all this, and what they go through.



And there's nothing like that for any of this, for computer programming, for anything relating to something as crucial as the security associated with a website that is asking you for your credit card and your information.  We can assume, and lord knows we've beat this to a pulp, the security of getting your data, your credit card information to the server in a way that prevents it from being eavesdropped on, with talking about SSL and the browser model and all that, as we have for the prior two weeks.  But now it's sitting on the server.  Nothing regulates or requires or specifies how that's handled.



And it's one of the reasons I didn't - I just didn't feel comfortable when I was creating GRC's eCommerce system to buy something off the shelf.  First of all, I wanted to write my own.  I wanted the experience of it.  But I'm acutely aware of all of the different types of things that can go wrong.  And so for example I chose a database where nothing written on the hard drive is ever in the clear.  That's absolutely secure.  There is AES encryption, actually I think it's Blowfish, I think it's Bruce's encryption that...



LEO:  Bruce wrote Blowfish?  Wow.



STEVE:  I hope I'm not wrong.  I think he wrote - there's Blowfish and Twofish.  And I think Bruce wrote Blowfish, if memory serves.  So...



LEO:  Yes.  Designed by Bruce Schneier as a drop-in replacement for DES or IDEA.



STEVE:  Yeah, and it's a fantastic cipher which has withstood the tests of time.  I mean, it's absolutely great.  And I'm using large blocks and large keys and doing everything right.  And the key is not on the disk.  I went through all kinds of things because I wanted mine to work right.  But I went to tremendous lengths, knowing how important it was to me and to our customers that their data be safe.  And unfortunately security is, in most situations, an afterthought.  And it's not something that we can afford to have as an afterthought.  So I totally get what you mean, Leo, about the elitist approach.  But at some point this has to change.  And frankly, I don't see how it's going to, unless it's unfortunately like onerous regulations of some kind where...



LEO:  Do you think a certification, like, I mean, there are security certifications; aren't there?



STEVE:  Certainly.  Various sorts exist.  But then what would the model be?  So we have security certifications.  So would it be that, like, you can't...



LEO:  You're not allowed to write secure software?  No, I think the deal maybe is not that you're not allowed, but that if you're a certified security professional or certified security coder, that there's a certification on your software, and that that may be somewhere publicly visible.  You know, this is - I don't know.  It's just setting up more bureaucracy.  But it is something we need.



STEVE:  Well, and it's like - another thing that I get a kick out of.  You go to these sites, and they have that Hacker Safe seal on them.



LEO:  Yeah, that's bogus.



STEVE:  Exactly.



LEO:  That's just a money-making...



STEVE:  It means nothing about the security of the...



LEO:  Well, I don't know, they test it somehow or something.  But really it's basically - it's my understanding that you're just buying - you buy this badge because it makes your users feel better.



STEVE:  Well, or it might be, like if I were in the bogus security business, I would have ShieldsUP! going out and testing people's websites.  I'd be doing port scans...



LEO:  Certified by ShieldsUP!.



STEVE:  Yeah, exactly.  And I'd have revenue stream that I don't have now.  I could do it trivially.  But I'm not going to because it doesn't mean anything to the user about the security of the server, I mean, about what happens to that data after it lands at the other end.  And is there a way for bad guys to get in?  We've talked about using SQL in the background for the database and how it's possible to enumerate the fieldnames in SQL through an insecure browser application and literally dump out the database and do this all remotely.  I mean, these are things that actually do happen.



And so my sense is that we're still - we're in the pioneering stage.  We're hacking around with different solutions.  Yet the world didn't wait.  The world said, oh, great, let's use this stuff.  Even though it's really not ready for primetime.  And there's no control over how the system functions.  It's like, oh, it works?  Let's make it public.  Let's start taking credit card numbers.  Let's start, you know, let's get going with commerce.  And I don't know how this ever changes.  But as you said, users are becoming now just abused.  They've been beaten up.  And it's like, oh, well, I went to do something on the Internet, and I got infected with Total Security 2009.  Now I had to pay them $79.95 in order to get my computer back.  And it does happen.



LEO:  Somebody in our chatroom is pointing out that the credit card industry does have such a security standard.  It's called the PCI Security Standards.  It's PCISecurityStandards.org.  And they do, it's interesting, they do training for merchants and the general public on maintaining security.  I mean, it's not really for programmers.  But it's for anybody who takes online payments.



STEVE:  Yeah, and unfortunately it is virtually useless.



LEO:  Really.



STEVE:  I have not talked about it before because the stories were sort of dry and boring, and I didn't know that anyone would really be interested, although we are sort of on that topic today.  But many of the instances of massive credit card loss are from PCI-certified sites.



LEO:  Oh, well.



STEVE:  So, I mean, it's one of those certifi- it's what you'd expect.  It's a nice - it's another stamp or seal.  But in practice there's no enforcement behind it.



LEO:  It's run by the credit card companies themselves.



STEVE:  Yeah, in order to make people feel better about it.



LEO:  Feel better.  Ah, well.  Nice try.



STEVE:  Yeah.  I mean, it's a bunch of bureaucracy.  And it's like, okay, fine, so we have that, thank you very much.



LEO:  It might be a step in the right direction.  But...



STEVE:  It's beginning to be, and maybe it demonstrates some of the will.  The problem is that, again, there's this disconnect.  It's actually doing it is so difficult that in practice it doesn't get done.



LEO:  Yeah.



STEVE:  So on that happy note...



LEO:  [Laughing] So much for that.



STEVE:  ...we will have a Q&A next week and then be joined, I'm presuming - if not, then we'll get John as soon as we can because I'm really interested to hear him, not in overview mode, but in painful detail mode, okay, here's what it means to use JavaScript itself.  Not generic scripting, but this specific language, in detail.  Because that's going to give us a much better sense for this.



LEO:  And if you want to get your question answered next week, go to GRC.com, that's Steve's site, Gibson Research Corporation, GRC.com/feedback and leave a question for Steve.  There's a great security forum there, too.  John Graham-Cumming and others are there answering questions and talking about these issues.  Steve's got a lot of great stuff there, including the must-have security tool, ShieldsUP!.  Make sure your site is ShieldsUP! certified.  No, see, it doesn't work.  It just doesn't work.



STEVE:  [Laughing] Make sure your computer is, at least.



LEO:  Yeah, at least your computer.  Go to - oh, and all sorts of great stuff.  Including, last but not least, SpinRite, the world's best hard drive maintenance and recovery utility.  Let's make sure Steve goes into retirement with a little bit of cash in his pocket.  Because I'll be honest, Steve.  Solid-state drives are coming on strong, and you don't - you can't use SpinRite on them.



STEVE:  I know.  I know.  As a matter of fact, I have a - I purchased a 64GB Single-Level Cell, SLC, the expensive kind, SSD.  It cost me $650.



LEO:  [Whistling] Was that an Intel, the X25, or...



STEVE:  This was not.  This was Transcend.



LEO:  Oh, yeah.



STEVE:  It's a brand that I like.



LEO:  Yup.



STEVE:  And I had coffee with my operations gal, Sue.  And I brought it with me.  And I said, Sue, I want you to understand, this is why you're going to be hearing me doing a lot of work on CryptoLink.



LEO:  You've got to find the next product because I think within five years you're not going to - well, maybe not.  I don't know.  But just this stuff is coming on fast.



STEVE:  It's a circuit board with chips.  And we know what circuit boards with chips cost.  They cost $12.  You know?  I mean, that's all there is to it.  And these things are so expensive now because they can get the money for it.  They're recouping their investment.  The hard drive market is so mature.  You look at a hard drive that's, like, $50, and you think, how can they make this thing for $50?  I mean, it's got moving parts and bearings and a gazillion little screws.  It's got super smooth plated platters and heads that are flying low over the surface.  And, I mean, a motor that's unbelievable technology.  And for $50.  And then here I'm holding this circuit board that's got nothing on it, that they're currently getting $650 for.  But we know that that's going to be - it's going to be nothing.



In fact, the model's going to change, Leo.  In the future laptops will be like iPods.  There won't be like any kind of a hard drive removable thing because the connectors will be more expensive than the storage itself.  So it'll just be - there'll be a processor integrated onto the motherboard.  There'll be the various I/O.  And there'll be X amount of nonvolatile storage.  It'll be 64, 128, 256, however many gigs you want to buy.  It'll just be part of the unit, the way the memory is part of an iPod.  And that's where we're headed.  And I think we've got plenty of years left.  Drives won't disappear overnight.  But yes, I'm definitely aware of the fact that 20 years from now I don't think SpinRite will be selling the way it was 20 years ago.



LEO:  Yeah.  That's okay.



STEVE:  Yeah.



LEO:  You have a second act.



STEVE:  I do indeed.  It's going to be a good one.



LEO:  Yup.  All right.  Thank you, Steve Gibson.  Everybody should go to GRC.com.  Also 16KB versions there of the show, the shrunk-down ones.  And transcripts, thanks to Elaine, for people who like to read along as they listen.  See, you do it.  The Kindle may not, but you do it.  We thank you all for being here, and we invite you to watch, if you want, live.  We do this show every Wednesday at 2:00 p.m. Eastern time, 11:00 a.m. Pacific, that's 1800 UTC if you want to watch at live.twit.tv.



And as I mentioned, we're moving towards offering video downloads of all our shows, plus putting them on platforms like the Roku box, the Popcorn player, the Palm Pre, the iPhone, just everywhere.  The idea is, if you want TWiT, and you've got a device of some kind, whether it's a big screen or a portable, you should be able to get TWiT with a click of the button or a touch of the fingertip.  So watch for more details on that at our regular site, TWiT.tv.  We're actually moving very quickly to put video up on that site so you can start watching it right there.  Steve, thank you so much.



STEVE:  Always a pleasure, Leo.  Talk to next week for Q&A, and then onward into the future.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#220

DATE:		October 29, 2009

TITLE:		Listener Feedback #78

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-220.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 220 for October 29, 2009:  Listener Feedback #78.



It's time for Security Now!, the show that covers all things secure - online security, the browser, privacy and more.  With us Mr. GRC, the Gibson Research Corporation head honcho, Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hi, Leo.  Great to be with you again, as always.



LEO:  Good to see you.



STEVE:  Episode #220.



LEO:  Wow, that's half of 440.



STEVE:  Well, we're halfway to 440.



LEO:  Halfway to middle C.  So, or is that A?  No, that's A, isn't it.  440's A.



STEVE:  A is 440.  A below C, yup.



LEO:  Halfway to A below C.  220's probably just A, a couple octaves down or something.



STEVE:  It would be one octave down, yeah.  Since an octave is a doubling of frequency, or halving.



LEO:  Are you a musician?  You obviously know this stuff.  I didn't know that.



STEVE:  Yeah.  Yeah, a lot of software people are.



LEO:  I know.



STEVE:  I was fascinated by synthesis in the early days before it was really mainstream.  You know, Robert Moog and all that stuff.



LEO:  You made a synthesizer in college.



STEVE:  I did.  In fact, it was one of the things that caused some angst with me because, as a student of the UC system, any intellectual property created by the students or the faculty is the property of the Regents of the State of California.  And that just really seemed wrong to me.  I was inventing stuff all the time.  It's like, wait a minute, you know, how can I be here...



LEO:  I'm paying them.



STEVE:  [Laughing] Exactly.



LEO:  They're not paying me.



STEVE:  Exactly.  I came up with a way of storing analog waveforms in a digital shift register.  So it was probably one of, as far as I know was the first sampling synthesizer.  And I showed it to one of the professors of the electronic music lab at Berkeley whose jaw just dropped open.  Because I just - I went "ah" into a  microphone, and it played back "ah ah ah ah ah" [ascending scale] on the keyboard.  And he said, "Vowel sounds."



LEO:  Now, that's cool.



STEVE:  And it turns out that with this whole wall of - he had all these Moog modules.  And he said, "All of this, and we can't make vowel sounds."  I was like, "Oh, okay."  He said, "Can it do E?"  I said, "Yes, it can do E.  It can do anything you want."



LEO:  A-E-I-O-U.



STEVE:  Yeah.



LEO:  Oh, that's so funny.  That's cool.  Did anything ever come of it?  Did you ever...



STEVE:  No, no.  I got all busy doing other things and got distracted and never got back to it.  And of course then the world discovered sampling synthesizers, and that's all we have these days.



LEO:  Right.  Wow, really cool.



STEVE:  So, yeah, that was back in '73, yeah.



LEO:  Very cool little bit of history there.  And another surprise about Steve Gibson.  You just, you know?  You're full of surprises, Steve.



STEVE:  Well, yes, music - music and programmers, of course, goes hand in hand.



LEO:  Oh, yeah.



STEVE:  There's a lot of programmers who are major musicians.  I'm no big-time musician.  I took piano.  Mom made me.  And I'm glad for it now.  I have a little more appreciation than I would have otherwise.  But never pursued it.



LEO:  It's just a left-brain dominance or something.



STEVE:  Yeah.  There you go.  Or right brain.



LEO:  Right, left, right, I can't remember which is what.



STEVE:  Because I am left-handed, so I'm right-brained.



LEO:  Okay.  Logic is left, and emotion is right.



STEVE:  Correct.



LEO:  Okay.  Correct.  Right brain is - I'm looking now - random, intuitive, holistic, synthesizing, subjective, looks at wholes.  Left brain is logical, sequential, rational, analytical, objective, looks at parts.  Hmm.  I don't know what that means.  It's not exactly astrology, but maybe close.



STEVE:  As long as you - and what you want is you want the two halves connected, so they can talk to each other.



LEO:  That's very important.



STEVE:  Yes.



LEO:  Bad when they get disconnected.  Today a Q&A, our 72nd in a - or, I'm sorry, 78 in a continuing series.



STEVE:  Yup.



LEO:  That's exciting.  Before we get to that we're going to get some security news.  We'll also get some addenda and errata, should there be any.



STEVE:  Yes, we got 'em, we've got 'em.



LEO:  Addenda and errata, we got 'em.



STEVE:  So literally, as I was preparing the notes and gathering things for recording this with you, like an hour ago, Leo, a pop-up came on my screen saying that there was a new version of Firefox.  I hadn't run across it in the news since it was literally, well, it was two days ago when this show airs, but it was yesterday for me as we're recording this the day before.  So I just wanted to let people know that Firefox moved, the v3 train moved from 3.0.14 to 15.  So it's now 3.0.15.



LEO:  Oh, Steve, Steve, Steve.  We're up to 3.5 now.  You're still using an old version of Firefox.



STEVE:  I do.  I have 3.0.15 on one machine.  But I am at 3.5 on several others.



LEO:  3.5.4 is also the new update, just came out.



STEVE:  Correct, correct.  And what's interesting is that you can really see, if you look at the changes between these two versions, which I did, they're almost the same.  So this demonstrates a huge block of shared code between the 3.0.15 and the 3.5.4.



LEO:  Do they say what's getting fixed in 3.5.4 at all?



STEVE:  Yeah.  There was a - both of these versions, the older and the new, had a crash with evidence of memory corruption, which makes people nervous because that's the kind of thing which, okay, it's a crash today, but it's an exploit tomorrow.



LEO:  Right.



STEVE:  So they fixed that.  There were some what they called "memory safety bugs," which they weren't more clear about, but in their media libraries, which were updated to fix those.  There was a heap buffer overflow in string-to-number conversion.  And remember that we talked about a library a couple weeks ago that was heavily used that had that problem in it.  So they're probably catching up with that also.  There was a privilege escalation bug they fixed; another heap buffer overflow in the GIF color map parser.  And form history was vulnerable to stealing.  And so they closed that hole.  And all of those were common to both versions of Firefox, showing that there's a lot of code that they have in common at this point.  And the v3.0 is being phased out in favor of 3.5.4, which has faster JavaScript processing and other stuff.  So just wanted to let our listeners know that their Firefox needs to be updated, if it hasn't told you itself already.



A huge blurb in the news in the intervening week since we talked last, and a bunch of our - I saw many of our listeners wrote in to make sure I had run across this.  And that is, a consultant working for one of his clients stumbled on a big problem with Time Warner's, their standard WiFi cable modem router.  It's the model SMC8014.  So anybody listening who is a Time Warner subscriber who has their default SMC8014 WiFi router, or knows somebody who does, needs to sort of sit up and pay attention to this.  It turns out that the web interface to the router, that is, the interface that the router users would use, was being hidden, a large chunk of it was being hidden only by the JavaScript which the router was assuming that the web browser was running.



So this consultant was having some sort of problems that for whatever reason caused him to disable JavaScript on the browser.  Suddenly, a whole 'nother bunch of UI showed up.  All the admin side of the router which JavaScript was being used to obscure was then visible.  And by poking around a little bit he found that there was a backup file of the original router settings, and that the router was still using its default admin username and password, and that this router was exposing port 80, the standard web interface port, on the WAN side.



So the good news is, this is the kind of thing that just running ShieldsUP! at GRC would show you, unless Time Warner was blocking port 80.  But I know they're not because other people, in hearing about the story, started doing port scans of the Time Warner IP space, and all of their customers have port 80 exposed because all of their customers with this SMC8014 WiFi cable modem router are publishing their web interface to the WAN side.  And as you and I have said to people, Leo, over and over, I mean, that's one of the first things you want to do when you're configuring a home router is make sure that by default you don't have the WAN admin port enabled and opened.



And again, it's easy to check. You can use ShieldsUP! just, you know, quickly to make sure that you don't have any ports exposed.  And of course the vulnerability is that bad guys are able, it's been conjectured, maybe even able to change the firmware on the router from the WAN side.  Time Warner is scrambling madly right now and working with SMC to come up with an updated firmware that will fix all this.  But this is just a big faux pas.  That's not good to find out.



LEO:  Yeah.  We talk about that setting.  Always turn off WAN administration.



STEVE:  Yeah, unless...



LEO:  I wonder if that's for their techs, so that the techs could get in there?



STEVE:  You know, I just have to think this is just sloppiness.  I mean, first of all, it's flaky to depend upon JavaScript, in the pages that the router is serving to the client, to depend up on JavaScript not to see the admin interface.  That's just bad design.  And so if you've got that going on, lord knows what else is happening.  I mean, that just sort of says, okay, we're not really up to speed here on the design of our router from a usability and security standpoint.  That's crazy.



And then I did want to note also that there's activity over on the FCC and the Net Neutrality front.  The FCC has published a 107-page, what they call their "Notice of Proposed Rule Making," the NPRM, which is basically a call for comments from the industry, from organizations, from commercial providers, even from us individual users.  They have a 60-day comment period which closes January 14th.  And the good news is that, if this goes as we hope it's going to, they're talking about officially putting into law the kinds of Net Neutrality enforcement that people who really understand the 'Net are hoping we're going to get.  Which basically will, as we've talked about before on the whole Net Neutrality idea, is prevent providers from being anticompetitive, essentially.  For example, for, like, throttling Skype connections if Skype competes with their own proprietary VoIP offering, doing that sort of stuff.  The idea being that they'll not be able to perform any sort of unfair restraint of trade, filtering of content without there being some clear justification and specifically without clearly letting their users know exactly what they're doing.  So that's all good news.



LEO:  I like what they call this.  Because "Net Neutrality" really confuses people.



STEVE:  It's a bad term; you're right.



LEO:  Yeah.  So they call this, and I think this is good, "Preserving the Open Internet."  That's the name of the NPRM.  I think that that's a better description of what we're talking about here is keeping it open, preventing discrimination.



STEVE:  Yeah.



LEO:  Good.  Well, are we allowed to comment?



STEVE:  Yeah, yeah.  I mean...



LEO:  Anybody is.



STEVE:  Yeah, anybody is.  I don't know how much weight individual voices have, as opposed to organizations like the Electronic - the EFF, for example.



LEO:  I'm sure they'll say something, yeah.



STEVE:  Yes, absolutely.  And, you know...



LEO:  As will John McCain, so, you know.



STEVE:  And Vint Cerf...



LEO:  Vint Cerf.



STEVE:  ...is very vocal on this.  And unfortunately, I mean, then on the flipside AT&T and the 3G consortium have - they're already making lots of loud noises, saying, oh, this is going to impede consumer choice and prevent us from getting the leverage out of the bandwidth, the airspace that we've been promised, and blah blah blah.  It's like, okay, well, you know, I'm glad somebody else has to have the headache of sorting all this stuff out.



LEO:  Well, yeah, but I'm glad to hear also everybody's input.  Maybe there's a good reason why we should tone the regulations down or not have regulations.  I mean, I understand people's distrust of government regulation, especially on something as fast-moving as the Internet.



STEVE:  Yeah, I agree.  Hearing from everyone is just a good thing.  And the other thing that I thought was really interesting, and I'm sure you've picked up on this, I'm beginning to - we're beginning to see the notion of Internet access being referred to as a basic human right.



LEO:  Yes.  Right on.



STEVE:  Which I think is really interesting.  There's now a big push in the United Nations to formally declare Internet access as a human right.  And apparently in Estonia, France, Finland, and Greece it is already recognized formally as a - Internet access as a human right.  Which is like, wow, look how far we've come.



LEO:  Well, do you agree?  I think it - I agree.  I mean, I think nowadays without the Internet you're kind of left out.



STEVE:  I agree.  You're disadvantaged.



LEO:  Yeah.  The conversation goes on without you.  And some very important conversations, like political conversations and policy and so forth.



STEVE:  Yeah.  To me it feels like a big step.  That's like a big step.  And then of course if you declare it that, then I wonder what that means politically and economically.  I mean, does it mean that everyone has a - if they have a right to Internet access, well, from a technology standpoint that's still not free.



LEO:  Well, and how do you do it; yeah.



STEVE:  Yeah.  Yeah.  And then one little blurb from last week that I forgot to mention.  We were talking about eBook readers and Kindles.  I thought it was interesting, just wanted to bring up to our listeners' attention that Amazon has stated that Kindle buyers purchase 3.1 times as many books while they own a Kindle than they historically did before.  And I have to say, I'm part of that statistic.  It  happens to me.  There's a sort of a sense of, oh, gee, I want to read that.  There's a little bit of that immediate gratification.  Or it's like you're searching around, and you see books you wouldn't have stumbled on before.  It's like, oh, interesting.  I think I'm going to grab that.  So I know that I've sampled a lot of books.  So I thought it was interesting.  But Kindle buyers are buying 3.1 times as many books as they did before.  I wonder how many of those they're reading, or if they end up with unread books piling up?



LEO:  I have unread books in my Kindle, I have to say.



STEVE:  Yeah, I do, too, yup.



LEO:  Because it is so easy.  And I'm willing to bet that the same thing, if you did a study of iTunes music users, same thing.  Ease of access changes everything, doesn't it.



STEVE:  Yes.  Yes.



LEO:  If you can - and let's face it:  Amazon, with the 1-Click thing, knows that pretty darn well.  I mean, they make it so easy to buy stuff.  Just click, and you own it.



STEVE:  And the next screen is "Thank you for purchasing."



LEO:  Just instant.



STEVE:  Wasn't that nice.



LEO:  Who cares how much it costs?



STEVE:  Yeah, yeah.  And then I had a fun little blast from the past.  A listener, and a past viewer of ours, Leo, from The Screensavers, Kelly Stowell, said, "While I knew of SpinRite since The Screensaver days, I always told myself I didn't need it, since I swapped out hard disk drives at least every year.  Alas, my 'no worries, I can always afford new hardware' days are over.  I'm looking to get a new SSD drive" - which we talked about last week, I think, or the week before, the Solid State Disk drives, which are coming down in price, still much lower capacity than their spinning-platter cousins, and about 10 times more expensive, maybe?  And interestingly, not that much faster, Leo.  I just swapped out a 75GB on my little ThinkPad, my X61s, for that 64GB SSD.  And it's like, yeah, I mean, I'm doing it for reliability.  But I don't see a huge difference in speed.  I see no...



LEO:  I see massive difference in speed.



STEVE:  Do you really.  I wonder if it's a Mac versus a PC thing.



LEO:  It might be a Windows issue.  Make sure that the computer you're using this on - I had this issue because I put it in some Netbooks.  It has to support the SATA2 spec, or you won't get the speed benefit.  So in other words, if you don't have the throughput, and I bet you you don't on that XS...



STEVE:  On the little X61s?



LEO:  Yeah, because that's a few years old.



STEVE:  Yeah.



LEO:  So you're not seeing - in other words, the drive's faster than your pipe.



STEVE:  Right, than the interface is.  Yup, that makes sense.



LEO:  Because you do see benefit, of course, because the access time is virtually zero because it's random access.



STEVE:  Yup.



LEO:  And the read speeds are very, very fast.  And I'll tell you, on the Mac, I boot from it, and the boot time has come down to almost nothing after the power-on self-test.



STEVE:  Oh, nice.



LEO:  Once it actually starts, it hits the drive, it's [sound effect], we're here.



STEVE:  Ah, cool.



LEO:  Now, I'll tell you, I just ordered a new Dell laptop for running Windows 7 that only has solid-state drives.  And I'll let you know if I see a similar thing.  It may be that Windows, because of the nature of its boot process, maybe there's a lot of thinking involved and stuff, might not benefit.  But, boy, the Mac does.  You don't see, I mean, applications launch instantly.



STEVE:  Wow.



LEO:  And it's - you get kind of used to it, I have to tell you.  I have to tell you.



STEVE:  Well, so he says he's "looking to get a new SSD drive, but not for another five months.  And my current drive has to hold me over until then."  And he said, "Unfortunately, my not-very-old Raptor drive began to fail, and I hoped SpinRite might help.  And considering that it was a Raptor," which I guess he must mean was expensive, "it was more affordable for me to get SpinRite.  Well, SpinRite worked very well and got me back up and running within two hours.  Excellent product, Steve.  Regards, Kelly Stowell, Windsor, Ontario."



LEO:  Isn't that nice.



STEVE:  So thank you for the feedback, Kelly.  Appreciate it.



LEO:  Another happy SpinRite customer.



STEVE:  Once again.



LEO:  Once again.  Well, it's not surprising.  We use SpinRite on everything here before we use those drives, before we put them into use.  Because it gives me...



STEVE:  Do it preemptively.



LEO:  Yeah, it just gives me that sense of confidence.  We really hit our drives hard.



STEVE:  Yeah.  Oh, you're using them like crazy.



LEO:  Oh, we go through a lot of them.  But also we record video direct to them, I mean, it's really - they're getting exercised.  So it's important to us.



All right, Steverino.  Are you ready, my friend, for questions?  Endless questions for Steve.  But we've picked 10.



STEVE:  And #10 is the Security Screw-up of the Week.



LEO:  I love those.  Oh, I love those.  Starting, though, with Marv Schwartz at Case Western Reserve - very good school, very good tech school - commenting on the Mozilla/Firefox plugincheck that we talked about last week: 

Steve, by now you already know, I would guess, that in order to get www.mozilla.com/plugincheck to work with NoScript - that's that plug-in that you use, that you recommend to protect yourself against JavaScript exploits - you have to allow both www.mozilla.com and - and here's the little catch - www.mozilla.org.



STEVE:  Yes.



LEO:  That's where the plugincheck comes from.



STEVE:  Yes, exactly.  And I've mentioned to you when we talked about this, and again I recommend this for Firefox users, it worked for you, it wasn't working for me.



LEO:  Aha.



STEVE:  And I had enabled Mozilla.com.  But then if I'd just looked again at the little NoScript icon, I would have seen that it said, oh, there's something else that I'm blocking.  And then you click on it, and I did when I saw his note.  It's like, oh.



LEO:  Duh.



STEVE:  Doh.  And then I enabled Mozilla.org; and, bang, it all worked perfectly.  So if anybody else got caught out by that, whom I've recommended NoScript to, who are NoScript users - and I know many of our listeners are because they really do, they're as concerned as I am about the issue of scripting - that that's the little catch. They probably were a little more on the ball than I was and noticed that Mozilla.org also had to be enabled.  They are now both for me, and the plugincheck works great.  And it turns out that I did have one out of 12 that was back versioned.  I had an older version of a QuickTime plug-in for Firefox that was no longer current.  And so it was like, oh, good, how would I have known that otherwise?  So, as we know, when they go to the next major version of Firefox, which will be 3.6, it will incorporate this automatically.  It'll show you if plug-ins on the pages you're visiting are back versioned.  It'll let you know that.  But again, Mozilla.com/plugincheck is a great service from the Mozilla guys.  But you do need both Mozilla.com and Mozilla.org enabled for scripting.



LEO:  Is there a pop-up that tells you, or something, that you're getting content from a different page?



STEVE:  Well, actually on NoScript the little icon notifier down in sort of the equivalent of the tray down there in the lower right, if it's blocking the main page you get like the big red slash through the icon.  And then, if you enable the main page but subsidiary things are being blocked, it's a much smaller - in my case it was a little too small, but when I knew to look for it, it's like, oh, of course.  It's just sort of a smaller thing saying the page you're visiting we're allowing scripting on, but we've blocked scripting from somewhere else.  And in this case it was scripting from Mozilla.org.  And it's, again, trivial to enable it.  And I made them both sticky because I trust Mozilla.com and Mozilla.org.  And this way, of course, with NoScript, if I'm rambling around the 'Net somewhere, I don't have scripting enabled.



Oh, speaking of which, I want to confirm that we do have John Graham-Cumming, who had to back out last week from our having him on our planned episode 221.  He will be on 223.  So he is our guest next week to tell us in depth about JavaScript security.



LEO:  Oh, excellent.  That's fantastic.  Yeah, I can't wait.



STEVE:  Yeah, it's going to be great.



LEO:  Question 2, Paul in London, Ontario, Canada wonders about making online banking safer.  He says:  Hello, Steve and Leo.  Long-time listener.  Love the show.  You both are doing a great service, and I appreciate your podcast every week.  Thank you very much, Paul.  My question is my bank is offering a program called Rapport by Trusteer to help protect my online banking transactions.  I was just wondering if you have any information you could share about the program, and if it's needed when I do my online banking.  It raises the question of why is my bank offering this?  Don't they think their security measures are enough?  The bank I use is President's Choice Financial in Canada.  Thanks in advance if you use my question on the show.  You guys are great.



And Steve, could you make your own OS?  Call it SOS - Steve's OS - and it can save all of us from the other choices.  I'd use it.  An OS built from the ground up with security in mind?  P.S.:  I have a copy of SpinRite.  I got one problem, though, Paul.  It'd probably look like DOS, I've just got to warn you.  Certainly be a command line OS.  I have a copy of SpinRite, and it has saved my bacon a number of times.  Great product, Steve.



STEVE:  Yeah.  The problem with Steve's Operating System is that it would - we'd all be old and grayer than we already are.



LEO:  Well, you're going to write one, aren't you, for the PDP-10?  Or 11?



STEVE:  I'm going to write one.  But no one will care.  I mean, you know, except five other people who still have old PDP-8s alive and running.  But...



LEO:  Oh, that'll be fun.



STEVE:  It really will be fun.



LEO:  That's a good - that's your retirement hobby.



STEVE:  It's my retirement hobby, exactly, exactly.  But, so, yes, unfortunately not mainstream on the OS side.  It's just too big a project, really, for one person.  And to do the kind of job that needs to be done, it would take forever.  But relative to Paul's question, this Rapport by Trusteer is something I've run across a few times.  And it's interesting.  It's an alternative to what we've been talking about.  We've been talking about the fundamental problems of the browser and server security.  So this Trusteer is a company that's a third-party offering that hardens browsers on behalf of their clients.  In this case their client is the bank.  So the bank offers this Rapport service.  And essentially it is a plug-in, a toolbar that you add to your browser.  And what it does is it basically does everything they can think of for hardening your browser.



For example, it's very much like sort of now we have in the most recent browsers we've got private browsing where history of the things we do are not left behind on the machine.  Nothing is written to the hard drive or into the file system, but it's kept in RAM.  They actually - they have some DNS hardening technology so that you're not prone to DNS spoofing.  They don't go into great technical detail about what they've done.  But they make it very clear that they understand that the openness of the APIs in our contemporary browsers, which is what allows toolbars to know where you're visiting and what you're typing, you know, those kinds of APIs are being leveraged by hackers in order to gain access to what you're doing.



So this is a very good thing.  This is something, when Paul asks why is my bank offering this, don't they think what they're doing is enough, I would argue that the bank recognizes they don't have the kind of control over the other end of their connection.  They can have a super-secure server and have their end all bolted down really well.  But if the user's got malware in their computer that's doing keystroke logging and things, basically the bank is having to rely upon the integrity of the browser which they're using to interface to them.  So I like this idea.  Instead of, for example, the bank developing their own wacky individual application to talk to them, they're saying, okay, we're going to use a third party who's got all the technology, bringing this technology to the table of hardening the browser.  So I think it's a great thing.  And they've got a whole bunch of banks that are lining up behind them and using this technology.  So...



LEO:  This is good.  I didn't realize when you mentioned it.  This sounds like something really good.



STEVE:  Yes.  I mean, this is a beautiful reaction to the fundamental problem that we've been talking about for the last couple weeks of the whole browser model just being prone to abuse.  And so these guys are coming along and saying, okay, we're going to - they use words like "vault" and so forth to say we're not letting your data escape through the browser APIs, where the openness of the API is normally something that allows you to leverage the power of the browser, because in this case you don't want openness.  You want this thing to be closed and bolted down while you do banking.  And so this is an add-on for browsers.  I think it sounds great.



LEO:  Yeah, I'm kind of a fan of sticking to your knitting.  And if somebody's really good at security, they become the people who do it; right?



STEVE:  [Laughing] Sticking to your knitting.



LEO:  Sticking to your knitting.  The bank should do what it does best.  Every bank cobbling a solution together is not a good idea.  I think you're exactly right.



STEVE:  Exactly.



LEO:  And then we only have to vet one solution and feel secure with that.



STEVE:  Yup.



LEO:  That seems like a good way to go.



STEVE:  In fact, we'll be talking to sticking to your knitting here in question #4, as well.



LEO:  Good, okay.



STEVE:  I love that.



LEO:  Before we get there, Abhi Beckert in Cairns, Australia has a Mac OS "10" tip:  Hi, Steve and Leo.  Have you heard of the ClickToFlash plug-in for Safari on the Mac?  I haven't.  It's a free open source plug-in which disables Flash by default, replacing all Flash objects in the page with a simple box.  Then you click to load the actual Flash object.  There's something similar on Firefox on the Windows and Mac side, as well, I believe.  I'll find out for you.  Apple has reported that Flash causes more crashes under Mac OS X than every other Mac application combined.  Now, we should mention that Apple doesn't like Flash and has been trying to kill Flash for some time.  It honestly doesn't surprise me that Flash has so many security holes.



ClickToFlash reduces Flash use only to those times when I want it - a video, a photo gallery - and eliminates Flash banners and Flash cookies altogether.  Oh, I'm going to have to install this.  I never allow those Flash objects to run.  It's a great security tool.  I use it on both my desktop and laptop.  As a side benefit, my laptop runs noticeably cooler and with better battery life.  I think there is a similar plug-in for Firefox.



STEVE:  Yeah, so I just wanted to mention that.  I wanted to notify you and the Mac users who are using Safari who didn't know.  This is the kind of thing which I just think is a good idea.  It's going to lower your bandwidth.  You're not downloading Flash objects.  Flash, I mean, Flash is one of our constant problems that we're reporting from a security standpoint.  So if you don't mind your page having, like, big dead spots all over it where normally all kinds of Flash animation is running, I know it's a huge relief for me to have Flash disabled as I do by default.  And then, if I'm going to somewhere where Flash is the reason I'm going, then it's like, okay.  You click on it, and it runs.  



LEO:  You just enable it there, yeah.



STEVE:  And I'll tell you, it's strange when you get used to your pages not being loaded with these really obnoxious sometimes Flash-animated ads, and then you go to someone else's machine that's running a generic browser where Flash is active, and stuff is jumping around, and frogs are coming out of the ads and all kinds of strange things are happening. It's like, oh, boy.  Yeah, it's just better not to have it unless you want it.



LEO:  And Web905 in our chatroom tells me, and I remember this now that he mentions the name, that the Firefox add-in that does the same thing is called Flashblock, one word.  It's just like NoScript for Flash, basically.



STEVE:  Exactly.



LEO:  Yeah.  And we know how you feel about that.  Well, I mean, this is one I would run.  I think this is, you know, Flash is kind of a blight on the web, to be honest.



STEVE:  It's gotten carried away.  It's like now there's escalation of who can make the most annoying, visually attention-grabbing ads.  And, I mean, somebody should look at the page, and you hope you don't have epilepsy because this thing might trigger a seizure.  It's just nuts how far it's gone.



LEO:  There's a move afoot.  One of the reasons Apple doesn't like Flash is because it's owned by Adobe.  And there's a move afoot to move to an open standard that will allow this kind of animation in video and so forth in HTML 5 using vector graphics, SVG.



STEVE:  Scalable vector graphics, yup.



LEO:  And you can do everything.  I mean, I've even seen demos on YouTube's site where they don't use any Flash, and it's just as good.  In fact, it's better.  It's just that the browsers have to come along and support HTML 5.  As they are rapidly doing so.  I don't know if it'll be any more secure, though.



STEVE:  [Laughable] Well, we'll have...



LEO:  At least it'll be open.  I mean...



STEVE:  There'll be problems in the SVG implementations until we get those bolted down, so...



LEO:  But they'll be open, and people will be able to look at them, and I think that helps a little bit, than having just a kind of opaque box.  Question 4, Paul in Lancaster, PA wonders about custom apps versus commercial apps:  Steve and Leo, the story of the Starbucks employee whose computer got infected by visiting a knitting site - he stuck to his knitting, and look what it got him - raised an interesting question for me.  Is it better to write a web application like a forum or an online store from scratch, or to use an off-the-shelf system?  Well, we know what Steve does, but anyway.



The way I see it, custom apps allow the programmer to put in just the level of functionality they want without having undue complexity.  And as you say, Steve, complexity is the enemy of security.  But off-the-shelf apps may be more secure because they're either open source, meaning there are theoretically more eyeballs looking for security holes, or they're commercial applications, meaning the company's reputation is at stake if they release an insecure application.  I'm interested in hearing your opinion on this.  Thanks for the great show.  Yeah, he's clearly stated the pros and cons here.



STEVE:  Yeah, he has.  And I think, I mean, he raises a good question.  One of the liabilities of using a custom app is that when a problem is found in it, then the bad guys go looking for all the instances of it they can find because they've got an exploit that then they can multiply across all of the instances of the websites that are using that app.  So that's a downside.  In general, for most people, I think that the pro side of using custom, I mean, of using commercial apps probably wins because, as Paul says, you get the benefit of many people looking at it, of a company behind it whose reputation is, I mean, really stands to be tarnished if they make a mistake.



I would say you absolutely want to stay on the security upgrade train if you're using a commercial app.  Make sure that you keep it current because we know for example many instances where commercial or open source code tends to get static on a server while the code is being moved forward and being made much more secure.  If you're running something four years old, then you've got a huge number of holes accumulating that bad guys can take advantage of.  My approach, obviously, as a serious coder, is I want to do my own.  I want it to work the way I want it to.  As he says, I want only the features that I want.  You know, for example, my eCommerce system doesn't have the cart model because I just - or you don't have to sign up and subscribe and create an account.  I find that kind of eCommerce site really annoying.  If I imagine I'm just going to go somewhere once, I don't want to have to go through a whole bunch of rigmarole just to buy something.  I want to buy the software and get out of there.



So I really do think that there are pros and cons.  But in general, for typical programmers who are not serious major security-aware people, there is a chance you can - a very good chance because being secure is so difficult, writing secure code is so difficult, there's so many ways that you can be caught out, that if there was ever someone who really wanted to penetrate your site and focus just on your site, the exposure that you have, I think, if you do something yourself is much greater than if you use a commercial solution.  But then promise yourself that you're going to keep it current, and really make the time somehow to keep the code on your server current.  That's so important.



LEO:  Good answer.  Question 6.  Lex Thomas in Research Triangle Park, North Carolina, is reminded of a programmer's adage.  We've got to do more of those security sayings, by the way.



STEVE:  The security maxims.



LEO:  Yeah.



STEVE:  Yup.  We've got a bunch.



LEO:  Good, yeah, someday - is reminded of a programmer's adage from 1984:  While reading some articles talking about the just-released Windows 7 and the imminent Ubuntu release, I stumbled upon an old programmer's adage which was attributed to Datamation magazine.  I remember that.  Quote, "The activity of debugging, or removing bugs from a program ends when people get tired of doing it, not when the bugs are removed."  Datamation, January 15, 1984.  For those who are waiting for Microsoft to quit having Patch Tuesday, I'd say they are waiting for Godot.



STEVE:  It's funny, I love that quote.  And I think it's so true.  And it reminded me of something that I read that I've always really appreciated, that Donald Knuth wrote in the preface to a book of his.  Now, of course we know Donald Knuth.  He wrote the famous - I've got them behind me, you can probably see them in the video...



LEO:  I see them, yeah, I recognize the binding.



STEVE:  ..."The Art of Computer Programming."  Of course Don was the designer of Pascal, which was a language deliberately created for teaching programming and meant to really help convey the concept of block structuring and programming without go-tos and the notions of programming.



LEO:  I thought Niklaus Wirth did Pascal.



STEVE:  Oh, gosh, what am I - of course.



LEO:  He did MIX.  Knuth wrote most of that book in a kind of a faux assembler called MIX.



STEVE:  Exactly, a pseudo assembly language, you're completely correct.  I got the wrong author here.



LEO:  Who could forget Niklaus Wirth?



STEVE:  Anyway, in his preface - and this is his book on  Metafont, which is a huge program.  Metafont is Knuth's typesetting system.  And he said, "My goal in this work has been to write a computer program of which a professor of computer science might be proud" - which of course he is - "in spite of the fact that the program must meet real-world constraints and compromises.  I've tried to explain thousands of details as well as possible, using the best documentation tools available.  Since I have learned much in the past from reading other people's programs, I have also tried to make my own program sufficiently stimulating that it might give a bit of pleasure to its readers.  There aren't many jokes, but several of the algorithms are amusing and/or amazing."



And then here's the point of this, which is what I loved.  He said, "I believe" - now, this is a huge program, Metafont.  I mean, it's big.  He says, "I believe that the final bug in Metafont was discovered and removed on January 4, 1986.  But if somehow an error still lurks in the code, I shall gladly pay a finder's fee of $5.12 to the first person who discovers it."  And he said, "(This is twice the previous amount" - of course he's going in powers of two, so 512 cents - "and I plan to double it again in a year.)  You see, I am really that confident."  And I love that because it's his belief that this is bug-free code.  But it took a professor of computer science who did nothing for years but carefully, carefully writing this one program to produce something that he believes, and apparently it's been pounded on substantially by a large number of people, to be absolutely bug-free.



LEO:  It'll be the first program in history, however.



STEVE:  It's, well, it's because it is - we know that complexity is the enemy of security.  And complexity is the source of so many bugs.  It's just it's difficult to make a perfect large piece of code.



LEO:  It's interesting that he asserts that it's perfect.  That's kind of interesting.  I never heard that.



STEVE:  Yeah.



LEO:  Hmm.



STEVE:  We skipped #5, by the way.



LEO:  Oh, well, let's go backwards.  Thank you.  I'm upside down.  John in Baltimore, Maryland.  Oh, yeah.  Sorry.  He's wondering about SSL certificate strength and key length:  Steve, a recent discussion of SSL and man-in-the-middle attacks got me thinking when I needed to update my website with a new SSL web server certificate that uses 1024-bit key length.  I noticed that both the Entrust Root CA and the Intermediate CAs use 2048-bit key lengths.  My question involves the SSL certificate key length of 1024 used by many websites like Bank of America, PayPal, et cetera.  Is 1024 adequate, and for how long, given the evolution of computer power?  Is it time to consider 2048 bits for standard SSL certificates?



STEVE:  It's a great question, and it's something we've never really touched on before.  First of all, one of the confusing things is these key lengths, when we're used to talking about key lengths like 128 bits.  The reason this is confusing is that these are public key lengths as opposed to symmetric cipher key lengths.  The key lengths for symmetric ciphers, due to the nature of the way they work, are much shorter to offer an equivalent amount of strength.  So, for example, today a 64-bit key length like DES, for example, a very old cipher - actually DES is 56 bits.



LEO:  And an old broken cipher, at that.



STEVE:  Yes.  Well, breakable.  I mean, the block size is 64 bits, so it uses a 64-bit block.  And that's now regarded as too few bits to encrypt at once because there just aren't that many combinations of 64 bits.  Well, it's 2^64.  But still, that allows you to, with modern-day computers and memory, to begin to build a table, even if it doesn't include the entire table, enough of it that you can begin to find collisions.  So 64 bits is not a long enough block size, that is, enough bits to encrypt at once.  Now we're at 128.  And the key length of DES is a 56-bit key.  Even 64 is regarded as, eh, we'd like it to be bigger.  I mean, still that's a lot of - that's a large number of keys.  But now 128 bits is considered a safe minimum for a symmetric cipher.  But all the key lengths change when we talk about public key technology, that is to say, an asymmetric encryption and description where we use different keys to encrypt and decrypt.



Now, in John's question, he notices that typical SSL web server certificates are using a key length of 1024, 1024 bits.  What's important here is that they're also all expiring within a couple years.  That is, the keys that are issued by the root certificate authorities like VeriSign, Entrust and so forth, they all have expirations of one, two, and typically three years.  I haven't seen any that are longer than three years.  So it's that expiration length which allows them to get by with a 1024-bit key length because they know that no matter what happens, that certificate will expire within three years.



The reason the root certificate authorities themselves have doubled that key length, 2048 bits, is that the certificate authority generally has expirations way out in the future.  I seem to remember 2038 and sometimes even further out than that.  So their signing, their key needs to remain secure for decades.  So as a consequence, just as an extra security measure, I mean, it might well be that 1024 would be enough for them.  But they're saying, you know, we don't know what's going to happen between now and decades from now.  So let's sign our certificates with a double-the-length 2048 bits because we are confident that that will allow us not to worry between now and the year 2038 or whenever their certs expire, sometimes even further out than that.



LEO:  And now that machines are so fast, it's not a heavy burden to have double the bits.



STEVE:  Exactly.  I mean, the public key technology is a lot slower, but you don't have to do it very often.



LEO:  Right.  We got Tim Lemmon in Atlanta, Georgia.  He tried to give Disney the knuckle.  We were talking - it'll come back to you.  Steve, my family went to Disney World three years ago.  When entering any of the theme parks, we had to swipe our membership card and scan our index finger for entry.  Disney thinks it's like the Homeland Security or something.  Then I heard one of your podcasts about the subject.  I always said I'd try my knuckle if I ever went back.  Remember somebody did this instead of this.



STEVE:  Yeah, we objected to the idea that just for something like going through a security kiosk at a theme park, that anybody would be getting your fingerprints.



LEO:  Terrible.



STEVE:  I mean, that's personal biometric information.



LEO:  Yeah.  So give them the knuckle.  Last week we tried it.  The entrance wasn't busy, so I swiped my card, then firmly pressed my index finger knuckle on the glass plate.  System didn't like it, so I tried again.  Same response.  Third time didn't work.  By then one of the employees noticed I was "having difficulty" and came my way to help.  So I gave in and scanned my actual fingerprint.  The system let me through with no trouble.  Based on these results I have to assume, one, the system's programmed well enough that it realized there was not an actual fingerprint to scan; two, the system had retained my original fingerprint scan on file from three years ago, and my knuckle wasn't even close; or both.  I started to ask the Disney employees, but quickly realized they had no idea.  Makes you wonder what's really happening with the fingerprint scans; doesn't it?  Of course the point of that is to match, to make sure you're the same person.



STEVE:  Yes.  Unfortunately, and this is annoying, it's very likely that they do have his original fingerprint, and they've retained it for three years and will probably retain it forever.



LEO:  In some insecure database, stored in the basement of Disney Central.



STEVE:  With employees who are as clueless as the turnstile employees, who didn't realize what was going on, in charge of that data.  I mean, it is a concern.  The problem of using your knuckle is probably getting a knuckle match the next time you go through three years later.



LEO:  You have to start with your knuckle.



STEVE:  You've got to, exactly.  Never let them have anything but your knuckle.



LEO:  Yeah, that's - the damage is done, in other words.



STEVE:  And remember which knuckle.  Yeah, I mean, exactly.  And I guess probably they're not wanting you to, like, share your card around with other people.



LEO:  I'm sure that's the real reason.



STEVE:  Yes.



LEO:  And, you know, come on.



STEVE:  So the only thing I could suggest is, if you wanted to use a finger, don't use the finger they recommend.  Don't give them your index finger.  That seems to be the most often scanned finger.  Or don't give them your thumb.  Give them your little finger, give them your pinky because the system will probably think, wow, this is a small guy.  But, you know, who cares what the system thinks.  And but my sense is, from all the fingerprints that I've seen, a knuckle looks pretty much convincing unless you had some, I mean, it wouldn't fool a human.  But I would imagine, if you'd always given it your knuckle from the beginning, it would probably say, okay, this is the same knuckle we saw before.



LEO:  It's a weird fingerprint, but I'll take it.



STEVE:  Let the guy through, yeah.



LEO:  Let him through.  Or use your pinky or something.  Something that won't be of use to anybody.  Eric, reporting from an undisclosed location, asks about port knocking, SSH security, and Security Now!:  Steve, your show is great.  I've been listening since you first started putting out the series.  I'm so glad you've been doing it.  Thank you.  I'm at a university and recently had someone hack into my SSH server.  Ooh, that hurts.  I was using freeSSHd for Windows XP.  It was very strange in that it didn't appear to be someone who got in by brute force.  Oh, even worse.  It was a first attempt from a particular IP address, and there was no password or username entered into the log, just a connection attempt, and boom, there they were, connected.



Since then I've been working to reformat the drive in case they put a keystroke logger or other malicious software on it, and put up more secure SSH infrastructure.  But it'd be great if you could spend a few minutes doing a roundup of SSH best practices, specifically something you spoke about many years ago, port knocking.  Is it a combination of stealth mode, port knocking, moving the SSH port to something other than 22, et cetera?  What is it you recommend?  Many thanks.  Eric.



STEVE:  Well.  First of all, if someone gets into your system, then you can't trust your logs.



LEO:  Right.



STEVE:  That's one of the first things that forensic security guys know is that your logs are useless, unfortunately, if your system has been hacked.



LEO:  The first thing a hacker does is mess with the logs.



STEVE:  Exactly.



LEO:  Cover their tracks.



STEVE:  Exactly.  The first thing they do is to clear the logs in order to prevent you from really understanding what it was that they did to get in.  So there's really no reason to believe that, from the logs - you just can't trust anything.  So from that point it's not clear whether they used a password or not, how many times they pounded on it.  I will say that I've heard many people who have SSH running on port 22, the default port for SSH, that the amount of connection and brute-force attempts to get in is stunning.  So this is something that is really happening on the Internet now, and increasing.  It's going up over time.



So no matter what else you do, there's nothing I would recommend more than not using port 22.  I mean, that's the default port, so it's the last place you want to run your SSH server.  It's trivial to change the port to something else.  So, I mean, absolutely do.  Some people might say, well, isn't that just security through obscurity?  It's like, well, this is an instance where you've got massive scanning going on across the Internet of port 22.  So why leave yourself open as a sitting duck and allow someone to connect to you?  Clearly you need a very high-strength username and password because what they're going to be doing is just running through a password dictionary, trying to think of anything they possibly can to get in.  And in an unattended system, or a system that you're not watching, they can be sitting there, pounding on your SSH server, trying to get in.



So absolutely put the port somewhere else.  You'll notice, if you watch your logs, all connection attempts disappear.  And so, sure, someone could scan all the ports at your IP, find a TCP connection being accepted there, and pound away on it.  But they don't know what TCP connection it's going to be.  And the probability of that happening is vastly lower.  So it certainly makes sense not to run a known service at a known port unless you have to.  You have to run web browsers at 80 because it's - well, practically - because it's really an annoying thing to tell users, oh, go to John's website, but then put :2637.  And people go, huh?  What?  You know, the colon is the override where you tell you browser to connect, not to the default port of 80, or in the case of SSL of port 443, but rather to some random port that you specify.  That's just not practical.  But for your own SSH server, by all means move it somewhere else.  Clearly, you want a username and password that will stand up to brute-force hacking.  That goes without saying because you're inherently wanting to expose this to the Internet, which means here's an exposed service, you've got to protect it.



Now, port knocking we've talked about a couple times.  It's a clever approach which allows you to use some other system of arriving packets at a given IP to open a port.  Essentially, the idea would be, for example, you might try to connect to a certain port at the IP, then do a different port, then do a third port, then do a fourth port.  And only after four attempts at specific ports in a specific sequence is then the actual port that you want to connect to made available.



The point is that connection attempts are TCP SYN packets arriving at that IP.  So if you had something, for example, monitoring your router's log, the log would notice that you received a SYN packet.  It would add an entry in the log that a SYN packet was received from a certain IP.  And then when you remotely tried to connect to a different port number, it would make that entry in the log.  So if you had something watching the log, it could look to see whether a sequence of attempted connections to closed ports - these are ports that aren't even open.  They're just dead.  So they're not going to respond.  But they'll still make an entry in the log.



So by deliberately connecting to a specific sequence over time, that's a way of keeping your port closed.  And given that we've got 65535 ports, so that's one less than 16 bits' worth of ports, if you had a sequence, for example, of four different ports you had to try, that would be 2^16 times 2^16 times 2^16 times 2^16.  Which ends up being 2^64 possible combinations, minus a tiny bit because you don't have a port 0.  So that's a huge number of possible knocking sequences, just to get access to the service you're protecting, before you have access to it.



So it's a very interesting technology.  I mean, port knocking is something, you can Google it, you'll find open source software.  There are people who are using it to protect services.  So, yeah.  I mean, that's additional security if you've got a service exposed.  And of course I did a little bit of Googling.  I was wondering about just the overall security of freeSSHd.  And just a couple weeks ago there was an announcement of a denial-of-service attack that's preauthentication.  Which is to say that there is something people are doing which is crashing that service before they authenticate.  Well, we know what that means.  That means that maybe it's possible to do some sort of a buffer overrun before you've authenticated.



And in fact, if since that has happened someone has figured out how to crack through freeSSHd, it may be that it is in fact possible to bypass the whole username and login process using a buffer overrun which has not yet been widely disclosed.  We may be right in the verge of, like, a new zero-day exploit for this freeSSHd daemon.  So that's something you want to watch for, too.  It's, again, another reason to get off of, no matter what you do, get off of port 22.  Put it anywhere else.



LEO:  Wow.  I have to go change some SSH servers.  I'll be right back.  We're running them in Linux, though, and I think they're pretty hardened.  But, hmm, it's good to know.



STEVE:  Yeah.



LEO:  Question 10, our last question, and it is the Security Disaster of the Week.



STEVE:  Actually question 9 is our next one.



LEO:  Oh, you're right.  Then question 10.



STEVE:  And it's a special...



LEO:  I'm all out of order.



STEVE:  We have a special treat for you, too, Leo.



LEO:  Oh, good, okay.



STEVE:  It's there in red.



LEO:  Oh, okay.  How exciting.  Let's start with Joe Dorward.  He says he doesn't mind if I do this in Scottish.  I might mind.  Others might mind.  He lives in Berkshire, England, and he realized that the free Internet access at the British Library may not be safe.  Steve, I was at the British Library in London last week, and there were people everywhere with laptops.  Very few had books open.  And I realized they were only in the library to take advantage of the free WiFi Internet access.  He gave us a long URL here.



STEVE:  Yeah.  It doesn't matter.



LEO:  Bl.uk/whatson/planyourvisit/wifi/wififree.html.  A hacker's paradise, I thought smugly.  They've no idea what they're opening themselves up to.  Then I realized - I'm sorry.



STEVE:  You're really good at that, Leo.



LEO:  No, I'm not.  If you're a Scot you're going, oh, that's awful.  It's like when you've heard Brits do American accents, and it's just painful to the ear.



STEVE:  Yeah.



LEO:  That's what this is.  Then I realized, in spite of listening to almost every episode of Security Now!, I understand the dangers of open WiFi hotspots, but I don't know how to take advantage of their free WiFi Internet access safely.  So here's the question.  Can you tell me what I have to do to use the British Library's free WiFi Internet access safely?  Or is it just crap?  No, I threw that in.  Let's assume the people running the network know what they're doing, and there's a bad person already connected.  How do we protect ourselves, Steve Gibson?



STEVE:  Well, we've talked about this a few times, so I apologize to our listeners who are going, oh, my god, we've already covered this.  But it's an important issue.



LEO:  It's worth doing.



STEVE:  Yes.  So I just wanted to say, again, the threat model is that you want to be safe there, where you've got unencrypted connections.  Open WiFi means that there is no encryption in the local hotspot.  So that, because it's an Ethernet, inherently, anybody with a laptop who has a modified WiFi adapter, which are easily found and available, can listen to all the traffic that is transacting there in the library.  So anybody who is not otherwise secure is sending their email sometimes, well, many email passwords are not over secure connections.  So standard POP and SMTP are nonencrypted connections.  So anything that's not encrypted is going to be in the free and completely sniffable.



So really all you have to do is make sure that the stuff you don't want anyone to be able to access is over an SSL connection.  SSL is your friend.  It will protect you.  So, for example, if you're using Yahoo! Mail, Hotmail, Google Mail, any sort of web transaction where you're concerned about security, make sure that you have a persistent SSL connection.  If you want more than that, then this is where you need some sort of a VPN solution.  We've talked about Hotspot VPN, which is OpenVPN based.  And there are, you know, any kind of VPN, this is really what they're used for, is then all of your traffic will be encrypted from the time it leaves your computer until it gets to the VPN endpoint, wherever it is.  Either a service on the Internet, maybe you have an endpoint running in your house, and so you link to your home, and then your traffic is decrypted there and goes out on the Internet in the clear.



So you just - you want somehow to have encryption active in that area where the danger exists, which is in this case where you're wireless until your data gets to the local hotspot that the library is running.  And so if you can arrange that, then you can use their free WiFi Internet access safely.



LEO:  And that's true of anywhere you are.  Any hotspot, that's the way to do it.



STEVE:  Yes.



LEO:  Finally - I'm sorry I got this out of order.  I got it right now, I think.  Eric Nichols in Odessa, Delaware, with the Security Disaster of the Week.  Subject:  FIOS WEP crack - say that three times fast - no packet sniffing necessary.  I've been a long-time listener.  I've heard a rumor that the ESSID of a FIOS access point is actually a packed version of the MAC address of its network interface.  That's a good way of generating unique ESSIDs.  However, they should have stopped there.  It turns out that the default WEP - yes, WEP - key is [fanfare] the MAC address of its network interface.  Doh.  I found this website with a calculate to decode the MAC address from the ESSID - does use JavaScript, be warned - http://fioswepcalc.webs.com.  For research purposes I tested it there.  Yeah, worked on the first try.  Pause for the collective groan.  Keep up the great work.  Say hi to Leo.  Oh, my god.



STEVE:  Okay.  So listen to what this means.



LEO:  Oh, my god.



STEVE:  This is so bad.  So they said, okay, we know that MAC addresses are going to be unique.  So just to remind our listeners, a MAC address is a 48-bit thing which is 24 bits is assigned to the manufacturer and then 24 bits is incremented by the manufacture; so that all of their interfaces that they make, 24 bits' worth of Ethernet interfaces will all have, when concatenated with their manufacturer-assigned 24 bits, will have a unique 48-bit MAC address.  That's important because packets are routed among the Ethernet from one MAC address adapter to another.  So you need to have unique addresses.  And so this concatenation of the 48 bits is the way that was solved.



So then they said, oh, let's base the SSID, that is, our wireless access points beacon ID, on the MAC address.  That way it'll be unique.  And everyone said, okay, that sounds like a good thing.  Unfortunately, they then, as Eric says, they took the MAC address and used it for the WEP key so that all of the Wireless Equivalent Privacy, WEP, the default WiFi, will have a different key, thinking that that was clever.  The problem is, of course, what they're essentially doing is broadcasting the WEP key through the beacon, the WiFi SSID, which anyone is able to get.  I mean, it's insane.  You know, it's...



LEO:  Well, talk about security through obscurity, they assume that you won't have sussed onto this, and so they're fooling you.



STEVE:  Right.  And there's some packing going on so that you need a little JavaScript in order to undo this.



LEO:  It can't be too complicated.



STEVE:  Well, no.  And so this FiosWepCalc.webs.com, I went there.  There's a little script that it runs.  And so the idea is you put in the ESSID that you get from the access point, and it tells you what the WEP key is in order to connect to it, right through its security.  Such as it is.  Security Disaster of the Week.



LEO:  Oh, my goodness.



STEVE:  Yes.



LEO:  Steve, a pleasure once again.  10 questions good and true.  If you want to watch us do the show live, we do it every Tuesday, I'm sorry, Wednesday at 11:00 a.m. Pacific.  That's 2:00 p.m. Eastern time, 1800 UTC.  Next week I'm going to ask if you can move, Steve, but I'll talk about that after we get off the air because we need to flip-flop with the Daily Giz Wiz.



STEVE:  We'll just have to tell John, since John Graham-Cumming is our guest next week.



LEO:  Oh.  I hope...



STEVE:  I think that makes it late for him.  But I have no problem.



LEO:  Well, let's see if we can do it Tuesday at 1:30 instead.  And if not...



STEVE:  Oh, you mean like change days.



LEO:  Yeah.



STEVE:  Oh, no problem at all.



LEO:  And time, a little bit.  Because the Giz Wiz, yeah, because Dick can't do it Tuesday, so he needs to do it Wednesday.  So you can watch us do it live next Tuesday instead of our normal time Wednesdays.  But, you know, forget the live, just download the podcast.  You can get it from iTunes, Zune, anywhere podcasts are offered.  And of course you can get it directly from Steve himself at his website, GRC.com, the Gibson Research Corporation.  He has 16KB versions.  He has transcriptions.  He's got show notes.  He's got the full version, too, all at GRC.com.  That's also where you go to ask questions like the ones we just answered - GRC.com/feedback - and to find SpinRite, Steve's fantastic hard drive maintenance and recovery utility.  Everybody should have it.  If you've got a hard drive, you should have SpinRite.



STEVE:  And you know what the slogan is for SpinRite.



LEO:  What is it?



STEVE:  It works.



LEO:  That's simple.  Short, but sweet.  And it's true.  Simple and true.  You can't get better than that.  GRC.com.  That's where ShieldsUP! is, too, and all the other great free utilities Steve offers everybody to secure their systems.  Next week, John Graham-Cumming.  This is going to be fun.  We're going to talk about JavaScript and why it sucks.



STEVE:  JavaScript Security, the oxymoron.



LEO:  I love it.  All right, Steve.  We'll see you then.



STEVE:  Talk to you then, Leo, thanks.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#221

DATE:		November 5, 2009

TITLE:		The Oxymoron of "JavaScript Security"

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		John Graham-Cumming

SOURCE FILE:	http://media.GRC.com/sn/SN-221.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo are joined by author and software developer John Graham-Cumming to discuss many specific concerns about the inherent, designed-in, insecurity of our browser's JavaScript scripting language.  Now 14 years old, JavaScript was never meant for today's high-demand Internet environment - and it's having problems.



LEO LAPORTE:  It's time for Security Now!, the show that covers all things secure and private and important, like that.  With us right now, the king of security, Mr. Steve Gibson from GRC.com.  Hello, Steve.  



STEVE GIBSON:  Hey, Leo.  Great to be back with you again for our 221st episode of Security Now!.



LEO:  Unbelievable.  We have a good show this week, too.



STEVE:  We've got a great show this week, absolutely.  We have a - we don't often do guests on the show.  But a friend of both of ours, John Graham-Cumming, whom we've mentioned a number of times, and of course he is the author of "The Geek Atlas," which we've talked about and both like very much.  He's going to be on because he did a - he gave a presentation to a recent virus conference.  The title was "JavaScript Must Die."



LEO:  Hmm.  This is right after your own heart, isn't it.



STEVE:  Believe me, this is - yes, exactly.  I've understood in broad strokes what the problems are.  John is going to tell us in painful detail why 14-year-old JavaScript just really doesn't cut it anymore.  And his thesis, that we'll discuss in a minute, is that there's probably no way to fix it.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Well, we're going to get him on in just a minute.  I'm sure there's some security news in the hopper.  So, Steve, what's been happening in the week since we talked last?



STEVE:  Well, we've got a little bit of news.  It's been relatively quiet.  One thing that I wanted to do, though, which sort of sets us up for today's topic, is we talked about the most recent set of security patches for Firefox, and also for SeaMonkey since they use a bunch of common code.  And Firefox 3.0 and 3.5 we talked about last week.  And I just sort of quickly glossed over those things.  But I came back and looked more closely at what went on.  And I thought, you know, it's one thing just to say, oh, update Firefox.  But it's interesting, I think, every so often to just say, okay, wait a minute.  Let's just take a look at what it was that happened in this one, just one of a continual procession of security fixes because it's very educational relative to today's topic of JavaScript.  And also you and I were not really sparring a little bit, but you were saying, wait a minute, you're still on 3.0?  You haven't gone to 3.5?



LEO:  Right.



STEVE:  So that sort of folds into this, too.  So there were 10 different things, major things that were fixed.  There was a form history vulnerability that would allow form history to be stolen.  A security researcher, Paul Stone, reported that a user's form history, both from web content as well as the smart location bar, was vulnerable to theft, so that a malicious web page could synthesize events such as mouse focus and key presses on behalf of the victim and trick the browser into auto-filling-in forms which it would then send to the server.  So without your interaction.  And that's one of the things that John will be talking about today, is that JavaScript provides no differentiation between things that it does and things the user does.  So JavaScript is able to perform on your behalf, which is convenient, but also creates vulnerabilities like this one.



The second problem was a crash with recursive web-worker calls.  Security research Orlando Berrera of Security Theory reported that recursive creation of JavaScript web-workers can be used to create a set of objects whose memory could be freed prior to their use.  Okay, so you're creating a bunch of things, then you're freeing their memory before you use them.  Well, that's not good because then you've got a memory problem.  These conditions often result in a crash, which could potentially be used by an attacker to run arbitrary code on a victim's computer.  And so this text is coming from the Mozilla site.  And so their site said, "Note:  Web-workers were introduced in Firefox 3.5."  So this vulnerability did not affect earlier releases such as Firefox 3.0.



The third problem, a crash in Proxy Auto-configuration regular expression - "regex" - parsing.  Security researcher Marco C. reported a flaw in the parsing of regular expressions used in Proxy Auto-configuration files.  In certain cases this flaw could be used by an attacker to crash a victim's browser and run arbitrary code on their computer.  Since this vulnerability requires the victim to have a PAC, a Proxy Auto-configuration file, configured in their environment with specific regular expressions which can trigger the crash, the severity of this issue was determined only to be moderate.  And the workaround was to disable JavaScript.  Number four...



LEO:  Of course, what else.



STEVE:  Of course.  There's a heap buffer overflow, remember we talked about it, in the GIF color image map parser.  In this case the security research firm iDefense reported a heap-based buffer overflow in Mozilla's GIF image parser.  This vulnerability could potentially be used by an attacker to crash a victim's browser and run arbitrary code on their computer.



Number five, a Chrome privilege escalation.  A Mozilla researcher reported that the XPCOM utility unwrapped doubly wrapped objects before returning them to Chrome callers, Chrome being not like Google's Chrome browser, but internal technology that Mozilla also happened to coincidentally call Chrome.  This could result in Chrome privileged code calling methods on an object which had previously been created or modified by web content, potentially executing malicious JavaScript code with full Chrome privileges.  The workaround for Mozilla?  Disable JavaScript.



Number six, a heap buffer overflow in string-to-number conversion that we've seen a couple times and talked about.  In this case a security researcher, Alan Rad Pop of Secunia Research, reported a heap-based buffer overflow in Mozilla's string-to-floating point number conversion routines.  Using this vulnerability, an attacker could craft some malicious JavaScript code containing a very long string to be then converted to a floating point number by the user's browser, which would result in improper memory allocation and the execution of an arbitrary memory location.  This vulnerability could thus be leveraged by the attacker to run arbitrary code on a victim's computer.  Mozilla says, workaround?  Disable JavaScript.



Number seven, cross-origin data theft through document.getselection.  And John will be talking about cross-origin problems in JavaScript.  Security researcher Gregory Fleischer reported that text within a selection on a web page can be read by JavaScript in a different domain using document.getselection function.  Now, these are supposed to - the origins of scripting is supposed to be separate.  But there's all kinds of problems with that not being done right that creates cross-origin, sort of like cross-server, leakage.  This violates the same origin policy.  Since this vulnerability requires user interaction to exploit, its severity was determined to be moderate, not severe.



Three to go.  Download filename spoofing with RTL, that's right-to-left override.  Mozilla security researchers Jesse Ruderman and Sid Stamm reported that when downloading a file containing a right-to-left override character in the filename, the name displayed in the dialogue title bar conflicts with the name of the file shown in the dialogue body.  An attacker could use this vulnerability to obfuscate the name and file extension of a file to be downloaded and opened, potentially causing a user to run an executable file when they expected to open a non-executable file.  So that could kind of catch out people who think they're more savvy and professional and know what's going on, like checking the filenames.  Except whoops, due to the way this is handled, it's possible to obfuscate the actual name of the file that you're downloading.



Number nine, we talked about the media libraries being upgraded.  It was called an upgrade, the media libraries, to fix memory safety bugs.  Mozilla upgraded several third-party libraries used in media rendering to address multiple memory safety and stability bugs identified by members of the Mozilla community.  Some of the bugs discovered could potentially be used by an attacker to crash a victim's browser and execute arbitrary code on their computer.  The liboggz, libvorbis, and liboggplay libraries were all upgraded to address these issues.  And then on the Mozilla site it said, "Note:  Audio and video capabilities were added in Firefox 3.5."  So prior releases of Firefox, such as 3.0, were not affected.



And finally, crashes with evidence of memory corruption.  I remember when we talked about this last week it's like, well, that seems sort of ambiguous.  But specifically it said that Mozilla developers and community members identified and fixed several stability bugs in the browser engine used in Firefox and other Mozilla-based products.  Some of these crashes showed evidence of memory corruption under certain circumstances.  And we presume that with enough effort at least some of these could be exploited to run arbitrary code.  Mozilla's workaround?  Disable JavaScript.  So...



LEO:  Now, how much of that is a problem with JavaScript, and how much of it is just a workaround that prevents people from accessing these other problems which aren't really JavaScript problems but can be addressed through JavaScript?



STEVE:  That's a very good point.  These are typically - these are problems in the browser which JavaScript is used to get access to.  So JavaScript is the means to using these mistakes.  It's the mistakes themselves that are the problem.  Now, what John is going to be talking about is different than this.  But what I wanted to highlight here is that there are new things that were added to 3.5 which are the sources of new problems.  So we've talked again, as we often do, the idea that anything new has a problem because it hasn't been proven.  It's just it's so difficult to design code securely that anything that you do, there's just going to be a certain percentage of the code that's going to have a problem.  So...



LEO:  Although as we've seen, everything old has problems, too.  It's not like, I mean, it's not - they're just a new set of problems.



STEVE:  Yes.  Well, okay, yes.



LEO:  I mean, it's not like old code is somehow magically better code.



STEVE:  I would disagree, Leo.  I think older code is better code.  Older code has had this kind of stuff pounded out of it.  But what we need is...



LEO:  Well, that's the question, is does it get pounded out, or does it just get pounded?  I mean, you can't say XP is safer because it's had many, many, many, many patches.  Because we keep finding holes in it.



STEVE:  Well, it's because people - no one leaves it alone.  We're still - it's not a static operating system.  Microsoft keeps messing with it.  98 is old, but solid, and isn't prone to being affected now.  I really do believe older code is better code than new code.  However, it's got to be old code that you leave alone, that you don't keep messing with.  And so XP continues to be brought forward because Microsoft's supporting it, and features that are being added in Vista and Windows 7 are still being backported into XP, which is destabilizing it.



LEO:  True.  True, true, true.



STEVE:  So it is significant, though.  Relative to Firefox 3.0 and 3.5, I wanted to mention to people that Mozilla has formally stated they are not going to be continuing to support Firefox 3.0, the Firefox 3.0 series, after January of 2010.  So only November and December, two more months of support for Firefox 3.0.



LEO:  Really.  That's all?



STEVE:  Yes.



LEO:  Wow.  That's pretty quick.



STEVE:  Yeah.  That does strike me as being quick.  I wanted to mention to people using the Opera browser to check for updates.  They're now at version 10.01 with a bunch of vulnerabilities.  I won't go into them in detail.  But there's a set of vulnerabilities.  They're publicly known and available.  So if you're an Opera user you definitely want to make sure you stay current there.



And then one bizarre bit of news.  I picked up on this on the Discovery Channel news.  Their security editor, Eric Bland, on the 28th posted an article that just captured my imagination.  The title was "[Digital 'Ants' Take on Computer Worms]."  "Digital ants could soon be crawling through your computer's hard drive, but don't worry, they are there to help."  And, okay, this is just too fun.



"Scientists from Wake Forest University and the Pacific Northwest National Laboratory have created an army of digital ants and their superior officers, digital sergeants and sentinels, to search out viruses, worms and other malware.  The new antivirus software could provide better protection while freeing up valuable hardware.



"'We are using the ants to sense something very basic, like a connection rate,' said Errin Fulp, a professor of computer science at Wake Forest University who helped develop the digital ants.  'Then we collect that evidence which points us to a particular infection or security threat,' said Fulp.



"Like their biological counterparts, each individual ant is not very bright.  A connection rate, CPU utilization, or one of about 60 other technical details is all they can sense.  When an ant detects something unusual, it leaves a digital pheromone, a tiny digital sense that says something" - oh, this is wacky.



LEO:  This analogy's gone a little too far.



STEVE:  "...a tiny digital sense that says something unusual is going on here, and that other ants should check it out.  The digital ants report any suspicious activity to a digital sentinel, a program designed to watch over a set of computers in a network.  The sentinel sorts through all the information the ants gather and, if it's suspicious, passes the information on to a digital sergeant.  The sergeant then alerts the human supervisor, who can deal with the problem.  The sentinels and sergeants reward the ants for finding problems.  If an ant doesn't find enough problems, it 'dies' off, although a minimum number is always maintained.



"If a particular kind of ant finds lots of problems, then more of them are created to monitor the problem.  The entire system is modeled off of a normal ant colony and uses 'swarm intelligence' to find and diagnose problems.  The beauty of using digital ants, instead of a traditional antivirus program, is their flexibility.  Traditional antivirus software usually scans constantly or on a set time schedule.  Constantly scanning for threats is effective, but uses a lot of computer resources, resources that could be better spent doing something else.



"Scanning at certain times, usually at night, optimizes computer usage, but it leaves a computer more vulnerable [in the interim].  Since the number of ants rises and falls with number of problems being detected, it can free up computer hardware to perform calculations when an attack isn't happening.  If an attack is happening, more ants can quickly be created to help deal with it."  So there you go, Leo.



LEO:  Digital ants.



STEVE:  We're going to have ants crawling around in our computers.



LEO:  Well, it's funny because John Graham-Cumming calls JavaScript the "elephant in your browser."  So this is really kind of a menagerie of problems here.



STEVE:  And I have to say, all of this starts making my PDP-8 computer look...



LEO:  Look better and better.



STEVE:  ...pretty good.



LEO:  Hey, if you never get on the Internet, you'll never have a problem.



STEVE:  That is, that is the case.



LEO:  Well, maybe never.  But you'll have fewer problems.  What else we got before we - should I get John on, or do you want to cover some errata first?



STEVE:  I'm not going to hold him up for long.  I have a brief errata and a short little SpinRite story.



LEO:  Okey-dokey.



STEVE:  My errata is titled "I hate Adobe."



LEO:  That's not an errata.  That's a facta.



STEVE:  Okay.  Get this, Leo.  I haven't had it happen a second time because I haven't used another machine.  But Adobe's Flash updater, with no apparent ability for me to stop it, installed a demo of NaturalReader.



LEO:  Oh, no, that's not right.



STEVE:  Now, there was a checkbox.  It also wanted to give me a free MacAfee security scan.



LEO:  No.



STEVE:  And I said no, thank you.  But then it says it's - I'm watching it update itself, and it says it's installing a demo of NaturalReader.  Well, first of all, I own NaturalReader.



LEO:  Oh, great.



STEVE:  I use the voice for various things.  So, and sure enough, on my desktop now - or was, I deleted it - but there didn't seem to be a way of uninstalling the demo.  It didn't leave...



LEO:  Oh, that's inexcusable.



STEVE:  Didn't put something in the Add/Remove Programs.  There was an icon it added to my desktop.  When I clicked it, and I made sure this was all legit, it popped open.  It was a web page that was running NaturalReader from my system.  And it's like, okay, wait a minute.  I mean, so this is nothing to do with Adobe Flash.  And this thing is installing demoware that I couldn't see any way to avoid.  I mean, this is really wrong.  So...



LEO:  What was the updater?  Was it your Adobe Reader updater?  I mean, what was...



STEVE:  It was the...



LEO:  The Flash updater?



STEVE:  It was the Adobe Flash updater.



LEO:  God.



STEVE:  And so I just, I wanted to put out a call.  I'm sure if other listeners had this happen to them, drop me a note at GRC.com/feedback.  Let me know if you saw the same thing.  This is just - at this point it happened to me.  I haven't seen anything more about it.  But it's like, oh, if Adobe starts doing this, then this is really wrong.



LEO:  Companies do tend to like to do stuff like that, just kind of auto-install software.



STEVE:  I know.



LEO:  Lately I've just made sure, you know, like very carefully when I'm installing software, especially free software, watching each window, say oh, no, I don't want the Yahoo! toolbar.  No, I don't want the - uncheck, uncheck, uncheck.



STEVE:  I know.  And by default they're checked, and you've got to go in and manually say, no, thank you, I don't need another copy of Google Toolbar installed.



LEO:  Golly.



STEVE:  Anyway, we did have a nice note from Martin.  He said, "Hello, Steve and Leo."  So he addressed both of us.  He says, "Not a great SpinRite story, but just a successful one."  He said, "My primary data print server started acting funny.  So I thought a reboot was in order.  Once the server turned back on, it sat and sat at the 'applying computer settings' screen.  Uh-oh.  A need for SpinRite.  So I ran SpinRite at Level 2.  It found two bad, unrecoverable sectors in the course of 30 hours.  Following the completion of the scan, a successful reboot was performed, and the server works perfectly now.  I've since reconfigured a new server for my data and printing.  But without SpinRite, I would have had a really tough time pulling my data off the old machine.  Like I said, just a plain SpinRite success story, a successful one.  Thank you for a great product."



LEO:  That's not so plain.  That's nice.



STEVE:  Yeah.



LEO:  It's a good feeling.  Let's get John on right now because he's been, poor guy, he's been waiting in the wings for half an hour now, and I want to call him.  I think he's in Great Britain, which means it's also getting later and later at night.



STEVE:  Yup.



LEO:  So let's get him on.  He's the author of "The Geek Atlas," which I love.  In fact, I will go get my copy of it to hold up as we talk to John.  It's really a must-see.  And he has a good website, too, which you can go to.  It's, let's see, JGC.org.  I'm just calling him up right now.



JOHN GRAHAM-CUMMING:  All right.



LEO:  There he is.  Hey, John.



JOHN:  Hello.



LEO:  Welcome to the show, John.



JOHN:  Now, do you see me all right?



LEO:  I don't see you yet.  But if you turn on your camera...



JOHN:  Maybe if I press this video button...



LEO:  It's a magic button there.  There he is.



STEVE:  And Leo, this is an authentic UK accent.



LEO:  As opposed to my crappy fake one?  Yes, it is.  John, it's great to see you again.  Welcome to the show.



JOHN:  You actually sound like an evil villain in an American movie, trying to be British, when you do it.



LEO:  Yeah, yeah.  Not good, I know.



JOHN:  Although somebody in the chatroom accuses me of sounding like an evil villain.  And I do actually have a white Persian cat.



LEO:  Uh-oh.



JOHN:  Which I could bring onto...



STEVE:  Uh-on.  Long as it's not on your lap, stroking it.



JOHN:  Not right this minute.



LEO:  Ernst Stavro Graham-Cumming.  So, Dr. Evil, welcome to the show.  This all started with a blog post.  And we put a little SnipURL, or Steve has, together, snipurl.com/javascriptsecurity, if people want to read it.



STEVE:  Yeah, John sent me a little heads-up to a blog posting of his, probably a subject that he knew already was near and dear to my heart, on his blog posting, where it's titled "JavaScript Must Die."  He said, "My thesis is that the security situation with JavaScript is so poor that the only solution is to kill it.  End-users have very little in the way of protection against malicious JavaScript.  Major websites suffer from cross-site scripting and cross-site request forgery flaws," both of which we've covered in this podcast in the past.  "The language itself allows appalling security holes.  And as data moves to the cloud, the 14-year-old JavaScript security sandbox becomes more and more irrelevant."



So, you know, I've spoken over and over and over about just the idea, the concept that a user browsing the Internet can go to a server, and that server can give their browser code, any code, of any kind, I don't care about the details.  The idea that you could go to a site you've never been before, and something remotely, who you don't know that you trust, can install code on the fly which your machine will run, in any fashion, creeps me out.  I mean, from a security standpoint there's just nothing good about that.  What I love about what John has done is he understands and knows JavaScript inside and out and can put meat on this fundamental concern I have, I mean, the idea that that's basically a bad idea.  And John can fill in the details.



JOHN:  Okay.  What an introduction.  So perhaps I should tell you just a little bit about this talk that I gave and the conference it was at because it sets the scene a little bit for what I was talking about, which is that this was given at the Virus Bulletin Conference in Geneva in September.  And Virus Bulletin is typically about viruses, malware, worms, all the sorts of things that come out of the virus industry.  It's a very hardcore conference.  There is a commercial track in the conference where you get some sort of commercial discussions, but it's really about technology.



And I had wanted to talk, I've talked at that conference quite a lot of times.  And I wanted to talk about something a bit different this year if they would let me, which was JavaScript security, because I thought that what was needed was a bit of a wakeup for people.  And this was a welcoming forum where we could talk about it.  And so in the presentation I pushed as hard as I could in, you know, claiming that JavaScript had to be completely destroyed.  And in fact I even, right at the end of the presentation quoted from, I think it's "Aliens," where she says we should take to the air and nuke the whole thing, to try and sort of get the point over that it is a very serious situation.  And what I did in the presentation was I went through some very serious examples of problems with JavaScript.  Now...



LEO:  That's something you don't have to do here because that's pretty much what this show is all about.



JOHN:  Yeah.  And of course as a listener I'm well aware that...



LEO:  It's about all we talk about.



JOHN:  You just have to say "JavaScript" to Steve, and he gets a sort of scared look on his face, as well.  But...



LEO:  Understandably.  Me, too, now, I have to say.



JOHN:  Well, you know, and to get things off to sort of a good start, the way in which I deal with it, just so everyone knows, is I use NoScript...



LEO:  Yes.



JOHN:  ...in Firefox.



LEO:  As does Steve.



JOHN:  So I whitelist the sites I really trust.  And then when I come to something I don't trust, obviously it's off.  And then if I need it, I'll do the "temporarily turn it on," just so I can take a look around at what's needed on that particular site.



LEO:  Just to provide complete balance, I should say I don't do that.  I use JavaScript on every platform, all the time.  I just boldly go where no elephant has gone before.  And you probably think I'm crazy.



JOHN:  No, I don't think you're crazy.



LEO:  Oh.



STEVE:  So give us a sense, John.  There are a number of things that you've touched on.  One was I loved this notion that you picked up on that the security model, which is now 14 years old, as is JavaScript, is no longer really protecting what we care about.



JOHN:  Right.  So if you go back in history, JavaScript security, the sort of defining areas of JavaScript security date to 1995 with early Netscape versions.  And at that time there were two big concerns.  There was a worry that a malicious website might attack your computer.  You know, the big worry was, okay, there's this JavaScript thing running in your browser.  Somehow it's going to get access to your documents folder and steal the letter you wrote to the bank or something like that.  That was one big concern.  And that's why JavaScript doesn't have an easy way of getting at files on the disk.  And in fact that's why when we do uploads of files we have to go on this browse thing and select the file and actually get it because JavaScript specifically prevents the code from actually going and looking at files on the hard disk.  So it was that sort of "protect the computer" side of things.



And then the other key thing was stop a malicious website interacting with another one.  So you can't be on your bank's website, and then some other website suddenly is able to play with the bank's website and do a transfer or something.  That one's still very, very important.  That's a very important part.  That's the cross-domain security which we can talk about.



But the first one, about stop a malicious website from attacking your computer, I think is less and less relevant.  And the reason for that is essentially we're moving a lot of our stuff out into the cloud.  Just look at, you know, Google Mail, Google Docs.  In my company, in my day job, we use Google apps for everything.  So we've got the calendar, the mail, documents, it's all up in the cloud.  So that notion of attacking the PC is becoming a little bit irrelevant.  You know, my work computer, I've got barely anything that's actually on it.  You could steal it from me and, you know, you're welcome to it.  Don't actually do that, but what I mean is, you know, it's not full of those documents.  So that part of the JavaScript sandbox is important because you don't want random code attacking your machine.  But it's not as important as the cross-domain attacks that can exist.



STEVE:  Well, I know that in your slide presentation you also talk about the fact that JavaScript is inherently a global language.  And you give an example of the TechCrunch website, which loads 18 - it looked like the home page - 18 different third-party JavaScripts from, for example, Mediaplex.com, ScorecardResearch.com, Quantserve.com, IXNP.com, DoubleClick.net, GoogleSyndication.com, CrunchBoard.com, Snap.com, TweetMeme.com and Google Analytics.  So there is script coming from all of those different domains onto the same page.  What's the consequence of that?



JOHN:  Okay.  So, first of all, I chose TechCrunch just because they load a lot of JavaScript.  But they are by no means an outlier.  There's plenty of other websites that load lots of different sorts of JavaScripts.  And I actually have stats on that which I'm going to blog about in the next few days because I've got a spider that's been looking at this.  And there's an important thing to distinguish when we talk about this, when I talk about the consequence, which is, yes, JavaScript has very many global variables, global functions, global objects, which I can talk about separately.



But specifically in the instance of TechCrunch, what's dangerous is something that's slightly outside of the language itself, but the way in which browsers use the language.  So that is that when a web page like TechCrunch is loaded, and it contains a whole load of these script tags, and script tags have a thing with the source attribute, and the source attribute says go get this piece of JavaScript from over there.  So it could be from DoubleClick, it could be from Google Analytics, could be from all over the place.



What happens then is that the browser puts them all together, if you like, in the web page you're running, so in that TechCrunch web page.  And they're able to interact with each other as if they all came from the same place.  So there's no sense that they are in any way separated.  So they can all talk to each other.  They can all call each other's functions.  They can all look at each other's variables.  So they have this equal access.  And what I liken this to is the way in which on Windows you run as administrator all the time.  It's a bit like the administrator thing.  You know, you're on the TechCrunch website, everybody gets to do everything to everybody else.  And that means that, if you were able to compromise one of those JavaScripts, any one of them, maybe by breaking into the website that hosts it, by changing a DNS setting, any way in which you could compromise it, then you get access to everything else.



So just to give an idea, Google Analytics is present on around 40 percent of the top websites by traffic.  Imagine if you could insert into Google Analytics's JavaScript.  You'd instantly be running your code on 40 percent of those websites when people went to get it.  Because there's no way of protecting it.  There's no way of knowing that it's genuine.  And there's no way that JavaScript is protected from the other bits of code in the page, or the page itself.  It gets to do whatever it wants.



So what scares me is, I mean, I went ahead and said we've got to kill JavaScript.  But what scares me actually more than that is the way in which the browser uses JavaScript, which says there's no containment between these things, and there's no way of proving that the JavaScript is correct.  For example, we've seen - I think, Steve, you've talked about this, these DNS attacks where you're able to modify DNS.  Imagine if you did that to an ISP, where you just decided to change the entry of Google Analytics.  Suddenly you'd be able to attack an enormous number of websites that people were loading through that ISP.  And there's no way that you can actually verify that that happened.



STEVE:  Right.



JOHN:  The big problem is, I thought, well, wait a minute.  Maybe if we loaded those scripts over HTTPS, we'd get an invalid certificate, and the browser would warn us and say, wait a minute, this has been modified.  But it turns out, I did tests on this, that the most popular browser out there, IE, gives you a warning of the classic sort of, you know, there's something funny here, do you want me to carry on, okay.  And then goes ahead, if you hit okay, goes ahead and runs that particular piece of JavaScript.  And of course we know that most users are educated to hit okay.



STEVE:  Right.



JOHN:  So actually doing this HTTPS protection doesn't help you, unless you're running Firefox or Safari.  And what happens in that case is, if the certificate fails because you're loading the JavaScript through HTTPS, and the certificate's bad, it just simply doesn't load it.  Silently throws it away.  So, you know, once again Firefox, and in this case Safari, do the right thing.  They protect you.  So if you're going to do anything to sort of save this, you could do HTTPS to protect it.  But the big problem, when you go back to this global thing, is that the browser shoves all of the script tags, essentially, at the same, what I call the "administrator level" in the browser.  And that's what causes your major problem.  And that's what I find the most scary thing.  There are issues...



STEVE:  Well, and it's also...



JOHN:  Yeah, go ahead.



STEVE:  As I understand, it's also possible for a JavaScript to redefine the language intrinsics; to, like, redefine fundamental intrinsic functions in the language.



JOHN:  Yeah.  So that's a rather - there's a really great example of this which happened with Twitter, which is that the - there was a way of getting a list of, I believe it was the people you were following, through using a thing called JSON.  Now, JSON - JavaScript Object Notation - is, essentially, it's an object which is written in JavaScript.  And so it could be an array, or it could be an associative array, but written in JavaScript.  And what happens is the browser goes and downloads it, normally, so that some other piece of JavaScript can use it to display something on the screen, like the list of people I'm following.  If you're logged into, say, Twitter or any other site, then of course you have this problem, which is that the cookies can be sent by anybody.  So if anybody says, requests something, it looks like you're logged in.  And so you have that problem which happens with, you know, cross-site request forgery where you're logged into your bank; and, you know, it tries to do a transfer even though you don't see that happening.



Well, so the really nasty example with this Twitter thing was that what it was doing was there was this JSON object.  Now, the JSON object isn't JavaScript code itself that you could actually look at.  So nobody should have been able to get it if they were doing one of these cross-domain things.  But when it got loaded by our script tag, because it was actually JavaScript, it got loaded into the same, if you like, context as any other JavaScript that was loaded.  Now it had no name, so you couldn't in the language go and poke at it and say give me the list.  So it looked like it was safe to do this.  But it turns out in JavaScript, because of its incredible flexibility they built in, it's possible to actually redefine the object constructor.



Now, if we go to the way in which objects work, when you have, in an object-oriented system, you have something which says I'm making a new object, and at that point sets up memory and things like that.  Well, it turns out that JavaScript has this special thing, there's nothing wrong with it, it's just a special JavaScript thing called a "prototype."  And you can go into this prototype thing and actually redefine things which to many people they would think are inherently not changeable.  And one of the things you could redefine was what we call the "setter," which is the thing that actually sets the values that go into this object.  And what it was possible to do, if you redefined the setter for the global object, then when this Twitter status thing got loaded, even though it had no name and was essentially anonymous, it had to get constructed and set.  And in that moment you could grab its contents.  And so that's an example of something in the language that's kind of scary.  Again...



STEVE:  And so it...



JOHN:  Yes.



STEVE:  So if this was actually done and exploited, which I guess is what you're saying happened...



JOHN:  Yes.



STEVE:  ...it's clear that this is not a fault of the language.  It's the fact that the language is very powerful.  But it also means that somebody somewhere who really understood this stuff went out of their way to create this exploit.  I mean, wrote code that would leverage this functionality of JavaScript in a way that ended up being malicious and allowed all this information to be stolen from people.  



JOHN:  Yeah, absolutely.  I mean, this was done by some security researchers.  And I'd have to find the exact reference to it.  But it's pretty easy to define, though, because I know that Bruce Schneier talked about it.  It's called "JSON hijacking."  And JSON is spelled J-S-O-N.



STEVE:  Right.



JOHN:  And it's an example of something very, very powerful in the language which is rather scary because it lets you get at things that are very, you know, it's almost like you're dropping down into an assembly language level and fiddling with stuff on the processor.  This is at such a high, deep level in the language that it's scary.  It also allows you to do amazing things, which has made JavaScript very, very powerful.



But I want to emphasize one thing.  You could leave this in the language if you fixed the problem of all the scripts in a page having exactly access to each other.  Because if you separated them into little, you know, silos, then the script that was actually redefining the object constructor could use that for legitimate purposes, and it wouldn't ever be able to touch this other script that was coming from Twitter.  So, you know, in the presentation I said, well, you've got to destroy all of JavaScript.  The biggest issue for me is this issue of all the scripts being able to run at the same level of priority.  And actually that's number one.  And then number two is there's no way of proving that a script hasn't been modified.  So that's another worrying thing.



LEO:  Let me ask you about that first point.  Could a browser with attention to security like, say, Chrome do that kind of siloization of the JavaScript modules?



JOHN:  Yeah, actually there are, there are a couple of proposals around.  Mozilla has this thing called the Content Security Proposal, CSP, which proposes a way in which  basically we restrict the way in which JavaScript is used in the browser.  Douglas Crockford, who's one of the real experts on JavaScript - I'm definitely not at his level - has proposed a system of sort of silos for the different scripts.



STEVE:  Would you call them separate name spaces?



JOHN:  Well, I think the idea is they are sort of separate name spaces; although, you know, in JavaScript, because things are so sort of global, it's a bit dangerous to talk about name spaces.  But the idea would be that scripts could get the sort of tag associated with them that says, you know, we're the same.  We come from the same site.  We can work together.  And then, you know, someone building a website, if they didn't do that, then it'll be like, well, you're siloed off there.  You go do your thing, in track with the web page, and that's fine.  Because you want to be able to do this stuff for things like Google Analytics.  People want to be able to do that, you know, bring in external scripts and run them.  But the danger is they can interact with each other.



So, you know, there are proposals.  I made a different proposal which is around signing scripts - and we can talk about that a little bit further on - which is to do with cross-site scripting, which is another big area.  But this idea that all the scripts are running in the same context is scary and I think does need to get addressed.  And I think there are some thinking - there is thinking around addressing it.



STEVE:  And do scripts not stomp on each other then by mistake?  Like, I mean...



JOHN:  They can do.



STEVE:  Yeah.



JOHN:  Yeah, they can do.  Because you could, for example, redefine a function, you know, you give some function.  And so often when you look at JavaScript that's actually out there, they'll use really weird names, you know, start things with underscore and just go xxxxx, you know, just because they don't want to stamp on each other.



STEVE:  Right.



JOHN:  The other thing is, there is a way in JavaScript to completely contain your functions, your variables, which is to use a closure.  A closure is a special sort of function, basically sort of anonymous sort of function where it turns out that you can define variables to be local in JavaScript if you specifically do define them that way.  And if you wrap it all up in the global function, you know, it's this anonymous closure thing, and nobody else can actually get at it.  So I think it's obviously very, very powerful.  It has all these sort of facilities.  You just have to be pretty good at programming it to be really safe.



STEVE:  And is there any evidence at this point that this single-context environment is currently being used by some scripts to talk across to other scripts so that creating some separation would then break sites that had become dependent upon it?



JOHN:  Yeah, it probably would.  There are some examples in the web analytics world, particularly when you get in a situation where you upgrade to a new version where they make use of the fact they can read what the old version was up to and grab data out of it.  So, you know, you've got the old tag and the new tag.  And the new tag can say, oh, by the way, I can go grab that from this tag over there, because it knows it can get access to it.  So, yeah, there is an upgrade issue for that.  And it's certainly the case that inline scripts, i.e., ones that haven't been sourced from somewhere else, if you go and look at, you know, any large website, they are expecting to be in the same context.  So you've got to, you know, you've got to be careful about how you do this.  But I think it is, from a security perspective, something that needs to be worried about.  Because it is, that combination is scary.



STEVE:  What's your sense of how worried people are?  I mean, are we the only people worrying about it?  Or are, like, important people worrying about it?



JOHN:  I think...



LEO:  You guys are important, now, come on.



JOHN:  No, I know, self-important.



STEVE:  People who could actually do something.



LEO:  Ah.  That's different.



STEVE:  Yeah.



JOHN:  Yeah, people actually do something.  Well, there is this Mozilla CSP thing, which I think is very important.  Douglas Crockford, of course, is very involved with that kind of script, has been making a lot of noise about this issue, and he has some good presentations about it.  And there are a couple of moves to try and make JavaScript safe.  People may remember quite recently there was a situation with The New York Times where a malicious ad was inserted in The New York Times.  This is exactly an example of, yeah, here's a piece of JavaScript, it could do what the hell it wanted.



There is a thing called ADsafe.  And ADsafe is a way of statically examining a piece of JavaScript which you're going to use in an ad, typically, and enforcing certain security so it can't do lots of malicious things.  And in fact what it does is it uses this thing I talked about where you encapsulate the entire thing so it can't get out, around.  And it's only allowed access to a thing called the ADsafe Object, which lets it, well, this is a proxy for some of the more dangerous activities.  So that is a very good thing because it allows you to take an ad and test it.



And there's another thing called Caja, or Caha, C-a-j-a, which is again a safe subscript, subset of JavaScript.  So this is definitely being thought about.  But I think at the current stage of things it's a bit scary that there are all these different issues going on.  We've seen all these cross-site scripting and many other things I talked about in my presentation, which are rather terrifying.



STEVE:  What scripting does an ad need to run?  I don't want ads running scripts.



JOHN:  No, I realize you don't.  You probably just want there to be...



STEVE:  I mean, it's enough to put up with the ad itself.



JOHN:  You know, to be honest with you, I actually would feel happier if we got JavaScript under control and dealt with some of these issues, and that they were used for ads rather than Flash.  Because at least the JavaScript implementations are, for the most part, open, and we know what the hell is going on inside them.



LEO:  A lot of times a JavaScript - it's the worst of both worlds because JavaScript is used to enable Flash.



STEVE:  To invoke the Flash, right.



LEO:  We use that on our website.  We have a Flash player, and the JavaScript checks to see if you have that capability and tries to do something intelligent if you don't.



STEVE:  Well, in my case, I was briefly using Google Analytics until I looked closely at what it was doing, and I realized that every time one of GRC's pages was being presented to anyone who visited GRC, the code which I had been asked by Google to tack onto the end of my page was going out and fetching a block of code on the fly that I had no chance to look at or understand.  But it was - so basically my server was causing anything Google wanted to append to all of my pages to be included.  And I just - I thought, well, I just can't have this.  I mean, that's ridiculous.



JOHN:  Well, and if you look at that TechCrunch example I gave, I mean, there's tens of them.  And TechCrunch is basically in a trust situation.  They say, well, we trust this code isn't doing anything malicious, and it probably isn't.  And we also trust that nothing's ever going to go wrong with it.  And you've just got no way of verifying it.



[Talking simultaneously]



JOHN:  ...a proposal to do signing of JavaScript.  This was back in Netscape 3.0, maybe, I mean, a long time ago.  You can still find information about it.  And it's just gone nowhere.  And I would be much happier if they were signed so we'd know when things changed.



STEVE:  Yeah, one of the things that all security experts know is, as bad as external security problems are, the great majority of actual exploitation or mistakes or, I mean, either by mistake or deliberate, occur internally.  So all it would take would be somebody with some malicious intent at any one of these sources, for example, in the TechCrunch example, not to pick on them specifically because, as you said, many sites are pulling many scripts from many locations.  But, I mean, it creates this multiplication of potential for problem.  It would just take one insider job exploiter to change the script in some subtle way that would have a huge effect on the Internet, not just one site, but every site that pulled script from them.



JOHN:  Right, exactly.  Exactly.  So that is a real worry,  yes, definitely, that, you know - and I think in a way it can be quite easily dealt with by siloing.  So if something bad happens, you know, it's contained, at least.  Now, that would make an enormous difference.  I think if we could then sign scripts, then that would make a big difference because then you, you know, you'd enter into some agreement and say, hey, you know, these guys signed it, and so that gives you another level of, you know, assurance that it's the right thing, the thing you were actually asking for.



STEVE:  And are you suggesting that it be digitally signed so that it would have a certificate that would be checked before it was run?  Or that then it would be agreed to, a certain script, and then they would not be able to change it without going through some sort of authentication process or authorization process.



JOHN:  Well, I suspect that last one is a bit too complicated.  I mean, I think if you got to the point of just saying, look, Google Analytics always comes over HTTPS.  It's signed by Google.  And, you know, we've signed this piece of JavaScript.  That would give you quite a lot of information.  It would save you from a lot of potential problems to be able to do that.  And the only thing I'd be...



STEVE:  Yup, and then that - go ahead.



JOHN:  No, the other thing I'd be proposing is that the other problem is that cross-site scripting is a problem because, if you can - so cross-site scripting, which is a really weird name, basically it's the problem of somebody manages to inject JavaScript into a web page via, say, in a chatroom, for some reason, there was an interesting example on reddit not very long ago where someone manipulated a markdown, you know, the markdown format they used for marking things up to actually inject a piece of JavaScript into the page.  That got stored in their database.  Anybody who read the comments on that particular story, that JavaScript executed in their browser.



Now, if you think back to the fact that all the JavaScript is executing at the same level of priority, that piece of JavaScript executing in there now has got access to all the other JavaScript in the entire page.  Now, you can actually fix that problem.  And this is partly what Mozilla CSP is trying to do.  They do it in a slightly different way.  But one way to do it would be to sign the script tags you put into a page.  So this page author would say, I put this in, and here's my signature.  You can check.  Now, I mean, it wouldn't matter if someone managed to insert a piece of this JavaScript because it wouldn't have the signature.



STEVE:  Right. 



JOHN:  And you would - that would end cross-site scripting if you did it.  So, again, that's not inherently bad in JavaScript.  It could be a different language; right?  It could be VBScript.  But the issue is you don't know where it came from, and it gets nevertheless sort of administrator, if you like, within the contents of the page, access.



STEVE:  Right.  So it really, in the case of cross-site scripting, it really is a strange fluke of sort of the Web 3.0 approach where users are submitting content, that malicious users can submit script content which will be displayed and run by anyone who then views that content.



JOHN:  Yeah.  And the thing is, there's loads of, you know, examples of these cross-site scripting things.  And the inherent problem is that what happens is you've got these layers of software in, you know, a common website.  So suppose that, you know, you're using JavaScript and HTML in the browser.  It gets submitted back over HTTP.  It goes into a Ruby on Rails app which gets stuffed into a MySQL database.  There's loads of potential for weird stuff to happen to that stuff you entered along that route because you've got all these different languages and escaping, well, in MySQL it's like this, and in Ruby it's like that, and et cetera.



And there've been, you know, classic examples of this.  The reddit one was interesting because it was a bug in their markdown implementation.  There was a Ruby on Rails one to do with Unicode decoding, where they had this thing which tried to deal with Unicode, and they'd handwritten it themselves, and it turned out there were some bugs in it, and it was possible to create essentially bad Unicode that got decoded into ASCII with a script tag in it.  So that, you know.  And there's another great example which is to do with UTF-7, you know, Unicode type thing, which is if your website wasn't specifying that it was in, you know, UTF-8, UTF-16 or whatever, you could use UTF-7 characters and then stick in their metatags - and by the way, this is UTF-7, which would then promptly get decoded by the browser into a script tag, and off you go.



So there's loads of potential.  I think Douglas Crockford calls this the turducken problem.  You know that thing where they put a chicken inside a duck inside a turkey?  You've got just layers and layers of different stuff.  So, sorry, I'm getting too excited.  Now I'm going to have to start coughing.



LEO:  Stop talking about turduckens.



STEVE:  Well, just in terms of traditional security, how secure has JavaScript's actual sandbox turned out to be in practice?



JOHN:  Actually, to be honest with you, I think it's pretty good.  There have been lots of bugs.  But, you know, hey, what a surprise.  It's certainly no Windows, let's put it that way.  I mean, it's, you know, there are bugs, and you do see examples, if you look in the SANS database and things like that, of such and such a bug in the sandbox where we could get through and do cross-domain things or cross-security-domain things in IE.  But, yeah, there are bugs.  What a surprise.  There was a nasty one in Google Chrome which the Mozilla guys found in, funnily enough, by actually inspecting their code.  That was just a few weeks ago.



STEVE:  Right.



JOHN:  But to be honest, the sandbox has been pretty good.  The bigger problem is not the sandbox because, as I say, it's not breaking out of the sandbox is the problem.  You can do plenty of damage within the sandbox.



STEVE:  Right.  And so problems there are resulting, or are the result of, bugs in JavaScript's implementation of the sandbox.  But everything else we've been talking about are sort of - are fundamental to what happens when you have scripting power in a browser in this very complex environment where users can provide code, code is being pulled from multiple domains into a single page, code from all these multiple domains is able to see each other and interact with each other.  And again, all of this is hugely complex, and we know that complexity is the enemy of security.  So bad guys are able to look at all this and just rub their hands together and think, wow, look at all this opportunity we have for exploiting all of this complexity, fundamentally enabled by the fact that we've got a scripting engine running in the user's machine that will do what we tell it to.



JOHN:  Yeah.  And by the way, I've got nothing against us having a scripting engine in the machine.  I think that's actually a very important part of where we're going with, you know, mobile code being able to be downloaded.  And, you know, I'm very happy to use things like Gmail.  I think it's fantastic.



LEO:  Yeah, absolutely.  You use Google Docs in your company.  You can't do it without scripting.



JOHN:  No.  And it's fantastic.  And I think the issue is we need to look at the way in which JavaScript is being used in browsers today and deal with some of these problems because, you know, there are lots of nasty examples of cross-site scripting problems.  You know, stealing someone's Twitter friends is probably, you know, the timeline is not that serious.  But you can imagine these things do get more and more serious as the systems get more and more complex.  And so fixing is important.  So that was sort of the reason for my presentation was to say, wake up everybody.  This is not, you know, a fun situation.  Let's not just let it run and run like this.



LEO:  Steve, I don't want to preempt, if you have some other questions before we get to John's recommendations.



STEVE:  No, I think this is perfect.  I'd love, I mean, I know my solution.



LEO:  Well, it sounds like John uses the same solution.  You both prefer to use NoScript.  Is that right?



STEVE:  Right.  Right.



LEO:  John, how do you use NoScript?  You said you turn on full protection and then allow sites.



JOHN:  Yeah.  Yeah.  It's funny actually because I didn't use it for a long time.  And I used to listen to Steve talking about JavaScript security and go, what a nutcase he is.  Of course there's nothing wrong.



LEO:  Nothing wrong with that.



JOHN:  What a crazy idiot, going on about how you shouldn't run JavaScript in your browser.  And then I started - I had done a few things with JavaScript.  Then I started working with some really high-end JavaScript developers, and we started looking at some things.  And I just got more and more and more appalled.  So, yes.  I use NoScript, and I basically have it, you know, it's like those old application firewalls.  I have it yelling at me all the time.  And I find it infuriating.  But I like it...



LEO:  That's why I don't use it.



JOHN:  Yeah, no, I understand.  I mean, so...



LEO:  You need it, though, it sounds like.



JOHN:  Of course the sites I'm using all the time are whitelisted, you know, they're allowed to do whatever they want.  So I just go ahead and decide to trust them.  And, you know, for other sites I have it essentially switched off, you know, so that basically, you know, you cannot get any JavaScript running unless I specifically say so.  And then I'll go in and do it when I need to.



LEO:  What about on cell phones?  I mean, a lot of cell phones use JavaScript.



JOHN:  Yeah, I mean, I have an iPhone.  And to be honest with you, I use it to access not very many different sites, so...



LEO:  Stay off the web.



JOHN:  No, I use it to stay on the web, of course, particularly for email and Twitter.  But I don't find myself browsing around a lot on my iPhone.



LEO:  For that reason.



STEVE:  Well, the idea that in the long term JavaScript is with us, I think no one contests.



LEO:  Yes.



STEVE:  We agree that a scriptable browser is vastly more useful than a dead browser that just lays there and can only display static pages that come from servers.  I mean, that was, you know, the Web 0.5 version of the world, and not something we're ever going to go back to.  The idea that there are, as John has presented, there are definitive ways to fix some of the aspects of JavaScript, I mean, I'm still uncomfortable by the idea that anything I, you know, random browsing is going to be running code on my machine.  That just isn't cool with me.



But the idea that these more appalling security holes, I mean, the things that are in there really by design are being looked at and can be tightened up I think is tremendous good news.  And I will tell everybody that, I mean, using NoScript is a burden.  You go to a site and something doesn't seem right.  It's not quite working.  And so then it's like, okay, let's see if turning scripting on will make the form work correctly.  And it always does.



JOHN:  Yeah.



STEVE:  I don't have NoScript set to tell me when it's blocking something.  That's really obnoxious because scripting is everywhere now.  So all I do is, if I see that a site doesn't seem to be functioning right, I look down at the bottom, and there'll be like a little red slash through the "S," saying I'm blocking stuff for you.  And it's like, okay, fine.  And so normally I temporarily allow scripting.  You're able to do it just like for the session or to permanently whitelist, which is very nice.  That way I don't have my whitelist growing forever.  Because most sites that I'm randomly going to, I'm not coming back to.  So I find that it really works for me.  And I think for today it's the right balance between, you know, we have to have some scripting for sites that need it; yet you don't really just have to be running around completely naked on the 'Net all the time and allowing anyone to poke at your browser.



JOHN:  The problem is with NoScript is that, you know, you have to be a pretty high-end user to be able to use it.  And that's why, you know, my presentation, you mentioned this at the beginning, Steve, which is I said there's no viable way for my mother to control this.  And that's why this is something that's got to be fixed technically to protect people from what's happening.  It's good for people like us.  But it's not a solution for the general web user at all.  It drives me insane.  And, you know.



LEO:  Well, that's why I don't use it.  But now I'm terrified.



JOHN:  There's one thing I didn't talk about, which is kind of interesting, which is just to leave you with this thought, which is that there's no way for a website to tell the difference between a click made in JavaScript and a click made by a human.



STEVE:  Ah, I meant to bring that up.  Yes, yes, yes, I meant to bring that up.  Yeah, talk about that, John.



LEO:  This is that click fraud thing; right?



JOHN:  Yes.  The thing is...



STEVE:  We actually talked about it already earlier in this episode, the idea that - well, go ahead - that JavaScript and user clicks are seen as the same thing.



LEO:  Right.



JOHN:  Yeah, there's just no way.  Because, I mean, what happens is you've got this system in the browser of events, which are things like, you know, you move the mouse over something, and [indiscernible] changes color or whatever JavaScript is used for.  Or you click on something.  And because of the way in which the web is put together with these essentially different layers which are essentially independent from each other, what happens in JavaScript is you can fire an event.  You can say cause this click to happen, which turns out to be an immensely useful thing to do because you might want to, within your JavaScript, you know, click on something as if the user had done it.  You know, you might have two buttons, and you want to actually click the other one, or some other thing that has to happen.  But actually inside, and I guess going back to the website, there's definitely no way to tell whether a machine did that or a human did it.  So you get this problem of you can't tell whether a person actually initiated that action or not.  And so that's another one of those things where you think about it and say, wow, it would be really good if you could actually tell if that was actually the mouse was moved and someone actually clicked on it, or if a piece of code said, hey, click it.



STEVE:  Well, yes.  And for all kinds of, I mean, we talk about authentication a lot.  And so it's really important to be able to, like for a server remotely to be able to know for sure that when it challenged the user, the user himself physically moved the cursor over a button and clicked on it, rather than the page happened to load some script from somewhere that did that on the user's behalf, for something really important where you really want to assure you actually have user focus and awareness and interaction.  And with the model as it is now, you don't have that.



JOHN:  Yeah.  Yeah.  So that's, you know, one of those things in, you can argue whether that's in the language or in the implementation of the language in the browser, but is a worrying thing if you're trying to understand, you know, what did a machine do and what did a person do.



LEO:  Well, I hope that people are paying attention to this, and I hope that something gets done about it.  We need it.  It's a very powerful language.



STEVE:  The important people.  We hope the important people are paying attention.



LEO:  Well, all it takes is for Google, for instance, although given the problems you talk about with Google Analytics, maybe there's no hope.  But for Google or somebody, maybe Google could say, well, we're going to make Chrome enforce this.  We're going to silo the data.



JOHN:  Well, Google are the people behind the Caja - or Caha, depending on how you say that "j" - project.  So there's definitely thinking in Google going on there about it.  And I talk about Google Analytics just because of its incredible popularity.  There's nothing inherently wrong with Google Analytics.  I mean, it scares me that it's on so many sites.  That's what worries me about it.  I don't think Google's up to anything naughty.



LEO:  Well, but loading code without any, I mean, kind of - it's inherently risky.  But it's doing what everybody does with JavaScript, I guess, so...



JOHN:  Yeah, it sure is.  And it's just that's the biggest worry is that it lets us slap things together, and they're all running as the same priority, and that's a scary situation.



LEO:  Is Caja as good a solution, do you think, as siloing or signing?



JOHN:  No.  I think if we had proper silo, you know, we could actually break things up into separate spaces and then...



LEO:  We don't need to strip the language down, then.



JOHN:  I think there's some merit in working, going down to a subset of the language which is known to be safe and sort of building back up again from there to try and avoid some of the scarier parts.  I think that's a valid thing to do.  But I think that, you know, just being able to sign things and know they are what you're expecting to get is very important.



STEVE:  Well, and we're talking about a language which is 14 years old.  Remember the world 14 years ago when JavaScript was designed.  It wasn't facing anything, any of the challenges that it's facing today.



LEO:  Well, part of the problem was that JavaScript wasn't in fact designed.  I mean, it was very ad hoc and was implemented in a variety of different ways.



STEVE:  Well, and the fact that it's even called JavaScript is a misnomer.



LEO:  Yes.



STEVE:  I mean, it's got nothing to do with Java at all.



JOHN:  No, no, absolutely.  I mean, I guess Netscape were hoping that Sun would buy them, and so they called it JavaScript.



LEO:  Well, John, I'm so glad we could get you back on again.  I do want to give a plug for your "Geek Atlas" because it's a great book from O'Reilly that covers 200, what 256 of the great geek...



JOHN:  128.



LEO:  128, okay.  Two to the...



JOHN:  Yeah, here it is.



LEO:  Here it is.  Take a look at it.  He's got it.



STEVE:  2^7.



LEO:  2^7, not 2^8, yeah.



JOHN:  If I can get it back in front of the camera.  Here we go.  And now, here's the big surprise.  I just received this today.



LEO:  Oh, but the book is upside down now.  What, it's an updated...



JOHN:  It's a German edition.



LEO:  [Speaking German]



JOHN:  Yeah, so he can speak German.  So English or German, depending on what you like.



LEO:  Congratulations.  That's really great.  It's a wonderful book.  I have it, and I hope maybe someday to retire and make the trek to all of those sites.  Be fun.  Be really fun.  JGC.org is the place to go for the blog, John Graham-Cumming's blog.  And Steve's SnipURL for the article that started this all and the slide stack that started this all is snipurl.com/javascriptsecurity.  Did I get that right, Steve?



STEVE:  Yup.



LEO:  Well, that's great.  Thank you, John.  We really appreciate it.



STEVE:  Thank you so much, John.  It's great spending the time with you.



LEO:  I've got to quickly go instead NoScript on all my machines.



JOHN:  It's too late.  I already infected them.



LEO:  How many times have I said that before?  But this time I'm going to really do it.  You did finally scare me into it.  And we'll see you next time on Security Now!.



JOHN:  Right.



LEO:  Bye bye.



STEVE:  Bye bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#222

DATE:		November 12, 2009

TITLE:		Listener Feedback #79

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-222.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now!, Episode 222 for November 12, 2009:  Your questions, Steve's answers #79.



It's time for Security Now!, the show that covers all things, you know, safety on the Internet and privacy and security.  And he's the guy to do it, just the guy you'd want to have on your side in a troubled time, Mr. Steve Gibson from the Gibson Research Corporation, GRC.com.  Hi, Steve. 



STEVE GIBSON:  Yo, Leo.  Great to be with you again.



LEO:  Yeah.



STEVE:  Episode 222.



LEO:  Which we're recording on 11/11.



STEVE:  At 11:00.



LEO:  At 11:00.  Wow.  Wow.



STEVE:  Lots of alliteration today.



LEO:  Yeah.  Well, I don't know if - again, this is not going to air until the 12th, but we're recording on the 11th.  I don't know if - you don't say Happy Veterans Day, but a tip of the hat to our men and women who are serving and have served in the armed forces.  We appreciate your service.  And we're having a big parade in Petaluma at 1:00.



STEVE:  Oh, very cool.



LEO:  So if you hear marching bands and cannons firing and all of that, that's the Veterans Day Parade going downtown.  It's such an old-fashioned community.  I mean, we do stuff like that.  I love it.



STEVE:  Yeah, that's really neat.



LEO:  Yeah, I wanted to drive the Mustang down the street, but I'm busy.  But our VP Finance, Lisa's husband, Lisa and her husband Mike own a beautiful 1967 cherry-red Camaro.



STEVE:  Mmm, nice.



LEO:  And he and their six-year-old son is driving that in the parade with their club.  So that's really neat.  So, my friend, it is time once again for a Q&A segment.



STEVE:  Brought to us by our fantastic listeners.  334 postings when I pulled the mail down, from which we selected just a handful, but good ones, interesting ones.  And a really, really nice, well, and sort of - we wrap it up with, I think it was the Biometric Horror Story of the Week.



LEO:  [Laughing] You know...



STEVE:  So, always trying to find something fun.



LEO:  I was talking to somebody who works at Disneyland.  He is a programmer, actually works for Pixar, but he goes - he has one of those cards that lets you go to Disneyland all the time.  I said, "When you go there, do you scan your finger?"  He said yeah.  I said, "You should scan your knuckle."  He didn't know what I was talking about.  He's a computer programmer.  He ought to know.



STEVE:  Yeah.



LEO:  We're putting out the word, anyway.



STEVE:  So we have a bunch of security news.  We've got a little bit of errata.  I have an interesting SpinRite piracy story to tell.  And a bunch of great questions from our listeners that we will answer.



LEO:  Did you know - I don't know, I should have asked you this off the air, but somebody has made an iPhone application out of our Vitamin D segment?



STEVE:  I actually do know.  I've communicated with the author a number of times for him - he wanted permission, and I said, oh, of course.  And I aimed him at the Vitamin D page where I had a...



LEO:  It has a link to that, yup.



STEVE:  I had audio that was just the Vitamin D stuff.  And a number of our listeners wrote to say Vitamin D, the Vitamin D podcast is on iTunes.



LEO:  We license our stuff using the Creative Commons License for noncommercial attribution share alike.  So you're welcome to do mashups like that, provided you're not making money on it and you have the same permissions, use share alike permissions.  So I think that's really a great way of sharing the information.



STEVE:  Yeah, it's very cool.



LEO:  Yeah. So if you want to share Steve's great episode on Vitamin D - what is it called?  Do you know?



STEVE:  I have not...



LEO:  I have it right here.  I just found it.  It's called "Vitamin D:  Listen and Learn."



STEVE:  Ah, perfect.



LEO:  And you can get it by just searching for Vitamin D on the iTunes store.  And this application was made to promote awareness of this misunderstood "vitamin."  Information by Steve Gibson of GRC.com and designed by Ultra Software Solutions, USSapps.com.  So I think that's really neat.  And it does have the audio of the show.  What a great way to share all this information.  And it's absolutely free, it says, just like the sun.  So that's great.



STEVE:  That's perfect.



LEO:  Yeah, that's really great.  Thank you, USS, for doing that.  You want to do, I'm sure, some errata and news, I would guess?  Yes?



STEVE:  We have all that kind of stuff.



LEO:  All right.



STEVE:  And we had a Patch Tuesday.  We're recording this after the second Tuesday of November.  And we know Microsoft, they're up to the same old routine, as is pretty much everybody else.  And speaking of the iPhone, we have news of the very first iPhone worm.



LEO:  Oh, yeah.  It's a funny one.



STEVE:  It's a wacky thing, yes.



LEO:  All right.  So let's hear what's happening in the world of security.



STEVE:  Well, we have pretty much all the regular culprits are present today.



LEO:  The usual suspects.



STEVE:  Of course top of the list is Adobe.  By the way, remember last week I said I hate Adobe?  I still do.  And now I discovered that, in addition to installing this unasked-for demo of the speech package, when I rebooted my machine after a security update and then next ran IE, there was now a toolbar that it had added for the speech demo that had appeared in IE.  I just...



LEO:  We had talked last week about Flash doing that; right?



STEVE:  Well, I'm sure that I remember, yes.



LEO:  I tried it, and I saw there is a checkbox, but you have to notice it, on the web page before you download the Flash.



STEVE:  [Growling]



LEO:  It's not even in the install.  It's like before you download.



STEVE:  And did you see also the offer to install Google, I think it was a Google toolbar also?



LEO:  I don't remember what it was.  But...



STEVE:  But you did see a demo for the speech app.



LEO:  No, I saw the toolbar thing.



STEVE:  Oh, okay.



LEO:  I don't know how this - but I just can't believe they would install something without at some point, however fine the print, saying we're going to install this.



STEVE:  Oh, I'm sure it was there.  I mean, again...



LEO:  But who sees them?



STEVE:  I'm sure it was there.  I must have missed - maybe there was a way to turn it off, although I remember turning off the no, I don't want the Google toolbar, thank you very much.



LEO:  Yes, that's the one I thought I saw.



STEVE:  And I didn't see the other one, so.  And in fact I meant to look through our mailbag because I figured our listeners would have said, oh, yeah, I ran across that, and here's where it was.  But I ended up filling up our Q&A sort of near the top of the pull and never got through reading everything, so I didn't confirm it.  But in this case we have Shockwave, that has about 450 million users, which has five critical flaws, four of them allowing arbitrary code execution.  I don't have Shockwave installed.  So users should look in your browser's add-ons, or extensions, rather.  For example, in Firefox it's not an extension, it's a plug-in.  That's where those sort of like the non-extra UI features, but more of the built-in browser enhancement plug-ins go there.  And so, for example, I see Adobe Flash, but not Shockwave, which is different than Flash.



So first of all, if you don't have Adobe Shockwave in, for example, your Firefox plug-ins, don't add it.  I mean, it's just more gunk, you know.  And I'm never one for installing stuff you don't need.  But if you do have it, it is exploitable.  And so you definitely want to go to get.adobe.com/shockwave, so that's the URL, get.adobe.com/shockwave.  And it will, as of this date, give you v11.5.2.602.  And anything earlier than that, which would be 11.5.1.601 and earlier, has these problems.  So if your browser does have Shockwave, first of all, you may want to just remove it.  If you don't think that you - if you don't know you need it.  I'm surviving quite well without.



LEO:  Most of the time you don't.  Yeah, most people use Flash now.  Shockwave is not necessary on the web.



STEVE:  Yes.  So I think basically when they talk about 450 million users, it's like, yeah, well, these people acquired it at some point, and it's still living in their machine, creating vulnerabilities they don't need.  So maybe, I mean, what would make the most sense is, if you know you don't need it, get rid of it.  And if you do need it, then make sure you've got 11.5.2.602, which you can get from get.adobe.com/shockwave.



Also Sun, the latest version of the Java Runtime Environment, and I mean the latest version, has multiple vulnerabilities and no updates available.  They have acknowledged multiple problems.  There is enough disclosed for problems to be - for exploits to be created on the 'Net.  Unfortunately the only workaround is the workaround we all know all too well, which is disable JavaScript to prevent Java, the Java Runtime Environment components from being exploited until Sun updates themselves.  One of these weeks I'll happily report that there is a new version of the Java Runtime Environment.  At this point there's notices all over the various security sites, talking about a zero-day problem, that is, problems that have been acknowledged and are being exploited, but for which there's yet no patch, which is the case with the Java Runtime Environment.



LEO:  So a week ago Java was patched.  And you're saying it has new holes now?



STEVE:  Yes.



LEO:  For crying out loud.



STEVE:  Yes.



LEO:  I can't believe it.



STEVE:  Yes.



LEO:  They were just fixed.



STEVE:  Yes. Yes.



LEO:  Okay.  Okay.



STEVE:  There's some interesting news from the EU, the European Union.  There's been a lot of issue over the rights of users to stay connected to the Internet when they've been accused of filesharing.  And, you know, we've talked about sort of, I mean, there's really no global consensus yet.  We've talked about how now Internet access is being considered a human right.  Whatever that exactly means I think is unclear.  But the idea being, well, it's really important.  And so given that, the question is, what level of proof does an ISP need to be given in order to disconnect users?  France, under strong lobbying pressure from the music and film industry, has been proposing a three strikes and you're out approach, where you are notified twice that you are downloading illegal copyrighted content.  And if you're found to be doing that a third time, after two prior notices, you're disconnected for one year.  What's happening is the EU is trying to unify all of this various sort of unclear policy under a single agreement.  And the good news is it's looking like agreement is being reached and Internet users are going to get some relief and a sort of a strong pro-user result where...



LEO:  Good.



STEVE:  Yes, where none of this will apply, where you can't simply be accused.  Remember that we talked about a story recently where just being accused of doing this, where the ISP was offered no proof, there were ISPs that were under pressure from the Motion Picture Association to disconnect users just because they said so.  And the ISPs were saying, wait a minute, you know, we need more than that.  So the good news is now it's going to require a court order that includes proof that this is actually going on.



LEO:  There is, you know, this is a larger issue.  This is the ACTA treaty, the anti-counterfeiting treaty that has been negotiated, currently being negotiated in secret.  And it's not just France.  They want to get this through all over the world.  And by the way, it's really sneaky because, if the treaty is ratified, the U.S. Congress has to make this the law in the U.S. as well.



STEVE:  Ooh.



LEO:  Even though it would never, nobody would ever, you know, concede to these really draconian provisions.  It's anti-American.  The treaty is in secret, but some of it has leaked out.  Michael Geist in Canada has leaked it out.  And it is in fact calling for that three-strikes provision, with three strikes accused, not three strikes conviction.  France modified it.  But the other countries are considering this, three strikes accused, and off the Internet for life.  And your name being distributed so that other ISPs will not give you service.



STEVE:  Whoa.  This goes way further than...



LEO:  Horrible.



STEVE:  ...than the article.  Because I was reading an article from the Associated Press that MSNBC covered.



LEO:  It's a much bigger story than this.  And if you want to read more, EFF.org, read about the ACTA treaties.  And Michael Geist's blog in Canada is an excellent blog.  He was the one who found these provisions.  Now, it's still being negotiated.  But the point was it was being negotiated in secret.  They obviously didn't want anybody to know about this.  Now that it's in public, we need to say, hey, that's not okay.  That's not acceptable.



STEVE:  Yeah, this is not okay.  Off for life.



LEO:  Yeah.  Isn't that nice.



STEVE:  Come on.



LEO:  EFF has gotten very involved in this because they really are afraid that - and it wouldn't go through a legislative process in the U.S., that's what's interesting.  Because it's a treaty, it would have to be ratified.  And of course that's what the movie industry and the record industry want.  They don't want discussion over this.  They want it to be secret, and they want it to go through without anybody knowing.  And then it would be the law.



STEVE:  Wow.



LEO:  You wouldn't have a choice.



STEVE:  And so accusation without proof, three times, and then you're banned from the Internet for life.



LEO:  Isn't that nice.



STEVE:  That's horrifying.



LEO:  They tried to do it in New Zealand.  If you look at the list of countries, Korea, they're trying to get this through in, it's just appalling, yeah.  So this is something everybody - I'm glad you brought it up because it's something everybody should be aware of.  And find out more at EFF.org.



STEVE:  We'll keep our eye on it too.  Microsoft brought us Patch Tuesday this month of November, as they always do every month.  We had six security bulletins on Tuesday, November 10, so I'm sure everyone's Windows machines are lighting up with their little yellow shields, saying oops, we've got some updates for you which will require a reboot.  Three were critical.  Three were rated important.  They were pretty much obscure, remote code execution, kernel-level things that involved the Windows kernel and a couple of the Office apps.  So, you know, nothing really earth-shattering.  But as usual, find a time when you can download them and shut things down and reboot your system.  You want to stay current with that.



Both Leopard and Snow Leopard, the Mac OSes, were updated, Leopard to 10.5 and Snow Leopard to 10.6.2.  Apple as usual is not being very forthcoming.  They said, "This affects the stability, compatibility, and security of users' computers."  Yeah.  Thanks a lot.  No kidding.



LEO:  You know what else it does?  And I'm sure there's security involved.  It also breaks Atom support.  So that if you're running a Hackintosh, which is a Macintosh on one of these Netbooks...



STEVE:  Interesting.



LEO:  ...don't update because it won't work anymore.



STEVE:  Interesting.



LEO:  Yeah.



STEVE:  Yeah.  They said that it fixes a number of security issues...



LEO:  Yeah.



STEVE:  ...including arbitrary - yeah.  Yeah, exactly.  And some usage we don't like issues, arbitrary code execution flaws, some cross-site scripting vulnerabilities.  There was a denial-of-service flaw, privilege elevation flaws, unexpected application termination, of course unexpected boot termination in the case of these Atom machines.  And also said that attempts to download unsafe content may not always produce warnings.  And there was - apparently there was a way for dictionary attacks against SSH logins to not be detected.  So you definitely want to update this unless, as you said, Leo, you really can't because you're using the Mac...



LEO:  Well, they got you, don't they.



STEVE:  Yeah, on a non-Mac - on non-Mac hardware.



LEO:  Yeah, yeah.



STEVE:  So, yes, update.  It's 157MB, which I updated when I fired up my Mac this morning to fire up Skype and do the podcast with you, Leo.  So it takes a while to grab it and update it, but definitely worth keeping current.  Meanwhile we have iKee is the name of the first iPhone worm, which is spreading only locally throughout Australia at the moment because it scans for specific Australian 3G wireless networks.  So it's not going to go global.



What's interesting is that the way this happened is sort of a gotcha.  The most popular jailbreaking system for the iPhone installs an SSH server as part of its jailbreaking process.  And unfortunately it has a default password which is set, which because being default, everybody knows what it is.  So if the user who jailbreaks their iPhone in order to allow it to run non-Apple iTunes store-based software, what they're getting in the process is an SSH server which is exposed to the Internet with a default password everyone knows.  So that's all you need to create a worm, which has been created.  The good news is this is benign, relatively.  It changes your wallpaper to some '80s singer guy that I've never seen or heard from.



LEO:  Oh, you've never been Rickrolled, obviously.  It's Rick Astley.



STEVE:  Okay.



LEO:  It's an Internet meme.  People were sending links saying, oh, this is the latest greatest thing, and it would be Rick Astley singing "Never gonna give you up, never gonna let you down."  Anyway, it's a horrible meme.  It's a prank.  It's a prank.



STEVE:  Well, and one other Dutch hacker, actually even before this, there was a Dutch hacker who was using this hole to send offers to iPhone users to close the hole in return for them sending him five euros to his PayPal account.  So there was sort of an attempt...



LEO:  But you don't have to.



STEVE:  Well, yeah, exactly, you don't have to.  All you have to do...



LEO:  Just a suggestion.



STEVE:  Exactly.  I'd be happy to show you how to change your password if you send me five euros, please.



LEO:  Well, and that's the fix; right?  You just change it from the default.



STEVE:  Yeah.  That's, exactly, change it from the default, change it to something, you know, I mean, while you're at it, make it a gnarly password because you don't want, you know, the next thing that'll happen is - actually what you'd love to do, I mean, I don't know enough about the iPhone, I haven't looked at it, you would like to shut down this SSH service.  I mean, that's really the solution, is why would you want an SSH service running in your iPhone?



LEO:  A lot of jailbroken iPhones do so you can SSH into your phone.



STEVE:  Oh, okay.  Well, there you go.



LEO:  That's one of the reasons they do it.  In fact, it's a necessity for, I believe, some of the jailbreaking.



STEVE:  So in order to set it up like underneath the phone's UI and so forth.



LEO:  And then you can - you could turn it off, but a lot of people want to keep that - they hook up their iPhone, and now they can SSH into it.  It's a full operating system.  So you can mess with it.



STEVE:  In that case, change the password.  Absolutely.



LEO:  If you're going to use it, change the password, yeah.



STEVE:  Absolutely change the password.  Now, the biggest scary news of the week is our topic for in-depth coverage next week.  Which is the bad hole which has just been found in SSL.



LEO:  Oh, crud.  That's not good.



STEVE:  There's a session renegotiation hack which has been discovered in the latest current version, v3 of SSL, which we all know is also TLS.  We covered the protocol at some length a while go.  I didn't talk about, for example, session renegotiation because it's sort of off the mainstream of how two machines normally hook up.  Turns out that it's possible for a man in the middle to attack an SSL session, that is, an existing SSL connection, and insert his own transactions into the stream.



So people are scampering around, this has been known for a couple months, it's been kept under wraps.  Under NDA the details were given out.  I mean, this is a big, big problem.  The various standard bearers, the OpenSSL and the Gnu Project are working to update their specs.  There'll be a new RFC.  I mean, basically this is a fundamental flaw in the protocol that we're going to cover in depth next week.  So I wanted to let everyone know I know about it because there was a bunch of people dropping mail to me saying, oops, have you heard about this?  Oh, yes, I know about this, the renegotiation problem.  So we will all know about it in detail next week.



John Graham-Cumming, who was our guest last week, prepared a PDF and PowerPoint files of his slide presentation.  I knew about them last week, but they were in the PPTX format that required you to have the very latest version of Office.  And so I'd asked him if he could do it in the older version of PowerPoint.  He went a little further and also created a PDF.  So you need no Microsoft PowerPoint viewer of any sort.  So I just wanted to give a heads-up to people that at the Security Now! page at GRC - and by the way, I made it quicker to get there, GRC.com/sn.  You don't even have to type out securitynow any longer, in response to some people in our newsgroups saying, hey, Steve, how about /sn?  It's like, okay.  You got that.  So GRC.com/sn.  And the Episode 221, which is when we had John talking about JavaScript, I put links there to both of those files, which I'm hosting locally, courtesy of John.



LEO:  Great.  That's nice of you.  That's great.



STEVE:  In an interesting twist on SpinRite, from someone who gave me his name - I don't have any problem sharing it, I doubt that he will because he went legit in the end - Cody Krieger.  He said, "Dear Steve.  Not sure if this is the right address to send this to."  Actually he sent it to our sales address, but Sue forwarded it to me.  "But to be honest, I'm feeling a bit lazy after the ordeal I've just gone through.  About two months ago I underwent a fairly serious hard drive malfunction.  Two went dead.  Both had an extreme case of the click of death, and another started to fail.  These were all in the same machine."  And frankly I'm beginning to wonder maybe if his machine's, like, way over temperature or something.



Anyway, he says, "I immediately whipped out" - what he called "my trusty copy."  We learn a little bit later it wasn't quite his.  "I immediately whipped out my trusty copy of SpinRite and set it on data recovery mode.  After the long wait, I discovered that SpinRite had brought both" - he put in bracketed and asterisks - "drives back into working order.  Not feeling very trustworthy of either drive after all that clicking, as I suspect both drives' failure can be partially attributed to firmware or mechanical defects, I immediately imaged both onto their own brand new 1TB drives.  Not 10 seconds after this finished, both drives collapsed dead again.  This time they failed to even spin up.



"I then ran SpinRite on maintenance mode on the drive that was starting to go bad.  That drive has lasted me up until now.  Today that drive started clicking angrily at me while my system was sitting idle for the most part.  I'm running SpinRite on it right now, and I'm buying another drive to replace it with in anticipation.  Having realized how many times SpinRite has saved me (two months ago wasn't the first time), I figured it was time for me to actually buy a copy of the software.  I confess I had been using a pirated copy.  No single piece of software has ever worked wonders like this has for me, and you deserve every penny of my money for it.  Thanks for making such a wonderful piece of software.  Keep it up.  Cody."



LEO:  Wow.  So isn't that nice.  I love these stories.  They're so heartwarming, in a geeky kind of way.



STEVE:  Well, yeah.  I mean, and I frankly, I mean, I have a mature appreciation of the reality of software sales.  I never locked my software or copy-protected it.



LEO:  Thank you.



STEVE:  Never done anything like that.  That just gets in the way.  I ignore, like, if you look at anyone else's hard disk utility software, they tell you you can run it on exactly one drive.  Well, that's ridiculous, too.  I mean, if a person's going to buy it, I fully expect they're going to want to run it on all the drives they own.  And that's what the license is for.  Use it on any drives you personally own.  So, you know, if someone is going to use a piece of pirated software and accept the risk of doing so, I do know unfortunately that there are damaged, deliberately damaged versions of SpinRite that install bad stuff on people's computers.



One of the things that Greg deals with, my tech support guy, is someone will call up and say, hey, you know, SpinRite just installed a trojan on my computer.  And it's like, I don't think so.  What's your serial number?  And then the guy, uh, oh, well, this isn't really my copy.  And, you know, and then we go from there.  So, you know, certainly there's a risk of doing so.  But if someone's going to do that, then they're not a customer of mine.  So I don't recognize, I don't regard it as lost revenue or piracy.  I mean, you know, it'd be nice if the MPAA and the music industry had a similar mature feeling, recognizing that not every piece of song or movie that is being viewed or listened to represents lost revenue.  But, you know, it's not the way they operate.  So anyway, I appreciate Cody's purchase and his great note talking about how - what a good job SpinRite did for him.



LEO:  I'll start with Question #1 from Mike in Baltimore, Maryland.  He wonders about changing his SSH port every single day.  Hmm, that's interesting.  Every time you talk about SSH and port configuration, I remember I want to ask this question:  In addition to logging the SYN packet request, would changing the SSH open port number every day to a randomized port provide any additional security?  My Linksys router running the Tomato firmware allows me to map an external port to a different internal port.  I can map external port 62305 to internal port 22 - the SSH port - for example.  So if I wrote a script to randomize that external port number every day, would that provide any security benefit?  Or am I wasting my time?  Thanks for the great podcasts.  As soon as I stop spending so much money I will be buying SpinRite and running it on all my drives.  Maybe spend some money on SpinRite first.  I currently have no problems with any, but a few are quite noisy and starting to worry me, and I would like some peace of mind.  Well, it's an interesting strategy.  What do you think?



STEVE:  Well, I'm not a big fan of that.  The idea, I mean, it's sort of clever.  My sense is you'd get much better benefit from using a really good, really impossible-to-guess username and password.  Certainly moving the port around every day would prevent someone from sitting there, pounding on it, on a fixed port, even if it wasn't 22, for some period of time.  On the other hand, if the port disappeared, I guess they would figure you'd closed the service.  But they could also just scan your IP and find where you'd moved it to.



The question, though, most put me in mind of I think perhaps, depending upon how Mike uses SSH, the best solution of all, which is not to have the port mapped at all unless he has some reason to believe he will be logging in over SSH from somewhere outside of his home or office, and thus need the port mapping at all.  That is to say, not running the service when you don't need the service, if that's feasible, is by far the best solution.  Microsoft famously got into so much trouble during all of the early years of Windows, specifically because they were running services by default all the time on every version of Windows, when it was installed, even if users had absolutely no need for doing so.  Remember we lobbied, for example, about the Universal Plug and Play service.  And I just said, you know, it should not be running.  Nobody needs it running.  Sure enough, there was a bug found in it, and it became a big problem.



And we just, you know, the whole issue of SSH came up because remember there was a protocol flaw found in a Windows SSH daemon that was - it was a popular free SSH daemon that it turns out skirts around your need to even log in.  So there's a perfect example of where you just, if you don't need the service running, it's really better not to just leave it open all the time.



Now, for many people it may not be feasible.  The way they operate, their lifestyle may be such that they can't explicitly, for whatever reason, fire up the service when they know they're going to be remotely accessing home.  Maybe they never have notice of when they're going to be doing so.  But it may also well be that a person's mode of using remote access does give them the ability not to have this thing open all the time.  In which case, turn it off when you're not using.  That's by far the best solution.  Failing that, moving it around daily is interesting.



On the other hand, if you didn't know where your script had remapped the port, then you'd have to be checking the port mapping before you left the house in order to know what today's port was that had been chosen.  So that seems a burden also.  Why not just turn it off if you're not using it.  And, you know, if your port's jumping around all over, and you don't know what port it's on, it might as well be off anyway because you're going to have no better luck finding it than a hacker would.



LEO:  Yeah.  I mean, that's security by obscurity; right?



STEVE:  Yeah, I mean...



LEO:  And not even that obscure because a port scanner's going to find it right away.



STEVE:  There's nothing wrong with some obscurity.  That's, I mean, that's just another layer.  But you don't want to depend upon obscurity.  So when people talk about security through obscurity and say that it's a bad thing, what's bad about it is if you depend upon its obscurity.  It's not, you know, there's nothing wrong with adding some obscurity.  That just gives you more security.  But you don't want the obscurity to be the only security that you have.



LEO:  Better to implement port knocking, if you could do that; right?



STEVE:  Yes.  And we've got an interesting question about that, too, in our question bag of today.



LEO:  Well, port knocking coming up.  Let's get to Question 2, however.  Dana Rae Park in Kelseyville, California declares herself to be a "SNite head," she calls it.  Through Leo's radio program, I got turned onto Security Now.  Wow.  That's interesting.  Because usually I think people who listen to the radio program are less sophisticated.  You know, I don't expect them to be the geeks.  In fact, I even say when I talk about the podcasts on the radio show, I say, "Now, if you really want to geek out...."  But this is the geekiest of all the shows we do, so that's pretty good.  Well done, Dana Rae.



It took two weeks, but I finally downloaded every one of Security Now's 220 episodes.  Steve, your reminiscing about old computers took me way back to when I was selling Apple IIs and IBM ATs.  Well, I guess Dana is a geek.  I've been out of the game for quite a while.  Until a couple months ago I was using an ancient Compaq desktop Windows 98SE machine with dialup.  Welcome to the '90s.



STEVE:  Can you still do that?  That still works?  Is there some modem somewhere you can call?



LEO:  Then a friend of mine kludged together an XP Pro machine for me, and my landlady gave me access to her ATT DSL modem/router via a 100-foot cable.  This was a quantum change and challenge for me.  I bet.  Steve, following your advice I use Firefox with Adblock, NoScript, Tree Style Tab, Flashblock extensions, and the very useful KatMouse - five Steve Gibson-recommended Firefox extensions.



She says, when I access the 2701HG-B Gateway System Summary through my browser, there is a Firewall icon which tells me, "The firewall actively blocks access of unwanted activity from the Internet."  Am I behind two firewalls, one on the router and one on XP?  The Summary also says "Your system software is current.  Check back for future available upgrades."  I don't know what the 2701HG-B gateway is.  Do routers phone home for updates like XP?  Am I safe?  Am I practicing safe computing?  SNite Heads For a Safer Internet, she signs it.  That's great.



STEVE:  Well, there are a couple things here.  First of all, I wanted to remind people about KatMouse, which Dana refers to.  I just love it.  And I've noticed, I've been using one of my Macs a lot more than usual for some - actually because the best PDP-8 emulator is running over there.  And I guess the Mac, Leo, when you float your mouse over a Mac window and use the scroll wheel or ball or whatever, it's smart about automatically scrolling the window that you're over; right?



LEO:  Yes.  I never noticed that, but you're absolutely right.



STEVE:  So you don't have to click on it in order to bring focus to it.



LEO:  Wow, that's a nice feature.  I never noticed.  Steve, you found something.  I never saw that before.  You're absolutely right.



STEVE:  Well, it's a fantastic feature.  And what's what KatMouse does for Windows.  And I wanted to bring it up again because I've had so much positive feedback from people who love it as much as I do.  Just the idea that you can have multiple windows.  And, I mean, I'm a scroll-wheel fanatic.  I love my scroll wheel.  And in fact we talked about the Logitech mouse which is still my favorite, that has that high-inertia zero-friction scroll wheel where you can just, like, spin the wheel and go whizzing through things.  It's just great.



LEO:  It's a VX Nano.  In fact, I'm buying more of them.  I love them.



STEVE:  I have some now in stock because I like it so much.  Oh, actually, though, there's a better one, or one that I like better.  And that's the - it's the MX Anywhere.  It's also Logitech.  I think they call it the MX Anywhere Mouse.  What I like about it is that the VX Nano, you have to - it provides you the ability to store the little tiny, tiny little receiver, the USB receiver...



LEO:  Yes, right in there.



STEVE:  ...underneath the mouse.  But in order - and doing so turns the power off, which is what's nice.  But that also necessitates that you're constantly opening the little battery door and pushing the red button to pop the thing out and so forth.  The MX Anywhere Mouse has also internal storage, but the idea is the receiver lives normally just in your laptop, on your laptop.  And then there's a cover that you just slide with your thumb to cover up the laser tracking hole.



LEO:  That shuts it off?



STEVE:  Yes.



LEO:  That's much better.



STEVE:  It's much better.  The mouse also is a little bit larger and a little heftier feeling.



LEO:  It's not a laptop mouse.  It's more of a desktop mouse.



STEVE:  It's more of a desktop mouse.  But no, but it's meant for laptops because it's got the same micro-size receiver.  And so anyway, I really - I've switched to that one, and I like it more because it's a nice-feeling mouse.  But mostly you just, you know, when you're done, you close your laptop, you leave the receiver sitting in the USB hole, the USB socket of your laptop, and then just slide the cover closed on the laser positioner, and it powers it down.



LEO:  So my only question on this, is it a leftie-friendly mouse?



STEVE:  Oh, I'm a left-hander, but I right mouse.  I mouse with my right hand.



LEO:  So is it symmetric, I guess would be...



STEVE:  Not exactly symmetric.



LEO:  It looks like it's slightly asymmetric, but not so much that it might...



STEVE:  No, it's not horribly so.  And I also like that it's got buttons all over it.  It's got, you know, both the - you can do the tilt wheel, and it's got a little button back behind it that works like, for example, the Mac does that Expos thing, is that what they call it, where all the windows short of shrink down and go to their corners so you can quickly choose between windows?



LEO:  Yeah.  It's nice to have those features.



STEVE:  Yes, so it's got all the...



LEO:  And you can remap those if you want.  I mean, you don't have to...



STEVE:  Actually I have.  I've got the mouse - who wants to horizontally scroll?  I never...



LEO:  I know, I don't understand that one.



STEVE:  No.  So I've got that set up for back and forward the browser, so that I tilt the wheel to the left in order to, like, go back to the prior page, or to the right to go forward.  And which frees up the other two buttons on the left-hand side, which I use for top of page/bottom of page in the browser, so I can instantly jump to the top if I just press the upper of those two, or jump to the bottom, which I think is much more useful for me.  So anyway, so yeah.



LEO:  Well, I'm going to try this because I'm running out of VX Nanos.  So I have to get a new one.



STEVE:  Yeah, try the MX Anywhere.  I really like it.  I think it's better than the VX Nano.



LEO:  I'll get a couple of them.



STEVE:  And I've got a few used VX Nanos, if anyone wants them.  No.



LEO:  Don't say that.  You'll get some emails.



STEVE:  And also...



LEO:  Now, let's answer her specific question, though; right?



STEVE:  Yes.  She is behind, Dana is behind two firewalls.  And I thought that was an interesting point that we've never really made before, and it's something we're probably going to be getting used to more and more in the future, is we're all going to be behind an increasing number of firewalls.  You know, over time ISPs are beginning to do some firewalling themselves.  Then you've got the firewall in your router.  But any router, even if it doesn't specifically say it has firewall features, the nature of NAT routing is such that unsolicited packets coming in don't have anywhere to go.  There isn't - by having packets leave the network out onto the Internet, a temporary mapping hole is created to allow packets coming back from that packet's destination have a way to come back in through and know which one of the computers behind the router to go to.  Failing that, unexpected packets just hit the router and drop.  They're just ignored because there's nowhere for them to go.  So any NAT router is a firewall.



And then, thank goodness, Microsoft has turned on their firewall that's built into their OS.  And I think probably every personal operating system now, no matter whether it's Microsoft, Mac, Linux, anything, there's a firewall component there which is blocking unsolicited inbound traffic.  So, yes, there's multiple layers there.



And finally she asks about router firmware, which I think is the most important issue and point of her question.  And it's something I wanted to bring up because routers do have problems.  Manufacturers are finding problems.  And I don't think there's ever been a case where I've checked with my router's firmware, and there has not been an update available.  Many times they're little non-security-related things.  But just the other day we talked about a really ridiculous router that was broadcasting its WiFi key in the SSID that it was using, and also the MAC address.



LEO:  Oh, yeah.  So stupid.



STEVE:  And there was a router that had a default password exposed out to the WAN side.  So there are definitely instances where manufacturers are being apprised of serious problems that firmware updates are fixing.  So I just thought this question was a nice little reminder to me and all of our listeners to go visit your router.  We don't do that very often.  You know, log into your router's admin page.  Now, most routers require you to explicitly check to see if there's a firmware update.  It sounds like this 2701HG-B, whatever it is, if it's volunteering that the system software is current, it does sound like it's phoning home.  It's pinging or doing something from time to time to see whether the firmware is current or not.



Now, a router typically has no way of affirmatively notifying any machines behind it.  So that's why it's necessary for you to go to the router and check in with it and ask it, is there a new version of your firmware?  I would just recommend, you know, I don't know how to add a tickler to everyone's life, except, you know, here, this podcast, #222, Dana's question sort of reminds us it's useful to check in with your router from time to time and see whether there's newer firmware for it.  Because who knows what they will have fixed?



LEO:  Yeah.  It's something I always forget.  So we'll just have to make it, you know, we'll just remind you.



STEVE:  Right.



LEO:  Keep it in mind.  Check it from time to time.  I think there's no - as far as I know, there's no router that does it automatically.  You kind of have to check.



STEVE:  The only thing they could do would be to bring up a web intercept page, which would be a little jarring for people.



LEO:  Yeah.  You don't want to see that.



STEVE:  So if you were trying to go somewhere, and your router blocked you and said, hey, I've got new firmware, I mean, on one hand that wouldn't be - that'd be a cool feature if you could turn it on, and you chose to turn it on.  But it's not the thing you probably want to have on, or certainly not be able not to disable.  So...



LEO:  You might not want to rely on it, either.



STEVE:  Yeah.



LEO:  Question 3 from Andrew DeFaria in Tempe, Arizona with some SSH tips.  Here are some SSH tips you didn't mention for securing SSH.  We should - we've said SSH a few times.  We should mention the secure way to get a terminal session on, at least as far as I know, on Linux and UNIX-based computers; right?  I don't know...



STEVE:  Well, exactly.  It stands for Secure Shell, where "shell" is the term for, like, getting a command prompt window from a UNIX environment.  And there are certainly, you know, we talked about the free SSH daemon the other day that had the problem but is available for Windows.



LEO:  Oh, yeah.



STEVE:  And certainly there is SSH for Windows, as well.



LEO:  What do you get, though?  Do you get a DOS - I guess you get a DOS prompt when you do that on Windows.



STEVE:  Well, and there...



LEO:  I don't know what you would get.  Because, I mean, on the Mac, there's a terminal, you know, there's a command line.  And on Linux there's a command line.  But I guess you'd get DOS.



STEVE:  Yeah.  I would think you would get a command shell.  And actually, you know, the Windows command has become increasingly powerful over the years so that it's not so much just running a pokey old copy of DOS that has no awareness of what the system is doing.  You can start and stop services.  You can reconfigure your Internet connection, I mean, there's all kinds of things you can do now from a contemporary Windows command line.



LEO:  And if you have a web server, SSH is often the way you will manage it and control it.



STEVE:  Well, and yes.  SSH then, the big thing that people do is it can be used as a tunneling protocol.  We've talked about tunneling where the idea being you use one protocol to route packets for another different protocol inside.  And so SSH is often used - it's a little bit of a techie thing to set up.  But it works sort of well.  The other problem is that SSH is a TCP protocol.  And there are all kinds of problems with tunneling TCP in TCP because, if you are in a situation where there's packet loss, then the SSH tunnel will lose packets, but those packets contained TCP traffic that you were tunneling.  And so you can end up with a situation where both of the TCP connections are timing out and are doing retransmits, and you get something called a "tunnel stall" as a consequence.  So the fact is, SSH is not an ideal tunneling protocol.  But it's sort of a poor man's VPN, and it works.  It's not what I would recommend, though.  But, again, it works.



LEO:  Yeah.  So continuing with Andrew DeFaria's recommendations, if you want to run SSH:  Turn off username/password functionality.  Use a preshared SSH key only.  And I do that when I have SSH on my servers.  So that way it's using public key crypto, actually.  It's kind of cool.  You generate a key, and you share that key on the server.  And when you log in, you don't have to give a password because you offer instead your key.  Is that right?  Am I understanding it correctly?



STEVE:  That's exactly right.  And it's something I should have mentioned.  So when I saw this, I thought, ah.  And I ought to give other people credit.  Many other listeners who use SSH said, hey, Steve, forget about this whole username/password guessing altogether.  Remember we've talked many times about how SSH servers are coming under tremendous attack from just brute-force password guessing.  So it's possible to completely eliminate username and password functionality and, as you say, use PKI, public key infrastructure, use a previously set up SSH key which your roaming client, your remote client will have, your local server will have, and that's the way you negotiate the connection.  So there, you know, you can let them pound on your username and password all they want.  They will never get in because they won't have this preshared key that you've established beforehand.  That's absolutely the secure way to go about this.  But it's, you know, takes a little bit more configuration.



LEO:  Yeah.  I have a whole step-by-step thing that I just run.  Tell you, it's a real convenience, and it's kind of nice, it's one of those few things where it's more convenient and more secure.  So it's kind of a nice thing to have.  You know, I just SSH to my server, and I'm in automatically.  And nobody, I think nobody else, unless they could get my key, could do that.



Step 2.  This one's even more complicated.  I put together a Perl script I call "bice" that scans the logs nightly looking for attempts to break in (of course they can't because they'd need a preshared key but try they do nonetheless) - and I see that in my server logs all the time, dozens and dozens of attempts.  And they just - it's brute force.  They're just trying random passwords - and then emails the upstream provider to tell them to stop.  I'm not sure that's such a good idea.



STEVE:  That's exactly my feeling, Leo.  I get, I mean, I've been running Security Now! for - Security Now!.  ShieldsUP!.  Been running ShieldsUP! for I don't know how many years, and we've got - we're on the high side of 80-something million uses.  And every so often there's some, I won't use any derogatory term, there's a person who has some sort of automated log-reading emailer that emails complaints to Level 3 that I'm trying to break into his system.



Well, I've never done that in my life, and I never would.  You know, he's using, he or some user in his network, is using  ShieldsUP! over an SSL connection so that we know that we're bypassing any proxies and we're connecting directly, we get the real IP.  So it means that, you know, he asked us to scan the ports of his machine, which then logs the scan, and has an automated emailer that sends out complaints to everybody in the world.  So, and I among them.



So it's just - this automated email thing I think is just really dumb.  And unfortunately it's done enough that all it's doing is causing the security services that are valuable, that belong to ISPs, to stop reading their mail because they get all this automated crap, frankly, that they just think, well, there's no person here.  This is just some bot that the guy set up, and oh, isn't that clever, read his logs and send email.



LEO:  Yeah.



STEVE:  No.



LEO:  Yeah.



STEVE:  Bad idea.



LEO:  And, you know, there's so many break-ins, I don't really - or attempts to do this, I don't really monitor them because it just tells me something I already know.  Most of them come from China.



STEVE:  IBR, Leo.



LEO:  What's that?  Internet Background Radiation.



STEVE:  Internet Background Radiation.  That's my acronym for it.  Unfortunately, this is the reality.  We've got worms, I mean, this Code Red is still out there, living on some machines, scanning around, looking for a vulnerability that we hopefully knocked off, you know, many years ago.  If you grab a bunch of IPs and monitor the traffic, there's just garbage on the 'Net now that will never go away.  It's Internet Background Radiation.  It's not aimed at you.  It's just aimed at random IPs and hoping that, you know, I mean, stuff that's just dead, that just, I mean, has no chance of finding any recipient target.  It's just out there, you know, packets on the 'Net.



LEO:  It's amazing, isn't it.



STEVE:  Yeah, it really is.  I mean, it's sort of like a life form now.



LEO:  It is, it's alive.



STEVE:  Yeah.



LEO:  Tip 3, you mention you can't trust your logs if the hacker gets in.  Seems to me a nice modification would be to change syslog or other logging facilities to shadow all logs to a location not known to the intruder, perhaps even on another system, then perform comparisons with the original and shadowed log files.  Any discrepancies would indicate a break-in to be investigated.  This is actually a class of larger programs, intrusion detection programs that do things like this; right?  They're always looking for changes in fundamental system files.



STEVE:  Well, again, there's a right way and a wrong way to do this.  And I thought this was an interesting point.  I mean, I agree with Andrew.  The problem is, if you change syslog or other logging facilities that are running on that machine to also log somewhere else, how is that going to be unknown to an intruder who's intruded into your machine and is able to look at everything you are?  So the only way to do this is if you are logging on the wire, as they say.  That is, not logging in that machine and having that machine send duplicates of its logs somewhere else because, if it's doing that, then presumably the bad guy can know that and go there in order to defeat them.  And in fact we've seen recently a situation where bad guys were able to get in and were able to use the keys that a logging system had in order to then gain access to the system they were logging to.  So exactly this kind of thing can be done.



The only way to do it safely is if you have sort of a separate machine which the machine it's monitoring has no awareness of, which is promiscuously monitoring all of the data, and exactly as you said, Leo, like an intrusion detection system.  It's looking at all the traffic and logging it itself.  In fact, such a machine doesn't even have to have an IP.  I've got one myself set up that way at Level 3, a machine which is logging all the traffic, but it's able to be on an Ethernet without an IP.  Because remember, Ethernet uses MAC addressing.  And the IP layer, which is created by ARP, is just a convenience to allow machines to be numbered by Internet protocol within the network.  But it's entirely  unnecessary.  So I have a machine that you cannot address by IP because it doesn't even have one.  And it works just great, monitors all the traffic on the network.  And that makes it quite invulnerable.



LEO:  Let's move on to our next one, shall we?  But anyway, thank you, Andrew, for some good ideas.



STEVE:  Yeah.



LEO:  It's all about thinking about security.  That's the main thing.



STEVE:  Great talking points, absolutely.



LEO:  Duane McElvain in Chicago, Illinois wants some clarification on SSL.  Oh, boy.  You gave me such bad news this morning.  Ai-yai-yai.  Steve and Leo, on a previous episode someone brought up the idea of using SSL on every web page, every time.  This sounded brilliant to me, and I believe your consensus was that, while it's not necessary, it's a great idea.  Actually we said that the cost nowadays on modern machines is so low, why not?  The drawback is the server overhead could be crippling - I guess he's right.  For a high-volume site, that could maybe be a lot of overhead.



STEVE:  Because, yes, all of the individual users are concentrating their connections to a single server.



LEO:  Yeah.  Wasn't really thinking about that.  Later in Episode 220 you were discussing public key encryption bit lengths and how (roughly paraphrased, please forgive me) 2,048 bits is mathematically a huge jump up from 1,024, but processors these days have no problem with it so that's why some sites potentially use 2,048 bits.  Pardon the nitpick, but which is it?  Is it overwhelming or not?  I just want to make sure I'm understanding you two correctly.  Do you think that encouraging (if not requiring) SSL for all websites would work without crippling web server capacity?  If not, what's the downside (aside from computational cost)?  I'm a big fan and have been since the single-digit episodes when I 

discovered your show. SpinRite has saved my bits at least twice.  Yay.  Keep up the fantastic work, both of you.  Regards, Duane McElvain. 



STEVE:  Okay.



LEO:  He's confusing issues here, isn't he?



STEVE:  Well, it's because it's a confusing issue.



LEO:  Yes.  I'll give you that.



STEVE:  If we were still back in the days of HTTP 1.0 and SSL version - well, I would say v1, but that one never really went to the world - v2, then there was a concern because browsers were initiating connections for - there was a constant stream of connections, maybe 10 or 12 or 15, if you had a page with lots of, for example, images on it.  When the page came with all those image references, the browser would open connections, individual connections to retrieve each one of those images.  If you didn't want the so-called mixed content warning, where it says remember - and IE and various browsers like Firefox have different terminology.  But it's that warning that says this page contains some secure and some insecure content.



Well, that freaks people out.  But normally that means that things like ads or images are not coming across SSL, where the page itself did.  And it can be a concern, but it's not necessarily a concern.  So the way you solve the problem is, if the page comes across by SSL, then you'd like all of the references to also use SSL, so the whole page is secure.  That meant that, back in the HTTP 1.0 days, that the browser would open a flurry of connections back to the origin server in order to retrieve all those bits and pieces.  So each of those connections would require an SSL handshake and would seriously damage the server.  So back then the webmasters quickly learned not to leave sites in SSL.  Switch the user into SSL when necessary, and quickly get them back out as soon as not because it was going to be much faster.



Well, many things have happened since then.  So we went to v3 of SSL, also known as TLS, that we'll be discussing next week for reason of this recently found man-in-the-middle attack problem.  One of the things that we learned when we talked about the SSL protocol in detail is that it is possible to cache credentials.  That is, that expensive setup process only needs to be done once, the first time a client and a remote web server talk to each other.  There are time limits.  But they're ample.  And what that means is that the client is able to say, hey, I have a fresh credential from a recent connection to you.  How would you like to reuse that?  There's no reason for the server not to do so, and servers do.  What that does is it completely short-circuits the expensive part of the public - the expensive public key part.  They do negotiate a new shared secret symmetric key, which is what you want for a new connection.  But that's instant.  That takes no processing power at all.  So first of all, you get credential caching.



The other thing that happened is HTTP evolved.  That is, the protocol that SSL would be carrying evolved to 1.1, where browsers stopped opening individual connections for every asset that they were querying from a given server, and by default they limit their connections to two so that a browser will open up to and no more than two connections, and then the protocol was enhanced so the browser could pipeline.  The browser could send multiple queries to the remote server.  The remote server could return multiple assets all over a single connection.  So instead of bringing up a connection, getting one object, and then taking it down, bringing up another connection, getting one object and taking it down, now the browser will bring up some semi-persistent connections and do all of its work through them.



So even if you didn't have credential caching, you no longer have a flurry of connections being brought up.  The browser brings up to two connections and then will hold onto those as the user moves around the site, being able to continually move pages and the server's assets, other site assets, buttons and images and so forth, through those connections.  So my feeling is both with SSL 3, also known as TLS, with its credential caching, and the fact that all browsers now support this pipelining of multiple assets through a single connection, there just would not be a burden on contemporary servers if the sites used those features and left people in SSL all the time.



LEO:  There you go.  The definitive word.



STEVE:  You're right.



LEO:  Jason M. in San Diego raises an interesting point:  Steve and Leo, thanks for the great podcast.  I always look forward to seeing the latest episode pop up on my media player.  I have to take slight issue with your justification of - well, here we go, this is right down your alley here - of using public keys of 1,024 bits, specifically that they will expire after usually no more than three years.  Now, that's true of the certificate, but not necessarily true for the key.  The certificate may expire, but nothing prevents the site operator from generating a new Certificate Signing Request (CSR) against the same public key.  I would even be so bold as to wager that very few sites actually generate new key pairs in conjunction with a new certificate.  Likewise I could wager that the Certificate Authorities do little, if anything, to prevent their customers from reusing key pairs or even informing their customers about the issue.  As someone deeply involved with security, I'm always impressed that each episode provides new, relevant information.  As someone who does technical education and presentations, I'm amazed at how smooth and professional each episode is.  Keep up the great work.  Well done, Steve.



STEVE:  Well, Jason raises a great point.  So let's elaborate a little bit.  What he's talking about is that there's sort of multiple steps for manual production of a key over in the UNIX world.  In the Windows world, it's pretty much automated.  And he raised a question, and I thought, well, I wonder if all of my keys, for example, for GRC.com over the years have been the same.  So I went and looked.  And every single one of them is different.  Microsoft encapsulates the...



LEO:  It does it automatically.



STEVE:  Exactly.  It encapsulates the process through the GUI.  You press a couple buttons.  And it says, okay, where do you want to write your new CSR, your Certificate Signing Request?  So what's happened behind the scenes is that a hopefully very good, cryptographically strong, random number generator has generated a new key pair, a public and private key pair, which you want to be based on very good, high-quality randomness so that it can't be guessed.  And remember then that what we're doing is we're keeping our - we're keeping one of those to ourselves.  It's secret.  The other one we're going to be publishing.  So what we want is we want then - we want to provide those to the certificate authority to prove that we're the owner of this key pair, and then the Certificate Authority is going to digitally sign what we call the Certificate Signing Request.  We send them the CSR, the Certificate Signing Request, requesting that they sign the certificate.  So it's that certificate that then has this typically three-year expiration which is enforced by the Certificate Authority.  You can typically buy certificates for one, two, or three years, not longer than that, which is annoying.  But that's - it's a tradeoff.



LEO:  Well, they have, yeah, they have to have some expiration; right?



STEVE:  So Jason's point is that, since technically the typical user controls the generation of the CSR, that there's nothing to prevent the user from just having the Certificate Authority resign the same key pair.  And he's right.  Over in the UNIX world, using for example the OpenSSL package, you have a much more manual process for generating your certificates.  And if for some reason you wanted to keep the same public key pair, you could do so.  You could simply use the same one to submit, to generate a Certificate Signing Request to a Certificate Authority.  They would sign it.  I mean, they're doing no policing of whether...



LEO:  It's not their job.



STEVE:  Exactly, it's not their job.  And that's the other key point is, yes, they're definitely not going to tell you, wait a minute, this is the same key pair you gave us three years ago.  Well, yeah.  You may have a reason for wanting to do that.  I can't think of a good one, but you might.  So Jason's point I think was very well taken, that is, that certainly anyone who understands security will absolutely change their public key pair.  They'll take the opportunity of renewing their certificate to do that.  But he's completely right that there's nothing, nowhere in this system are you forced to do so.  And what that would mean is that a 1,024-bit public key could have a lifetime greater than three years.  It could have a lifetime of 40 years.



LEO:  Forever.



STEVE:  50 years, if you kept - if you insisted on continually using the same one.  You'd be exposing yourself to a larger attack window because there would be much greater time for someone to get to your key.  I can't think of why you would.  Windows doesn't give you the option.  UNIX does.  But standard protocol always has you regenerating your public key when you're updating your certificate.  So even then, it seems unlikely that it would happen.  But his point is a very good one.  It could.



LEO:  Yeah.  Just something to be aware of, again.



STEVE:  Well, and I liked it from a theoretical standpoint.  It strengthens our understanding of what's going on.



LEO:  Yes, exactly, yeah.  Paul Wilde in Bristol, UK feels that security shouldn't annoy the user:  Guys, love the show, very informative.  I'm in the UK.  My bank, Smile - makes you just happy to be doing business with them - has just introduced two-factor authentication with the addition of a card reader pin-generating add-on.  Great, I hear you say, but it's not.  It's a big calculator-sized thing you have to use when you want to use functions like bill paying.  Great, I hear you say again, but it's not.  It means you can only pay bills, et cetera, when you have this stupid, fat, ugly thing with you.  A credit card-sized add-on or a key-ring dongle is the way to go.  It annoys me so much I'm moving the bank account.  Keep up the information overload.  Best, Paul Wilde.  You know, the best to me is cell phone.  And my bank, BofA, uses that.  You press a button, it sends you a text on your cell phone with a number, and you use that.  And I always have the phone with me.



STEVE:  Yeah, I think that's pretty good.  It's funny, his - first of all, I completely understand.  I think his bank is going to get a clue pretty quickly as they start losing accounts when they tell people.  And this big thing can't be cheap, either.  So I'm wondering, you know, who's paying for this big calculator-sized thing.



I overheard a conversation at Starbucks last week that I made a note, I mean, literally right then I sent myself a text message or email so that I would get it at home, so I would make a note, so I could share it with our Security Now! listeners.  A guy explaining to his buddies that the password policy at his company was so obnoxious because they made him change his password periodically.  And so immediately my ears perk up.  It's like, oh...



LEO:  That's good.  That's what you're supposed to do.



STEVE:  That sounds like a good policy.  And he says, the problem is they apparently remember the passwords you had before.  So you can't change to the same one.  You can't fake it out and use the same one and not really change it.  Nor can you change to the one that you had before.  So you can't ping-pong between two.  And at this point everyone started listening with rapt attention.  And he says, I figured out that apparently they remember the last five.



LEO:  Wow.



STEVE:  So every time I am told that I have to change my password, and I don't want to because I like my password, I sit there and change it...



LEO:  Five times.



STEVE:  ...five times.  And the final time I go back to the password I want.  And I just...



LEO:  That's just silly.



STEVE:  I was, well, but here's the point.  This is, I mean, there's a big lesson here, of course.  That is, if users are absolutely determined not to have security, they're going to arrange somehow not to.



LEO:  Well, yeah.  Even if it's a real big pain in the butt, apparently.



STEVE:  They're going to write the password on their forehead.  They're going to scratch it onto their LCD screen.  They're going to do something.  I mean, they're going to stick it underneath their keyboard.  They're going to do whatever they can, you know, to get around the best security intentions of whoever's trying to protect them from themselves.  I mean, you could imagine this policy where it's like, okay, we'll remember the last five because we really, really, really, really, really want you to change your password and not use any that you've used before.  Now, all of us, any of us who are programmers or algorithm designers, we know how to defeat what this guy has done with his, you know, five in a row.



LEO:  You make it for 20.



STEVE:  Well, you make it 20, or you prohibit them from changing the password...



LEO:  Right, five times.



STEVE:  Like once a day or something.



LEO:  Yeah.  Yeah, yeah.



STEVE:  Anyway, so I just - I got a big kick out of the idea that this guy was - he was just determined to keep the password he likes.  Which if course is really not secure.  It's like then never changing your password, and he's figured out how to arrange never to change his password.



LEO:  It blows my mind that he goes to such lengths to do it.



STEVE:  Yeah.  And, you know, and so when I read Paul's note, "Security shouldn't annoy the user," I thought, okay, well, and on the other hand, security policy should try to strike a balance between not annoying the user and getting the user to behave.  I guess, you know, it would take maybe some security training for this smart-aleck whom I overheard at Starbucks to understand why this was in place.  And, I mean, and he could use different passwords for every month of the year or something so that he...



LEO:  He's just determined.  He says, I don't want to have to remember another password.  But, I mean, the amount of time it must take to enter and change it five times...



STEVE:  Yup.  He's going to win.  He's going to win.



LEO:  That's really what it's all about.  This has nothing to do with anything but I'm just mad, and I'm going to win.  Jason in Rochester, Minnesota had a brainstorm:  Steve, I got an idea while you were talking about port knocking a couple episodes back.  Since each port knock conveys one fewer than 16 bits of information - okay.



STEVE:  Well, okay, yeah.  Remember, because ports go from - there's no port zero.



LEO:  There are 16 bits a port.



STEVE:  16 bits a port, but minus one because there's no port zero.



LEO:  Right.  65,000...



STEVE:  So it's 65,535, not 65,536.



LEO:  Okay.  One fewer.  Four port knocks equals close to, but not exactly, 2^64 combinations (16 billion billion).  But if someone happens to be sniffing the traffic during a valid knocking sequence, they'd know the combination.



STEVE:  Uh-huh.



LEO:  That's kind of a problem.  What if something like the old PayPal football were used?  The ports knocked would be pseudorandom depending on a preshared key, you'd salt it with the key and the time of the day, let's say.  What do you think?  Jason in Rochester.  I like that.



STEVE:  Yes.  Well, first of all, I'm not a fan of port knocking.



LEO:  Oh, really.  Okay.



STEVE:  Yeah.  Well, it's so prone to problems.  First of all, the Internet is known to deliver packets out of sequence.  That is one of the big, you know, big things that the TCP protocol guarantees is that, at the application layer that is above the protocol, everything will be in sequence.  So, for example, when you download a file, you're  just downloading - you set up a connection, and this binary blob comes through TCP.  Well, you want to know that all of the chunks of the file that you receive are in the right order.  So the application doesn't have to worry about that at all because TCP uses sequence numbers specifically to make sure that the packets that are being reassembled at the receiving end are in the proper sequence.  And in fact, packets often arrive out of order, and then the TCP protocol will hold an out-of-order packet, waiting until a missing packet to fill in the gap comes along.



So here we have a problem with port knocking because what this means is that, if you send packets out to remote ports, you have to wait a long time to make sure that that packet got there before you send another packet.  And if you send them too quickly, you risk the chance that they will arrive out of order since routing can often do that on the Internet.  And in that case you've got a bad knock.  So then you couldn't connect, and you don't know why.  So you do it again.  And maybe you luck out this time.  I mean, it's just - it's error prone.  The first patent actually that I already have pending for CryptoLink's technology is an invention which solves this problem completely.  And it does it in a single packet.  And it's very cool.  And we'll talk about it when I can.  But aside from the fact that port knocking has these problems, it's nice; and it's, I mean, it's clever.



So what Jason has suggested is, well, first of all he highlighted the other big problem.  And that is that, if you have a static knocking sequence, which is the way most systems are configured, then you are protected from somebody randomly trying to access a service.  So what the port knocking does is, if you knock in the proper sequence, by sending, for example, in Jason's example, four packets to successively different ports, in the proper sequence, something is monitoring that and will see that and go, oh, that's the secret knock, and then will open a port to allow anybody incoming.



Now, hopefully, if it's clever, it will only allow the same remote IP as the packet's source IP.  So you've opened a port that is still filtered only to accept incoming traffic from you, the source of the knocking packets.  Many systems don't do that.  They open it for everybody, and that's, again, not as much security as you could have.  But anyway, that's what the knocking does is open a port that you are then allowed to use to access a service that's been protected until then.



So the problem is, as he points out, if your connection is being monitored, somebody eavesdropping who, for example, knows you're using port knocking, if you have a static knocking sequence, all they have to do is repeat the knocking sequence, which they captured from the wire, and the port will open for them.  And then they're in.



So his notion was use a port-knocking sequence which changes.  Now, time of day is a possibility.  But there's actually a better approach.  And it's - which can function very well.  And it's a little more like the way the VeriSign credit card works, where it's a known sequence rather than a known time.  That is, there is a counter which is encrypted with a secret key.  So if you take a counter, and you run it through - say a 128-bit counter, and you run it through a 128 symmetric block cipher, you're going to get out 128 bits which are pseudorandom.  Every time the counter counts up, these bits are going to change to something different.  So you then - you take that 128 bits, and say you just took the lower 64 for our example.  So those 64 bits give you the - you break it up into four groups of 16, which give you the port you want to knock on.  So the receiver would have a synchronized counter so that it's able to anticipate the knocking sequence that comes in.



The problem is that you might have a packet dropped.  And that's another problem, is that the Internet not only resequences packets, it has a complete freedom of dropping packets at will if any router's buffers are too full along the way.  So many different things could cause this knocking sequence to have a problem.  Meaning that these counters would get out of sequence.  The beauty of this approach, though, is that if you sent two knocking sequences in a row that got through without any packet loss or reordering, and there's always a problem with port knocking, but if you did, then the recipient would be able to decode the knocking sequences back through the secret key and see that, even if the counters were out of sequence, then what happened was two successive counts.  That is, the knocking sequence, when decrypted, turned into a count, and then a count plus one.



Well, the only way that's possible is if the other guy who sent the packets had the same secret key.  So you've authenticated yourself independent of time and independent of bad knocks and their counters being desynchronized.  It would allow multiple users to authenticate through the same system, if they had counters in different states.  So it's a cool way of using two successive knocking sequences to prove that you know the secret key, even if you don't know what time it is, that is, you're not timer based, or if your counters are in different states.  So with the limitations of port knocking, it is possible to come up with something that could not be sniffed.



Oh, and the other thing you do is you never accept a knocking sequence that you've seen before.  That is, this counter counts up for every knocking sequence.  There would never been an instance where you would get an obsolete knocking sequence.  So you only allow them to move forward in time, much like the football does moving forward in time, or the counter in the VeriSign credit card does.  So it's possible to make it work.  It's just tricky.  And because of the problems of packets not arriving reliably or arriving out of sequence, the whole knocking thing I don't think is a great solution.  And there are better ones.



LEO:  That's great to know.



STEVE:  Yeah.



LEO:  Yeah.  I wasn't aware of that.  Last question, our Biometric Abuse Question of the Week.



STEVE:  Or story.



LEO:  Story of the Week.  Michael OConnor of Oswego, Illinois shares his Biometric Abuse Story of the Week:  

Dear Steve and Leo, I'm flabbergasted.  Like many married couples, my wife and I each have our own checking account in addition to our joint account from which we pay our bills.  Every couple of weeks each one of us goes to our respective bank, withdraws some cash from our own account, and deposits it into our joint account so as to have funds immediately available.  We've done this for a couple of years.  There's never really been a problem until today.  Since my wife wasn't feeling well, I told her I would handle the 

transaction for her.  All she would need to do is write out a check to me drawn on her account.  I'd take it to the bank to cash it.



When I pulled up to the drive-thru, where I presented the check, the teller asked if I had an account with them.  I said no, but mentioned my wife did.  The teller said I would need to come into the branch in order to complete the transaction.  I wasn't pressed for time, and although it was a slight inconvenience I was happy to comply.  When I got into the bank I approached the teller window, mentioned I needed to cash a check drawn on their bank.  The teller asked me if I had ever cashed a check with them before.  I informed her that I had not.  She said that in order to cash the check, mind you it's drawn on the bank I'm attempting to cash it at, she would need to see ID, but would also need to scan my fingerprint.



I can only imagine the look that I must have shot back.  "What?" I asked.  "You need a scan of my fingerprint before you will cash this check?  I won't do that."  I guess I caught her by surprise based on her response, where she assured me that the only way they would cash the check is if I provided them with my fingerprint.  I asked to speak with a manager, and the manager informed me of the same thing.  It's bank policy, and no exceptions would be made.  I asked to speak with her boss, who a little less politely told me the same thing.  To be honest, they actually made me feel like I must be hiding something if I wouldn't let them scan my finger.  I shared with her my opinion of the bank's policy and quietly departed, feeling emotionally mixed between pissed off and violated.



Over lunch I continued to ponder what had just happened, and I couldn't believe that what the bank was doing wasn't a violation of my privacy.  After all, I had provided them with a state-issued ID.  And there was no reason to believe I was committing a crime.  Therefore there was absolutely no reason for them to need to access my biometric data.  I'm not sure how far I'll take this impromptu crusade of mine (EFF, are you listening?).  But I thought I'd start by sharing it with you guys.  After all, when it comes to computer security and privacy, you guys are one of the first resources I turn to.  Thanks for letting me share my tale.  Best, Michael OConnor, Oswego, Illinois.  It sounds like this might be something since 9/11 would be my guess.



STEVE:  Well, first of all, I completely agree.  We've talked about the whole issue of biometrics.  It's a mixed blessing.  The blessing is mixed because biometrics are not something you can change.  You're able to change your password anytime you want.  But your fingerprints are you.  And that's what makes them so valuable, for example, in criminal forensics is people tend to leave fingerprints behind, and that uniquely identifies them as being them.  The problem is, electronic security is basically repurposing something which I think has substantial value.  Now, I can, I mean, when I renewed my driver's license last time, you know, I've been - I don't drive that much, so I have not been on, literally, on the police radar for a long time, and I think I went however many the maximum years is you can go.  And then they said, well, look, you know, we've extended you automatically as long as we can.  You need to come in now, make sure - you need to let us see you because we haven't seen you for so long, and make sure your eyes still work and so forth.



So I was annoyed that the California DMV wanted my fingerprints.  And it's like, okay, well, fine.  I mean, that's - I have no choice there.  But I would argue, as Michael did, about casual disclosure, like we've talked about the Disneyland card gate, casual disclosure of biometric data.  We don't know what the bank is doing.  I don't trust the databases in general to keep this information from leaking.  We're constantly hearing stories about this data getting loose.  And I would hate for my fingerprints to be surfing the Internet without me.  That's just - that's creepy.



So anyway, I really do, I really think that, I mean, first of all, as he says, he's got a valid state ID.  It's his wife's check that he's cashing, so she's got the same last name as he does.  I mean, this really does seem like a rigid policy.  And I've got to wonder, I mean, you know, obviously this is not a huge check.  If this is what they do every couple weeks for spending money, it's probably a few hundred dollars.  It's not, you know, $10,000.  So I don't know, it really does seem like a bad policy.



LEO:  I think we're seeing it more and more everywhere.  But I think he raised a really important issue, which is that you get one and only one.



STEVE:  Yeah, exactly.  And if it gets loose, it's loose.  I mean, yeah.  And just casually, cavalierly scanning them into some database is like, oh, I don't know.  I mean, I would like a firm explanation from the bank.  And I don't think Michael got one.  All he got was "It's our policy, sir."



LEO:  Well, presumably, if she had mailed me the check - you know, it's because he's cashing it at the window.  I mean, if he deposited it, they wouldn't require - that's what's bizarre about it.



STEVE:  Right.



LEO:  I mean, that check is something that the bank honors, and transfers money on the basis of, all the time.  But it's just because he's asking for cash at the window, I guess.



STEVE:  Yeah.  And, you know, I guess I question it being anything relative to 9/11 because I don't think everybody else is doing this.



LEO:  Unless it was a huge check.



STEVE:  Yeah, exactly.



LEO:  I don't know.  That's, yeah, very bizarre.  Well, Michael, let us know what happens.  That's not good.  And Steve, we've come to the end of another thrilling, gripping edition of Security Now!.



STEVE:  Number 222.  223 is going to talk about this recent bad news for SSL, the latest, greatest version of SSL and TLS, and how a hacker has found a way to insert plaintext into a transmission during renegotiation of security credentials during an established connection.  That's not good.



LEO:  Unh-unh.  Wow.



STEVE:  I mean, basically what it means is all clients and servers will have to be updated.  This is not like something you can work around.  This is the SSL protocol, or TLS I guess I really ought to start calling it because that's the official name.  But it needs to be scrapped.  Version 3, or TLS 1.0, we need to go to 2.0 of TLS.  That's the solution.  And it necessitates SSL being changed everywhere.



LEO:  Yeah.



STEVE:  It'll certainly be - SSL is very tolerant of backward compatibility.  So new versions will come out that close this hole, which will still run back versions.  But there'll be an impetus for everyone to update their browsers and their - actually it's probably the operating system level.  So it'll be another patch that'll come out from Microsoft and the various Linuxes and Macs and so forth that'll fix this.



LEO:  My friend, we have come to the end.  People, there is much more if you go to GRC.com - 16KB versions of the show for the bandwidth-impaired, Elaine's great transcriptions, all the show notes.  And of course GRC's the home of SpinRite, the world's best hard drive maintenance and recovery utility.  You must have it if you have a hard drive.  And all of Steve's free stuff, too, some great, wonderful free programs like ShieldsUP! and Wizmo and on and on and on.  Just go to GRC.com, Gibson Research Corporation, for more information.  Steve, once again we have been nominated for a podcast award in the technology section.  You won, I think, last year or the year before.  So...



STEVE:  Yeah.  We cheated, though.



LEO:  What, we asked people to vote for us.



STEVE:  Yeah.  We used our listeners, who just overwhelmingly came out.  And we just swamped everybody else.



LEO:  We shouldn't do that.  So I won't mention that if you wanted to vote for a show on the TWiT Network, that you would go to PodcastAwards.com and, starting November 13th, cast your - I wouldn't say that because, you're right, that wouldn't be fair to the other guys.



STEVE:  It wasn't even a contest.  Our listeners stood up for us, and it was game over.



LEO:  Yeah.  So whatever, you know, just forget that I mentioned that.  We're nominated - a lot of shows are nominated this year round.  So...



STEVE:  You mean there's, like, other people than TWiT?



LEO:  Oh, yeah, yeah.



STEVE:  Awww.  In that case, everybody, let's go swamp everybody else.



LEO:  Yeah, I didn't mention that part.  There is a competition here.



STEVE:  We don't want you to lose.  We want one of the - we want the TWiT shows to win.



LEO:  Nah, that's fine, I don't care.  Hey, Steve, it's great to talk to you.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



LEO:  I don't care if we win.



STEVE:  It's fun to win.



LEO:  You're nominated for Best Technology, along with - I think you're the only - oh, no, Floss Weekly is also in that category.  And there are some categories where we're competing against each other.  It's silly.



STEVE:  Yeah, actually there were a lot that I noticed that were like that last time.  I mean, where it's like, wait a minute, you know, I mean, I...



LEO:  Basically all of them are nominated.



STEVE:  Yeah.



LEO:  All right, my friend.  Thank you so much.



STEVE:  Absolutely.  Talk to you next week for a propeller-spinning episode on SSL.



LEO:  That'll be very interesting.



STEVE:  Yeah, absolutely.  Have a great week.



LEO:  Thanks, sir.  Take care.



STEVE:  Take care.  Bye bye.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#223

DATE:		November 19, 2009

TITLE:		A Security Vulnerability in SSL

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-223.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo plow into a recently discovered serious vulnerability in the fundamental SSL protocol that provides virtually all of the Internet's communications security:  SSL - the Secure Sockets Layer.  Steve explains exactly how an attacker can inject his or her own data into a new SSL connection and have that data authenticated under an innocent client's credentials.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 223 for November 19, 2009:  The Trouble with SSL.



It's time for Security Now!, the show that covers security in great detail, sometimes excessively geeky detail.  And that's because this guy's a geek, Mr. Steve Gibson of GRC.com.  And that's why we love him, because unlike the others, on this show you learn how it works.



STEVE GIBSON:  Can you have too much detail?



LEO:  No.  No, you can't.



STEVE:  Not for our audience.



LEO:  Well, that's the point.



STEVE:  Not for these guys.



LEO:  That's exactly the point.  These guys love that stuff.  Hello, Steve.  How are you?



STEVE:  Leo, it's great to be with you again, as always.



LEO:  You have a good week, I hope?



STEVE:  Had a great week.  And we have a great episode.  This one, this is just classic, perfect Security Now!.  It's tech-y; it's relevant; it's important; it's a real problem.  The industry has been secretly scurrying around and meeting and trying to figure out what to do about it.  The good news is there's something that can be done about it.  But, I mean, it incorporates all aspects of sort of the security world that we've been talking about for more than four years.  So this is the recently discovered problem in SSL, which turns out to allow bad guys to insert their own badness into connections that everybody at each end thinks is secure, but it's not.



LEO:  That's pretty serious.



STEVE:  It's bad, yeah.



LEO:  That's pretty serious.



STEVE:  It's not good.



LEO:  And before we get to that, I know you probably have some errata and security news to cover, as well.



STEVE:  Yup.



LEO:  I want to remind people that your show is nominated in the Podcast Awards.  And they have till November 30th to vote, so you're kind of down to the end now.  In the technology section; am I right?  [www.podcastawards.com]



STEVE:  Yes, the technology section.  Although, I mean, we really do need to make a determination here, Leo, you and I and...



LEO:  I'm going to let people vote their conscience.



STEVE:  Okay.



LEO:  Vote for your favorite.  Well, the reason you're saying this, I know, is because there are two TWiT shows nominated.



STEVE:  Right.



LEO:  Security Now! and FLOSS Weekly.  And by the way, there are other excellent shows also nominated, like Skepticality, which is really great; The Naked Scientist; Bwana.TV.  So there are plenty of...



STEVE:  No.  If they're not on the TWiT network, forget about it.  No.  No.  No, that would be really interesting.  It would be great if the listeners to this podcast really did vote for their favorite podcast, this one or FLOSS.  I'd love to know.  I'd be - that would make the number more useful and interesting than just overwhelmingly, okay, we told everybody to please click this button.



LEO:  Yeah.  We don't want to lobby.



STEVE:  No.



LEO:  And by the way, you won this category I think last year.



STEVE:  It was year before last, yeah.



LEO:  Year before last.  You've won it a couple of times.



STEVE:  I think it was the first year.



LEO:  First year you won.  You won again the year before last.  It's not like...



STEVE:  At one point...



LEO:  At this point it's emeritus.  So, but we do want people to vote.



STEVE:  The old man on the hill is still up there on the hill.



LEO:  Exactly.  We do want people to vote, mostly because it's a great way of bringing awareness to podcasts.  And vote for your favorite podcast, whatever it is, at PodcastAwards.com.  You'll have till November 30th.  You can vote every day.



STEVE:  You can?



LEO:  Yeah.



STEVE:  It's not one per person?



LEO:  No.  You can vote every day.



STEVE:  Oh, goodness.  Oh.



LEO:  So stuff the ballot box.  Be my guest.  Actually that's one way you could solve this.  You could vote for Steve one day, Randal the other day, and mix it up.  They're all my children.  I'm not going to select.  Just vote your favorite.



STEVE:  You like all your children equally.



LEO:  I love you all deeply.



STEVE:  That's important, Dad.



LEO:  So what do you want to do first, news or errata, Mr. Gibson?



STEVE:  News, we've got some security news.



LEO:  Okay.



STEVE:  Not surprisingly.  One of the - I was going to say the "baddest."  One of the worst problems that Microsoft patched last Tuesday, last week, the second Tuesday of November, is heavily expected by the security community to be exploited very soon, if it's not even - if it's not already being done.  So I wanted to further encourage - I know that the fact that Microsoft patches typically require you to reboot your machine, I know that I've been in a position where I've got so many things open and set just the way I like, and I'm in like the middle of things, that rebooting the system right then is a problem.  But there's this problem with the embedded open type fonts, EOT fonts, which, well, there's a couple lessons here.  It's a font-parsing bug which allows remote code execution.  The problem is that it's a kernel bug.



LEO:  Ooh.



STEVE:  So it's an overflow that occurs in the kernel.  Well, since these EOT files can be compressed and encrypted by their spec, their spec supports encryption, that makes it extra difficult for antiviral software to see what's going on, because it's an encrypted payload.  And so that's expected to thwart AV.  And so it'll be systems which simply load a page.  This is the other reason it's expected to be a big deal is that it's the classic drive-by problem where you just get some text on a website, and it can take over your machine.  Interestingly, because this is a kernel-level problem, Vista's IE7 and IE8 sandboxes, which are designed to protect the system, offer no protection for this exploit.  And again, because it's a font-rendering problem in the kernel, this is not helped by disabling JavaScript.  So even turning JavaScript off will not help.



So the thing that I find annoying is that fonts are being rendered in the kernel.  There's something fundamentally broken about that.  And we know where this happened, and we know when.  Because, I mean, the idea is the kernel is your holy, sacrosanct - it's the kernel.  I mean, it's the OS.  You want to keep application sorts of things out of it.  It provides core services.  It handles the abstraction of your I/O so that various apps can vie for the peripherals, and the kernel manages that.  It typically abstracts the file system so that applications are able to talk to NTFS or FAT files in a uniform fashion.  It handles memory management so that applications are able to request memory resources, which the kernel juggles.  If it runs out of RAM, the kernel swaps things out that are not being used and brings new, empty memory in from swap space, I mean, all those really low-level things.



Well, at one point Microsoft, hopefully before they got the security religion, I mean, because you wouldn't ever want them to do this after they were concerned about security because it completely breaks security, Microsoft said, well, we need - we want faster display performance, so we're going to move GDI, the Graphics Device Interface, from user space, where it had always been, into the kernel, in order to minimize the user-to-kernel transitions because it's expensive to cross between user space and kernel space.  So they said, well, let's move GDI, this complex rendering code which includes the whole font system, down into the kernel because won't that be a good idea.  Yeah.



LEO:  Oh, boy.



STEVE:  And as a consequence, this is what you get.  You get more complexity.  You get little mistakes.  But rather than it being a mistake in user space that just causes a much more limited problem, now it's a mistake down in, you know, God Central of the computer.  I mean, this is where everything happens.  And as we've seen, for example, with rootkits, I mean, the reason rootkits are such a problem is that they're down in the kernel, able to literally do things like hide files from the directory system so you can't see them, and AV systems can't see them.



So anyway, I wanted to encourage people, I wanted to further explain this particular vulnerability, which was fixed last week, and just make sure - and also explain or reinforce how trivial it will be for this to be exploited.  Again, it's in the public domain now, what this problem is, how to exploit it, how it can be used.  It will be anyone who touches a website, whose Windows system renders fonts on a website, that hasn't patched this can get their machines, at the kernel level, taken over.



Now, Microsoft, to their credit, has done some things in Vista and later, like Address Space Layout Randomization, ASLR, where the chunks of the kernel are located in sort of semi-random locations, making kernel-level exploits more tricky.  But there's lots of instances where even Address Space Layout Randomization can be worked around.  So if you haven't by any means yet rebooted your machine with last week's patches, delay only as little as possible because this is a bad guy.



LEO:  That's really too bad.



STEVE:  Also in news following from last week, and you probably already have heard of this, Leo, the jailbroken iPhone problem that we discussed has, not surprisingly, escalated.  We're no longer changing wallpaper to some random singer from the past.  We're now stealing phone data, including contacts, music, photos, email, text messages, and pretty much everything.  There are two known and more expected current worms that are sucking personal content off of iPhones that have been jailbroken where their SSH server password has not been changed.



Remember from last week we discussed this, that the problem is that jailbreaking installs an SSH server, and it has a default password that everyone knows.  If you jailbreak your phone and don't change that password, then your phone literally can be contacted over the Internet, just like you were running a little web server.  In this case it's an SSH server.  Someone can log onto your phone and do pretty much what they want.  The original problem, which was a worm constrained to Australia, was just changing wallpaper.  Not surprisingly, that quickly escalated into much more damaging attacks.  So if you do have a jailbroken phone, do make sure you change that SSH password because it's getting bad quickly.



There's a recently acknowledged by Microsoft zero-day problem with Windows 7 and Server 2008 Release 2.  This is another problem with Server Message Blocks, the SMB protocol.  Microsoft is suggesting people block ports 139 and 445, which are, you know, the Windows filesharing, file and printer-sharing ports, which is used for the SMB protocol and all other kinds of things.  They've acknowledged this problem.  Exploit code has been posted in blogs on the Internet so people are aware of it.  Most  people are not going to have those ports exposed.



As one of our Q&As from last week asked, if I'm behind a router, and I'm using XP, aren't I behind two firewalls?  It's like, yes.  So unsolicited packets are not coming in from outside.  However, there are some exploits involving, not surprisingly, web browsers, where you go to a web page; the page you receive contains a specially formatted URL which can cause your machine to reach out to a malicious SMB server.  In that case, blocking your ports isn't going to help you because you're initiating an outbound connection to a hostile SMB server.  All it needs to do is send back some bad data.



Now, the good news is, if this happens, the only consequence is that you need to pull the plug on your machine.  It completely locks it up.  It puts it into an infinite loop in the kernel.  The machine won't respond to anything - keystrokes, mouse movements, nothing.  You cannot shut your machine off.  You just have to - even the power button apparently doesn't work.  You literally have to pull the plug out of the back and then wait, you know, count to five and plug it back in, in order to get control of your machine again.  So it's just a denial of service attack.  But it's something that Microsoft, I'm sure, well, hopefully they will patch it during Patch Wednesday.  Because the fact that this happens on Server 2008 is a problem.  You don't want, you know, a main corporate server to get locked up.  I mean, it completely shuts it down.  It's a complete kernel-level denial of service.  It would be necessary to somehow trick the server to going to a malicious SMB server.  But we know that hackers are clever.  I wouldn't be at all surprised if this ends up happening.



LEO:  Those nasty boys.



STEVE:  Now, I did want to follow up a little bit on our port-knocking discussion from last week also because I forgot about one other reason that I don't like port knocking.  I talked about how the problem is with port knocking you have multiple packets arriving at a given firewall, for example, where they just die because they're not admitted.  But the fact of their arrival at a particular port in a particular sequence is like the secret combination.  One of the problems that we talked about was that, sure, anyone who is listening to your conversation could replicate the knocking sequence.  And then that's what led me into a discussion of ways you could cleverly implement essentially a one-time authentication-style system that would prevent that.



I forgot one of the other big problems with it, and that is it's extremely susceptible to a denial of service, that is, not a flood, but technically a denial of service where - that is to say, a denial of knocking sequence.  If anybody else knew that this was what you were doing, for example, if a corporation were depending upon this, or if you were for some reason a high-value target, or high value to just even one random person, all they have to do is send random packets at your IP address every so often.  And that will look like failed knocking sequence packets and cause the software, which is looking for the proper sequence, to constantly think, oh, look, there's somebody trying to get in, and we're not going to let them.



Well, the problem is, if at the same time a valid person is sending the proper knocking sequence, their packets will be intermixed with the ones deliberately designed to screw up that knocking sequence, and you'll never get in.  So it would deny someone access to the service that they're trying to use to get in, just by spraying some deliberately wrong packets every so often.  So there's lots not to like about it.  It's, I mean, it's sort of a poor man's clever way of getting in.  But it's certainly far from optimal.



And I have, since we seem to be on the theme of pirated SpinRite software in the last...



LEO:  Last few weeks, yeah, yeah.



STEVE:  I have another confession from a guy named Troy Starkey who said, "Hi, Mr. GRC."  He sent this to the sales email address.  And the subject of his email was "I wish to thank you for your software."  He said, "Hi, Mr. GRC.  Firstly, let me commend you on your fantastic software."  Of course he says this after he purchased it.  But actually he thought it was fantastic beforehand.  He says, "It has repaired a few of my drives in the past.  So I truly wanted to show my appreciation by finally purchasing your great software.  I regret to admit that when my first drive went on the 'fritz'" - he has "fritz" in quotes.  I don't think that's his drive's name, I think that's where the drive went.



LEO:  Drive went on fritz.



STEVE:  It went on the fritz.  "I went searching the Internet desperately, trying to get it fixed, as I had a lot of digital photos on it, and I came across a copy of SpinRite 6 registered to someone else."



LEO:  Oh, boy.



STEVE:  "To my amazement, SpinRite worked perfectly, and I was able to save all of my data.  At that stage I was under a lot of financial pressure and could not afford to purchase your software.  But I vowed to buy it when I was on my feet financially.  Well, I'm on my feet now, and I offer you my support for a fantastic product that saved my irreplaceable photographs.  So please accept my sincere apologies."  I certainly do.  He says, "I feel horrible that I used that copy, but I have always supported products that I use.  And now I can add you to my list of great software.  Let's hope I don't need to use it in an emergency again.  I do have a word of advice for people who try to use SpinRite on the dreaded clicking hard drives, the ones that sound like the heads are trying to bash their way out of the hard drive enclosure" - which makes it sound a little dramatic, but, you know...



LEO:  That's an apt description, yeah.



STEVE:  We've talked about clicking hard drives before.  And he said, "and won't be detected even in the BIOS.  Place your clicking hard drive in an antistatic bag and place the drive in your deep freezer.  I left mine in for about 60 minutes.  Then remove from the freezer and the antistatic bag and tightly wrap it in a towel or similar absorbent cloth."  That's to prevent moisture from condensing on it, right.  He says, "Quickly attach it to your PC and power it up whilst everything is still frozen.  Drive worked well enough for me to then correct it with SpinRite 6 and transfer the data to a healthy drive.  Kind regards, Troy Starkey."



LEO:  You know, I've heard this.  And I know you have, too.



STEVE:  Oh, yeah.  The refrigerator trick is a great standby.



LEO:  But doesn't the drive immediately heat up?  I mean, come on.



STEVE:  Well, it gets hot very quickly.  But, see, but that initial clicking is the drive trying to initialize itself and get out onto the surface and find some servo data.  So all you really need to do is to kind of give it a little bit of a help over that first hump to get itself going.  And once it's going, then you're often able to stay out there over the disk surfaces.  The drive's initialized, the BIOS sees it, SpinRite can see it, and you're off to the races.



LEO:  Got it.  I see.  So it's really just that first thing that you want it to go.  Okay.



STEVE:  Yup, exactly.



LEO:  That makes a lot of sense.  All right.  We are - I'm very interested in this subject.



STEVE:  Oh, it's really a good one.



LEO:  We all have kind of a little bit of a vested interest since SSL is the...



STEVE:  Yeah, just a little.



LEO:  ...technology that secures, you know, all secure web interactions on ecommerce sites and so forth.  So is this going to be one of those propeller episodes, Steve?



STEVE:  Eh, kinda.  It's not going to hurt people.  And I don't think it'll require multiple listens.  It's up there.  But it's going to be good.  Okay.  So while I was rereading some of the RFCs that specify the way SSL and TLS operate, I appreciated yet again how so excruciatingly careful the specifications are and how well and carefully they were written.  So those people who were involved in putting it together, they must, given that it's so clear how careful they were, they must be thinking, ooh, crap.



LEO:  We worked so hard.



STEVE:  We were so careful.  And we missed one little thing.



LEO:  So it's the nature of that they missed something.



STEVE:  Yes.  And I'm going to explain what they missed.  Everyone's going to get it.  And we'll talk about the consequences and how that's leveraged and ultimately what it's going to mean.  It does mean a revision of TLS, the Transport Layer Security.  It's got to be changed in order to fix this.  And there's really no workaround.



So, okay.  A little bit of review of the way SSL and TLS hook up to each other.  When the client wants to initiate a connection to the server, it establishes a TCP connection.  And then the first packet it sends, it's called a Client Hello packet.  That packet contains the highest protocol version that it supports; a blob of randomness that it has made up for itself; a session ID; a list of the ciphers, that is, the cryptographic ciphers that it is equipped to use, which it's offering to the server; the compression method that it proposes to use.  The server receives that Client Hello packet containing all of that.  And it responds with its Server Hello, which contains a proper subset of some of those things.  It knows what protocol version the client has offered as the best it can do.  It knows what protocol version it has as the best it can do.  So it chooses the highest that they can both do.  So it sort of negotiates the best, the latest protocol that they both are aware of in terms of number.



And so, for example, we are currently at TLS v1.2.  I imagine we'll be at 1.3 before long.  And so everyone will, you know, both ends will breathe a sigh of relief when they exchange, oh, you know 1.3?  Oh, thank goodness, because I do, too.  And now we can solve, we don't have to worry about this new problem that we have.  So they agree upon the latest revision that they both are aware of.  The server generates its own chunk of randomness, which it sends back, along with the session ID that it confirms that it received from the client.  And the client, remember, sent its list of ciphers, cryptographic ciphers that it knows.  The server looks at those and weeds out any that it doesn't know about, so it sends them all back.



So basically it says, okay, it says to the client, of those you sent me, these are the ones I also know about.  So choose from among those.  And it agrees on a compression method, if the client wanted that.  It also sends its certificate, which is the server's assertion that, hey, you've connected to whatever - PayPal.com, Amazon.com, eBay.com - over a secure connection.  Here's my certificate, which I'm using to prove that your connection has not been spoofed and that I really am Amazon, eBay, PayPal, whatever.



So the client then takes the agreed-upon cipher set, chooses a cipher from it, which it now knows that they both understand.  It operates at the protocol version that the server has returned, which it knows that they both understand.  It takes the randomness that it generated, the randomness that the server provided, and it then does a key negotiation.  Basically in that certificate, and the certificate is signed, so it will take - it'll look at the list of certificate authorities that it has, see that it was signed by a certificate authority that it has in its list of verified valid authorities, and the certificate contains the server's public key.  So it will encrypt the data composed from the randomness that they both have, using the server's public key, and send that back in what's called the client key exchange packet.



And so what that's doing is, that's saying, okay, here's the master key for this session that I'm proposing.  Since it encrypted it with the server's public key, only if the server contains the matching private key will the server be able to decrypt that in order to get the same data that the client has.  So nobody listening in the middle is able to do that.  They won't have the server's private key because the server guards that with everything it's got.  And the fact that the server can decrypt it proves to the client that it has the private key matching the certificate.  Otherwise, for example, anybody could record the certificate during a connection to a secure site and then play back that certificate, pretending to be that site.  But the certificate does not contain the private key.  It contains the public key.  So that wouldn't help somebody who was trying to spoof the site.  So, you know, so basically that's the way this all works.



Then the next packet is what's called the "change cipher spec" packet, which is the client saying I've given you everything you need.  Now I'm going to switch to secure mode using the ciphers that we have agreed on.  So it sends this change cipher spec packet.  And that is the last packet sent in the clear.  It then sends, using the agreed-upon encryption, it sends a finished message which ends the handshaking, which is it contains the master secret encrypted under the cipher and a hash of all the preceding handshake messages.  So all of their conversation up to that point is hashed.  All of that is encrypted under the current encryption, and that's sent to the other end.



So what's significant here is that, until that cipher change spec message, everything is in the clear.  That is, you don't bring up the cone of silence on this dialogue until this change cipher spec message goes in each direction.  The server does the same thing.  It also sends a change cipher spec message to the client saying, okay, here we go.  The next thing you're going to receive from me is the finished message encrypted from my end, proving that I have everything that we've each received.  So this is a very nice, lockstep approach for agreeing on protocols, agreeing on ciphers, agreeing on session ID, compression, proving to each other that we've each got - we made up randomness, and we've exchanged it, and we're all on the same page, and then switching into encrypted mode.  So the guys that designed it designed it very, very carefully.



Now, it is possible for either end to request renegotiation for - and this could happen for various reasons.  For example, it might be that the client is at a public website, XYZCorp.com.  And they're browsing through some publicly available pages, but that this client is an employee of XYZCorp.com and wants to go into a specially protected, extra secure region of the XYZCorp.com site.  So they browse there.  And when they go to a certain directory, the web server says, whoa, wait a minute, that's going to require  more security.  You need to have a client certificate which would have been issued by the XYZCorp IT staff.  But at this point, even though they had a secure connection, the server had offered its certificate, as it always does, but the client had never been asked to present a certificate because up until then it was an anonymous client.  It could be - it might be a non-employee, might be anybody.



So the point is that during an already negotiated secure connection, there are situations which can arise that can require a renegotiation of the security context for a number of reasons.  One, for example, in this case might be that the server says, okay, if you want to see this page, we need more credentials from you.  We need additional authentication.  So what can happen is that upon attempting to connect to that special page, the server is able to send a hello request message to the client, basically saying, hey, we're going to start over again here.  I want you to send me a new hello message, just as if we were just connecting.  And let's do this again because this time when I send my certificate, I'm also going to send - the server's thinking to itself - a certificate request which requires that the client return a certificate with its next set of packets, which otherwise wouldn't be required.  So that's a way of the server saying, okay, we've got to up the ante here on authentication.  So this notion of renegotiating the security context of an already established SSL connection has been around for quite a while.  That's not big news.



Now, the reason the developers of this protocol weren't concerned about a security problem with renegotiating is that this hello request and the follow-on exchange of hello messages would all be contained in the secure tunnel.  That is, those messages, all of this renegotiation, it would all be performed in a secure context, that is, with the previously negotiated security, which wouldn't be upgraded until, once again, that change cipher spec message was sent, and then a finished message was sent for each side to end their handshaking relationship, essentially to end the whole negotiation.  So the developers said, hey, that's fine because we can have a renegotiation any time because it will always be under the existing security context.  So, and the protocol makes sure that no man in the middle can mess with this.  So what happened in the last couple weeks is that some very clever hackers thought about this some more and figured out a way around it within...



LEO:  Oh, isn't that nice, yeah.



STEVE:  Yeah, it's extremely cool.  So here's how it works.  First of all we need to - I need to make sure people understand that man-in-the-middle insertion is truly trivial.  I mean, it's the reason that many of our listeners have reconfigured their wireless networks in a Y configuration with routers.  Because unless you do that, if you want to offer open WiFi, you want to have an open WiFi and an encrypted WiFi, like open for guests or even for neighbors, the problem is that that exposes your entire network to man-in-the-middle attacks.  And we know that that comes from playing games with the ARP system, the Address Resolution Protocol.



Remember that the reason there's this awkwardness, this ability for a bad guy to insert themselves into a conversation, which is what we mean by man-in-the-middle, not somebody just eavesdropping passively, but somebody who has arranged to receive, sort of to have the traffic flowing through them so that it's subject to, not only their observation, but their modification and addition and subtraction of packets.  The reason we get into this is that the Ethernet LAN is based on MAC addresses, yet the Internet protocol is based on IP addresses.  So there needs to be a mapping made between which LAN MAC adapters have been assigned which IP addresses.  So that's what the ARP table is.  It's just a table of simple associations.  This IP address is this MAC address.  That IP address is that MAC address.



And so when a computer initially powers up onto a Local Area Network, it sends out a broadcast packet that says, hey, I'm configured so that my gateway is this IP.  Who is that?  So it says what adapter has that IP.  And the adapter listening for such broadcasts, and all Ethernet LAN adapters listen for broadcasts like that, check to see if that's one of the IPs that they've been assigned.  And if so they go, hey, I'm that IP.  Here's my MAC address.  And so that creates an entry in this newly booted computer's ARP table so that it knows how to address packets to the gateway.  And similarly, as machines come on the LAN, they send out broadcasts.  They also can listen to other broadcasts just to learn about other adapters, sort of as a side effect of being on the LAN.



So it turns out that because this association between IPs and MAC adapters is dynamic and can be changing, these things also expire.  If you don't get a response a couple times, then the computer will say, oh, okay, maybe the IP address changed or the adapter changed.  So it'll sort of try to renew the ARP table.  As a consequence of this, there's lots of opportunity for mischief.  And...



LEO:  What layer does this happen at?  Is this at the Ethernet layer?  Is this - this is a TCP/IP issue.



STEVE:  Well, it's actually at the Ethernet LAN layer.  And this is a protocol that was added to the Ethernet because it wanted - the Ethernet wanted to carry a foreign protocol.  It wanted to carry IP protocol on top of the lower level Ethernet protocol.



LEO:  It was kind of a necessary handshake so that you could marry the two.  You could put TCP/IP over Ethernet.



STEVE:  Exactly.  But it's because it's dynamic, because these tables are being built on the fly, that there's all kinds of ways for bad guys to insert their MAC adapter into other machines' ARP tables.  And so that's the trick is if a bad guy inserts their MAC adapter MAC address into the gateway ARP table for a different IP, then the gateway is none the wiser.  It will send packets that are intended for somebody else to the bad guy.  And all the bad guy has to do is forward them on to the intended target, and that target will be none the wiser.  And similarly, if the bad guy inserts its MAC address into the target's ARP table for the gateway, then when that machine thinks it's sending packets back to the gateway, it's actually sending them back to the attacker.  And the attacker simply forwards those to the gateway.  And so that allows an attacker to splice himself into the conversation.



And there's tons, many more due to the history of this for UNIX and Linux machines than, for example, for Windows and Mac machines.  But there's plenty of software around where you can simply bring a laptop to an open caf, and within a few minutes you are now filtering all the traffic going from that open WiFi hotspot to any of the users in the caf.  So, I mean, this is real.  This is not sci-fi.  This is not even difficult.  But until now you really couldn't do anything with it.  If they were not using SSL, and we've talked about this a lot, if they were not using SSL, they were just logging into their POP server, then their name, their account name and username are going to be in the clear.  You can capture them.  If they're surfing the web, you can see all the URLs and all of the data that they're transacting once you've spliced yourself in.  In fact, you really don't even need to use an active attack.  You could just passively monitor all the packets if you just wanted to suck in all this information.  It has been believed, though, that an SSL connection protected you completely from a man in the middle.  We now know in some circumstances it does not.  So here's how this happens.



A user initiates a connection to a remote server after somebody has placed themselves in the middle.  Now, this doesn't have to be in a caf with WiFi.  It could be in a hotel with a bad employee who's able to go into the closet where the router is and plug their computer in, in which case they're able to do this with every employee, I mean every guest in the hotel who's using the hotel's network.  So there are all kinds of other scenarios than just the open WiFi.  The idea though is you do need to be in the flow, not passively eavesdropping, but actively able to intercept traffic.  So a...



LEO:  Well, how is that different from just plugging in?  Do you say "I am actively listening"?  I mean, is there something you do to signal that?



STEVE:  Well, no, yeah.  What you start doing is, you begin listening to ARP - you listen to the Ethernet traffic, and you send your own ARP packets, malicious ARP packets to the various endpoints to confuse them and get them to put you in their tables instead of each other.



LEO:  Right.  You respond to their ARP requests with your own MAC address.



STEVE:  Actively, yes.  And before you know it, you're spliced into their conversation.  So then you see the client initiating an SSL connection to a remote server.  You know that because it's over port 443, the SSL port.  You hold that packet for a second, that is, the attacker holds that packet and sends their own to the remote server, establishing their own SSL connection.



LEO:  Hence the man in the middle.



STEVE:  Hence the man in the middle.  They go through the protocol negotiation, just as I said.  So now the attacker has a secure connection to the remote server.  At that point the attacker sends a malicious request to the server.  That is to say, like some sort of command that the client hasn't sent, making it malicious.  I mean, something that the client never intended.  And I'll explain how that can be formed.  And, I mean, these things have been done and proven in the last few weeks.



So the attacker sends this command which is unfinished to the remote server and then sends a new Server Hello message.  So in one packet it sends the beginning of a command, then sends a Server Hello message, which it's able to send at any time.  That is, part of SSL and TLS is either side can request renegotiation at any time.  The server receives the - I'm sorry, the client.  It's the Client Hello message, not a Server Hello message.  So the malicious guy in the middle sends a Client Hello.  The server goes, oh, okay, this guy wants to renegotiate.  That's fine.  So remember that all of this SSL negotiation, up until after the change cipher spec message, is in the clear.  So the bad guy sends the Client Hello message that it had been holding and blocking from the real client.  And so that it forwards it to the server, and the server believes it is renegotiating the existing connection; whereas the actual good guy, the innocent client, thinks it's establishing a new connection.



So what happened was the man in the middle was able to hold the client's hello message briefly, send its own, negotiate a connection, get a secure connection, send some stuff to the server, then allow the client's hello message to pass through it, and all it then does is allow the standard handshake to proceed, and essentially knitting the innocent client's SSL connection to the server.  Client doesn't know anything about a previous SSL connection.  The server sees it as a renegotiation of an existing one.  What happened was, as a consequence of this, the attacker was able to send some stuff ahead using the, well, on this little brief sort of a stub of a connection, but over SSL.



Now, how is that useful?  One of the ways that we see the web is being used is that requests to servers, like standard HTTP get requests, have these very complex-looking URLs with all kinds of gobbledy-gook in them.  Remember, you know, it'll be https:, for example, or just :// and then the domain, then the directory and the page.  Then there'll be a question mark which starts the parameters.  And then you have all these parameters afterwards which are sophisticated command directions, causing things like PayPal to transfer money or banks to log you in, causing purchases on Amazon and so forth.  So there's all this parameterization in this - contained in the URL.  That's normally protected within the SSL secure wrapper.  So it can't be seen by someone eavesdropping.  It can't be synthesized by a man in the middle.  It's protected.



After that get request are a series of headers, things like, for example, the host header is required by HTTP 1.1, the current version of HTTP, where it says, you know, www.amazon.com.  It'll say this is the host I am trying to connect to.  And then things like time and date and also cookies.  Every one of these header lines ends with a carriage return line feed and then the next header.  CRLF is the abbreviation for carriage return line feed.  This hails from way back in the PDP-8 days with a teletype, where you'd be typing along, and then when you come to the line you send a carriage return character, which moves the head back to the beginning, the typing head back to the beginning of the far left of the paper, and then a line feed, which rotates the paper's platen up by one line, and then more characters follow.  So the end of each line is this carriage return line feed, and then the next one.



Well, imagine what happens if what the attacker in this scenario sends is a sophisticated command with a URL and all of this extra stuff padded on the end which the receiving server knows this is a command for it to do something.  Then it adds a couple headers.  But the last header it leaves open.  For example, the header is ignore this colon, space.  And that's where it ends its insertion.  It leaves that last header unterminated.  Now it passes the innocent client's Client Hello message through.  The client establishes an SSL connection.  And the client sends its valid get request, its HTTP get command.  Well, because the server - sorry.  Because the malicious man in the middle left that last header unterminated, what the server sees is ignore this colon, space, and then the client's request, which looks...



LEO:  Oh, wow.



STEVE:  Isn't that cool, Leo?



LEO:  Yeah, yeah.



STEVE:  Which looks like just a header, and it is a header of the malicious request.  Which means the client's actual command is absorbed.  But then - here's the good part.  The client, because it's got a connection that's secure to a web server it knows, it continues, its command follows with other things, including its cookies.



LEO:  Oh, great.  We're cool here.  I know you.  Here.



STEVE:  Yup.  You're over a secure connection.  You've proven who you are.  I've seen your certificate.  Here is my cookie authentication for who I am.  So that ends up getting tagged onto the attacker's command, allowing the attacker to perfectly impersonate the client, the innocent client.



LEO:  Because that has the authentication cookie.  That's all it really needed.



STEVE:  Exactly.  Exactly.  Because that was a way for it to get the innocent client to make a request, and the client would automatically include its authentication cookies that it has from dealing with the server in the past, allowing the attacker to impersonate the client and the attacker to do whatever it wants to, whatever it can, given its ability to send a command to the server.  So this has got everybody really concerned.



LEO:  It seems like that was pretty easy.  I mean, okay, maybe...



STEVE:  No, no.  That's exactly the point, Leo.



LEO:  Seems like it was kind of simple.



STEVE:  It's why it's so - as I said, after I understood this, and I was rereading the RFCs to refresh myself, I was like, okay, wait a minute now.  Why is this so easy?  The RFCs were written so carefully and so deliberately.  And it's like, oh, crap.



LEO:  So was the oops leaving this hole with the line termination?  I mean, what was the oops?



STEVE:  Well, the oops was that they were relying on the existing security of the previous connections.



LEO:  Allowing the continuation.



STEVE:  Yes.  They were assuming that the renegotiation would be protected by the secure envelope that had already been created.  There was no provision for carrying forward the security context that had been established as part of the renegotiation.  And that's what we're going to talk about next is how they have solved the problem.



LEO:  Oh, good.  Probably too late for me, but they've solved it.



STEVE:  Well, actually, I mean, I should say how they will solve the problem.



LEO:  How they hope to solve, yeah, yeah, yeah. 



STEVE:  Nobody has the solution yet.  We're all vulnerable to this today.



LEO:  Oh, very interesting.  It does, it did worry me when you said SSL is flawed.  I thought, oh, no, you know.  But at least they have the encryption before it's sent.  So, just to recap, they're using ARP - is it spoofing?  Would that be the word?  Not poisoning, but spoofing?



STEVE:  Well, it's any scenario where you have a man in the middle.  So it is definitely possible for someone to insert themselves in the middle on an Ethernet LAN by playing games with ARP.  But the presumption is that SSL and TLS provide us with an end-to-end safe channel such that we establish the channel.  And that's one of the cool things about SSL.  This tunnel, this encrypted tunnel comes up first.  It's negotiated.  Everybody agrees at each end.  It comes up, and then everything passing through it is in this cone of silence.  It's encrypted securely, specifically so that nobody who is monitoring or intercepting can have access.  The only thing somebody in the middle can do is deny service.  But if the packets transit through, the whole point of SSL is that there's no way for anyone to mess with you.



LEO:  See, I always kind of thought of it like a VPN, like it's an encrypted tunnel.  But it isn't really a tunnel, is it.



STEVE:  Well, it's a - there's no encapsulation of protocol.  But the packets themselves are - the payload of the packets themselves are encrypted within the IP wrapper.  So...



LEO:  Okay.  So they look like standard IP packets, but they are encrypted within.  The data's encrypted.



STEVE:  Correct.



LEO:  Okay.



STEVE:  Correct.  So what this does is, this is a significant and fundamental flaw which was - just someone tripped over.  And in fact, I mean, it's bad enough that the major vendors of SSL protocol have met secretly before this became public knowledge and scratched their heads and said, oh, crap.



LEO:  What are we going to do?



STEVE:  This is really bad.  Okay, so it turns out the fix is incredibly simple.  The TLS, the Transport Layer Security, we've talked about how it and SSL v3, which was the last version of SSL, how the protocols are virtually identical.  That's true, except that TLS added one feature.  It added the ability for what's called extensions.  Extensions are a variable list of things which the client, in the Client Hello packet, in that initial packet going to the server, the client can say, oh, and by the way, I'm extra special.  I know the following extensions.  And it can know them and leave them, leave their payload, the actual extension payload empty, if it just wants to assert to the server that it's aware of these things.  Because in some cases the server may need to know that the client is aware of these extensions in order to enable it to use them.



So an example of an extension, a very useful one, is one that allows multiple homing over SSL.  One of the problems with SSL is that you're not, with SSL, able to have a single IP address post multiple different domains because the initial connection and negotiation has to happen before the client is able to send through the tunnel, the SSL channel, the request containing the host header that tells the server which server it wants.  So the certificate negotiation that has the server's name in it is tied to a single IP address.  But with IP starvation, and how nice it would be, for example, to have multiple domains on a single IP, it'd be nice to have that.



So one of the TLS extensions allows a TLS client to provide the server name in the Client Hello packet.  That allows a smart server to say, oh, this client wants this certificate.  So it allows the client essentially to ask for the certificate that it wishes at a single IP address.  Well, that's very cool.  I mean, that solves a big problem for SSL.  Another example of an extension would be for, if you had a really lightweight, really small client, like a whole system on a chip that doesn't have much buffer space and much memory, it's possible for large SSL packets to get fragmented, and it's necessary for the client to have enough buffer space to reassemble the fragments into a full packet.  But the client might just not have that much RAM available.  So one of the other extensions allows the client to negotiate with the server a much smaller maximum fragment size to allow the client to not need so much buffer space.  So that is cool.



And then finally I'll give you one last example because it's something we'll all understand.  The client is able to tell the server what certificate authorities it knows about.  Remember that when the server sends its server certificate to the client, that certificate will have been signed by some certificate authority.  Well, if the client is able to say here's the authorities I know about, please give me a certificate signed by one of them, that can prevent an SSL negotiation failure as a consequence of the server handing the client a certificate signed by someone it doesn't know or doesn't trust.  So those are some existing extensions.  It turns out that all we have to do is add one more.  And it is a renegotiation info extension.  And all it contains is that finished data from the prior negotiation.



So the idea is that, remember that in this attack scenario the server saw the real client's Client Hello message.  It saw that as a renegotiation of the existing connection, whereas the client thought it was its initial contact packet.  So all we need to do is enhance the protocol.  We add a renegotiation info type of extension which contains the payload from the previous finished message.  That finished message is this - basically it's the I'm proving to you everything which has gone on before we're in agreement on.  So if renegotiation requires that extension - which it doesn't today.  That's the mistake.  The mistake is the renegotiation did not require any security context from the previous secure context.  It assumed security because it was in the security envelope.  But in this particular attack there really wasn't a security envelope.



So if we simply change TLS, probably 1.3, to version 1.3, we simply change TLS so that renegotiation must have the payload from the previous security context as part of the hello message, the problem is solved.  The server, who is aware of this, would never accept a renegotiation that didn't have that packet from the previous security context.  And in the scenario we painted, the client wouldn't think it was renegotiating.  It wouldn't have any context to share.  So the server would deny the renegotiation and drop the connection.



LEO:  Perfect.



STEVE:  So to give you a sense for how careful these guys are, I'm going to read from the draft.  There's already an Internet draft for this fix.  I mean, these guys have scrambled in order to, like, deal with this.  And this is beautiful because the language of this gives you a sense for how careful they have always been, and just how much of a mistake this was.  So this is under the category of backward compatibility.  And this is the problem we face now because none of us have TLS 1.3.  It doesn't exist yet.  We all have 1.2.  First of all, it's worth saying that SSL v3 doesn't have any provision for extensions.  That was added in TLS v1.0.  So SSL is completely dying at this point.  That is...



LEO:  Because you can't fix it.



STEVE:  Exactly, it's not fixable.  TLS can be revved, but SSL can't be.  So goodbye to SSL.  This, like, gives some reason to no longer allow a fallback to SSL.



LEO:  So people have been using TLS, not SSL, even though we call it SSL.



STEVE:  Exactly, yes.  Everybody now has TLS clients and servers at each end.  And that's the actual protocol we're using because it's got all these extra cool little features, basically thanks to these extensions.  So under backward compatibility they say:  "Existing implementations which do not support this extension are widely deployed" - yeah, like that's all we have right now - "and in general must interoperate with newer implementations which will support it.  This section describes considerations for backward compatible interoperation."  Okay.



On the client side, client considerations:  "If a client offers the renegotiation info extension, and the server does not respond, then this indicates that the server either does not support the extension or is unwilling to use it.  Because the above attack looks like a single handshake to the client, the client cannot determine whether the connection is under attack or not.  If clients wish to ensure that such attacks are impossible, they must terminate the connection immediately upon failure to receive the extension without completing the handshake.  Otherwise, they may be performing client authentication and thus potentially authorizing the data already sent by the attacker, even if the client itself sends no data.  Note that initially deployment of this extension will be very sparse, and thus choosing to terminate the connection immediately is likely to result in significant interoperability problems."



Meaning that, you know, if we told our browsers not to allow TLS without renegotiation protection, we couldn't talk to anybody today.  And it's going to take a while before we're going to be able to talk to anybody.  So it's not practical to enforce that.  But these guys are being - this is how careful they're being.



On the server side, server considerations:  "If the client does not offer the renegotiation info extension, then this indicates that the client does not support the extension or is unwilling to use it.  Note that TLS does not permit servers to offer unsolicited extensions."  And that's generally true of the whole spec.  Remember that all throughout this I've been saying that the client first makes the offers.  The server then chooses from among them.  So similarly, if the client doesn't say I know about renegotiation info extension, then the server does not have permission to use it because it might break the client.  



LEO:  Yes.



STEVE:  That didn't know about it.  So it says, "Note that TLS does not permit servers to offer unsolicited extensions.  However, because the above attack looks like two handshakes to the server, the server can safely continue the connection as long as it does not allow the client to re-handshake."  So that's a significant point.  A server could accept a connection that did not have the renegotiation info extension being offered by the client.  It would simply have to flag that connection as non-renegotiable and never allow renegotiation on the fly.



LEO:  Which then also prevents this exploit.



STEVE:  Exactly.  So it says...



LEO:  Does that break anything else, though?  I mean, is that...



STEVE:  No, no, that's the beauty of this is that right now clients don't often want to renegotiate.  But it's in the spec, so the attackers can use that.  But it's not common for clients to renegotiate their credentials once they've established it.  So a nice solution is for all servers everywhere to get themselves updated.  And it's, you know, I was going to say it's easier for the servers to do it, but that's not necessarily the case.  Hopefully Microsoft will respond next month, and we'll all have TLS v1.3, and you'll hear about it right here on the podcast.  There'll be party streamers and noisemakers and things going off in the background.  So, and a crowd of ovation.



So the beauty is that a server that does know about, has been upgraded, can still accept connections from clients that are nave and protect both the client and the server if it simply notices that the client didn't offer it, so renegotiations are disabled for this session and do not allow renegotiation.  It says, "If servers wish to ensure that such attacks are impossible, they must not allow clients who do not offer the renegotiation info extension to renegotiate with them and should respond to such requests with a no renegotiation alert, which has now been described.  Servers should follow this behavior."



LEO:  Great, great.



STEVE:  So that's the story.



LEO:  So how does that get implemented?  Do we do a new - what do we do?  The extension gets pushed out, or...



STEVE:  Well, yeah.  For all platforms that have any kind of built-in updating deal, I know that the GNU SSL group are up to speed.  Microsoft is involved.  In fact, they're one of the co-authors of that paper I was just reading from.  So everybody who produces SSL is certainly aware of this and is on the ball.  And so they will be shortly updating the crypto libs of all the various packages.  I mean, you know, we've had our crypto lib updated under Windows several times already this year.  So it'll just happen again, and it'll be "Now supports TLS v1.3," and servers will be updated to do the same thing, and the problem will be solved.



LEO:  Is there - I guess you could go in, what, the About menu or something?  You would look in the browser, or would you look in the - it's the browser, right, that you would look at.  Or is it the operating system?



STEVE:  I would think, well, no, it would be the browser.  If you were connecting to a remote system, you'd look under the connection characteristics and see if you were using TLS 1.3 or 1.2.  I'm just making it up.  It might be 2.0.  I don't know what they're going to do with...



LEO:  I think it's, yeah, right, I think it's 1.0 right now in Firefox.  I'm just trying to find it.  Could it be that old?



STEVE:  It'd be 1.2 probably.  That's been the current spec for some time.  Although there's nothing wrong with 1.0.  They just added some more features to it.  And they're about to add another big one.  And I imagine they'll just take it to 1.3.



LEO:  Right, right.



STEVE:  So that's the story.  It's an interesting kind of oops that is clever, that the designers just didn't consider, which we will shortly, pretty easily, fix.  But it does offer some interesting opportunities for exploitation.  I imagine hackers will run around and have some fun with it before they get shut down.



LEO:  Is there anything we can do until then?  I guess not, really.



STEVE:  I can't see anything.  Hopefully this thing will - this will get fixed quickly.  There's really no protection from man-in-the-middle attacks.  I mean, if you were aware of the MAC address of your gateway, and there was something that could tell you if that ever changed - frankly, that's a feature I've already got logged in for CryptoLink.  CryptoLink will have built-in ARP games detection just to alert people for it.  It's on my bullet list of things to do.  But I don't - I'm not aware of any software now that does watch for malicious ARP traffic and alert you if your gateway changed because that would immediately tell you that something was going on.



The problem is, if you were in, like, an open WiFi hotspot, it might be that the very - and likely that the moment that you got on the air, the attacker was there waiting for your initial broadcast and stuffed his MAC address into your ARP table and beat the gateway to doing so.  Gateways tend to be underpowered, and attacker machines tend to be more powerful.  So they're able to get their packet, to beat the gateway in responding to a broadcast.  So there you wouldn't see a change.  The initial MAC address would just be wrong.  On the other hand, if you looked at the MAC address, you might see that it was like an IBM or a Sony machine.  Remember that MAC addresses do contain the manufacturer's ID in them.  And so it's like, wait a minute, I don't think I have a Sony gateway.  I think someone with a Sony computer is playing games with me.



So there are some things you could do, but not easily.  So I think we'll just have to hold our breath for a couple weeks and hope that Microsoft gets this fixed quickly.  I hope everybody in the SSL, or sorry, the TLS community will be able to respond quickly.  They should be able to.  The spec is designed with these extensions in mind.  They've done a trivial - I can't think of anything cleaner than simply saying use the payload from the finished packet in the renego- as the payload for the renegotiation info extension, and you're done.  I mean, that's all it needs to be.  It's such a simple fix that it ought to be able to be done quickly.



LEO:  Just fantastic.  Very good, clear explanation that I, in my limited capacity, even understood.



STEVE:  Like I said, this was...



LEO:  It's fascinating.



STEVE:  I just knew this was going to be a good episode.



LEO:  Yeah.  Well, thanks, Steve.  Everybody should rush to GRC.com, not only to get a copy of SpinRite, especially those of you who've been using it without paying for it.  Stands for Gibson Research Corporation, that's easy to remember, GRC.com.  And there's lots of other stuff there.  You've seen ShieldsUP! probably, all those free programs Steve offers.  And also 16KB versions of this show, show notes, and transcriptions by Elaine, who is so great.  She did a transcription for me, a rush, last week.  And she's just the best.  She's just a great, really great transcriptionist.  [Thank you, Leo.]  So that's all there at GRC.com.  Next week your questions and answers; right?



STEVE:  Yup, that's what we're going to do, Leo.



LEO:  So go right now to GRC.com/feedback if you've got a question.  Somebody in the chatroom is saying, well, IPSec allows renegotiation.  This apply to IPSec?  We'll find out.



STEVE:  Good question for next week.



LEO:  That's a good question for next week.  Go to GRC.com/feedback and leave your question.  Steve, we'll see you next week.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#224

DATE:		November 26, 2009

TITLE:		Listener Feedback #80

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-224.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 224 for November 26, 2009:  Your questions, Steve's answers #80.



It's time for Security Now!, the show that covers everything you need to know about security with Steve Gibson, as always - the man behind GRC.com; the discoverer of spyware, the man who coined the term spyware; author of SpinRite, the great hard drive maintenance utility, and a lot of security utilities like ShieldsUP! and more.  Hey, Steve, it's good to see you.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  Happy Thanksgiving week.



STEVE:  And thank you.  And you know, I think you're right.  I think if someone listened to this podcast constantly and thought about it, they probably do over time get everything they need to know about security.  We really do cover the bases.  And it doesn't happen over a short period of time.  But, I mean, I keep hearing from people who write, that go to GRC.com/feedback and send me their thoughts.  And they're saying, wow, I'm like my whole group's security guru now, thanks to listening to you guys...



LEO:  That's fantastic.



STEVE:  ...a couple years.  So, yeah.



LEO:  Yeah, I mean, I think you get - we added security news a couple of years ago.  And I think so that way at least you know what's breaking security news.  We've been doing Q&As now, this is our 80th, so that's a couple years we've been doing that.  And so that covers a lot of bases.  And then of course you get these great lectures where you understand, like last week, where you really understand SSL.  Those are very valuable.  And I think you're right.  Cumulatively, I don't know, I think there's nothing we haven't covered at this point, from crypto to SSL to hacks to buffer overflows.



STEVE:  Social exploits.



LEO:  Yeah, you bet.  So what's been going on in the world of security since we talked last?



STEVE:  Well, we've got our regular cast of characters.  Actually sort of pretty much the same sort of stuff.  A number of listeners wrote about a story which I had run across also, so I thought I would bring it up.  This was where some people from the NSA were testifying in Congress about security things and happened to mention that they had worked with Microsoft on hardening of the security of Windows 7.  Well, of course this upset some people who are mistrustful of government and specifically the NSA.  You may remember that there was a coincidental acronym collision in part of Windows where there was something that, if you looked at the binary code of Windows some years ago you could see _NSAKEY was the - I mean, and it stood for something completely different from National Security - is it Association?



LEO:  No, no.  That would be a professional group.  The National Security Agency.



STEVE:  Agency, yeah.  And so anyway, it turns out that the NSA has been helping Microsoft, but also Apple and Sun and Red Hat.



LEO:  Oh, that's interesting, huh.



STEVE:  And what they've been doing mostly is just sort of working with them on best practices, the idea of making sure that things are bolted down and turned off.  I think that probably the companies are saying, hey, is there anything you guys know about that hasn't occurred to us that would help us make our operating systems safer?  So it's not like the NSA is creating code or writing blobs of these operating systems that they're then secretly handing to the companies to install.



LEO:  Let's hope not.



STEVE:  Well, yes.  And the concern is that, you know, this mistrust, the conspiracy theories that people have...



LEO:  Well, it's not just a theory.  They were spying on us through the phone company, so...



STEVE:  That's true.  There have been some things...



LEO:  We know they have some interest in our activities.



STEVE:  Yeah.  Again, my sense is, though, that with the kind of scrutiny our operating systems get, where we've got packet captures going on, I mean, we have such a community now of security concern surrounding these, it's not like any of this is being done without anyone watching.  I mean, everyone is watching.  So I'd be really skeptical whether any packets could be playing games without being seen.



LEO:  It'd be hard to do these days, yeah.



STEVE:  But I did want to acknowledge the people that wrote in saying, hey, Steve, did you see this article or this news?  What do you think of it?  I mean, to me it looks very benign.  I mean, I'm probably less prone to conspiracy theorizing than most, so maybe I'm being nave.  But to me it looks completely benign.



LEO:  Microsoft says there's no backdoor.



STEVE:  Right.  Also the continuing saga of the iPhone jailbroken worms.  It's very plural now.  I don't know whether you saw this, Leo.  But there's - now we're seeing the rapid emergence of very bad worms, which are taking advantage of this default password in the SSH server that the jailbreaking installs in iPhones.  There is now one which is actively stealing banking data and enlisting the iPhones into a botnet.



LEO:  Wow.



STEVE:  It's a worm targeting jailbroken phones which steals online - it's designed to steal online banking login credentials, so it's looking for those.  It changes the iPhone's password after it gets in so nothing else can get in; connects to a command-and-control server in Lithuania to download additional files and data and to send back the information it has stolen from the phone; and ties the iPhone into a botnet.  So this quickly went from some fun and games in Australia a couple weeks ago, where as you remember some random photo was changed on people's backgrounds, the desktop of their iPhone, into now something which is seriously bad.



LEO:  Not good.



STEVE:  So this is a problem with anything that is as intimately connected into a network.  I mean, we've certainly seen, I mean, this is why we have the security problems we have with Windows and all PCs now to varying degrees is that they're part of a big network.  Well, phones are computers that are becoming increasingly powerful and open and part of a big network.  So that creates this opportunity.



We've got all versions of IE have various types of problems.  Starting with the most recent IE, IE8 has a strange problem that's been found in Microsoft's own attempt to prevent the problem.



LEO:  Oh, boy.



STEVE:  There's something called - and we've talked about cross-site scripting.  In order to prevent cross-site scripting, one of the things you do is so-called "output encoding."  That is, for example, in sites where you allow users to submit their own content, for example, you don't want to allow a user to submit a less-than sign or a greater-than sign because that allows you to bracket some keywords like an href, a link reference, or to invoke scripting or play other games.  The idea being that when - what you submit is then presented to a different user by the browser, the browser that's outputting this will see those brackets, the angle brackets, and say oh, this is some html.  And it will render that text that somebody else, a malicious user put up as html, interpreting it on the fly.  So to prevent that it's possible to do so-called output encoding so that dangerous things that are submitted will not be presented back to the browser in their same dangerous form.



So Microsoft has a cross-site scripting filter in IE8.  Apparently they did it wrong.  And what's happened is there are now proofs of concept.  And it's been shown, and Microsoft has acknowledged, that it is possible to trick their filter so that the filter which is trying to prevent the problem actually creates the problem.  So some clever hackers figured out a way to give the filter something to filter which would cause it to do what it was designed to prevent.



Now, what's interesting is that there's a way to turn this off.  If a web page is presented with a header from the server which is serving the page, which is x-xss-protection:0, that is, cross-site protection zero, that disables IE8's filter.  Well, interestingly, Google knows about this, is aware that there are problems, and in a formal statement from a spokesman said we're aware - well, when asked why their servers were serving this cross-site scripting protection colon zero header to turn this off in IE8, their spokesmen said, "We're aware of a significant flaw affecting the cross-site scripting filter in IE8, and we've taken steps to help protect our users..."



LEO:  This is amazing.



STEVE:  "...by disabling the mechanism on our properties until a fix has been released."



LEO:  Wow.  Wow.



STEVE:  Yeah.  This is just getting crazy.



LEO:  So when I surf to a website on Google, where...



STEVE:  Well, where they've got active content and they're trying to protect themselves, what they're doing is they've added that header to their otherwise endangered pages so that IE8 won't perform this protection.



LEO:  I see.



STEVE:  And, see, essentially, IE8 is trying to do this on behalf of webmasters who haven't properly output-encoded their pages.  So this allows IE8 to protect the website on behalf of the website owners.  Well, Google is smart enough to be - they feel - to be doing the output encoding properly, the output encoding protection themselves.  So this is really not providing Google with any benefit.  And in fact it turns out, due to a flaw in the way Microsoft did this, it's creating a danger where one doesn't exist in the case of Google sites.



LEO:  This is wild.



STEVE:  So it's intended to do good.  It does bad.  So Google says, uh...



LEO:  We'll do no evil.



STEVE:  ...we'll turn that off till you get it fixed.



LEO:  So other webmasters might do the same, could consider doing the same thing, then.



STEVE:  Well, they could, as long as they're very sure that they've prevented these problems themselves.



LEO:  In the first place, right.



STEVE:  In general it's probably, because this is a specific way of tripping it up, and because it only works under IE8, it's like, well, you know, it's probably doing more good than harm for most webmasters by helping them to eliminate cross-site scripting problems.  But in the case of a webmaster who really knows what they're doing, they'd probably want to turn this off just to prevent their site from being abused in this way.



LEO:  Can I point out something?



STEVE:  Oh, yeah.



LEO:  If I were a hacker, and I had a cross-site scripting exploit on my web page, I'd make sure to turn off cross-site scripting protection when I came to my page.  So if it's known how to disable this protection, what kind of protection is that?



STEVE:  Yeah.



LEO:  Am I missing something?



STEVE:  Well, it's that the bad guy who has the server...



LEO:  Ah, because of the nature of cross-site scripting, I have to take advantage of somebody else.



STEVE:  Exactly.



LEO:  I see.  So it doesn't matter if I issue it from my page.



STEVE:  Exactly, because you have complete control of your page.



LEO:  Got it, got it, got it.



STEVE:  You can present your visitors with any kind of malicious content you want to.  The idea is tricking other sites, like Facebook or MySpace and so forth, to present text that they weren't designed - that they were designed to disallow presenting.



LEO:  And I should underscore that, which you've said before, that NoScript prevents cross-site scripting.  So if you're using - first of all, you're not vulnerable if you're using Firefox in the first place.  But NoScript is a very good, even if you don't use - don't tell Steve.  When you turn off the JavaScript stuff, it still prevents cross-site scripting.



STEVE:  Well, we also have exactly that advice recommended for a new zero-day flaw that is in both IE6 and IE7.  Some raw code was posted to a security blog to demo this under an alias, so no one really knows who posted it.  But a number of security firms tried running this code, and it immediately crashes IE6 and 7.  And it has been shown that it can also be used to run explicit code remotely.  It's an abuse of the getElementsByTagName JavaScript method.  So it's a method in JavaScript in Microsoft's HTML DLL.  It's mshtml.dll.  Microsoft has no patch for it.  They've acknowledged it.  And their recommendation is [clearing throat] disable JavaScript.  Not surprisingly.  So once again, yes, NoScript would prevent that from being exploited.  I would imagine the second Tuesday of December we'll probably be talking to our listeners about a fix for this problem in mshtml, the getElementsByTagName JavaScript exploit, which probably by then will be in active use.  So selectively enabling JavaScript I think is still the best policy.



And finally, Opera is a little bit late to the game, but better late than never.  Several weeks ago we talked about this buffer overflow in a commonly used C language numeric conversion, the D to A conversion function.  Opera has finally updated their browser to v10.10.  So any Opera users out there, make sure that you're running 10.10, and you'll get the benefit of that fix.



LEO:  10.10, okay.



STEVE:  And lastly - that takes care of security stuff.  I wanted to mention in errata, for all of our listeners that really appreciated the extra-special, and some thought bizarre, Vitamin D episode we did, I'm getting a flood of  questions from people who have wanted to know, they wanted an update, they want to know what's going on.  They're sending me articles and links and all kinds of things.  I've been deliberately mute on the topic because I have really wanted to respect the Security Now! nature of this podcast and not confuse the two.



So, Leo, you've agreed to do with me a special podcast from time to time on my findings in my own little sort of hobby of health.  And so I wanted to tell our listeners that before long we're going to do another one which will follow up some on Vitamin D, but also talk about my next breakthrough for myself.  The reason I'm delaying it is that I'm waiting still on some results that will take longer to happen.  But I have some exciting news on a different front that I want to share that I think a lot of people will find very interesting.  I'll say more when that is in the can and we can point people at it.



LEO:  Okay.  And I'll get the lawyers working on the disclaimer.



STEVE:  [Laughing] Yes, we're not doctors.  We're not trained medical professionals.  I'm just a health hobbyist.  But I have some interesting additional news and something else I think people will really find very interesting.



LEO:  Excellent.



STEVE:  And a short note on something that's near and dear to me personally, and that is of course SpinRite.  The subject, from a Darren Wigley, was "Thank you times a thousand."  And he just said very briefly, he said, "Please know that this software totally bailed me out of a bad situation.  At least it was not life-threatening."  He said, "Until recently I kept a lot of priceless homemade videos on an external drive.  As bad luck would have it, that drive died; and all my movies, I thought, were gone.  I purchased and downloaded SpinRite 6 and didn't have much hope.  But then out of the blue all my data came home to me.  Thank you so much for creating this wonderful software.  Crappy software is certainly out there, but it is not this by a long shot.  I only hope that others find this great software.  I know I will be recommending it.  Much success to you in the future, and keep up the good work.  DMW."  So thanks, Darren, for sharing your testimonial about SpinRite.  I really appreciate it



LEO:  Very good.  Very good.  Question 1, Drew in Virginia Beach, VA.  He wonders about old code:  Steve, I love the show.  Insert normal kudos, hooahs, et cetera.  You and Leo are as great as SpinRite is awesome.  I'll refer you back to Episode 221, my friend, where you were saying that old code is better code.  But if you recall, several episodes earlier you went into detail about how a voting machine, secure in its day, could now be hacked due to improvements over time.  Seems to me this is a case where a new security hole was created by its age, since I think you said the ability to find the hole was due to 20 years of advances.  Because code, finally able to be stress tested, showed flaws not initially known, doesn't this say old code isn't better, just more abandoned?  Just a thought.  Hope to hear your response.  Drew.



STEVE:  Well, I wanted to put this question in, also as a proxy for all the people who wrote.  It's interesting.  I guess this is sort of a little bit of a religious issue, religious in the sense of what one believes that...



LEO:  It's a matter of faith.



STEVE:  It's a matter of faith.  And I wanted to say I don't know that there's really a right answer.  It's certainly the case that code can be written to be incredibly bulletproof, but to do so is incredibly expensive.  I look at the code that is used to run the shuttle, the NASA shuttle project.  And the amount of reviewing and testing and debugging that they do makes that the most expensive code per byte that, I mean, it's orders of magnitude more expensive.  But it has to be correct.  So it is possible to create correct code.  It's just excruciatingly expensive.  I mean, it's uneconomical unless the cost of a mistake is people dying in outer space.  So we don't have code typically that is written that well because it's too expensive.



I mean, I'm reminded, remember the horrible story with the Pinto with the bad gas tank where it was found that if you rear-ended a Pinto, that the gas tank had a high likelihood of exploding?  And it turned out that the manufacturer knew about that.  But they made the decision that, well, a certain number of them are going to have that problem, and we'll make restitution for those problems.  But that makes more sense than recalling all the Pintos that have been sold.  I mean, it was an economic calculation that was hard to understand, but that's the one they made.



And similarly, everyone wants code to be bug free, but it's so difficult to make that happen.  It's just it's not economical.  So in practice what happens, and this is what we spend so much time on this show looking at in detail, dicing and parsing, is that code is launched with problems.  And in fact I remember, I haven't seen this for a long time so I don't know if Microsoft is still doing it - and I'm sure you'll remember, Leo.  Remember those days when we could see, we would see, there were public bug lists of known problems in newly released versions of Windows.  And, I mean, it was like 50,000 problems.  But it was like, you'd read them, and you'd just kind of, oh my goodness, this is what they've released?  It's like, yes, but this is only going to affect people whose first name begins with F and live in Tampa on odd Thursdays of a full moon.  I mean, it was just unlikely things to happen.  They know it's there, but oh, well, we didn't get around to fixing it because we promised everyone we were going to ship this thing in the same year as the operating system was named, and it was getting near Christmas so we really had no choice.



So what Microsoft does is, well, I'm sorry, what everybody does is pretty much do the best job they can and figure that, well, as problems arise we'll fix them incrementally.  Well, what that means is that, as long as you stop adding new things, if all you do is fix problems, and you fix them carefully so that your fixes don't induce new problems - and that's one thing we do see also, we often see fixes creating new problems.  But if you're really careful, then in theory older code is allowed to become more bulletproof over time.  And if you can then stop messing with it, if you can stop adding things to it, it has a chance to get better.  But it's also the case that people can make more problems than they're fixing, or they can stop messing around with it and cause more problems.



So again, I completely recognize that there are many ways to look at this.  Maybe there isn't an answer.  Maybe it's not possible to say old code is better than new code.  I like to think that systems which have been around a while, that have been maintained well and carefully, are - if nothing else, they're a known quantity from a security standpoint.  Whereas anything new is, I think, fundamentally more dangerous.  I think that I can state with some reason to have some authority.



LEO:  Okay.  I think there's problems on both sides.  That sounds perfect.



STEVE:  Yes.  There are problems with both sides.  But if nothing else, something which has been around is a known quantity. 



LEO:  Right.



STEVE:  And I guess that's really - I guess that's...



LEO:  Better the devil you know than the devil you don't know.



STEVE:  From a security standpoint I think that's absolutely true, yes.  So, you know, I can stand behind that representation.



LEO:  Yeah.  And following along the same lines we've got one from an anonymous listener who says:  Is old code really better than new code?  After four-plus years of listening, it's apparent you favor old over new because you think the problems are discovered, known, and perhaps even fixed.  Being a software guy myself, who started programming on the original PC in assembler, then spending the rest of the '80s and '90s at Lotus working on 1-2-3 and others, I can understand your favoritism.  Yet the thought occurs to me that, given the last five years of concentration on secure code creating by Microsoft - ah.  This is a good point actually.



STEVE:  Yes.



LEO:  Perhaps the favoritism might be misplaced.  I have the advantage, as you do, from MSDN to play with the new O/S and apps.  And I'm suggesting a case can be made that newer software coming from Microsoft is more secure than old stuff.  For example, I find IE8 much more - well, we [chuckling].  I find IE8 much more secure than Firefox or Safari or the previous IEs.  Well...



STEVE:  Oops.



LEO:  Maybe not.  Windows 7 seems more - "seems" is a big word - more secure than Windows XP.  It's a thought I'd like you to mull over because I'm interested in what you think. He's saying essentially that improved techniques in writing software and improved coding tools make it more reliable.



STEVE:  Yes.  And I thought, because this was a different question than the first one, this was also worth looking at.  One of the things that I have been - that I try to be very careful about is to separate insecurity from mistakes from insecurity from policy.  I've really never argued strongly about Microsoft's security mistakes.  I mean, we point them out.  We're sorry for them.  We hope they're going to fix them soon.  My argument with Microsoft traditionally has been that they were insecure by policy.  They had a firewall in XP that was turned off when you installed it.  And they said, oh, well - I remember this so well.  Yeah, but the path most users will arrive at as they're installing XP, they'll come to a dialogue box, they'll be offered to have it turned on or something.  I never bought that, and that was never the case.  Which is why XP's firewall initially was off all the time, and they were having all these problems with - the other problem, by policy, is services that were running by default, by policy, in Windows.



So my traditional argument with Microsoft is that these were not mistakes they were making.  These were policies.  I mean, this wasn't some coder who had a wrong check for the end of a buffer in code.  This was Microsoft saying, well, it'll be easier for users if these things are turned on by default.  It's like, yes.  And it will be easier for hackers to get into those users' computers if those things are turned on by default.



LEO:  Right.



STEVE:  So the good news is, slowly, I mean like glacially slowly, Microsoft's security policies have matured, at a speed that's so slow I can't and I will never understand why.  But it has happened, and we're here today rather than where we were years ago, where the firewall is on by default.  Services are not on, or at least not exposed.  And they finally offered this notion of local services, where they understand things make sense to have on the local area network but not published out over the Internet, so the notion of a service scope, where it's a local scope as opposed to a global scope of access.  So that's very much the case.



And certainly also the focus that Microsoft has had is having an effect.  I do agree that Microsoft is clearly concerned about security.  This anonymous listener mentions the MSDN, which is the so-called Microsoft Developers Network, which I subscribe to every year.  And now when I look at the online help for Windows functions,  many of them have new stuff in red where it says, warning, this function is deprecated in favor of the following function, which will perform end-of-buffer overrun checks for you.  It is strongly recommended you not use this function, you use the new one.  And so they're creating an awareness which is really important.  I mean, just doing that, just saying, uh, wait a minute, smoking is bad for your health is on the carton.  So it's like, oh, it's going to affect somebody.  And just warning developers, this function could be bad for your code security.  Make sure you want to use it, and why not go check out this one.  I mean, that kind of thing makes a lot of sense.  And so, yes, I do agree that Microsoft's new stuff is certainly better than when their old stuff was new.



LEO:  It's not merely that, though.  I mean, for instance, buffer overflows come from using, you know, not checking bounds and things like that.  If policies are in place for programmers to do the right thing, or even maybe compilers are smart enough to prevent that kind of thing, doesn't that make them less likely?



STEVE:  You know, the problem is programmers don't want a compiler to be that smart because then they're not fun to program.



LEO:  Right.



STEVE:  Programmers want macho.  They want horsepower.  They want access.  They want C pointers where you're able to play games at a low level.  The reason C is such a popular language from the beginning is that it is so dangerous.  And programmers want the danger.  There are certainly languages which could be created that absolutely will not let you make a mistake.  They just don't have the capability of those kinds of errors.  And those languages exist.  They're well understood and well known, and not well used.  No one wants to use them.



LEO:  Like Ada.



STEVE:  Yeah, well, I mean, I don't know specifically if Ada doesn't allow you to do that.  But it's certainly the case that, you know, heavily interpreted languages just don't give you the flexibility.  They're absolutely safe, but they're just not - they're not macho.



LEO:  Yeah, yeah.  Not macho.  I like that.  Programmers, stop being so macho.  You're causing problems.  Let's talk about the Web of Trust.  Brandon in Indianapolis wonders about such things.  He says:  Back in Episode 214 you guys highlighted the Google.com/safebrowsing page.  It's very cool.  However, why wouldn't someone just install Web of Trust?  It's over at www.mywot.com.  This is new to me.  It's an add-on for Firefox and Internet Explorer that will rank sites based on reported malware and phishing and so on.  It ranks sites three ways:  Green is trusted; yellow is proceed with caution; red, don't ever go there.  On sites that have malicious ads or pop-ups on them, the add-on will warn you before loading in the pop-up, asking you if you're sure and informing you the site is known as a malicious one.  Best part is it will rank search results.  So you can go to Google and type in "free," and it will give you red, yellow, and green rankings on each site.  I use this in a couple of ways.  One is to stay protected, the other to infect virtual machines with malware and then try to clean them later.  What?



STEVE:  I think he's saying that this will help you find bad sites so you can go to them and get yourself infected.  It's like, okay.



LEO:  I've installed - okay is right.  I've installed it on my mom's PC as I'm always the one she calls when she has issues.  You guys do a wonderful show.  Been listening since Episode 1.  Keep up the good work.  Well, did you try this little plug-in?



STEVE:  I didn't.  But I wanted to address the idea, the concept of webs of trust.  It's not something we've ever talked about in all of our episodes, all 224 of them.  Well, I guess now we have, so this is Episode 224.  So not in the previous 223 episodes.  You know, the concept is an interesting one.  It sort of evolved out of the frustration, I think, of 4K trust assertion.  We've often talked about how annoying it is that people have to purchase certificates from a certificate authority, that these people who are really doing nothing other than issuing some bits are needing to be paid because what they're doing is some research.  They're performing research.  Every couple of years I've got to go jump through hoops.  They've got to do telephone calls, and they check my D&B numbers and things in order for me to get SSL certificates for GRC.com.  I have to prove, you know, who I am, and that I'm the webmaster for that domain, and we're a real corporation, and we've been around, and here's our address.  And, you know, this information is current.  So in return for all that, they make an assertion that they stand behind.  They get some money to run their infrastructure.  I get my certificate, which then has to be renewed every few years, and we go through all this again.



There are, you know, people in the Richard Stallman sort of world who just hate all that idea.  And so they've said, wait a minute, rather than have a single central authority that everyone trusts and that that authority then makes assertions, why not create a web of non-authority, but by having the web be big enough and people sort of vouching for each other, then that sort of creates sort of this floating set of assertions where a whole bunch of people have all agreed that this person is who they say they are, and they've made similar assertions.  I'm sure you've heard of these Web of Trust parties where people will get together and show each other their IDs, sort of verify them informally, and then...



LEO:  Yeah, it's for PGP key signing, yeah.



STEVE:  That's a perfect example, where it creates, I mean, and that's an instance of a web of trust.  In this case, for example, where we've got this Web of Trust server, it's relying on people to report malicious conduct and sites that they run across as they run across them.  And then it uses these add-ons in the browsers to alert people so the browsers are, whenever you're trying to go somewhere, the browser's add-on is going to ping back to this mywot.com server with the URL; ask that server to represent whether it knows anything good, bad, or indifferent about the site; and then present the user with green, yellow, or red based on that.  The alternative that he mentions is Google, which is out there spidering the world, literally the entire Internet, and using its own analysis of what sites do to determine whether they are doing known bad things or not.



LEO:  And actually OpenDNS is similar.  It will flag a phishing site.  It's not as effective as Google or MyWot, probably, but...



STEVE:  Yeah.  And anyway, so...



LEO:  There are other people doing this.



STEVE:  Yeah.  I guess, I mean, if you had a large enough community, if you had people actively feeding back their experiences, then I think the notion of a web of trust for this can function.  I guess if there's a way to have both, I'd just as soon have both.  That is, use the web of trust plug-in and also use Google as my search engine, and let Google make sure that it's looked at these links before I have the opportunity to click on them, so I have a chance to protect myself.  So anyway, I wanted to highlight it as an alternative and also to sort of talk about something we never have before, which is this notion of sort of a non-central authority sort of cross-representation of trust as an alternative.



LEO:  Yeah.  I'll have to take a - I mean, I'm looking at it.  They have a decent pedigree.  They're funded by Open Ocean and Finnish - they're from Finland.  It looks like they do tools.  I'm not sure exactly where their system is a community-based system, even though Web of Trust implies it is.



STEVE:  Yeah, and it does sound like from the description that maybe you use the add-on in order to send the feedback back.  So you probably have the add-on as the interactive agent.



LEO:  Of course then you have to trust them because you're - so it's more than web of trust.  It's a leap of faith.  I'm going to have MyLOF.com.  Number 4, John Edwards from Edinburgh, Scotland.  He's in password hell:  Dear Steve.  On SN-222 you spoke of an overheard discussion at your local Starbucks - other coffee outlets are available.  The discussion was a company's policy of making their employees change their password on a regular basis.  You said this policy makes sense.  But it seemed the people in the discussion thought otherwise.  They were trying to find all sorts of ways to circumvent it, kind of ridiculously extreme ways to circumvent it.



What do you say to the whole big wide world of Joe Public who have to use passwords and usernames for most all of their everyday life, be it paying bills to numerous firms, banking, email, general shopping, eBay, PayPal, Amazon, even tax and yes, TWiT forums.  The list, as we all know, is endless.  The last count I had 65 different sets of passwords and usernames, of which 21 were essential.  Now, try and keep all those in your brain, never mind having to periodically change them, voluntarily or under pressure.  I can sympathize, he says, with the people in that overheard conversation.  These people no doubt have the same problem we all do.  And day by day it just gets worse out there.  Where is it going to end up?



Steve, I often joke to my friends at the bank.  I say, "Guys, if you give me anymore passwords, I'll have to start a wee black book to keep them in."  I'm sorry, I didn't say "book" right.  Book.  A wee black book.  All joking aside, Steve, I guess many people do just that.  I have a half a dozen bank accounts.  Each one needs a telephone inquiry password or an Internet banking password and username.  And they're all starting to move toward three-part passwords, that is to say, three individual passwords and a username.  It's a security nightmare.  Help!  P.S.:  I now find I can't live without Security Now!.  As each week passes by, I become more educated and terrified.  Keep up the terror, guys.  Well, that's what I do.  I use Evernote, and I keep all my passwords in there, and I encrypt them.



STEVE:  Yup.  And Leo, I'm still using - we've talked about this a couple times - an offline Palm Pilot, sitting off to the side here.  It's by my right hand.  Anytime I need it I can put in a few characters, because the little notepad has a very nice search, and it instantly finds, like I remember that I wanted to know what my Chase - I have, like, Chase online access to my main credit cards.  And I'd forgotten what my Chase password was.



LEO:  Oh, yeah, all the time.



STEVE:  And it was something that I wanted to make sure was going to be very, very safe.  So I put in CHA and hit find, and bang, there it finds it.  And I look at it, go okay, and transcribe it onto the web browser, and then I'm logged in.



LEO:  Now, do you sync that to anything?  Or is it just on that Palm?



STEVE:  I do not sync it to anything because I don't...



LEO:  So if anything should happen to that Palm, what are you going to do?



STEVE:  [Laughing] That's a problem.



LEO:  Yeah.



STEVE:  Yeah.  It will sync itself to an SD card because it's got an SD card reader.  And so I'm able to copy it to an SD card.



LEO:  Oh, all right.



STEVE:  But I don't want to sync it to a PC because then all that stuff is in the PC, where it's then no longer offline.



LEO:  Well, and that's the problem I have with Evernote because it's, you know, the convenience of it is it's on my iPhone, it's on all my computers, and it's in the cloud.  But it's risky.  Of course I do encrypt.  But you have to trust their encryption.  And, by the way, my encryption password, it's just the same, it's one password.  So in effect there's one password to get all that data.



STEVE:  Yeah.  And if I were to start again I would probably do something like that.  At this point, since this sort of has been my incremental solution for many years, and it works, and it's as secure as I can, I mean, it's not universal.  I don't have it on my portable phone and other things.  I will not stick it in my phone because we were just talking about problems with iPhones.  So, I mean, this is a dilemma.  And I liked John's note because he just sort of says, you know, this is really a problem.



And part of me thinks that, one way or another, eventually this will be solved.  It's hard to guess what the solution will be.  I mean, it's hard to know what the solution will be.  Maybe it'll just be solved incrementally.  It may be that we'll, you know, we've talked about solutions.  Like things like VeriSign, where they offer a one-time password based on a credit card with a battery in it, or the football that is based on time.  And so you loop through third parties.  It may be that ultimately these sorts of things, which are still nascent, which are still not universally adopted, will begin to see some convergence around a solution.  Or our favorite little gizmo...



LEO:  The Kindle?



STEVE:  The USB gizmo.  I can't believe I've forgotten what it is now.



LEO:  I've forgotten it, too.  I know what you're talking about.  Stina's thing.



STEVE:  Yeah, Stina's thing.



LEO:  YubiKey.



STEVE:  YubiKey, yes.  It might be that something like that makes absolute sense.  So I just sort of wanted to say yes, John, I feel your pain, and I feel the pain of this poor guy that we talked about two weeks ago who was deliberately jumping through hoops so as not to be forced to change his password because he so much didn't want to.  And the bad thing is we know most people, most non-listeners of this podcast are using one password for everything.



LEO:  Oh, yeah.



STEVE:  Or just a couple.  And they're vulnerable to that being - losing control of it, to it getting away from them.  But...



LEO:  And there are choices.  There's, like, KeePass.  There's RoboForm and 1Password on the Windows and Mac, respectively.  I mean, there are tools to do this.



STEVE:  Yeah.



LEO:  But the people who use them are more sophisticated, frankly.  My mom doesn't use a password manager.



STEVE:  No.  And we talk a little bit - there are some interesting questions this week.  We're going to be talking briefly about this notion of Internet access as a human right and how we feel about that.  And there's this notion that, as a consequence of pressure on us, we're being pushed onto the Internet.  I mean, it's necessary almost for more and more things that we want to do during the day.  Unfortunately, authentication comes hand in hand with that.  We need to be able to identify ourselves in a secure way.  And, I mean, I really see this as a huge disconnect, a huge problem which is burdening people, for which there isn't a unified solution.  There isn't one solution that works for everybody because it's not all pulled together yet.  And somehow it needs to be.  This is the kind of thing that Stina and YubiKey and VeriSign and these kinds of companies are saying - they're out there waving their arms around saying we solved the problem, we solved the problem.  Except they haven't until everyone uses them.



LEO:  Right.



STEVE:  So, and we've talked about also the problem of having like a keychain full of dongles of non-unified solutions.  That's not a solution, either.



LEO:  No.  And so I'm glad he wrote because I certainly hope we didn't come off as unsympathetic to these guys.  I didn't really like the way they were solving it; but, I mean, I share their pain.  Doug Smith, Albany, New York worries when human rights become inhuman rights:  Hi, Steve and Leo.  A couple episodes ago, I'm not sure exactly when, I recall you and Leo discussing a move afoot in some places to establish Internet access as a basic human right.  My take on your comments was that you both were leaning in favor of that idea, basically pointing out there is much that people miss out on if they don't have access.



While I don't dispute the idea, I must say my gut reaction was more of fear rather than comfort because I believe that it should be a basic human right to be off the grid, as well.  There's a different between a right and a requirement.  But all right.  We'll go on.  I don't think anyone should be obligated to have Internet connectivity to fulfill their civic duties.  They should not be required to have an email address.  They should not be required to have a cell phone.  I'm with you on all of this.  They should not be required to vote electronically over a network.  They should not be required to submit their taxes electronically, and they should not be required to have Internet access at home in order for their children to attend public schools.



I'm much more afraid of the ways government would abuse Internet connectivity when it is deemed to be available to everyone than I am of the consequences of people not having access.  The fact that not everyone has access means that government is still responsible for communicating with us even if we don't own a computer or have an ISP contract.  Just another perspective I'd like to hear represented.  As always, thanks for the great podcast.  You guys are the best.  Doug Smith.  What do you think?



STEVE:  I really do see his point.  I've been, as a non-parent, I hear stories from other parents of, like, the way papers are submitted now.  Even at the high school level you can't submit papers handwritten.  They have to be printed from a computer.  And one of the reasons is that they're put through a central clearinghouse, an online database, to look for forgery or for...



LEO:  Plagiarism, yeah.



STEVE:  For plagiarism.  And when my sister told me that my niece and nephew were doing this, it's like, huh?  I mean, that was news to me.  And so seems to me that that's a good example of you have to be using a computer.  You have to have access to a computer.  And I think that's what he means by they should not be required to have Internet access at home in order for their children to attend public schools.  I mean, it's the way things are done now.  And I know that one of the gals that I hang out with at Starbucks in the morning is a schoolteacher, and she sort of - she's a science teacher for her elementary school and sort of has taken up the responsibility of educating the other teachers in using the web services that are available.  And it's not possible now not to use that sort of technology as a teacher.  And she posts things on her site which she assumes students and parents will have access to.  And the sense is you have to be online now in order to be functional in a public school.



And I completely agree with him.  I heard you chiming in when he talks about email and cell phones.  I'm annoyed now when I'm filling out a form, and some random form line wants my email address.  I protect my email address.  I don't want spam.  I want control over that.  And the idea that this is the way I'm going to be contacted, I would like the choice.  And so I really understand what he says.  I'm not sure that I intended us to sound, like, positive or encouraging of the notion that Internet access was being defined as a human right.  I just thought it was interesting in the sort of, like, wow, that strikes me as a big deal, as a significant thing, not something small.



LEO:  I'm of the opinion it absolutely is a human right.  And the point being that everybody should have it available, not required.  Although what if we take what he just wrote, and we put in "telephone" or "snail mail" or "television"?  I mean, part of what he's saying makes sense to us because these are new technologies.  But you wouldn't really be puzzled by somebody who said what's your phone number and then had difficulty dealing with you because you didn't have a phone.  We've accepted that as being kind of ubiquitous.



STEVE:  Yeah, that's true.  If someone actually had no cell phone and no home phone...



LEO:  No way of reaching them by phone.



STEVE:  No phone.



LEO:  That's their right.  It's their privilege.  But as a result there are going to be some consequences in the modern world.



STEVE:  Yeah.



LEO:  And because that's an older technology we kind of accept that.  We understand that.  And there are some hermits who don't want a phone, and that's fine.  You can do that.  But expect to have a little more difficulty in your life.  And I think that's all that's going to happen here.



But what's very important is - and I think it's akin to electricity.  I often liken it to the rural electrification programs of the Great Depression, where there were people in this country in rural areas who had no access to electricity.  And it was deemed a priority by the government, and it happened to help in the Depression employ people with programs like the Tennessee Valley Authority to electrify these rural areas because - you know, "right" is a strong word.  We can argue about what's a right.  But it's certainly something everybody ought to have access to is electricity.  And I think the Internet is very similar to that now.  You don't have to have electricity.  You don't have to have a phone.  You don't have to have the Internet.  But you should have it if you want it.  You know?  You should have the right to have it if you want it.



STEVE:  Yes.  You should be able to get it, and it should be affordable.



LEO:  Yes.  It's not free.  Nobody's saying it's free.



STEVE:  Reasonably affordable.



LEO:  But there's lifeline phone service that's subsidized by all of us who have phones so that people who can't afford a phone, can't afford a full price phone, can at least get lifeline service because it's recognized that a telephone is a vital important lifeline, at least for 911 if nothing else.  So I think it's like that.



STEVE:  There are public utility or public service opportunities for web connection also, like public libraries, where you're able to use a computer.  And thanks to web-based technologies you can have an email address on Google Mail or Hotmail that gives you an email address even though you don't have your own Internet connection and computers and things.  So there are ways to solve the problem.



LEO:  They do that, in fact, at least here in California, for homeless people.  They have programs to give them phone numbers and email because it's hard to apply for a job if you don't have somewhere you can be reached.



STEVE:  Right.



LEO:  And the idea being, if you provide this for these  people, maybe they can get work, and they can get off the streets.  But, you know, it's very hard to get off the streets, when you're living on the streets, if you've got nothing.



STEVE:  Right.



LEO:  So I don't think anybody's saying that there's an equivalent between a right and a requirement.  I'm just saying that I think it's very important that we recognize Internet access is increasingly important to participation in our modern world.



STEVE:  Yeah, and I do like your analogy with the notion of telephone, for example, or even electricity.  I mean, it's, yeah, I think that's a good one.



LEO:  It's easy for us with new technologies because, I mean, well, we lived without a computer, you and I, when we were young men.  We lived without email.  We survived.  But times have changed.  I wouldn't expect my kids to do so.  Although I'm reading Jerry Pournelle's book right now, "Lucifer's Hammer," about a comet hitting the earth and losing, you know, basically civilization is gone.  And you really realize how dependent we are on technology.  And, I mean, there's not - there's only, I don't know how much, 30 days of food in the U.S.  We all live pretty - almost hand-to-mouth, really.



STEVE:  Wow.



LEO:  So should something horrible happen - and by the way, he also raises the issue in the book, very few of us actually know how any of this works.  You get in your car, and you drive around, but we have no idea how it works.



STEVE:  It's a really good point, too, how much of the detailed knowledge required to recreate the technology is gone.



LEO:  It's gone.



STEVE:  Yeah.



LEO:  We're living in this house of cards.  Let's hope it all stays okay here.  Hey, Joe Perleberg from Green Bay, Wisconsin has our next question.  He has some insights on the fingerprints that we've talked about in the past required for checks at the bank:  Steve and Leo, I was listening to the latest episode of Security Now!.  I have some more information regarding the taking of fingerprints when cashing checks.  I live in Green Bay, Wisconsin.  And of the many banks I went to around town, nearly all of them, all of them required a fingerprint to cash a check for a non-account holder.  Also, I even noticed some retailers that asked for a fingerprint - whoa - when writing a check over a certain amount to purchase items.  Wow.  Retailers now have fingerprint devices?  I completely agree with your stance on the issue, but I thought you should know that this is by no means an isolated incident.  I was told by several banks this is a new measure to protect against check fraud, but that it doesn't necessarily stem from 9/11.  Which is what I thought.  Thanks for putting out an excellent show.



STEVE:  You know, I guess I'm sort of out of touch with checks.  I'm not a check user.



LEO:  Don't use checks.



STEVE:  Yeah, I use my credit card as cash and then pay the balance every month, so it works for me.  The card company's not real happy with me because they don't make any money from me.  I guess they get a percentage, though, of all of the money that I run through the card, so they're making it there.  But I thought that was interesting feedback.  The problem of course is that, you know, you mentioned, whoa, retailers are taking fingerprints now.  The problem is storage is cheap, data transit is virtually free, and the technology for reading fingerprints went from once upon a time getting ink on you that no one would want to do, to sticking your thumb on an optical scanner.  Well, the cost of doing that has just dropped to nothing.  So...



LEO:  I have one on my new Dell computer.  And actually I kind of like it.  It has a preboot authentication.  So it's kind of like the BIOS password.  When you open the thing up, before Windows even does anything, you have to scan your password.  I kind of like that.



STEVE:  Yeah, well, I have it on all of my laptops.  Not my Macs, but both of my Lenovos.  And the drive is encrypted.  The fingerprint is down in the TPM, the Trusted Platform Module.



LEO:  It's TPM, that's right, yeah.



STEVE:  Nothing can get to it.  And it turns on, and it says, okay, let's see who you are.  And so I swipe my finger over the scanner, and it looks for the match and finds it, unlocks the drive, and then it can boot.  But until I do that, it's locked up tight.  No, it is - see, there I have no problem with it because I'm controlling the information.  It's in the TPM.  And it's my laptop recognizing me.  The idea, though, I mean, it just, oh my god, the idea that retailers are sucking in people's fingerprints, we're in for a fall.  This is not going to end well.



LEO:  I like it.  It's like your mom saying, "This is all going to end in tears."  



STEVE:  This is not going to end well.



LEO:  Joe Dorward from Berkshire, England brings us the Head Shaker of the Week report:  Steve, I just attempted to log out from my Hotmail account.  Here's the error message I got:  "Sign out failed.  We could not sign you out because your browser seems to be blocking third-party cookies.  Close all browser windows to sign out.  To prevent this error in the future, you must enable third-party cookies by changing your browser settings."  Thank you.



STEVE:  That's the most backwards thing I have ever heard of. 



LEO:  Well, I can't even think of why, right, because you're in Hotmail.  This is first-party cookies they want to set.  Who's setting a third-party cookie?



STEVE:  And it's to leave.  It's not to...



LEO:  It's not even...



STEVE:  It's not to sign in.  It's not like they're using some third-party authentication server.  I mean, apparently they are.  But they're trying to do that to say goodbye somehow.  And so they're saying, well, unfortunately we cannot log you out because you're blocking third-party cookies.  Which means we're sending your browser something to cause it to get something from another server.  And because you're not sending a cookie back, that other server can't recognize who you are, and that's preventing us from accepting your logout.  It's like, okay.



So then they're saying close all browser windows.  So that at least is good.  That means they're using session cookies somewhere rather than persistent cookies.  So losing your session cookie is what happens when you close all your browser windows.  So that's good.  But then they're saying, just so you don't have this problem in the future, turn on third-party cookies so that we can log you out next time.  I don't know.  It's just I got the biggest kick out of that.  It's like, okay, well, who knows what Hotmail is doing.



LEO:  You see nowadays a lot of sites that require third-party cookies in a lot of ways.  I use a service called Feedly that is kind of a home page service I really like for - it gives me Google Reader and my home page at Firefox.  But for obvious reasons it needs third-party cookies because it's on the Feedly site, but it's getting it from Google Reader, I mean, it's just - you're seeing more and more of this.  But as we've talked about before, and I encourage people to listen to earlier shows, third-party cookies are a way information can leak from the page that you're on to somebody else and can even leak across site.



STEVE:  Yes.  And so I would say that awareness of them is all that we would really hope people have.  And then arrange a solution that works for you.



LEO:  Now, you treat all cookies as session cookies; right?  You say they're only alive through the session.  Or is that you that does that?



STEVE:  Yes.  It's a nice setting in Firefox that allows me to normally discard all cookies.  But when I'm at a site where I do want to be remembered, then I use just a simple little tool.  And it's simple to the point where you don't even need it.  If you went into Firefox's UI you could say "trust this site."  But it allows me just - it's a little tiny "c," "c" stands for cookie, and I'm able to click on it and just say, like when I'm on Amazon or eBay or PayPal, a site that I care about where I'm going to be coming back in the future, I'd like them to remember who I am, I just say, yep, remember that cookie.  And so it creates an exception to the normal policy of discarding them all the time.  And then they're persistent.  So it's, again, it's an opt-in rather than an opt-out approach.



LEO:  Right.  And Euchre [sp] points out in our chatroom that the reason Hotmail would do it is because you're on Hotmail.com, but there are other Microsoft.com and maybe even Live.com sites involved.  And so those would show up as third-party cookies.  Even though they're all from Microsoft, they're different domain names; right?



STEVE:  Right.



LEO:  So I guess that makes sense.  Our last question, Mr. Gibson, comes to us...



STEVE:  This is so sad.



LEO:  I haven't read it yet.  But I see the title.  I'm intrigued.  Steve in Rochester, New York brings us the Sad Biometric Stupidity Story of the Week.  I love these.  This is of the ilk of the knuckle at Disneyland; right?



STEVE:  Oh, if only.



LEO:  Worse?  Hey, Steve and Leo.  I just finished listening to Episode 222 with the story about a man who couldn't cash his wife's check without giving up his fingerprint.  We were just talking about that.  In early September, at a Bank of America in Tampa, the same thing happened.  The really sad part is the bank wouldn't make an exception even though the man had no arms and therefore no fingerprints to give.  This is the story at ABC local news.  Unbelievable.  "Man with no arms denied check cashing.  A man born without arms is upset that a bank would not allow him to cash a check without having a thumbprint.  Steve Valdez said a Bank of America branch in downtown Tampa [Florida] would not allow him to cash a check from his wife last week."  He wasn't an account holder, so as usual they asked for a thumbprint.  He's got prosthetic arms, but there's no fingerprint.  He presented two forms of ID, still was denied.



"He said a bank manager told him he could either come back to the bank with his wife or open an account himself.  Bank of America spokeswoman Nicole Nastacie said the bank has apologized to Valdez.  [She] said the bank should have 'offered alternative requirements if an individual is not able to give a thumbprint.'"  I wonder what happens at Disneyland to the guy.  That's just, oh, that's...



STEVE:  Isn't that amazing?



LEO:  I think he has a lawsuit under the Americans With Disabilities Act, to be honest.



STEVE:  I would imagine.  I mean, here's a policy which obviously wasn't well thought through.  And it's like, okay.  And, well, and so here's the problem.  As we move forward, and the need for a fingerprint becomes ubiquitous, what does he do?  I mean, it's nuts.



LEO:  Not everybody has a fingerprint.



STEVE:  Not everybody has one to give, even if you wanted to give one.



LEO:  Sorry.



STEVE:  Yeah.  And believe me, I'm sure our listeners know, resist with your last breath.  I mean, again, the idea that retailers have fingerprint scanners, I mean, [verbal shudder].  It's a reason to use a credit card.



LEO:  Well, you know what's next:  DNA.  Everybody can give DNA in some form.



STEVE:  You're probably right.  So here, lick this swab, and we'll...



LEO:  Yeah, give me a hair.  You know?  I mean, seriously.  I think that we are ready - and by the way, the implications of that are terrifying.



STEVE:  Oh, boy.  Because after we've got the genome sequence, yes, then it's like, oh, well, don't worry, we're going to check out your health factors in the future and see what problems you're prone to.  Oh, no, it gets very Big Brother-y pretty quickly.



LEO:  I just got word that I am going to be allowed to participate in a very interesting project that a geneticist named George Church does, or is doing, that you're probably going to say, Leo, stop right now, don't do it.  He's at Harvard.  And he is doing - let me see what they call this.  He's at the Harvard Medical School, and he's a professor of genetics, professor of health sciences and technology.  He's got a project called the human, I'm sorry, the Personal Genome Project, in which he asks...



STEVE:  PGP.



LEO:  PGP.  He asks people to not only give up their genome - you volunteer for this - but also to answer extensive questionnaires about your phenotype - medical records...



STEVE:  In order to match them up, yup.



LEO:  Reason being, if somebody is willing to do this, if enough people are willing to do this, there's huge value because you can say, well, look, here's a gene site that seems to be correlated to obesity.



STEVE:  Yes.



LEO:  But you can't do that unless you've got the two.  So Esther Dyson has volunteered to do this; a number of his colleagues at Harvard.  And I said, you know, I'm already a public figure.  So I can't be harmed at this point by this kind of stuff.  I self-insure because I have my own business.  So I don't have to worry about discrimination by employer or an insurer.  So I volunteered to do this.  And by the way, all data is published including your name because they say we can't guarantee full anonymity.



STEVE:  Wow.



LEO:  So rather than try to guarantee full anonymity, we tell you upfront we're going to publish it.



STEVE:  I think that's very cool.  I mean, if that's - I think - I take my hat off to that.  I think that's exactly the right way to do it.



LEO:  Yeah.  Just don't promise something you can't guarantee.



STEVE:  Yeah.



LEO:  However, you can see the huge societal value to people volunteering to do this.  They hope to get 100,000 volunteers.



STEVE:  Yeah.



LEO:  Anyway, I volunteered.  We're going to interview him on Futures in Biotech and talk about it.  And I realize, I understand the risks.  I mean, I understand maybe better than most because of doing this show with you for so long.  But I think it's worthwhile.



STEVE:  Yeah.  And, I mean, certainly this kind of information could be used for good.  And of course it could also be used for discrimination.



LEO:  Yeah.



STEVE:  Which is, you know, the dark side of that is, well...



LEO:  Absolutely.  I could be denied insurance.  I could be denied employment.  But I'm of an age now, and my business is my own.  So I feel like relatively protected.  I mean, 10 years from now I could be on the street looking for work.  But I'm willing to take that chance.  And I think there is such a benefit.  Anyway, we're going to talk to him.  I think it's very interesting.



STEVE:  Very cool.



LEO:  They don't do your whole - they can't do your whole genotype.  They do a portion of your genotype.  But it is, you know, it's very interesting, I think.



STEVE:  Well, and it makes sense that it needs to be voluntary because this is supersensitive information.  And...



LEO:  They have a very extensive informed consent document, as you might imagine.



STEVE:  Yeah.



LEO:  And you have to pass tests and so forth before you can participate.



STEVE:  Cool.



LEO:  I think it's very, very interesting.  People want to know more about it, it's PersonalGenomes.org.  And I don't know if they're looking for volunteers from the public yet or not.  I know that was the plan.  I guess they are.  It's a very interesting idea.



Steve, I really appreciate your time, as always, and your insights.  And it's so valuable to talk to you.  And I thank 

you for doing the show, as I know everyone else does.  People can go to Steve's website, GRC.com, Gibson Research Corporation.  That's where all of the freebies like ShieldsUP!, DCOMbobulator, Shoot The Messenger, some great security stuff, Perfect Paper Passwords, live.  Also 16KB versions of this show.  Thanks to Steve, by the way, who's taken over the editing of that.  Do you do that yourself, or do you get somebody to do it with you, or...



STEVE:  No, I do it myself.  You drop the file in the drop box, I get it in the later afternoon, I edit it down and post it for Elaine to do the transcriptions.



LEO:  That's very nice.  Steve pays for the transcriptions, too.  So this is his commitment to you.  So transcriptions, 16KB versions, and of course the full version and all the show notes at GRC.com.  And while you're there, help Steve out a little bit.  Help a brother out.  Pick up a copy of SpinRite - help yourself out - the world's best hard drive maintenance and recovery utility.



STEVE:  It may come in handy.



LEO:  Yes, it may, definitely.



STEVE:  And this is our Thanksgiving episode.  So Happy Thanksgiving to everyone, those who observe Thanksgiving.



LEO:  That's right, this will ship on Thanksgiving, that's right.



STEVE:  Yeah.



LEO:  So if the turkey didn't put you to sleep, maybe we did.



STEVE:  If the tryptophan doesn't get you...



LEO:  Security Now! might.  Great, Steve.  Thanks.  Have a great - are you going to Mom's for Thanksgiving or staying home?



STEVE:  Nope, going to have dinner down here in Southern California with a bunch of friends.  And I do Mom's on Christmas.



LEO:  That's great.  Not a ham sandwich, I hope, on turkey day.



STEVE:  Nope.



LEO:  Okay.  Get some actual turkey in you.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#225

DATE:		December 3, 2009

TITLE:		Same Origin Troubles

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-225.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo plow into the little understood and even less known problems which arise when user-provided content - postings, photos, videos, etc. - are uploaded to trusted web sites from which they are then subsequently served to other web users.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 225 for December 3, 2009:  Same Origin Troubles.  



It's time for Security Now!, the show that protects you as you surf the world on the World Wide Web.  Mr. Steve Gibson is here.  He is the man behind the Gibson Research Corporation, creator of SpinRite.  You know, I was looking at your - hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again.  You know, we don't have a jingle, and I guess that's a good thing because...



LEO:  No, you don't need a jingle.



STEVE:  ...that would sort of be distracting, like you do with Dick DeBartolo, to be, like, talking over jingles that were going in the background.



LEO:  [Singing] You've got viruses, and Steve's got the cure.  He's the man - no, that doesn't fit.  It doesn't...



STEVE:  No.



LEO:  I was looking at your Wikipedia entry.  And it's funny, I mean, it's so funny to watch the discussion behind the scenes because there are people, I think it's one guy, but there's somebody who doesn't like you.



STEVE:  Yeah.



LEO:  And somebody questioned calling you an engineer.  And I just wanted to, you know, I wanted to, like, get on there and say, what do you mean, is he an engineer?  The guy, for crying out loud, he built the light pen for an Apple II.  I mean...



STEVE:  Yup, that blew Wozniak away.  I remember that Steve Wozniak was at the Applefest, the Boston Applefest.  And he stood there - I loved the pronoun he used.  He looked up as I was demonstrating the light pen.  And he said, "You always blow me away with what you're able to get my machine to do."



LEO:  Oh, isn't that nice.



STEVE:  He was possessive about it.  I thought, that's really neat.



LEO:  Well, that's also, from Woz, very high praise.



STEVE:  And the real trick of engineering was that, whereas all light pens of that era were big cigar tube-size things...



LEO:  I remember, yeah.



STEVE:  ...mine was the size of a regular little pen.  And I had figured out how to mount the amplifier at the other end, back in the Apple.  And I used something called a transconductance amplifier because the photo diode, you had to use a photodiode, not a photo transistor, because of the response time.  A transistor's amplification makes a photo transistor way too slow to respond to the beam moving past in front of the screen.  The photo diode can do that.  But the problem is then you have to count electrons, literally almost like a photo multiplier.  And to do that at the end of a four-foot cord, and to put the amplifier in the Apple, which is a noisy environment - anyway, it was a, well, I guess it was a feat of engineering.  So, yeah, I think I qualify as an engineer, so.



LEO:  Probable some people listening have no idea what a light pen is.  In the days before styluses and touch screens you used light pens; right?



STEVE:  Yeah.  Well, it was - well, actually I would say the day before the mouse because...



LEO:  It predated the mouse, too.  You're right, yeah.



STEVE:  Yes, exactly.  The idea was I think it dated from maybe like NORAD or, you know, high-end display systems.  And you'd - because I remember like in early movies that were showing, like, military complexes, there would be people in uniform, like, touching the screen with a pen.  And the idea was - and those were old XY displays, where the beam jumped around all over the screen like painting air traffic control diagrams and things.  And so you could, if you touched the pen to where something was on the screen, the system would notice where the beam was when the pen said, ooh, I just saw the beam go by.  And that was a way of feeding back coordinates into the computer.  So, yeah.  And, I mean, it was my first real independent corporate success was the light pen for the Apple II.  And actually there were some tremendous articles that were very flattering about how well it worked.  And, in fact, Atari bought it from me because they wanted it for their Atari.



LEO:  I didn't know that was yours.  I remember the Atari light pen.



STEVE:  Yeah.  I wrote all the software for it, too.



LEO:  I'll be danged.



STEVE:  Yeah.



LEO:  And part of the discussion was interesting, which is, well, what constitutes an engineer?  How do you - do you have to have a degree in engineering to be an engineer?  I mean, that doesn't make sense.  An engineer is somebody who designs and builds stuff.



STEVE:  Yeah, I think of myself, I mean, sort of both scientist and technologist.  I think of a technologist as an applied scientist.  I like creating things.



LEO:  Right.  Well, that's what engineering is.  It's applied science.



STEVE:  Yeah.



LEO:  And that's what, you know, we often talk about that on the network.  And it's one of the reasons we're doing more science stuff with Ray and with Kiki, because I think people forget the strong bind between science and technology.



STEVE:  It was probably the Windows XP raw sockets thing that upset...



LEO:  That's when you made enemies.



STEVE:  That's when I made enemies.



LEO:  And you were right.



STEVE:  I was right.  But that doesn't really count.



LEO:  I mean, that's the funny thing.  Even Microsoft acknowledged, finally, yeah, it was a problem, and took it out.



STEVE:  And fixed it, yeah.



LEO:  But, you know, damage done.  But it's still - it's funny, I mean, when you see somebody saying, well, Steve's not an engineer, it's just you have to laugh at the person [indiscernible].



STEVE:  Yeah, I love where people who have said, yeah, he's only ever written one program, it's like, oh, have you been to GRC lately?



LEO:  People often say things without any knowledge.  You hear that all the time.



STEVE:  Well, and the other thing, too, is the anonymity.  We don't know who these people are.  I mean, everybody who matters knows who I am and what I've done.  But the 'Net lets people with no pedigree whatsoever comment as if they had some.  It's like, oh, okay.  I mean, I just - I do what you do, Leo.  I just ignore it, say okay.



LEO:  Brush it off.  What are you going to do?



STEVE:  Yup.



LEO:  What are you going to do?  Somebody's pointing out in the chatroom that "Jeopardy!" uses a light pen and has since 1984.  That's how the contestants sign, you know, write their answers, Final Jeopardy answers.



STEVE:  Ah, and sportscasters.  Weren't they doing things now with, like...



LEO:  Telestrator is essentially a light pen, yeah.



STEVE:  Right.



LEO:  Although now I'm sure it's touch, not light, yeah.



STEVE:  I would think so, yeah.



LEO:  Before we get to our subject - what is our subject, by the way?



STEVE:  Our subject is - you wouldn't know from the title.  Normally you do.  The title is Same Origin Troubles.  There's been a, I would say it qualifies as a kerfuffle in the security community which was launched about the middle of November, so about two weeks ago, by a security outfit who claimed that they had discovered some flaws in Shockwave Flash which made all websites that weren't specifically designed to protect against it vulnerable to user-uploaded content.  And Adobe responded; and, I mean, there were articles in a number of major industry newspapers.  SC Magazine had a comment; Computerworld had a comment.  Of course the Register weighed in.  And it brought to my attention the fact that we had never explicitly discussed same origin.  Because it's a fundamental security aspect of the Internet that unfortunately most sites actually are not good about handling.



So because it really is a problem, even though I would argue that, sort of on Adobe's side, that it's not their problem, even though unfortunately Shockwave Flash is more permissive in a number of ways than it ought to be.  I thought that would be a great thing to talk about is the idea of the danger associated with user-uploaded content and how that danger can be mitigated by making sure that when you serve back user-uploaded content, you don't do it from the same origin as the content you trust because inherently you should not trust user-uploaded content.



LEO:  All right.



STEVE:  So wind up your propellers.



LEO:  Fascinating.  Yeah, no, this is very relevant.



STEVE:  It way is, yes.



LEO:  Really great to talk about.  Before we do that, I would like to - and we will have, of course, as always, our weekly dose of security news, errata, updates, things like that.



STEVE:  And I have a nice Thanksgiving story.



LEO:  Aw.  So will we start - you want to start with errata, security news, where do you want to start here?



STEVE:  Yeah, we've got a bunch of security news.  Nothing, well, okay, yeah.



LEO:  [Laughing] Something.  A little news.  A little.



STEVE:  I wanted to make sure that everyone using Safari had updated themselves.  Apple recently fixed multiple critical vulnerabilities which affect both Mac OS X and Windows.  There were multiple vulnerabilities in Safari's handling of just pretty much everything, a variety of web page scripting constructions and malicious images.  There was an integer overflow error caused by improper handling of images, containing an embedded color profile.  It's interesting, color profiles seem to be a problem for Apple.  We've had a lot of, like, mentions of color profile problems in the past.  I don't know what's going on.  Someone ought to really look at that code closely and say, okay, let's just fix these things once and for all.  Or, who knows, maybe they keep tweaking with it and messing it up, as our old code/new code dilemma.



Safari can be made to crash while parsing specially crafted XML content.  And of course the concern was that a crash could be evolved into an attack, which is generally the way those things go.  There was an error in Safari's handling of navigation which could cause a specially crafted HTML file to load a local file and lead to information disclosure, which is not good, depending upon what local file you load.  They've discovered that the way cross origin, which is actually the topic of our content today, our podcast, the way cross origin resource sharing was implemented in WebKit could result in cross-site request forgeries, which we've discussed in a separate podcast before.  So that got fixed.  And the way WebKit handles FTP directory listings could lead to arbitrary code execution, information disclosure, or at least application termination.  So that all got wrapped up and fixed in the latest version of Safari.  Now, I wrote 4.0.0, but I think I meant 4.0.4.



LEO:  Let me check and see what I, you know, because I'm sure I'm up to date.  I am running 4.0.4.



STEVE:  Ah, good.  Then my memory was correct, and what I wrote was wrong.  So everyone wants to be at 4.0.4.



Not surprisingly, Internet Explorer, another one of our favorite troubled browsers, has a pretty bad zero-day remote code execution vulnerability.  The bulk of the market share of IE is still at version 6 and 7.  Even though 8's been out for a while, 6 and 7 are the ones that are vulnerable.  Interestingly, in Microsoft's extensive note - they've acknowledged the problem.  They know they've got it.  Hopefully we'll get this fixed in December, on December 8th, which is next - which will be the second Tuesday of December and will be the Patch Tuesday for December.  I'm hoping this gives them time to fix it.  In their extensive write-up they said, well, but IE5 isn't vulnerable.  In fact...



LEO:  5?  Who gives a - 5?



STEVE:  I know.  And in fact they even had to say that 6 running on Windows 98 was vulnerable.



LEO:  Oh, dear.



STEVE:  Of course that won't get fixed anytime soon.  But it turns out that there's a problem with the way CSS-style objects are invoked which surprised Microsoft.  Exploit details and proof of concept of this exploit are on the 'Net.  So that makes it a zero-day exploit.  And we've often talked about the Metasploit framework, which is this framework that allows hacks to be created and deployed very quickly.  The Metasploit framework exploit module 37085.RB will demonstrate this and allow people to do bad things to IE6 and 7.



And I think I remember reading that 6 and 7 still have, like, 80-plus percent of the IE market.  So lots of people have not moved to 8.  I mean, I was reluctant to do so.  I waited a while.  And pretty much now when I'm on one of my machines that's still on 7, it's like, okay, yeah, fine, I'll go to 8 now.  I'm sort of getting used to it and the way it looks and so forth.  And it's arguably more secure.  Certainly in this case it is.  So if anybody right now is still on 7, this might be a little good reason to kick yourself up to 8, which has become, I think, stable enough to use.  In a little twist on Microsoft's second Tuesday of the month updates, remember that last update was November's, and that it was a massive update.  A huge number...



LEO:  Biggest in history; right?



STEVE:  Yes.  A huge number of things fixed.  And it turns out...



LEO:  Broken.  No.



STEVE:  Yes.  There is now the Black Screen of Death.



LEO:  Oh, yeah, I've been seeing a lot about this, yeah.



STEVE:  Yes.  Apparently Microsoft tweaked in this massive update some ACLs.  Those are Access Control Lists which govern what processes are able to read and write files and even registry keys in the registry.  And Microsoft has acknowledged the problem.  They're trying to track it down.



LEO:  It's Windows 7 only; right?



STEVE:  Good question.  It might very well be, although...



LEO:  That was my sense, but I haven't done a lot - I haven't...



STEVE:  Yeah.  It might very well be Windows 7 only.



LEO:  And by the way, I don't think that widespread.



STEVE:  No.  And that's what Microsoft is saying.  It's like, okay, we're looking into it.  But it's not, I mean, I updated everything.  Although I'm not on Windows 7 yet, so it wouldn't have hit me.  But, yes.  If this had been a huge, huge problem, first of all, it would not have gotten through Microsoft's own pre-release testing.  And the world as we know it would have come to an end if everybody running Windows 7 had this happen.  But certainly, apparently, maybe it relates to one particular graphics driver.  I think I remember seeing, it's like some ATI Radeon something or other, where you could say, okay, well, I could see how that could slip through Microsoft's testing.  But it's never good when the security updates that we're being increasingly forced to install just out of our own instincts for self-preservation, when they go bad, that's not good.  So...



LEO:  It just underscores the difficulty, though, that Microsoft faces with this huge variety of hardware that they run on.



STEVE:  Yes.



LEO:  Testing is a nightmare.



STEVE:  It's phenomenally difficult, yes.  And in a weird story that I just sort of picked up on...



LEO:  Just briefly, the chatroom is saying that on Slashdot now the story is being retracted.



STEVE:  Really.



LEO:  Yeah.



STEVE:  Okay.  So Microsoft said they were investigating reports.



LEO:  And this might be the Microsoft result.  This was a Neowin report.  And Microsoft said they hadn't seen issues - okay.  Prevx, the guy who found it, has issued an apology.  They blame malware for making changes to the registry which causes this behavior.  So they had malware on their system, making it an even more oddball environment.



STEVE:  Interesting.  So, okay, so there was something bad there to start with, and then Microsoft's security updates come along, change some ACLs and piss off the malware, and so now other things don't work.



LEO:  Yeah.  Thank you to Avillafane and Mike and others who notified us of that.



STEVE:  Yup.



LEO:  That just broke, so...



STEVE:  Cool.  A pub in the U.K., a bar, which is offering free WiFi, free open WiFi, was fined $13,000 by the copyright holder of some content that the copyright holder claims was illegally downloaded.  And that's caused a lot of news in the U.K. because, I mean, the idea of somebody offering free open WiFi being sued due to the conduct of somebody taking advantage of their open WiFi service, I mean, that's something that obviously would be huge if this were setting a precedent for the way the world's going to be moving forward.



Now, there's pending legislation in the U.K. which they call the Digital Economy Bill, which would provide protection because the business would be classified as a public communications service provider, which would make it exempt from litigation.  That is, essentially they would be considered a common carrier and not responsible for the actions of people using their service.  And then some legal opinion was obtained which - and the legal opinion came down and said that WiFi hotspots in public and enterprise environments that provide access to the Internet to members of the public, free or paid, are public communications services, which then would exempt them.



But at the moment there's not this legislation in place.  And as far as I can tell, this fine is still in place.  And I imagine the pub is not - has asked to remain anonymous and isn't discussing, isn't talking about the specifics.  But it caught my attention because this does sort of, I mean, we're all massive users of WiFi hotspots as we travel around with our laptops, hopefully keeping cognizant of security.  But if this was setting a precedent, obviously, such that people were using the hotspots to download illegal content, and the hotspot providers were then coming under legal attack as a consequence of the actions of the people that they were offering the service to, well, that potentially really throws a monkey wrench in this whole notion of go to Starbucks and get free WiFi, or wherever.



LEO:  Yeah, no kidding.



STEVE:  So it'll be interesting to see how this gets handled.  And then it does create, though, another problem, of course.  If it's clearly made policy that there's a complete hold harmless and somebody offering such delivery system like open WiFi isn't liable, then where is the liability?  I mean, then you would go to an open WiFi hotspot specifically to do your illegal things, and...



LEO:  Well, but it's similar to the safe harbor provided to Internet service providers.  I mean, if you're a pub owner you're...



STEVE:  So you're just extending that; right.



LEO:  You're passing along Internet service.  You're becoming an Internet service provider.  And I think that in the U.S. you would be protected.  I think it's interesting the British tried to make a law against it.  I don't know if that would hold up here.  That's very interesting.  It's a terrible precedent.



STEVE:  Yeah.  And again, it looks like this Digital Economy Bill, which is slated to pass, will fix the problem in the U.K., which will be a good thing because - and I hope these people don't pay their $13,000 fine until that happens, or they get some good counsel.



And the last little bit of news on the reminding people not to click on links in email, especially if they appear to be IRS refund letter notices...



LEO:  You've got money.



STEVE:  Which I guess is attracting a lot of people.  There's the so-called ZeuS Zbot trojan is now spreading very successfully, unfortunately, by so-called drive-by downloads.  Email spam pretending to be an IRS refund letter is downloading the trojan if recipients click on the link in the email, without any additional user interaction.  So they're leveraging some known vulnerabilities in whatever platform, presumably Outlook, that uses the IE viewer in order to download these things.  So it's always worth reminding people, no matter how good you've been in the past, you must still be good in the future because these things, these problems are not going away.  And the IRS, actually this is enough of a problem that the IRS has issued a formal statement on their own site saying we don't send email like that.  So don't blame us.  Don't click on the links.  Just delete these things.



LEO:  Yeah.  Wow.



STEVE:  I just wanted to mention in the Windows versus Mac never-ending...



LEO:  War.



STEVE:  ...debate, war, that I've been using a MacBook Pro for about the last month for many hours in the morning because I've been doing a bunch of PDP-8 programming.



LEO:  Really.  On a MacBook Pro?



STEVE:  Well, because - yes, because that's where this really nice PDP-8 emulator is available.  And so...



LEO:  Ah.  Not on Windows.



STEVE:  There are some, but not nearly as nice.



LEO:  Interesting, huh.



STEVE:  And so as a consequence of this strange sort of drag-me-along-kicking-and-screaming out of Windows over to the Mac, I've been using the Mac a lot, really for the first time in my life.  And I just wanted to acknowledge that it's pleasant.  I mean, there are things about it...



LEO:  What did you think, it was like oh, my god, it's going to be a nightmare?



STEVE:  No, well, I just thought it was kind of different and kind of Romper Room-y.



LEO:  It's not that different.  That's really the real message I think in this war is they're getting more alike all the time.



STEVE:  Yeah, except there are, for example, the fact that you can't grab any window edge, that you can only resize from the lower right corner.  It's like, okay, why?



LEO:  Right.



STEVE:  But I like the way their, what, user preferences is sort of like the equivalent of the Windows Control Panel.  I just like the way that's integrated.  The fact that the apps have, like, they all share the menu bar at the top rather than each app having its own menu bar, which is a big...



LEO:  You like that.  Because that's a big complaint people have.



STEVE:  As a Windows user, it's a little unnerving because I'm not used to that changing.  Once you get used to the idea that the window with focus changes that, then it's like, oh, okay, I get it.  I don't quite understand - I've always been wanting to ask you, Leo.  When I close something, like I'll close Firefox.  Well, so the Firefox logo over in the whatever that thing is you call, like - oh, the dock...



LEO:  The dock, yeah...



STEVE:  It's got a white dot next to it.



LEO:  It's still open.



STEVE:  Yeah.  Which makes me feel like, okay, it's not really gone.



LEO:  See, this bothers me about Windows.  Windows does something to me that seems a little odd, which is you don't explicitly close an app, it closes itself after the last window is closed.  And on the Macintosh there's a quit command for every - and by the way, one of the things that's great about the Macintosh is the uniformity of menus.  There's really a kind of a standard for how menus have worked.  And you can always say that on the menu there's the application's name.  At the very bottom of that menu will always be a quit command.  And it's always Control, or rather Command, Q.  So that's how you have to quit it.  Closing the last window does not quit an application as it does in Windows.  And that's confusing for Windows users, I understand.



STEVE:  And, okay.  So when I - yeah.  I mean, I'm confused.



LEO:  But it makes sense to me because the window is just - is not the application.  The window is just a display window.



STEVE:  So, okay.  So if other apps, if I were to open other applications that needed the RAM, is the one that...



LEO:  No, it's still running.



STEVE:  No kidding.  Okay.  Well, I mean [laughing].



LEO:  It always seemed odd to me that you could - I never felt like the application was closed out in Windows because I'd close the last window, and now it is, I guess it's closed out.  But I never explicitly said I'm done with this application.  The Mac makes you say explicitly, no, I'm done with the application.  Just because I closed the last window doesn't mean I'm not done.



STEVE:  Well, now, in Windows, unless you're talking about...



LEO:  There is an explicit close command, I understand, which is unaccountably Alt F4.



STEVE:  Oh, Alt F4, I'm there.  I'm there, baby.



LEO:  I think Command Q's a little more mnemonic.  But okay, Alt F4.  And you probably use Alt F4.  But Windows also will close an application when you close its last window.  And that's the behavior the Mac is not doing.



STEVE:  Okay.  But the way you're saying that, applications are windows in Windows.  That is...



LEO:  No, no, no.  You can have an application, you can have a TSR-style application that's running without a window.



STEVE:  Well, you can have...



LEO:  Sure, an index, things do that all the time.  There is indexing going on in the background.  There's always something going on there.



STEVE:  Well, services, for example, are applications that don't have windows.  And you can have an application present multiple top-level windows.  But normally a top-level window is an instance of an application.  So for example, if I launch Internet Explorer, and I look in the Task Manager, and I see IExplorer.exe, if I launch, if I start another copy of Internet Explorer, I get another instance of IExplorer.exe.  That is, it's actually multiple copies of the application are running.  So when I'm closing windows, I'm closing applications on a one-for-one basis in Windows.  Instead of thinking of in terms of, like, closing the last window closing the application.  Each one is actually an application.



LEO:  Is an instance, yeah.



STEVE:  Is an instance of an application.



LEO:  It's not that way on the Mac.



STEVE:  I get that now.



LEO:  An application is instantiated when you run it and remains instantiated until you explicitly close it.  The window is a view into the application, but it's not required for an application to be instantiated.



STEVE:  Right.  Interesting.  Now I get it.



LEO:  I didn't realize, to be honest, I did not realize that Windows was so closely tied, the instantiation was so closely tied to a view.



STEVE:  Right, I think you...



LEO:  So all the views on Windows, the applications always have a view.



STEVE:  Yes.  You can make an application have multiple windows.  But normally the top-level window is an application.  And if you have multiples of those open, you've got actually multiple copies of applications.



LEO:  Now, all of this gets a little moot with threading.  And that was the thing that Chrome did that was interesting was that each tab was an instantiation of the application.



STEVE:  So they could die separately.



LEO:  Right.



STEVE:  Right, or hang and get killed and so forth.



LEO:  Now, remember, you're a sophisticated user.  And so an operating system is designed not for you.  You understand what's going on under the hood.  To the person who don't know what's going on under the hood, all they know is...



STEVE:  They don't even ask these questions.



LEO:  Well, they do because you go, well, that is one - that's one very subtle problem that switchers have.  The more obvious problems is the buttons, the windows zooming, you know, growing a window and moving a window.  But that's a subtle one that kind of bugs people, I think, is that, well, wait a minute, on Windows I didn't close that application, I just closed a window.  And now the application is gone?  And I don't feel like, I'm like, are you sure it's gone?  I don't know.  There's no sign that it's there or not.



STEVE:  And I knew that it was around still because it would come back if I clicked on the icon, bing.  It's like, oh.  But I was thinking maybe it was like Apple was being clever and, like, leaving it in RAM; but preferentially, it's like other stuff came along and needed its memory since I had closed it technically.  And it was like just sort of being around quickly if I needed it.



LEO:  Well, I mean, some stuff's probably locked, but most of it's purgeable.  So, I mean, the memory manager is pretty sophisticated in OS X.  Remember that the heritage of the Macintosh, which just might go back to pre-OS X days, the memory management was godawful.  And you really had a hard time reclaiming memory, and there was all sorts of issues.  But they have a pretty good - they have a system very comparable to Windows now.



STEVE:  And when I think about it, like on the Finder icon, if you right-click on it, it says open another Finder window.  Now, the Explorer, the Windows Explorer is that way.  That is, there's one copy of Explorer running.  And then you could have, like, multiple views of your file system and your computer and so forth.  But that's sort of an exception.  Most of the other things in Windows, the so-called, the top-level window, like the browser window, multiple tabs will live within that one application.  But as you launch multiple apps, multiple instances, those are actually separate applications, separate application instances that start up and run.  So, yeah.



LEO:  To me the Mac way, I mean, I don't want to belabor this, makes more sense because it just reminds you that there are applications running without windows.  I have many applications running that don't have a - for instance, here's a little FriendFeed notifier that's running in the background.  It pops up a window when there's something new on FriendFeed.  But it doesn't have a window when there's, you know, it pops up a window and lets it go.  I mean, Windows has many applications like that, as well.



STEVE:  Sure.



LEO:  So I just think it's - I like to explicitly close an application because then I know it's closed.  But that, you know, this is minor.  And my real point, and the thing I tell people who want to engage in a war, is this is like human and chimp DNA.  There's 99.99 percent similarity between Macs and Windows.



STEVE:  Yeah.  I like the power.  Maybe it's just the comfort.  Maybe it's the familiarity.  To me Windows feels like more of a power user's experience.  But I have to say, and I'm noticing, and I'm looking around, I'm seeing more and more Macs.  I mean, like, Macs really seem to be coming on strong.  And, I mean, and why wouldn't they?  I mean, if you want to surf the web and do email and actually get work done and not be all obsessive about the OS itself, but just use a computer as a means of getting your work done rather than it being the end itself, then I could easily recommend the Mac.



LEO:  It's great for programmers because it comes with a very powerful programming environment.



STEVE:  In fact, yes, mine just updated Xcode.  There was a major...



LEO:  Xcode is amazing, yeah.



STEVE:  Yup.



LEO:  And then you get Ruby, you get Python, you get Perl all built in.  You know, comes with that.  So I think it's a lot of geeks who want a terminal window.  You know, they want the bash, UNIX bash shell.



STEVE:  Well, and the idea that it's got actual real UNIX underneath it...



LEO:  Exactly.



STEVE:  ...is a compelling feature for many people.



LEO:  But to each his own.  They're all running on Intel chips.  It's all, you know, it's all more similar than different, I guess maybe.



STEVE:  Yeah.  And but it's very pretty.  I like it.



LEO:  Yeah.



STEVE:  So I just wanted to say I've been using it for quite a while.  It took a while to get used to it.  You've got to customize it a little bit here and there.  I fixed the caps-lock so it's a control and overrode that because why is there a caps-lock, that's so...



LEO:  But by the way, it's easy to do in Windows.  You have to install...



STEVE:  You mean...



LEO:  I mean in the Mac.  You have to install a program on Windows to do that.



STEVE:  Yes.



LEO:  Oh, I hate that caps-lock key.  Hate it.



STEVE:  I had an interesting little quick fun Thanksgiving story that I wanted to share.  Literally on Thursday of Thanksgiving an email was written by someone named Mark Schoonover.  He said, "Happy Thanksgiving.  As luck would have it, I'm out with the in-laws, and they asked me if this clicking they are hearing with their drive is anything to worry about.  Well, it is.  I can't read everything from the drive.  I do own a copy of SpinRite, but it's at home, 365 miles away.  I was hoping there was a way for me to download a copy, but I don't know my transaction ID/serial number to my licensed copy of SpinRite.  Is it possible to look that information up?  Here is my billing information."  And then he gave his name and his street address and so forth.  And he says, "I know it's a holiday, but hopefully you're available."



And then I've noticed that in the little dialogue it said "Sent from my mobile device."  So Sue, who runs GRC's operations side - taxes, bookkeeping and so forth - happened to check in on Thursday since she, like the rest of us, operates from home so it's easy for her to.  She wrote back and said, "Hi, Mark.  How about an email address that you may have had when purchasing?  Nothing is coming up under the address you wrote from."  And he wrote back, "Well, it's possible I used...."  And then he gave a different address.  "That email address was before I used this personal email address.  Thanks for the quick response."



And then Sue wrote back, "Mark, your original receipt with download instructions has just been sent via email.  For your information, your transaction code in your email receipt is basically the keys to your account.  It will allow you to obtain replacement copies as well as edit your contact email should it need ever be changed.  Sincerely, GRC Sales Department."  And then his final reply was, "Thanks again for handling this during a major holiday.  Got to love a company with great customer support.  The great news is, SpinRite saved the day.  It managed to repair the problem in a single Level 2 pass.  I was able to get the system to restart, get the data off, then remove the drive from service.  I'm now in good graces with my mother-in-law.  Have a great Christmas."



So, yup, we have that system.  As long as you know your transaction ID, you can get it from our server anytime, wherever you happen to be.  And if you don't, we can typically find it for you and send it to you.  And then you can get it again.



LEO:  So once again, SpinRite saves Thanksgiving.  That's a nice story.  And, yeah, I think there are probably more than a few people who went home for the holidays who were called to duty.  How was your Thanksgiving?



STEVE:  It was great.  I just had a quiet meal with some friends.  And it was uneventful, which is, you know, kind of what you want.  Just good food and great conversation.



LEO:  That's the best kind, absolutely.  Hey, let's get to our story of the week.  We're going to talk about - I don't even know what it means, even after you described it.  We're going to talk about same origin problems.  All right, Steve.  I've got my propeller hat, my virtual propeller hat on.



STEVE:  So we've never discussed this issue of what's called "same origin policy."  Wikipedia defines it very succinctly. They say the same origin policy is an important security concept for a number of browser-side programming languages such as JavaScript.  The policy permits scripts running on pages originating from the same site to access each other's methods and properties with no specific restrictions, but prevents access to most methods and properties across pages on different sites.  And what that really means is different origins.  This notion of an origin, the origin we're talking about is essentially the web domain - Amazon.com, eBay, PayPal, whatever.  And the issue is the safe handling of content that's being served by sites.



And increasingly, I guess the term is "mashup," is like this notion of a given site that's now providing content from many different places at once.  So this is potentially dangerous, if it weren't for strict enforcement of the same origin policy, meaning that your browser is - it receives a web page from the main site that you're visiting.  And that web page then requests that other stuff be pulled in to finish out the page from other domains.  So the browser goes out and retrieves other stuff from maybe many different domains.



LEO:  Well, you see this all the time.  I mean, even now almost every page pulls ads from another domain; right?



STEVE:  Right, right.



LEO:  Is that an example of it?



STEVE:  That's a perfect example.  And what's critical is that the content, whatever it is, if it's a GIF, if it's a JPG, or a Shockwave Flash ad, I mean, we're seeing Shockwave Flash ads all the time.  And they can be very powerful.  They can be running - there is, you know, ActionScript is the scripting language in Shockwave Flash.  And there's a way for ActionScript to invoke JavaScript.  So you know how I feel about all this scripting going on.



But it's crucial that the various components that are coming from different origins not be able to touch each other, that is, that there be individual isolation.  Otherwise there's possibility for something malicious in one of these things sourced from one origin.  There would be the possibility for it reaching into and modifying content in a different origin.  So this is generally accepted practice.  Well, what this one security firm, Foreground Security, a couple weeks ago made a blog posting where they explained that Shockwave Flash's excess permissivity...



LEO:  [Laughing]



STEVE:  ...almost promiscuity, but not quite, the excess permissivity could be abused to essentially render any user-uploaded content dangerous.  So SC Magazine, the security magazine, ran the story:  "Researcher finds 'frighteningly bad' Adobe Flash flaw."  The Register said:  "Adobe Flash attack vector exploits insecure web design."  And then the subtitle was "User-supplied malware upload peril."  And even Computerworld said:  "Flash flaw puts most sites, users at risk, say researchers."  And the Computerworld story went on to say:  "Hackers can exploit a flaw in Adobe's Flash to compromise nearly every website that allows users to upload content, including Google's Gmail, then launch silent attacks on visitors to those sites....  Adobe did not dispute the researchers' claims, but said that web designers and administrators have a responsibility to craft their applications and sites to prevent such attacks."



And the CTO, the chief tech officer of Foreground Security was quoted in that story saying, "The magnitude of this is huge."  And these guys are based in Orlando, Florida.  He said, "Any site that allows user-uploadable content is vulnerable, and most are not configured to prevent this."



And then:  "He used the example of a company that lets users upload content to a message forum to explain the process."  He said, "'If the user forum lets people upload an image for their avatar, someone could upload a malicious Flash file that looks like an avatar image.  Anyone who then views that avatar would be vulnerable to attack."



And in their rebuttal, and this is like some back-and-forth going on, Adobe cited Microsoft's 10 Immutable Laws of Security, which Microsoft published back in 2000.  Law No. 4 pertains to this, and I love how succinct it is.  This is from Microsoft saying this.  "If you allow a bad guy to upload programs to your website, it's not your website anymore."



LEO:  Good point.



STEVE:  So, okay.  So what all this boils down to is, and it raises an important point that is really crucial, which is why I wanted to talk about it this week, and that is most sites which do display any content which was uploaded by users are not being safe, and serving that from a different origin domain.  That is, most applications, web form applications, online email, all of these things that we refer to as Web 2.0 stuff, which has really jazzed up the 'Net and is creating all of this interactivity, anytime a web server is, as part of its business, is accepting stuff from users, it is truly crucial and really unappreciated that it must then serve that back from an entirely different domain.  And most don't.



LEO:  Oh, okay.  That's interesting.



STEVE:  I mean, and it's critical.  Most don't.



LEO:  So the safeguard is in there because the domain is different.  Right?  It's kind of a name space issue; right?



STEVE:  It is a name, yes, it is exactly a name space issue.  And what this researcher was pointing out, on one hand, is something that Adobe says, well, we all know that.  We've always known that.  And it's like, but yes, but no one is taking - no one is paying attention to this.  And specifically, where Shockwave Flash is a little flaky, having looked at this, in my opinion, is that it is - where it's permissive is that you can get Shockwave Flash the plug-in to parse a file that doesn't have a .swf, a Shockwave Flash file extension.  You can stick a malicious Shockwave Flash content on the front of an image that ends with JPG or GIF.  And if you embed this in a web page, Shockwave Flash will run it, even though it doesn't have the right file extension.



Shockwave looks at the content, the beginning of the content.  And if it starts off as a valid Shockwave Flash file, it executes it.  And so that allows people to bypass upload restrictions.  For example, a site might say, oh, well, we're only going to allow uploads of JPG images.  Well, you can upload a Shockwave Flash object ending with a JPG extension.  And if the browser displays it, the Shockwave Flash plug-in can be invoked and run script where the webmaster never expected script to be run.  And so Adobe has said that they cannot make Shockwave Flash behave better.  That is, I mean, you could argue this is really broken, that it is this permissive.



The other thing that it ignores is the so-called "content-type" header.  A content-type header is, it tells the browser what type of content the object is.  So, for example, it'll say content-type:text/html, which tells the browser this is a text content of html.  And browsers are smart.  And if it the file doesn't end in html, the browser won't render it because the content it received and the content type don't match.  Similarly, you might have a zip file with the content-type application/zip, or application/gzip and so forth.



Anyway, again, Shockwave Flash ignores that.  And you could argue, wait a minute, I mean, it really should not ignore that.  So I would argue that Adobe has some responsibility in the degree to which Shockwave Flash can be abused.  They're now saying, because they've sort of been pushed up against the wall, well, we can't change it because it would break everything.



LEO:  Can I get a clarification?  You've been saying Shockwave Flash.  Do you mean Shockwave and Flash?  Or are you just using Shockwave Flash as a longer term for Flash?



STEVE:  I'm meaning Flash.  You're right.



LEO:  Flash, okay.



STEVE:  Yes, yes.



LEO:  I mean, I think it's technically Shockwave Flash.  But you mean Flash.



STEVE:  I just, yes, Flash content.



LEO:  Yeah, okay.



STEVE:  Yeah.  So one of the problems is that Flash is - and this was the focus of this posting that got everybody stirred up is that Flash is too permissive in allowing itself to run Flash files, even when they have a different extension, and even when they've got the wrong content header.  It's that which allows users, bad guys, to upload malicious content which will pass the upload filters and then could be served by the server.  So that's a problem.  



But the bigger problem - but this is sort of a subset or an exploit of a bigger problem, which is that if all user-provided content were being served from a completely different domain, and that's the way it should be, then even this wouldn't be a problem.  So Adobe is saying, wait a minute, this is really not our problem.  This is a problem that people have ignored the same origin issue.  They are serving user content, user-provided content, from the same origin as other stuff, the website's content.  And inherently that allows the user-provided content to interact with scripting that's provided by the site that the user is visiting.  And that's really dangerous.



So, I mean, I agree with everybody, the real lesson here is - and I'm hoping that webmasters are hearing this.  Because the problem is, it's not easy to fix.  I mean, we're talking about having to - talking about having to host all of the stuff that could come from the outside, blog postings, pictures, avatars, content, I mean, there's all of these sites now that are allowing users to upload things.  I mean, even Gmail, for example.



LEO:  And it's just kind of the way the web works.  I mean, you wouldn't want to turn that off.



STEVE:  Well, no.  And you can't.  I mean...



LEO:  Right.



STEVE:  You can't turn it off.  And the problem is getting to safety from here because, if it had always been done correctly, then we wouldn't have a problem.  But it hasn't mostly been done correctly.  There are some sites - and, you know, I scanned past them, and I meant to write them down so I could recite them.  But there are sites like professional sites, like Hotmail and Yahoo!, for example, I don't know that those are two, and I tried to track them down again, and I couldn't find the references.  Because in this research I ran across major sites that are aware of this, and they definitely serve anything coming from - anything that ever originated from other than their webmasters come from a completely different domain.  So they did it right.  The problem is, that requires every webmaster who's going to be hosting content with any of these state-of-the-art applications to have two domain names.



LEO:  Right.



STEVE:  And all of the overhead that goes along with it.  I mean, it's a big deal.  That's not a simple thing to ask someone to do.  It's certainly not simple to ask them to change it now.



LEO:  Well, you know, it's interesting.  You for years have served your images from one server and your text from another; haven't you?  Have you kind of done this?



STEVE:  Yes.  For a number of different reasons I've done that.  And I do have a number of different domains.



LEO:  Is that potentially the same problem?  I mean, I know it's your content, so obviously it's not.



STEVE:  Right.



LEO:  But it is mixed content.



STEVE:  Exactly, yes.  And so, for example - and traditionally, for example, I have had images.grc.com and then GRC.com.  Now, I've folded that back into GRC.com/images.  And so there were reasons I was doing it once upon a time.  Literally I was serving images from a physically different server, just for bandwidth reasons.  I realized that, wait, this is crazy for me to be serving images over my T1s, back when GRC used to be behind a pair of T1s.  And so Mark Thompson, for example, was for a while hosting images.grc.com just so I could use bandwidth where it made much more sense.  So there were a number of things I was doing.



But so there I was, splitting my content between multiple domains.  However, in that case it was a subdomain.  And apparently there are scripting ways to get around subdomain variations, so that that's not enough.  You can't just say user-suppliedcontent.mydomain.com versus mydomain.com.  You've got to have something like user-suppliedmydomain.com, that is, a fully different top-level domain, and have the content coming from there.  Otherwise you can get scripts to agree on subdomain sharing having a - being treated like the same origin.  And that's not safe.



And so this is big news for many webmasters who never appreciated the danger.  And in fact the guys that made a big deal about this were reticent to do so because they were able to demonstrate exploits of Flash on many popular sites.  And, I mean, they were saying, well, what do we do?  We really want to force Adobe to fix this.  And their focus really was on Flash.  Adobe has said we're not fixing nothin' because we can't change Flash or it'll make it more restrictive, because its permissivity is one of the - that is to say, it's lax security operation, which is really what it is.  It should have been much more standards based, in which case webmasters would have had to make sure that content headers were correct.  And many of these avenues for exploit of this same origin problem would have been cut off.  But those are wide open right now.



So, I mean, by my talking about it and shining additional light on it, I mean, again, this is a problem which is potentially big.  But it's, you know, we know the problems don't go away if you ignore them and if you hide them.  And maybe somehow Adobe could come up with a compromise where they do a version of Flash which can be asked to be more secure, and then webmasters can incrementally - webmasters who care and want to protect themselves could incrementally require that more secure Flash plug-in, which would then propagate over time, and they could protect their site using a Flash player that was able to be more restrictive, able to be asked to be more restrictive.  I mean, I don't know what the solution is.  But this is a problem.  And I recognize that it's potentially big.  And the problem is, it's not easy to fix.  It's...



LEO:  Well, let me put you on hold.  I mean, you must have some prescription, or something you'd like to see happen.



STEVE:  Okay.



LEO:  I hope you do.  I have some thoughts about it, too.



STEVE:  Okay.



LEO:  We're clearly not going to ever get rid of this multi-homed web page problem.  So clearly this is a problem.  And as I said at the beginning, it's a name space problem; isn't it?  It's the problem is that web browsers and JavaScript and other web languages kind of don't isolate their code very well.



STEVE:  Right.  Okay.  So to put it simply, and then we'll talk about solutions, there's a clear problem which is created when a page is composed of objects which could be smart, could be scripted, coming from different places.  Because traditionally, if scripting came from the same place, that is, different instances of scripting or different parts of scripting, they're inherently able to have visibility into each other.  They're able to...



LEO:  Yeah.  That's what I was getting at, yeah.



STEVE:  Yeah.  So because of the recognition of the problem, the wizards of the web, always understanding that this was a potential problem, created this notion of same origin, specifying that only content that was served by the same origin, the same web domain, could interact with each other.  Otherwise, stuff coming from somewhere else, from a different domain, would inherently be isolated.



So, I mean, that was an understood but dramatically underappreciated issue.  And the problem is that there's no enforcement.  Nobody makes content from users come from somewhere else.  And so the de facto, the default, is oh, well, I have mydomain.com, and I'm going to - and I have an SQL database.  And when stuff gets submitted to my site, it goes into my SQL database, which is a backend on my server, and then we want to - we're going to have a forum, and so we're going to want to show people what other people have posted.



LEO:  Right.



STEVE:  And so it's, I mean, it's sort of the natural thing to do.



LEO:  And the presumption is, and this is the mistake, right, if it comes from me it's safe.  If it comes from my domain it's safe, even though I know it doesn't come from me.



STEVE:  Correct.  And so then we say - so the webmaster says, oh, but I don't want people who might be bad people to submit scripts because then the scripts would go into my database.  And then when people viewed a page containing scripts that had been submitted by maybe a bad guy, those scripts coming from my database, through my domain, my server, would have equal access to everything else on the site.  And that's really bad.



LEO:  Right.



STEVE:  So the webmaster who's trying to do the right thing says therefore I'm only going to allow - I'm a photo sharing site, and I'm only going to allow JPG uploads, or GIF uploads.  The problem is that due to the funky way that Flash works, it doesn't care if its script is named .JPG or .GIF.  It runs anyway.  And so this sort of creates a backdoor that allows scripting to run even though it's identified as an image.  And that's really bad.



LEO:  Yeah.



STEVE:  So that's a problem.  But the bigger problem, the more generic problem is that, as Microsoft's Law No. 4 of Internet security says, if you allow a bad guy to upload programs to your website, it's not your website anymore.  Which is their way of saying you really need containment.  You really should be sure that inbound content from users goes to a database which is on a different domain.  And, I mean, it's a pain in the butt to do that because you have to now have main domain and other domain and make all the links work and make everything work.  And then...



LEO:  But would that solve it?



STEVE:  That really does solve it, yes, because then all of that content comes from a different origin.  And the browser will then enforce this different origin and enforce containment.  And then malicious scripting that could have snuck in through some other means won't have access to the main domain's scripting.  I mean, you still have the problem that it's scripting that's running on the user's browser.  But it's toned down at least some.



LEO:  It's a little ironic because even Google doesn't do this.  And certainly they would have the technology to.  Is it difficult to do?  I mean...



STEVE:  Yeah.  Well, it's not difficult if you did it from day one.



LEO:  Yeah.  Retroactively it's hard to do.



STEVE:  Oh, retroactively it would just be a huge nightmare.  I mean, all the links in all your pages that refer to content and, I mean, yes, everything would have to get changed around.  And then you have other sort of little side effects, like browsers might be saying, wait a minute, we don't want cookies.  I mean, suddenly now that provided content is a third party.  So now you have cookie access problems because you're not - because one of the things that you're wanting to restrict is you're wanting to keep bad scripting from having access to the user's session cookies because we now know that session cookies are used for creating persistent log-ons.



And so you definitely want the bad scripts, you want to keep them from having access to that.  So you want them to be in a separate domain.  So that's an example of what maliciously can be done if you're in the same origin.  If you're in the same origin, you've got access to the user's cookies.  And all kinds of mischief can be made that way.  So it would be nice if, in the case of Flash, it were much less permissive.



LEO:  Right.



STEVE:  I can understand them saying we can't change it now.  Unfortunately it's too late.  It would break too many things.  Maybe some pressure can be brought on them to allow this to get fixed incrementally for webmasters who are willing to tweak their sites as necessary to run the Flash in a more tighter, less permissive way.  But the thing I mostly wanted to shine a light on is this whole notion of same origin.  Because we've never talked about it.  I mean, which also sort of demonstrates how obscure it is, the fact that we've gone to Episode 225, and this is a big deal that hasn't really come on the radar until now.



LEO:  Well, it came up because of Flash, but it's more than just Flash.  It's been a problem in JavaScript.  In fact, I'm sure John Graham-Cumming refers to this, you know, this name space issue.  JavaScript can be confused - I think we even talked about it - or tricked by using common variable names.



STEVE:  Yes.  It is one of the things - and this is where we were talking about it was with John a few weeks ago.  And that is the way Adobe defended themselves.



LEO:  It's not just us.  You're all screwed up.



STEVE:  Well, and saying that this is a well-known problem, and websites shouldn't be doing this.  And in fact Howard Schultz, who's an editor for SANS, in the SANS newsletter they talked about this, and Howard was the chief security guy at eBay for many years.  He was quoted in an editorial that SANS ran saying who is this Brad Arkin - Brad Arkin was the spokesman at Adobe.  He said, "Who is this Brad Arkin kidding?  Saying that 'sites should not allow user uploads to a trusted domain' is completely unrealistic."  And so that's Adobe saying, yeah, sites shouldn't do that.  It's like, well, okay, but they all do.  And so basically Adobe is saying, it's not our fault.



LEO:  Even YouTube does it.  I mean, everybody does it.



STEVE:  Yup.



LEO:  So you're saying if YouTube had a separate server that was FlashYouTube.com, and all the Flash came from there, and all the other content came from YouTube.com, that would - it wouldn't solve the problem, but it would mitigate it a little bit.



STEVE:  It's not even clear that using a subdomain solves it.



LEO:  No, no, yeah.  It would have to be completely, like, FlashYouTube.



STEVE:  FlashTube.com would be where the actual Flash objects lived, within the YouTube domain.  So people would go to YouTube.  But the things they looked at would be coming from FlashTube.com.  And there the completely different domain name would, in the browser, would keep them from ever having any interaction.  And today we don't really have that.  I mean, it's all possible.  The really high-end professional sites understand this, and they do it.  But most sites don't.  And I'll bet you we'll be doing a podcast here before long, talking about some bad consequence of this.



LEO:  Right.  And is there anything that the end user can do?  I mean, can you - are there any settings you can set in your browser that make it - I guess not because it can't tell.  It all comes from the same place.



STEVE:  There were, among all of this skirmish, people saying, well...



LEO:  The browser should solve it.



STEVE:  You could turn off Flash.  It's like, oh, well, thanks a lot.  Yeah, I mean, talk about dead websites.  And in fact there's a toggle Flash add-on for IE, and NoScript offers Flash suppression.  Or, like, Flash on demand, where it just shows you sort of an F, and then you click on it if  you want to run it.  So that's something I've seen NoScript doing.  But again, we've become so dependent upon Flash for so much.  And again, it happens to be one too readily exploitable vector of this problem.  But it's not really the problem.  The real problem is that, as Brad Arkin at Adobe unrealistically suggests, sites should not allow user uploads to a trusted domain.  Well, it's like, well, okay, good luck with that.  Sites are going to.



LEO:  You know, somebody's pointing out in the chatroom, and I was just playing with YouTube a little bit, YouTube does do some of that.  They have a server called YTimg.com, where thumbnails come from, anyway.  I don't know if the Flash comes from there or not.  That's very clever.  So maybe they are doing something like that.



STEVE:  Really, I mean, I wouldn't be at all surprised if sites that are really on their game, I mean, where there's a lot at stake, they've said, okay, well, their webmasters really understand.  And here's the problem is that so many sites these days are canned.  You buy some blogging app or some foreign app, and you just stick it in.  And you run it on yourdomain.com, and there's no concept of this whole same origin policy issue.  It just isn't there.  Someday this problem will get solved, like so many other ones we talk about.



LEO:  And blocking Flash alone, although I do that, there's a Flashblock script, and there's a Safari plug-in which I use called ClickToFlash.  So I do that.  But I do it more because I don't want Flash animations to start playing while we're doing the show when I go to a site.



STEVE:  Yeah.



LEO:  But there are ways to do that.  But that's not enough because it's just - that's just Flash, and now the same problem occurs with JavaScript and other...



STEVE:  Well, and I use a very nice add-on for Firefox, Adblock Plus.



LEO:  Right.  That's very extensive, yeah.



STEVE:  Oh, my goodness, it's so nice.  You just don't have fish jumping around your page when you go somewhere.  Or just really annoying things flashing at you and trying to get your attention.  It just quiets all that down.  So that also would protect you in a nice way.



LEO:  Right.  Steve, I'm glad we did talk about this.  It's funny that this has been around forever, but this is the first time we've talked about it.  Same origin problems.  Steve Gibson is at GRC.com.  Now, that's his website.  You can go there to find this podcast, of course, both 16 and 64KB versions, depending on your bandwidth capabilities.  There's also transcription so you can read along as you listen, and show notes, too.  It's all at GRC.com.



We have a feedback episode next week.  So if you want to leave a question about this or any other security topic, go to GRC.com/feedback.  And while you're there just pick up a copy of SpinRite.  You never know when you'll need some hard drive recovery or maintenance.  GRC.com.  Steve, I can't wait to talk to you next week.



STEVE:  Thanks, Leo.  We'll do it in seven days.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#226

DATE:		December 10, 2009

TITLE:		Listener Feedback #81

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-226.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 226 for December 10, 2009:  Listener Feedback #81.



It's time for Security Now!, the show that covers your privacy and security online with the guru of privacy and security, our very own Steve Gibson.  Steve, it's great to see you once again, from GRC.com.



STEVE GIBSON:  Glad to be with you, Leo.  We've got a Q&A episode, our 81st one, with some security news, a little bit of errata.  I have an interesting SpinRite story from the future.  This has been sent back from the future.  So I thought that was, you know, a fun thing to share.  And we've got our Q&A.



LEO:  I love that idea.  What do you want to start with, errata or news?  News, I guess, huh?



STEVE:  News, yeah.  This is just the podcast following the standard second Tuesday of the month.  So Microsoft has, on cue, released a batch of updates.  There were 11 things that they fixed.  None of them are particularly notable, so I'm not going to go into any great detail.  The good news is that they did fix, as we were projecting and hoping they would, that bad zero-day vulnerability in Internet Explorer, which we discussed at length, it was either last week or the week before.  And I remember saying at the time I hope that they would have time to fix this because it was being actively exploited on the 'Net.  There was plenty of documentation about how to do it, and people were getting hurt by it.  So that was fixed.  So I just wanted to mention that we had passed through another second Tuesday of the month, and to encourage people to keep themselves up to date, as always.



LEO:  Do they put out, like you can look up Patch Tuesday and what was patched for this Patch Tuesday?



STEVE:  Yes.  They have a page essentially for December '09.  All of them had, except one, actually, there was an ATL COMM vulnerability that wasn't high exploitability.  Because remember they now associate each of these with an exploitability index, which is, you know, yes, there's a problem.  And Microsoft rates how likely they think it is to actually be exploited.  And it's like, okay, well, fine.  So these were all definitely things you want to get patch because Microsoft was saying, yeah, there's probably going to be exploits created from these.



LEO:  There's quite a few.  But not a huge one like last month.



STEVE:  Yes, not a record-breaking one.  So that's good.  There's an interesting trend that has just recently surfaced which is really good, which is voting systems are beginning to swing open, to open source rather than closed.



LEO:  Yay.



STEVE:  Yes.  That's just such good news.  There's an Open Source Digital Voting Foundation, the OSDV, that has an eight-year timeline, or like a roadmap, during which they're going to produce a comprehensive, publicly owned, open source, complete electronic voting system from registration all the way through election management and vote tallying.  They've got a good team that are putting this thing together.  They've released - the event was that they released sort of a preliminary blob of code to say, you know, here's a sample of what we're going to be doing.  And then what was really interesting was that just five days after that, one of the most notoriously problematic closed source companies, that is, Sequoia, that's had all kinds of problems with its voting systems, they announced that they were going to go open source, and that by...



LEO:  Wow.  That's fantastic.



STEVE:  Yes.  Which is really good news.



LEO:  Now, why is open source - you should maybe say briefly why that's a good thing.



STEVE:  Well, for something like this, I don't think - I'm not - I don't necessarily believe that having something open source instantly means that it's going to be safer.  But open source which is actively scrutinized is arguably dramatically safer.



LEO:  At least you know what's going on.



STEVE:  And that's the key.  So the fact that something is open source, if it's open and no one ever looks at it, well, it doesn't help you any.  But if, in being open, it allows, and experts do take advantage of the fact that it's open, then you're in good shape.  Now, Sequoia, for example, they threatened to sue [Ed] Felten and his friends at Princeton if, in response to a court order where Princeton was asked to analyze these machines, if they did so, then Sequoia said we're going to sue you.  So, I mean, you could argue...



LEO:  Oh.  Oh.  That's exactly the opposite of open.



STEVE:  Yeah.



LEO:  That's like, don't touch our stuff.



STEVE:  You could argue that, like, they're like the poster child of the wrong way to do this.



LEO:  Right.  Hiding it.



STEVE:  Saying that everything is proprietary, and it's all closed, and just trust us.  Yet when the results of their machinery have been looked at closely, there have been discrepancies found.  And they've said, oh, it must have been a static discharge.



LEO:  [Laughing]  I'm sorry.



STEVE:  No, I'm not kidding.



LEO:  I can't - I'm sorry.



STEVE:  You know, like vote tallies didn't tally.  Oh, well, it's an operator error or a static discharge.  And it's like, okay, well, how are we supposed to trust these people?  So, I mean...



LEO:  I think you're supposed to wear wrist bracelets when you vote.



STEVE:  So it's really, really good that, first of all, that there is this Open Source Digital Voting Foundation.  The idea will be that they'll produce an open source system.  Because it exists, and many people care, lots of smart people will study the source and say, hey, as far as I can tell, they've done, like, all my hot buttons have been, like, taken care of here.  Now, it's certainly the case that something can still be missed.  But it's much better to have many eyeballs looking at it than not.  So Sequoia doing this demonstrates another step forward.  And in the case of OSDV, this Open Source Digital Voting Foundation, they're going to freely license the result of this project to machine makers and others who have some application for it.



And I'm sure the license will include some things, some constraints on, look, we're giving this to you for you to use, but you can't just go screwing around with it.  You've got to use it as is.  And if you make changes, then there'll have to be some sort of review process, blah blah blah.  But the idea being that the value added will no longer be this intellectual property which is so prone to mistakes.  Instead, the value added - and there's still things that people, you know, that companies can do to add value - will be in the packaging and the production and the deployment and all the bells and whistles which will allow them to have product differentiation.  It just won't be that there will be any value, that is, any commercial value in secret intellectual property.  In fact, you could argue, as more companies take this approach, those that are trying to maintain closed systems will then...



LEO:  Will have less value.



STEVE:  They'll end up having a hard time convincing anyone to buy their stuff.



LEO:  Well, let's hope so, anyway.  Yeah.



STEVE:  So, but really, really a good news.



LEO:  Yeah, yeah, yeah.



STEVE:  Now, on the bad news front...



LEO:  Uh-oh.



STEVE:  For our listeners in the U.K., and we know we have many, ZDNet UK reported the news that the major ISP Virgin Media is about - has announced formally that they are about to employ deep packet inspection to anonymously scan their customers' data, everything going to and from their customers, without their consent.  They're...



LEO:  Well, at least they're telling them that.



STEVE:  Well, yeah.  Well, they're telling the world.  The world's not happy, as you can imagine.  What they're saying is that they're wanting to assess anonymously how much illegal copyrighted filesharing is transiting their system.  So they're using deep packet inspection to look at the data transactions to their customers.  The top level is they check to see whether the protocol is any of the known notorious filesharing protocols.  And if so, then they will go deeper into the packets and look to see whether that flow is apparently copyrighted data.



Now, they're saying that all of this is done anonymously, that the equipment that's been installed and they're getting ready to turn on, it strips the IP address of the customer out of the packet.  They're not attempting and intending at this point to do anything more than just get some sense for how much of this is going on.  So to me this feels like the beginning of something worse.  But we'll have to see.  And, you know, apparently their public acknowledgement of this is not the sort of thing that they think is really going to be great PR for them; but they must have felt that it was worth doing it and that they certainly could not do it secretly because it would come out, as these things always do, and then they would look really bad for having done it in secret.  So anyway, a little bit troubling, but...



LEO:  I'm glad that they at least had the sense to publish it.  But you're right, I mean, that's not - it's better than nothing.  Hey, by the way, I notice you're wearing the hacker shirt.  I don't know, I have a NO cup now.  So...



STEVE:  So it just says N-O, period?



LEO:  Yeah, look.  See?  Can you see it?  That's right, it just says N-O, period.  It's from the same people, ThinkGeek.  Actually a couple of guys from the Argonne National Labs in Illinois came by, Tom and Steve, and they brought me this NO mug.  Obviously Security Now! listeners.  Thank you, Tom and Steve.  Now Steve and I both say NO.



STEVE:  No.



LEO:  No.  No.



STEVE:  No.  I ran across an interesting page that showed - this is in our errata topic - that showed the current demographic breakdown of web clients on the 'Net by operating system.  So not the traditional IE versus Firefox, but what percentage of Windows XP is on the 'Net?  And what I found interesting was that today XP has 84 percent...



LEO:  What?



STEVE:  I'm sorry, no, sorry, 64 percent of the OS.  Vista is at 23.  Mac is at 5.12; Windows 7 at 3.77; Linux at 1 percent; Windows 2000, still out there, 0.62 percent.  And the iPhone is 0.54 percent, with miscellaneous others at 1 percent.  So summing up the various Windows - XP, Vista, Windows 7 and Windows 2000 - Windows, any Windows, is at 91.26 percent, with Mac at 5, and then Linux at 1.



LEO:  Wow.



STEVE:  So still very skewed toward Windows.  And but those numbers are certainly - Windows numbers are falling.  Mac is rising.  Linux is rising.  But they certainly have a ways to go.



LEO:  There's some problems, as you can imagine, with the particular methodology and how the browsers identify themselves.  But I think in general that's the correct proportion.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  And an interesting report that was sent back from the future by Jake and Phillip, who need to remain anonymous, they explain, because they're with a time correction team.  The subject of the email that caught my eye was "SpinRite Saves the Future."  And they write, "Dear Steve.  My team and I would like to express our heartfelt appreciation for SpinRite, your fine, lifesaving product.  We've all become tremendous fans of SpinRite 12."  Of course I'm only at...



LEO:  12?  Wait a minute.  You're up to 6.



STEVE:  Yeah, I'm at SpinRite 6.  So, and given...



LEO:  Oh, these people are calling from Alduran, okay.  I understand.



STEVE:  Well, essentially yes.  Given the fact that I release major version updates very infrequently...



LEO:  12 is going to be...



STEVE:  12 is out there a ways, yeah.  So they continue, "Your software saved our lives.  Here's what happened.  My team was sent on a mission to prevent some unfortunate results of the bad science presented in the movie '2012.'" 



LEO:  Oh, boy [laughing].



STEVE:  "While traveling too close to the sun, an unexpected solar flare" - and I was thinking, okay, are there any expected solar flares?  But, you know, I guess if you're a time traveler...



LEO:  You know, yeah, sure.



STEVE:  Yeah, exactly.  So one caught them by surprise.  "An unexpected solar flare hit our craft, resulting in a near complete loss of data from every system onboard.  This caused our reentry into the earth's atmosphere to be very far off course.  At this time I would like to apologize to the people of Utah.  I cannot imagine the fright our reentry must have given everyone there.  Please accept our sincere apology.  Anyway, once we landed, if you may call it that, we set about restoring our data.  We popped in SpinRite v12, and in a mere three days' time all of the data from our craft was back, exactly as it had been prior to the above-mentioned unpleasantness."  Now, this does give me pause, Leo, to think that maybe spinning magnetic hard drives are not as short-lived as I was concerned.



LEO:  They might survive.



STEVE:  Yeah.  Apparently...



LEO:  Or...



STEVE:  ...SSDs didn't take over the future.



LEO:  You'll invent some way to save SSDs.



STEVE:  Ah, but he doesn't specify what kind of technology SpinRite v12 has recovered.  So he says, "You really saved our pork product (bacon, as they say in your time).  Steve, you really are a magician.  And although we really shouldn't tell you this, CryptoLink v3 is going to rock the world."



LEO:  I love it.



STEVE:  "Please keep up your good work.  Sincerely, Time Correction Team XVI."



LEO:  I love it.  Somebody reads a little too much science fiction.



STEVE:  They have to read a lot to keep up with me, so.



LEO:  I'm reading the new Jerry - not new, the new recording of Jerry Pournelle's "Mote in God's Eye," which Audible just released.



STEVE:  Oh, one of my favorite, all-time favorite books.



LEO:  I love the genre, first contact genre.  You know what, I hadn't - I have never read this one before, which is funny.



STEVE:  What, you've never read "The Mote"?



LEO:  No.  Isn't that weird?  No.



STEVE:  Oh, Leo, it's got a surprise.  It's such a good surprise.



LEO:  Well, I love Larry Niven, so...



STEVE:  Yes.  And when Niven and Pournelle get together, it's great.  That's the only problem with that book is that you don't know something which you will never forget once you learn it.



LEO:  Oh, I love it.



STEVE:  And it makes it a little more difficult to reread it.  And I'm a big book re-reader.  So...



LEO:  Oh, well, I'm lucky, then.  I've never read it.  So I'm, like, I'm in heaven here.



STEVE:  Go slow.  Don't read it overnight because then you'll be like, aw, it's over.



LEO:  Well, that's nice about Audible.  No, that's what's nice about Audible.  You really kind of can relish it.  But you know what, Jerry told me when he was on TWiT a couple of weeks ago that the way they work together is Jerry is the plotter.  He said, you know, I'm better at plotting than Larry is; and Larry's better at writing than I am.  So Jerry does the plotting, and Niven does the writing, for the most part.



STEVE:  And fills in all of the plot specifics.



LEO:  Right.



STEVE:  Interesting.



LEO:  And so you can credit Jerry Pournelle with the twist.



STEVE:  Yeah, good point.  Very good point.



LEO:  Oh, now I'm excited.  Oh, now I'm very excited.  I can't, I cannot wait.  Anyway...



STEVE:  Wait till you learn the secret.



LEO:  No, don't, no, okay, don't spoil it.



STEVE:  No, no, I'm not saying anything.



LEO:  But one of the things I really like about it, I was a big fan, still am a big fan of the Patrick O'Brian 19th-century seafaring novels.  And what's funny is the future, in the future, and this takes place I think in the year 3000, the Navy, the Spacers are like the Navy.  It's exactly the same kind of thing.  They have stewards who bring coffee, I mean, it's just like they're at sea.  And obviously there was an intentional parallel done by Larry and Jerry.  And I think it just really, it works so well.  It's really, really great.  So anyway, I just - I don't know why I mentioned that, but I'm reading that right now.



Hey, we're going to get to our questions.  We've got some great ones for you, including at the very end, of course, we save the good stuff, the Brilliant Disneyland Authentication Solution of the Week.  I've been hearing from a lot of Disneyland folks about this system, by the way.



STEVE:  Yep, I have, too.  There was a surprising number of Disney notes in the last mailbag, so...



LEO:  Yeah, lot of Disney folks listen to us.  All right,  Steve, are you ready for a question or two?



STEVE:  Ready, yeah.



LEO:  Ready, Eddie.  Question one from Chris in Las Vegas, Nevada.  He's thinking about ARP.  Steve, Windows throws an error when it receives an ARP response for the same - okay.  Here we go.  Get ready.  Buckle in.  Windows throws an error when it receives an ARP response from an IP address it's trying to use itself, saying another device has the same IP on the LAN.  We've all seen this.  If you use static IP addresses, for instance, it'll say, well, there's another device on the LAN with the same IP address.  So wouldn't it be trivial to have the stack throw an error if it received multiple responses for the same IP address from different MAC addresses?  We're trying to avoid ARP spoofing here.  It could also just be a small program running that watches for such anomalies and notifies the user.  Shouldn't, you know, it should always be, if it's one IP address, the same MAC address.  The only real downside I can see is in cases of sites using something like link aggregation or something, or bonding.  In that case you might get a false positive.  What do you think?  That's an interesting idea.



STEVE:  Well, it's a great idea.  And I think I mentioned a couple weeks ago that one of the things I was going to toss into CryptoLink, because it's so easy to do, exactly as Chris says, is just watch the LAN traffic for anything suspicious.  And so, for example, another example of something suspicious would be if an IP-to-MAC address mapping appears to change.  Now, that would happen if you deliberately manually changed the IP address on some machine on your network.  But that's normally not happening.  So but it would be an indication of someone coming in and beginning to spoof ARP traffic and mess up the IP-to-MAC address mapping.



So Chris is completely right.  It would be a - it's a trivial thing to do, a simple little program.  You know, it's not, for example, in Windows, mostly because people wouldn't know what to do with it.  The idea of an IP address collision had to be in Windows.  And as you say, Leo, we've all seen this.  It's in Windows and Mac and Linux and, you know, UNIX, all the OSes, where they detect more than - they detect some other device that is responding to a MAC address query for the same IP that they have.  And it's like, wait a minute.  And again, it's all these OSes detect it and alert the user because you cannot have, just by definition, two devices with the same IP address on the same LAN.  That would just cause confusion.



Technically, electrically, it's possible.  But we've decided, well, we're not going to - we're going to disallow that because who's supposed to be the recipient of the traffic?  So in typical sort of Microsoft approach, how would you present a warning to the user saying, oh, we believe that ARP spoofing may be occurring on your network?  It's like, okay, well, you're never going to see a note like that from Microsoft.  So it makes sense for it to be an add-on utility or something that an expert user would know how to interpret.  And another example would be if this utility were to remember the MAC address of the gateway persistently.  That is, like, make a little entry in the registry and then notify you if at any time in the future the MAC address for the gateway appears to change because that's classic man-in-the-middle ARP spoofing where somebody else spoofs the gateway ARP response in order to get themselves knitted in the middle.  Well, I mean, I'd love to know if without me doing anything the MAC address for my gateway changes because there's absolutely no reason it ever should.  Or if I get the notice after just having reconfigured my network, I go, oh, yeah, of course.



LEO:  Right, right.



STEVE:  I just made a change.  I'm expecting that.  But so Chris is absolutely right.  We will see that in CryptoLink.  Maybe I'll spin out a little freebie that does that just while I'm at it because it would be simple to do and makes a lot of sense.



LEO:  And some routers, I'm being told by people in our chatroom, do this and that kind of thing, and they warn about that kind of thing.  So it's, yeah, that's...



STEVE:  I've never seen that.



LEO:  Moss Wahlberg [sp] is saying Cisco and HP switches have built-in ARP spoofing protection.  I don't know if they use that technique for it.



STEVE:  Okay, yeah.  That would be a different approach where they would be resistant, for example.  One of the games that people have played historically is it used to be that, in the old trusting days of the Internet, a switch or router or anything actually building an ARP table that maps IPs to MAC addresses, they would simply accept as the truth any ARP response that they saw on the wire.  ARP traffic is broadcasted, and network interface cards see all the traffic, even if they don't accept it all in the case that they're on, for example, on a hub, as we used to use in the old days.  And so it's possible for a third party on the network to see other devices getting themselves registered on the 'Net using ARP and just say, oh, I might as well add that information to my own local ARP table.  In case I ever need to talk to any of those guys, I already know their MAC address.  So I don't have to go ask them, go through the whole ARP protocol broadcast and response to get that.  In other words, they used to just accept all the traffic on the network and store it.  Well, that's absolutely wide open for exploitation because it means that spoofing is trivial.



LEO:  Right.



STEVE:  All you do is you just send out malicious ARP packets, and everybody on the network will accept them as gospel.  And so one of the things - so there are many things you can do.  For example, you would never accept an ARP reply unless you were expecting one.  That is, only when you had a pending request out and were expecting a reply would you take it.  And in any kind of a race condition you could do things, like if you got two different replies you could say I think I'm going to stay with who I believe from the previous response rather than some newcomer that's different.  So you could certainly see plenty of strategies for putting filters up and preventing this kind of stuff from being just so wide open.



LEO:  Right.  Question 2, Peter Jaros from Brooklyn, New York.  He has a new approach to defeating whole disk encryption and other in-memory-key schemes.  We talked a little bit about that.  Never unplug the machine.  Steal the computer without ever turning off the power or letting machine go to sleep.  How would you do that?  He actually gives us a link to WiebeTech.com.  And I guess it's - I'm guessing it's some sort of battery backup.  Yeah, it says transport a live computer without shutting it down.  No other product performs this patent-pending feat.  It's a hotplug device, obviously just a battery, big old battery you plug the computer into and then take it with you.  And by the way, it says right here, "How to circumvent whole disk encryption."



STEVE:  Okay.  So it actually is more clever than that.



LEO:  Oh, really.



STEVE:  It's very cool.



LEO:  WiebeTech, if you want to see this, dot com.



STEVE:  Okay.  So the computer's plugged in.  Okay, well, so you can't ever power it down.  Yet it's receiving power now.  So this clever thing is able to run in parallel with existing power.



LEO:  Oh, it would have to be, yeah.  So this would be for, like, law enforcement.  They come into your house.



STEVE:  Precisely.



LEO:  They think something's going on in your computer.  It's running, and you logged in, so whole disk encryption is now - everything's unlocked.  But they obviously can't reboot or they'll never get into it.  So somehow they have to keep it exactly powered up and take it back to the station.



STEVE:  They also need to keep the screensaver from activating.



LEO:  Oh, boy.



STEVE:  Or the machine going into standby.  So they have a little USB dongle called the Mouse [Jiggler].  And it says it just generates little mouse move messages.



LEO:  I love it.



STEVE:  So they plug this thing into a USB port, and the mouse starts jiggling around on the screen.  Now, the reason that it caught my eye is that I was asked, oh, a couple years ago to be part of an advisory panel for an FBI effort to build a lab on the West Coast.  They wanted to do a big forensics lab, and they wanted it to have all the stuff it needed.  And in some of the meetings that I attended they were explaining, here are the problems that we have.  And one of the problems that, I mean, they really do have is they get a warrant for some company's hardware that - computers that they believe there's bad stuff on.  And if the people, if they've turned the computers off, and there's active encryption on the system, they can't get back in.  And so this is like, this is really a problem that they have.  So this gadget, not only does it have the little USB mouse wiggler, but it's like a UPS.  But it's one where the power comes out of the AC outlet.  So they give two examples.  One is where they say, well, many computers are plugged into an outlet strip.



LEO:  Right.



STEVE:  So you plug this backup power supply, with a male plug, you plug it into the power strip along with the computer.



LEO:  So this is kind of a feature of power strip.  It's all, I guess it's in serial, and you can just apply power to any plug socket.



STEVE:  Sure.  All the power strip connectors are just in parallel.  So you plug it into the power strip.



LEO:  Parallel, okay.



STEVE:  You plug it into the power strip.  Then you unplug the power strip from the wall.



LEO:  Right, because it's now getting power.



STEVE:  It is now, exactly.  So the power's feeding into one connector of the power strip...



LEO:  That's clever.



STEVE:  ...and out to the computer.  Or, if the computer's plugged directly into the wall, and on their site they show a little picture of this, if there's anything else plugged, you know, all wall outlets have, like, two plugs.  So you unplug the lamp or whatever is plugged in there with it.  You plug their box into the other dual outlet, then unscrew it, pull it out, and snip the wires.



LEO:  Wow.



STEVE:  So now you've got their backup unit running, just routed through this little two-outlet plug back to the computer.



LEO:  They call this their "outlet seizure" method.

 

STEVE:  [Laughter]  And I just think it's very clever.  They've got the mouse wiggler to keep the machine alive.  And so...



LEO:  You should have to have a license to buy this stuff.  I mean, really.



STEVE:  Yeah, well, I mean, it's diabolical.  And it would prevent you from - basically they don't know, if the computer shuts down, that they're going to lose all access to it.  But they do know that it's alive and running right now.



LEO:  Yeah, why take a chance?  I can see this stuff now, so let's snag it.



STEVE:  Yup.  I wouldn't be at all surprised if there's a large order from the FBI coming their way.



LEO:  Oh, yeah.



STEVE:  I do know that the FBI, from our conversations, I mean, this is a problem that they've got.



LEO:  That they have to solve.



STEVE:  And this would solve it.



LEO:  Yeah.



STEVE:  I just thought it was very clever.  I knew our listeners would get a kick out of it.



LEO:  Oh, I love it.  WiebeTech.  Yeah, WiebeTech.  They have videos demonstrating the whole thing on the site.  I was just looking at them.  Pretty cool.  Pretty cool.



STEVE:  Yeah, it actually works.



LEO:  Let's move on.  Question #3 from Tom Aafloen, from Karlstad, Sweden.  He has a password manager for my mom.  Actually it wasn't my mom that had the problem, but okay.  We'll use it.



STEVE:  A generic mom.



LEO:  Any - or me.  Certainly me.



STEVE:  Certainly my mom.



LEO:  Hi, Steve.  Leo mentioned a couple of Security Now! episodes ago he didn't think his mom would use any of the password managers out there.  But there is one that is just as simple as Notepad - all right, I think anybody could figure that out - but secure.  The application is called LockNote.  It's made by Steganos.  It's a text editor/notepad and encrypted text document in one.  Wow.  It's a portable application, no need for installation.  You can run it right off a USB stick.  It's only 312KB in size.  And since you only store text in it, it's not going to grow that much even with tons of passwords in it.  It is open source - it's on SourceForge - for the paranoid.  You can get it from Steganos.com.  It says you cannot have multiple documents in one instance of LockNote, but you can easily copy the application and have multiple versions with different passwords if you want.  A simple application like this probably can run in multiple instances on Windows.



Just thought I'd pass this along.  I've used this in combination with SuperGenPass - which I've recommended - for a long time now.  I even have a LockNote version for gift ideas to my friends.  So it doesn't have to just be passwords.  You can lock up anything in here.  You have mentioned on the show that when someone passes away it can be hard to end that person's accounts on all the sites he or she may have been registered on.  Well, an envelope with your LockNote password and the location of the file solves that.  Put that in a security safe deposit box or something.  He says, I'm in no way affiliated with the makers of LockNote, just a fan.  Love the podcast.  You should make it twice a week.  Tom in Sweden.  What do you think?  Have you looked at it?



STEVE:  I have.  And the reason I posted this was I'm impressed.



LEO:  It's a good idea.



STEVE:  I've got the source, and I'm going to take a look at it because they don't talk at all about what they're doing.  And I want to make sure that what they're doing makes sense.  But what this is, is just an EXE.  When you download it, and if you go to Steganos.com - it took me a little while to find it.  But on the left-hand column under "Free Stuff," there's, like, four free things.  The other ones aren't very compelling; but this one was, called LockNote.  You just download it, and that's it.  There's no setup.  There's no install.  I mean, I like everything about this so far.



And what it is, is it's just like a Notepad app.  In fact it looks exactly like the Windows Notepad.  And what's cool is that you can cut and copy and paste, and it acts in every way like Notepad.  Then you can assign a password to it.  Now, as far as I could tell it makes no attempt to make sure you use a good password.  I just put "nuts" in, and it loved it.  So it's like, okay, well, that's not a super good password.  I could have probably put "r" in, and it would have been happy.



But what's nice is that it binds the text and the password into itself, into the EXE.  So you never have a separate text file.  It's just this EXE.  And as he says, I mean, I'm a little thinking, okay, 312K, that's huge.  But that's just my bias because if it were in Assembler it'd be much smaller.  But it's neat because you then, under the file menu, you can change the password.  And the only way you can change the password is if you know the password because if you try to run it when there is a password, it just says what's the password?  And so, I mean, it's very clean.



For me, as I mentioned before, I just got this one big list of URLs and usernames and passwords that I keep in my Palm Pilot.  Well, I could easily just cut and copy and paste that into this, give it a really good, strong password because the vulnerability would be guessing the password, so you want to make sure that it's not guessable.  And but it just - I love it because it is so clean and just so simple.  There's nothing to learn.  No UI.  No fanciness.  It's not trying to do more than just locking up a text file.  And it and the password are in some fashion bundled to itself.



Now, again, these guys clearly know security.  They've got a bunch of security stuff on their site.  So I'm assuming they're doing everything correct with the password.  That is, they're not including the password in the EXE.  Instead, they're hashing the password or encrypting it or doing something.  Anyway, I've got the source.  Here's a perfect example.  We were talking at the top of the show why open source can be useful.  Frankly, if they told me on their site this is exactly what we're doing, yeah, I'd believe that because they've disclosed it, and they have no reason to lie to me.  But they didn't tell me anything about what they're doing.  So the good news is I can answer those questions by looking at the source.



LEO:  You can validate it, yeah.



STEVE:  Yes.  So I will - well, there's nothing to validate because they didn't say anything.  But I want to know for myself what they're doing.  And I will next week tell all of our listeners exactly what they're doing from my having looked at the source, and be able to say, okay, here's exactly what they're doing, and they did it all right.  So anyway, it's very cool, and I wanted to tell our Windows users.  Unfortunately there's no Mac version, although it's open source.  Again, it's not a super-brilliant, hard-to-reproduce concept.  But it's just done, and it's just - it's very nice.  I like how clean it is.  And it's a cool little gizmo.



LEO:  Very, very neat.  Question #4, a long one.  Get ready.  Stand back.  Jim in California, in the Bay Area, has some real-world feedback about WOT - Web of Trust.  We talked about that I think a couple episodes ago.



STEVE:  Yep, a browser add-on.



LEO:  Steve, first of all, let me say I've been a fan of yours for many years.  The security information that you post on GRC.com is invaluable.  I've been a regular user of ShieldsUP! for years.  I'm also a very happy owner of SpinRite, which is an essential tool for my computer work.  It's fantastic.



Now, I recently discovered Security Now!.  Wow.  I had no idea you were on the air, and I'm thrilled.  Now I'm listening nearly nonstop to previous and weekly podcasts and passing it on to my other geek friends.



This is a big thing for me is I don't understand how people could be in the tech industry and not know that TWiT exists, but they do.  They are.



It's people like you and Leo that really make the world a better place as your help to others is priceless.  Thank you.  Spread the word.  Let them know.



What I'm writing to you about is a point regarding Web of Trust.  There's a bad shortcoming regarding WOT.  I started using it and recommending it about a year or more ago.  So he was ahead of us on this one.  What I found was that undeserving sites were being blacklisted, that is approved, in WOT.  These sites were listed as having malware, adult content, et cetera.  Oh, I'm sorry, blacklisted means bad.  They're bad, okay.



STEVE:  Right.



LEO:  So that undeserving sites that are fine were listed as being not so fine.  I knew nothing could be further from the truth.  These sites were totally safe and helpful.  On emailing WOT about this, I was informed that WOT does not moderate the ratings.  How it works is, when a user finds what he or she believes to be a bad site, they simply tag it as bad, what category of problem occurred, and comments.  Yeah.  That's a problem in a lot of things - email blackholing with MAPS and ORBS and that kind of thing.  There's no appeal process.  There needs to be some way of aggregating the information and kind of validating it.



Seems some users may think they got infected from a certain site, but due to the nature of clickjacking or maybe cross-site scripting it may not have been from that site at all, possibly not even during that session.  We all know that.  Users often don't know what happened or why.



Further, what some Internet "griefers" are doing is using it to launch political or social or other attacks on websites by using WOT to blacklist that site.  Any user who uses WOT will see a warning page when they attempt to go to the actually benign site.  This warning is a full page and will certainly scare off any new visitors.  Better safe than sorry?



Consequently, as you might imagine, I've stopped using WOT and stopped advising its use to others as it forwards malicious users' efforts to deny service to legitimate websites.  That's a shame.  Web of Trust is a neat idea, but unfortunately it really needs trust.  Or at least modifiers and verifiers, an expensive proposition.  Perhaps WOT has corrected this problem in some way.  It's been over a year since I conversed with them.  As always, there are people in the world who use technology to harm rather than help.  They need to follow the examples of Steve and Leo.  That's a shame, but that's a very good point.



STEVE:  And it's not surprising.  I mean, the concern was that their threshold for blacklisting a site would be very low.  And you could argue that, if they don't have a huge user base, then they're not going to have an opportunity to receive a large consensus on a site being bad.  In fact, it sounds to me like any user saying, oh, I got hurt by this site, suddenly makes it questionable.  Now, it would be nice if they, like, published how many people agreed, or if there was...



LEO:  That's what they need.  They need, yeah, some aggregation or something, yeah.



STEVE:  Yeah.  But he's right.  As it is now, it sounds like they're - it's just unfortunately he's right that it would cost a huge amount of money for them to go around verifying everything.  Which frankly, when we were discussing this, I was saying that I liked the idea that Google's bots were doing this because they've got no cross to bear.  They're looking at all the code.  They're able to be kept up-to-date with the latest exploits and see whether they see evidence of those exploits on the sites that the bots visit in their normal web visiting, as they spider around the web.  So to me I think that does make more sense than this kind of an aggregation approach.



LEO:  Alas, it's true.



STEVE:  Yup.



LEO:  Matthew Justice in Austin, Texas - a good place for justice - wonders about Google's DNS Server.  Steve, just in case you did not see this - this actually happened since we talked last.  This is brand new.



STEVE:  Yes.



LEO:  Google is now doing its OpenDNS kind of a thing.  It's a public DNS server, 8.8.8.8.  He says you might want to run it through your new DNS benchmark tool.  And when might we, the world, be able to play with this?  Love your show.  Thank you.  Matthew.  So you have a tester.  When this BIND flaw was first publicized, you figured out a way to test; right?



STEVE:  Well, actually it's different from that.



LEO:  Oh, okay.



STEVE:  It'll pop your eyes out of your head, Leo.  But if you go to GRC.com/dns/benchmark.htm, you'll see just a screenshot of it.  And I've - this is what I spent a large chunk of the year working on.  It's gorgeous.  And I just need to finish its documentation.



LEO:  Well, let's see it.  We want it.



STEVE:  We'll have it soon.  So many people wrote about Google's new DNS service...



LEO:  So this just tests the speed, not its security.  That's right.  We showed another program that tested the security.



STEVE:  The spoofability system is tied to this.  And in fact I got onto this because I wanted to launch them both around the same time.  So this is performance as opposed to security.



LEO:  Wow.  This is great.



STEVE:  Oh, it's phenomenal.



LEO:  Look at this.  Steve, wow.



STEVE:  It's a real piece of work.



LEO:  Now, you can't download it yet.  Or can you?



STEVE:  Oh, it's there.



LEO:  Oh, good.



STEVE:  It's downloadable.  Just click on it.  And it's tiny.



LEO:  175K.  I downloaded it faster than my mouse could click it, practically.



STEVE:  Yeah, and it's all Assembler.  And it works.  I'm glad that Google did this because I will - I'll add Google's servers to it.  I've seen a couple postings from people who have used it already, and Google's benchmarking a little slower than OpenDNS.  And this thing even tells you if, like, OpenDNS is in its default configuration, if it redirects mistakes.



LEO:  Google does not do that.



STEVE:  And Google does not do that, right.  So...



LEO:  Yeah.  Which surprised me because, if anybody would want to stick some advertising in there, I would have thought it would be Google.



STEVE:  And do you know, I have not - I've been so preoccupied trying to get ready to get this finished that I have not yet looked in depth at Google's DNS offering.  Have you done a show on it yet?



LEO:  Yeah, we talked about on This Week in Google, and I have certainly used it.  And...



STEVE:  So what's Google's motivation?



LEO:  Well, they don't disclose their motivation.  They say, well, we just, you know, we want to improve the experience on the 'Net because the more you use - and actually this is probably true.  The more you use the 'Net, the happier we are; right?  And that makes sense.  Now, the problem is there is OpenDNS already.  And frankly, OpenDNS I think has some significantly better features, things like filtering and so forth.  But the nice thing about Google, it's easy to remember.  It's 8.8.8.8.  And I can't remember the other one.



STEVE:  The other one is 8.8.4.4.



LEO:  So very simple, very easy to remember.  But, you know, I think it's good to have another one out there.  I don't think there's anything - I can't see anything wrong with it.



STEVE:  Yeah, well, we'll know soon how its performance compares, and ultimately I think that's the way it will win, with a tool like this that makes it easy for you to see, from your location, what is the fastest server, which is really what you want to know.  That's why no one can say, oh, OpenDNS is faster.  Well, you might live next door to Google's DNS server, in which case it's going to be a lot faster.



LEO:  Right, right.  So I'm adding 8.8.8.8.  And so how - I just would click to run it, or how would I...



STEVE:  Yeah.



LEO:  Run benchmark.  Okay.  Oh, I have to right-click it?  I'm not too bright when it comes to this.  I see the red button.  Now what do I do?



STEVE:  You can click on the big GRC "G" logo if you want.  That'll start it up.



LEO:  Oh, okay.  Well, it's testing them all now.  I see.  Okay.



STEVE:  Yeah.



LEO:  So, all right, cool.  So, yeah, Google is sinking to the bottom at this point, so...



STEVE:  Yeah, and it may be that they have said, okay, we're launching this, and over time we've going to install more servers.



LEO:  Yeah, they've got plenty of bandwidth; right?



STEVE:  Yeah.  We can imagine, if they wanted to give OpenDNS a run for their money, they'd be able to.



LEO:  You know, Verizon's is very fast, the four-dot.



STEVE:  Yes.



LEO:  Huh.  Yeah, Google's way down on the list.  Not way, way, way down, but lower than some of the other ones.  Interesting.  Interesting.  So this continues to run...



STEVE:  Until it finishes.  You'll see a little progress bar there at the top which is moving along.



LEO:  I see, yeah.  Oh, that's neat.



STEVE:  And it shows cached, uncached, and dotcom.  Those three different bars are showing you different things.  And then if any little red marks appear on the left, that's reliability problems because it's looking for any loss of reliability.  I mean, there's a ton of technology here.  It's what I - as I said, it's what I've been working on.  I've talked about it a number of times.



LEO:  That's neat.



STEVE:  And we'll do a show on benchmarking DNS as soon as I get all the documentation finished.



LEO:  They're saying in the chatroom, uh, Leo, you might want to click the giant "Run Benchmark" button.  I'm not that bright.  Sorry.  Let's move on.  Question - so, yeah.  I mean, I think this is a good choice.  I use OpenDNS.  Now, OpenDNS does do the thing that you may not like, and others may not like, which is if you do a bogus, a nonexistent search, it pops up a helpful page with some advertising on it that says, you know, did you mean this?  It doesn't bother me...



STEVE:  In fact, other people are beginning to do it, too, other ISPs.  Comcast, I believe, is doing that.  You'll see that OpenDNS is shown in orange in the benchmark.  I detect that for any DNS server.  And so I alert people that this is what's going on.  And on the summary page, once the benchmark is finished, I actually interpret everything that has happened and compare your DNS servers that you currently are using to everything we just learned about all the other alternatives and advise whether - I actually compute whether there's a statistically significant improvement that you could make by making some changes.  So anyway...



LEO:  Top four in my results are orange, and numbers two and three are OpenDNS, which is usually what I use.  I like OpenDNS because I can say - I can use the filtering for my kids and stuff like that.



STEVE:  Well, and if you become a subscriber you can turn off the redirection.  So it's not like...



LEO:  Right.  And that's free.



STEVE:  Yeah.



LEO:  It's not like you have to pay for anything.



STEVE:  Yeah.



LEO:  I use the redirection because, first of all, I like it, and I don't want to - I want to support them.



STEVE:  Yes.



LEO:  It's all for free.  Question 6 comes from Lex Thomas in Research Triangle Park, beautiful North Carolina.  He wonders about router DNS.  This is a little different:  I've been reading about Google's new Free DNS project.  We just talked about that.  A few years ago for a brief time I used OpenDNS, liked it a lot.  But after an unfortunate and unrelated incident, I had to restore my PC, which caused me to lose my OpenDNS settings.  I put mine in the router.  I think that's what he's about to say.



After that I just never got around to putting OpenDNS back in.  I just defaulted to using what the ISP sent down the pipe.  I suppose I should have set up my router instead to point to OpenDNS, rather than doing it in Windows since I'd probably want every computer on the network to use this alternate DNS anyway.  I haven't made up my mind about Google's DNS yet.  But are there any advantages or disadvantages to using the DNS lookup in the router as opposed to the operating system?  Thanks for a great show.  Been a fan for years.



Yeah, I've been using it in - I use it in my router at home because that way my kids, you know, unless they're smart enough to bypass it, or motivated to bypass it, which apparently they are not at this point, any computer they use has the same filtering on it.



STEVE:  Well, we've learned some interesting things through - not only through the work on the DNS benchmark, "we" meaning myself and all the people in the GRC.dns newsgroup where we've actively been working on this, and on the spoofability tester before.  What's interesting is that there's a growing list of routers that the spoofability test crashes.  And as we know, crashes, well, exploits start out as crashes.  And then people figure out exactly what it was and how that the router is crashing, and they turn them into remote code execution.  And so there's the possibility that there are a surprising number of routers that you can give them a specially formed DNS response and take over the router.  So we're a little concerned about that.  So I discussed that on the spoofability system pages.



The other concern I have is that typical consumer routers are not very smart.  You know, they're made to be very inexpensive so that they're profitable for the people making them.  And doing DNS lookup correctly is sort of tricky.  You want to remember what the fastest configured DNS server is, and you want to give it a chance to reply.  But if it doesn't reply, then you want to ask it again.  And if it still doesn't, then you want to ask all your secondary, tertiary, and so forth servers.  And the fact is, this is the logic that UNIX and Mac and Windows uses.  That is, when all these OSes are given multiple DNS servers, they use them intelligently and in a way that overall maximizes performance.



The problem is that, if you remoted your DNS to the router, now it's sort of your proxy.  And so your computers all just get one DNS address, meaning the router, and are at the mercy of the router doing the right thing.  It's certainly possible for a smart router to be doing a good job with DNS resolution and be passing that back to the clients that are using it to provide that service.  But the fact that we've seen flaky router operation, and in fact the DNS benchmark has revealed that some routers are much slower than going direct.  That is, the router is actually a speed problem for that.



And so, for example, you give your - you're using the benchmark.  You leave the router registered.  And you'll end up finding that, for example, going directly to OpenDNS is faster than using your, like, often 192.168.0.1, for example, because typically your DNS will be the same as your gateway, which is the IP that the router has inside your network.  So we've also seen, thanks to this benchmark, that using the router is slower than manually configuring DNS and just bypassing it completely.  So your mileage may vary.  Once the benchmark is finished and public, people will be able to see for themselves.  Certainly Lex is right.  Putting those settings, sort of making them global for your whole network, exactly as you have done at home, Leo, can make sense because then every system gets the benefit of making a single configuration change.



LEO:  Right.  And you can override it because, if you override the DNS numbers in any individual machine, it'll override it.  And so...



STEVE:  Exactly.  Instead of just saying "obtain DNS automatically," you just manually put those in.



LEO:  And don't tell my kids that.



STEVE:  Exactly.  Right.



LEO:  Well, actually, what I do is I lock down the settings.  Then they'd need an administrator password to change the network settings.  So it's actually so much more effective, I think, than any filtering solution out there.  It just seems like that's the no-brainer for any parent.



STEVE:  Yup.  So switch to OpenDNS and then go to your OpenDNS configuration page and remove the kinds of sites that you don't want people...



LEO:  Well, it has built-in that you can just say, I mean, it has a whole list, but it has pretty good filtering.  You can say just keep us safe.  But you have to create an account.  It's free, though.  That's the advantage of that.



STEVE:  Yeah.



LEO:  Steve, are you ready for our Disney authentication questions of the week?  Starting with Question 7, Daniel Ernst from West Bloomfield, Michigan, USofA.  His Disney fingerprint story:  I'm a week behind, just finished 224.  Thought I'd mention my experience with fingerprints at Disney.  My family went to the Disney parks in Florida last year and encountered the fingerprint scanners.  I've been guarding my fingerprints for as long as I can remember, going back to an FBI tour in the '70s - that's neat, he wised up in the '70s - and not volunteering to have my fingerprints taken.  I'm sure I would have balked at giving them up at Disney, had I been surprised by it.  But being a Security Now! listener I was well prepared.  I didn't even try the knuckle thing.  I waved over a gatekeeper and explained I'm a privacy advocate.  This is what people should do.



STEVE:  Yes.



LEO:  Instead of trying to fake it, let them know.  Because if enough people complain, they'll go, oh, I guess we can't use this system.  I waved over a gatekeeper, explained I'm a privacy advocate - nice way to put it, I'm sure he did this nicely - and refuse to give up my family's fingerprints.  This is interesting.  The employee wasn't surprised, told us the alternative is to show photo ID each time we use our passes.  We had our IDs out the next few days at the entry gates, and without a hiccup we were let in each time almost as quickly as those giving their fingers.  So no need to fool them.  Let them know you'll take the alternative.  If enough people do, maybe they'll get the message.  That's great.  I love it.



STEVE:  Yeah.  I thought that was a really good bit of news.  I did - a bunch of people, as you apparently independently experienced, Leo, have been talking about this and Disney.  And I saw, I found an article that talked about Disney's policy where they say that they are deliberately keeping this biometric data separate, that they're not recording a fingerprint at the resolution, that is, enough data points so that it could even be used for recognition.  It could only be used as a go/no go sort of verification.  So only a few aspects of the fingerprint are being maintained.  And they flush them after the pass which is associated with it has been expired by more than a month or something like that.



So even independent of all this, it does sound like Disney at least was always conscious of these issues, which is really nice to hear.  Of course that doesn't tell us anything about anybody else's fingerprint policies.  So everything we've said about banks needing you to use your fingerprint in order to cash a check and so forth likely still applies.  But at least in the case of Disney it sounds like they've been acting responsibly.



LEO:  Yeah.  And here we go with our Brilliant Disneyland Authentication Solution of the Week.  And this comes from another Swede.  You know, we have a lot of Swedish listeners.  And just a tip of the hat.  It's really great to have all these listeners all over the world.  I love it.  And Tom Aafloen from Karlstad, Sweden says:  Hi, Steve.  You and Leo sometimes talk about the problem with companies wanting to have your fingerprint.  I think it's going to be harder and harder to resist this.  By the way, if you are a Swedish citizen and you come to the U.S., you get fingerprinted.  And you sometimes get iris-scanned, as well.



And with nagging kids behind you and a stubborn Disneyland employee in front of you, the slight obvious knuckle solution might not always work.  So why not dedicate a finger?  Save your index fingers for personal use.  Use your pinkies as a personal backup in case you injure your index fingers.  Let's say use, I don't know what's left, your middle finger, for external companies [laughing].  I can't wait until I can hold up my middle finger, my palm facing me, at the Disneyland reader and pressing it down there.  There's no correlation between the fingerprints on your different fingers; right?  I mean, if they have my middle finger, it doesn't mean they can figure out what my index finger is.  Love the show.  Tom in Sweden.  What a great - does that mean the same thing in Sweden as it means in the U.S.?  I don't know.  Apparently so.



STEVE:  Apparently it does.  And I just - but I loved the idea.  I don't know why, I mean, it's so simple.  We've got 10.



LEO:  Got 10.



STEVE:  And he's right, there's no correlation of fingerprints from one to the other.  So it's not like your DNA, where they can say, oh, look, this is the father of somebody because they're able to see that it's a close match.  And so by all means, use your middle finger for the bank that insists that they have a fingerprint.  And you may need to conceal which finger you're using.  But if you can get away with it, I think that makes a lot of sense.  I just - I thought that was very simple and very clever, as some of the good ideas are.



LEO:  My god, man, you're brilliant.  Brilliant.  Now,  I've completed the benchmark here from the DNS benchmark.  And the Google - I see Level 3 is very high up there.  Google is fairly far down.  Not at the bottom of the list, in the top 20.  But by far OpenDNS is the fastest.  I don't know what this 156.154.7...



STEVE:  You can click one of the tabs.  The other tabs will identify by name and...



LEO:  Ah.  Neustar.  Huh.  I don't know who - N-e-u-s-t-a-r.



STEVE:  And they're pretty high on your list?



LEO:  Number one on my list.



STEVE:  Oh, interesting.



LEO:  Look at that, incredible response time.  Look, their cache time is almost zero.  Their purple bar.



STEVE:  Interesting.  So they - it must be - see, that's one of the things that's so interesting about this is DNS performance is absolutely a function of where you are.  So it must be that if you're using your fancy Ethernet T1 or, no, super connection, that for whatever reason, wherever that terminates has got very short response time to that particular server.



LEO:  Here's an interesting tidbit.  The highest ranked DNS server that does not replace the 404 page is NTT.  That's the Japanese telecom.  No, I think it's NTT DoCoMo, isn't it?  America Technical Operations.  Then Speakeasy, Neustar again, then Level 3.  Somebody's saying in the chatroom that Google uses Level 3, so their connectivity might be coming through Level 3.  Then Sprint.  Speakeasy is very big on there.  The Planet.  Time Warner.  It's interesting.  So Comcast, Verizon, and then Google way down on that list.



STEVE:  It's a cool little app, isn't it.



LEO:  Boy, I love this.  Steve.  I wish more people knew about this.  We've got to...



STEVE:  Oh, everyone'll know soon as I get the documentation finished.



LEO:  Plug this more.  Oh, wait a minute.  I'm seeing Google.  It's announcing itself.  It is above some of those others as Level 3 Communications, not as Google, 8.8.8.8.  So I wonder if they're just using Level 3's DNS server and branding it Google.



STEVE:  And click on the recommendations, is that what it is?  No, conclusions.



LEO:  Conclusions. 



STEVE:  And it turns everything into English so that people who aren't super gurus can just sort of quickly scan through, and it highlights important things that it found.



LEO:  It's interesting because we're using - it says there's only one DNS in here, and it's our local router's DNS.



STEVE:  So it knows that; right?



LEO:  Yeah.  But I think that that's because this is Skypesaurus, which DNS is not important to Skypesaurus, particularly.  System name server is slower than three public alternatives.  This is great.  Look at this, Steve.  You're brilliant.



STEVE:  Well, this is a big piece of work.  But it was a labor...



LEO:  I can't believe this.  And this is free.



STEVE:  Yeah.



LEO:  GRC.com/dns/benchmark.  You can get it right now.  It's a tiny download.  You'll think you didn't really get it.  When you click on it, it's like, wait a minute, I must have missed that.  So it's, like, five copies because it's just - it was so fast.  Steve writes everything in Assembler.  This is what's so great about Steve.  Look, if you go to GRC.com, buy SpinRite just to say thank you, Steve.



And then, by the way, it's a great thing to have.  Everybody who has hard drives needs SpinRite.  It's the world's best hard drive maintenance and recovery utility.  But there's so much great free stuff there, like this benchmarker.  And of course the show is there, including 16KB versions.  Steve makes those himself.  We stopped making them, so Steve said nope, gonna make 'em, gonna have 'em.  Thank you, Steve.  He also pays for transcriptions himself.  He takes this stuff really seriously.  So give him your support because he works very hard for us.  GRC.com.  Do you know what we're doing next week?  Maybe we're answering that question about ARP spoofing and random data.  I don't know.



STEVE:  We're definitely - I'm going to come clean and say that I got myself tangled up on the last Q&A, and I'll have a complete, thorough, clear answer.



LEO:  Good.  And all the security news and more, every week, with Steve, right here.  You can watch us do the show live on Wednesdays.  We do it at 2:00 p.m. Eastern, 11:00 a.m. Pacific, every Wednesday unless there's a schedule change.  But you'll find the schedule in our calendar and the live video at live.twit.tv.  And some really interesting changes coming to our websites soon that's going to make it easier for you to see what you want, including video of all our shows, and this one, as well.  So people who have been wanting to see Steve's smiling face as he saves the world can do that.  It's all at TWiT.tv, and live.TWiT.tv for the live streaming.  Steve, we'll see you next week.  Have a great week.



STEVE:  Thanks, Leo.  You, too.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#227

DATE:		December 17, 2009

TITLE:		Cyberwarfare

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-227.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo examine the amorphous and difficult-to-grasp issue of nation-state sponsored cyberwarfare.  They examine what it means when nations awaken to the many nefarious ways the global Internet can be used to gain advantage against international competitors and adversaries.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 227 for December 17, 2009:  Cyberwarfare.  



It's time for Security Now!, the show that covers your security, your privacy, your online persona.  And with us today, as always, Mr. Steve Gibson.  He's the king of security, the man who discovered spyware, coined the term "spyware," wrote the first antispyware program, and publishes a lot of free security stuff on his website, GRC.com, along with his great program, SpinRite.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be back with you once again.



LEO:  This is going to be a fun - I'm very, very interested in this one. 



STEVE:  It's a topic we have never really discussed because for a long time, frankly, I had a hard time taking it seriously.  I guess it's maybe I'm too close to the topic, and it just - or it seemed like a little sort of more sci-fi than real.  But we're going to talk about cyberwarfare.



LEO:  Wow.  So it is real.



STEVE:  I still, you know - it apparently is.



LEO:  [Laughing]  Apparently.



STEVE:  [Laughing]  Apparently it is.  I mean...



LEO:  Well, it's like saying espionage is real.  Apparently it is.  But, I mean, until you have something, you know, somebody's actually caught...



STEVE:  Yeah.  For example, earlier this year, in 2009, in April, it was discovered that China and Russia had both infiltrated the control systems for the U.S. power grid.



LEO:  Right.  I remember that.  We talked about that.



STEVE:  Yes, we talked about it.  Their stuff was found there.  And it's like, oh.  Well, it didn't just happen to install itself.  I mean, somebody put it there.  And so this is clearly going on.  Now, there are all kinds of different types of attacks.  I want to talk about the different sorts of attacks going on, and countermeasures.  And really the reason I just chose today was that John Markoff, who has been a reporter in the tech industry for years, he's now with The New York Times, and there was a front page story that John co-reported about the U.S. and Russia having essentially opened talks about signing a cyberwarfare treaty.  And as I'm reading it I'm thinking, okay.  Well...



LEO:  A treaty?  A treaty?



STEVE:  Yeah, it sounds dumb to me because it's not like a nuclear arms or a biological weapons treaty, where your compliance to the treaty is subject to inspection.  Cyberwarfare doesn't exist in the real world.  It's something - it's a technique rather than an object.  So I don't know.  So anyway, we've got a lot to talk about.



LEO:  Very interesting.



STEVE:  I think our listeners will find it interesting.  And then a couple big pieces of security news.  And we ended up having a success.  Someone put their hard drive in the freezer and reported that.  So...



LEO:  Oh, that's interesting.  Because we've talked about that before, but I don't know if I ever saw anybody do it.



STEVE:  Well, he got his data saved because we talked about it, as a matter of fact.



LEO:  Oh.  I love it.



STEVE:  Yeah.



LEO:  I guess we should start with the security news, Steve, and then get onto anything else that's going on, and then cyberwarfare.



STEVE:  Yeah.  I forgot to ask you before we began the show.  I heard you, as I was watching the feed as you were getting set up, you mentioned to Dick that he won the Podcast Best of Comedy stuff.



LEO:  Oh, congratulations.  You won the Best Technology podcast.



STEVE:  Yeah?  I didn't know.



LEO:  This shows you how much we care about things like this.  I'm glad you brought that up, Steve.  You are, in fact, podcast award-winner for 2009 for Best Technology Podcast.



STEVE:  Yay.



LEO:  Beating out all the rest, including great shows like Bwana.tv.  We love Bwana.  He's great.  FLOSS Weekly, another TWiT show.  GeekBrief, Linux Outlaws, the great MacCast, Mike Tech Show, SDR News, Skepticality, and the Naked Scientist.  Security Now!, Best Technology Science Podcast for 2009.  And thank you to all the listeners who made that possible.



STEVE:  Wow, yes.



LEO:  Because it was your votes.



STEVE:  Yes, yes, yes.



LEO:  I heard that they got eight million total votes over the several week voting period.  Eight million.



STEVE:  Wow.



LEO:  So it's a significant, I mean, this means something.



STEVE:  Wow.



LEO:  Yeah, we won - we were nominated for nine shows, and in several categories, like yours, two of our own shows nominated.  And of course I know everybody else who got nominated, too.  I mean, these are the best podcasts in the country, in the world.  But we won for Best Comedy Podcast, that was Dick.  We won for Food and Drink, that's Munchcast.  Which we're bringing back because we had actually canceled the show.  We're bringing it back.  If you like it that much, it's back on the schedule.  We're going to start doing it on Sunday afternoons at 2:00 o'clock, right after the radio show, right before TWiT.  We also won for - what else did we win for?  There was one more.  Oh, Best Video Podcast.  TWiT won.



STEVE:  Very cool.



LEO:  And that was a tough category.  I was actually - did not think we had a chance.  We were competing against Buzz Out Loud, Cranky Geeks, Diggnation, Filmriot - which is a brilliant show - Mr. Deity, NASA EDGE, Scam School, TED Talks?



STEVE:  Wow.



LEO:  Tekzilla, I mean, these are the - I was blown away that we won that one.  So I had thought, oh, there's no chance.  So thank you, everybody, for all the votes.  And congratulations, Steve.  There is a plaque or a trophy of some kind, which we will immediately mail to you as soon as we get it.



STEVE:  Hey, cool.  That means a lot.



LEO:  I expect to see it on the thing behind you there.



STEVE:  That means a lot.



LEO:  Well, you deserve it.  I mean, heck, this is a great show.  It's not the first time you've won, we should point that out, either.



STEVE:  Although I think wasn't the first one Best Security Podcast?  Or was it Best Technology?



LEO:  I don't remember.  I think it was technology.



STEVE:  Okay.



LEO:  Yeah, it was technology.  They're not that granular.



STEVE:  Right.  That's very cool.



LEO:  Well done.  Sorry I didn't mention this earlier.  You know, it just shows you that we don't - our mind's not in that...



STEVE:  It's funny when you talk about the number of votes and what it means.  I won - you know how the senior class in high school is, like, most likely to this and most likely to that, like, in life?  I won Most Likely to Be President of Bank of America, of all things.  And it's like...



LEO:  Huh?  And actually, these days, not such a good job.



STEVE:  No.  And I guess that was our high school's modality...



LEO:  It was like the highest award you could get.



STEVE:  Yeah, or like maybe you're going to, I mean...



LEO:  They weren't far off.  You're an entrepreneur.



STEVE:  But my point is that I think I was probably - the only reason was that I was the only one who was, like, written in who got, like, more than one vote.  Everybody else, I mean, I'm sure there were lots of other people who people wrote in for that.  But, you know, two people probably said, oh, that sounds like Steve.  And it's like, okay.



LEO:  That's all it takes.



STEVE:  It just seemed so random to me then, and even more now.  So, yeah.



LEO:  I think that in order to get this award we probably had to get a substantial number of votes.  I know that the video category - Todd Cochran, who runs these awards, and thank you, Todd, for doing this, he was saying that the video category got I can't remember how many votes, but a ton of votes.



STEVE:  Oh, yeah, I mean, and listen to the competition.  Wow.



LEO:  Yeah.  I mean, it's the best.  I can't believe we beat TED Talks, Diggnation, Tekzilla, I mean, these are great shows.  So thank you, everybody.  We really appreciate it.



STEVE:  Very neat.  Okay.  So two pieces of news.  I wanted to mention that the House of Representatives, the U.S. House of Representatives, passed a significant resolution, HR 2221 [Data Accountability and Trust Act], which is the electronic data breach notification legislation.  Something similar will happen in the Senate, and then they'll be put together for reconciliation, and then the final bill will be produced, and the President will sign it.  And it looks like all that's going to happen because this isn't, like, super controversial or anything.



The reason it's significant and good news, well, it's sort of a mixed blessing.  Right now there are completely randomly differing state-by-state regulations which make it very difficult for companies to comply because, if they're doing business in multiple states or have any kind of presence in multiple states, and in fact if the consequence of a breach affects people in other states, then they're subject to differing regulations.  So having a federal law will, and this does, will supersede state-by-state regulations.



Now, I said it was a mixed blessing.  The bad part is that the FTC is the enforcement side of this.  But government, financial institutions, insurance companies, nonprofits, and institutions of higher education are exempt from FTC jurisdiction.  So it's like, okay, well, we're making progress, but we still have a ways to go.



The other good piece of news is that when there have been major breaches which have been publicly exposed, the stock prices of the companies responsible have been substantially hit.  And of course that gives the budgets of the CTOs in these companies, or the information security officers, now some more leverage with their boards, saying look, we need a budget to do what we know how to do in order to prevent us from getting a black eye if we disclose private information publicly by mistake.  So that ends up, you know, in general we're moving forward, which I think is certainly good.



Now, the dark side this week is that a lot of attention is finally coming to, and that's a good thing, to a really bad SQL injection attack.  I've seen reports that talk about as many as 1.2 million sites being infected, although to get to that number you need to use various sort of primary domains for the attack.  The one that's most well known, and people can see it for themselves, as I had you do before we started recording, Leo, if you put into Google, you just Google "318x.com."  Don't click on anything.  Don't go to the sites.  What this is doing is this is Google having found instances of sort of the fundamental domain of the attack.



We've done a discussion in detail of SQL injection attacks before, so I'll just summarize it by saying that an SQL injection attack is a means by which malicious parties can inject some text of their choosing into an unwitting website.  For example, unfortunately, the SQL or "sequel" database is often on the back end of a web server.  So the pages are being presented as a consequence of data stored in the database.  Which means if you change what's stored in the database, you change the presentation of the website.



Now, databases are, for example, often behind forum systems, where you have a user-interactive forum.  Or they can be behind wikis, for example, where again you've got essentially malleable web content.  The problem is that it is certainly possible to secure these; but it is much easier, as is always the case, for them not to be secure.  And so at the moment nearly 300,000 sites, actually I think there's a number - as we're recording this, Google is reporting 259,000 instances of the string "318x.com" in sites that it just is randomly indexing.



Now, what happens is that domain appears in what's called an "iframe."  An iframe is an inline frame which, when the browser rendering the page containing this encounters it, it then essentially follows that frame to wherever the frame points.  Well, what the frame contains is a script tag that says SRC - short for source - equals http://318x.com/a.htm.  So that does two things.  It loads, when that a.htm is retrieved from the domain 318x.com, it loads a second iframe from aa1100.2288.org, so just some random domain someone got, /htmlasp/dasp/alt.html.  And then another script from some, I mean, I won't go through all of this in detail, but some JavaScript which is used for tracking.



Then that first one that I read, the aa1100.2288.org blah blah alt.html frame, it creates a third iframe pointing to another page, share.html, on the same site; loads a script from that second domain, just like a different subdirectory there.  The share.html detects the browser type and writes and loads multiple browser-specific iframes which point to obfuscated script files located in the same directory.  And so those further probe for the nature of what's on the client side.  So, for example, it checks for MDAC, OWC10, and various versions of Adobe Flash.



Depending upon the results, then it specifically probes for known exploits, including the integer overflow vulnerability in Adobe's Flash Player, which is described in CVE-2007-0071; the MDAC connection ActiveX vulnerability described in Microsoft's note 07-009; the web components vulnerabilities we just talked about a couple months ago, described in MS09-043; the video ActiveX vulnerabilities recently described and patched; Internet Explorer's uninitialized memory corruption vulnerability.  So it goes through those.  And if it's able to exploit those successfully, then it delivers another file at http://windowssp.776.org/down/down.css, which you might think would be a formatting file.  It's not.  Down.css is actually a Win32 executable that is a variant of a known Windows 32 backdoor which is called the Buzus, B-u-z-u-s...



LEO:  Of course it is.



STEVE:  ...trojan.  And that installs a number of files:  ammxv.drv under the user profiles; syesm.exe under common files; and then a bunch of things are installed in the registry, including a rootkit which prevents any of those from being seen and discovered.  And the bottom line of that is that it then connects up to a server at 121.14.136.5 via port 80 to sign itself up as a trojan.  And it then goes about stealing credit card and bank login information from your machine.



And this is all over the Internet, as a Google search on 318x.com demonstrates.  So Windows users with unpatched systems who go to innocent sites - and again, they're not visiting malicious sites, they're visiting sites that haven't been sufficiently security aware, that have this little script tag, this iframe script tag added to them.  And then, as you can see, all hell breaks loose.  And you end up with a backdoor trojan rootkit installed, which then steals credit card and bank login information actively in the background.



LEO:  Now, okay.  So somebody who just did a search for 318x.com, sees all these sites, let's assume that some of them are still infected.  And the person's running...



STEVE:  Oh, all of those are infected.



LEO:  Well, Google's - I went to a couple, and they've been disinfected since Google did the index.



STEVE:  Ah, okay, good.



LEO:  I mean, people, I mean, they're wising up, I guess.  But assuming that it's infected, and you go there, first of all, you have to be using Windows; right?  Not going to work on any other kind of operating system.



STEVE:  Right, because the vulnerabilities that it is exploiting, even Adobe Flash that is a cross-platform vulnerable target, it is installing a Win- it's running Windows EXEs and Windows, you know, a Windows trojan.



LEO:  Although there's nothing to say that somebody couldn't embed other things on that page.  But that's what we're seeing, the 318.



STEVE:  It's worth noting also that this is evolving over time.



LEO:  Right.



STEVE:  From the first instance where this began to appear in November, because this thing is such a linked chain of events, the links can be changed at any time.  So after, even after this script tag has been installed, it points to something that points to something that points to something.  So it's very easy.  And the people that have been monitoring this have seen an evolution of what this thing does over time.



LEO:  Right.  So, now, if I run Windows Update, and I'm updated, am I still vulnerable?  Is that exploit - has it been patched?



STEVE:  All of the exploits which this thing attempts to exploit have been patched, yes.



LEO:  Okay.  So that's one way to avoid this is to make sure you keep up to date.



STEVE:  Exactly.  And the other is to selectively enable JavaScript.  Because this fundamentally is all about JavaScript.  Without JavaScript there's no vulnerability.  So again, if you were a person using Firefox and NoScript, where you turned on scripting selectively where necessary - although it's worth saying that the flipside is many of the sites you might visit which are infected might be ones that need scripting enabled.  So you would innocently turn it on...



LEO:  Ah, good point.



STEVE:  Yeah.



LEO:  So in a way that's a way around NoScript because, hey, I want to use whatever this site is.



STEVE:  Yeah, I want the user forum or the wiki or whatever.  And, gee, I have to turn scripting on.  So you would turn it on.  And NoScript does what it needs to.  When you turn scripting on, it refreshes the page so that the scripts you have then enabled have a chance to come alive.  Unfortunately, this thing would then grab you.  If you had any unpatched vulnerabilities, you'd be in trouble.



The lesson here is, and we've talked about this often, is really do update your computers as soon as known problems are fixed because this is a perfect example.  Now that this mechanism is in place, I mean, there will be lots of sites that are not attended, that will not get this script tag removed.  You mentioned some you checked have been.  Clearly people are informing the webmasters, hey, you've got a problem, fix this, and the webmasters do.  There will be sites, in the same way that there's still Code Red is out there, installed on machines...



LEO:  Forever, yeah.



STEVE:  ...randomly.  Yeah, forever.  So the problem is that until 318x.com is taken down, and who even knows where - I didn't even bother to look for the registry of that.  It'd be interesting to see where it's registered.  Until it's taken down, it can be pointing to anything.  So the second a zero-day vulnerability appears, if there's a known exploit for it, that could get added to the list of things that this existing infrastructure checks for, and it could be very successful as a consequence.



LEO:  Wow, fascinating.



STEVE:  So I wanted to share it because it's, I mean, it's a perfect example of a multifaceted exploit which is seeing wide-scale success, unfortunately, at the moment.



LEO:  [Sighing]



STEVE:  On that note - on that note...



LEO:  On that note...



STEVE:  I got a nice note from Chris Rivera.  The subject was "Steve is my hero."  And he said, "In a recent episode," meaning of Security Now!, "you guys mentioned the hard drive in the freezer trick.  I've known about this, as well, but never had occasion to use it.  Wouldn't you know my luck.  My portable drive took a nosedive this weekend.  This was my only backup of my kids' photos and videos.  To me, this is the most important data in the world.  As I plugged in the USB drive, I heard a clicking sound.  I wanted to scream so loud.



"As my blood pressure was rising, I remembered you guys talking about the freezer trick.  So I froze my drive and reconnected it later.  It showed up, only to quickly die again.  It would only run for maybe 60 seconds at a time.  Without much hope, I fired up SpinRite and put it to work at Level 2 on the 320GB drive.  12 hours later, it had reported that there were no sectors bad or unrecovered.  In fact, it didn't report anything at all.  But I remembered you talking about how sometimes SpinRite fixes drives without anything to report.  So I plugged it up to my Fedora box, and voila.  I was able to copy the entire drive contents over to my workstation.  You have saved me so much heartache."



LEO:  That's great.



STEVE:  "I will never trust portable drives again.  That was my third one to go bad.  Each time I lost pictures of my kids.  Luckily I have backups.  But I've never had recent full backups, and have always lost some of the data.  I am most impressed with SpinRite.  Thank you so much for creating such an amazing application.  I hope I will never have to use it again (I mean that in a good way).  Did you write that in Assembler?  Keep up the amazing job of Security Now!, Steve and Leo.  Signed, Chris."



LEO:  Awesome.



STEVE:  So happy...



LEO:  It's good to know that works.  I mean...



STEVE:  [Indiscernible] story, yes.



LEO:  There's always been one of those, you know, I always thought it was kind of an anecdotal thing.  But I guess it does work.  It makes sense that works; right?



STEVE:  It really does because it's just, you know, drives are running on the hairy edge as it is.  I mean, the sectors are requiring lots of correction.  The reason that SpinRite is effective as a preventive maintenance tool is that it's able to go along and fix the problems before they get pushed to the point the drive can no longer fix things.  But even something as random-seeming as freezing the drive just, I mean, it just changes enough that the drive has a chance to work again for, like, one last try.  So it's funny, too, he  mentioned external drives.  I'm concerned about the heating of external drives because many of these little enclosures provide no active air flow across the drive.



LEO:  Right.



STEVE:  And many drives are designed, first of all, they're running fast.  They're generating a lot of heat.  But there are good enclosures that do have a fan, that are actively cooling the drives.  But drives really do not like to get overly hot.  That will really hurt them.  And so one of the problems I think we're seeing, I mean, these external enclosures are very popular.  But be conscious of the problem of the drive getting too hot.  Maybe, for example, don't just leave them on, plugged in all the time, but plug them in only while you're actively transferring data to and from them, and then unplug them so that they're not just sitting there, day in and day out, running with no active air flow across them because they really will overheat.  And he talked about three of them dying on him.  And it may very well be that they're just getting too hot.  I see that, we see that a lot.



LEO:  I wonder also if heating/cooling, heating/cooling is worse than just staying hot.  I mean...



STEVE:  Well, there is that, too.  You're right.



LEO:  You don't want to expand/contract, expand/contract.  It wears out bearings, there's metal fatigue, there's all sorts of issues that go along with that.



STEVE:  That's true.



LEO:  I just - they don't - it's all magic to me.  These things shouldn't work anyway.  They're way - the density on these things, the speed, it just doesn't make any sense at all.



STEVE:  I completely agree.



LEO:  Whoever thought that - Jerry Pournelle was talking about that on TWiT I think a couple of weeks ago where he, like you, like me, like anybody who'd been paying attention in the '90s, fully expected that by now we'd be using something else, solid-state memory or something.



STEVE:  Yeah.



LEO:  I mean, spinning drives?  Come on.  Terabytes?  You're kidding.  Okay, Steve.  Let's get to it.  Cyberwarfare, our topic.



STEVE:  So when I was looking around for some specifics, I ran across an interesting interview which the PBS show "Frontline" had done with John Arquilla, who's the associate professor of defense analysis at the Naval Postgraduate School.  And I'm going to share the beginning couple paragraphs of this because I think it sets the tone really nicely for this discussion.  And this interview was six years ago, in March of '03.  So John says:



"I came to the whole cyberwar business as a bombs-and-bullets guy.  I didn't know a whole lot about computers.  But when I was working for the Central Command in the last Gulf War" - which, you know, the first Gulf War - "it became very apparent to me that our biggest advantages came from what we knew and what our opponent didn't.  On the spot we cobbled together something called a Joint Surveillance and Target Acquisition Radar System.  This allowed us to know exactly where the opponent was and how to strike him.



"It occurred to me in the wake of that tremendous and lopsided victory of ours that much of what we did could have been held hostage to the disruption of any of those information systems.  That was the beginnings of cyberwar, the idea that the vulnerability of communications could cripple an advanced army.  What made it strong also made it weak.  Then it was only a baby step from there to think about this happening across our entire society, commercially and socially.  The crippling of information systems could have profound disruptive effects.



"What made that thought even more chilling was the notion that this power existed in the hands of a few hackers.  The disruptive power of this small group was growing by leaps and bounds.  This was something that we were vaguely aware of through the '80s, but really came into its own in the '90s.  What bothers me more than anything else, as I look at the data each year coming out of the various computer emergency response teams, is that hackers could do a tremendous amount more damage than they choose to do.  This says to me the threat is real.  We need to get our arms around it before people do get serious about making costly, costly disruptions a way of life."



LEO:  Wow.



STEVE:  And, you know, it's funny, what struck me when I read him talking about hackers could do so much more damage than they so far have chosen to do, I mean, we've talked about that often here.  I've remarked that, I mean, almost quizzically that these viruses only so far seem to exist for their own sake.  They're like little proof-of-concept things.  They're kids...



LEO:  Sure, but that's how you would do it; right?  If I were a bad guy, I would do a little testing first; right?



STEVE:  Well, of course and that's what happens is that, you know, kids with spare time on their hands...



LEO:  That's how they learn.



STEVE:  Exactly, they create these things.  Now, I actually think that that ends up being a huge - we'll in retrospect, when we look back on all of this development of computers and networking communications, that will end up having been a huge blessing because it is these relatively innocent proof-of-concepts which have raised our awareness of the problem.  I mean, that's what's created Symantec and McAfee and all the other antiviral, antimalware responses, is these things are vulnerabilities that exist in our machines where the vulnerability is being demonstrated without really being exploited.  Except I would say now that we're beginning to see that change.



We know that organized crime is getting involved.  And when I was talking about what this backdoor trojan does, this Buzus trojan that is using the SQL injection attack, well, it's actively hurting the people who end up hosting it unwittingly.  It's stealing their credit card information and their bank logon data.  So I guess we've - it's clear that we've crossed the threshold between purely benign - oh, I'm a virus, and I'm just here to replicate for my own sake - now we're beginning to see the exploitation of this.  But overall, in the context of nation states employing these sorts of things, if it weren't for the fact that we had this infrastructure of monthly patches from Microsoft and the idea that our systems are porous, essentially, they are not rock solid.



Software has bugs.  Bugs can be turned from things that crash your computer into things that actively exploit the porousness of our defenses.  That really creates an opportunity for further exploitation.  So as I was thinking about this, I thought, okay, we use this prefix "cyber," and we've talked about cybercrime and cyberterrorism, and now cyberwarfare.  And it occurs to me that it's the users of these, or the attackers who are employing these things - the thing that differentiates cybercrime from cyberwarfare and cyberterrorism really is the motivation.  So, for example, monetary profit I would argue would be behind cybercrime.  If we decide that, like, warfare is something that nations do against each other, then they're not trying to profit monetarily.  They're trying to in some way attack some other nation that they've decided they're at war with.



And in all of this case, there's this serious problem with attribution, that is, attributing the source of the attack.  When we were talking earlier about the malware that was found installed in the U.S. power grid control system, there was belief that it was - that some of it was Chinese, and some of it was Russian.  But of course...



LEO:  You can't tell.



STEVE:  ...their governments disa- you're right.  Their governments disavowed any participation, said no, you're crazy, it's not ours.  Well, and all we have is suspicions.  So there's a sort of a fundamental sort of plausible deniability about anything that's going on in this cyberspace.  And, for example, even in instances - we've talked about this before - where control systems for, like, botnets have been tracked down to specific countries, well, even when we find the control computers, and they might be in, for example, China, we don't know that there's anything that's China-based about where they came from because that control computer could be under the control of a computer located in an entirely different country.



So, I mean, it's interesting.  I've read articles about the fundamental problem of the Internet being this autonomous routing technology, which we've also often talked about, how a packet dropped anywhere in the world now onto a network with a given destination IP address will be picked up by the router on that network, which inspects the header of the packet, looks at the IP address, and forwards it on in the direction of its destination.  It doesn't care anything about the source IP.  Now, there are some filters, for example, on the ISP networks which prevent spoofing of source IP.  But that's within a given domain, and that's the exception today more than the rule.  In general you just drop a packet anywhere in the world into a network with a given IP, and that packet will end up at that destination, with no backtracking, no way of knowing where it came from, no authentication.  I mean, it's the strength of the Internet, the resilience of the Internet comes from this.



But it is - it also is a, I mean, from a standpoint of attribution of sources of attacks, sources of any type of malicious conduct, I mean, it's a huge Achilles heel.  And I can't see, having thought about this, any practical way of getting to a more secure technology without adding a massive burden to the way the 'Net works.  I mean, one of the reasons it works as well as it does, it's as inexpensive as it is, it's able to grow and be flexible and resilient, is that trusting nature.  If there was some sort of public key crypto where packets had to be signed, for example, in a succession of envelopes where a router would only accept a packet from another router if it was authenticated, then you could potentially have backtracking provability, but at a huge expense.  The packets would grow in size.  There would be this massive public key verification and signing needed at each step.  I mean, basically none of it would work nearly as well as it does.



So it's really difficult to see how we get there from here.  And of course the other problem that the Internet has is that to some degree the equipment that we're using are black boxes.  We fundamentally trust them.  We purchase them from suppliers and plug them into our networks.  It says "Cisco" on the front, for example, and it looks - it's got that Cisco green paint on it, and it looks like a Cisco router.  Well, we don't go in and inspect them.  We don't know for sure what's there.  And there have been instances of counterfeit Cisco routers coming from other countries that have questionable software installed in them, and in some cases known malicious software.



LEO:  Right.



STEVE:  So there we have what we think is a trusted appliance.  And upon inspection it turns out that this is a counterfeit.  And we also have seen stories where cryptographic equipment, we talked once about how there was cryptographic equipment purchased, I think from a company in Switzerland, which upon inspection turned out to have known backdoors installed in it, and other countries were buying this on the reputation of the seller, which was stellar.  But nonetheless, backdoors were discovered which would allow other nations, at the national, nation-state level, to access this data which some other nation was depending upon being impervious to decryption.  So that kind of cyberintelligence, or counterintelligence, is, we know, probably also going on.  We know that it has.  There's no reason to imagine that it hasn't.



So it seems to me that we could broadly divide attacks into - cyberattacks, cyberwarfare - into two broad categories.  There's stuff happening in the background, and there's stuff happening in the foreground.  By background I mean sort of like behind our backs.  Quiet, continuous, the kind of thing that is probably happening all the time.  And then foreground attacks are things like bandwidth floods, like huge denial of service attacks that, you know, that attempt to swamp networks.  My feeling is that those would have to be ineffective to some degree on an international basis.



For example, one has to imagine that the United States, and probably maybe all nations, have, like, a kill switch on their transnational Internet links.  That is, it must be possible, for example, for someone somewhere in the U.S. government to say, okay, take us off the 'Net.  Literally, you know, take the U.S. off of the global Internet.  Cut our transoceanic links.  Cut our satellite links.  We need to be an island for a moment.  It's just hard to imagine that that facility doesn't exist.  Which means that flooding traffic that was coming across those links would get blocked.  And so would, for what it's worth, you know, nonflooding sort of malicious traffic, which is operating in a much more stealthy, non-in-your-face, sort of just bandwidth attack mode.



On the other hand, one wonders if the bad guys, I mean, we being bad guys relative to other countries, other countries being bad guys to us in this - in a cyberwarfare scenario, if there would be other assets installed in country that could act on behalf of a nation outside of that country's borders, maybe in the event of it being cut off, or maybe using some other communications means to activate something that is sort of essentially a sleeper agent cyber thing that has been installed.  I mean, the problem with all of this is its presence is potentially unknowable.  It's just - it's like bad firmware installed in appliances that essentially are sleeper agents that are in country waiting to be activated and then do who knows what.



LEO:  I love that kill switch idea.



STEVE:  Yeah, don't you think there has to be that?



LEO:  I have to think that anything that we can think of at this point they are doing or have at least thought about; right?  I mean, they game this stuff all the time.  They are always looking at these scenarios.  So I presume that they're kind of looking at ways to respond to this.  And that's an obvious one, a kill switch.  Big red button for the President to push.



STEVE:  Yeah.



LEO:  Takes us offline.



STEVE:  As I was thinking about all of this, I mean, this whole sort of almost to me sci-fi dimension, the flipside of that is that we're becoming, thanks to the Internet, I mean, thanks to this Internet which represents this potential threat from cyberness, it's also really knit the globe together into in many ways a single economic entity.  And, I mean...



LEO:  Well, we are, I mean, economically we're all linked.  You know, if somebody brings our economy down, we know this, we just saw it, it hurts everybody.  And so this is war.  This is the same thing as a nuclear war.  This is a scorched-earth kind of alternative scenario; right?



STEVE:  Well, exactly.  And I think that's my point is that, I mean, we know that China is building its military.  I've seen many reports that talk about China's really putting an escalating effort into cyberwar potential.  And I think, okay, but wait a minute.  Who are they going to aim that at?  I mean, are they going to aim it at us?  The American consumer is supporting a lot of China's economy from  purchasing so much stuff.  And so how are we going to be at war with China?  I mean, to me that doesn't make any sense.  Again, it's - once upon a time, when national economies were only national, you could imagine lobbing bombs at each  other.  But maybe I'm just being nave here.



LEO:  Well, maybe it's a crazy idea.  But remember they had that nutty idea of limited nuclear war.  Maybe there's such a thing as a limited cyberwar, like a kick in the shins, where it wouldn't necessarily take everything out, but it might be like a little nudge with a threat, an implicit threat.  And I think if - I think there was a very clear and implicit threat with the trojans that were found in our electrical grid.  In a way maybe that was the point - not testing the technology, but to say we have the means.



STEVE:  There was also - I read a report that talked about a U.S. capability to infiltrate other countries' networks, which surprised me in its apparent effectiveness, and that our intelligence and ability to conduct cyberwarfare was so great that there was a concern that we would disrupt normal civil and civilian operations if it wasn't kept under control.  That is, it was difficult to constrain it to military targets, and that it could leak out and affect - essentially we don't have the ability to target as well as we need to.  We've got things that are a little too blunt.  But the idea that we even have such things is like, whoa, okay.  I mean, again, as a technology...



LEO:  I'd be more "whoa" if we didn't.  You know, I'd be more "uh-oh."



STEVE:  And, see, that's the other thing, too, is I wonder if some of this isn't the military saying to the politicians, well, what if?  I mean, you can "what if" anything and scare the bejeezus out of people, politicians, and say we need hundreds of millions of dollars to develop this, if not billions, because we know the other side is doing it.  It's like, okay, what?  Okay, I guess.  So they've got a bunch of hackers who are really good, and they're actively attempting to penetrate our networks.  Okay.  So we do the same?



LEO:  Yeah, I mean, I don't know.  Yeah, I guess we have to; right?  To me it's very much like espionage.  It's in the same kind of realm as espionage.



STEVE:  Sort of dark and murky, and no one's really sure.



LEO:  Well, if they're spying on us, and we presume they are, then we need to spy on them.  We have to have counterespionage.  I think it's very analogous to espionage, with the difference that it's a weapon.  So espionage can escalate to sabotage.  And cyberwarfare could escalate to sabotage in the same way, I guess.



STEVE:  Well, yeah.  And it seems to me, too, that the way this is being portrayed is as not a standalone attack.  That is, we wouldn't - no country would launch only a cyberwar attack on another.  But it would be part of a broader disruptive umbrella.  So, for example, if, I mean, inconceivable as it is, the U.S. and China were ever to come to fundamental blows, then I guess there would be a massive, I mean, from everything we've read, a massive cyberwar, I mean, component...



LEO:  Absolutely.  Absolutely.



STEVE:  ...to what was going on in an attempt to disrupt each other's systems.



LEO:  And it would be very effective.  I interviewed a guy many years ago, this must have been 15 years ago, who wrote a book on cyberwarfare, who said you don't do it by itself.  In fact, he used the grid as an example.  What you do is you disrupt the grid with both cyberwarfare and sabotage.  You blow up a few power plants.  But you also make sure that you're in the computers that would then switch them over.  You can create very easily with a few small incidents and computer hacking, you can take out the entire grid of the United States.  And that would not by itself be a problem unless you were then also launching an invasion or bombing or sending nuclear missiles.  So it's part of an overall strategy, not something that would exist by itself.



STEVE:  Right.



LEO:  I mean, if somebody took down the grid, that'd be bad.  But eventually you'd fix it.  It's only as part of something much more serious that you would even contemplate this, I think.  Now, if you're trying to undermine - now, then there's subtle things.  If you're trying to undermine our economy by creating - years ago I remember there were always rumors that foreign governments were printing counterfeit dollars.



STEVE:  Right, hundreds.



LEO:  The Soviets were doing that.



STEVE:  Yeah.



LEO:  And the idea being that they would then circulate them and create huge deflation in the U.S.  If there were an ideologue out there who said, well, we don't want to destroy the U.S., we just want to prove that capitalism doesn't work, nowadays they wouldn't print $100 bills.  They would just create false trades and derivatives, and there'd be a lot of cyber ways to do this.



STEVE:  They would do the things we just finished doing to ourselves.



LEO:  Unfortunately, yeah, they'd do what we did.



STEVE:  Yeah.



LEO:  So that's what I'm saying is I think there's a lot of different ways to use this and look at this.  This is a very interesting tool.  And I know for a fact that the U.S. has been very aware of this for at least two decades and has worked very hard to both do counterwarfare and to have our own initiatives; right?



STEVE:  And I think what must be happening, then, is that - first of all, I think that what you're discussing is sort of - or were briefly there - I would call cyberterrorism.



LEO:  Yes.



STEVE:  That is, more of a non-state actor that is using electronic information system...



LEO:  Well, it could be a state actor.  Remember the Soviet Union wanted to prove that capitalism was bad. 



STEVE:  Yeah.



LEO:  But it also could - so it could be state, or it could be...



STEVE:  Or independent.



LEO:  ...independent.



STEVE:  Yeah.



LEO:  I mean, the interesting thing about cyberwarfare is it doesn't require huge resources.  You don't have to build a weapon of mass destruction.  You don't have to...



STEVE:  No, and that's a very good point, too.  Because, I mean, when we were talking before the show, or I guess at the top of the show, one of the things that strikes me as odd about this is that there isn't anything for either side to inspect about the other.  The notion of us signing a cyberwar treaty, I mean, to me that just strikes me as ludicrous because how is anyone going to know that you're in compliance?  And why would anyone be in compliance?  I mean, it seems to be that everyone is taking this so seriously although, I mean, I'm trying to get my head around it because it's hard for me to take it as seriously as everyone else seems to be.  But given that everyone is taking it as seriously as they are, then no one is going to abide by a treaty where what you're entreated against doing can't be found, can't be proven.



LEO:  Yeah.



STEVE:  So everyone's going to just say, oh, yeah, we're all - we've stopped doing that.  Meanwhile, as you say, a small group are able to develop strong cyberweapons, potentially.  You don't need a huge industrial complex to do that.  And so I guess it's just that over time, as the Internet is becoming more pervasive, and it's not a curiosity, it's becoming, well, as we've been discussing recently, now having access to it is being considered a human, a fundamental right of being alive, or being able to have access to it.  Clearly countries are looking at it and saying, okay, well, we're not sure what it is, but it's something.  And we'd better understand what it is because it seems that other countries are working to understand what it is.  And it's going to be a component of national defense.



LEO:  Some people in the chatroom are making a point that a treaty might also have importance in terms of protocols for communicating, to say hey, this isn't our attack.  Or here's, let's, you know, it could be more than just we won't do it if you don't do it.  It could be that there's more subtlety involved.  It could be saying we agree not to do these kinds of things, or we should have some sort of early warning system that we jointly sponsor.  I imagine there are things to talk about; right?



STEVE:  I think that's a very good point.  John Markoff's article did only talk about sort of this mutual agreement not to develop.  I mean, what was talked about in the article was an agreement not to develop cyberwarfare technology.  Which struck me as like, okay.



LEO:  That's impossible.



STEVE:  Good luck with that.



LEO:  I don't think that's doable, yeah.  No, my reaction to that is, no.  Crazy.



STEVE:  Yeah.



LEO:  But I think there might be more that we could talk about; right?



STEVE:  Yeah.  Yeah.  And I'm not a pacifist, but I'm not overly aggressive, either.  And so I think talking is good.  Talking is better than not talking.



LEO:  Absolutely.  Well, very interesting subject.  I'm so glad you brought it up.  The notes, Steve's copious notes are online at GRC.com.  You can find those there along with 16KB versions of the show which Steve puts together - thank you, Steve - and transcripts, which Steve pays to have done by the great Elaine.  Elaine Farris; right?



STEVE:  Elaine Farris, yup.



LEO:  She does such a wonderful job.  [Aw.]



STEVE:  Our transcriber.



LEO:  So you can read along as you listen, or read instead of listen, or listen instead of read, or whatever you want.  Whatever you want to do.  While you're at GRC.com, look for those great free programs that Steve gives away.  Wonderful stuff.  We were talking on This Week in Google about your DNS program and how good that was.



STEVE:  Oh, cool.



LEO:  Yeah.  And also, of course, SpinRite, the world's best hard drive maintenance and recovery utility.



STEVE:  Yay.



LEO:  Yay, SpinRite.  Do it first so you don't have to freeze your drive.



STEVE:  There you go, exactly.



LEO:  And congratulations once again.  Best Technology Podcast.



STEVE:  Oh, that's so neat.



LEO:  Isn't that a nice feeling?  That's...



STEVE:  That is great.



LEO:  We'll send you the trophy.



STEVE:  Thank you, Leo.



LEO:  We will see y'all again next week.  We do this show live on video, and you can watch every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time.  I think, I've got to get my UTCs together, but I think if I'm correct that's either 1900 or 2000 UTC.  You can also download video soon from TWiT.tv.  And in a few weeks we'll be able to get podcasts of that and have it on the Roku box and all that stuff, too.  We're moving ahead.



STEVE:  And next week is Christmas Eve, but Security Now! will be there.



LEO:  Amazing.  How do you do it?  We'll see you then. 



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#228

DATE:		December 24, 2009

TITLE:		Listener Feedback #82

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-228.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 228 for December 24, 2009:  Your questions, Steve's answers #82.



It's time for Security Now!, the show that covers everything having to do with your security, your privacy, your safety online.  And here he is, the secure, private, safe Steve Gibson.  Hello, Steve.



STEVE GIBSON:  [Laughing] Hey, Leo.



LEO:  How are you today?



STEVE:  Great to speak with you again.  I'm great.



LEO:  Our holiday edition.



STEVE:  Yes.  And based on the weather on the East Coast, I'm glad we're both on the West Coast.



LEO:  No kidding, no kidding.  It's Christmas Eve.  And you are visiting your mother.



STEVE:  Yup, well, the whole family.  I grew up in Northern California and wandered down here following my strange career path.  And Mom used to, you know, back then we didn't have the Internet so she'd - we'd talk on the phone.  She'd say, "Honey, when are you going to come home?"



LEO:  Aw.



STEVE:  And I said, "Mom, you know, this is just the right distance."



LEO:  [Laughing] I know.



STEVE:  If the faucet's leaking, I'm sorry, I can't help you with that washer.  Go get my brother-in-law.  He'll grumble a lot, but do it.



LEO:  I'm safe on that count because Mom lived in Santa Cruz and then moved to Rhode Island.  I stayed here.  So she moved away from me.  But she lives two blocks from my sister, so...



STEVE:  Yeah.  And I like it that it's just a short little hop up the freeway.  I mean, not the freeway, just a short little hop up the - by plane it's like an hour.  And so it's close enough that it's easy and not a problem.  So, yeah, it works just great.



LEO:  Well, we are gathered today to answer listener feedback.  This is our 82nd listener feedback episode.



STEVE:  Yup.



LEO:  We're back on the even number, the mod-2 episodes for our Q&A.  And I bet you we have some questions about last week's episode on cyberwarfare.



STEVE:  We've got some interesting things there, of course.  One person gave me the perfect opening to talk about this ridiculous, the unmanned Predator unencrypted video mistake that the Defense Department made, so we'll talk about that.  Lots of interesting security news.  And I managed, believe it or not, I still managed to somehow find a SpinRite testimonial unlike any others.  So...



LEO:  You'd think we have heard them all.



STEVE:  You would have thought we would have done them all, but we've got a new one.  So, yup.



LEO:  Well, let's start with any security news or errata we want to correct?



STEVE:  Yup.  Well, once again, Adobe is in the doghouse.



LEO:  Uh-oh.



STEVE:  There is a publicly exploited, confirmed by Adobe, critical remote code execution vulnerability...



LEO:  Again.



STEVE:  ...again, in Reader and Acrobat, any versions current and prior.  So right now they're at 9.2 of both Adobe Reader and Adobe Acrobat.  And those and everything before are vulnerable.  The nature of the problem is a so-called "use after free" error.  We've sort of talked about that.  The idea is that many systems dynamically allocate memory as needed.  So the code'll be going along somewhere, and a packet will come in, and the program doesn't have anyplace to put it.  So the program asks the operating system, this is one of the functions of an operating system is to provide memory on demand when asked for by code.  So the code'll say, give me a chunk of memory, and the OS will say, okay, here's a pointer to the chunk of the size you asked for.  The program will then do whatever it does with it and use it for a while and then free it.  The idea is that it dynamically asks for it as it needs it.  And when it's through with it, it releases it.



And long-time listeners of - long-time listeners.  Well, long-time users will remember the old days of Windows where there were things called "memory leaks," where remember you'd, like, use Windows for, like a few hours, and you'd run out of memory.  There was, like, it would crash.  Well, what those old-style memory leaks actually were, they were programs that forgot to release the memory that they had asked for.  And so a program would just keep asking for memory, intending to let it go, to give it back to the operating system so that it could be reused.  But there was a bug in the program, and it would so-called leak memory, meaning that it ended up just consuming it but never releasing it.  So in this case...



LEO:  And in most cases modern memory managers and garbage collection and programming languages have taken care of that.



STEVE:  Well, yes.  Although in some ways that don't require the programmer to behave himself.  For example...



LEO:  Encouraging lazy programming, yeah.



STEVE:  Right.  For example, what'll happen in - as soon as we moved from the 16-bit world, Windows 3.1 and 95, 98, and ME, there was a chance to change the paradigm.  And starting with Windows NT, when a program terminated, the OS had the ability to robustly release any unreleased memory.  So frankly, the problem went away, not because all the programmers really got good about behaving themselves, but because the operating system started taking responsibility for their misbehavior.  An example where you can't do that is a server app.  Like all of the code that I write I don't - I haven't rebooted my server in years.



LEO:  Right.  No memory leaks there.



STEVE:  No memory leaks.  And, I mean, there have been problems where - in fact there was one a few months ago, toward the end of the work on the spoofability test.  It turns out that I was creating threads, and there were some thread handles that I was not freeing.  And so over the course of weeks I would see the server's consumption slowly drifting upwards.  And it's like, ehhh, you know, I can't live with that.  So I just put some time aside and reread my code.  And I said, yeah, you know, I don't think I'm releasing the handle of those threads.  And sure enough, added that one little line, and then the problem went away.  And I'm back to absolutely robust long-term operation with no memory leak.



So what happens is that, if programmers are not very careful, it's possible to re-use a pointer to memory which has been freed.  And that's the so-called "use after free" error.  In this case, in the Adobe products, there's a method in the code called newPlayer.  And there's an object called the Doc.media object.  And by exploiting the way it works, it's possible to allocate memory, put what you want in memory, that is, for the attacker to load their code in there.  But due to the nature of the way it's set up, you're not supposed to be able to execute the code.  And in fact you can't.  But if you release it to the operating system, saying okay, I no longer need this, and then use the pointer, you're able to access the code, which you would otherwise be prevented from accessing.  So it's a mistake which Adobe made.



And as I was looking at the details of this, and the fact that we talk about Acrobat or Adobe problems pretty much every single week now, I'm wondering what's this escalation?  And I think it must be that hackers have realized there is a body, a large body - and if you've installed Reader lately you know how large the body is - of code which wasn't very well written.  I mean, so they sort of painted a target on themselves.  You know, for a long time they got away, while everyone was aiming at Microsoft and calling Microsoft a big, bad, security vulnerability, Adobe was busily adding features and bloating up their software, not paying attention to security.  And so here now they've got - they've got code that they're late in the game in raising the security bar on.  And the attackers have said, let's take a look at this Adobe stuff.  Everybody else is finding problems; maybe we can.  And, you know, wherever you look there's a problem.



LEO:  It's a fertile field, isn't it.



STEVE:  Exactly that, yes.  Speaking of which, Mozilla is back in the game.  In this case, though, they do have a patch.  Oh, I forgot to mention that Adobe has indicated that they're going to fix this with their planned January 12th update.  And I'm not kidding, their advice is disable JavaScript.



LEO:  As usual.  As always.



STEVE:  As we've heard before.  However, this is not the first time our listeners have been advised to disable JavaScript in Acrobat Reader.  And in fact, you know, so it's very likely that it may still be disabled from the last time we told people to disable it.  If not, the fact is, JavaScript in a PDF reader really seems crazy to me.  I mean, I recognize that, yes, you could script your documents and make them do fancy things.  But I don't know anybody who does.  So here you've got this dangerous feature turned on which allows the exploitation of this, that you almost certainly don't need.  So it's very easy to disable JavaScript.  Mine's turned off on all of my installs.  That's just something that I do as part of setting up a new system.  And I would imagine our listeners who have done this in the past still have it disabled, so they're not in trouble.



LEO:  So it's enabled by default.  But once you disable it, it will continue to stay disabled in upgrades.



STEVE:  Correct.



LEO:  Okay.



STEVE:  And I'm trying to think now, when I was doing the research for this, there was a comic strip on a major newspaper site was being served from a third party.  And I can't remember, it was like King Comics or King something.  Anyway, the point is that users started complaining that their computers were getting infected from looking at these comics.  And it turns out it was this vulnerability, this Acrobat Reader vulnerability was being exploited.  The SQL injection exploit was used on this third-party comic provisioning server to install this malicious Acrobat content, this malicious PDF content, which was then being served to the unwitting newspaper as content from a third party and was exploiting this to take over people's machines and install malicious code.  So...



LEO:  As is often the case, you've got these blended threats where they take advantage of one flaw, this SQL injection exploit, to take advantage of another flaw.



STEVE:  Right.  So on the Firefox and SeaMonkey front, everyone who's been keeping themselves current will probably have noticed that the 3.5 progression of Firefox recently went to 3.5.6.



LEO:  Noticed that, yes.



STEVE:  And anybody who was still at 3.0 went to 3.0.16.  And SeaMonkey has also moved to 2.0.1.  There were seven sets of problems fixed, a bunch of things.  Multiple errors in JavaScript and the browser engine which can cause memory corruption and potentially remote code exploits.  A bunch of stuff with the media library.  The liboggplay and the Theora libraries for audio and video both have memory corruption and integer overflow problems.  They found out that there was a way that the location bar, the URL location bar could be spoofed.  And in fact the vulnerabilities were being reported, which would allow a hacker to place an invalid URL up in the location bar so it would look like a legitimate site, to obviously allow for phishing and spoofing attacks of different kinds.  There was a privilege escalation vulnerability, a problem with NTLM reflection, and then some scripting problems - Gecko ActiveX object exception messages and things.  All of that's been fixed.  But a bunch of stuff.  So and because, of course, this is open source, the full exploit details are available through analysis of the source.  So anyone learning about these problems can say, oh, you know, I'm going to go figure out how to exploit these because they've got access to the source code, just as the Mozilla team do.  And so this is one of those situations where, you know, you want to get yourself made current because we keep seeing instances where people are being - and we'll be talking about one next here - where people are still being infected by things that have been fixed.  And Mozilla says [chuckling], "If users are unable to install the update immediately...



LEO:  Yeah, yeah, here it goes.



STEVE:  ...they should disable JavaScript in Firefox until they are able to install the newest version of the browser."



LEO:  Now, you're just looking for those now.



STEVE:  I just - I Google that expression.



LEO:  Google "disable JavaScript."



STEVE:  That's how I supply my security news every week.  But importantly, I did want to mention that here we are on the eve of a new year, at which Mozilla has said they are going to stop moving the version 3.0 Firefox forward.  So this is time, probably.  Now, if something really horrible surfaces that was in 3.0.17, which I guess is what we're about to get from them, one wonders if they wouldn't fix that still.  But for our listeners it's probably time to move from 3.0 to 3.5 and continue following that into 2010 because they're saying they're going to suspend support for that.  And you can really understand why they would have to.



Clearly, there's a huge common code base.  The fact that they're always having to rev both together means that all the same problems are in both sets of code.  But it's just a huge amount of extra effort for them to continue creating 3.0 versions.  And 3.5 has been around long enough, as you pointed out to me when I was reluctant to move.  Elaine, our illustrious transcriber, however, reported that she went to 3.56 and something bad happened, like she lost all browser functionality and was having to fall back onto IE.  I haven't heard any other problems with it.  And I'm current across the board.



LEO:  As am I, yeah.



STEVE:  So whatever it is, it doesn't seem to be a widespread problem.  But I haven't heard from her since last week when she said ouch, she got bit by upgrading.  [All fixed!  Elaine]



LEO:  I get these questions on the radio show all the time.  And one thing I say is, anytime you install anything there's always the risk that the installation can go bad, and something gets screwed up, and you're going to have a problem.  It doesn't mean there's necessarily something wrong with the program, but some percentage of people that happens.



STEVE:  Well, and Leo, no two PCs in the galaxy are the same.



LEO:  Right, right.



STEVE:  It's just amazing this stuff works at all.



LEO:  I know.



STEVE:  I mean, it just...



LEO:  I say that every show.



STEVE:  I've got all these computers.  There's no two of them that are the same.  They've got different chipsets.  They've got different hardware.  They're different ages.  They've got different histories.  And they're somehow managing to mostly stay alive.



LEO:  We had a call on Sunday or something from a guy who went to Vista SP2 and just black-screened.  His computer just rebooted and won't start.  And I said, well, you know, there are millions of people who've installed this SP2 without it.  So it's something about the way your system was that was unique.  And there's no knowing what it is.  You can't predict it.



STEVE:  No, no, no.  And I was thinking about we were talking a week or two ago about the days of DOS, where you would install DOS, which meant three files.  And you'd add a memory manager, oooh.  And it had a config file.  Okay, I know what all that is so far.  Now it's just, you know.



LEO:  But at least then when something went wrong you kind of, you know, you kind of knew what was going on.  Now there's so many things going on in the background, so many processes, so many applications installed.  Just look, you know, launch your Task Manager.  There's...



STEVE:  No, don't do it.  No.



LEO:  There's dozens and dozens of things going on.



STEVE:  And I will say, being really particular about what's running can bite you sometimes.  Because one of the things that I'll often do is I will launch Task Manager and look at the thing just scroll.  And I'll think, okay, I've got to do something about this.  So I'll go in and go through a big bunch of weeding out process.  Or I'll go over to the Windows services panel and selectively turn off things that I just don't need.  And one of my favorites is to turn off DHCP because all of my IPs and my network are statically assigned.  And then what'll happen is I'll take a machine somewhere else and forget that I disabled the DHCP service because I didn't need it, and I didn't want it running.  And it's like, oh, why can't I get an IP address?  Oh, I know why.  But always, you know, there's a few cycles that are lost in remembering what it is that I did.  So it's sort of a mixed blessing.  We just sort of all limp along.



LEO:  It's just the way it is.  There's nothing we can do about it unless you want to go back to DOS.



STEVE:  Speaking of limping along?



LEO:  Yes?



STEVE:  The Conficker worm reports, "We're alive and doing well, thanks for asking."



LEO:  I'm glad it's - what?  It sent us a postcard?



STEVE:  Many of our listeners have asked, hey, whatever happened with Conficker?  Well, it just reared its ugly head, or heads, again.  It took down recently an entire seven-hospital maternity and continuing care medical network in New Zealand.  All 3,000 of the PCs within their network had to be turned off.  And the hospital's lab, the main hospital's lab is currently running at about 10 percent capacity.  And the hospital is only accepting patients in need of urgent care.  I should say "hospitals" because apparently it's a seven-hospital network plus some other ancillary labs and outpatient clinics.  And it ripped through their entire network and brought them down.



There are - reports vary, but there are somewhere between 5 and 15 million PCs infected worldwide.  And the number ranges that large because finding them and counting them is not easy.  But there's an interesting site that I've never talked about, ShadowServer.org, www.shadowserver.org, which tracks botnets and denial of service attacks and other things.  Really interesting.  If you look just down the left-hand column of the pages on the site, for example, there's like a botnet map that you can click on.  And they're showing, in real time, the size and location of botnets.  And they also have charts over days, weeks, months and years where you can see with some level of accurate reporting where these things are, where the botnets are, where the infected computers are.  You're able to break it down.  They've got charts and tables, you can break it down by country.  It's believed that the largest infections of Conficker, which, as I said, is alive and doing well, are in Asia, all throughout Asia, where between 10 and 27 percent of individual ISPs' total routable Internet address space is infected.



LEO:  Wow.



STEVE:  10 to 27 percent.  Now, what's interesting is, and this comes back to what we were talking about, about late patching, is that Conficker spreads using an RPC, a remote procedure call vulnerability in the Windows Server service that was fixed exactly 14 months ago, on October 23rd of 2008.  Here we are about on December 23rd of 2009, 14 months later, and Conficker is spreading using something that Microsoft fixed 14 months ago.  And it is now called by the security community without question the most prolific worm that has ever existed.



Now, in looking back, I got a big kick out of the wording that Microsoft uses to describe the vulnerability.  Microsoft's text reads, "This security update resolves a privately reported vulnerability in the server service.  The vulnerability could allow remote code execution if an affected system received a specially crafted RPC request.  On Microsoft Windows 2000, Windows XP, and Windows Server 2003 systems, an attacker could exploit this vulnerability without authentication to run arbitrary code.  It is possible that this vulnerability could be used in the crafting of a wormable exploit."



LEO:  Possible, huh?



STEVE:  Gee, that could happen.



LEO:  I'm just looking at the ShadowServer.org stats for Conficker population.  Going straight up, going straight up it's actually hit 7 million unique IPs in November.  I mean, yeah, it could possibly.  Might, just might.



STEVE:  You might have a worm would come out of this.



LEO:  Could be.



STEVE:  It could be bad.  We would recommend that you patch this.



LEO:  Could be.



STEVE:  And then they say "Firewall best practices and standard default firewall configurations can help protect network resources from attacks that originate outside the enterprise perimeter."  Well, okay.  That's standard boilerplate that all of their messages have on it.  And in fact that doesn't work in the case of Conficker because what we see happening over and over and over, I mean, this is, remember, a whole bunch of UK hospitals were taken down.  I don't know what it is about Conficker and hospitals.  But...



LEO:  Yeah, we gave them a hard time because we said why, why, why would a hospital have its important computing systems on the public Internet?



STEVE:  Well, yes.  And in fact remember that in one case it was the equipment running the operating theater.



LEO:  Yeah, was online.



STEVE:  Was having these problems.



LEO:  In this case, the New Zealand case, it was when they were updating.  So they probably weren't online until they said, okay, now, everybody go online, get system updates.  Which is just boneheaded.



STEVE:  Well, it's hard to say what's going on.  In a report from the government site which talks about this, somewhat tail between their legs, they say that their best guess is that an employee brought an infected machine into the network.  And that was my point about firewall configurations not helping because it's - Conficker spreads within a local area network where you don't have firewall defenses.  So, yes, you can have a strong perimeter that's protecting you from the public.  But anything that pierces that, whether it's a USB thumb drive or a laptop that's brought inside, anything, any way for it to get in, and then it just has a field day.  And as we see it just rapidly infects all the machines.



Now, here's what's difficult to understand, is how could - first of all, we don't know how long the infection's been in place.  So it might be that Conficker has been in this network but just wasn't noticed until recently.  And in fact in terms of remediation of Conficker it's actually causing a problem that Conficker is not more damaging because the fact that it just exists to exist, and we've talked about that, too, you know, it's typical of viruses and worms, they're still sort of at the proof-of-concept stage for whatever reason.  The fact that it's not really doing bad things means that there's sort of - it's difficult to commit heavy-duty resources and time to cleaning it out of networks where it's just not that big a problem for a lot of ISPs.  It's like, oh, yeah, well, so our users are infected, you know, good luck to them.  They're still paying their bills.  Yeah.



LEO:  Amazing.



STEVE:  Anyway, ShadowServer.org is a neat place to poke around for anybody who is curious about all that.  And I got a note from Troy Starkey, who said - his subject was "I wish to thank you for your software."  He said, "Hi, Mr. GRC.  Firstly, let me commend you on your fantastic software." Oh, yeah.  Okay, I thought I was reading the wrong one, the way it started.  "Let me commend you on your fantastic software.  It has repaired a few of my drives in the past, so I truly wanted to show my appreciation by finally purchasing your great software."  No, I think I am reading the wrong one.



LEO:  Oh.  You get so many, it's hard to choose.



STEVE:  Wait a second.  I can - yes, yes, yes.  Okay, sorry.  Peter Lilley says, "Hi, Steve and the GRC gang."  And the subject was *YAWN* -  YAWN in all capitals with asterisks bracketing it - "A SpinRite miracle so typical you'll think it's boring."  And so he says, "Hi, Steve and GRC gang.  I've been listening to the podcast for four-plus years, so I must have heard around 200 stories of SpinRite's miracles.  Today my sister called me in a panic as her old laptop would not boot, bluescreening on every boot, with NTFS.sys errors.  Of course there was no recent backup because there was, quote, 'nothing important,' unquote, on the laptop.  Oh, yeah.  Except the hundreds of photos documenting the lives of her twin five-year-old daughters.  While she sounded more than a little panicked at the idea of losing all her photos, I have to say I felt a serene calm as I reached for my SpinRite CD.  Feeling like I'd lived through this story myself...



LEO:  Very confident.



STEVE:  "...before just a few times.  So I popped in the disk and ran Level 2.  Boring.  SpinRite found problems, of course, and recovered the data.  Yawn.



LEO:  Naturally.



STEVE:  "The machine loaded Windows successfully on the next boot.  Yeah, yeah, like was there any doubt?  Steve, of course I'm joking, and I think this is marvelous.  You must swell with pride every time you hear yet another story that data recovered miracles are so commonplace.  Thanks for a fantastic product."



LEO:  There you go.  I don't think there's anything commonplace about it.



STEVE:  And thank you, Peter, for a terrific piece of email.



LEO:  It's just another day in the office of SpinRite.



STEVE:  Yeah, well, that's what we do here.



LEO:  We have 10 great questions from our great audience and that Steve...



STEVE:  We got good ones, yes.



LEO:  Reminder, if you want to ask a question, best way to do that is to go to GRC.com/feedback and ask that question.  And Steve will - Steve likes to research his answers and come up with the right answers.  So the best way to do that is just to go to GRC.com/feedback.  Are you ready, Mr. Gibson?



STEVE:  Let's do it.



LEO:  All right.  Question one from Tom Newman in Discovery Bay - which is up here in San Francisco Bay Area - how the bad guys keep one step ahead when it comes to malware.  Kind of topical for our Conficker discussion.  Hi, Steve and Leo.  I heard Steve mention a number of times about what Google and other sites are doing to detect and flag websites that can harm your computer with malware.  You mentioned a link from a listener that pointed to Google's Safe Browsing site that flags bad websites?  This past month I've received three messages through Skype saying that my Windows - through Skype, well, there's a little - there's something a little suspicious right there, I don't think Skype is warning you about things - that my Windows software was infected, I needed to download a software patch to fix the problem.  The messages pop up on my screen with "Software Update" as the title.  All three times I was running on my Mac.  So he knew it was bogus.  Each time I blocked the sender, but I still received more of these messages.  I did a Google search of the linked websites, the one with the "patch" software, and Google didn't show anything wrong with the site.  However, when I did a whois of the site, it showed me that they were created within one day of when I received the warning message.  Of course, it's a cat-and-mouse game.  The website in each message was different by one or two ending letters, and the Skype sender was also different each time.  By the way, that's a good way to detect a malicious site is it's kind of a random URL; right?  Because they're constantly changing these.



STEVE:  Yeah, like 318x.com that we talked about last week, it's like, okay.



LEO:  Yeah.  And then there'll be a 319 and a 319z and - the wording of the messages indicated they were all set by the message's indicated person.  The whois records indicated these sites were owned by someone in the Czech Republic.  So my point is you can't rely on Google or anyone else to keep you safe when it comes to malware.  The bad guys are always going to be one step ahead by changing website URLs, email addresses, et cetera, so you really do need to be careful and practice safe browsing.  He's written a blog article about this with a screenshot of the warning message on GeekNewsCentral.  By the way, this site is owned by Todd Cochrane, who does the Podcast Awards.  Thank you, Todd.  Congratulations on your Podcast Award, Best Technology Podcast, Steve Gibson.  And thanks for the great work you do.  That's Tom Newman who does the FrogView, I'm sorry, FogView Podcast from Discovery Bay, California.  His website is FogView.com.  And I will put, and I'm sure you will, too, a link to the blog posting in our show notes.  [http://www.geeknewscentral.com/2009/12/20/attention-malware-on-your-computer/]



STEVE:  Yeah.  Anyway, I thought that Tom's point was very well taken, and a good one.  It reminded me, though, of sort of what we understand already about antivirus software.  That is, you know, it's, as you mentioned, it's a cat-and-mouse game.  You can't be guaranteed that Google is going to flag bad things in the same way that you can't be guaranteed that your AV system is going to know about emerging threats that haven't been added to it yet, just as Google can't know about a website whose domain was registered the day before that there are probably no inbound links to so Google's bots aren't following along.  And still in both cases that doesn't mean, in the case of AV or Google's protection approach, it doesn't mean that they're useless because many bad sites do persist for a long time, just as many viruses and malware do persist for a long time.



And, you know, there is Google.  And, you know, we talked about Web of Trust reporting problems, and certainly the AV manufacturers are constantly fielding new instances of these bad things, updating their signatures as quickly as they can and really trying to stay ahead of it.  Certainly we know that a lot of effective blocking is done.  So all of this is very good.  It's just that security is a moving target, and software is porous.  And so while Tom is right, I would say all of this is good, and certainly better than not having it at all.  But certainly he's also right in saying we need to practice safe browsing.  And all the lessons that we've learned, like not clicking on links in unsolicited email, and also not believing that you need to fix your Windows software when you're running on a Mac is...



LEO:  And when you get the message from Skype.  No, in fact I say this on the radio show, again to quote the radio show, all the time, which is you can have antivirus software and antispyware software.  It's a good thing to have it.  But it's secondary line of defense.  You are the first line of defense, and your behaviors.



STEVE:  Yup.  And clearly, the fact that Skype is being used as the delivery mechanism is meant to catch out less sophisticated users.



LEO:  Who probably don't even know they have Skype running.



STEVE:  Exactly.  Or, I mean, again, many non-computer-savvy people are going to see a Windows Update box pop up and believe it.  And because, I mean, because Windows also pops up valid boxes saying similar things.  So, I mean, it's sort of a social engineering hack, you know, coming through a bizarre channel, i.e., Skype.  But certainly some percentage of users are going to say, oh, wow, I guess I have a problem.  Click here to fix.  So it'll catch people.  None of our listeners, but others.



LEO:  Not just Skype.  I mean, all IM clients are used this way.  Every time I log into MSN I get 30 of these.  And I get a lot of messages saying - from Pretty Girl 13 saying, oh, yeah, I'm all alone.  And usually, by the way, those are not what you think they are.  They're not a come-on to join some adult site.  They're really a link to a page that is malicious.



STEVE:  Yes.  Yes, they just want you to click...



LEO:  They want you to go to that page.



STEVE:  Just click this one link, just this one time, is all we need.



LEO:  So don't say, oh, I'm immune to this, let me just check this out, it's ha-ha.  No, no, no, it has nothing to do with Pretty Girl 13.  Here's a question that's a whole category of itself:  "I read that this is broken.  What's the story?"  Rob near Ottawa, Canada wonders, "How long does it take to crack SSL?"  Steve and Leo, I read an article on Mark Taw's blog [MarkTaw.com] - and I'll put a link again in the show notes, it's a long link.  I don't know if this post is accurate or just FUD.  The article claims that in 1995, SSL was brute-force cracked in 32 hours.  Now with today's computers it can be cracked in a matter of minutes.  Is that true?  Was it true?  Is it true today?  Could you explain this?  Help.



STEVE:  Well, it's an interesting blog posting because it talks about how SSL was cracked in a very short time 15 years ago.



LEO:  Yes.



STEVE:  And we've talked about the SSL protocol.  When I looked closely at the details of the posting, I saw immediately what was going on because they posted the key that was found that allowed them to decrypt the SSL connection.  And it was exactly 10 hex characters.  Well, a hex character represents four bits.  So 10 of those is 40 bits.  And those old-timers of us may remember when 40 bits was the maximum length of encryption that was exportable from the United States.



LEO:  That's right.  It was intentionally crippled.



STEVE:  Yes.  Encryption was considered a munition, and so it was regulated by the State Department, and you couldn't export it from the U.S.  So SSL could be forced to negotiate a symmetric key of only 40 bits.



LEO:  Intentionally crippled.



STEVE:  Yes, exactly.  And so remember that 32 bits is 4 billion.  32 bits is 4 billion combinations.  So we're adding only 8 bits to the 32 to get 40.  Well, we know that 8 bits in a byte, that's 256.  So it's going to be 256 times 4 billion, which is a big number, but it's 40 bits.  I mean, we know that's no longer strong enough.



LEO:  Well, and it wasn't then.  That was the whole point; right?



STEVE:  Correct.  Even then you could put - if you put a bunch of machines on the problem.  And so what I liked about this is it highlighted something, which is we've talked about the SSL protocol and all this fancy public key technology and certificates and certificate authorities and chains of...



LEO:  Webs of trust and, yeah.



STEVE:  Certificate chains, exactly, all of this.  Well, all of that ends up generating a symmetric key which is of a certain length.  And that's actually used to encrypt the payload.  So all that fancy protocol stuff is basically to authenticate the endpoints and allow them to negotiate a secret symmetric key.  Well, 15 years ago that was - could be, in fact, you weren't limited necessarily, but if either endpoint could only support 40-bit SSL, then they would negotiate down to that.  So back then the result was a symmetric key which was just too short.  I mean, it arguably then should have been a minimum of 64.  But it was deliberately crippled.  So that meant that if anyone then captured traffic, then you could do an offline attack by just guessing, brute-forcing that 40-bit key until you decrypted the contents of one of the packets, and then you'd have the contents of all of the packets.



So it's one of the reasons why we really do need to future-proof our technology.  I mean, for example, we've talked about this notion of what's safe today may not be safe tomorrow.  Of course everyone talks about quantum computing and the idea that we're going to suddenly have a huge jump in computing power.  It's not clear how that's going to happen or when.  But if you were doing packet captures, like back then, and you were capturing packets that were 40 bits encrypted, you could certainly break 40-bit encryption using today's technology just in a blink.  I mean, there'd just be no problem doing it at all.



But I like the idea also, it's not something we've talked about before, which is that the upshot of all of the fancy handshaking is a symmetric key.  And if that is not long enough, you can brute force attack it; and, you know, you get the contents of the packets.  So to answer Rob's question is to be very sure everyone understands, 40-bit encryption is no longer in use, cannot be used.  Thankfully, the laws changed in the U.S. that allow everyone to use much stronger encryption, and SSL now does.  And again, even though it doesn't sound like 128 or 256 bits is that many more bits, oh, baby, I mean, when every single bit doubles, and you double and double and double, you know, what, 256 compared to 40, so you're doubling 216 times, that's really a lot of doubling.



LEO:  So you couldn't - even, like, the NSA couldn't crack it at this point.  In anything like a reasonable amount of time.



STEVE:  Everyone, I mean, you ask any crypto person who's at state of the art, they do not believe that 256-bit symmetric key encryption is crackable by anyone.



LEO:  At all.



STEVE:  Everyone says, oh, well, yeah, but, you know, there's back doors and all these things.  It's like, well, we've gone over the AES algorithm.  We did a podcast on it, exactly how it works.  People with absolutely no agenda, mathematicians and cryptographer who would love to put a feather in their cap by finding a weakness, have studied it like crazy.  They've used reduced-strength versions to say, oh, well, instead of doing 14 rounds of encryption, if we only do five, then there's some things we can see where the bits aren't really being scrambled as deeply as they need to be.  And it's like, yeah, but the designers knew that.  That's why there's 14 rounds, because you very quickly lose all ability to track this.  So everything we know says that nobody can decrypt this if it's well-enough encrypted.



LEO:  Good news.



STEVE:  Yes.



LEO:  Fear not.  But it's funny because these articles, you know, bloggers can write anything they want.



STEVE:  Yeah.



LEO:  And this guy's not a security expert.



STEVE:  And he asked, is this FUD?



LEO:  Right.



STEVE:  The answer is yes.  I mean, that's the history.



LEO:  I wouldn't say it's intentional FUD, it's just it's misguided.  The guy doesn't know what he's talking about. 



STEVE:  Right.  But I did like it from a historical perspective.



LEO:  Absolutely, yeah.



STEVE:  Because it shows where we came from.



LEO:  But we get these questions, I'm sure you get them all the time, from people who say, I read an article that said, you know, whatever, you know, public key cryptography's been cracked, or WPA2 has been cracked.  And usually it's yeah, but that password or 40-bit key, that kind of thing.



STEVE:  Yeah.



LEO:  You listen to this show, you'll get the straight stuff.  But that's why we answer these questions.  Scott in upstate New York points out a security hole he says you could drive a truck - or fly a Predator UAV - through.  Steve and Leo, the people in the Pentagon should really listen to more Security Now!.  This was in the news.  It turns out that the video feeds from American UAVs - what is that?  Unintended Air...



STEVE:  Unmanned Aerial Vehicle.



LEO:  Unmanned Aerial Vehicle - are sent unencrypted to the ground.  Insurgents discovered this and are using $26 off-the-shelf equipment to intercept the feeds and plan their operations around the locations of the drones.  This flaw has been known since the '90s, but Pentagon officials assumed it wouldn't be exploited because, hey, those Afghans and Iraqis, they're stupid; right?  This is a clear failure of the security-through-obscurity model.  What do you think?  Scott, a loyal Security Now! listener.



STEVE:  Well, a bunch of our listeners, as you might imagine, posted questions about this, wanting some commentary.  And we're in a little bit of an information deficit, as one might imagine, because...



LEO:  Yeah, they don't want to talk about this.



STEVE:  ...the government is embarrassed.  I did hear an interview from someone who sounded like he understood the equipment.  And as I understand it, the problem is that there is a large network of ground-based receivers which are more than a decade old.



LEO:  Ah.



STEVE:  And the problem would be, while you could trivially, I mean, this is - I guess it's digital.  It's digital video because they're using a digital video satellite software.  There's some software made by a Russian company who is also, coincidentally, not happy that their software, which you can purchase for $25.99, that their software is being used.  The idea is their software is - I think it's called SkyGrabber or something.  The intention is that people who use satellite Internet links are vulnerable to having their satellite Internet monitored because the encryption is not very good.  And this stuff apparently decrypts this digital information - if it's even encrypted, and it may not even be encrypted.  It's just it's what's necessary to essentially demodulate the digital data and convert it back into digital.



So it turns out that the UAV planes are, while they do have encrypted command and control technology, so it is not possible for anyone to intercept and, like, take over the planes, for whatever reason they emit unencrypted video which is being received by these ground, very old, very inexpensive low-technology ground-based receivers, which collect the video and then relay it back to command central, wherever that is.  And I've actually heard, I don't know this at all for sure, I know that the UAVs are built by a company in San Diego, Southern California.  I've heard that they're being flown by pilots also in San Diego.  So, I mean, they're - literally we're talking remote control.  These things that are flying over Afghanistan and Pakistan are being controlled from halfway around the world.



LEO:  I heard Las Vegas.  But, you know, same thing.



STEVE:  Yeah, exactly.  Way, way far away.



LEO:  Yeah, yeah, here.



STEVE:  So here's the problem, is that they're inexpensive.  It's old technology.  But that's really also not an excuse because there's a new version I think called the Reaper which the government has just commissioned and ordered from the same company that also has unencrypted video.  So it really does seem to be a case of people just not paying attention to this and not thinking it's going to be a problem.



What happened was that some Shiite terrorists were captured, and their laptops were found to contain recorded video from the UAV over-flights.  And then that was - I think that was in '08.  So more than a year ago that happened, but nothing was done to change it.  And the problem is, the infrastructure that exists, the equipment which is installed can't be upgraded.  Sure, you could encrypt the feed on a UAV which costs an amazing amount of money.  And we know that putting even just a little symmetric cipher in there would be zero overhead.  The problem is, apparently the receiver needs to decrypt it.  I guess it's unable to forward it encrypted back to home base.



I mean, again, we have no idea of all the specific details.  But it does seem to be the case that for whatever reason the existing infrastructure can't take encryption without a huge reinvestment, which is much more than is in the budget right now.  And what's really dumb is that the various people who are embarrassed are saying, oh, well, we really don't think it represents a big problem.  It's like, okay.  Except that for people who know the terrain, the people on the ground who are adversaries, they're able to look at these video feeds and know exactly where the plane is flying over.  So that seems to me to be a problem.



LEO:  It's an interesting story, isn't it.



STEVE:  Yeah.



LEO:  Question four, Chris in Texas worries a bit about the free SSL certificates you might have seen:  Long-time listener, but can't seem to remember if you've covered this already.  There's a company called StartCom Ltd. that gives away basic SSL certificates.  Hey, that's cool.  I'm just wondering if these certificates are safe to use.  They're listed as a trusted authority in Firefox and IE and all the other browsers.  But free, what's the catch?  Is there one?  I've gone through the process of signing up in which they generate you a certificate signing request for authentication, not a username, and validated my domain ownerships.  Everything has seemed professional.  No process has varied from authorities I've used.  What's your opinion on these guys?  Your show has been part of my commute since the days of single digits.  Look forward to my feeds every week.  Thank you for all the wonderful information.  Well, there have been other free certificate authorities in the past.



STEVE:  Well, okay.  So here's the deal.  StartCom is a good little reputable certificate provider.  They do have their certificate authority certificate installed in all the major browsers.  So if you look at the root certificates that are installed in IE, StartCom is there, and the same thing for Mozilla.  So it is the case that their certificates will work, meaning that if someone were to use a free certificate from them for their server, then all the users who are using popular browsers would be able to establish SSL connections without any problem.



The only downside is if it were for some reason really important to trust this company, that is, to trust your connection, a user that is on a client, on a browser, might check the certificate chain and think, huh, this certificate was signed by StartCom.  Never heard of them.  Heard of VeriSign, heard of GoDaddy, don't know who StartCom is.  So remember that implicit in this is not only that we're using them for encryption, but we're using them for authentication of the server.  And that's important in this era of DNS spoofing and man-in-the-middle attacks and all that kind of stuff.



So I would say to Chris there's nothing wrong with these at all.  If their root certificates were not installed in all browsers, then you'd have a problem that some users of browsers that didn't have the StartCom root certificate wouldn't be able to make a connection because, you know, the signer of the certificate that's being offered by the web server wouldn't be known to the browser.  But it is.  So that's not a problem.



The only issue would be that, you know, if a user was concerned about the reputation of who signed the website's certificate stating that we verified all this.  StartCom's FAQ pages do talk about this and explain that, you know, they have a highly automated system which allows them to issue short-term, that is, one-year free certificates.  My guess is that their model is they're issuing certificates for a year.  That'll bring you back every year.  And maybe you'll decide, hey, this has been working for a few years.  I think I'm going to pay for a longer length certificate, where they will do a little more testing in order to justify the longer life of the cert.  But I think it looks like it's a fine solution.



LEO:  Great.  Yeah, I mean, there have been a number of these companies.  I mentioned Thawte, which was purchased unfortunately by VeriSign.



STEVE:  By VeriSign.



LEO:  Stopped doing the freebies.  But I've used free certs for email and stuff, for PGP, and I don't see anything wrong with that.



STEVE:  Nope.



LEO:  It doesn't cost them that much to do a cert, let's face it.



STEVE:  Costs them nothing.  It's only the bureaucratic side of verifying identities and domains and so forth.



LEO:  It's been my experience that free certs sometimes don't go through as many hoops to verify.



STEVE:  Precisely.



LEO:  Yeah.  Anton Wirsch in Tokyo, Japan, has some great info about San Diego's Sea World fingerprinting at the entrance.  This is not just Disney.  In late November I was home for the holidays and went to Sea World in San Diego.  After I had purchased my ticket I found at the entrance to the park they were electronically fingerprinting everyone as they entered.  After listening to your podcast, this concerned me.  Who was managing the fingerprinting data?  What security measures did they have?  What happened to all the data in case Sea World went under? 



I was instructed to a window where I could ask questions about the fingerprinting.  The young person at the window assured me the fingerprint is not stored anywhere.  He showed me a paper that explained what their system was doing.  The fingerprinting machine used the fingerprint to generate a number that was then mapped to the barcode of the entrance ticket.  This allows Sea World to ensure that only one person is using an entrance ticket.  If a person leaves the park, then wants to reenter, the fingerprinting machine should regenerate the same number, match the mapped barcode on the ticket.  My concern, though, is that I just have to take their word on that, that that's what they're doing.  I have no proof they're not sharing my fingerprint or storing it in their database.  I'd like to hear your thoughts on this.  That does make sense.  That's a reasonable way to use it.



STEVE:  Actually it's very cool.  I like that a lot.  I have several thoughts.  One is it's terrific that there is a window where you can go and ask your questions, and that they have a paper that they will show you that explains this.  I mean, it does tell me that Anton who listens to Security Now! is not the first person to feel a little sketchy about why Sea World wants his fingerprints.



LEO:  Right.



STEVE:  And their solution I think is very clever.  Essentially they're hashing his fingerprint.  They're taking details which are probably hopefully relatively static, and they're running it through a hash to essentially generate a digital signature.  But as is true of all hashes, that's inherently a one-way function.  That's what a hash is, when we've talked about it, and we've discussed hashing at length in the past, the idea being that you can take a document of any length or a blob of information, you run it through a hash, and it produces a unique value for that document.



Now, what's special about that is that you cannot get the document from the value.  So in this case you cannot get someone's fingerprint from the number that results from hashing the fingerprint.  Yet you can still use it for identification, that is, the same fingerprint should generate the same hash value.  And what you would like to do is to limit the length of the hash.  That is, if you took a fingerprint and hashed it to a really large multi-bit hash, then essentially you've got something as good as a fingerprint, that is to say, if no two people could ever be expected to have their fingerprints hash to the same value, then what you've got can still be used to uniquely identify you.  So that's not what you want.  What you want is a limited bit-length hash.



So, for example, imagine that the fingerprint were taken and hashed, and only 16 bits were kept.  You could take any 16 bits out of the, you know, a 256-bit hash.  So now what do you have?  16 bits, as we know, is 64K.  So now you've turned a fingerprint into one of 64,000 possible values, meaning that many people on the planet will - because there's a lot more than 64,000 people.  That is, everybody's fingerprint will produce a number, randomly distributed if it's a good hash function, between 0 and 65535.  So it's no longer sufficient length to uniquely identify a person, yet it is sufficient to disqualify a person who's impersonating someone else.  That is, the chance would be one in 65536, one in about 65,000, that an arbitrary imposter would have a fingerprint that hashed the same number.



Now, I don't know that Sea World is using a truncated length hash.  If they were, that would be very cool.  They'd get the seal of - they'd get the Security Now! seal of approval for their technology.  But, you know it's nice that we're seeing evidence of, you know, this kind of responsibility.  Because I think it's entirely acceptable that the fingerprint itself is not being stored, but it's being turned into something which is a unique token that represents the person.  That's cool.  And as for believing them, I absolutely would believe them.  I would say they've got a window, they've got a paper, you know, it seems unlikely that they're going to produce all of that and explain it all and then have it not be true.  If nothing else it would open them to a lawsuit.



LEO:  Oh, gosh, yeah.  You don't want to lie about that.



STEVE:  Exactly.



LEO:  Yeah.  Marv Schwartz, who's at the great Case Western Reserve University in Cleveland, one of the excellent tech schools in the country, reminds us about blocking lookups with the HOSTS file.  He says:  Steve, way back in Episode 42 you told us about blocking unwanted sites with a hosts file.  From what you've said in 227 - our last episode - wouldn't blocking 318x.com with a hosts file entry now be a very good idea?  If your hosts file blocked it, then 318x.com would never get control and therefore could not invoke chained malware.  Thanks again to you and Leo for a wonderful program which I enjoy without fail every single week.  And congratulations on winning the Best Technology Podcast Award.  You deserve it.  Best wishes for the holidays and New Year.  Marv.



STEVE:  Many of our astute listeners mentioned that.  So to all of them, and to Marv, I wanted to say absolutely right.  Remember that we talked about this, and this is an ongoing threat, and that it is as a consequence of that SQL injection a huge number of sites have been infected with a little embedded iFrame which contains a reference to 318x.com.  So the first thing your browser that encounters one of these pages will do is attempt to pull the contents from the URL contained in that little embedded frame, that little iFrame.  To do that it has to look up the IP address of 318x.com.  If you stick that in your hosts file, the search stops right there.  Nothing will go any further, and you are safe.  And lord knows nothing good is ever going to be at 318x.com.



LEO:  No reason to have that.



STEVE:  It's not like you're going to not be able to send email to your mom or anything for Christmas.



LEO:  But as you pointed out, it's very likely to be 3189.com or whatever at some point.  So it's only a limited, of a limited value.



STEVE:  Yes.  And in fact in the reporting, in the research that I did prior to last week there are variants of that already in existence.  So again, blocking - but which is not to say that blocking 318x.com is not a - would be a bad idea.  Putting it in the hosts file is a good idea.  I wish I had suggested it last week.  So I wanted to give everyone some props for saying, hey, that's a great place for the hosts file.  Absolutely is.



LEO:  Another Ohio resident, Matt, tells us of a new finger-based biometric technology, not fingerprints.  Steve and Leo, I heard discussions on your podcast about banks wanting fingerprints and various retailers now requiring them.  But where I work we utilize a slightly different system.  We sell memberships for various things.  We used to give out cards with pictures on them, but it costs too much money and time to have card printers and to print them.  So we have a new system that reads finger veins.  From what I've seen it works extremely well.  They claim near zero percent failure rate.  So now we don't have membership cards, they just scan their finger.  People don't have to worry that their fingerprints are on file, just their veins.  And what are people going to really do if they know the layout of your finger veins?  And he points us to m2sys.com.  They make the finger vein reader.  Well, this is similar to the palm readers, right, that you use at Level 3, or your provider uses.



STEVE:  Well, it's a different technology.  The palm readers are measuring physical, sort of external physical metrics.  They're, like, measuring the length of my fingers and the size of my hand and so forth.  This is actually, instead of a reflective technology, which is what a fingerprint uses, this is a transmissive technology.  That is, you put your finger into this thing.  And it uses near infrared light.  So the infrared light shines through your finger from the back of your finger down to the front, where there's an imaging array which sees it.  And hemoglobin absorbs in the IR.  So as a consequence of that, the imaging scanner can see the layout of your veins.  And this is actually a technology that's been known and used for years in a different way.  We've probably seen pictures of people in hospitals who have something slipped over their finger which is able to take their pulse and measure their blood oxygen by doing exactly the same sort of thing.  So I think there are even some things you can clip on like an earlobe in order to, like, keep track of pulse because as the veins throb with our heartbeat, that changes the amount of IR which is absorbed in the path through that chunk of flesh, whatever flesh it happens to be.  And it's very easy to get a pulse from that.  These guys are going a little further and actually getting an image from it.



So on their site they talk about the advantages of this.  For example, one of the problems with fingerprints is they, being on the surface, they are prone to damage.  You could get a - you could have a scar or cut yourself or burn yourself, you know, various things that affect the surface of your finger do not affect and do not change over time the layout of your veins in your finger, which they claim is every bit as unique as the print on the surface of your finger.  So I just thought it was an interesting little tidbit.  People may, if this catches on, see a different kind of technology in the future where they're sticking a finger into something rather than on something, the idea being that IR light will be shined from the back of your finger through your finger to pick up a vein pattern.



LEO:  Interesting.



STEVE:  Well, and it has the other feature that it isn't something that you leave on water glasses in restaurants and things.



LEO:  That's a good point, yeah.



STEVE:  Yeah.



LEO:  Yeah.  So it doesn't have any value in criminal investigation or that kind of thing.



STEVE:  Right.  From a forensics standpoint it's not going to help you.  But it certainly would, it's the kind of thing you probably know is going on because you're having to stick your finger in a hole in order to get it read.



LEO:  Question eight, Brian Kuner in Akron, Ohio - three Ohios in a row, Steve, did you do that on purpose? - just discovered that GRC's unreleased DNS Benchmark fixed a longstanding problem.  You haven't released the DNS Benchmark?



STEVE:  Nope, still working on the documentation.



LEO:  Oh, okay.  Because we have been able to download it and use it.



STEVE:  Oh, absolutely.  And it's done.  It's completely finished.  I just need to get all of the screens documented.



LEO:  Publicize it.  Just wanted to let you know that I'm a Security Now! listener.  Just listened to 226, heard you and Leo talk about the DNS Benchmark utility.  So I downloaded it and ran a test.  My router DNS tested very low on performance, even though I'm using OpenDNS.  I've been having a problem for a while where I open Firefox, and it has problems reopening about half the tabs I'd opened previously.  After looking at the benchmark results I changed my computer to directly point to OpenDNS, and quick testing has shown it solved my Firefox problem.  I could kick myself for not trying that before, since I should have known better.  Thank you for writing this utility and resolving a longstanding problem I've been having.  Why would a router be slow?  I guess just kind of a dumb router, I guess, huh?



STEVE:  That's exactly the problem.  And in fact I'm at a loss, complete loss to understand why routers have decided to take on the responsibility of proxying DNS on behalf of their LANs.  It's not like they're adding any value at all.



LEO:  Right.



STEVE:  They're not caching.  These things barely have four bits to rub together.  I mean, they are, you know...



LEO:  They're dumb.  They're dumb little boxes.



STEVE:  They're an empty plastic box with nothing inside.  And it's like, oh, well, we're going to...



LEO:  I'd like to help.



STEVE:  Yeah, we're going to offer DNS services to all the  machines on the network.  It's like, why?



LEO:  Do most routers do that, or no?



STEVE:  It seems to be on the rise.  It's a new thing.  Older routers didn't.  They would just pass through whatever DNS servers the ISP upstream was giving them.  Now, for whatever reason, they advertise themselves, their own gateway IP, as the sole DNS for the network.  Which then requires that they field these DNS queries.  And the problem with that is that there's some sophisticated logic that is employed by Internet-aware computers.  From the very dawn of time UNIX machines were on the Internet where, you know, the requirement was two DNS servers.



And of course then Windows and Macs and Linux machines, all Internet-aware systems, generally have pretty good logic.  They will recognize which DNS server has been working well and issue requests to that one.  Then, if it seems to not respond, they'll try again.  And if it still doesn't respond, then they'll send requests out to all the other DNS servers they know about.  And you can actually register more than just two DNS servers.  You can, if you use like the advanced configuration tab, at least in Windows, and I'm sure it's the case in UNIX and Linux and probably is on the Mac, you're able to equip your machine with more backup DNS servers.  In which case it'll send parallel queries to everybody else it knows about.  And the one that responds fastest then becomes - moves to the head of the list, and it'll be the one the system uses.



So it's very intelligent.  I don't think any of that is going on in these little routers that can't get out of their own way.  Who knows what they're doing?  I mean, they're apparently doing the least possible.  And what we discovered, one of the reasons I've ended up being so down on routers imposing themselves, is that I have an also as-yet-unreleased, but also finished, but not yet documented, spoofability test, which is very cool.  And the DNS Benchmark is part of the release of a whole suite of DNS things that I'm getting ready to do.  It crashes these routers.  That is, they get in the way.



And I'm just doing regular DNS things, and we found about 10 or 11 so far that are completely crashed by this.  Just by doing DNS lookups.  It's like, get out of the way.  They're offering no value.  I do not understand why it's become so popular.  No one that I've spoken to has even been able to offer a reason.  If it were caching, for example, if the router had some weight behind it, and it was using a good upstream algorithm, and for example providing caching services, then you could argue that other machines on the network could, when they want to go to Google, the router would know, instead of them having to cache it themselves.  But these things don't.  They're just pitiful little empty boxes of plastic.



So anyway, it seems like - I'm not surprised that Brian found that getting his router out of the way helped him.  And I thought it was worth sharing with our other listeners.  Probably by the time we talk about how we're able to crash routers, nobody who listens to this podcast will still be using their router as a DNS server.  At least I can hope that because it seems like a really dumb thing to do.  But it is the default configuration in many cases.



LEO:  Interesting.  All right.  Long one.  Take a deep breath.  This is from Ilari Kajaste - I'm sure I'm mangling his name because it's in Finnish.



STEVE:  You do a much better job than I would, Leo.



LEO:  Finnish, often the letters in the name have no relationship to the pronunciation, it has been my experience.



STEVE:  And fortunately Elaine also receives this PDF.  So she always spells everyone's name correctly, even if we mangle the pronunciation.



LEO:  She's good at that.  I'm going to say Ilari Kajaste - because I know "j" is "ye," is almost a "y," Kajaste - in Finland takes issue with fingerprints and other biometric data as identification.  He says, or she says:  You've been talking a lot about fingerprint privacy on Security Now! lately.  I'm a very strong privacy advocate myself, member of the local EFF - as am I - and all that.  But I can't help thinking there's something very odd in the talk about biometric data privacy.  The problem is this:  A water glass I handle at a restaurant, the door handle I touch when entering a store, the kiosk I use for ticketing for a bus, aren't these all valid places to surreptitiously pick up my fingerprint?  No matter how hard I protect my precious index finger's unique pattern, I'm essentially giving it out every day.  Same extends to all biometric data.  Well, not all.  I mean, I don't know how people would get your iris.



But with technological advances, DNA will become very inexpensive to analyze; right?  Iris patterns can be obtained from a distant photo - oh, I didn't know that - and so on.  By our simple existence we are essentially continually broadcasting biometrics to the world.  Considering biometrics is something that's supposed to be private, seems like looking at the whole issue upside down.



I think we really need to start considering biometrics - fingerprints, iris patterns, DNA, all of it - not as private, but rather as public data, safe to be broadcast even on one's own home page.  That way we, society, could learn to use them reasonably as we'd stop considering the data itself private.  Biometrics would still remain as valid use for identification for many purposes.  There is still the hassle with reproducing biometrics even if you have the data.  Duplicating a fingerprint from an image isn't all that easy.  Duplicating iris patters or DNA is much more difficult.  Especially when using multiple biometrics combined and verifying the read event by measuring say, body temperature and so on, fooling the biometric readers can become quite a problem.  It's a matter of balance, of course.  Biometrics should only be used where the cost of counterfeiting is higher than the benefit.  But the same goes for all security measures.  Sure, it becomes easier to fool the readers with technological advancements.  But the biometric readers will improve as well to counter that.  However, keeping biometric data private will only become increasingly difficult.  It's an uphill battle that should be abandoned.  I'd be very, very interested in hearing your thoughts on this, Steve, as I really appreciate your thought-provoking insights into security matters.  I've been listening for quite a while now.  I'm currently working my way through most of the Security Now! archives, truly an amazing resource.  Thank you, Ilari.  That's a good point, isn't it, Steve.



STEVE:  Yeah, he really, I mean, it is absolutely a good point.  The other thing I was thinking about as I was listening to you talk was voiceprint analysis.



LEO:  Sure.



STEVE:  There's another example.  I mean, you and I are literally broadcasting our voice all over the place.  So if we were ever depending upon the non-reproducibility of our voice, that would be a problem since there's an amazing amount of sample of our voice now.  And I like his point about the fact that it's not the knowledge of the biometric, it's its ability to produce it on demand.



You know, for example, if law enforcement needed a DNA sample, you know, they don't accept one from an envelope from you.  They say, "Say ah," and they swab the inside of your mouth, I presume, or at least that's what they do on the various shows that I've seen.  So they're getting a live real sample from the person that they've identified the sample as coming from.  So you have no ability to spoof the DNA that they're acquiring at that stage.



So everything that he said aside, am I going to post my 10 fingerprints on my website?  Uh, no.  It's, yes, it's the case that I'm leaving my fingerprints around.  But all of the security that we use is shades of gray.  You want to control access to your DNA and to your fingerprints, and now we know to the vein prints inside our fingers, to whatever extent possible.  Even though Sea World is hashing a fingerprint, I'm glad that our listeners, I mean, I don't think it's wrong for our listeners to be a little skeptical.  And I love it that they're asking questions, as clearly other people are, saying wait a minute, why do you want my fingerprints?  I'm concerned about privacy.  I don't want to be giving them out all over the place.  I agree with him that, you know, spoofing them is a problem.  But at the same time I don't think there's any substantial cost to minimizing disclosure.  I think that's still a useful strategy.



LEO:  Yeah.  Yeah.  Last question from Marco Silva in the Madeira Islands, Portugal.



STEVE:  It's nowhere near Ohio.



LEO:  No, nowhere near Ohio for the last two.  I love how, you know, just totally global our audience is.  He wonders about your unreleased, another unreleased program, the Router Crash Test, and wonders if router configurations could be changed.  Steve and Leo, I just ran the "Router Crash Test" on your DNS website.  Fortunately, my router didn't crash.  But if I run this test on a router that does crash, could doing so change the configuration?  You say that the crash "never results in any permanent damage to the router or other equipment.  Some routers reboot themselves and restore their service.  Others hang and need to be powered off for a moment and powered back on."  He's just worried whether this test could accidentally change the router's configuration on a router that has crashed.  I don't even know about this, by the way.



STEVE:  [Laughing] I'm behind.  I'm working as hard as I can to catch up.



LEO:  What the heck is this?



STEVE:  We will be doing podcasts about this stuff as soon as I get all of the pieces assembled.  What we discovered was that it was possible to crash routers.  And we then decided, "we" meaning all the denizens who hang out in the GRC newsgroups and I, when we were working on this about a year ago, actually.  And this all resulted from the Kaminsky DNS spoofing stuff that was in early '08 or mid '08, I guess.  So we then determined, well, we had a bunch of users whose routers were crashing when we were developing the spoofability test.  So we figured out how to keep that from happening, but then also what it was that they weren't liking.  And this is exactly what we were talking about a second ago, about the routers that are imposing themselves as DNS servers that were unable to field valid DNS queries and replies.



And so I created a separate test.  I made the normal spoofability test not typically crash routers, and then created a router crash test because as all of our listeners know, what starts out as a crash today is a remote takeover exploit tomorrow.  And the concern is that it might be possible to send DNS replies at routers that are proxying and take them over remotely.  So, I mean, we have no evidence that that's the case, but that's the way all these things start.



LEO:  Sure.  Anytime you've got a crash, that's the potential.



STEVE:  That's the potential.  And essentially we are able now to remotely crash people's routers that are imposing themselves in the DNS lookup process.  So to answer Marco's question, routers store their configurations in their firmware, in nonvolatile memory.  We can't, since we're crashing the router, we don't know for sure that we're not altering the configuration.  But it seems really a stretch that we would be, and we've never seen a situation where we have.



LEO:  But use at your own risk.  Don't just go around crashing your router for fun.



STEVE:  [Laughing] Correct.  And I do list the 10 or 11 routers that are known to be crashable at this point.  And every so often somebody reports another one.  It's like, okay, here we go.  I mean, they're just, you know, these things are inexpensive consumer appliances, and they're being pushed beyond, I think, what they should be doing by interposing themselves in DNS.  They're just - they're not adding any value for doing so.



LEO:  Steve, always a pleasure.  You make everything seem so clear.  And today I wasn't too frightened.



STEVE:  Good.



LEO:  Which is nice.



STEVE:  Good.  Because it's the holidays, Leo.  We don't want to frighten you and Santa Claus.



LEO:  Merry Christmas.  Have a great Christmas Eve and a safe trip to see your mom.  And we'll talk again next week.  For those who watch live, we're doing two shows next week because the following week I'm going to be out of town at CES, covering the big Consumer Electronics Show.  And Steve is committed never to missing an episode.  So two shows in our live taping next week.  We'll start early and go late.



STEVE:  Perfect.



LEO:  Thanks, Steve.  Have a happy holiday.



STEVE:  You, too, Leo.  Happy Christmas, Merry Christmas, Happy Holidays, all that, and talk to you next week.



LEO:  We'll see you next time on Security Now!.

 

Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#229

DATE:		December 31, 2009

TITLE:		The Rational Rejection of Security Advice

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-229.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo turn everything around this week to question the true economic value of security advice.   They consider the various non-zero costs to the average, non-Security Now! listener.  They compared those real costs with the somewhat unclear and uncertain benefits of going to all the trouble of following sometimes painful advice.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 229 for December 31, 2009:  The Rational Rejection of Security Advice.



It's time for Security Now!.  This is the show where you will be protected.  You will arm yourself against a sea of troubles and, by learning about security, perhaps end them.  Or at least prevent them.



STEVE GIBSON:  It will protect you whether you like it or not.



LEO:  Our security guru.  Actually the topic of the show today is maybe whether you - maybe not.



STEVE:  True.  We have the title of today's show, "The Rational Rejection of Security Advice," why it is not necessarily, that is, in fact, the argument has been recently made that in terms of the actual economics of the cost of following advice versus the cost of not following advice, that it is cheaper just to ignore us and disconnect your iPod.



LEO:  We shall find out.  I should say our security guru Steve Gibson is here from GRC.com, as always, host of 229 episodes now of Security Now!, entering soon our new decade.



STEVE:  Yes, this is our New Year's Eve episode, December 31st.



LEO:  Last presentation of 2009.  Well, this is going to be interesting.  I think I'm the poster child for the rational rejection of security advice.



STEVE:  Yes, we'll have lots of examples actually of, through the last four and a half years, of you saying, well, how big a problem is that really?



LEO:  I don't want to do that.  I don't want to do that.



STEVE:  I really don't - I like scripting.  I need my scripting.



LEO:  Ooh, boy.  All right.  Well, we'll see.



STEVE:  So it has been a quiet week since we last checked in with our listeners.  Only two little bits of news.  There's a new zero-day flaw that has - a zero-day vulnerability has turned up in Microsoft's web server, IIS.  And the security community is sort of at odds with itself about whether this is going to be a big deal or not.



The problem, it turns out, is that if the web server is configured to allow uploads of things like images, like JPEGs, to an upload directory - and, for example, you would do that if you had a Web 2.0 site where you were allowing people to, like, upload their photos or their thumbnails or whatever, like to forums or to photo posting sites and so forth.  The problem is that there is some technology that protects executability by file extension.  So, for example, you wouldn't want .asp, which is Microsoft's active server page technology, to be live in an upload directory because a user could upload code, essentially, active server page code, and it could be run.



Well, it turns out that there's a little bit of a parsing, a filename parsing flaw.  If you were to upload malicious.asp semicolon .jpg, that is, essentially you'd have the actual filename would end with JPG, then it would get through the filters.  And the way, unfortunately, the way Microsoft's IIS current server currently parses, the semicolon would stop the filename parsing, so the server would see malicious.asp after it slipped under its defenses and execute the code.



LEO:  Now, Microsoft says this is only if you're poorly configured.



STEVE:  Well, yes.



LEO:  Like you have to do a stupid job of configuring IIS.



STEVE:  And thus the argument within the security community.  Microsoft is saying not a big deal.  There are people who have said, oh, just wait.  I mean, there's enough IIS out there, you know, there's enough targets, it's a target-rich environment, that it only takes a few.  And if exploitable, then this is really bad.  So, and it also takes having an executable upload directory, which is really crazy.  I mean, no...



LEO:  Yeah, you shouldn't have that.



STEVE:  No sane webmaster would configure a server so that uploads of images and things that are supposed to not be executable would have execution rights.



LEO:  That's how my server got hacked, by the way, a couple years ago.  I had an open directory that you could upload to.  And the problem with PHP is it's executable.  So all somebody had to do was upload a malicious PHP script, and then he could run it.  And he found the open directory.  And so that was my fault.  Badly configured.  I don't have those anymore.



STEVE:  And the point is that it's easy to do.



LEO:  Yeah.



STEVE:  With all of the servers out there, all of the - one of the things that often happens is that a webmaster, in trying to get stuff to work, like if something's not working, his scripts aren't working, they'll quickly or temporarily make everything executable or writable, just to sort of see if that's the problem, intending later to go in and re-restrict the rights.  And, oops, what if they forget?  It's like they're so excited that they got it working, they then go off and, like, make sure it's working and do other things and forget that the way they got it working was to overly permit rights.  I mean, it happens so easily.



So anyway, it's expected that maybe a week or two from now - Microsoft's next Patch Tuesday will be January 12th.  So there's some window of opportunity.  If they patch this that quickly.  They haven't had a lot of notice of this.  So anyway, I just wanted to sort of put that on the radar.  It may end up getting patched, but nothing will happen.  Or two weeks from now when we are again recording - because we're doing a double recording today, recording our second episode for next week, which will be Episode 230.  We're recording that also since you're going to be off reporting on activities at CES.



LEO:  Yes, yes.



STEVE:  And my only other little tidbit was, I saw this, and I said, yeah, well, we knew this was going to happen.  Kindle's DRM has been cracked.



LEO:  Oh, thank goodness.  I'm glad about that.  I don't like DRM in any situation.



STEVE:  You know, I support Amazon.  I support the Kindle.  I carry it with me.  I love it.  I recently rediscovered the Financial Times, which is something I enjoy because it's got a nice out-of-the-U.S. perspective, and it's well written, and good reporting.  It turns out that when Amazon released a PC client, Kindle for PC, that was sort of the Achilles heel because now if this thing, this Amazon client is running on a PC, then all the very mature hacking tools come to bear.  We've got disassemblers, we've got decompilers, we've got debuggers, we could single-step, we can catch things mid-load, I mean, there's just a huge mature set of tools which, you know, don't exist for some random little piece of hardware with a funky eInk screen.  But boy, you bring the client into a PC environment and, suddenly, good luck keeping it protected.



And, you know, we've talked often about the fundamental impossibility of what Amazon wants to do.  You want to give people something which they in the privacy of their own homes can decrypt and read.  So the device has to decrypt it to display it, just like DVDs, just like Blu-ray and HD DVDs.  I mean, doesn't matter how much huffing and puffing you do, it's going to get cracked because the device in the user's control has to be able to decrypt it.  End of game.



LEO:  Yeah.  The key is built in.  You can't hide it.



STEVE:  Yes, has to be.



LEO:  Has to be.



STEVE:  Yes.  So again, what Amazon's trying to do, just like the DVD guys, just like Blu-ray and HD and everything else that will quickly be cracked, is fundamentally impossible.  So again, I - and as you said, you don't like DRM.  We would argue that, you know, I don't want to steal anything.  But it would be nice not in any way to be inconvenienced by DRM.  So that, if a book that I buy, I want to read on a PC, what if I want to read it on two PCs, or three PCs?  And they're all mine, and I'm the only one going to read it.  Well, the DRM starts to get in your way.  So anyway, there are two different people who are now claiming that they've cracked it in different ways.  



LEO:  Is it a practical thing, though?  I mean, can you now, you know, share your books?



STEVE:  Not quite.  But it'll, you know, wait three days.



LEO:  Right.



STEVE:  I mean, this is - it's over.



LEO:  It doesn't take long.  In fact, I'm surprised it took a year.



STEVE:  There was - actually, apparently it didn't.  There were some obscure scripts around that now we're seeing reference to.  One user who was posting to the blog of one of these crackers, he wrote, "I've been aching for someone to un-DRM Kindle for PC," this story goes.  He says, "A few of my textbooks for this semester and next are only available on Kindle and dead tree."  Whatever dead tree is.



LEO:  Dead tree is paper.



STEVE:  Okay.  Oh, got it.



LEO:  That's what we call - that's what we nouvelle digerati call...



STEVE:  That's the jargon for...



LEO:  ...things printed on paper.



STEVE:  Got it.



LEO:  Dead tree.



STEVE:  He says, "I have an eInk reader already, not a Kindle.  And so I don't want to be forced to buy a Kindle.  But the $10 Kindle book is so much better than a $30 paper book.  Not to mention it's reflowable, and I can more easily  make it fit my eSlick's screen."  So he has an eSlick reader, which is a cute little thing from the Foxit people, who of course are a well-known alternative PDF group.  And so he'd like to be able to, you know, he's got content that is currently Kindle-only, and he'd like to be able to read it on his non-Kindle reader.  Of course that's not what Amazon wants him to be able to do.  So this is - he's excited that this is on its way.  And you can imagine people being excited for different reasons.  So, anyway, I wanted to put that on our listeners' radar.



And finally, what I thought was initially the brilliant tip of the year, but I'm a little less sure of that now.  This is sort of in our errata category.  I ran across this when I was pulling together the Q&A questions for next week's Q&A episode, which we'll be shortly recording.  Levi Stoll in Denver, Colorado offers this cool sounding suggestion for cleaning keyboards.  He wrote, "I've been catching up on Security Now! podcasts after a busy year.  And I heard Leo talking about washing his keyboards in the dishwasher."



LEO:  That was a while ago, yeah.



STEVE:  "I used to do this regularly, but there's a better way.  Key caps, it turns out, are not built to withstand the high heat of a dishwasher..."



LEO:  Well, you don't have to use high heat, obviously.



STEVE:  Good point, "...and frequently warp as a result.  I now fill a container with four to six denture cleaning tablets."



LEO:  Oh.



STEVE:  "And use just warm water.  Add the key caps, and a few minutes later they come out all sparkly clean and disinfected.  Thanks for the excellent podcast.  I look forward to Security Now! each and every week, even when I don't have time to keep up."  So I thought that was interesting.  Now, I did a little poking around, thinking, okay, what are denture cleaning tablets?



LEO:  Yeah, what are they?  They're fizzies.



STEVE:  Turns out they're very aggressive.  And you might put your keycaps in, and they'd come out all without any writing on top of them.  So I'm a little less sanguine about suggesting that to people.  Apparently retainer cleaning tablets are much gentler.  For example, I ran across some dialogues with people saying, hey, you know, I've been using denture cleaning tablets to clean my jewelry, and boy did they come out all sparkly.  And apparently it's, yes, but it's also attacks gold and silver and weakens it and does bad things.  So it sounds like maybe those are on the extreme end of the cleaning strength.  But it's been recommended that retainer cleaning tablets are more mild and gentle.  So, anyway, I just thought was sort of an interesting little...



LEO:  Yeah, I mean, we used to - it's funny because in the early days of TechTV for some reason the producers just loved the mouse and keyboard cleaning segments.  We did a dozen of them.  And, I mean, it's like, they're $5 to buy a new mouse, $10 for a new keyboard.  Just buy a new one, for crying out loud.  And you pry all the key caps off, you have to take a picture first so you can put them back in the same place.



STEVE:  Yeah, otherwise you're in trouble.



LEO:  Yeah, believe me.  It's easy.  You think you know exactly where everything goes.  But some of those keys are kind of obscure.  And it's a pain to pry them off, pain to put them back on.  I put them in the dishwasher because it's quick and easy.  If it doesn't work, big deal.  I buy a new keyboard.



STEVE:  Yeah.



LEO:  But I've washed this keyboard.  The trick, as long as we're talking about it, is you've got to let them dry.  Don't be impatient to get it back in service.  Give it a week, on the edge, dripping.



STEVE:  Ah, yes.



LEO:  Because if it's not dry, you're never - it's never going to work again.  So I'm not recommending people do this, please.  Don't write me a letter saying, "You broke my keyboard."



STEVE:  Yeah, I mean, I'm looking at mine, and it just, you know...



LEO:  They're grungy.



STEVE:  It is.  It is.  I don't even want to...



LEO:  You want to dishwash it because just cleaning the key caps - it's not just the keycaps.



STEVE:  Yeah, I was going to say what's really bad is what slips down in between them and collects over time.  It's like, what?  It's like alien who knows what.



LEO:  Oh, yeah, it's microbial.



STEVE:  Hairs and skin and, yeah.



LEO:  It is, yeah.  And so you can just imagine what's growing in there.  And the truth is, in an environment like this, where we share this keyboard, you know, I have - there's other people, you know, use this studio.  Used to be my desk.  Now it's the studio.



STEVE:  If the keyboard starts walking off by itself, you know that it's time to...



LEO:  So this is the Apple Aluminum.  It washes very nicely.  I've done it twice.  It'll probably corrode.  But, yeah, don't do it in the hot cycle.



STEVE:  I'm going to have to - actually a project of mine coming up is to take the guts out of one of my keyboards because they draw so much power.  They, like, the house lights dim when I plug this thing in.  And because it's old school, it's more than 20 years old.  I love it.  It's clanky and wonderful.  But it's a PS/2 interface.  And what I want is not only to have it, give it a USB interface, but also somehow much less power consumption.  And so I'm going to end up just taking all the guts out and do my own little keyboard scanner so that I can plug it into a laptop when I'm not tied and tethered to AC power, and still have useful battery life.  So I'll spin off sideways and get that done here one of these days.  But I'm looking at this keyboard, it's like, oh, just it really does need - it needs some attention.  So I'll get around to that.  In the meantime, I got an interesting piece of mail with a strange title that caught my eye:  "SpinRite Cooks My Bacon." 



LEO:  I certainly hope that's not a new use of SpinRite.



STEVE:  From Phillip Nordwall in Bellingham, Washington.  He says, "I just wanted to say thanks for your great program, SpinRite, as well as Security Now!.  I'm a systems manager for a computer science department, and we have been using SpinRite since the middle of 2008.  We have used it a couple of times for data recovery on laptops issued to students.  But more notably, we PXE boot 108 machines every quarter for a SpinRite preventative maintenance run.  We have cameras in the labs.  If you're interested in seeing 108 machines concurrently running SpinRite, just send me an email.  Hearing all the testimonials for SpinRite saving people's bacon, I've decided that, when I retire one of my home hard drives, I'm going to attempt to use SpinRite to cook my bacon via a heated drive.  I thought you might get a kick out of SpinRite cooking bacon instead of saving it.  Thanks for all your work.  Phillip Nordwall."



LEO:  That's very funny.  PXE is the Preboot eXecution Environment.



STEVE:  Yes.  Which essentially allows...



LEO:  A lot of machines have now...



STEVE:  Yes, and probably all new BIOSes do, a way, basically, of booting over the 'Net.  And they've got it set up so that they've put together a bootable image of SpinRite which allows them then to boot SpinRite over the LAN.  And so, you know, not have to go running around individually booting.  I think it's very clever.  And they run it quarterly just as preventative maintenance, so that none of those machines in the labs have trouble.  And course every so often a student laptop does.  He did also in his note - I removed it - he gave me the licensing number and name because they have a site license.  So that they're all up and up.



LEO:  That's a very affordable and effective way to use SpinRite, actually.  That's clever.



STEVE:  Yeah.



LEO:  My laptop has PXE, and it uses it for the preboot authentication with the fingerprint scan.



STEVE:  Right.



LEO:  So it PXEs, and then it runs this, you know, kind of primitive scanner program before I can even access it.



STEVE:  Your new Dell laptop.



LEO:  Yeah, yeah.  And that keeps the hard drive locked.  Everything's locked unless you - I wonder, though, how, I mean, come on.  How effective is that fingerprint scanner really?  Can't you spoof it?



STEVE:  You know, it's funny.  I've been wondering, and so I have some of my fingerprints not registered.  It never gets fooled by them.  And I've had two experiences of, in both cases women, I don't know if it's a sexist fingerprint reader or not, but women who cannot, just cannot register on the thing.  I don't know if it's that their ruffles don't have ridges or what is happening.  But a gal that I have helped with security and set up - I chose a little Dell laptop for her and was getting her all tuned up and set up, a friend from Starbucks, just she'll - she's got kind of honkin' fingernails, which may be part of the problem.  And she's about as computer illiterate as anyone could be.  But she really cares about security.  So it's very important to her that no one be able to access her computer.  And the problem with her fingerprint reader is she can't ever make it happy.  And, I mean, I've had her, like, do it on the palm of my hand so I can see how hard she's pushing, and I've watched her do it.  And what's so strange is like when she's trying to train it.  She'll just stroke it, and it'll say, eh, no.  She'll do it again, eh, no.  I'll do it once, and it says, oh, good swipe.



LEO:  Dr. Mom has a theory.



STEVE:  Okay.



LEO:  Hand lotion.  Tell your friend to stop using hand lotion.  It fills in the ridges.



STEVE:  Okay.



LEO:  I bet you you don't use hand lotion, Steve.  I'm just guessing.



STEVE:  No, you're right about that.



LEO:  I don't see you putting on the hand lotion.  But women, all the time; right?  And Dr. Mom says what happens - I imagine what these things are doing is they see the bumps and ridges; right?  They're bouncing a light off of it.  It's almost like a CD reader.



STEVE:  I think that's actually ridges, but in a different technology.  I believe they're capacitive.  And so once again...



LEO:  But there's a rhythm to the whorls, how many ridges and how close together and so forth.  But if your fingers were swole up with emollients, maybe that would affect it.  I don't know.



STEVE:  Well, anyway.  So my experience has been, if anything, these things are too finicky and not permissive enough.



LEO:  Now, "MythBusters," now, "MythBusters" is not a scientific show.  A lot of people bring up stuff like this.  They bring up, oh, "MythBusters" proved - and it's a TV show, folks.  You know, it's entertainment.  It's not science.  However, they were able to spoof these fingerprint readers, they claim.  Now, the problem is that the technology's changed a lot.  The early fingerprint readers, you could spoof them with Play-Doh.



STEVE:  I was just going to say there's a difference in reader technology.  So what I remember from the "MythBusters" spoofing was that it was not the little strip reader like you and I have on our laptops.  I've got them on all my ThinkPads and use them and like them.  But rather those were the full, press your thumb on this plate kind of reader.  And, yes, those are easily spoofed.



LEO:  Yeah.  Well, I use it.  I don't - it's one of those things where, you know, I still have a password, too.



STEVE:  It's a good thing.



LEO:  It's a good thing.  Why not.  All right.  Tell me I'm not crazy.  Frequently I listen to you, Steve - and I have to say, you know, I've been here for every show, except for the scariest one which Alex Lindsay did.  The next week he said, "I'm never doing that show again.  I'm scared."  But I guess I'm used to it because I know how scary and dangerous it is out there.  But I choose, I think with intelligent forethought, I choose what security measures to take and what not to take.  Am I crazy?



STEVE:  I don't think you are.



LEO:  Whew.  Thank you.



STEVE:  What happened was, the thing that sort of put this on my radar is there's an annual, very small workshop which is invitation-only, very small and sort of intimate, called the New Security Paradigms Workshop.  The site is, not surprisingly, NSPW.org, New Security Paradigms Workshop dot org.  The most recent one was held September 8-11 of this year, 2009, at the Queen's College at the University of Oxford in the U.K.  And a paper was delivered by a Microsoft Research researcher, Cormac Herley, titled "So Long, and No Thanks for the Externalities:  The Rational Rejection of Security Advice by Users."



Now, to set this up a little bit, I'm going to - I want to read from the introduction page of the site because it gives you a sense for where the conference is oriented.  Their introduction says, "NSPW's focus is on work that challenges the dominant approaches and perspectives in computer security.  In the past, such challenges have taken the form of critiques of existing practice, as well as novel, sometimes controversial, and often immature approaches to defending computer systems.  By providing a forum for important security research that isn't suitable for mainstream security venues, NSPW aims to foster paradigm shifts in information security.  "In order to preserve the small focused nature of the workshop, participation is limited to authors of accepted papers and conference organizers.



"As a computer security venue, NSPW is unique in format and highly interactive in nature.  Each paper is typically the focus of 45 to 60 minutes of presentation and discussion.  Authors are encouraged to present ideas that might be considered risky in some other forum, and all participants are charged with providing feedback in a constructive manner."  So, you know, don't laugh at the guy when he's putting something out there that may be contrary to what you're used to hearing.



"The resulting intensive brainstorming has proven to be an excellent medium for furthering the development of these ideas.  The final proceedings are published after the workshop, giving authors an opportunity to incorporate feedback from the workshop.  The proceedings of NSPW are published by the ACM, a very well-known Association of Computing Machinery.  In 2009 we had papers on usable authentication, malware detection, file system access control, and secure routing.  We had papers that challenged the foundations of security practice by questioning how we analyze and evaluate security problems."  And here's the kicker.  "We even had a paper that argued that users were potentially right to ignore standard security advice.  The full proceedings for 2009 and past years are available here.  Enjoy."



And so any listeners who are curious about other aspects of this, NSPW.org has everything there.  Click on proceedings.  There's a list of all prior years, 2009.  There's a list of the papers from this year.  And specifically, this one by Cormac Herley, which when I learned of it a couple months ago, it's sort of just been in the back of my mind, thinking okay, the guy brings up some very good points that we have to discuss because they're issues which have always sort of been in the margins of our discussion.  And Leo, as you said, you're often sort of taking a bit of a contrarian position, saying wait a minute, you know, how big a problem is this really?



So Cormac takes a look at - from the whole spectrum of advice sort of stuff.  And these are, not coincidentally, here we are four and a half years into the podcast.  We've already covered everything pretty much that there is to cover.  But he looks at passwords, threats from phishing, and certificate errors, SSL warnings that users get.  And when we talk about sort of the economics of following advice, well, obviously we're not talking necessarily in dollars and cents, although in his paper he does go into quantifying the cost in terms of, like, twice the minimum income of a random person and over the course of a year how much time would be spent in doing something versus what the cost would be to not doing something.



So the idea is, in terms of economics, we mean like sort of academic economics, where there is arguably a non-zero cost for following advice.  And of course a few weeks ago I talked about the conversation I overheard at Starbucks where there was this executive with his coworkers explaining to them the lengths he goes through to avoid the IT department's password policy.  Passwords expire at his company after not apparently very long, and he finds it very annoying that he's being asked to change his password constantly.  So he's so determined that he knows better than the IT department about the safety or lack of this policy that he'll go through five other passwords in a row in order to get back to a sixth one because the system remembers the last five and won't let him use any that he's used recently.  So they've got a password policy which they're attempting to enforce, but in this case this guy believes he knows better.  That is, the hassle that he's being put through, the cost from an economic standpoint, the cost to him of being forced to really change his password is far higher than he believes the expense would be of...



LEO:  Getting hacked.



STEVE:  Getting hacked because he's managed to fight to hold onto the same password forever, essentially.



LEO:  Well, that makes sense if it's, you know, your access to your New York Times page.  Maybe not if it is to your bank.  So different sites have different values.



STEVE:  Well, yes.  And in fact one of the things that I've noticed is I've seen websites where five years ago - Amazon is a perfect example.  I've been an Amazon member from, like, day two when I heard about it.  It's like, oh, this sounds wonderful.



LEO:  Me, too, yup.



STEVE:  And I confess my first password was weaker than weak.  But back then



LEO:  It didn't matter.



STEVE:  ...at the dawn of the 'Net, it was like, eh, who, you know, there's you and I and four other people were on the Internet, Leo.



LEO:  Exactly.



STEVE:  And I trust you.  So, and besides, if you want to buy a book, that's fine with me.  So when, oh, I know when it was, it was when I was signing up for S3 stuff.



LEO:  Yeah.



STEVE:  I wanted to mess with Jungle Disk and S3.  And so I needed to sort of, like, refresh my account.  And I tried to just log on as me because Amazon already knew me, and it said, oh, you've got to be kidding.  That's your password?



LEO:  Well, that's good, that's good.



STEVE:  And so what happened was over time their policies changed.  Now, what probably - if you peel back the covers you can imagine that there were probably people getting hacked because there were people who had, I mean, my password wasn't really bad compared to what it could have been.  And in fact, if I think about the absolute lack of enforcement then, people probably had a password of, like, "X," literally.



LEO:  Well, you saw - I don't know if you saw, but Twitter just recently banned 300 passwords.  They said you cannot create a Twitter account if you use "sex," "12345," "ASDFG," all of the obvious passwords.  In fact, it's worth looking at that list of passwords just so you understand what a crappy password is.



STEVE:  And we also know that that was a consequence of Twitter being hacked.



LEO:  Many times.  And in fact its own people being hacked.



STEVE:  And so my point, and you just made my point for me, is that what must have happened is that Amazon was having problems with the fact that they weren't enforcing stronger passwords.  And so they didn't retroactively suddenly surprise me one day and say you can't use this anymore.  Maybe they would have if more time had gone by.  But instead, when I attempted to do anything that gave them sort of an in, they said, you know, we're not good with that anymore.



So in terms of policy, and we've talked about all this before, we know that longer is better because it makes them less susceptible to brute force.  We know that varied composition is better - upper and lower case, numbers and letters.  We know that things that are not in the dictionary, like the list that you were just running through, not simple words.  But then there's other policy advice, like don't write it down.  And we've talked about, for example, how Bruce Schneier takes issue with that, saying the problem with a don't-write-it-down policy is that while writing it down exposes it to discovery, it encourages it to be weak because, if you can't write it down, you're going to choose something easier to remember.



LEO:  Not writing it down encourages weakness, yes.



STEVE:  Yes.



LEO:  Right, right.



STEVE:  Exactly.  So and then of course don't share it with anyone is sort of obvious.  Then changing it often is the other sort of standard policy is, oh, how long have you had that password?  You should change that.  And it's like, okay, obviously that's sort of common sense.  And then, finally, no reuse of passwords across sites.  We have often talked about that it's better to have different passwords for different sites, the vulnerability obviously there being, if some employee at one of those sites went bad, or if a keylogger logged you into one site, it might say, hey, maybe this person - or the employee might say maybe this person is using the same password everywhere else.  Let's go see if we can log on with their credentials in other places.  So obviously not reusing a password is a good policy.



LEO:  You know, I recently started using - and you've talked about this, too.  In fact, this is our recommendation is these password wallet programs where you kind of have the best of both worlds.  In fact, they'll even generate tough passwords for you, store them.  You have one master password which you can remember, so everything's protected.  But you have different passwords for every site.  So I started using one called - which I love and I recommend - called LastPass.  I use it because it's cross-platform.  But get this.  They have - they've obviously listened to the show.  In fact, I'm going to say hello.  Because they have two-factor authentication - one with YubiKey, works with YubiKey, they're running YubiKey server; the other with Perfect Paper Passwords.



STEVE:  No.



LEO:  Yes.  You can print out exactly what you do, what you recommend, a sheet of paper for your second factor.  You put it in your wallet, cross it off.  It's as if they were listening to the show and tried to design the perfect password storage system.  I just love it.



STEVE:  I'll check it out.



LEO:  LastPass.com.  It's free.  If you want the pro version it's a buck a month.  And I've been using it.  And I put it on every browser, on every system - Linux, Mac, Windows, Droid, iPhone, everywhere.  It's really great.  And they obviously are Steve Gibson fans.



STEVE:  So having run through what we all agree from, I mean, in fact, passwords were the first three or four episodes of our podcast four and a half years ago...



LEO:  Oh, yeah.  Oh, yeah, the most important thing, yeah.



STEVE:  Having run through - and of course this is what most people, you know...



LEO:  It's the first line of defense, yeah.



STEVE:  ...when they're using, well, it's the first issue of security they encounter when they're on the Internet today.  No matter what it is - email, any kind of an online account, whatever - that's the way we protect it.  So backing away from this for a minute and taking an okay, wait a minute.  Now, we're not talking about the listeners of this podcast.  We're talking about our moms, or girlfriends, boyfriends, people who are not listening to a security podcast because they're fascinated by the mechanisms and machinery and, I mean, are curious about what can go wrong, but users who just want to use the Internet; someone who wants to be safe, who's aware that there are dangers, but isn't into it for the sake of being into it, but just wants to be okay.



So here we give them all of this criteria.  It's like, oh, well, here's what you have to do.  And your password's got to be like this, and it's got to be like this, and you have to change it all the time, and you can't use the same one.  I mean, at some point they're like, whoa, hold on a second.  I can't use - you're telling me I have to have a really fancy password with different upper and lower cases and numbers and letters mixed in.  And I can't write it down.  And I have to change it often, and I can't use it in multiple places.



And so if we take the contrary position, it's like, okay, what's the likelihood of there being an exploit, of there being a problem with this?  And what Cormac does in his paper is he challenges this advice, not saying, oh, yes, it wouldn't be wonderful if everyone did this, but saying what's the cost of doing it?  And the point is the cost is not nothing.  If I were to try to explain that to Mom, the feedback I'd get from her as she rolls her eyes is, "Honey..."



LEO:  Get real.



STEVE:  Well, "I'm just going to unplug the computer."



LEO:  Right, right.



STEVE:  And so really, if we look at changing it often, okay, so what's the risk?  The risk is that somewhere far in the past our password would have been captured, but it wouldn't have been used until now.  So the not changing it often creates a window of opportunity.  But if the password is captured and immediately used, which is probably more likely, then changing your password often provides you no benefit.  Right?



LEO:  Okay.  Let me think about that.



STEVE:  Because it would only be if you changed it, like, every few minutes...



LEO:  Right.



STEVE:  ...that someone would have to fit within a very small window in order to exploit the fact that you had had the same password.  So again, the changing it often, the argument against that is that most times the password is going to be captured and probably used quickly.  So it doesn't really matter how long you've had the same password.  The only place where that would matter would be if a year ago the password were captured and it hadn't been used until now.  So that changing it anytime in that year would have thwarted the attack.



So you could say, okay, that's dumb.  I mean, changing it often is, first of all, a real pain because if you just got comfortable with - it's like when I lose one of my credit cards because of online fraud, it's like, oh, I had just memorized the darn thing, and now I've got to go memorize it again.  So changing your password is very expensive from a user argument, from a user cost, and it's not really clear.  It's like should you?  Yes.  What happens if you don't?  Probably not a big problem because the nature of the attack is not using real old passwords.  That just probably doesn't happen.



LEO:  Right.



STEVE:  Now, how about the no reuse of passwords across sites?  So we talked about what the cost there is, or the exploit is, some sort of cross-site abuse where something sees your logon credentials, something or someone, a keylogger or malware or a trojan or something, or an employee at a site that's a bad employee at a site sees your credentials and then specifically tries to reuse them on other sites.  Could it happen?  Yes?  How likely is it?  One of the problems, and it's a really good point that Cormac brings up, is we don't know the answer to these things.  We don't really - we in the security community don't have real quantified research about the nature, the size of the risk.



LEO:  That's interesting.  We're just assuming empirically.



STEVE:  Theoretically, see, this could happen.  Oh, no.  It's like, no one can argue that it could happen.  But the beautiful, like, rational response to, like, if someone were trying to, like, push too far is - and this is your response, Leo - well, okay.  How likely is that?



LEO:  Right.  Well, you have to have that information to weigh your response; right?  



STEVE:  Yeah, you absolutely do, in order to know whether the cost of following the advice is worth the expense of not.  Now, he raises another really good point in this whole domain of phishing.  And I've talked often about how really annoyed I am that Mom has to deal with URLs.



LEO:  Right.



STEVE:  And of course phishing is really, if you think about it, really tough to train a non-computer user about.  First of all, we have to tell them, okay, IP numbers in the URL, those are probably bad.  So if you click on something, and it's 29.243.16.71, you know, to make up a random number, it's like, oh, you know, you can't tell anything about where you just went.  So that's scary.  That's probably bad.  Except that they might see 192.168 dot something dot something.  Their local network IP could appear in various contexts when they're talking to their local machine or another machine on the LAN.  So then it's not bad.  So that's confusing.



Then we have the problem of a link, for example in email, that says www.paypal.com, but that's an HREF in HTML where it's actually where the URL associated with what's visible, you're seeing www.paypal.com as a clickable link, but the HREF is www.drevil.com.  So now we have to say to them, oh, well, you can't trust what it says, what the link says.  That's like, oh, what?  Well, how can I ever click on anything?  It's like, well, no, you can't.  Just don't.



And then there's the problem of www.paypa1.com.  Looks like PayPal to a cursory view.  But it's a number one.  And so we have to explain to them, okay, that's not the same.  So look carefully, make sure every letter is what you expect, not something that looks similar.  Oh, and by the way, www.paypal.ru, that's bad, too.  You know, there is no PayPal in Russia.  You can pretty much guarantee that you're going to have a bad experience if you go to PayPal.ru.  So then we have to explain to them that the com is important.  But then the next thing over, the second level domain name, is really where you're going.  Except there's Amazon.co.uk.  That's good.  But BofA.co.uk, oh, that's bad.  So, I mean, think about how incredibly confusing the knowledge of how to parse a URL, I mean, we all, the listeners of this podcast, take it for granted.  We know how to read this.  Oh, and another favorite of mine is if we tell them that you have to read from the right to the left because of course URLs, you know, we have com as the top level domain, and then the second level domain is where you're going.  So, for example, we explain that www.paypal.com.drevil.com...



LEO:  Is not the same.



STEVE:  That's bad, too, because that's really DrEvil.com, and it's a machine down the tree from him.



LEO:  But you're right, we shouldn't have to have URLs.  In fact, Tim Berners-Lee said I never expected anybody to be using URLs.  This was for machines, not humans.



STEVE:  And then - I'll wrap this up.  Because if then they're presented with www.drevil.com/www.paypal.com, now they're thinking, oh, good.



LEO:  It's fine.



STEVE:  It's fine because it's PayPal.com on the right.  But no, that's behind a slash, so that's a directory of DrEvil.com, and you're in trouble again.  So, you know...



LEO:  It's not commonly understood.  You and I and everybody listening to the show knows it.  But it's not common.



STEVE:  And I'm exhausted from just giving those examples.



LEO:  I know.



STEVE:  I mean, there's so many ways this can be wrong.  And we're trying to tell users, oh, check to make sure where you are.  You cannot, I mean...



LEO:  Yeah, you can't.



STEVE:  ...it's not reasonable to tell where you are.  And then I love the point that he makes about SSL certificates, which is virtually 100 - and I know I just said the word "virtually."  I've been told that I use the word too much.  It's like, okay, that's the one I need right here.  Virtually 100 percent of certificate errors are false positives.  That is to say, if you think about...



LEO:  What?



STEVE:  First of all, phishing sites don't use certificates.  So the only time you can get a certificate error is if there's a certificate in play, and something's wrong.  You don't get a certificate error on a non-SSL page.  And phishing sites just don't bother with HTTPS.  All the studies have shown that users don't look.  Users don't understand the difference between what's the content of the page and what's on the browser window dressing, the so-called "chrome" of the browser.  Users don't understand that a lock showing on the page is different from a lock down in the tray.



LEO:  No, yeah.



STEVE:  Or in the URL.



LEO:  I don't even know how you'd explain that to somebody.



STEVE:  Exactly.  Again, my model is my mom, like the person who wants to be poking around on the 'Net, and I want to keep her safe.  And she's already signed off after, like, a minute of this.  And the other thing is, it's funny because, I mean, when I approach somebody who is a neophyte, and they say to me, they ask me, okay, well, what do I need to do to be safe?



LEO:  I don't know.



STEVE:  You know?  There isn't an easy answer.  The fact that I don't even know how to answer that question...



LEO:  Wise up.  But that's not a good answer; you know?



STEVE:  No, because here we are four and a half years into this, and we're still talking about new stuff that's coming along.  So on the SSL certificate, just to wrap that up, the point that Cormac makes very, I mean, robustly is that the only time you see certificate warnings is when, for example, a certificate is expired.  Remember, not long ago GRC's certificate expired.  I was at Starbucks, and someone sent me email saying, "Hey, Steve, by the way, I hope you were...."  And in fact I was spending, I was going to spend a whole day working offsite.  And it's like I had to run home and solve the problem because my certificate expired.  It just caught me unaware.  And I've talked about how when I have seen errors, I've gone in and pursued them, and sure enough, without exception, the certificate expired a day or two before.  And I know they're running around, scrambling, trying to get their new certificate issued.



So over time users see these sorts of problems, like certificate errors, and they - I still sold SpinRite with an expired certificate because people had gotten used to it and thought, oh, well, maybe they checked the certificate themselves and saw that it had expired at midnight, four hours before.  Or maybe they're just already used to false positive certificate errors.  But for whatever reason, studies have shown people ignore them.  And that in fact they are right to do so.  They're behaving rationally when they do that.



LEO:  Because 99 percent of them are false positives.



STEVE:  .999, I think, yes.  And the point is that bad sites, phishing sites, just don't use SSL, so they don't have a problem.  Or in the rare...



LEO:  That's a good point, too, right.  You don't see a certificate error.



STEVE:  Exactly.  You can't get a certificate error if you're not even trying to use one.  And the flipside is, in the rare case that they have gone to the trouble of issuing certificates, they've also gone to the same trouble to make sure everything's correct.  So for them, the correctness of their certificate is their whole life.  I mean, this is all part of the spoof that they're trying to pull.  For me, I've had certificates for years.  It's sort of an annoyance that I have to renew them every couple years.  So I'm not thinking about it the way somebody who's focused on valid certificate spoofing is thinking about it.  For them, they're going to make sure nothing generates an error because that's all part of their campaign.



So what happens is, with all of this - for example, in the cat and mouse game with phishing, the original phishing hacks were numerical.  So we told users, oh, don't trust numbers.  Then, okay, people started - the bad guys evolved to lookalike names, PayPa1.com.  Now we tell users, oh, you've got to look at, you know, numbers are still bad, but now look, make sure that every character is correct.  And then there was a next level of escalation.  And we ran through all the wacky ways that you can obfuscate a URL that's visible to confuse users.  And these are people who have actually somehow been convinced that this is something they have to worry about.



And so the argument is, what's the cost of just ignoring all of this?  The fact is the written policies of all the banks are you're indemnified.  If you notify us within a couple days of some problem, of you becoming aware of the problem, your maximum liability is $50, or zero.  Policies vary.  But in general, because the bank or whatever financial institution is wanting to encourage this Internet use because it's good for them, it lowers their costs, it allows them to streamline and automate and outsource and all that, they're wanting to say, okay, we'll take responsibility for there being a problem.  I mean, I've never paid anything when my credit card has leaked out onto the Internet.  I get a call.  They say, Steve, were you in a French health spa yesterday?



LEO:  I get that call a lot.



STEVE:  And it's like, uh, no.



LEO:  No.



STEVE:  Wasn't me.  They go, okay, fine.  We're going to cancel this card, and we'll send you another one in the mail.



LEO:  Get this one.  Jennifer calls me - Jennifer calls me every few weeks saying QVC is on the line again.  They say we bought $800 worth of crap, and they're shipping it to Southern California.  And they give the same credit card number every time.  And it's one we haven't had in years.  It was canceled years ago.  Somebody continues to use it with their address and our phone number.  But the funny thing is, QVC, I don't know why, but they ship them the goods.  It's like, I'm not liable.  I haven't used that credit card in years.



STEVE:  Wow.  That's nuts.



LEO:  But I love it when I get the call because then I, you know, it's like, well, at least they're paying attention, I guess.  But why are they shipping this stuff? 



STEVE:  So what we have is a mess.  And with the users being protected from the exploitation of their identity.  Now, I would argue that identity theft is something where we've all heard the horror stories of what happens when your identity actually gets stolen, and it's a big problem.  But even there, if you do the math, if you look at - apparently there are 180 million adult users of the Internet in the United States.  And if you just on the back of a napkin sketch out how much time out of everyone's day goes into scanning URLs and fussing around with passwords per site and password rules and all of this overhead versus what's the expense to the user of not doing so, Cormac makes a compelling case that all of this is just nonsense.



LEO:  Yeah.  But you've got to do something.



STEVE:  Well, and it's very clear that LastPass and what you're doing makes sense for you.



LEO:  Yeah.



STEVE:  I'm looking forward to checking it out myself because it sounds like a beautiful solution, one I can understand.  And all of our listeners understand this.  Mom doesn't.  You know?  That's a threshold that is too high for her.  And in fact I recognize it when I talk to somebody who wants my advice and isn't a Security Now! listener or a candidate, they want, like, where's the tradeoff?  And the perfect question for them to pose back to me is, well, how likely is that?



LEO:  Yes.



STEVE:  I mean, that stops me cold because all I have is the absolute knowledge that it's possible.  But I have no idea how likely it is.  And one of the things that occurred to me as I was reading this that Cormac did not discuss is one thing that we're lacking is positive feedback when something we do saves us.



LEO:  Oh.  Like that was a good thing to do, yeah.



STEVE:  Yes.  We never get that.



LEO:  That's a good point.



STEVE:  We don't - we're not - we don't get awarded for links we don't click in email.  We just know we can't click those.  But imagine if you actually knew that, had you clicked it, you would have been in bad shape, well, that would positively encourage you.  Similarly...



LEO:  Nice job, Leo.  You just avoided getting phished.  Yeah, yeah.



STEVE:  Reality just split.  Leo clicks the link; Leo doesn't click the link.  Look at the world if Leo had clicked the link.  Oh, my god.



LEO:  Right, right.



STEVE:  And I'm running with NoScript, so I'm blithely jumping around from site to site.  But nothing is telling me, whooo, boy, you just avoided a bad one right there.



LEO:  You've got to have some positive reinforcement.  That's key, yeah.



STEVE:  So you don't know what the scripts you don't execute would have done to you.  And so one of the problems is that we know listeners of the podcast whose shields are up, who are protected, who are using complex passwords, who do look at URLs, who do scrutinize the links in the bottom, these bad things are not happening to us.  But still we don't - there is no system that tells us what horrors we avoided by behaving ourselves well.  So one of the things that is missing, I think, is positive feedback for our good behavior.  I mean, we're still going to be on good behavior because we understand the consequences. 



LEO:  Right, right.



STEVE:  But I do have a friend who is long-winded about answering questions.  And whereas I sort of...



LEO:  I know your friend.  I think I've had dinner with him.



STEVE:  Yes, you have.



LEO:  You didn't have to say more than that.



STEVE:  And I've watched people ask him this sort of question.  Well, you know, what do I really need to do?  And half an hour later, when they start to snore, he's like, well, okay, I'll finish this after you're awake.  And the fact is, it's just not practical to explain to most people.  But the question is why?  It's because it isn't worth it.  And most users get that intuitively.  We like security for its own sake, because it's fun, it's interesting, it's got mechanisms, it's got good guys and bad guys.  And we do know, we're very conscious of what could happen.  We hear about them, these actual things happening to people all the time, too.



But most users make a different, purely economic-based - for us it's a hobby.  Most people don't want to mess with this.  They just want to get on with their life.  They make an economic judgment which says, okay, I know that some people, I've even had friends that have gotten viruses.  And they don't know what they did; I don't know what they did.  This all makes me very uncomfortable.  But I'm just going to push on and hope for the best because I asked somebody once what I should do, and I just glazed over because I couldn't understand half of what he was saying.



LEO:  But we need simple - we need maybe - I don't know who's going to do this, or even if it's doable.  But we need some sort of quick, easy, simple instructions.  I endeavor to do that on the radio show because I can't give them two-hour instructions.



STEVE:  Well, and Cormac makes the point, and this is what I have done, is he talks about prioritizing.  He says, if you go to US-CERT and look at their rules for, like, proper security, it's pages of dos and don'ts.  But, for example, my number one thing is do not click on links in spam.  Number one.  So if you ignored everything else, do not click on links in spam.  I would argue that's probably the worst thing you can do.  And so then if you created a hierarchy - and so that's a simple, clean, clear rule.  Now, then the question is, well, what about links from Aunt Sarah?  Oh.  Well...



LEO:  You want to hear my rules?  This is what I do on the radio show because you have to codify it.  And people get mad sometimes because I don't give them shades of gray because you can't give them shades of gray.  You have to say, do these five things.  To me, number one is run Windows Update automatically, religiously.  Because even if you continue to click links, if you're not vulnerable to the exploits, you're going to be protected.  So number one, Windows Update.  Number two, don't click links in email or in Instant Messenger.  Number three, don't open email attachments.  That's become lower down on the thing, on the list because that's no longer a common vector of viruses.  It used to be number one, email attachments, but less so now.



STEVE:  Right.



LEO:  But I extend that now to say don't - and by the way, the true, as you know, the true rule is do not open executable attachments.  But of course most people can't tell.



STEVE:  Right.



LEO:  So you can't say don't open executable attachments.  You just say no attachments.  I also say don't accept files from strangers, and that may be on Facebook, from peer-to-peer, you know, links and files are really the deadly vectors these days; right?  That's where the viruses get in.  And I think those are simple enough that people can remember.  You know, I should add make good passwords and stuff like that.  But those are simple enough that I think people can remember them and act on them.  Would you add anything to that list?



STEVE:  I think, no, I think you're right.  I think in terms of a hierarchy, I think that that's the minimal behavior for people being safe.  And everything beyond it, the content of this podcast for the last four and a half years, are looking more closely, dissecting threats, understanding them.  But I liked this for our end-of-the-year topic because I really do think that there's a very good point, and that is that, arguably, that comeback of, well, how likely is that, it's probably not that likely.



Now, arguably, links in spam, ooh, you don't want to go to - you don't want the universe to fork and take you down that road.  Clearly wrong.  Phishing attacks, well, we know they happen.  But then again, it's easy to get over-paranoid, that is, am I happy when I lose my credit card, when it gets loose because I've used something other than PayPal?  No.  I'm not happy.  But I'm protected.  I get another one.  Life goes on.  And there's some cost to me.  But I was pretty much indemnified for, well, I was completely indemnified for that.  And so that's the case with most of this kind of online fraud, is users are safe.



Now, losing your identity, getting your machine all mucked up with stuff, you know, that costs you time and trouble and annoyance.  And it's happened to most of the people who are neophytes.  I've looked at their machine.  I've tried to figure out what they did.  Typically they clicked on a link in email.  That did them in.  So I really think that's the big bull's-eye, and everything else is interesting, theoretical, worth discussing.



LEO:  We're not saying - and somebody in the chatroom said, Hartwell said, "Well, I guess this is the last Security Now! ever."  We're not saying that you don't talk about it.  People who listen to this show want to know all the other stuff.  We're talking about what do you tell Mom.



STEVE:  Yes.  We're discussing the science of Internet security.



LEO:  On the show, yeah, yeah.



STEVE:  The science and the technology and the practice.  And, well, and it's from that that we're able to distill the most important things, and that inherently means there's going to be some least important things, some things that are less likely to happen.  And certainly our listeners want to know about parsing a URL and being not caught out by something that might be strange.  Most people are just like, oh, don't confuse me with all that.  I just want to buy my doughnuts and go on.



LEO:  [Laughing] I love it.



STEVE:  So the rational rejection of security advice is...



LEO:  Sometimes it is rational.



STEVE:  It is rational.  And it is arguably in many users' best interests.  See, the other thing, Leo, is for us,  listeners of this podcast, these things are not expensive.  I do look at the URL.



LEO:  Right, right.



STEVE:  That's part of my experience of using the 'Net is looking at the URL, checking the URL of a link that I'm hovering over before I click on it.  It's inexpensive for me to do that.  It is not inexpensive for Mom to do that because she doesn't really understand it.  And that's the problem.  We're giving people rules to follow.  We make the rules.  We understand, you, I and our listeners understand why and where they came from.  Instead, we're imposing conduct on people that just sort of - they don't really understand where it came from, why they're being asked to do that.  Well, what is this URL?  So it just makes them anxious and uncomfortable.  It makes them itchy, and they're not happy.  And we might as well have people who are probably going to be okay, and happy, than maybe not that much safer anyway, and miserable.



LEO:  Steve, I think this is a great episode to hand around to your friends and family.  And maybe someday we'll write a little pamphlet.  There must be something like that out there that's just the basics, what you should do, what you need to know, how to protect yourself in 99 percent of the cases.  The other 1 percent, you should be listening to Security Now!.



GRC.com's the website.  You can go there right now and get a 16KB version of this show for the bandwidth impaired.  Steve also pays to get transcripts done.  Elaine Farris writes those up and so you can read along as you listen.  He also has a whole bunch of great free programs, security programs there, and the flagship of the operation, the great SpinRite, a must-have hard drive maintenance and recovery utility.  If you don't own SpinRite, go get it:  GRC.com.  Happy New Year, Steve.



STEVE:  Happy New Year to you.  We're plowing into 2010, and I'm sure we're going to have lots of fun and adventures for our listeners.



LEO:  2010.  You know that's the year we make contact.



STEVE:  I'm ready.



LEO:  Yeah, we'll see.



STEVE:  I'm way more than ready.



LEO:  It's about time.



STEVE:  Yes.



LEO:  All right, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2009 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#230

DATE:		January 7, 2010

TITLE:		Listener Feedback #83

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-230.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 230 for January 7, 2010:  Your questions, Steve's answers #83.



It's time for Security Now! Episode 230, the first episode of the new year.  I won't say the new decade because Steve Gibson's an engineer, and he will quibble.  Here he is, Steve Gibson, our host, security expert, the man at GRC.com, the creator of SpinRite.  Hey, Steve.



STEVE GIBSON:  Yes, are we numbering our years from zero or from one?



LEO:  We did a decade-ender TWiT last week.  And I started off by saying, I know, it's not the end of the decade.  But if I do an end-of-decade TWiT in December 2010 I'm going to get far more mail than if I do it in 2009.  So I'm doing it now.  We moved to two digits, but the decade will end in another year because we started...



STEVE:  Yeah, it's interesting, as an assembly language programmer and actually any programmer, there's always this question of are you counting from zero or are you counting from one?  And it's one of the things you learn as you mature as a programmer is that, first of all, that matters.



LEO:  Yes.



STEVE:  And many bugs have come from someone saying, let's see, if the maximum count is five, then that means I have five things.  No, you have six things because zero is a thing.  So...



LEO:  Programmers learn that pretty early, I think.  I know I did.  That's like the first thing you learn.



STEVE:  Or they go into the social sciences.



LEO:  Yes.



STEVE:  They just say, okay, I can't do this.  I don't understand.



LEO:  [Laughing] Steve just burned all you social scientists.  Which I am, so there we go.  We're going to get to - we have some great questions, I know.  You've collated some questions from our listeners, 10 wonderful ones.  And we should say, if you have a question for Steve, you can go to his website, GRC.com/feedback and ask a question.  Steve loves those questions, and every other show...



STEVE:  Oh, they're so good, Leo.  I just - we have got great, great listeners who are, you know, taking the opportunity to send stuff back.  I love it.



LEO:  Now, we've recorded this a little bit ahead because as we are talking, Steve, Kiki and I and the entire gang are in Las Vegas for the Consumer Electronics Show.



STEVE:  Yup.



LEO:  So if you're listening to this on the 7th or the 8th or the 9th or the 10th, don't forget, you can go to live.twit.tv and watch our live coverage.  I'm really trying to bring the big Consumer Electronics Show to your living room, or to your den, or wherever you watch it because you don't have to travel.  We're going to show you all the interesting cool stuff.  We've got all of our team out there - Ryan Shrout from PC Perspective, Ryan Block from gdgt, Wil Harris, Dr. Kiki, Dick DeBartolo, Paul Thurrott.  Of course I'm there.  Steve, we're going to launch right into it; right?



STEVE:  So we may not have flying cars, but we have all the rest of the technology...



LEO:  We're getting there.



STEVE:  ...that George Jetson and Leroy or Elroy, Jane and everybody had.



LEO:  [Singing] Meet George Jetson.  Jane his wife.  His dog Astro.



STEVE:  Astro, yes.



LEO:  You know the Ford Flex has this BLIS system, and it will tell you if somebody's in your blind spot.



STEVE:  Nice.



LEO:  If you get too close to somebody it pre-tensions the brakes, pre-tensions your seatbelt, I mean, it's - they have automatic parking now.  I mean, they really - we're getting very close to automated cars, I think.  This is - I think it's pretty exciting.



STEVE:  I'm all for it.



LEO:  Yeah.  We will be safer.  Let's get to our questions of the day, starting with Ocie Hudson from Ocala, Florida.  He's been watching the packets flow.  Sounds like a Crosby, Stills and Nash song.  Hi, Steve.  In Security Now! #223 - that was the SSL renegotiation bug that we talked about - you remarked, as one of our Q&As from last week asked, if I'm behind a router, and I'm using XP, am I not behind two firewalls?  It's like yes, so unsolicited packets are not coming in from outside.  Now, that was your response.  Here's his story:



I have a Linksys WRT54G router between my computer and the ADSL connection.  Windows XP is my operating system.  It's running Sunbelt Software Personal Firewall (SPF).  We've talked about that before.  In fact, I think you recommended it.  The router's firewall is configured to block everything inbound, and I have configured the SPF firewall to log dropped packets.  Now, here's the thing:  During any given 24 hours there are anywhere from as few as 50 to several hundred packets that transit the router firewall and are dropped by SPF.  Most, but not quite all, are TCP packets sent by a website which Firefox is currently on or which has been recently connected to a port on my computer that is now closed.  Not port 80, apparently.  SPF drops them because the port is closed.  But why the website sends them, who knows?  Why they pass the router's firewall is unclear, but I assume it's probably because the packets have my computer's MAC address in the header; right?



Also from time to time an unidentified process attempts to send an outbound TCP packet from a closed port to some other computer on the Internet, not always the same one.  The destination computers have only been identified by their IP addresses.  None has ever been identified as hosting a website.  So I don't understand why you believe that two firewalls prevent any unsolicited packets from being received by the software and operating system running on a computer.  It seems to me that just one firewall should be all that's required.  But according to my SPF logging of dropped packets - it can be informative, sometimes mysterious.  I wonder whether it might allow some to transit that it should have dropped.  In other words, should he be concerned by these results?



STEVE:  Well, this is a great question because it addresses sort of the boundary condition, which I have to actually confess is the reality of at least what his router is doing, which is arguably what it was designed to do and probably maybe the best it can.  So he talks about during any given 24 hours there are anywhere from as few as 50 to several hundred packets that are dropped by - that pass through his router to hit his Windows XP machine where his SPF firewall logs them and drops them.  So his question is, okay, wait a minute...



LEO:  How are they getting there?



STEVE:  Well, yeah.  What's going on?  Well, the problem with NAT is - we've discussed this extensively and done a couple episodes on it - is that the router sees an initial packet, typically a TCP SYN, that's short for sequence packet, going outbound to a remote website, for example, or whatever you're making a TCP connection to, typically websites, maybe a POP server, SMTP server, whatever.  So it creates an entry in a table such that when the packet returns, that it's able to say, oh, I remember seeing sort of the corresponding packet go out there.  So now a reply has come back.  So that tells it to which computer behind the NAT on the private LAN to forward that packet.



The problem is that routers have different sorts of logic for when to remove that table entry.  For example, in the case of TCP connections, there is an orderly shutdown where the computer will send a FIN, for finish, packet.  Then the other end is supposed to send back an acknowledgment of that FIN, and then its own FIN packet.  And then the computer that initiated the shutdown performs a final acknowledgment of the other end's FIN.  So in the same way that there's this so-called three-way handshake to establish a connection, there's a similar three-way handshake to gracefully shut down the connection.



But in order for that to occur, that path has to remain open during the shutdown.  That is, if the second the router saw the FIN come in, if it, like, removed the entry from the table, that would cut off the computer from the inside so that it wasn't able to be satisfied.  And if the computer doesn't get an acknowledgment of its FIN packet, saying I'm trying to finish this connection, it'll keep sending those, which may recreate a table entry since that's an outgoing packet.



So the truth of the way a router works is a little less elegant than the theory.  And so what's happening with the WRT54G is it's deliberately leaving these tables, these NAT-mapping router table entries in place to make sure that both ends are able to satisfy themselves with saying goodbye to each other, essentially.  Now, what can happen is that, for example, the far end might not see an acknowledgment, so it'll send a second finish packet.  But the SPF firewall, which is - it can be rigorous.  When it sees the finish packet come in, it immediately terminates its permission for this connection.  So essentially the stateful firewall is tracking the state of the TCP connection.  It is very clear and conscious about when the connection is shut down.



So what happens is, as it's truly terminated, that firewall stops permitting packets in that conversation.  Yet the router, which can't be that sure because it's not really - it's not the host of the connection.  The computer where the firewall is is hosting the connection.  The router is just sort of passing stuff through.  It has to be more permissive to make sure that packets get through and are acknowledged.  So the firewall will emit sort of spurious logging of packets which, I mean, it's exactly what was described here.  He's talking about websites he was just visiting, pages he just pulled up, places where Firefox is.  And so there was a dialogue and an exchange, it ended, yet the border router continued to let some, like, remaining debris from sort of just the end results of that connection through; whereas the firewall on the computer said, okay, we're done.  And then if anything else comes in, it logs it as unsolicited.



So that's what's happening is there actually is a little kind of a gray area in this.  And it's worth mentioning that UDP connections like DNS typically uses, since they are stateless connections, that is, there is no startup and shutdown, router logic is very different for UDP.  If a UDP packet goes out, a timer is established, sometimes for a minute, sometimes for five, sometimes for 15.  It depends upon the logic in the router.  There is no notion with UDP protocol of an end of communication.  So outgoing packets create these entries in router tables which, as packets continue, that entry is refreshed.  And it's only after there's been no activity for some length of time that the timer expires and the router removes that from its routing table.  So I would expect if you were doing UDP things you'd probably see even more debris.  That's what's going on.



LEO:  That makes sense.  And he shouldn't worry that, because that's happening, that he might be missing other packets, that the firewall's missing stuff?



STEVE:  Well, the one - that's a very good point.  The one thing I was going to - I was sort of chuckling when he said, oh, yeah, in 24 hours between 50 and...



LEO:  50 and a hundred.



STEVE:  ...several hundred packets.  That's like, baby...



LEO:  That ain't nothin'.



STEVE:  ...if you look at the outside of the router, you want to see something that is effectively blocking stuff?  Monitor the outside of the router.



LEO:  It's 50 to a hundred a minute.



STEVE:  It's a storm out there.  So the router is doing the right thing.  It is really blocking unsolicited packets.  It's just not blocking some of the tailings of conversations that you are having which technically are solicited.  Those were dialogues you initiated inside the network.  But again,  yeah, on the outside, oh, it's bad.



LEO:  I like the way you said that.  It is, it's a conversation trailing off.



STEVE:  Yeah.



LEO:  Just like [sighing].



STEVE:  Just like [sighing].



LEO:  Question 2 comes from Troubled.  He is a regular in our chatroom, in fact he's in there right now, from Ontario, Canada.  He's worried about DNS port randomizations being negated by NAT.  And you will only understand what that means if you've been listening to the show since Episode 1.  And I'm ashamed to say I kind of understood what it meant.  Dear Steve,  But not ashamed, proud.  Proud.



STEVE:  There you go.



LEO:  Dear Steve, I just finished listening to your Security Now! episode for December 22.  I heard you speak about weaknesses in routers and how you were concerned by the fact that consumer routers seem to prefer to hijack DNS queries.  We were saying, why are they doing DNS?  Doesn't make any sense.  While I think I understand the problem correctly, I'd like to hear your take on it.  The specific problem is related to the fact that the recent DNS issue was fixed by making DNS queries use random outbound ports so as to make a MITM be forced to guess - now I'm getting lost.



STEVE:  Man in the middle.



LEO:  Man in the middle, okay.  I've never seen it abbreviated.  Okay.  So the specific problem related to the fact that the recent DNS issue - is that the BIND problem that we're talking about, that man-in-the-middle BIND problem?



STEVE:  Yup.



LEO:  Which was fixed in some cases by making DNS queries use random outbound ports so as to make a man-in-the-middle attack forced to guess the source port for the reply.  In effect you're getting an extra 16 bits of security, giving approximately 32 bits minus, say, the 1024 ports usually reserved for root.  Now, the big question, what happens when you NAT the DNS on a device, as most or all home routers do, that sequentially maps outbound requests?  Seems to me you would lose that extra randomness since the router just changes them to be sequential now.  While the original query port may have been in fact random, the new NAT'd port is the part the attacker needs to guess, not the original port; right?  Of course there's still some guesswork for man-in-the-middle attacks since you'd have to factor in the occasional port incrementing by standard system usage, which could be harder if it's a busy machine.  But that's just a few; right?  It's not 16 bits worth.  Thanks for the shows.  Love 'em all.  Troubled.  That's a good question.  You're going to have to explain what it means.  I think I kind of get it.



STEVE:  Yeah, it's a good question.  And, in fact, exactly that did happen in many instances shortly after port randomization was adopted by servers.



LEO:  Really.



STEVE:  But it's not the consumer router, it's big iron NAT routers.



LEO:  It's your ISP's router.



STEVE:  Exactly.  So what happened was BIND was updated to issue its queries from random ports.  But in the case that the DNS server, the ISP's DNS server was behind their big iron NAT router, then that randomization was derandomized.  It was lost.  And suddenly queries were going out into the public space from sequential ports.  So that had the negative effect of sort of reversing the security improvement of using query source port randomization.



Now, the reason it's not a concern for the consumer, that is, who has a home NAT router that is very likely doing the same thing, is it's not their query to the ISP that we're concerned with spoofing.  It's the ISP's DNS server's query out to get the IP from the Internet.  So it is the case that, if a man in the middle were monitoring a customer, an ISP's customer's DNS queries, well, then all bets are off.  I mean, a man in the middle wouldn't even need to intercept the traffic.  He would see a query go out to the ISP, and they could immediately send back a spoofed IP as an answer.  So in fact a DNS spoofing in an open network is a complete vulnerability.  There's no protection for that.



LEO:  Okay.



STEVE:  And, in fact, it's funny, as I was thinking about this, I realized that that's obvious, that's another obvious attack, an even simpler attack in any open WiFi network.  We've gotten ourselves all worked up about ARP spoofing and knitting ourselves into intercepting traffic and pretending to be the gateway so that we get all the traffic going by.  Well, it's like, wait a minute.  If there were, like, an evil Google site, then it would be trivial to see anybody sending a DNS query for Google.com out into the, literally into the air, and simply respond with a bad IP.  And then that user's computer would then march off in the wrong direction.



So spoofing DNS in an insecure local network is trivial.  But that's not where the vulnerability comes from, where the query source port randomness is something that's a problem.  It's not the user's query that's being spoofed.  It's the user's query goes to the ISP.  And that's also, by the way, typically not over the public Internet.  It's within the ISP's network.  You're behind, if you're on a cable modem or DSL, you have a connection to your ISP.  So none of that traffic to their DNS server is visible to the public.  It's the DNS server's query outbound that is in danger of being spoofed.  And sure enough, a NAT router that's interposed there can derandomize queries.  So Troubled is sort of right to be troubled, but sort of in a different place.



LEO:  Don't be troubled, Troubled.  All right.  So all right.  Now we go to Question 3 from Peter Sinclair.  He's in Castle Hill, New South Wales, Australia.  And he says:  Dear Steve, I've been a Security Now! regular since the start and a SpinRite owner, as well.  I heard your recent warnings about overheating in portable disk drives and recalled a paper I wrote - so this guy knows what he's talking about, too - some years ago about disk drive heating effects.  It was based on some IBM-sponsored research back in 1989.  It turns out - get this.  Here's a little math.  Heat generation within a disk drive is proportional to the cube of the rotational velocity and inversely to the fifth power of the diameter.  I'd attach a copy but I can't see how on this form.  Keep up the good work, and regards to Leo, as well.  Peter Sinclair, B App Sc, M App Sc - Bachelor's in Applied Science and Master's in Applied Science.  Obviously an expert on this stuff.  So the cube of the rotational velocity means it goes up very rapidly with the rotational velocity; right?



STEVE:  Ah, yeah.  I wrote back, and I said, "Peter, I have got to see this paper."



LEO:  Did you get it?



STEVE:  He replied, and I received it, but it was just this morning when I was preparing all of this.  So I have not had a chance to review it.  And lord knows what the math looks like in there.  So it might have taken me a while to digest it in any event.



LEO:  I love it.



STEVE:  I will make a mention of it next week because the idea that heat generation is proportional to the cube of the rotational velocity and inversely to the fifth power of the diameter, I mean, if I understand that right, it means that, as the diameter gets larger, to the fifth power, heat goes down.  Which, okay, I don't know why that would be.  I mean, anyway, none of that seems intuitive to me, so I'm really curious.  And of course what I do know is that seeking is a big deal, too, because one of the ways that SpinRite tends to heat up drives is that it is, once it starts, it's in there going tick tick tick tick tick tick tick, I mean, it's going step by step by step.  Every one of those little cylinder jumps is a burst of high energy because the head is accelerated very quickly and then immediately decelerated.  So there's extra power being drawn and extra heat being generated by the drive, which is why SpinRite's also continuously monitoring the temperature of the drive and letting people know, oops, this thing's getting hot.  I mean, it will work the drive harder than, I mean, sure, doing a big file copy is sort of the same because the head's jumping around all over the place, writing to the disk.  But SpinRite will continue that for hours.  So I can't wait to see what the paper says, and I will share it with our listeners.  I just got a big kick out that.  It's like, here's the equation for heat generation.



LEO:  I love it.



STEVE:  It's like, whoa, okay, cool.



LEO:  Here's a question from, or maybe a statement, from Daryl in Kansas.  He declares router DNS adds value.  We were talking, again, about why these dumb little routers should bother with DNS.  Hi, Steve and Leo.  Just finished listening to Episode 228 regarding why someone would use a router as the LAN DNS server.  I smiled when you brought the subject up.  What you say is not useful actually can add a lot of value.  In fact, I've locked down my router so that clients attaching to my LAN only use OpenDNS.  Now, I know you've heard of OpenDNS.  In fact, we talk about it all the time, OpenDNS.com.  There's a big incentive for businesses and families to use OpenDNS to manage network traffic.  In fact I do use it at home and here at TWiT.



He says:  Incidentally, when I ran your DNS benchmark tool - thank you for a great tool - OpenDNS fared very well.  My experience, too.  I think it came in second.  I really haven't had any problems running this way, and the benefits, as I said, add much value.  I can manage my network from any Internet connection and see stats of what's been happening on it.  And since I'm a family man, it's been a great tool to filter out the sites I don't want on my network.  This guy could be quoting me, Daryl.  Anyway, I thought I'd share at least one great reason to use your router as a DNS server.  Thanks for a great podcast.  I've listened to them all.  And the best to you both.  Well, that's not what we were talking about, of course, but...



STEVE:  There were two people brought up good points.  We've got one a little bit further, I think it's in fact the next one.  But I wanted to reiterate this because Daryl's completely correct, certainly.  If you configure the router to use specific servers, rather than allowing it to just get whatever DNS servers the ISP serves to it through its DHCP query when it's logging onto the ISP's network, then all of the machines within the network get the use of that DNS just as a function of them doing their own DHCP query during the autoconfiguration of their network connection when they're booting up.  You're right, Leo.  You had said exactly the same thing.  I just wanted to make sure that, since I was so negative on this, that we sort of were on the record...



LEO:  I'm must be misunderstanding because this is not what the routers are doing, if they're doing DNS.  This is just replacing the setting, just as you would on your computer, that's normally provided by the ISP, but explicitly filling in OpenDNS's DNS server.  But the DNS is not done by the router, it's done by OpenDNS.



STEVE:  Correct, correct.



LEO:  When we were talking about...



STEVE:  And that's always the case.  Unless you're running your own BIND DNS server which is going out and resolving DNS for you, then the router is just passing this thing through.  So you're right, all it's doing is giving you...



LEO:  An explicit DNS server instead of the one that would be provided by DHCP otherwise.



STEVE:  Right.  And it's worth mentioning that this is different than what our next question addresses and what I was talking about because I was talking about the router passing its IP to everyone behind the LAN as their DNS server.



LEO:  Saying I'm the DNS server.



STEVE:  Exactly, instead of passing the values you configure, that is to say, OpenDNS, onto all the machines behind the LAN.



LEO:  Right.



STEVE:  Right.



LEO:  That was what I was understanding is that somehow the router, when you were talking about it last time, actually two times ago, that somehow the router was trying to preempt DNS. 



STEVE:  Well, and so the question is, I mean, if you think about it, there are two aspects of this.  There's what DNS is configured for the machines on the LAN behind the router, and what DNS the router itself is using.  Is it accepting DNS servers from the ISP, which are almost certainly not going to be OpenDNS?  Or have you or someone like Daryl gone in and said, I want my whole network to use OpenDNS because it's better DNS?  It gives me all these extra features, filtering and monitoring and web safety and so forth.



LEO:  Okay.  Question 5, Tom Zerucha, he's writing from San Diego but living in Michigan.  That's just what he says.  He has another reason for routers to proxy DNS.  Steve, the router has to provide your computer with something in the DHCP field for DNS when you plug it in.  And in some situations this could be before it has received its own main address by doing the DHCP query out to the ISP.  For instance, maybe you have to configure it with a password or something else.  So what does it do?  Well, it can't put in an entry for DNS it doesn't have, so it simply implements a forwarding proxy.  This makes sense.  Now I'm understanding.



STEVE:  Yes.



LEO:  This is what's going on.  This makes sense.  It implements a forwarding proxy.  When the WAN is configured and/or comes up and the router then gets the real DNS from the DHCP server out there in the world, it can use it.  But if the router doesn't yet know what to put into the DNS field for the DHCP request, it needs to send something in that field to the local computer saying give me a lease.  I mean, what should it do?  How would you solve this?  Build a router that is plug and play that doesn't require anyone to manually configure any DNS by telling the computers, just use me as DNS, I'll give you the new DNS when I find out.  And then they proxy that off.  That makes sense.  So is that what's happening?



STEVE:  Well, so yes.  So let's back up a little bit.  I've used in the last two questions this DHCP.  That's the protocol that is used for autoconfiguration of network connections.  It's a widely used, universally understood protocol.  It's when, for example, in Windows users or on Macs, where there's this obtain an IP address automatically or obtain configuration from the network, what happens is any machine on a network can make a broadcast.  So it powers up.  It knows nothing, I mean, nothing about the network.  No gateway IP.  It doesn't know what network it's on.  it doesn't know if it's a 192.168 or if it's a 10. or a 172., I mean, nothing.  What it's able to do is simply send a broadcast that says, "Hi there.  Is there a DHCP server available that wants to tell me some stuff?"



And so a router, a home network router is, among many other things, a DHCP server.  So the computer on the LAN turns on.  The DHCP server hears that cry for help and says, yeah.  Here I am.  What do you need?  In the process, it gives its IP to the computer.  The computer then says, oh, here's all the stuff I don't know.  And basically it's sort of, it's very closely related to DNS, but it can provide other information than just look up IP addresses.  Essentially it says, I don't know anything.  Tell me what I need to be a citizen on the LAN.  And so it receives the IP of the gateway, the DNS servers that it's been told to be configured for.  It even gets its own IP.  The DHCP server assigns them sequentially or, in some cases, since all of this traffic on a LAN will have a MAC address identifying the adapter, which is to say the computer on the LAN, it's possible to configure the router to always give a certain machine a certain IP, rather than just sort of having them randomly assigned.



And in fact one of the things that machines can do is say, I'd like an IP, and last time I had this one.  And so that helps the IP addresses to be relatively static.  That is, you're not guaranteed that the DHCP server will give you the same one.  But if all the citizens on the LAN suggest what they had before, then generally as they come and go, are powered up and powered down, they'll be reissued the same IP.



Now, this exact same thing happens with the router and the ISP.  So when the router is powered up and sees that it's got a connection on its WAN side, not on the internal, on the LAN side, it's the DHCP server facing the ISP, it's a DHCP client.  So it does the same thing to the ISP's network that we do to it on our LAN.  That is, it sends out a broadcast:  "Hi, there.  I seem to be on.  Fill me up with the specifics of how I should be configured."  The ISP maintains a big iron DHCP server, hears the query, and provides all of the connection information to the router.



So what Tom has said, and the point he makes I think is a very good one, is that there are situations like with dialup ADSL, where you've got your LAN connected to the router, which may not yet be connected to the ISP.  I'm sort of old school, and I understand how these things work.  So I'm always plugging my router into a cable modem or to the DSL router or whatever and sort of letting it get going and stabilize and all that because I understand that it needs to get all of its connection stuff from the ISP before it knows what to give to the network.



Well, clearly, as these connections to the ISPs have evolved and become less static, where you do have DSL connections which are being established and broken, exactly as Tom says, it could be the case that there are computers on the LAN that connect to the router before it connects to the ISP.  They ask for all their numbers to be filled in, including DNS.  The router doesn't have them.  It's got its own gateway address, so it knows to tell everybody on the LAN, hey, I'm your gateway.  But it can't pass through any DNS addresses because it doesn't know them yet.  So what it does is it proxies for the ISP's DNS, just saying, don't worry, everybody, just use me.



LEO:  I'm in control here.



STEVE:  I'll take care of your DNS queries as soon as I figure out who I should ask.  And so...



LEO:  Right.  That makes sense now, yeah.



STEVE:  It absolutely does make sense.



LEO:  Yeah.  It's almost a necessity that they had to do that.



STEVE:  Yup.  It does make sense.  So thank you, Tom.  That explains why this is being done now.  And it would be interesting to see whether it's done as a function of the order in which these things turn on.  For example, if the router does have an established set of addresses, and you then connect to it, does it pass the DNS through, or does it always proxy, whether it knows DNS or not?  It could be that it's smart, and it's dynamic.  That's not something I even looked at before.  But it's a great point.



LEO:  Question 6, Jeffrey Hilgers with the U.S. Navy, Bagram Air Force Base, Afghanistan.  Wow, Jeffrey, we salute you in your service to the country.



STEVE:  Yup.



LEO:  Thank you.  He's got a great tip about Microsoft's Patch Tuesday:  Steve, in Episode 226, you mentioned in the beginning about where people can go to read about what was released on each Patch Tuesday from Microsoft.  I wanted to pass along that eEye Digital Security - which is, by the way, a great, I think they do great work.



STEVE:  Yes.



LEO:  ...the day after Patch Tuesday releases a very nice bulletin summary of what was released the day before.  They also give information on the vulnerability itself and links to Microsoft's information on it.  You can view these bulletins at eEye.com/Resources/Security-Center/Patch-Tuesday.aspx.  Or just click the - actually the easiest thing to do probably is to go to the eEye website.  In the menu there you'll see the Resources menu item.  You'll see Security Center under that, and then Patch Tuesday under Security Center.  So it's right off the front page, eEye.com, the Resources menu item, Security Center, and Patch Tuesday.  That's really a great feature of eEye.  I'm glad that they do that.



STEVE:  Yeah.  I looked at the page.  And, you know, it's a little self-serving.  They're saying, of course, oh, well...



LEO:  We knew about this years ago.



STEVE:  And all of our users who are using such and such, our product, they've always been protected from this preemptively because our Blink technology blinked out before.



LEO:  I never asked you what you thought about Blink.  It's free; right?



STEVE:  It is.



LEO:  Like personal, yeah.



STEVE:  Yup.  And Marc ended up leaving eEye.  He's no longer with eEye.  He wandered off to pursue...



LEO:  I didn't know that.  Oh, okay.



STEVE:  ...other things.  And we've corresponded a little bit since.  I think that there are people using it who are very happy with it.  There are other people who sort of still feel more comfortable with a traditional pattern-based intrusion detection approach rather than the behavior-based approach that Blink uses.  So it's sort of another goody for the arsenal.  I wanted - I mention this because I've been aware of this page but never talked about it before, and it is nice.  They do a little more open-the-kimono sort of job of telling more detail and more interesting stuff.  Microsoft, you could argue, has a little bit of a bias toward minimizing these problems, like I read that one issue about the RPC vulnerability where they said, oh, this could...



LEO:  Not gonna happen.



STEVE:  This could turn into a worm.  And it's called Conficker.  And it's the curse of the Internet.



LEO:  Well, maybe.



STEVE:  Yeah.



LEO:  Let's not be hasty here.  Yeah, it's always true, everybody has their own axe to grind.  And EI has kind of the opposite side of it, which is, you know, it's dangerous out there, and use our tool.  And Microsoft's...



STEVE:  Yes, we could have protected you from this.



LEO:  Microsoft's position is it's not dangerous out there.  Don't worry.  And somewhere in the middle is the truth.  But you probably should read both; right?



STEVE:  And even Microsoft's own researchers are saying, oh, don't worry about any of this stuff.  Remember...



LEO:  Wrong.  Wrong.



STEVE:  ...from last week the economics of ignoring security advice.



LEO:  Tim Wells in Marietta, Ohio addresses Firefox update issues.  Steve, you mentioned in Episode 228 a couple of weeks back that Elaine, your transcriptionist, had trouble upgrading to 3.5.6.  By the way, I think we're at 3.5.7 as we record this.  Could be 3.5.8 by the time you hear this.  I, too, encountered issues upgrading to 3.5.6 of Firefox on my Netbook.  Here's the story.  I needed to go to a website, so I grabbed my Netbook, clicked on Firefox.  Firefox pops up, says it's updating.  So I impatiently wait for my Netbook to update.  Then it crashes.  And then I couldn't get into Firefox at all.  Every time I clicked the Firefox icon I'd get "Mozilla Firefox has encountered a problem and needs to close."  So I went to my desktop computer, downloaded Firefox 3.5.6 directly from Mozilla - the full thing, not the patch - and manually installed it on the Netbook, and this fixed the problem.  Thanks for the wonderful podcast.  Heard every episode.



STEVE:  So I wanted just to pass this on for Elaine's sake.  I didn't ever follow up with her to see if she'd fixed the problem.  But it's been my experience, within a sufficiently large audience, what happens to one person will happen invariably to many, many more.  So if any of our other listeners - it sounds like there was just a little glitch of some sort in the auto update edition of Firefox, but that downloading the whole thing and installing it over what you had works fine and fixes the problem.  So Elaine, if you're listening - well, I know you are because you're typing this right now...



LEO:  Hi, Elaine.



STEVE:  ...and you've just had to type - you've had to type all of this.  And this.  And this, too.  And even this.



LEO:  And that, too.



STEVE:  Yeah.



LEO:  That's mean.



STEVE:  And everybody else that this happened to.



LEO:  Anytime - and I said this two weeks ago.  Anytime you install something, a certain percentage of people are going to have problems just from the install because it goes bad.  Cosmic ray hits it or whatever, and it goes bad.



STEVE:  It's impossible.  I don't know how Microsoft does as good a job as they do.



LEO:  I believe it.  I know.



STEVE:  Or Mozilla and everybody else, for that matter.



LEO:  Yeah, it's really remarkable, given the hundreds of millions of people who are installing this stuff.



STEVE:  Yeah.



LEO:  Zec in Colorado is next.  He asks about PayPal investigating small purchases as money laundering.  Oh, boy.  I sell a fair amount on Etsy, which is a handmade online marketplace.  To which I give two thumbs up, by the way.  Etsy's great.  Payment method of choice, PayPal.  Today I had a $9 transaction held pending an investigation by PayPal, even though everything appears to be legit, and I even communicated with the buyer.  I couldn't believe a $9 transaction would set off PayPal's sirens.  So I asked around.  One friend said their friend had a bunch of small deposits from writing work withheld, investigated, and ultimately not returned to her because PayPal thought she was laundering money.  So what's up?  All I do are small transactions with my business.  Are they going to keep doing this to me?  Keep up the good work.



STEVE:  So this sort of hit me at an interesting time.  I'm not sure why I did, but during the Christmas holidays, while I was at Starbucks for a couple hours, from 5:00 a.m. until my family woke up and I rejoined them for breakfast, I happened to read a lengthy, really heartfelt, sad story from a software developer who had really been raked over the coals by PayPal.  And we've never really talked about this side of it.  I'm an avid PayPal user, as an eBayer who uses PayPal to get money to eBay merchants.  And I love using PayPal when it's available because it does prevent having to disclose my credit card information to any sites that offer PayPal.  So from an individual user standpoint it's, well, it's a great thing, and I've never had a problem.  



Apparently, though, they are so popular that PayPal is a huge target for fraud.  And who does that surprise?  None of our listeners, I'm sure.  The problem is that there's all kinds of automated fraud protection which appears to be hair triggered.  Now, I don't know in Zec's case what it was that set PayPal off.  In the case of the blog that I read, a software publisher wanted to do a limited-time bundle with some other publishers.  And so they agreed over email they were going to be in charge of hosting it.  They were a PayPal merchant.  Everything was going along.  The offer worked really well, which pushed their revenues out of the normal profile that had been established with PayPal and set off warning bells, locked the money, prevented people from purchasing with them.  And then PayPal is apparently extremely difficult to deal with.



Again, it's not a business I'm in or I want to be in.  So I don't want to be overly critical of PayPal.  I think they're offering a service.  We've talked about we'd like to see them have better competition so that they do a better job.  For what it's worth, the Internet is full of horror stories of merchants, small merchants really being unhappy with their interaction with PayPal.  I know that there are plenty of merchants that have never had a problem.  Sometimes I think about, for myself, gee, wouldn't it be nice to offer our customers a PayPal button.  But then I remember, gee, it's not robust.  It's not something I could count on.  If I did a new version of - like a new product release, and there was going to be an upgrade, there would be a flood of retail sales, and it would set off all kinds of alarm bells.  And what I've seen, from what I've read, is merchants have no leverage at all.  Basically you're just out of luck.



LEO:  I transfer, any time we get a bulk of money in there, actually PayPal is now my salary.  So anytime we get a bunch of money in there we transfer it out because we don't want it to ever get locked up.



STEVE:  Yes.



LEO:  So we're pretty assiduous about getting the money out of there, getting the money out of there, getting the money out of there.  But PayPal, you know, we changed the way the donations, or the contributions, I should say, because it's not a nonprofit work, that's how - that's my entire salary. So whatever people donate goes to me.  All the advertising money goes to the company, to hosts, company salaries and all that stuff.  I'm the only one who's paid out of PayPal.  It's working pretty well.  People have been very generous.  On to Question 9 from Poojan Wagh in Chicago, Illinois.  He wonders, should I be paying for more than 128-bit encryption?  He says there's a website, we'll name names, CrashPlan.com.  It allows one to do offsite backups to a friend, peer to peer.  That's an interesting idea.



STEVE:  Yeah.



LEO:  I'd like to do this with my in-laws, but I'm wondering if their free offering of 128-bit Blowfish is enough.  I trust my in-laws to safeguard the data at their end, but I'm wondering about the data in transit.  For a $60 license you can get 448-bit Blowfish.  Is it worth it, or is 128-bit enough?



STEVE:  It's a great question.  And the answer is 128 bits is more than enough.



LEO:  More than enough, yeah.



STEVE:  We're talking symmetric encryption.  So it's state of the art.  Blowfish was designed, as we know, by...



LEO:  Bruce Schneier.



STEVE:  ...Bruce Schneier, exactly.  And it's a cipher which has withstood the test of time - very conservatively designed, well analyzed.  It's a very good choice.  And this is clearly these guys saying, well, we want to hook people on this...



LEO:  Free stuff.



STEVE:  ...free stuff.  We want to somehow add value beyond what's free.  So we're going to give them 448-bit Blowfish.  Well, okay.  You absolutely do not need it.



LEO:  This is cool, though, because they can give it to you free because they're not providing the storage.  It just - it's like Hamachi or something, connected to another server.



STEVE:  Exactly.  They're providing transit.  And in fact I'm - now, what's not clear is whether the 128-bit encryption is one-time key or a persistent key.  So the reason that Poojan's question sort of says, hey, I'm only concerned about this in transit, is I'm assuming the key is generated with some sort of key handshake, pseudorandomly, and used in a session.  But probably another key is used next time you connect.  That's the only sane way to do it, in which case 128 bits is just fine.  Now, you could also argue that 128 bits is fine forever, which is probably the case.  So again, there's just no reason to pay extra money for extra bits of key length on a really good symmetric cipher like Blowfish.  128 bits is fine. 



LEO:  I'm going to have to take a look at this.  That's an interesting solution.  Hmm.  Our last question comes from Matt Ridley.  He's in Kaukauna, Wisconsin.  I think I just pronounced that the Hawaiian way.  Probably not how they pronounce it in Wisconsin.  Maybe Kaukauna.  He wants some info about - or adds some info about the UAV Predators:  Hey, I just listened to the last episode this morning on my way to work.  Want to let you know more details about the Predator/UAV news.  Two of the guys in an online community that we have shared for eight years or so fly UAVs - that's, what is it, Unmanned...



STEVE:  Aerial Vehicle.



LEO:  ...Aerial Vehicle, and have at least had some experience with the Predator.  Those drones we use heavily in Afghanistan and Iran.



STEVE:  Right.



LEO:  According to them, after this came out, the following is the current setup:  Controls are encrypted, as you mentioned; mission mode cameras are encrypted during flight.  This was the issue was can people see the camera output.  The unencrypted videos in question are usually from takeoff, landing, and refueling.  The reason being, according to them, the pilots, is that the video timing lag caused from encryption/decryption - ah - gives them so much latency that it's not safe during takeoff, landing, and refueling.  Well, duh, of course, that makes sense.  Once the UAVs are aloft, real-time video feedback is less critical, so encryption is engaged.  According to them, in 2012 this video will become encrypted, as well.  That makes perfect sense.



STEVE:  It really does.  Now, there are many - again, we don't - no one that I've run across sounds to me like they're an absolute authority.  So there's lots of people saying...



LEO:  I'm sure the people who know don't talk.



STEVE:  Exactly.  So, I mean, but this explanation makes sense, except that encryption and decryption should be really fast.  Symmetric encryption/decryption doesn't take any time unless we're dealing with hardware that is so old, which really could be the case, you know, we run across that from time to time, too, that we're seeing really old hardware which is just - it can't do any more than it was designed to.  So I really, from a theoretical standpoint, though, I love this idea that they do not encrypt takeoffs, landings, and refuelings where they really need, for their own piloting controls, real-time video feedback.  But once they're in the air, that's less critical, so they click on encryption, get some lag, but have the security that they would hope these systems would have.  So that was cool.  Thank you, Matt, for sharing that.



LEO:  That kind of makes sense because even if it's a millisecond of lag, maybe it's a very minor lag, on a critical thing you really want to feel like the controls are real-time; right?



STEVE:  Oh, I mean, any videogame player knows...



LEO:  Yeah.



STEVE:  ...that if you've got lag between your controls and what you see, it's like, oh, this is just awful, compared to it being really instantaneous.



LEO:  Well, there you go, 12, or I'm sorry, 10 questions good and true from our listeners.  If you have a question for Steve, go to GRC.com/feedback and leave that question for him.  I'm sure he'd love to hear from you.



STEVE:  Absolutely.



LEO:  We answer questions every other show.  GRC, when you're there, by the way, is a great resource.  16KB versions of this show, Steve makes those available for easy download.  We don't.  He does, which I really appreciate your doing that, Steve.  He also pays for transcription, another great benefit to the community, and gives away a ton of great free software like Wizmo, DCOMbobulator, Shoot The Messenger, that DNS Benchmark Tool, more and more all the time.  Perfect Paper Passwords.  GRC, it stands for Gibson Research Corporation, GRC.com.



There's one thing there that you pay for, and I highly recommend you do, not just to support Steve, but because you need it.  It's SpinRite, which is absolutely without question the one, the only, the best hard drive maintenance and recovery utility.  If you're not using SpinRite, you're not getting the most out of your hard drives.  We SpinRite every drive before we put it into service.  It's a must-have.  GRC.com.  Steve, thank you.  Welcome to the new decade.



STEVE:  Always a pleasure.  As our listeners are hearing this, you're playing in Las Vegas at the Consumer Electronics Show.



LEO:  Oh, thanks for reminding me.  Please go to live.twit.tv for our live coverage and TWiT.tv for the downloads of - we're going to give you wall-to-wall coverage of the Consumer Electronics Show, yeah.  And we'll be back next week in-studio to talk again about security.



STEVE:  Episode 231 next week.  I'll talk to you then, Leo.



LEO:  Thank you, Steve.



STEVE:  Thanks.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




