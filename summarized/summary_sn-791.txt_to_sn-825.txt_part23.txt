GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#791

DATE:		November 3, 2020

TITLE:		Chrome's Root Program

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-791.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine a serious newly revealed Windows zero-day flaw, a public service reminder from Microsoft, Google's newly announced plan to get into the VPN service business, CERT's unappealing plan for automatic vulnerability naming, and a real mess that WordPress just made of an incremental security update to 455 million sites.  Then we'll close a loop, I'll update about SpinRite, and we'll finish by examining Google's new plan to go their own way with a new Chromium browser certificate Root Store.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Coming up in just a little bit a new Windows zero-day that's been around since Windows 7.  A screw-up in patching for WordPress, you're going to want to know about that.  And Steve's Dumb Idea of the Week.  All I can say is stay tuned.  Security Now! is coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 791, recorded Tuesday, November 3rd, 2020:  Google's Root Program.



It's time for Security Now!, and I mean right now, with this guy right here, Steve.  Well, there is an exclamation mark in the title.  That means it's definitely Security Now!.



STEVE GIBSON:  Better now than never.



LEO:  Now.  Steve Gibson is our host.  He's the man of the hour, GRC.com.  Hello, Steve.



STEVE:  Yo, Leo, great to be with you for, whoa, this interesting day.



LEO:  It's election day in America.



STEVE:  In the country, yeah.



LEO:  We're all just kind of nervously waiting. 



STEVE:  We're just biding our time.



LEO:  Biden our time.



STEVE:  Wait, Biden, what?



LEO:  Waiting to find out what happened.



STEVE:  To see if we're going to get Trumped or not.



LEO:  Yeah.  So we will find out.  But meanwhile we've still got a show to do.



STEVE:  The show must go on, as they say.  We're going to, for this week, Episode 791, we're going to look at sort of an interesting thing.  Without knowing it, we covered the first part of this last week, not knowing that there was a short, seven-day embargo on a new, just revealed, critical Windows zero-day flaw which was, as I said, embargoed, so we didn't know about it until later last week.



LEO:  We knew about the patch; right?  We knew they were patching it.  We just didn't know...



STEVE:  No.



LEO:  No.



STEVE:  There was Google who fixed a critical problem in Chrome.  But it turns out this was a chained exploit, and Chrome was just providing the front door.  But once you got in you needed to elevate your privilege.  And it turns out there's a way.  



LEO:  Now we know how.



STEVE:  No one knew how to do that before.



LEO:  Oh, nice.



STEVE:  Yeah.  We've also got a, speaking of Microsoft, a public service reminder from Microsoft.  They're trying to be as responsible as they can after the fact.  We've also got an interesting plan.  People are going to be skeptical, but we'll talk about it.  I'm kind of impressed with at least what they're saying, and that's Google's newly announced plan to get into the VPN service business.



We also have CERT, who has announced an unappealing plan for automatic vulnerability naming.  So no more Honey Monkeys, which I think is going to be a mistake.  But we'll talk about that.



We've also had a real mess with WordPress's attempt to update - and I didn't realize this, Leo.  They have 455 million sites.



LEO:  Oh, yeah.



STEVE:  That's a lot of sites.



LEO:  Yeah.  They're rapidly closing on half the Internet.



STEVE:  Boy.  Then we're going to close a loop with one of our listeners, who just sort of provided an interesting bit of feedback from the field, from stuff we've been talking about.  I'll give a brief update on SpinRite because it's where I'm spending all of my time now, as our listeners know.



And then we're going to finish by examining another Google thing.  Google's decided to create their own CA browser root program for the first time ever.  The only one who has their own, really as a consequence of the legacy, is Mozilla, with Firefox.  But I think Google's probably always been a little envious of the control that that gives Firefox and Mozilla.  They've always wanted their own.  Well, that's going to happen now.  So some interesting stuff to talk about for the week.



And, oh, I found this thanks to one of our listeners who tweeted this photo to me for the Picture of the Week.  It's a classic.  It's right up there with the gate in the middle of the path, with the well-trodden dirt paths that are just going around the gate.



LEO:  This is similar.



STEVE:  This is like right up there.  And notice this is a seriously - this is a big, thick cable on this bike lock.  You are not going to cut through that cable.



LEO:  You don't need to.



STEVE:  So you just might as well give up; right?



LEO:  Right.



STEVE:  Actually, there was one - remember the one we had where some bolt cutters were being protected by a cable in a hardware store so you couldn't take the bolt cutters away.  It's like, okay, wait a minute, they're bolt cutters, guys.



LEO:  Oh, it's a suggestion, that's all.  Just a suggestion.



STEVE:  That's right.



LEO:  Sometimes security is just a suggestion.



STEVE:  Sometimes it's just theater.



LEO:  Yeah, a lot of times.  All right.  We're ready.  Picture of the Week time.



STEVE:  Okay.  So for our listeners who are, well, listening, we have a series of yellow steel concrete-filled poles, you know, the kind that would block at the end of a driveway or a roadway where you didn't want cars to be able to drive through.  And  someone has chained or cabled their bicycle up to one of these.  The only problem is it's a pole.  And it's, well, maybe like a foot taller than the bicycle.  And you wouldn't even really have to lift the bike very high in order to pull the cable off of the top of the pole and then ride away with this bicycle.  So this is more of a - I guess this actually is sort of like that path photo that we like so much, Leo.  It displays a request.  It displays an intent.



LEO:  Yes, it's a suggestion.



STEVE:  It has no actual ability to - it's not enforcing the desire.



LEO:  Merely suggesting it.



STEVE:  It's just sort of saying, you know, this locked gate on this path, even though you could go around it, clearly we're trying to say please don't.  Similarly, this bike cabled to a pole, which is completely ineffective, is saying, look, this is the honor system.  I clearly am saying I've not left this bike out here just for anyone to walk away with.  I've cabled it to a pole, which doesn't stop you from taking it.  But clearly my intention is that you not.



LEO:  Yeah, yeah, please don't, yeah.



STEVE:  So it's the honor system of security.



LEO:  You could.  You could, but don't.



STEVE:  Yeah.  I don't think that'll work with Russian cyberattackers.  But we could hope.  Okay.  As I said, we have a new zero-day, and it's complicated by the fact that it has existed at least since Windows 10.  Which, as we know, Microsoft has...



LEO:  At least since Windows 7.



STEVE:  Oh, I'm sorry.  Yes.



LEO:  7, yes.



STEVE:  At least since Windows 7.



LEO:  Wow.



STEVE:  So last week we talked at some length about the bug Google found in the FreeType library, which had been in use since June 19th, 2015, so more than five years.  What we knew  then was that this flaw, which was patched by that update to Chrome, was a zero-day because it was being actively exploited.  They fixed it, when they were notified, they fixed it within 24 hours, which was impressive response.  And they notified the FreeType people, who also fixed it within 24 hours.  Also impressive.



What we did not learn until the end of last week was that there was a previously secret second part to this zero-day.  The FreeType flaw was what was being exploited through Chrome to open the door to the attacker.  But as is often the case, thanks to modern operating system design, the damage that can be done by an aberrant application or exploit of an aberrant application running under the non-root user account is deliberately minimal in modern operating systems.  All of today's web browsers are careful to run under the user's deliberately limited account privileges.



This is why successful attacks and attackers often need to chain two or more exploits together to accomplish their nefarious ends.  If the FreeType Library happened to run in the kernel, then a single exploit in it might have been sufficient.  But FreeType was also properly designed to run in user space.  So exploiting the FreeType flaw opened the door, but the attacker then needed to elevate their privilege on the system to root or kernel level in order to get anything useful, like from the attacker's standpoint, done.



The week before all of this, Google had seen the whole picture, or presumably the person who informed them had.  They saw this second phase, which was leveraging a previously completely unknown and quite potent zero-day flaw in Windows to achieve privilege elevation.  This was allowing the attackers then to do some real damage.  The privilege elevation that they discovered by watching it in action existed, or actually I should say "exists" because it still does today, within the Windows kernel-based, thus we have a problem there, Cryptographic Services API.  And because that kernel-based module, the Cryptographic Services Module, exports an API that's callable from userland, the bad guys can arrange to run their malicious code with full system permissions.



Google's Project Zero folks immediately reached out to Microsoft to inform them of what they had found and also to explain that, since this was an active vulnerability being exploited in the wild, Project Zero's normal, patient, 90-day disclosure window would be reduced, as they even did for themselves, to just one week.  Actually, they only needed a day.  And that's why the industry subsequently learned of this only late last week.  That was seven days, actually eight, after Google told Microsoft.



So Google's Project Zero Day disclosure starts off with saying:  "Note:  We have evidence that the following bug is being used in the wild.  Therefore, this bug is subject to a seven-day disclosure deadline."  And we've seen these in the past when we've talked about this and looked at these.  In the period before the disclosure deadline, all there is is just like a placeholder page, no juicy details available because they're holding that embargoed until the problem can get fixed.



They begin their write-up by explaining:  "The Windows Kernel Cryptography Driver (cng.sys) exposes a \Device\CNG device to user-mode programs" - so in other words, the cryptography driver looks like a device which exposes services through a device driver interface to programs running on top of the operating system - "and it supports a variety of [what Windows calls] IOCTLs, (IO control calls)," they said, "with non-trivial input structures.  It constitutes a locally accessible attack surface that can be exploited for privilege escalation," and they said, "such as sandbox escape."



So of course they're viewing it from the standpoint of a sandbox escape because the way this would have gotten in was through the browser.  And we know that code running in the browser is deliberately sandboxed so that, if it does something wrong, it doesn't have access to much.  But by taking advantage of this, that code is able to escape from Google's own Chrome sandbox.



So Microsoft, for their part, doesn't see this as such an emergency.  Google has already closed and locked the front door through which attackers were able to reach the crypto API vulnerability.  And November's Patch Tuesday being next Tuesday, a week from this podcast's date of the 3rd, which will be November 10th, expects to have this fixed.  So we now have a detailed description of the flaw, and the Project Zero guys even published proof-of-concept code which can be used as a demonstration of this to crash any Windows system.  It doesn't give you remote code execution.  They weren't going to go develop that to help the bad guys.  But this is the Project Zero deal is we'll give you a length of time to fix it, and then we're going to disclose it, which they have.  So it's a little unfortunate that Microsoft doesn't see this as a big deal.  And maybe it's just a function of one week from now before they'll have this thing patched.



But the other problem is that this is also known to afflict Windows 7 machines, which will not, as we know, ever receive a patch for this unless they're within an enterprise that is now purchasing security for their older machines from Microsoft.  The rest of Windows 7 users are left to fend for ourselves.  But to that end, although it hasn't happened yet, we can hope and expect that the micropatch folks at 0patch.com have been watching, and that they will again be able to offer one of their cute little patchlets for this, as soon as Microsoft offers the patch.  They typically go in, they reverse engineer it, they cutify it, because it ends up being like 28 bytes or 12 bytes or something ridiculous, and then they'll offer it to systems that are not otherwise being patched by Microsoft.



Sometimes they do this for free, but that's normally only until Microsoft has had a chance to respond in any way that they're going to, at which point then it's only their subscribers who are able to continue to receive this.  So this is an inexpensive way.  We've talked about these guys several times, for people who aren't comfortable continuing to run Windows 7 without any OS-level patching.  Our browsers are all being patched.  Chrome was immediately patched to close the front door to this.  But for what it's worth, now we know there is this other privilege elevation flaw which anything that can find some other way in could then arrange to execute itself with kernel privileges on Windows 7 machines that aren't being otherwise patched.



So if you want to buy yourself some additional security, then I think these micropatch guys are worth looking at.  And I know, Leo, it makes you feel a little queasy to have some third party patching Windows.  But they're really very transparent.  They publish the source code for these  things often and just sort of provide it as an inexpensive service.  So I think better than nothing, depending upon how you're using Windows 7.



Which brings us back to Zerologon - oh, boy - and what I called a "public service reminder" from Microsoft.  Last Thursday, continuing to feel the need to respond to this ongoing exploitation of this very serious Zerologon vulnerability - remember that two weeks ago in our podcast "Anatomy of a Ryuk Attack" we saw the Zerologon vulnerability being used by Ryuk or Ryuk or however you pronounce it, you know, for the delivery and exploitation of a ransomware attack on an enterprise.  So it's very real.



Anyway, they tweeted on the 29th:  "Reminder to all our Windows customers to deploy at least the August 2020 update or later and follow the original published guidance to fully resolve the vulnerability."  And then we have the CVE-2020-1472, which will probably live in infamy, although it's much easier to know of it as Zerologon.  We'll be talking about CVE numbers here in a little bit.  So anyway, for what it's worth, anybody who's listening to this podcast I'm sure long ago themselves patched.  But, boy, there is still an inventory of systems out there that aren't, and apparently aren't ever going to.



And this just, you know, Zerologon is the dream horizontal movement through an enterprise's network once some unwitting user clicks on a link and allows something to run in their email client.  This thing is like every bad guy's dream about how to then take hold of an enterprise because enterprises tend to have domain controllers, and this thing allows you to bypass authentication.  So, boy.



Okay.  Google One has announced - well, Google in the guise of Google One - adding a VPN, bringing up a VPN service, initially for Android.  They've just announced they're going to be getting into the VPN business.  That is, Google has.  They'll be adding a no-additional-charge VPN facility, first for Android users only.  Scuttlebutt is that's just the tip of the iceberg, though.  They're adding this to their existing paid Google One service.  And as I understand it, I don't pay Google, but for free you get 15GB of Google Drive and Gmail and, you know, sort of cloud stuff.  And if that's not enough, then for $10 a month or $100 a year you can expand that to 2TB.



LEO:  Yeah.  It's basically what Google Drive used to be.  They call it Google One now, with some additional features.



STEVE:  Okay.  Got it.  So because Google is Google, the announcement of them doing a VPN has been met with some well-deserved eye-rolling.  Actually, ProtonVPN just went off.  We're going to come back to this because of some interesting technology that they will be incorporating into this, some cool stuff we've never talked about before, and maybe I'll talk about other VPN providers.  But ProtonVPN was, I mean, Google's a big competitor; right?



LEO:  That's the issue; you know?  I mean, you could probably say, well, do you want the biggest advertising company in the world to be running your VPN?



STEVE:  Exactly.



LEO:  But Google's been always pretty good about not, you know -  I don't know.  I don't know how I feel about it.



STEVE:  Well, so that's why we're here talking about this.  So they are saying all the right things, Google is.  And they are bringing, as I mentioned, some new technology to bear which has never been done on a VPN, which Google can afford to do, due to their specific posture.



So first of all, to sort of set this, here's how they, Google, describe the problem and the way they're intending to solve it.  They said - and actually some interesting stats I hadn't known.  I didn't realize VPNs were this popular.  They said:  "Demand for VPNs is growing, with evidence that it's becoming more mainstream."



LEO:  Yeah, I think so.



STEVE:  "Up to 25%" - huh?



LEO:  Yeah, I think that's what we're experiencing, too, yeah.



STEVE:  Wow, "25 percent of all Internet users accessed a VPN within just the last month of," they said, "of 2019."  So that was even pre-COVID.  They said:  "Unfortunately, not all VPN providers have been proven to be trustworthy."  Okay, this is Google.  But still, as you said, Leo, I'm glad you did, Google, well, of course they've now got the DOJ breathing down their necks.



LEO:  I guess I would read the privacy statement carefully.  But they're not going to lie in the privacy statement.



STEVE:  Well, no.  Right.  So they said:  "Some services are vulnerable; others request unnecessary access to their users' data [huh] or monetize the same data [again huh] that users are utilizing the VPN to keep private and secure; while others fail to deliver on the promise of not logging their users' online activity."  So again, Google is going to be a non-logger.



They said:  "With growing demand for better privacy in a mixed landscape of solutions, we have used our expertise in privacy, cryptography, and infrastructure to build a Google-grade VPN that provides additional security and privacy to online connectivity without undue performance sacrifices.  With VPN by Google One, users' online activity is not identifiable to the VPN and not logged by the VPN.  We believe a VPN must be transparent and robust.  That's why we've open sourced our client and will provide a third-party audit of the end-to-end solution to make them externally verifiable.



"Privacy is at the core of the products and services we build."  Okay.  "With VPN by Google One, we will never use the VPN connection to track, log, or sell your online activity.  Some minimum logging is required to ensure quality of service."  And I've seen online people attacking Google about what that minimum is.  Those are specious attacks.  I mean, Google is, as you said, Leo, I mean, Google's going to do what they're going to do, and they're not going to breach their own privacy guarantees.  And we could argue they don't need to, but we'll get there in a second.



LEO:  They don't need to, exactly.



STEVE:  Right.  "But your network traffic or IP associated with the VPN is never logged.  To demonstrate how our design works, we've open sourced the code that runs on a user's device."



LEO:  Perfect.  Perfect.



STEVE:  "And in the coming months we will be open sourcing the server-side user authentication mechanism, as well as providing the results of a third-party audit, currently underway.  These will provide further assurances of how user data is handled and how robust the VPN's security is."  And wrapping this up, here's the cool bit.



"Open sourcing our VPN and providing an audit are just some of the steps we're taking to ensure user privacy.  While building VPN by Google One" - which is, you know, the formal name - "we realized it was important to strengthen some of the systems that are often attacked or compromised in order to access users' personal data.  Traditional VPNs can sometimes compromise a user's identity or online activity by linking the usage of their service to the activity they conduct by means of a session ID.  This ID could allow VPN operators, or attackers that compromise their infrastructure, to eavesdrop and identify users and their activity.



"We wanted to eliminate that vulnerability by separating the authentication of the subscriber from their use of the service.  By employing a cryptographic blinding step between user subscription validation and connecting to the VPN, we give users a stronger guarantee that their online activity won't be tied back to their identity."  That's what's new.  So the technique is known as RSA Blind Signing, which Google will be using, and it's a real thing.  It's actually old, like 1998 the concept was first developed.  It provides a means for Google to verify that a Google One paying account holder has the right to use their VPN service, yet without revealing who that account holder is.



We've never discussed blind signing technology, but I think it would make a terrific topic.  So we will.  And although, as I mentioned before, Google hasn't yet said so publicly, the word on the street is that this service for Android will eventually be offered widely across Google properties and, you know, like other clients for other desktops and so forth.  So I love the idea that their VPN itself is blinded to its user's identity as an account holder.  And frankly, I think that Google probably had no choice but to do that if they wanted to provide a VPN service since they're so strong now.  As we mentioned, the DOJ is breathing down their neck.



But we also all know that a user's browser's Google-tagged cookies, the instant they emerge from Google's VPN endpoint, will immediately scoot over to the nearest Google server to report in.  I mean, it's going to be like a zero hop.  I mean, it's going to be in the same building; right?  It's just going to go, bing, now I'm at the Google server.  So it's not as though the VPN provides any additional anonymity compared with any other VPN service.  But, and here's the key, I think, Google's use of cryptographic account authentication blinding means that at least it doesn't provide any less anonymity than the use of any other VPN service.  And there's a lot more to be said about this.  We'll be covering it in much more detail in the future.



So anyway, and they make a strong point.  They've got a strong infrastructure.  They're doing all kinds of cool stuff by looking at using DNS queries to figure out where the user is, and then automatically tie the user to the nearest VPN endpoint.  I mean, they're Google.  They understand infrastructure.  They've got a big infrastructure.  The promise is that initially any Android user who's also a Google One subscriber would be able to get the arguably useful benefits of running a VPN from their handset past the local WiFi hotspot, wherever they are, past that hotspot's ISP, and directly to Google, where their traffic would then emerge onto the Internet.  And yes, where all the Google cookies that they're already carrying would then instantly be gobbled up by Google.  But that's going to happen no matter whose VPN service you use.



LEO:  Yeah, yeah.  I love how you've personified them.  They're scrambling over.  The cookies are, "Oh, my home, my home."  Did they say what they're going to charge for that, just out of curiosity?



STEVE:  Free.



LEO:  So if you have a Google One account, which isn't free.



STEVE:  Right.



LEO:  But if you have that, you will get it.  Oh, that's interesting.  Yeah, I can see why Proton's a little worried.  Yeah, that's a little scary.  And yet I think that there will be plenty of people who will say, yeah, whatever.  I'm going to use a VPN from a company that's not Google.  Not in the advertising business.  I can understand that, too.



STEVE:  So this introduces a new section for the podcast, Leo, the Dumb Idea of the Week.  We have a proposal from CERT, of all people, or all organizations.  I think that giving catchy, sometimes humorous and descriptive names, often with matching graphic images, to security flaws is part of the fun of this industry.  We've had Spectre with that little spooky ghost with the stick hands, Meltdown, Dirty Cow, Zerologon, who can forget Heartbleed.  We've got BlueKeep, BLESA, SIGRed, BLURtooth we recently did,  DejaBlue and, you know, Stagefright was wonderful.



LEO:  That's a long history.  The very first virus.  Well, the Morris Worm, I don't know if that's a name.  But the very first widespread virus, the Melissa Virus, was given the name Melissa because that was in the code; right?



STEVE:  Yup.  Of course.



LEO:  And we remember it.  I wouldn't remember CVE-1992-1973.



STEVE:  Exactly.  And I'm always a little self-conscious when I'm spewing those off.  They sound like stardates.



LEO:  They do.  They really do.



STEVE:  It's like, what?



LEO:  Do they want to use the CVE numbering?  What do they want to do?



STEVE:  No, no, no, no.  Worse.  Well, yeah, it is worse.  So we've established that naming is important.  Not everybody agrees.  In a blog posting Friday, the original CERT, that's the one operating out of Carnegie Mellon University, which now collaborates and partners with the DHS's official US-CERT team, has proposed spoiling this particular bit of fun.  So the first thing I noted was that CERT's own blog posting was titled "Vulnonym."



LEO:  They made up a name.



STEVE:  Exactly.  They said:  "Vulnonym."



LEO:  Vulnonym.



STEVE:  "Vulnonym:  Stop the Naming Madness."



LEO:  Oh.



STEVE:  But of course Vulnonym is itself a fun and memorable name.  They didn't give themselves some serial number.  So what they have is an auto-vulnerability-naming service which they're proposing.  So here's what they said.  They said:  "Spectre, Meltdown, Dirty Cow, Heartbleed.  All of these are vulnerabilities that were named by humans."  Yeah, huh?  Anyway, sometimes, yeah, because they're good names.



LEO:  Shocking.  Named by humans?  How can we allow this?  I understand they don't want marketing, like they feel like maybe it's too, like, market-y.



STEVE:  Well, exactly.



LEO:  But they've got to be memorable.  We want people to remember the name so they know what they're worried about.



STEVE:  Right.  They said they were named by humans, "sometimes for maximum impact factor or marketing."  They said:  "Consequently, not every named vulnerability is a severe vulnerability..."



LEO:  Ah, that's reasonable, yeah.



STEVE:  "...despite what some researchers want you to think."  Okay, yeah, but Heartbleed was not good.  It was a great name.  And, you know, we all remember it.  Anyway, they said:  "Sensational names" - and believe me, they really solved this problem - "are often the tool of the discoverers to create more visibility for their work."  I think these guys are just sour grapes.  Anyway.



LEO:  They're just cranky.



STEVE:  "This is an area of concern for CERT as we attempt to reduce any fear, uncertainty, and doubt" - also known as FUD - "for vendors, researchers, and the general public."  Now, okay.  I would argue that the general public has relatively low exposure to these names.  No one knows what Meltdown is...



LEO:  No, that's true.



STEVE:  ...out in the public.  It sounds like something that once happened in Chernobyl, or when you leave your ice cream cone unattended.  But no one's thinking, oh, yeah, that's a vulnerability I need to worry about.  Anyway, they said, CERT said:  "Software vulnerabilities are currently catalogued by number, primarily the Common Vulnerabilities and Exposures (CVE) ID, which makes it very easy for computer analysis and storage.  However, humans aren't well conditioned to remember numbers.  Instead, humans prefer names because we find them easier to remember."  So really they're making our case, Leo.



And they said:  "We don't remember IP addresses, but do easily remember domain names to browse our favorite websites.  We also remember things like hurricanes, snow storms, operating system updates, particular geographic locations like cities or states, and so forth.  They are all named because it's easier to remember 'Mojave' instead of macOS 10.4, or 'Pittsburgh' instead of 40.4406 N by 79.9959 W."  Okay, CERT, you've made your point.



They said:  "Names of vulnerabilities in particular are matriculating into important spheres of influence.  Case in point, on July 11th, 2018, congressional testimony weighed the impacts of the 'Meltdown' and 'Spectre' vulnerabilities."  Of course those we know; right?  "The CVE IDs, CVE-2017-5753, CVE-2017-5715, and CVE-2017-5754 were never mentioned.  Only the sensational names were."  Okay, no.  Only the recognizable names were.  There's nothing sensational about "Meltdown" and "Spectre."  I mean, they're just not dry.  Anyway, they said:  "We aren't arguing that vulnerabilities shouldn't have names.  In fact, we're encouraging this process!"



LEO:  Okay, well, that's a matter of dispute.  But go on.



STEVE:  Yeah.  Just wait, wait.



LEO:  Wait'll you hear the names.



STEVE:  "Our goal is to create neutral names that provide a means for people to remember vulnerabilities without implying how scary or not scary the particular vulnerability in question is.  Our neutral names are generated from the CVE IDs to provide a nice mapping between name and number.  CERT decided that if we can come up with a solution to this problem" - spoiler alert, they haven't - "we can help with discussions about vulnerabilities as well as mitigate the fear that can be spread by a vulnerability with a scary name."  They said:  "We plan to name the vulnerabilities with a phrase of adjective/noun, for example, Arbitrary Albatross."  And I added here in the show notes, yeah, or how about Stupid Idea?



"When tackling this problem, we considered several lists of words to ensure no sensational" - oh, boy, did they achieve that - "scary, or offensive names were included.  We created the list of both adjective and nouns using the combined resources of the Wiktionary" - whatever that is, I didn't even bother to look it up.



LEO:  Wiktionary.  Yeah, yeah, yeah, yeah.  It's a wiki dictionary, yeah.



STEVE:  Okay, good, Wiktionary, "...and categories of words such as animals, plants, objects in space, and more.  Next, we created the method by which we map the CVE-IDs to the pair of adjective names."  Okay.  "After much consideration, we used the Cantor Depairing Function, which is a bijection between the natural numbers and a pair of natural numbers."  Well, obviously.  How else would you do it?



LEO:  Of course.  How else would you?



STEVE:  Of course.  Duh.  "This means that each natural number can be mapped to two natural numbers uniquely."  Because we wouldn't want any collisions of these fabulous new adjective noun pairings they've come up with.  "To test out this idea, we're operating @vulnonym" - so everybody wants to follow this.  This is going to be gripping.  This is a Twitter feed, @vulnonym on Twitter.  To publish the neutral names associated...



LEO:  This is an Onion article.  This can't be serious.



STEVE:  No, this is the truth.



LEO:  I can't believe it.



STEVE:  This actually happened.



LEO:  Oh, god.



STEVE:  And it's not even April 1st, "...associated with CVE IDs as they are issued.  Follow @vulnonym and let us know if this naming experiment is useful!  And in case anyone considers a word or name to be offensive, we have a simple process to remove it from the corpus and regenerate a name."



Okay.  So I digested this.  I checked out @vulnonym.  I'm not sorry that I brought all this up, since we may start seeing some very poorly named vulnerabilities, and we should understand what happened there.



LEO:  Oh, boy.



STEVE:  Okay.  So here are three tweets recently made by the @vulnonym tweet bot.  The first one, CVE-2020-4785 is called Whacking Mouflon.



LEO:  What?  What's a Mouflon?



STEVE:  A Whacking Mouflon.



LEO:  Whacking I get, but why is the Mouflon whacking, and who is a Mouflon?



STEVE:  We do not know.  But actually, Leo, this next one, the  next tweet?  "Hi, I'm CVE-2020-4649.  I was never good with numbers, though, so you can call me Unmatched Cwm."



LEO:  What?



STEVE:  Yes.  Spelled C-W-M.



LEO:  No one knows how to pronounce that, even.



STEVE:  There's no vowel.  There's no vowel.



LEO:  It's in Welsh.



STEVE:  Yes, it is.  I looked it up.  And if you were in Wales, you might know that it means a steep-sided hollow at the head of a valley.



LEO:  Yes, I did know that, actually.



STEVE:  Or on a mountainside.



LEO:  But it don't think you want to use it in common speech.



STEVE:  Well, no.  Have you been hit by the Unmatched Cwm?



LEO:  So are these real CVEs that they're tweeting?



STEVE:  Yes, yes.



LEO:  2014-1060 is Cyclic Hyrax.



STEVE:  Yes.  Now, isn't that catchy, Leo?  Wouldn't you like to have the Cyclic Hyrax vulnerability?



LEO:  This is ridiculous.  They just need better dictionaries.  I mean, if they had better dictionaries, maybe.



STEVE:  Then they could be fun.



LEO:  They could do what the NSA's doing; you know?



STEVE:  It's clearly their intention - I don't know who these people are.  They don't want anyone to have any fun.  We could not have Honey Monkeys if these guys were in charge.



LEO:  CVE-2020-16006 is Privileged Ukulele.  That one's at least kind of memorable.



STEVE:  Yeah, okay.



LEO:  They should have adjective/noun, and make the nouns a little more common.



STEVE:  Yeah, not Cwm.  What is a Cwm?



LEO:  What's a Cwm?  If you're Welsh...



STEVE:  Or a Mouflon.



LEO:  I think a Mouflon sounds like an animal, yeah.



STEVE:  It's whacking, whatever it is.  The Mouflon is whacking.  I don't know.



LEO:  Caring Doeg, D-O-E-G.  I'm sorry, Uncaring Doeg, that's CVE-2020...



STEVE:  Oh, it's really Uncaring?  Oh, my god.



LEO:  Uncaring D-O-E-G.  Equable Jawfish.



STEVE:  Maybe that goes with the Unmatched Cwm.  It's uncaring.



LEO:  These are the worst.  Lunar Termite.  Brisk Squirt.  Oh, you don't want Brisk Squirt.  I don't know what it is, but you don't want it.  Unvarnished, what is a Sarrusophone?  What the hell is a sarrusophone?



STEVE:  You want to report that one to your GP.



LEO:  Doctor, I've got a Brisk Squirt.  I need a shot of some kind for that.  Orchestral Waterphone.  Transverse Vison.  Voiced Adder.  Some of these are okay.  If it had less uncommon words, it wouldn't be that bad.



STEVE:  You know, so maybe the problem is the bot is unmanaged.  They need a managed bot.



LEO:  Or a better dictionary.



STEVE:  Somebody needs to look at these.



LEO:  What's a Sher?  Rakish Sher?  What's S-H-E-R, Sher?



STEVE:  Well, apparently that's in Wiktionary.



LEO:  That's a mistake.  It's too - they need a better word list, I think.



STEVE:  Yeah.



LEO:  Although, if you're going to be a vulnerability, I hope somebody comes along and names a vulnerability Brisk Squirt, just so we get to keep that one.  That one I would keep.  Oh, my god.  "Did you get the patch for Brisk Squirt yet?"  "No, man.  I'm suffering, dude.  Man, am I suffering."  Oh, my god.  I'm looking:  Uninvolved Dulcimer.  That's not bad, an Uninvolved Dulcimer.



STEVE:  That's not bad.  We could keep that one.



LEO:  Prominent Caterpillar.



STEVE:  If they have some personality, yeah.



LEO:  Sulfa Bonefish.  I think that's going to be my pseudonym from now on.



STEVE:  Okay, wait.  Sulfa is an adjective?



LEO:  Yeah, no, I don't think so.  So I think it's just - they're just taking random words.  It needs to be adjective/noun.  It needs to be common nouns, or at least a little more common than Cwm.  No Welsh allowed.  You've got to have at least one vowel per name.  Legless Umber.  Pensive Snakehead.  Grouchy Camelopardalis.  You don't expect security researchers to say that out loud.



STEVE:  Well, and what is the general public going to do with this?  I mean, they seem to be worried, you know, now compare this to Spectre and Meltdown.  This is like...



LEO:  And what you don't want is a chained vulnerability with Brisk Squirt and Roaring Swallower.  Then you've got a problem.  Imagine the chained vulnerabilities.



STEVE:  You know, Leo, Brisk Squirt is what you use to open the front door; right?



LEO:  And then you use Roaring Swallower to do the privileged escalation.  Oh.  Oh, my god.  What were they thinking?  I'm following this Twitter bot though because...



STEVE:  Clearly.



LEO:  I'm going to get a laugh every day from this.  Holy cow.



STEVE:  Is that one of them?  CVE-2020 Holy Cow?



LEO:  And, see, that's another problem.  What are they going to do?  They're going to have a special elimination of actual things that make sense?  



STEVE:  Wow.  I guess Brisk Squirt might be more the backdoor than the...



LEO:  I like Brisk Squirt and Roaring Swallower.  I don't know.  Definitely there's a chained vulnerability of some kind.



STEVE:  It's really going to be dangerous.



LEO:  Retrospective Gerbil?  No.  No, no, no.  I'm sorry.  There's just too much weirdness in this.  It's just not...



STEVE:  And it isn't April 1st or like something from the Onion.  It really actually is CERT.



LEO:  You don't want this one.  Undressed Mephitis.  It sounds like a venereal disease.  Wait a minute.  M-E-P-H-I-T-I-S.  Mephitis.  Oh, wow.  It's a noxious or foul-smelling gas or vapor.  You don't want, you definitely don't want Undressed Mephitis.



STEVE:  Ugh.  I don't think you want Mephitis with or without your clothes.  Ugh.



LEO:  Why would they allow "mephitis" to be in the dictionary?  You don't need that word.  Natty Gazelle, that's good.



STEVE:  It was supposed to be memorable.



LEO:  Yeah, no.



STEVE:  There's nothing memorable about Mephitis.



LEO:  Bearish Bushbuck.  Driverless Major.  Purulent Bandfish.  Unpainted Oto.  Okay.



STEVE:  I mean, it is a little bit like Mad Libs, Mad Libs for security vulnerabilities.  



LEO:  The Twitter feed, V-U-L-N-O-N-Y-M, vulnonym.  I just - I think some undergrad wrote this paper.  I do.  Oh, wow.  All right.



STEVE:  Okay.  



LEO:  Too late to name the show Squirting Whatever.  Probably too late, yeah.



STEVE:  Oh, boy.



LEO:  Steve.  That's the howl of the day.  Wow.  Wow.



STEVE:  Okay.  Stop reading it, Leo.



LEO:  I can't.  I'm looking away.  I'm looking away.  Do not look at the vulnonym.



STEVE:  Back on Earth, we have WordPress, who has fumbled an important update, you know, just after I was telling everybody last week that they should just be updating everybody's WordPress installations because bad problems need to get fixed.  Last Friday they patched 10 security bugs as part of their release 5.5.2.  The most severe problem patched would have allowed a remote, unauthenticated attacker to take over a targeted website through what they described as a narrowly tailored denial of service attack, whatever that means.  Actually I figured out what it was here in a minute.



WordPress wrote that:  "The vulnerability allows a remote attacker to compromise the affected website.  The vulnerability exists due to improper management of internal resources within the application, which can turn a denial of service attack into a remote code execution issue."



Okay.  The researcher who found the bug described it as interesting, but likely difficult to carry out in the wild.  He said:  "You have to be able to produce a very accurate DoS attack."  Okay, whatever that - an "accurate" DoS attack?  He said:  "The principle is to trigger a denial of service on MySQL so that WordPress will think that it's not installed, and then un-DoS on the DB" - the MySQL database - "under the same execution thread."  Okay.



Anyway, v5.5.2 also brought a bunch of feature enhancements in addition to the 10 vulnerability fixes, one of them being really - that one being really important.  WordPress described the updates as a short-cycle security and maintenance release, to fill in before the next major release, which will be 5.6.  And with the update, all versions since WordPress 3.7 will also be current.  So that was how WordPress hoped things would go with the update that they were beginning to push out to 455 million sites.  Boy, Leo, with that kind of install base they really have to be careful.



LEO:  Yeah.



STEVE:  I mean, they really have to be careful.  And they weren't.



LEO:  Oh.



STEVE:  It was soon discovered that this 5.5.2 was badly broken.  It turned out that 5.5.2 was causing new WordPress installs based upon that release to fail.  And so anybody who was attempting to do a new WordPress install of 5.5.2, it would fail.  As soon as they became aware of the mistake, they put the brakes on its rollout.  But they screwed that up, too, by inadvertently triggering the release of an unreleased and not debugged alpha version of WordPress, which they started downloading to customers.



So the first thing that happened was that WordPress site operators began reporting that, because of the 5.5.2, that new WordPress installs were failing.  And apparently others were complaining about broken admin login pages, which as another effect of that.  So scrambling around, WordPress said:  "5.5.2 caused an issue with installing ZIP packages available on WordPress.org for new versions of 5.5.x, 5.4.x, 5.3.x, 5.2.x, and 5.1.x."  They said:  "The issue only affected fresh WordPress installations without an existing wp-config.php file in place."  Thus new because they wouldn't have had that file as opposed to upgrading where that file would already exist.



They further explained:  "While work was being done to prepare for WordPress 5.5.3" - which was the fix to the mistake that they made with 2, which was what caused this new installation problem - "the release team attempted to make 5.5.2 unavailable for download on WordPress.org to limit the spread of the issue noted, which only affected new installations.  But this action resulted in some installations being updated to a pre-release '5.5.3-alpha.'"



Unfortunately, the alpha release mis-installation brought with it the old default "Twenty" themes and the Akismet plugin as part of the pre-release 5.5.3-alpha.  So that messed things up.  And admins who had not asked for any pre-release install were suddenly being greeted with the message:  "BETA TESTERS:  This site is set up to install updates of future beta versions automatically."  So they were like, what?  What just happened?



So in the wake, you can imagine, of all of this unasked-for auto-update mess, many WordPress admins were vocally worried and upset about the whole "not under their own control" issue.  And, you know, it's a problem that we have.  We of course were just talking about this last week.  I took the position, and I have taken the position, that anything hooked to the Internet needs to have the capability of being updated automatically.



But, you know, in light of all this, and standing back from it a bit and sort of looking at what Microsoft has done, maybe Microsoft's semi-compromise stance with Windows 10 is the best we can do.  Notify everyone of updates.  Kind of give them some push to update now.  But allow that "now" to be deferred for some length of time, to a more convenient time.  But ultimately, if they keep pushing it off, force the issue, if necessary, and especially if there's like a really critical issue that needs to get fixed.



And of course the problem is an operating system can notify its users.  Normally there's somebody there typing at the screen.  But there's no clear way for someone's router or most other IoT devices to notify them.  So I don't know.  I think we're going to need to have some sort of standards defined and adopted so that we can move this whole dilemma into history.  And as we know, my real complaint with Microsoft and Windows 10 is that they've taken the path deciding that they are never going to leave it alone.  They're going to keep changing things.  And that means because the system is so huge and so complex that nobody understands it anymore, that things are going to break.  And it's never going to have a chance to settle down and get the bugs worked out of it.  They're going to keep, they do keep introducing new problems all along the way.



So anyway, I just thought it was really interesting that here, you know, I was just talking about WordPress's need to, yes, push - well, remember there was a really bad, like a flaw in an update which they proactively patched.  I would always agree they have to do that.  But boy, Leo, they've got 455 million installations, they just have to be really careful.  I wouldn't want that responsibility.



LEO:  And it's written in PHP, which doesn't help.



STEVE:  No.



LEO:  Right?



STEVE:  No, you're right.  Personal Home Page.



LEO:  They didn't even bother to update the meaning.  They could have tried some retronym that made more sense.  But it's still Personal Home Page.  Come on, Rasmus.  Come on, man.  On we go with the show, Steve.



STEVE:  So just one little bit of feedback from a listener, Spencer Salmon.



LEO:  Not his real name, by the way.



STEVE:  Yeah, it does sound like a CVE.  He says:  "I just finished last week's podcasts, and you mentioned IE and Edge.  Interesting fact.  I work in the financial industry, and our core provider's web app is only compatible with IE."  And then he said in parens, "ActiveX."



LEO:  See?  That's why people still use it, yup.



STEVE:  Yup.  And, I mean, geez.  I guess I would wonder if a provider that was still there and hadn't moved forward was like a going concern.  Because, you know, IE is dying.



LEO:  Well, ActiveX.  Should anybody be using ActiveX?  That's so bad.



STEVE:  Yeah.  It was a bad idea.



LEO:  I remember you castigating it when they announced it.



STEVE:  Yeah.



LEO:  It basically allows arbitrary code on the web to run on your machine with full privileges.



STEVE:  It's misbegotten.



LEO:  Misbegotten.



STEVE:  Yeah.  Elk.  I'm sure that's a CVE.  Anyway, last week my time went into overhauling a bunch more of the earlier code on the pre-AHCI IDE/ATA driver code.  The way I had originally written that first cut exploratory code back in 2013, it wasn't ever intended to be production ready.  But the way this project is evolving, the sooner I can make it production ready, the sooner we'll have SpinRite.



So as I said last week, I've been realizing that I have an opportunity to pre-test pretty much all of what will become SpinRite's new foundation within the context of an interesting and surprisingly, well, interesting and low-level benchmark, which produces some surprising results.  So I'm taking that opportunity now, basically investing in SpinRite so that I can get as much of this code tested as soon as possible.  So I again expect that I'll have something to announce very soon.  But I keep seeing more opportunities to fix things.  And so no time like the present.



Okay.  Chrome's Root Program.  A little less than two weeks ago a new page appeared at Chromium.org titled "Chrome Root Program."  And it was not met with universal joy.  We'll get to that in a second.  Of course this podcast has covered the operation of SSL/TLS web server trust certificates at great length because its proper operation and functioning is crucial to enabling users and their web browsers to establish a trust relationship with otherwise unknown remote web servers.  Now we just all take it for granted.



And as we know, the system is far from perfect.  It has a myriad of well-known failure modes.  It relies upon several different actors, each performing their jobs perfectly, where failure by any of them to do so results in a local breach of the privacy and security guarantees which is the system's entire purpose.  But for better or for worse, it's the system we have today.  Someday, maybe something will obsolete it.  But again.



Okay.  So from the beginning, Chrome and most other browsers, "most" with a single exception, have all relied upon the connection security and certificate verification provided by whatever operating system they were running on.  The notable exception to this has always been Mozilla and Firefox.  To their credit, Netscape, way back then with their Netscape Navigator, invented SSL 1.0, and the concept of using public key cryptography to provide both server authentication and connection content privacy.



Over time, this evolved into NSS, which is Mozilla's Network Security Services.  NSS is the SSL/TLS library upon which Firefox runs and which it uses to provide all of its network connection security.  Since NSS is cross-platform and a freestanding component of Firefox, it includes its own root certificate store which anchors the validation chain of any certificate received from a web server that Firefox is connecting to.  All other web browsers, which inherently have a shallower history than Netscape's Navigator, since it was the first, and Mozilla's Firefox, which is a descendant, rely, as I mentioned, upon the hosting OS's platform for their connection security.



But how many times have I noted that today's modern cryptography is a solved problem?  What was once decidedly regarded as highly complex, don't mess with it, magic crypto from some ivory tower guru, is now run-of-the-mill.  So the barrier to entry of bringing up a new TLS communications foundation from scratch is as low as it's ever been, which is quite low now.



So against that backdrop, Google's new Chrome Root Program really shouldn't surprise us.  Google wants control over this aspect of Chrome's operation, which it has until now delegated to its hosting OS.  Chrome was able to operate on the sidelines.  We've talked about how this works through the years.  Basically it was able to watch the connections, blacklist and pin certificates.  But it's never been in the position to directly and completely manage the Root Store which underlies its browser's trust.  And you know, knowing Google, that's got to chafe.  So they finally decided, okay, we're just going to do this.



But running a Root Store program is also a significant responsibility since who you need to, well, it's a responsibility because you need to be very careful about deciding who you let in, who you don't, who you may need to kick out based on their behavior.  Over the years, the podcast has tracked a number of these incidents.  And of course these decisions that you make directly affect your customers' security and their ability to get to wherever it is they're trying to go.  Remember this torturous decision that the browser and OS vendors had to make when StartCOM was clearly found to be misbehaving and issuing certificates that they should not have been.  And it wasn't just that they made a mistake.  It's that they weren't forthcoming with it.  And that's almost a bigger no-no than making a mistake.



So from its position, which has up until now been on the sidelines, Google as I mentioned was able to sniff the certificate exchange and block certificates that, for example, after the decision was made to stop accepting certificates signed by StartCOM, they couldn't remove the StartCOM cert from the underlying OS's Root Store because it wasn't theirs to manage.  So clearly it makes sense, with Chromium going the way it has, that Google is going to just run their own.



So their low-key announcement of their intention to develop and run their own Root Store program, it establishes the importance of the browser's Root Store with this very short description that sort of states their case.  They said:  "When Chrome presents the connection to a website as secure, Chrome is making a statement to its users about the security properties of that connection.  Because of the CA's (Certificate Authority) critical role in upholding those properties, Chrome must ensure the Certificate Authorities who issue certificates are operated in a consistent and trustworthy manner.  This is achieved by referring to a list of root certificates from Certificate Authorities that have demonstrated why continued trust in them is justified.  This list is referred to as a 'Root Store.'  The policies and requirements for participating and being included in a Root Store are known as a Root Program."



So for longstanding, tried-and-true certificate suppliers with a  well-known, time-proven track record and impeccable credentials, like my own favorite provider DigiCert, inclusion in Google's, Mozilla's, and any other operating system's Root Store is pretty much a pro forma no-brainer.  But the world has a great many certificate authorities of somewhat questionable reputation.  And deciding whom to trust can be very political, as we've seen in some of these discussions.



So since the security of the Chromium project's upcoming Root Store is of crucial importance, I wanted to share the inclusion policies and their underlying philosophy.  Just sort of it's interesting to get sort of a snapshot into this.  Google said:  "The explanations below describe the Chrome Root Program, and policies and requirements for CAs to have their certificates included in a default installation of Chrome, as part of the transition to the Chrome Root Store."  Because of course it doesn't exist today, and everyone wants to be in it tomorrow.



So they said:  "Historically, Chrome has integrated with the Root Store provided by the platform on which it is running.  Chrome is in the process of transitioning certificate verification to use a common implementation on all platforms where it's under application control, namely Android, Chrome OS, Linux, Windows, and Mac."  And this is interesting.  "Apple policies prevent the Chrome Root Store and verifier from being used on Chrome for iOS."  Yes, it's too closed.  On iOS you have to use their underlying connection architecture.



LEO:  WebKit, yeah.



STEVE:  So, yes, with that comes their Root Store.  They said:  "This will ensure users have a consistent experience across platforms, that developers have a consistent understanding of Chrome's behavior, and that Chrome will be better able to protect the security and privacy of users' connections to websites."  You know, yeah.  They just want control.  They want to run their own store.  They said:  "For CAs that already participate in other public Root Programs, such as the Mozilla Root Program, many of these requirements and processes should be familiar."



They said:  "During this transition, the Chrome Root Store contains a variety of existing Certification Authorities certificates that have historically worked in Chrome on the majority of supported platforms."  So, yeah, naturally they're going to start with the standard set of CAs.  They said:  "This promotes interoperability on different devices and platforms and minimizes compatibility issues.  This should ensure as seamless a transition as possible for users.



"In addition to compatibility considerations, CAs have been selected on the basis of past and current publicly available and verified information, such as that within the Common CA Certificate Database," which is known as a CCADB.  "CCADB," they wrote, "is a database run by Mozilla and used by a variety of operating systems, browser vendors, and Certification Authorities to share and disclose information regarding the ownership, historical operation, and audit history of CA certificates and key material."  So in other words, they're not just going to grab everything and not verify that it's something that they for their own store agree that they really want to have in theirs.



They said:  "For CAs that have not been included as part of this initial Chrome Root Store, questions can be directed to chrome-root-authority-program, with hyphens, @google.com.  Priority is given to CAs that are widely trusted on platforms that Chrome supports in order to minimize compatibility issues.  For the inclusion of new CA certificates, priority is given to CAs in the following order, in order to minimize disruption or risk to Chrome users."  And they've got a list of five, so here's the order.



First, CAs that are widely trusted and which are replacing older certificates with certificates and key material created within the past five years and have an unbroken sequence of annual audits where these certificates and key material are explicitly listed in scope.  Two, CAs whose certificates and certificate hierarchy are only used to issue TLS server certificates and do not issue other forms of certificates.  Three, CAs that have undergone a widely recognized public disclosure process regarding their CP, CPS, audits, and practices.



So CP is Certificate Policy, which is a formal statement that the Certificate Authority has published, and CPS is Certification Practices Statement, another formal statement.  At this time, they said, the only discussion process recognized as acceptable is the discussion process operated by Mozilla on behalf of the open source community at mozilla.dev.security.policy.  Okay.  So that's a newsgroup.  And it is fascinating.  If you're curious to see how the sausage is made and, surprisingly, how much sausage there is to be made, you really need to check out mozilla.dev.security.policy.  If you just google that, the first link is a link to groups.google.com.  It's basically the Google view of this old-school NNTP-style newsgroup, mozilla.dev.security.policy.



It is so easy for us to underappreciate all the hard and really thankless work that goes on, to our immeasurable benefit behind the scenes by real people who we'll never know to thank.  When you just look at some of these discussions, it's like, wow, I mean, like there's just so much work that they're doing on our behalf, in order to end up with this heavily curated list of certificates.



LEO:  Thank you.  Thank you.



STEVE:  So continue down in priority, four, CAs that maintain sole control over certificate key material within their CA certificate hierarchy, and include their entire certificate hierarchy within a single audit scope.  And, finally, CAs that have been annually audited according to both the "WebTrust Principles and Criteria for CAs" and the "WebTrust Principles and Criteria for CAs - SSL Baseline with Network Security."  So, yes, this is lots of bureaucracy, but it's bureaucracy we depend upon in order to have the security that we just so casually take for granted.



LEO:  Yup.



STEVE:  So they said:  "Certification Authorities who do not meet all of the above criteria will be dealt with on a case-by-case basis.  Note that the requirements above are illustrative only; Google includes CAs in its Root Program, and includes or removes CA certificates within its Root Store as it deems appropriate for user safety.  The selection and ongoing membership of CAs is done to enhance the security of Chrome and promote interoperability."  Obviously, we don't want any certs that we have any reason to believe would endanger our users, yet we want all the certificates that people actually need in order to be able to go where they want to go on the web.



Then they said:  "CAs that do not provide a broad service to all browser users are unlikely to be suitable."  In other words, you know, if you're some CA that just wants your cert in the Chrome Root Store because, but if you'd have it like signed, like a significant number of active web servers certs, then it's like,  no, we're not putting you in.  They said:  "As this transition occurs, CAs should continue to work with the relevant vendors of operating systems where Chrome is supported to additionally request inclusion within their root certificate programs as appropriate."



Obviously, if everyone has the same basket of certs, that's going to be best for interoperability, and it gives Chrome a better place to launch from.  But Google wants, ultimately, Google wants control of their own Root Store.  They said:  "This will help minimize any disruption or incompatibilities for end users by ensuring that Chrome is able to validate certificates from the CA, regardless of whether it is using the Chrome Root Store or existing platform integrations."  So obviously there will have to be some sort of handoff between underlying OS store and Chrome's own.



They said:  "The Chrome Root Store Policy will be updated to more fully detail the set of formal ongoing requirements for working with Google in order to be distributed and included in a default installation of Chrome, as well as additional steps for applying or updating existing included certificates.  Any questions regarding this policy can be directed to..." blah blah blah.  And there's just more of this boilerplate that I'm going to skip because everyone has the idea.



So nothing too surprising here.  This feels as though it's a bit of a placeholder, like maybe largely cribbed from other Root Store program guidelines.  It does indicate that it will be refined over time.  So we could perhaps expect more specific requirements might be evolving.  And I mentioned at the top that this announcement was met with a moderate level of grumbling on some fronts.  And in doing some digging around, I found admins who are not happy about this.



We end-user consumers just happily click away on links, trusting that all of the plumbing underneath works correctly.  But there are those in the enterprise wearing well-worn plumbers' overalls who have identified that the proactive management of certificate Root Stores being a crucial anchor of trust throughout the enterprise can form an important and powerful management firewall.  If software needs to be signed by certs that are issued by recognized certificate authorities, and the same is true for websites, keeping a tight rein over the precise content of an enterprise's trusted Root Stores can form another potent line of defense.



And apparently that is being actively done.  There are admins who are very tightly controlling the Root Stores of their enterprise's fleet, for example, of Windows machines.  It's not just left up to the OS vendor.  So in light of Google's announcement that they would be splitting from the Root Stores of Windows, Mac, and Linux to go their own way, basically this grumbling took the form of, oh, that's just great, now we'll have another Root Store to deal with.  So these people were not happy.  And so, yeah, it'll make their lives a little bit more complex.  But on the other hand, it is the way Firefox has always operated.  So it doesn't seem like it's going to be a big deal.  And it's obvious that Google wants this for their own browser.



One question that wasn't clear to me is whether any given Chromium-based browser that is non-Chrome will be able to choose which store it uses, the Chromium Store that came with the browser, or the underlying OS's.  I suppose Microsoft might be willing to run their new and shiny Chromium-based Edge browser within the Chromium Root Store.  But it's going to be sitting on top of Microsoft's and Windows' own perfectly good Root Store.  So that seems sort of odd.  You know?  I mean, IE - is IE still in Windows 10?  Yeah, right, yeah.  Windows 10 still has that.



LEO:  Yeah, but they're really moving it out, yeah.  It's deprecated now.  I don't know how long it'll last.



STEVE:  Yeah, right.  



LEO:  They had to leave it in for those people using ActiveX.  Oh, god.



STEVE:  Yes.



LEO:  Yes.



STEVE:  Just say no.



LEO:  Just say no.



STEVE:  So that's the story.



LEO:  Okay.



STEVE:  With Google's Root Store.  We'll be moving away from an independent crypto, well, moving to an independent crypto architecture where the browser itself will be doing all of its own connections, rather than relying on the underlying OS.



LEO:  Steve, as always, clear as a bell.  You're fantastic.  This is a show worth listening to every week just so you keep up with what's going on.  But I think I learn more every single time.  I know you're waiting for me to come up with...



STEVE:  I was going to say, do we have...



LEO:  I know you're waiting for me to come up with yet another code name.  But I think I'll just stop.  I think Mutinous Genoveva was all I can do, and all I could take.  We do this show every Tuesday.  It's not always an election day, but it is today.  So get out there and vote.  Next week we'll be back after an Apple event that will be almost as exciting.  We get on at about - and next week might be a little delayed because of the event.  I'm not sure.  But I think we'll get on around 1:30 or 2:00 p.m. Pacific Time, that's 5:00 o'clock Eastern Time.  That's 20:00 UTC.



There's a live stream you can watch or listen to if you like to kind of watch behind the scenes.  That's TWiT.tv/live.  Audio and video is there.  But most people get the on-demand versions of the show.  That's why we call it a podcast.  Steve's got a couple of unique versions:  a 16Kb audio version for the bandwidth impaired, the truly bandwidth impaired.  But the even smaller version is the really beautiful transcriptions Elaine Farris writes.  Those are both available at GRC.com.  He also has standard 64Kb audio.  While you're there check out SpinRite, the world's best hard drive maintenance and recovery utility, fast approaching v6.1.  But if you get 6.0 now, you'll get 6.1 for free, and you can kind of participate in the early testing of 6.1, so that's probably worthwhile:  GRC.com.  Lots of other great stuff there.



We have the show, audio and video, at our website, TWiT.tv/sn.  You can also watch on YouTube.  There's a YouTube channel dedicated to Security Now!:  YouTube.com/twit.  The main TWiT channel has links to all of the sub show channels.  And of course the best way to get it would be subscribe.  That way you don't have to think about it.  You don't have to worry about it.  Just whenever you're in the mood, you say, oh, look, there's a new Security Now!, and you can listen to it on your device.



Steve.  I'm going to be hungover tomorrow, no matter what happens.  But I'll always be thinking of your Mutinous Gerbil.



STEVE:  Oh, good.  



LEO:  I'll keep it in mind at all times.  Have a wonderful evening, don't stay up too late, and we'll see you next week on Security Now!.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#792

DATE:		November 10, 2020

TITLE:		"Slipstream" NAT Firewall Bypass

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-792.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at the dilemma of Let's Encrypt's coming root expiration, new Chrome and Apple zero-day vulnerabilities, some new high-profile ransomware victims, China's Tianfu Cup pwning competition, the retirement of a PC industry insider, the continuing Great Encryption Dilemma, police monitoring of consumers' video, more ongoing pain for WordPress, a note about a sci-fi book event one week from now, and Samy Kamkar's tricky Slipstream attack and its mitigations.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  There's lots to talk about.  Let's Encrypt is facing a crisis on Android.  Steve will explain what's going on.  We're getting ready for Patch Tuesday, 113 new exploits.  Steve will give us a little heads-up on that, but we'll have our analysis next week.  And then we're going to talk about Slipstream.  This is something everybody with a router will want to pay attention to, a NAT firewall bypass.  We'll tell you how to fix it next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 792, recorded Tuesday, November 10th, 2020:  NAT Firewall Bypass.



It's time for Security Now!, the show where we cover your privacy, your security, how computers work, all of this stuff you need to know, with this guy right here.  He's our Explainer in Chief, Steve Gibson from GRC.com.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again for our 792nd episode.



LEO:  Wow.  Eventually those computers behind you will solve that problem.	



STEVE:  They're working on it.  You can see them.  They're just chugging away.



LEO:  Chugging away.



STEVE:  They're computing pi at the rate of one digit per year, I think.  They're not very fast.  So our title is something which I didn't have a chance to get to last week, but it was probably the most tweeted, like breathlessly:  "Hey, Steve, you've got to talk about this, you've got to talk about this on the podcast."  Well, anyway, so it's the topic.  It's Slipstream, which is our old friend Samy Kamkar, who's a hacker we've referred to from time to time.  He's done a bunch of Black Hat and Defcon presentations.  He came up with a way of bypassing the NAT firewall technology that we all take for granted and which is such a boon to those of us who want to be able to use the Internet, yet not have the Internet use us.  So that's our topic, the Slipstream NAT Firewall Bypass.



But there was a bunch of stuff that has happened in the intervening week, since we were all last together.  We're going to take a look at something interesting that's happening.  And I would love to know what's going on behind the scenes because it sounds like the Let's Encrypt folks suddenly realized that the root certificate that they had cross-signed in order to get themselves bootstrapped is expiring before they were ready for it to.  And like there's still a lot of - we'll talk about this - a lot of mostly Android OSes that never learned about the new replacement Let's Encrypt root cert.  And it's also interesting, too, because in retrospect this puts a different little spin on what we talked about, actually it was the topic of last week's podcast, Chrome's decision to do their own root certs because they kind of have to.  Anyway, we've got that.



We also have some Chrome and Apple zero-day vulnerabilities to discuss.  I'm going to touch on some new high-profile ransomware victims because that's the threat that just keeps on giving.  We have China's Tianfu Cup, which it's actually the third one of these which has happened.  That's their own kind of equivalent of the Pwn2Own competition.  That happened just this past weekend.  We also have the retirement of a well-known PC insider, and his parting comments were sort of interesting.



We've got the continuing Great Encryption Dilemma which was brought back to fore by something that the EU just did.  Also a somewhat troublesome experiment about police monitoring of consumer video, which we'll talk about.  More ongoing pain for WordPress.  Also I just wanted to drop a note about a sci-fi book event, which I'm sure John is aware of, occurring exactly one week from now, and I'm very aware of it.  And then we will conclude by talking about Samy Kamkar's Slipstream attack and how fortunately it was not named after a vulnonym.



LEO:  That gift keeps on giving.  I follow them on Twitter, man.  Every day there's something.  Vulnonym.  We'll talk about that later.



STEVE:  And of course we have one of our classic Pictures of the Week, which just, you know, you just have to say, what?  Also, Leo, there's a padlock in the middle of it.  It's small.  



LEO:  Oh, I didn't even see that.  Oh, my god.



STEVE:  Because you wouldn't want that to be opened by mistake.



LEO:  No, wouldn't want somebody to open that.



STEVE:  No, got to keep that sucker locked, yeah.



LEO:  And we go back to Steve and our Picture of the Week.



STEVE:  For those who can't see the picture, we have another of those curious locked gates in the middle of an empty field.  And it's like...



LEO:  What?



STEVE:  There's got to be a story here.  Like maybe there used to be a fence that they took down?  Or, I mean, it doesn't look brand new, so it doesn't look like they haven't yet - like they put the gate in, but not the fence.  And also there's a very well-used-looking padlock.  The original image was very high-resolution so I cut it way down so that it wouldn't bloat the file too much.  But, I mean, it looks like it's been there forever.  And of course you'd want that padlock there because you wouldn't want anyone to open the gate.



LEO:  Maybe there's a road under those leaves or something.  But still it would be trivial to drive around.



STEVE:  Well, yeah, look, there's nothing on either side.  I mean, it's...



LEO:  People are still building those.  Still building those gates protecting nothing.



STEVE:  Yeah.  Probably somebody had a contract to, like, install the gate there.  And they're like, gosh darn it, I'm going to get paid for this gate.



LEO:  Whatever you say.



STEVE:  Whether they want it or not.  Yeah, exactly.  So something interesting has happened with Let's Encrypt.  On Friday they blogged:  "Standing On Our Own Two Feet."  And the issue that's come up is so interesting and fundamental that I decided to share what they've said, with some inline editorializing, of course, about the situation they find themselves in.



So they wrote:  "When a new Certificate Authority comes on the scene" - which I'll note does not happen very often - they said: "...it faces a conundrum.  In order to be useful to people, it needs its root certificate to be trusted by a wide variety of operating systems and browsers.  However, it can take years for the OSes and browsers to accept the new root certificate, and even longer for people to upgrade their devices to the newer versions that include that change.  The common solution:  A new CA will often ask an existing, trusted Certificate Authority for a cross-signature, to quickly get it into being trusted by lots of devices."



And, you know, we talked about this in the beginning of Let's Encrypt.  And we looked at the certificate that they were producing was cross-signed by IdenTrust, I think it was.  Anyway, so they said:  "Five years ago, when Let's Encrypt launched, that's exactly what we did.  We got a cross-signature from IdenTrust.  Their DST Root X3 had been around for a long time, and all the major software platforms trusted it already:  Windows, Firefox, macOS, Android, iOS, and a variety of Linux distributions.  That cross-signature allowed us," they wrote, "to start issuing certificates right away, and have them be used by a lot of people.  Without IdenTrust, Let's Encrypt may have never happened, and we are grateful to them for their partnership.  Meanwhile, we issued our own root certificate, ISRG Root X1, and applied for it to be trusted by the major software platforms.



"Now, those software platforms have trusted our root certificate" - meaning the Let's Encrypt root certificate - "for years.  And the DST Root X3 root certificate that we relied on to get us off the ground is going to expire on September 1st, 2021."  They said:  "Fortunately, we're ready to stand on our own and rely solely on our own root certificate.  However," they wrote, "this does introduce some compatibility woes.  Some software that has not been updated since 2016," they said, "approximately when our root was accepted to many root programs, still doesn't trust our root certificate, ISRG Root X1.  Most notably, this includes versions of Android prior to 7.1.1.  That means those older versions of Android will no longer trust certificates issued by Let's Encrypt."



They said:  "Android has a longstanding and well-known issue with operating system updates."  Yeah, a frequent topic of this podcast.  "There are lots of Android devices in the world running out-of-date operating systems.  The causes are complex and hard to fix.  For each phone, the core Android operating system is commonly modified by both the manufacturer and a mobile carrier before an end user receives it.  When there's an update to Android, both the manufacturer and the mobile carrier have to incorporate those changes into their customized version before sending it out.  Often manufacturers decide that it's not worth the effort.  The result is bad for the people who buy these devices.  Many are stuck on operating systems that are years out of date.



"Google no longer provides version numbers on its Distribution Dashboard, but you can still get some data by downloading Android Studio.  Here's what the numbers looked like as of September 2020."  And I have in the show notes an interesting table, showing from the bottom which are the newest versions, moving back in time as we go up.  And so, for example - and they're also identified by API level or Android version.



So right now, as of September 2020, this year, 8.2% of all Android devices, Google says, are running Android 10.  If you go up a tier to include 9.0, which was Android Pi, now the total install base increases, that is, of Android 10 or 9, 9 or 10, to 39.5%.  One more further up to add 8.1 to 9 and 10.  That brings you to Oreo 8.1.  Now we're at 53.5%.  Move back again and look at everything since Oreo, the first, 8.0.  Now we've got 60.8%.  And if we drop one notch back to Nougat at 7.1 - so we've got 7.1, 8, 8.1, 9, and 10.  And this is the time where Let's Encrypt's root appeared.  We are at 66.2%, which is to say two-thirds of all current Android devices are from 7.1 on, that is, two-thirds are aware of the actual Let's Encrypt root.



But that leaves fully one-third of all current Android devices naive to this change in the root CA.  And they're working right now across all Let's Encrypt sites only by virtue of the fact that Let's Encrypt has this cross-signing relationship with IdenTrust, which goes away on September 1st of next year, meaning that those devices will no longer, believe it or not, will no longer be able to connect to any Let's Encrypt sites.  And we know how incredibly popular Let's Encrypt has become.  So, oops.  Bit of a problem there.



So they said:  "Currently, 66.2% of Android devices are running version 7.1 or above.  The remaining 33.8% of Android devices will eventually start getting certificate errors" - oh, that's true.  I thought they were going to say upgrade, but that's, you know, it's never going to happen - "will eventually start getting certificate errors when users visit sites that have a Let's Encrypt certificate.  In our communications with large integrators, we have found that this represents" - okay, they're saying around 1 to 5% of traffic to their sites.  Okay.  So those would be people using Let's Encrypt certs are saying that 1 to 5% of people who visit them have these older versions of Android.



On the other hand, there's a lot of people who have, like, one-third of all Android devices, that's a lot of devices, who wouldn't be able to bring up any Let's Encrypt-based websites.  So they said:  "Hopefully these numbers will be lower by the time DST Root X3" - that's the cross-signed root, the IdenTrust root - "expires next year, but they acknowledge the changes may not be very significant."



What can we do about this?  They said:  "Well, while we'd love to improve the Android update situation, there's not much we can do there.  We also can't afford to buy the world a new phone.  Can we get another cross-signature?"  They said:  "We've explored this option and it seems unlikely."  And I'll just stop here for a moment to say, remember that not only is Let's Encrypt incredibly popular with sites that want encryption, and now you could argue these days need encryption, but the bad guys have been having a field day.  So whereas when this original agreement was made with IdenTrust for the cross-signature, IdenTrust might have said, yeah, fine, why not?  That sounds great.  Well, nobody wants to cross-sign Let's Encrypt's cert now because essentially they're putting their reputation on the line for what we now know has been a crazy, like, insane abuse of this no-charge ACME bot-based self-certificate issuance.



So then they say, "Can we get another cross-signature?  We've explored this option, and it seems unlikely."  It's like, uh-huh, yeah, not surprisingly.  Oh, and they said:  "It's a big risk for a CA to cross-sign another CA's certificate, since they become responsible for everything that CA does."  Which is to say, yeah, all the certs that that Let's Encrypt in this case Certificate Authority issues.  They said:  "That also means the recipient of the cross-signature has to follow all the procedures laid out by the cross-signing CA."



They said:  "It's important for us to be able to stand on our own.  Also, the Android update problem doesn't seem to be going away.  If we commit ourselves to supporting old Android versions, we would commit ourselves to seeking cross-signatures from other CAs indefinitely."  In other words, like just sort of give up on having their own, actual their own CA, and just always be obtaining CAs that haven't expired yet.



So they said:  "It's quite a bind.  We're committed to everybody on the planet having secure and privacy-respecting communications.  And we know that the people most affected by the Android update problem are those we most want to help - people who may not be able to buy a new phone every four years.  Unfortunately," they said, "we don't expect the Android usage numbers to change much prior to ISRG Root X1's expiration."  Actually, that's a typo there.  They meant the expiration of the other cross-signing.



They said:  "But raising awareness of this change now, we hope to help our community to find the best path forward.  As of January 11, 2021" - so okay, this coming January 11 - "we're planning to make a change to our API so that ACME clients will, by default, serve a certificate chain that leads to ISRG Root X1."  Okay, now, which is to say their actual root.  So they have been planning to change their certificate chain so that it chains up to their own sole ISRG Root X1.  They recognize that that's going to cause a problem because of this immediate inability to get then to any of these Android, one-third of all Android devices that don't have ISRG Root X1 in them and never will.



So, they said:  "However, it will also be possible to serve an alternate certificate chain for the same certificate that leads to DST Root X3" - that original cross-signed one, which will at least be lasting until September 1st, they said - "and offers broader compatibility."  Uh-huh.  One-third of Android devices.  They said:  "This is implemented via the ACME alternate link relation.  This is supported by Certbot from version 1.6.0 onwards.  If you use a different ACME client, please check your client's documentation to see if the alternate link relation is supported."



So this is a takeaway for our listeners who may be using Let's Encrypt certs.  You want to make sure that you are running a late version of Certbot.  And there's no reason not to just go ahead and select right today now, so that you don't forget.  Well, I imagine we'll be talking about this next year because this is going to cause some problems for the world.  But you want to be chaining up to the DST Root X3.  I mean, why not?  It's just as good.  It's much more universally trusted.  And you then obtain one-third of Android users who you would otherwise be losing on January 11th of next year.



They said:  "There will be site owners who receive complaints from users."  I don't think the users will be able to complain because they won't be able to connect.  "And we are empathetic to that being not ideal."  They said:  "We're working hard to alert site owners so you can plan and prepare.  We encourage site owners to deploy a temporary fix," they said, "switching to the alternate certificate root chain to keep your site working while you evaluate what you need for a long-term solution, whether you need to run a banner asking your Android users on older OSes to install Firefox" - and I thought, ah, isn't that interesting because this is exactly what we were talking about last week; right?  Firefox has its own root CA.  It already knows, all versions of Firefox have long known about the Let's Encrypt root and have incorporated it.



Anyway, they said:  "...asking your Android users on older OSes" - that is, older Android OSes - "to install Firefox, stop supporting older Android versions, drop back to HTTP" - that's not going to fly - "for older Android versions, or switch to a CA that is installed on those older versions."  Ouch.  As in, you know, go get a certificate from someone else, not Let's Encrypt.  Certainly they don't want that to be your choice.



They said:  "If you get Let's Encrypt certificates through your hosting provider, your hosting provider may be serving the DST Root X3 until September 2021" - you hope, that would be good - "or they may decide to switch to the certificate chain that leads to ISRG Root X1 after January 11, 2021.  Please contact them if you have any questions."  In other words, make sure they're serving the older existing root.  They said:  "If you're on an older version of Android, we recommend you install Firefox Mobile, which supports Android 5.0 and above as of the time of writing."



They said:  "Why does installing Firefox help?  For an Android phone's built-in browser, the list of trusted root certificates comes from the operating system, which is out of date on those older phones.  However, Firefox is currently unique," they wrote, "among browsers.  It ships with its own list of trusted root certificates.  So anyone who installs the latest Firefox version gets the benefit of an up-to-date list of trusted certificate authorities, even if their operating system is out of date."



They finished with:  "We appreciate your understanding and support both now and over the years as we continue to grow as a CA, making sure people everywhere have access to encryption."  And now we know why Chrome has decided to adopt their own root platform, their own root store.  Chrome certainly is the default browser on all of these Android phones, and this allows - because Chrome, even though the OS will not be updating itself, at least the browser is.  And so this allows Google to push a Chrome anytime between now and the end of next August, which will be bringing its own root store.



Now, this is not a complete solution for Android because of course you're still going to have an obsolete OS-level store.  On the other hand, I would imagine Let's Encrypt is only being used, theoretically it could be used for other CA purposes, but almost entirely by web servers, which are only going to be serving to web browsers.  And so as long as Chrome switches to their own root store, certainly Chrome will be updating itself.  This solves the problem for the Let's Encrypt folks, at least on these older Android platforms, and so long as someone's not using something else.  I mean, what would it be on Android other than Chrome and Firefox?



LEO:  Oh, there's others.  Plenty of browsers out there.  So is this...



STEVE:  Popular, you think? 



LEO:  Yeah, yeah.  I mean, if you're on Samsung, you use the Samsung browser, the Internet browser.  I don't know which cert store they use.  And there are other, yeah, there are plenty of browsers.  But Firefox is probably the most obvious choice.  It's like Android's not so different in the Windows world.  There's dozens of weird off-brand browsers out there.



STEVE:  And non-Chromium based, because I would have had all Chromium browsers.



LEO:  Well, is that the case?  They're all using Google's cert store?



STEVE:  Well, we don't know for sure.  And we talked about this last week.  For example, would Edge on Windows use the Chromium certs, the new Chromium...  



LEO:  Yeah, because Edge is available on Android.  I wonder, though.  That's interesting.  There's Brave, but that's Chromium-based, as well.



STEVE:  Anyway, a really, really odd, yeah, really odd consequence of being on an older OS platform where, you know...



LEO:  Well, it's not the only one.



STEVE:  What has turned out to be a very popular CA is trying to...



LEO:  Yeah.  I use Let's Encrypt certs for a lot of stuff. 



STEVE:  Yeah.  I mean, they work.  They're great.  They're free.



LEO:  Dolphin has been around a long time.  I'm trying to see if Dolphin is Chromium.  So you think anything based on the Chromium engine is going to use the same certs.  I'm not sure that's the case.  It's an interesting question.



STEVE:  Yeah.



LEO:  Whose cert store does Chromium use?  I don't know.



STEVE:  Well, right now, I mean, it's the underlying OS platform cert store.



LEO:  Oh, it comes from Android.



STEVE:  What we know from - yeah.



LEO:  So but if a browser comes with its own cert store, it would override that.



STEVE:  Correct.  And I know, for example, Firefox does, and it always has.  And what Google has said is that they are establishing their own root program just to have control.  And a nice side effect is that then, if it were Chrome running on Android, then it would be bringing that along, and that one-third of Android devices wouldn't be having a problem.



LEO:  Yeah.



STEVE:  Anyway, really, really sort of interesting whoopsie.



LEO:  Yeah, kind of nasty, yeah.



STEVE:  You have to wonder, like, did it suddenly occur to them that, wait a minute, there's still a substantial population of Android devices, like one-third of them are not going to get updated.



LEO:  Oh, yeah.  Mostly outside the U.S., mostly probably by people on very inexpensive Android devices.  So they're not super sophisticated.  I don't think getting the word out, "Use Firefox," to them would be easy at all.



STEVE:  Right.



LEO:  But they're already on horrifically insecure platforms.  So, you know...



STEVE:  That's true.  That's true.



LEO:  Their life is miserable anyway.  



STEVE:  Well, and it's not a matter of like their security dropping.



LEO:  No, this doesn't affect security.  They can't go visit sites.



STEVE:  Complete inability to connect to any site with a Let's Encrypt cert.  



LEO:  Right, yeah.



STEVE:  And, I mean, it's going to happen.  That's a drop dead at the end of next August.



LEO:  Right.



STEVE:  It's over.



LEO:  Yeah.



STEVE:  So really interesting.  While we were recording last week's podcast, unbeknownst to us, Google was busy releasing another emergency update to Chrome for Windows, Mac, and Linux.  Which brought it up to v86, main v86, but ending in 4240.183.  And we don't know much about the zero-day flaw that was found being actively used in the wild except that we know that it's CVE-2020-16009 is a problem in the V8 engine, Chrome's JavaScript engine, which is being used to enable remote code execution.  So it was a zero-day, was discovered in use, and they immediately pushed out an update.



As I always do, I went to check my Chrome, and it turned out that, the 183 version of last week, last Tuesday, was already obsolete for me since, when I went to take a peek, it took that opportunity to move itself from 183 to 193.  Which is now where we are, although there's no information, no more details about that one yet.  So just a note that Chrome is moving forward.



Oh, and I'll also note that Android smartphone users should also be sure to poke their Chromes to verify that they are now running .185 or later to close a different Android-specific zero-day that Google found being exploited in the wild.  There was a heap buffer overflow vulnerability in that Chrome, in the previous Chrome, for Android UI component.  That was CVE-2020-16010.  It was being exploited to allow attackers to bypass and escape from Chrome's security sandbox on Android devices and then run their code on the underlying OS.



So at this point Google's internal - they call it the Threat Analysis Group, TAG.  And it's kind of cool because that gives them the acronym TAG Team.  The Threat Analysis Group TAG Team has discovered not only this zero-day, the Android zero-day, the previous two zero-days, bringing their total to three zero-days in Chrome in just the past two weeks.  Thus it appears that Chrome is finally receiving the attention from the attacker community that was once the province of IE.  IE used to be attacked like this.  Now these are all having been discovered in use in the wild at the time that they were found and fixed.  So as we know, once upon a time IE was the big target.  Now it's Chrome.



And speaking of targets, I've got a quick run-through, some high-profile ransomware targets.  The famous toy company Mattel was a victim.  We learned of it last Wednesday.  They're a publicly traded company, so they're required to file a 10Q quarterly report.  They acknowledged having been hit by ransomware at the end of July.  They say that no data was stolen, and that they were able to restore themselves quickly.



Compal, which is the world's second largest laptop manufacturer, they're a Taiwanese-based firm.  And they actually build the laptops for Apple, Acer, Lenovo, Dell, Toshiba, HP, and Fujitsu.  So they're a biggie.  They suffered a ransomware attack just this past weekend.  They were a victim of the DoppelPaymer ransomware gang.  Apparently about 30% of their computer fleet was compromised.  They said it did not get into their production line, so none of the builds of laptops for companies was affected, and that they were 100% back up by yesterday.  So no news on the details of how they got zapped.  But we do know that it was this DoppelPaymer gang.



Capcom, which is the well-known Japanese game developer, was hit by the Ragnar Locker ransomware in an attack, and around a terabyte of the company's data was exfiltrated.  Of course they're the well-known producer of Street Fighter, Resident Evil, Devil May Cry, Monster Hunter, and Mega Man game franchises.  The bad guys got into their networks in the U.S., Japan, and Canada.



And finally, I got a kick out of Threatpost's headline for this one.  They said:  "Campari Site Suffers a Ransomware Hangover."  And of course given that Campari is a famous producer of alcoholic beverages, including the brands SKYY, Grand Marnier, and Wild Turkey, a hangover seemed appropriate.  Anyway, they restored their servers after also being hit by the Ragnar Locker ransomware and received the attacker's demand of $15 million in bitcoin.  The attackers left a notice:  "We have breached your security perimeter and accessed every server of the company's network in different countries across all your international offices."



And then the note goes on to detail the types of data compromised, including accounting files, bank statements, employee personal information, and more.  The note said that they had obtained a total of 2TB of data and said:  "If no deal is made, then all your data will be published and/or sold through an auction to any third parties."  And I thought interestingly, as proof of theft, the group posted a copy of the contract between Wild Turkey and Matthew McConaughey.  Which is to say, yes, in fact, we did actually get your data.



LEO:  All right, all right, all right.



STEVE:  Here's the contract that Matthew McConaughey signed.  



LEO:  That's hysterical.  



STEVE:  Yeah.  So four more recent attacks.  The gang behind the Ryuk ransomware alone, just Ryuk, reportedly averages 20 attacks like this every seven days, every week.



LEO:  Wow.



STEVE:  I managed to pick up a bit of intelligence about Ryuk, the Ryuk gang's recent successes.  The average payment received by this Russian-speaking gang is on the average 48 bitcoins, so that's currently - and by the way, bitcoin is back up to 15K, $15,000 per coin.  And yes, we're shedding a tear, you and I, Leo, over our lost bitcoins.



LEO:  Well, yours is lost forever.  Mine is just locked away behind a password I can't remember.  I'm not sure which is worse.



STEVE:  Yeah, I would love to get mine because back then I bet I know the password I used.  



LEO:  And you had 50-plus; right?



STEVE:  I formatted it and installed Windows over it.  So it's definitely wiped.



LEO:  Three quarters of a million dollars.  But I'm not rubbing it in.



STEVE:  Okay.  Ouch.  



LEO:  Ouch.



STEVE:  So yes, actually the average payment received by the Russian-speaking is 48 bitcoins, just about exactly what I formatted.



LEO:  Ah, shoot.  Gosh.



STEVE:  $720,000 at the moment.



LEO:  Yikes.



STEVE:  And since 2018 they have netted at least $150 million.  The word is they're exceedingly tough during negotiations, rarely showing any leniency or compassion.  And the largest confirmed payment they are known to have received was, get this, 2,200 bitcoins, currently valued at $33 million.  $33 million.  So, boy.  I like to sleep at night.  I adhere to the old adage, "Crime doesn't pay."  And I'm sure most of us are not tempted by the lure of the dark side.  But neither is it difficult to imagine why ransomware, why the ransomware business is booming these days, as it clearly is.



LEO:  I bet where they are, the chances of them getting arrested are minimal.



STEVE:  Oh, I'm sure Putin is jumping up and down, clapping, saying yay, you go get those...



LEO:  For all we know, it's the GRU.  It could be, who knows.



STEVE:  Those Yankees.  Meanwhile, and this was interesting, there's a little bit of back story to this.  Apple's move to 14.2, I heard you guys talking about it on iOS Today, early today.  iOS users, of which I am one, may have noticed that our iOS devices were recently bumped from 14.1 to 14.2.  As I said, there's a story behind that.  The very short version is that this was done to close three zero-day vulnerabilities that were disclosed, or discovered rather, in use in attacks against iOS. 



LEO:  Ooh.



STEVE:  Yes.  The much longer and more interesting version is that, according to Shane Huntley, the director of Google's Threat Analysis Group - again, the TAG Team - the three iOS zero-days are "related" to those recent three Chrome zero-days, and the Windows zero-day that we covered last week.  So that means it was a big, well-coordinated, multiplatform campaign.  Since Google and Apple have clamped down on any details, we don't know whether the zero-days were being used against selected targets or sprayed.  But all iOS users will be wanting to upgrade to iOS 14.2 regardless.  And again, I've had to ask my phone if it had any news for me, and it said, oh, yeah, thanks for asking.  I've got an update.  Would you like to download and install?  I said, yeah, thank you.  I want 14.2.



These same three vulnerabilities have also been closed in the most recent iPadOS and watchOS updates, and they've also been backported to older generation iPhones as iOS 12.4.9.  What little we know from Ben Hawkes' Project Zero team is that the three iOS zero-days are - and we've got three stardate-looking CVE numbers.  I won't bother with that.  But first one, a remote code execution issue in the iOS FontParser component that lets attackers run code remotely on iOS devices.  Second one, a privilege escalation vulnerability in the iOS kernel that lets attackers run malicious code with kernel-level privileges.  And, third, a memory leak in the kernel that allows attackers to retrieve content from an iOS device's kernel memory.



All three bugs are believed to have been used together to form a highly - and I will underscore that word - sophisticated exploit chain.  This would have allowed attackers to compromise iPhone devices remotely.  And think for a moment about how difficult that is to pull off on a locked-down iOS device.  I mean, to engineer the attacks with Windows, Linux, or Android, it's so much easier.  All the code is just there to be poked at and  prodded.  But not on iOS.  As we know, Apple has their devices so locked down, encrypted, and hack-proof that it takes some serious effort just to get a peek under the covers on an iOS device, let alone perform any sort of deep reverse engineering that's of the kind required to find a problem, and then turn it into anything like a reliable exploit.  Almost all vulnerabilities are far easier to find and would be vastly easier to exploit once found.



So this feels like a world-class piece of work.  For that reason I would bet that this was never being widely sprayed around the Internet because they did not want it to get - whoever they are did not want it to be seen and found and closed.  While it was there and secret, it would have been incredibly valuable for enabling highly targeted information compromise on iOS devices.  And I wouldn't be surprised if this was a nation-state-level attack that has now been shut down and closed.  



LEO:  Interesting.  Interesting, yeah.  On we go with the show, Steve Gibson.



STEVE:  So introducing the Tianfu Cup, and I checked my pronunciation on this Chinese word since I thought, okay, let's, I mean, it's not like that's a hard one to pronounce, but Tianfu, T-I-A-N-F-U.  It's China's version of the West's Pwn2Own  hacker competition.  It was created two years ago, in 2018, following the Chinese government's regulation which barred their security researchers from participating in international hacking competitions over national security concerns.  Our listeners may recall that we talked about the absence of the Chinese hackers, who are among the most talented and most successful in the previous Pwn2Own and other hacking competitions.  It was like, oh, shoot, we don't have those guys this year.  They're being kept within their own borders.  But they're also being given their own competition.



So this was, this past weekend was China's third Tianfu Cup, a two-day event.  Contestants from 15 different teams participated to deploy and demonstrate their discoveries of original vulnerabilities to break into widely used software and mobile devices.  Each team was allotted five minutes and three attempts per category.  The requirement was to use web browsers to navigate to a remote URL, presumably where they would have staged a server attack on the device, or to use local software to obtain control of the browser or the underlying operating system.  The targets were software from Adobe, Apple, Google, Microsoft, Mozilla, and Samsung, all of which were successfully pwned utilizing previously unknown exploits.



The event's organizer said that:  "Many mature and hard targets have been pwned during this year's contest.  Eleven out of 16 targets were cracked, with 23 successful demos."  So that was, what, an average of a little over two cracks per.  And so the 11 that were cracked, there was Adobe's PDF Reader got cracked.  The Apple iPhone 11 Pro running iOS 14 and Safari.  That's interesting.  The ASUS RT-AX86U router, I think that's the one I have.  CentOS 8.  Docker Community Edition.  Chrome got cracked.  Microsoft Windows 10 2004.  Mozilla Firefox.  Samsung Galaxy S20 running Android 10.  TP-Link's TL-WDR7660 router.  And VMware's ESXi hypervisor.  All in an average of two cracks per.



The big winner was, not surprisingly, Qihoo 360's Enterprise Security and Government Vulnerability Research Institute.  They often are finding things that we're reporting.  They came out on top, winning just shy of three quarters of a million dollars, $744,500 in U.S. dollars.  And they were followed by Ant-Financial Light-Year Security Lab at a little over a quarter million - yeah, I know, funny name - $258,000.  And then a security researcher just named Pang came in at basically 100,000 - 99,500.



So the good news is they successfully pwned, at least an average of two times, all of those 11 devices.  But patches for all the demonstrated bugs have been released.  The exploits are being responsibly disclosed.  Patches are coming, which we could expect to see in the coming days, or as soon as the various publishers of those devices are able to get to them.  So as always, this kind of competition does get people to look harder at these various systems than they would otherwise if they didn't know that there was a nice carrot, a golden carrot that they might win.



LEO:  That Pang.  He's always coming in, taking the $100,000, every time.



STEVE:  He's a pang in the butt, Leo.



LEO:  I love it.  Just named Pang.



STEVE:  That's Pang.



LEO:  Some guy named Pang.



STEVE:  Pang took away $100,000.  There goes Pang again.



LEO:  Nice work if you can get it.  That's great.



STEVE:  So speaking of Patch Tuesday, Leo, today and in days following, many Windows machines will have the somewhat mixed blessing of receiving Microsoft's latest monthly insult of updates and new breakages.  Sadly, as we've been seeing all year, updating promptly appears to be of increasing urgency every month, as the stakes in this game seem to have risen during 2020.  So I expect that our next podcast, next week, will have a readout on some outcomes of this month's Windows 10 continuing update adventure.



But something I recently encountered was apropos of this.  Woody Leonhard, a longtime valued participant and commentator in the PC industry, announced on Sunday his retirement from our industry.  For those unfamiliar with Woody, two short bits from the Internet noted:  "Woody Leonhard is a columnist at Computerworld and author of dozens of Windows books, including 'Windows 10 All-in-One for Dummies.'"  And elsewhere it was written that "Woody Leonhard has covered Windows Dummies foibles and fantasies since the days of Windows XP.  With more than a million regular readers, he's Senior Contributing Editor at InfoWorld and Senior Editor at Windows Secrets, where he weighs in daily on all things Windows."



Anyway, given his deep background, I mean, he's been in the industry forever.  I thought that his parting characterization was interesting, if only to further assure us that we're not all crazy.  When he announced his retirement, he wrote:  "Life's changed in extraordinary ways since my first 'meatspace' book 'Windows 3.1 Programming for Mere Mortals' appeared 28 years ago."  He said:  "Windows has evolved from a rickety infrastructure built on top of a wobbly operating system to a wobbly operating system in its own right."



He said:  "I don't miss the original bug-ridden incarnations of Windows.  But I do miss the fire and vision that drove the unqualified success of Windows XP and Windows 7.  And I'll continue to rail against the flaws that are introduced  and sometimes re-introduced  with every round of updates."  He finished:  "Microsoft has a long history of Windows patching issues.  Some things never change, eh?"



LEO:  What are you going to write in five years, when you write your retirement?  It probably will be not much different.



STEVE:  No, exactly.



LEO:  Yeah, some things never change.



STEVE:  Yes.  Maybe I'll add something like, "Fortunately, there were some alternative OSes that it was a pleasure to hop over to."



LEO:  Yes, maybe.  Yeah.



STEVE:  Anyway, so a tip of the hat to Woody.



LEO:  Great man.  Great man.



STEVE:  Enjoy your retirement.  The rest of us are all having too much fun to quit.



LEO:  Right.



STEVE:  I think that's what this is, Leo.  I think this is fun.



LEO:  Yeah.



STEVE:  It is.  It is.



LEO:  Check.  Just check.  Just look.  Make sure.



STEVE:  Are we having fun yet?



LEO:  I'm having fun.  I don't know about you, but I love doing this.



STEVE:  Yeah, I am, too.  I am, too.



LEO:  But you do all the work.  I just sit here and eat popcorn while you give them the facts.



STEVE:  We had the Great Encryption Dilemma.  The Council of the European Union last week published a short, five-page draft resolution with the title, and this was a new term, they said:  "Draft Council Resolution on Encryption - Security through encryption and security despite encryption."  So we know where that's going.



I read through the resolution, and there's nothing new there.  But since the Great Encryption Dilemma remains outstanding and unresolved, I wanted to just stick a pin in this to note that the issue does remain alive and well, and also that I suspect it always will.  And I wanted to take this occasion to be a little more clear and definitive about this than I have been previously.  Cryptographers, and this podcast's audience, know with absolute clarity that this is a problem without a solution.  Such things exist, and this is one of them.  Bureaucrats, who are not cryptographers, are unable to accept the simple math of this fact.  Once unbreakable encryption was created, that was the end of it.  Game over.  Enciphering algorithms without known weaknesses now exist.  They cannot ever be made not to exist.  Once something is encrypted with them, the only known way to reverse the encryption is with a key.  Period.



Sure, a deliberately weakened encryption system could easily be created.  We know how to do that.  But that doesn't mean that the existing systems, the ones without any known weaknesses, can be uncreated.  They cannot be uncreated.  Governments and law enforcement may not be happy about what's been created, but it has been already.  So the cat's out of the bag, the horses have left the stable, the chickens have flown the coop, the train has left the station, and the ship has sailed.  This is done.



So hopefully this will forever remain a stalled issue, with academia and industry patiently explaining, over and over, as many times as necessary, to any government or law enforcement agency who asks, whenever it comes up, as it certainly will, that there's no safe way to add a deliberate backdoor into existing encryption.  And even if there were, and this is the point you always make, Leo, that would not spontaneously uncreate any of the existing uncrackable encryption technologies that anyone could still easily and freely use.  So that's just it.  Done.



LEO:  Yeah.  If they outlaw encryption, only outlaws will have encryption.



STEVE:  That's the only thing that they can do.  And exactly.  If they were to outlaw it, only the bad guys would be using it.



LEO:  Or math processors.



STEVE:  And the other thing, too, you know, if they want to have weakened encryption, are they willing to use it themselves?  No.



LEO:  No, of course not.



STEVE:  No.  They want us to have a backdoor; but oh, no, they need to have it because, you know, they're in charge.



LEO:  We're Congress.  We're safe.  No, no.



STEVE:  Okay.  So this one is a little creepy.  In Jackson, Mississippi, a small trial has been initiated and is being conducted for a month and a half, about 45 days, to explore the feasibility of allowing private citizens to have their video doorbells participate in police dragnet monitoring.  The rationale is, while on the one hand municipalities might install video cameras pointing down all four directions of every intersection, which is by the way exactly what I've noticed being done here in Southern California, that doesn't provide as much granular video coverage as might also be afforded if all of the video doorbells in residential neighborhoods were also tied into a much larger surveillance network.  We've talked about pervasive video monitoring before, and it's a little creepy.



But the EFF feels somewhat more strongly about this.  They noted that handing over control of live streams to law enforcement may not only allow the covert recording of a willing participant's comings and goings, but also neighbors, which of course could happen.  The EFF wrote:  "The footage from your front door includes you coming and going from your house, your neighbors taking out the trash, and the dog walkers and delivery people who do their jobs in your street.  In Jackson, this footage can now be live-streamed directly onto a dozen monitors scrutinized by police around the clock.  Even if you refuse to allow your footage to be used that way, your neighbor's camera pointed at your house may still be transmitted directly to the police."



And in sort of an interesting coincidence, this past August Jackson city officials voted to preemptively ban police forces from using facial recognition technology to identify potential suspects on city streets.  And although this is not that, it's getting close.  And the month before, in September, an analysis leaked from the FBI highlighted how smart doorbells could also be turned against law enforcement as live feeds could warn suspected criminals of police presence, alert them to incoming visits from police, and might show suspects where officers are, which could pose a safety risk to law enforcement conducting property raids.  So, yeah.  This is increasingly feeling like a brave new world that we are in.



WordPress, as I promised at the top of the show, once again in the news for their Ultimate Member plugin, or maybe it's Ultimate Dismember.  If you haven't yet been convinced by listening to me the last few weeks to sequester any WordPress instance so that its takeover cannot harm you further, here's another few reasons to consider either sequestering it or maybe evicting it completely.



Three separate supercritical flaws exist within another highly popular WordPress add-on known as Ultimate Member.  They have CVSS severity ratings of 10, 10, and 9.9, each out of 10, of course.  And the Ultimate Member plugin is installed on more than 100,000 WordPress sites.  Each of the three critical security bugs allows for privilege elevation leading to full control over a WordPress site.  The plugin allows, like the reason you have it is it allows web admins to add user profiles and membership areas to their WordPress sites.



And according to Wordfence researchers, the security guys, the flaws make it possible for both authenticated and unauthenticated attackers to elevate their privileges during registration to allow them admin status.  Oops.  And of course once an attacker has admin status on a WordPress site, they've effectively taken over the entire site and can perform any action they like, from taking the site offline to further infecting the site with additional malware. 



So I'm not going to bother delving into all the details about each of the three vulnerabilities because I think that a broader point needs to be made.  We've seen that the hacker community tends to focus on one category or another from time to time.  For a while, earlier this year, RDP was under attack.  Earlier than that, it was the router botnets attacking the authentication, the web authentication of routers.  And tomorrow it'll be something else.



But the recent evidence suggests that WordPress plugins have been enjoying a period, up until recently, of relative quiet and under examination by that nefarious community.  It feels like that community has recently awakened to just how much low-hanging fruit has been growing while their attention has been directed elsewhere.  Last week a security vulnerability in the Welcart e-Commerce plugin was found to be opening WordPress sites to code injection.  This led to payment skimmers being installed, crashing of the site, or information retrieval via SQL injection.



Last month, two high-severity vulnerabilities were disclosed in Post Grid, another WordPress plugin with more than 60,000 installations.  It opened the door to site takeovers.  And in September a high-severity flaw in the Email Subscribers & Newsletters plugin made by Icegram was found to affect more than 100,000 WordPress sites.  In August, a plugin that adds quizzes and surveys to WordPress patched two critical vulnerabilities which could be exploited by remote unauthenticated attackers to launch a variety of attacks including full site takeover.  Also that month, in August, the Newsletter WordPress plugin, with more than 300,000 installations, was discovered to have a pair of vulnerabilities leading to code execution and site takeover.



And before that, in July, researchers warned of a critical vulnerability in a WordPress plugin called Comments - wpDiscuz, which is installed on more than 70,000 websites.  The flaw gave unauthenticated attackers the ability to upload arbitrary files, including PHP, and ultimately execute remote code on vulnerable website servers.  I said before that WordPress is demonstrably a PHP-coded disaster, and that the tantalizing WordPress plugin ecosystem, which is I'm sure a large part of WordPress's allure, is also a hot mess.  It's impractical to tell people not to use it.  I get that.  That is, not to use WordPress.



But don't, I would say to people, don't run a WordPress instance on your Drobo.  I sort of chuckle when I see that in its menu of options.  It's like, oh, yeah, let's run WordPress on our Drobo and install a bunch of add-ons.  What could possibly go wrong?  Or, for that matter, on any machine that has access to anything  else.  That's when I talk about sequestration.  Depending upon how many tasty-looking goodies you add to your WordPress installation over time, there is a high likelihood of local site compromise sooner or later.  That means that containment is the best you can hope for.



So please consider it.  If you have WordPress running somewhere, somehow arrange a sandbox.  Contain it.  Put it on its own server.  Hook it up to a separate port on your router that you're able to firewall so that, if anything gets loose in it, it can't get loose on your network.  Do something.  Don't install it side-by-side on a server with a bunch of other stuff there.  That's just asking for trouble.



Okay.  Off my soapbox.  I mentioned one little bit of sci-fi miscellany:  "The Saints of Salvation" is the title of Peter Hamilton's final third of his...



LEO:  Is it out?



STEVE:  Next Tuesday.



LEO:  Oh, good.  I can finally read them.  I've been holding off because I hate it when you've got two books of the trilogy...



STEVE:  And Leo, I was thinking of you.  I've been waiting with great impatience.  You know, like all of Peter's work, it is a truly remarkable - I can speak of the first two of the trilogy, which I've read, which I know John has read.  It is a remarkable work of science fiction.  And I read a lot of science fiction.  In a world, ours, filled with lazy and largely derivative fiction, you know, I mean, it's engaging, it's entertaining, it's distracting.  Peter somehow always arranges to create entire, fully realized, believable worlds and characters.  And this "Salvation" trilogy is another one of those.  He's done so again.  It's annoying to wait long periods between installations of his multibook series.  And when, in this case, when the second of these three, when the second book dropped, I reread the first one because it had been so long...



LEO:  Right, to catch up, yeah.



STEVE:  ...I'd kind of forgotten it, to refresh my memory of what had happened.  The good news is I didn't finish the second one that long ago.  So I am just like, I'm on the edge of my seat.  I mean, it's Lorrie's going to wonder what happened to me because it's like, "Okay, honey, I just have to read this now."  



LEO:  He's a machine because the first one came out October 2018, the second one October 2019.  Here we are November 2020, I mean, it's boom, boom, boom.  One year a book.  He must just be - unlike somebody like, say, George R. R. Martin.  He must really - he's just consistent.  That's really awesome.



STEVE:  Oh, and Leo, they are so good.



LEO:  Well, I have the first two on Audible.  But I haven't listened because I don't want to - and I can start now.



STEVE:  You can start now.



LEO:  I'm starting now.



STEVE:  Because you will not be finished by next Tuesday when you can get the third.  And, oh, this is - and I mentioned this before.  I didn't, you know, the thing he does is he runs several timelines at the same time.



LEO:  Yeah, yeah.



STEVE:  There's the beginning of the whole adventure.  And then he's also running way in the future.  And so at first when you encounter the name of a planet that you've never heard of, it's like, what?  You know, what happened to where we were just the last paragraph?  But now that I'm - I guess I'll say I'm okay with the way he did it.  It makes more sense to be showing us how all this trouble we're in began, and also the way far future that resulted from all of that trouble.  So it's a little jarring.  But once you understand that he's, like, starting you at the beginning and also the far, far future, then it kind of makes sense.  And so I think it was the right thing to do.  And I'll just say to our listeners, boy, there was "Pandora's Star," which was the first of two books.



LEO:  Loved that.  Loved that.



STEVE:  Oh, my god, I think it's probably my favorite.  We were introduced to the Commonwealth with wormholes running trains through them, between widely spaced habitable planets.  The one standalone book is "Fallen Dragon."



LEO:  Wonderful, yup.



STEVE:  Which is excellent, with a surprise wonderful ending.  And it was "Judas Unchained" was the second book of the - "Pandora's Star" and "Judas Unchained," that was the two books.  And then the Salvation trilogy, as it's called.



LEO:  The new one, book three, is "The Saints of Salvation."



STEVE:  Correct.



LEO:  And that comes out November 17th.  I have preordered it on Audible.



STEVE:  Oh, baby.



LEO:  Then I'll have all three.



STEVE:  Yes, you can start listening because it is, oh, it is really completely new.  This is not the Commonwealth universe.  It's back to an Earth that we recognize, and then something happens.



LEO:  I can't wait.  "Salvation Lost," "Salvation," and "The Saints of Salvation."  Peter F. Hamilton, the Salvation Sequence Series.  Can't wait.



STEVE:  He did it again.



LEO:  Oh, you know, this is - because I wanted to read this so bad.  I even bought the books.  But then I thought, I don't want to be disappointed when I get to the end.



STEVE:  No, you're right.  And it's just so annoying to wait a year.



LEO:  Yeah, yeah, yeah.  Good.



STEVE:  Now you don't have to because you waited two years.



LEO:  Yes, that's right.  I distracted myself with other lesser books.



STEVE:  So Slipstream is a perfect name for this bit of cleverness.  And let's all be thankful that Samy Kamkar, the security researcher who invented this, or discovered it, or engineered it, had the freedom to name this whatever he wished, rather than needing to dip into vulnonym to receive a name.  Oh, my lord.  I'll confess to being morbidly curious yesterday.



LEO:  Me, too, yeah.



STEVE:  Yeah.  So I went over, and I took a look at CERT's feed at that moment.  I was greeted with Putative Loon, Pungent Pronghorn...



LEO:  Oh, that's the vulnerability I want.



STEVE:  Oh, yeah, the Pungent Pronghorn.  We also had Discordant Screamer, which I thought was interesting.  And also Feckless Mongrel.



LEO:  You Feckless Mongrel, you.



STEVE:  Yeah, and it's not clear to me that being told I've been a victim of the Feckless Mongrel attack demonstrates the achievement of CERT's intentions with regard to naming.  



LEO:  No, no, it's terrible.



STEVE:  So as you said, Leo, I think they chose a bad word list.



LEO:  Yeah, yeah.



STEVE:  And they need to figure out what to do about that.  But what did Samy come up with?  His NAT Slipstreaming page states:  "NAT Slipstreaming allows an attacker to remotely access any TCP/UDP service bound to a victim machine, bypassing the victim's NAT firewall," he says, "arbitrary firewall pinhole control, just by the victim visiting a website."  Okay.  So think about that for a minute.  What that means is that you go to a website, and external malicious servers can obtain access to any machine and port on your LAN.  That's bad.



So we've come to treat our NAT routers, as we know, as smart firewalls, which block all unsolicited incoming traffic by default, like bad guys trying to get into one of our machines where we don't want them to be.  They do this for us automatically by operating a system of stateful packet inspection, where any incoming packets must be replies to recent outgoing packets; right?  So this super elegant and simple scheme has served us almost without exception so far.  I'll quote from Samy's summary, even though his terminology is a bit opaque and confusing.  But don't worry, I'll explain with a really perfect example, and it'll all become very clear.



So Samy said:  "NAT Slipstreaming exploits the user's browsers, in conjunction with the Application Level Gateway connection tracking mechanism built into NATs, routers, and firewalls, by chaining internal IP extraction via timing attack or WebRTC, automated remote MTU and IP fragmentation discovery, TCP packet size massaging, TURN authentication misuse, precise packet boundary control, and protocol confusion through browser abuse.  As it's the NAT or firewall that opens the destination port, this bypasses any browser-based port restrictions."



Okay.  So all that was confusing.  And that's kind of in the weeds of what this is really about.  So it's important, but it doesn't really matter.  Anyway, he continues:  "This attack takes advantage of arbitrary control of the data portion of some TCP and UDP packets without including HTTP or other headers.  The attack performs this new packet injection technique across all major modern and older browsers, and is a modernized version of my original," he wrote, "NAT pinning technique from 2010, which was presented at DEFCON 18 and Black Hat 2010.  Additionally, new techniques for local IP address discovery are included."



And he finishes:  "This attack requires the NAT firewall to support ALG, Application Level Gateways, which are mandatory for protocols that can use multiple ports.  That is to say, control channel and data channel, such as SIP, H.323, which are the VoIP protocols; FTP, our old friend; IRC DCC, et cetera."



Okay.  So that's how we introduced this problem.  To understand what's going on, let's talk about Application Layer Gateways as they have been sort of generically named.  They exist because not all Internet protocols are as simple as HTTP, where we make an outbound query over a connection and receive a returning reply over the same connection.  The best, most well-known example, certainly for us old-timers, is FTP, the File Transfer Protocol.  With the original FTP protocol, which was designed before firewalls existed, the user's FTP client would reach out to a new FTP server to initiate a connection at that server's port 21.  They would exchange logon username and password prompts and answers over the so-called "control channel," and upon agreeing on the transfer of data, that transfer would not occur over the current connection to the server's port 21, but from its port 20, the so-called "data channel."  And most significantly, the remote FTP server would be the initiator of that data channel connection.



So we connect to the remote FTP server on its port 21.  It subsequently connects back to us from its port 20 to a port that we designate.  So what this means is that an FTP client would need to open a high-numbered listening port at its end.  Remember that, as a client of an operating system, applications running on that OS are restricted from opening low-numbered ports below 1024.  Those are reserved for privileged OS processes like that FTP server running on the remote server.  So over the original connection to the remote server's port 21, the FTP client would say:  My OS has given me port whatever, XYZ, where I'm now listening for your FTP server, your incoming return data channel connection.  So please open a TCP connection to me at that port, and I will answer.



Okay.  So in summary, the client sets up a high-numbered listening port, then initiates an outbound connection to a remote FTP service port 21.  And among other things, it requests the remote server to call back to it at that high numbered port.  So the bad news is that the operation of NAT that we've talked about often on this podcast is totally hostile to this wacky old active FTP protocol.  That was recognized early on by the first implementers of NAT because it broke FTP, which back then was still seeing some use.  I mean, it's still a viable protocol today.  But as we've talked about before, not from your browser.



Okay.  NAT broke it.  So this was solved, or at least resolved, with a somewhat horrific kludge.  NAT routers would notice when an outbound connection was being made to a server at port 21.  They would then begin sniffing the outbound traffic over the FTP control channel, looking for the client's command to open the reverse data channel.  And remember, that command would have the port that the client's OS had given the client to listen for a received connection.  The router, sniffing that packet, would then on the fly patch in a WAN port on the router for the remote server to instead connect and query, and the NAT router would establish a NAT mapping from that WAN port back to the client's specified listening port.



So if you think about that for a moment, you'll notice that this is effectively deliberately and necessarily penetrating the NAT firewall for this connection instance, this back connection from the remote server.  Since those early pre-firewall days, a number of other protocols have been designed which are similarly NAT hostile.  And the need for a means of opening incoming ports has been generalized under sort of the umbrella of Application Layer Gateway since the control side of this resides, not at the packet level, but as with our FTP example, within the application's data layer, the FTP protocol, or the whatever, the SIP protocol, or the BitTorrent protocol, or RTSP protocol, whatever.



Wikipedia explains this whole problem this way.  They said:  "Application-level gateway - also known as ALG, application layer gateway, application gateway, application proxy, or application-level proxy - is a security component that augments a firewall or NAT, employed in a computer network.  It allows customized NAT traversal filters to be plugged into the gateway to support address and port translation for certain application layer control/data protocols such as FTP, BitTorrent, SIP, RTSP, file transfer in instant messaging applications, et cetera.



"In order for these protocols to work through NAT or a firewall, either the application has to know about an address/port number combination that allows incoming packets, or the NAT has to monitor the control traffic and open up port mappings, a so-called 'firewall pinhole,' dynamically as required.  Legitimate application data can thus be passed through the security checks of the firewall or NAT that would have otherwise restricted the traffic for not meeting its limited filter criteria."  So a nice, succinct description of the whole thing.



So most clearly stated, the problem that Samy figured out, or the hack, the problem is that Application Layer Gateways attempt to be completely transparent to the application protocols they are proxying for.  They're sitting there in our routers, enabled by default, hidden, powerful, and automatic.  And because they're automatic and trusting, they can be readily spoofed by any inside agent pretending to need their help.  "Spoofing" in this context means tricking the user's border NAT router into opening a packet return path through to any internal IP and port  on the LAN of the attacker's choice.  This subjects any services, any servers existing anywhere on a LAN to remote external access and abuse.



The second part of Samy's work was to clearly demonstrate that JavaScript code running in any of today's web browsers, even in a malicious malvertisement on an unwitting website, is all that's necessary to launch just such a spoofing attack.  In other words, our web browsers themselves can serve as unwitting Application Layer Gateway spoofing agents.



So during his research, Samy explored all of the various ALGs.  He looked at Linux's Netfilter ALG support.  He reverse-engineered router firmware and finally settled upon the abuse of the SIP, the Session Initiation Protocol, as like a perfect target, widely supported.  It has lots of uses.  It's sort of a generic protocol that Application Layer Gateways support if they're going to do any support for SIP.



Samy wrote:  "While we found some FTP functions, we're more interested in ports that we can use.  Modern browsers prevent outbound HTTPS connections to a number of restricted ports, including FTP.  So abusing the FTP Application Layer Gateway is likely a no-go."  In other words, those are low-numbered ports, and browsers are already blocked.  They're already smart enough not to allow code running in the browser to reach out to port 21 and do anything.  So you can't use it.  He said:  "In 2010, when I first demonstrated NAT pinning, I used port 6667" - which of course was IRC - "via the DCC CHAT/FILE messages."  He said:  "Quickly, browser vendors blocked port 6667."  



So the same thing has happened this time.  In quick reaction to Samy's revelations, about two weeks old, all web browser vendors immediately announced their plans to block the TCP SIP ports 5060 and 5061, which are used in Samy's demonstrated attacks, by adding them to the browsers' existing restricted lists.  So already they won't let you use FTP ports.  You can't aim any browser traffic at 6667, thanks to what he did 10 years ago.  And now, shortly, you won't be able to aim any traffic at ports 5060 and 5061.



Chromium's developer Adam Rice said:  "As a workaround for the Slipstream NAT bypass attack, we will be blocking HTTP and HTTPS connections to the SIP ports 5060 and 5061.  This will mean that connections to servers on those ports will fail."  Once those ports have been added to the restricted ports list, Rice expects some impact to be observed by browser users.  For example, connections to servers on those ports, like if you tried to go to http://example.com:5060 or https://example.com:5061, will no longer work.  And that's probably not a big problem.



But if test servers happen to be spinning up instances on those particular high-numbered ports, that would be a problem in the future.  The development teams behind Firefox, Safari, and Blink, which is the Chromium rendering engine, have all indicated their intent to implement these mitigations needed to block these NAT slipstreaming attacks.



And the takeaway for our listeners is that it's probably worth going to the trouble of turning these ALG supports off in your routers, your border routers, if you have them.  I'm using pfSense at this location.  Actually I'm using pfSense at both locations, so nothing incoming would work.  But I do know that the ASUS router has a tab where there's a list of, I don't know, seven or eight of those things.  I remember I turned off IPSec, thinking that I didn't need it.  But I'm using one of those, as I mentioned once before, one of the little Verizon, they're not called nano...  



LEO:  Microcells or something, yeah.



STEVE:  Yeah, the little...



LEO:  Femtocells is the technical term.



STEVE:  Femto, yeah, femto, exactly.



LEO:  But Verizon has its own name.



STEVE:  Right.  And we're in a really bad reception area, so I'm using a femtocell for us.  And it requires IPSec.  So I was like really puzzled.  It was like, wait, how did I break that?  It was like, oh, and then I remembered that I had turned it off.  But there's typically a list of those things, like you may have a checkmark for SIP.  You may have a checkmark for IRC.  My point is, if you're not using those things, this is another example of turn stuff off that you're not using.



And so I know that there's a bunch of things that I could turn off in my ASUS router.  And I turned them all off.  Then it was like, then my femtocell broke, so I had to turn on IPSec.  But the rest of them are still off because I don't need those other things.  And this is an example of just not having unneeded services available, just protecting you, because today we have this.  Who knows what we're going to have tomorrow.  Our browsers will shortly be fixed.  In fact, I didn't think of it, but maybe that's what happened from the 183 to the 193 change that I mentioned from last week to this week.  Maybe those ports are already being preemptively blocked by Chrome because we know that they would be quick to do that.



So that's what the Slipstream attack is.  It is a clever way of abusing, essentially using your browser to pretend to be a client of one of these Application Layer Gateways, all of which had the ability, by spoofing what's going on, to trick the router into opening a return path back through the router, which the browser would be able to aim at anything on your network.  So it's certainly possible that bad guys could use it to get up to some mischief.



LEO:  I'm just busily trying to find out if my Ubiquiti supports Application Layer Gateway, and which ones - I know SIP is in there, but that's not turned on, obviously.  So most of that stuff you wouldn't turn on.  DCC for IRC, H.323 for VoIP, FTP, it seems like.



STEVE:  Well, exactly.  But the problem is most of them are on by default from the factory because they don't want the installation of their router to break something.



LEO:  Right, right.



STEVE:  And so for the naive user, okay, that's the right thing.  For our audience, you know, go pry that stuff out with a pitchfork.



LEO:  Yeah.  I'm just trying to figure out where that would be.  But I will find it.  And chaos...



STEVE:  And same thing on that ASUS router.  You've got to dig in a few...



LEO:  Yeah, I'm sure it's hidden away, yeah.



STEVE:  There are so many bells and whistles on the routers these days.



LEO:  Yeah.  The beauty of the Ubiquiti is I can do it from here.  I can log into my router at home from here and see what's going on.  So I'm just - I'm looking at it.  Probably advanced features or something like that.  Oh, yeah, Advanced Gateway Settings.  Bet you that's it.



STEVE:  ALG.  Gee, yeah.



LEO:  Well, anyway, we've got to finish the show.



STEVE:  Cool.



LEO:  I'll do that after.  I'll do that later.  Hey, that's it for this episode.



STEVE:  As they say, "That's the show."



LEO:  That's the show, baby.  And that's the guy, the guy behind the curtain.  He's Mr. Steve Gibson.  You want to know more, you go to GRC.com.  That's his home on the Internet, the Gibson Research Corporation.  That's where you can find SpinRite, the world's best hard drive maintenance and recovery utility.  He's working hard on 6.1.  6.0 is available.  You get a free upgrade.



STEVE:  Am.



LEO:  M?



STEVE:  Am.  I am.



LEO:  Oh, I thought there was some code, M.



STEVE:  Version M.



LEO:  M.  Yes, he is.  Yes, he is working hard.  6.1 will come soon, but you will have a free copy if you buy 6.0 now.  Steve also has this show there.  In fact he has unique versions of the show, a 16Kb audio version for the bandwidth-impaired; beautifully written transcripts by Elaine Farris so you can read along as you listen; and of course 64Kb audio.  GRC.com.



We have audio and video at our site, TWiT.tv/sn.  Of course, the easiest thing to do would be subscribe in your favorite podcast app.  You'll get it automatically, the minute it's available.  We do the show every Tuesday afternoon, about 1:30 Pacific.  It varies, depending on the shows before it.  But about 1:30 Pacific, 4:30 Eastern time, 20:30 UTC.



And the reason I mention our live production time is because you can watch us do it live, if you're in a big hurry.  The stream's at TWiT.tv/live.  There are audio and video streams you can choose from there.  People who watch live often like to chat live, which would be irc.twit.tv.  Yes, it's the good old IRC.  No DCC required.  Don't worry.  I don't think; right?  We don't need DCC.  ScooterX, correct me if I'm wrong.  We also have on-demand versions.  I mentioned that.  Oh, and we have a great forum.  Steve's got his forums.  They're fantastic.  We have ours at www.twit.community.  Okay.  Whew.  That being done, I think it's time to say so long, Steve.



STEVE:  Mission accomplished.



LEO:  Mission accomplished.



STEVE:  Until next Tuesday with the release of the final book in the trilogy.



LEO:  I know what you're going to be doing Tuesday night.  We'll see you next time on Security Now!.



STEVE:  Tonight I'll be finishing watching "Queen's Gambit."



LEO:  Oh, yeah, what a good show that is, yeah.



STEVE:  Ooh.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#793

DATE:		November 17, 2020

TITLE:		SAD DNS

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-793.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week the Chrome zero-days just keep on coming, and we contemplate what it means for the future.  We have two interesting bits of ransomware meta news including a new tactic.  We update after last week's Super Tuesday patch marathon, and examine new research into the most common source of Android malware to see where most unwanted apps come from  and it's not what we would likely guess.  We'll share a bit of listener feedback and an update on my work on SpinRite.  Then we look at the new "SAD DNS" attack which successfully regresses us 12 years in DNS cache poisoning and spoofing attack prevention.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with more Chrome zero-days, two of them in fact.  Did you see the Facebook ad for Ragnar Locker, the ransomware?  Steve will talk about that.  We also have a story, a very sad story about an attack on DNS servers that's probably coming soon to a server near you.  How to patch it and how it works, coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 793, recorded Tuesday, November 17th, 2020:  SAD DNS.



It's time for Security Now!, the show where we cover the latest security and privacy news from the king of security, Mr. Steve Gibson.  Actually, if you were the king you would be in trouble because you're doing a terrible job.



STEVE GIBSON:  I could be the esquire.



LEO:  The esquire.



STEVE:  That's right.



LEO:  The guy who's protecting us is what he is.  Hi, Steve.  It's good to see you.



STEVE:  Yes, indeed.  We have Episode 793 this week, and counting.  Just crossed the middle of November.  This one is titled "SAD DNS."



LEO:  Awww.



STEVE:  And normally I'm tempted to talk about the acronym, like how that was made, but I don't even remember.  It was such a stretch.  They used, like, S for I don't know, something, spoof or secure or something.  And then the A came from the beginning of a word, and the D from the last character of it.  And I just, every time I saw it, I thought, well, okay, that is SAD indeed.  But it's a compelling story.  What we have is a - we haven't had one for 12 years, a functional DNS cache poisoning DNS spoofing attack.  This, of course, harkens back to 2008 and Dan Kaminsky and his discovery.  But we'll get to all that.  Really interesting topic.  And we're going to spend some time because what the guys did in order to pull this off is very cool.



First, we've got a continuing count of Chrome zero-days.  We're going to contemplate what that means also for the future.  We've got two interesting bits of what I would call "meta news" regarding ransomware, including a new tactic which has just come to light.  We're going to update after last week's Super Tuesday patch marathon and examine new research into the most common source of Android malware to see where most unwanted apps come from.  And it's not what we would likely guess.  We're also going to share a little bit of listener feedback.  I'm going to update on my work with SpinRite.  And then we're going to plow into this really, well, it's well named, an awkward acronym, SAD DNS attack technology.  And of course we do have a great Picture of the Week.



LEO:  As always.



STEVE:  I think another good podcast for our listeners, indeed.



LEO:  Let's get to our Picture of the Week.  What do you say?



STEVE:  So we've got a six-frame cartoon here, two guys sitting side by side on a bench.  The first one says, "Just think.  At some point in my childhood, when my dad picked me up, it was the last time he would ever pick me up."  The other guys goes, "Mmm."  And the first guy says, "And neither of us knew it at the time.  It's a sad thought, isn't it?"



LEO:  It is.  That's a sad thought.



STEVE:  And the second guy says, "Yeah."  And then second guy says, "I sometimes think one day there will be some old programmer who will write the last line of PHP.  And that'll be the end of years and years of PHP.  And of course, he won't know it at the time, either.  That's a sad thought, too; isn't it?"  And then they're sitting in the fifth frame saying nothing.  And finally the first guy says, "No."  And the other guy says, "No, you're right."



LEO:  Not sad at all.



STEVE:  Not at all sad.  Ah, PHP, how we love to hate thee.



LEO:  Oh, how funny.



STEVE:  Yes.



LEO:  It's probably a thousand years off, though, I've got to tell you.



STEVE:  Yeah.  Well, and really, think about it, you know, some hobbyists sometimes are writing a little bit of Pascal.



LEO:  Oh, god, yeah.



STEVE:  I still actually have a career writing assembly language.  So some things just really never die.



LEO:  Every December, I don't know if you know about...



STEVE:  Leo, you and LISP.



LEO:  I write LISP.  That's as old as me.  That's literally a language that's older than me.  It was created in 1956.  I do this every year.  It's fun.  I never get very far, but there's a programming contest called the Advent of Code.  It's an Advent calendar.  There's a new problem for every day in December.  And every year, those of us who are enthusiasts, we gear up, we get ready, what language are we going to use.  It's a great way to learn a language.  They're very challenging problems.  I saw somebody post yesterday, "I think I'm going to do it in Fortran."  And I thought, oh, good luck.  Have fun, my friend.



STEVE:  Well, and with Fortran you just get a piece of paper.



LEO:  You can write it.



STEVE:  Get a piece of Scotch tape and put it down over the Shift key because...



LEO:  You're going to be pressing it a lot.



STEVE:  ...Fortran didn't have any case.



LEO:  All in caps.



STEVE:  It was all capitals.



LEO:  Yup, all in caps, yup.



STEVE:  Back in the days of card punches.  Boy, you know, memory was always a challenge.  We were punching holes in paper in order to remember binary bits back then.  So two more new zero-days revealed in Chrome.  Last week we had three zero-days patched in the previous two weeks.  Today we have five zero-days.  Patched in the previous three weeks.



LEO:  Geez.



STEVE:  I know.  And we were just talking about this last week, saying, you know, once upon a time IE was the favored target.  Now it's clear Chrome has become the majority browser.  And it's trying to be kind of an everyman's application execution environment.  It's trying to be a little mini operating system with all the crap that the World Wide Web Consortium keeps pouring into our browsers.  And it has bugs.



So last Wednesday the 11th, Chrome announced the stable channel update for Windows, Mac, and Linux.  We're now at 86.0.4240.198.  And I had commented last week that I was already a dot one nine whatever it was, or 163 or something.  I was further along than they'd made any announcement of, and I didn't know why.  Maybe this was part of that.  So this one is already rolled out.  Under "Security Fixes and Rewards" in their announcement of this stable update, they noted with their standard boilerplate that details would be kept restricted until the majority of users would no longer be affected.  They indicated that both of those new-in-the-wild zero days were discovered and reported by "Anonymous," the first on the 7th and the second on the 9th.  And this thing was released on the 11th.  So the update was pushed out to our desktops very quickly after it was reported to Google.  And the bounty rewards for both of those was $TBD.  So, you know, To Be Determined.



The first flaw was another of those "inappropriate implementation in V8," which is exactly the language that was used to describe the previous week's zero-day vulnerability.  The other flaw was a user-after-free flaw in the site isolation component, which of course we depend upon because we don't want cross-site exploitability.  And you know, this is the model for the way we need to be doing security moving forward.  Researchers spot problems, either doing static research or by catching something that they see happening in the wild.  They report them privately to the responsible party, whomever that is.  That responsible party rewards them for their discovery and for keeping their report private, and then quickly updates the affected software, pushing it out to all affected parties or devices, depending upon what it is.



I mean, that's what we're seeing here.  Problems are being found.  I mean, they're going to exist in something as crazy complicated as a modern browser, not to mention an operating system.  There's going to be problems.  There seems to be no end of them.  We'll be talking about last Tuesday's 112 things that were fixed.  And remember, those didn't just appear in the last month.  Those have been lurking in Windows and all related applications for probably a long time.  We know that some of them affect Windows 7, and those are not getting fixed anymore.  So, what, that's 2008.  That's 12 years ago.  So we have this problem.



One thing we know today with absolute certainty is that cyberwar and cybercrime, either ad hoc or organized, are very real things.  They exist, and they probably will now forever.  As with encryption, which we were talking about last week, once that genie is out of the bottle, you can't put it back.  Fifteen years ago, when this podcast was just launching, some cyberwar may have been underway by nation states.  I think I may have mentioned before that in the early days I was once approached by a three-letter agency and asked whether I might be interested in developing networked cybertechnology for offensive purposes.  I declined since that doesn't really appeal to me.  And I naively failed at the time to appreciate that my country might actually be under attack, then or in the future.



But we're living in a science fiction world these days.  We're all walking around with masks on, and we've got, you know, cyberwar is a real thing.  But I'm sure that plenty of other people did not decline when they were approached.  So this suggests that all of this has been percolating for decades.  Stuxnet showed us what was possible.  Edward Snowden filled in many suspicions and revealed a range of sobering truths about what our U.S. intelligence agencies had been and were up to.



So across this 15-year lifespan of this podcast, we've watched it happen.  Cyberwar and cybercrime have gone from "Really, like that happens?" to "Oh, my god, take us off the 'Net now."  There are corporations pulling the plug all over the place when they realize they're under attack.  So it's now front of mind for many in the IT industry; and CSO, Chief Security Officer, is now a C-suite position, which used to not even exist.



And of course we know that not all software is in the same position.  The firmware controlling an electric toothbrush just needs to manage its rechargeable battery, run a timer, and control its motor.  If it's not connected, there's no way anyone can get to it.  But any software, and I would highlight in bold "any," any software that is connected, even if it's a coffee pot or a thermostat or, as we know, printers, is exposed to what is obviously an increasingly hostile world.  Nothing connected to the Internet can afford the luxury of being naive to the very real possibility that it might be used as an entry point for cybercrime.  And no one using connected devices can afford not to exercise some caution over their deployment within a network.



And as I noted above, the Chrome project has evolved the right model.  The browser is out on the front lines.  It needs to be updatable autonomously with a super short cycle.  But since Google has not done it right everywhere, we know that, Android is a catastrophe.  And we'll be talking about that a little bit later.  Yes, they're working hard to fix their earlier mistakes, making more of the Android OS push updatable.  But the vast majority of today's Android devices, as we know, will never be updated.  So we can only hope for the sake of their owners that those devices die as soon as possible.  Just completely.  Just remove them from the world, to be replaced, hopefully, by Google's newer autonomously updatable operating systems.  That's where we have to be.



And as for the rest of the consumer and enterprise industry, the same goes.  The only responsible way to produce anything that's connected to the Internet is to provide a built-in means for allowing the party responsible for its maintenance some kind of autonomous means for pushing out critical updates.  Maybe get the permission of its user.  You need a means to do that, though.  Our routers don't really have that.  They operate just completely autonomously.  We've talked about this before.  They've been a source of a great deal of insecurity.  There just needs to be a way for these things to take care of themselves.



So anyway, I just, you know, the idea that every time we meet here Google has a few more editions of Chrome demonstrates that they've got that fast-cycle approach.  They were told of one problem on the 7th, another one on the 9th.  There's a new version on the 11th that removes them both.  They're not going to create a perfect solution.  We know that ship has sailed for anything that is sufficiently complex.  So the only thing you can do is put in place a response cycle that fields problems, reacts to them quickly, and just closes them down, you know, keeping people as safe as possible.



A group known as Intel 471 published a report.  I've got two pieces of sort of what I called "ransomware meta news."  As we have unfortunately been observing, the ransomware "business," and I put it in quotes in my notes, is booming.  I don't like calling it a business, but that's what it is.  But we've been looking at this like one case at a time, one piece of ransomware at a time.  And so it occurred to me that it's easy to lose sight of the forest when we look too closely at the individual trees.  When we pull back and take in the entire scope of what's been evolving somewhat unseen, what we have is a bit startling.  These guys report on that.



The question they answer, how many Ransomware as a Service - that's our acronym, RaaS, Ransomware as a Service - operations are there today?  We've touched on the comings and goings of a few of them.  But a comprehensive review finds that there are presently more than 25 separate RaaS, Ransomware as a Service, portals now in business, in the business of renting ransomware for use by other criminal gangs.  This group, Intel 471, published their report yesterday titled "Ransomware-as-a-Service:  The pandemic within a pandemic," you know, talking about the whole COVID-19 thing and like this has been happening this year.



Their report was not highly detailed, but it was illuminating.  And as I said, I disliked legitimizing this by calling it a business, but this is the way it's developing.  I mean, yeah, it's dark.  It's mal.  It's criminal.  But it's an enterprise.  And I guess it's not really surprising that what would be revealed, and this was in their report, is a hierarchy of players.  A few at the top who are pulling down the lion's share of the extortion revenue, they used the word "profit," but it just doesn't feel right to call it profit.  So it's extortion-based revenue.  There's also a much larger base of wannabe players who are in the "business."  They've got portals.  They're hoping to make their mark and then get cut in for a piece of this action.



So in looking through this report, I did note that this podcast had not missed anything.  The big players noted by Intel 471's research are DoppelPaymer, Egregor, Ragnar Locker, REvil, and Ryuk.



LEO:  They need some better vulnerability names.  I know where you can get them, too.



STEVE:  So those are the guys at the top of the pyramid making the lion's share of the money.  The one thing this research does show is that there are those other 20 me-too players who are working hard to move from the also-ran to the pay-us-now-or-else category.  They may not stay as second-tier players forever.  So we'll keep an eye on the news and see how this goes.



The second piece of meta news about ransomware, you just had to shake your head.  Ragnar Locker took out a Facebook ad.



LEO:  Wow.



STEVE:  I know.  I know.



LEO:  It's also, by the way, a pretty good name.  I do like Ragnar Locker, yeah.



STEVE:  Ragnar Locker, yup.  Last week we mentioned their successful ransomware attack on the Italian distiller Campari, and their publication at the time of the contract between Wild Turkey, one of Campari's brands, and Matthew McConaughey.  It appears that this gang is into shaming their victims as a means of inducing payment.  And I suppose this is the logical next step.



LEO:  Sure. 



STEVE:  Eventually companies are going to become more able to recover from the original, simpler, local ransomware encryption attacks; right?  I mean, like they're going to, like, with this in the air as much as it is, and we've talked about the CEOs are going to be looking at their CIOs saying, "We can survive one of these; right?  Everything's backed up?  If this happens to us, you'll get us back online quickly?"  And the CIO says, yeah, you know, we got that all set up last month or the month before, whenever.  So it's foreseeable that the effect of the original "We'll give you the decryption key" extortion may be weakening over time.



So get this.  After obtaining 2TB of sensitive data, which was stolen during their November 3rd attack, which was exactly two weeks ago today, and demanding a $50 million ransom paid in bitcoin, the Ragnar Locker gang have used a compromised Facebook account to take out a public Facebook ad threatening to publicly release the sensitive Campari data - remember they got 2TB of it - unless the ransom is paid.  So apparently this new tactic is intended to publicly shame and pressure the ransomware victim into paying.  Even if they don't so much need the decryption keys, they don't want it known that 2TB of potentially sensitive data is loose.  The compromised Facebook account belonged to a Chicago-based DJ by the name of Chris Hodson.  Chris believed that all of his online accounts had been protected by two-factor authentication.  But it turned out that he missed one, Facebook.



LEO:  Oh, geez.



STEVE:  Brian Krebs, who reported on this, wrote that Chris said a review of his account showed the unauthorized campaign reached approximately 7,150 Facebook users and generated an impressive 770 clicks, over 10%, with a cost per click of $0.21.



LEO:  Wow.  That's good.



STEVE:  Yeah.  Chris said Facebook billed him $35 for the first part of the campaign, but apparently detected the ads as fraudulent before his account could be billed another $159 for the campaign.  So we have a new wrinkle added to the ransomware scenario:  Ransomware gangs who get into a corporate network are going to first exfiltrate as much data as they can.  Then they will deny its owners access by encrypting it in their wake because why not?  Encryption is easy now.



Then they contact the victim and demand payment, not only for providing the master decryption key, but also to threaten the release of their victim's sensitive corporate data with the newly added wrinkle that they might widely and publicly employ an advertising pressure campaign to up the ante and further coerce payment.  And of course, you know, given that these attackers have already shown their true colors, I mean, right, they're criminals, there's no reason to expect nor any means to enforce the permanent deletion of the sensitive stolen data.  So it's a mess.



On the other hand, we're sort of where we were before with these gangs having it in their own best interest, much as they were actually giving decryption keys when ransoms were paid.  They have to honor their commitment to delete the data, or at least never release it, because if that ends up not being honored, then people will have no additional incentive to pay the ransom.  So it's a weird world we're in, but it's the one we've got.



Last Tuesday's Windows patching, Microsoft fixed, as I mentioned, 112 known vulnerabilities.  Not that there aren't going to be another 112 next month.  But this month we've got this 112.  Seventeen of those 112 were rated critical; 93 were important; and two were just moderate.  And in terms of remote code execution, looking at it from that perspective, 24 of those flaws of those total of 112 created pathways for attacker-supplied code to be executed in vulnerable systems using Excel, SharePoint, Exchange Server, Windows Network File System - we'll talk a little bit more about that in a minute - Windows GDI+ component, and Windows print spooler service.  Oh, and also Microsoft Teams.



We did receive the expected and hoped-for patch for the zero-day privilege escalation vulnerability which exists in Windows Kernel Cryptography Driver.  Remember, that was the one where, because the driver exposed an API to the userland for use by applications, that created a connection from user mode down into the kernel.  We learned about it the week before Patch Tuesday, when we learned that one of those zero-days that Google closed was part of a chain of which this was another part.  Microsoft felt, well, since the particular exploit vector was the browser, and Google took care of that, you know, we expected it would get fixed last week, and indeed it was.  So that's been fixed.



But this thing also affects Windows 7 and the synchronized server, Windows Server 2008 R2.  I went over to 0patch.com, wondering whether they would be offering a fix for Windows 7 and the Server 2008 R2 folks.  There was something in late October, but nothing yet in November.  They may get around to it.  And as the number of problems that Microsoft is not fixing on Windows 7 - which remember is still the number two platform in use.  Windows 10, yes, finally did replace 7 in the number one slot, but Windows 7 is now number two.  And so there's a lot of them, and they're never going to go away.  They will be running Windows 7 until their hardware dies, much like those phones, the smartphones running Android, the old Android that's not being updated either, until those smartphones die.  That's just the way this industry is turning out to be taking shape.



So I'll be keeping an eye on 0patch because, as I was saying, the longer this goes on, the greater the benefit to being covered by this third-party patching solution becomes for people who are still wanting to run Windows 7.  And there are lots of places where you could run it safely, if it's not being exposed to the Internet, or if you're keeping a state-of-the-art browser.  And Microsoft is continuing to keep Windows Defender updated, even on those systems.  So you've got a lot of security.  Although, yes, known problems that bad stuff that did happen to get in could take advantage of.  And the number of those known baddies is continuing now to increase for those things that we know affect Windows 10, which also affect Windows 7.  On the other hand, Microsoft is also introducing new problems in Windows 10 that will never affect Windows 7.



And in addition to repairing that zero-day and those many other repaired remote code execution vulnerabilities, an unspecified, and I love this, they just called it a "security bypass flaw,"  was fixed in Windows Hyper-V.  But as I was writing that, it occurred to me that calling something a "security bypass" says absolutely nothing about it.  Which I suppose was Microsoft's intention, since what cannot be described as a security bypass?  Last week's Picture of the Week was that locked gate standing out all by itself in a field.  That's a security bypass.



LEO:  Yeah, you don't really need security to bypass that.



STEVE:  Yeah.  One of the remote code executions is an RCE in the Network File System.  It's rated 9.8 out of 10.  And one place you really never want a remote code execution is in your network file system.  Microsoft has also stated that the attack complexity is low, which is only good news when you're the attacker.  Since NFS runs over TCP and UDP port 2049, expect to be seeing an increase in port scanning targeting 2049.  A Shodan query reported 38,893 exposed port 2049s on the Internet.  However, exploitation requires that an NFS share be configured for anonymous write access, thus no authentication required.  Doing something like that is not all that uncommon.  Leo, I'm sure you'll remember how once upon a time FTP servers would often allow for anonymous file uploads into a specific protected directory.



LEO:  Right.



STEVE:  You'd remove the privileges from the directory so that nothing there, like you couldn't execute anything from there.



LEO:  Yeah, you could have a public FTP site, yeah.



STEVE:  Yeah, exactly.  So it would collect stuff, and the idea being that such files received would be treated with caution, but that there was some valid reason for needing to receive unsolicited files.



LEO:  Yeah, if you had a BBS 



STEVE:  Like people submitting samples.



LEO:  Yeah, or people uploading to your BBS, that kind of thing, yeah.



STEVE:  Yeah, exactly, exactly.  So of those 38,893 servers answering on port 2049, we don't know what percentage of them are actually NFS shares and also configured for anonymous write access.  But I'd put some money down on a bet that attackers are working to determine exactly what that count is right now.  Microsoft also fixed critical memory corruption vulnerabilities in their scripting engine and in IE, and once again multiple remote code execution flaws in that HEVC, that's the Video Extensions Codecs library.  As we know, codecs are interpreters.  They're interpreting compressed media, and interpreters are hard to get right.  And of course all of those have Internet-facing exposures.  So yeah, as always, updating when you can would be wise.



LEO:  Yeah.



STEVE:  I thought this was sort of interesting.  Where do most malicious Android apps come from?



LEO:  I'm going to guess the Play Store.



STEVE:  Oh, Leo.  Yes.  Good guess.



LEO:  But that's because Android's not like a desktop operating system where you're downloading stuff all over the place.  You kind of can, but almost everybody uses Android, that's where they put new stuff on their systems is the Play Store, yeah.



STEVE:  We have some numbers behind your correct intuition.  It turns out the bulk of Android apps are not coming from unauthorized third-party app sources and repositories, as someone might think.  In a recently published 17-page report titled "How Did That Get in My Phone?  Unwanted App Distribution on Android Devices"...



LEO:  I don't like it in my phone.



STEVE:  ...NortonLifeLock, which has now been - it's like the formal renaming of Symantec.  Symantec is now NortonLifeLock.  I guess they wanted just to go to products rather than...



LEO:  Consumer products, yeah.



STEVE:  [NortonLifeLock] introduced the result of their careful four-month study.  They wrote:  "Android is the most popular operating system with billions of active devices.  Unfortunately, its popularity and openness makes it attractive for unwanted apps, malware, and potentially unwanted programs (PUPs).  In Android," they wrote, "app installations typically happen via the official and alternative markets, but also via other smaller and less understood alternative distribution vectors such as web downloads, pay-per-install services, backup restoration, bloatware, and Instant Messaging tools.  This work performs a thorough investigation on unwanted app distribution by quantifying and comparing distribution through different vectors.



"At the core of our measurements are reputation logs of a large security vendor, which include 7.9 million apps observed in 12 million Android devices" - so big samples - "between June and September of 2019."  So last summer, summer a year ago.  "As a first step," they wrote, "we measure that between 10% and 24% of users' devices encounter at least one unwanted app, and compare the prevalence of malware and PUP," the potentially unwanted programs.



They said:  "An analysis of the who-installs-who relationships between installers and their child apps reveals that" - as you said, Leo - "the Google Play market is the main app distribution vector, responsible for 87% of all installs and 67% of unwanted app installs, while also providing the best defense against unwanted apps.  Alternative markets distribute instead 5.7% of all apps, but over 10% of unwanted apps."  They said:  "Bloatware is also a significant unwanted app distribution vector, with 6% of those installs.  And backup restoration is an unintentional distribution vector that may even allow unwanted apps to survive users' phone replacement."  In other words, you backed up a phone containing bad stuff, and then you restored it to a new phone and brought the bad stuff back with you.



They said:  "We estimate unwanted app distribution via pay-per-install to be smaller than on Windows.  Finally," they said, "we observe that web downloads are rare, but provide a riskier proposition even compared to alternative markets."  And of course that's not a surprise.  One of our longstanding rules of the road is, remember, never download something that is offered to you when you're surfing the web.  Classically, oh, you need to update your version of Adobe Flash.  Click here.  Unh-unh, no, don't.



So anyway, exactly as you said, Leo, this research demonstrates that it's really just a numbers game.  We've often said that installing from non-Google Play sources is dangerous.  And that's true, as a percentage of per-installs.  But the Google Play Store does a far better job of keeping the crap off people's phones on a percentage of the crap basis.  When viewed overall, the Google Play Store being the source of 87% of all Android app installs simply means that, as their research showed, that's where two-thirds of all unwanted apps come from, only because that's where almost all apps come from.  And of course, as a percentage of all apps, they're doing a better job.



But interestingly, this still supports and doesn't change our longstanding advice, which is don't install stuff just because it's there.  That's where people get in trouble.  Resist the temptation to say, "Oh, look at that," and then click, "Yeah, gimme."  You know, some percentage will be junk that you don't want, even from the Google Play Store.  And in fact, as the research shows, since there's so much more stuff there overall, the absolute amount of junk that is potentially unwanted on the Google Play Store is just that much higher because there's just so much overall, even though as a percentage it's lower.  So anyway, that 17-page paper had tables and charts, and I have a complete decomposition of all this.  I put a link to it in the show notes in case we have any Android users who are interested in looking at this in more depth.



I had two interesting bits of feedback that I wanted to share.  Kevin Morris, he said:  "Hi, Steve.  I've been experimenting with various flavors of Linux, and once I burned an ISO to my flash drive, I always had a devil of a time ever being able to use it again."  He said:  "InitDisk solved the problem.  Thank you for that.  Kevin Morris."  He's in Santa Clara.



Anyway, so I just wanted to use that as a reminder to me to remind our listeners that that little InitDisk utility that I created earlier in this phase of work for SpinRite, InitDisk will be the USB prep technology which I developed for this next version of SpinRite, since so much has changed since, was it 2004?  Yeah, 2004, when SpinRite 6 was produced.  And back then diskettes were still a thing.  They're rare these days.  Not gone, but rare.



LEO:  They're pretty hard to find, yeah.



STEVE:  Anyway, yeah.  InitDisk does such a good job of preparing a flash drive that, oddly, other things will refuse in some instances to work.  InitDisk almost never refuses.  And /dev/jake is his Twitter handle.  He said:  "@SGgrc, playing devil's advocate, but isn't the Let's Encrypt issue you spoke of last week a good reason to force users of Android devices older than 7.1 to upgrade, if they can, or abandon those insecure devices?"  And of course he's talking about the problem of the Let's Encrypt root, which is expiring next year, and them scrambling a bit because they realize that fully one-third of Android devices which are older than 7.1 will never be updated.



So I just wanted to say, like, he says wouldn't it be a good reason to force users of Android devices older than 7.1 to upgrade?  How do you do that?  I mean, they own their devices.  We can't, like, scare them, wave our hands around.  They're obviously not paying attention to all this.  They don't know what's going on.  Stuff's just not going to work for them.  So, I mean, I wanted to make sure that everybody understood that there's no leverage.  Like wouldn't Microsoft love to force Windows 7 users to upgrade to Windows 10?  Well, lord knows, Microsoft pulled every possible trick in the book, even removing the Close box from the dialog and only giving you a choice of now or later.  They took away the "No, thanks" button finally, and still Windows 7 is the second most popular OS on the planet.  Microsoft would like that number to be zero.  They tried really hard.



So anyway, the point is that some things you can't make happen.  This is one of them.  It's just going to be those older devices.  Their batteries finally just give up, they only hold a charge for 10 minutes, and it's not a replaceable battery, so okay, fine, scrap heap for this thing.  That's the only way they're going to go away, just like Windows 7 machines.  You can't buy a Windows 7 machine now.  Anything you get that has Windows on it is going to be 10.  So over time, those old 7...



LEO:  It's expensive, too.  Not everybody can afford to buy a new phone like we do, or a new computer like we do.



STEVE:  Right, right.



LEO:  Windows 7 you could update, but I understand why those old Android phones, a lot of them were low-cost phones to begin with, $50 phones to begin with.  And you imagine a lot of them are in India and China and places where people just don't have the disposable income to replace them.  Which is unfortunate, I mean, they're stuck with it.



STEVE:  What about hardware level and driver level?  I would imagine a lot of them won't run as a very late-model Android.



LEO:  Exactly, yeah.



STEVE:  Updating isn't even a...



LEO:  Google created Android Go for these low-and-slow phones because they needed something that was lower resource use.  It's a tough situation.  But it's a testament to the success of Android, if nothing else.  You don't have this problem with iPhones because there were no $50 iPhones.



STEVE:  Right.



LEO:  Ever.



STEVE:  Right.  And there aren't, I mean, as we know, Android is the largest install base. 



LEO:  Right, by far.



STEVE:  Billions and billions of those things.



LEO:  Exactly.



STEVE:  So I thought it would be interesting for our listeners to share something that I posted yesterday in the spinrite.dev newsgroup at GRC.  This was sort of - actually, it was just as I was putting things down to switch over to work on the podcast production.  I wrote:  Everyone.  Working with millQ - he's one of our very valuable contributors.  That guy's got more PCs than anyone I've ever seen.  Working with millQ through a series of tests, we finally tracked down the cause for drives appearing and disappearing, depending upon whether, even though the system was booted from diskette, an unused USB stick also in the machine was causing some hard drives not to be seen.  A register within the PCI RAM space contained bogus data that my code had been relying upon.  Since only four of that register's 32 bits should ever be non-zero, the addition of a sanity test to that register's contents now prevents it from being trusted when it should not be.



This resolved the drive coming and going that millQ was seeing, and it might also have fixed other known and as yet unknown problems from ever occurring.  And I said:  A good day for the future of SpinRite.  I said:  I'm switching to podcast prep mode until it's behind me.  Thank you, everyone, for the patient testing and feedback.  We're making some last improvements that are very useful.  I said:  millQ has some weird crashing behavior on that one very old laptop - he's got an old ThinkPad 390.  And it turns out that by changing the setting of LASTDRIVE in the DOS config.sys he's able to cause some weird behavior.  And we have a guy in Germany, Chris, has a hang problem on one AMD machine which also doesn't happen if he boots it from floppy, but does if he boots from USB.



Anyway, but, I mean, we're down to, like, almost no problems remaining.  I was thinking, Leo, about the old - remember the old 90/10 rule where 90% of the work goes into the last 10%.  I'm at the 99.99/0.01 rule.



LEO:  Well, the 90/10 rule applies to every 10%.  So at 99, the last percent is going to take 90 percent of the effort.



STEVE:  Ah, right.



LEO:  You see?  It's basically...



STEVE:  Exponential.



LEO:  Yeah, you'll never get there, in other words.



STEVE:  Never really get it.



LEO:  You'll never be done.



STEVE:  The good news is we're getting to the point where it's like, okay, folks.  And a lot of the testers are really kind of getting annoyed because it has always worked for them on everything they've ever tried it on.  But of course those aren't the people that I'm concerned about.



LEO:  Right, right.



STEVE:  It's like, okay, good, yeah.  But I want this thing, you know, we've got a lot of SpinRite 6 users in the world.  And so every last little exponential 10% that I can remove from having a problem, the better.  On the other hand, it's like, works for everybody.



Oh, and somebody else wrote to me, it was just a cute note.  He said:  "Dear Steve.  I'm a regular follower of Security Now! and a VERY [all caps is his] happy SpinRite 6 user.  It is my go-to tool to test new drives as I purchase them.  I find that IF they successfully pass" - and this is a capital IF also, that's interesting, brand new drive - "successfully pass SpinRite's Level 4 testing, they usually give many good years of service.



"I'm writing to you today to ask you a favor.  With your blessing, I would like to join your testing group for the latest SpinRite.  Since it's nearly ready to go, what could one more tester hurt?  I just purchased" - yeah.  "I just purchased one of what will be four 4TB WD drives and found to my dismay that SpinRite" - and he's using 6.  Oh, yeah, he said SpinRite 6 at the top - "that SpinRite doesn't do GPT" - that's of course the newer partition format, GUID Partition Table, he said - "in its current version."  Duh.  He said:  "I suppose I should have known this, but didn't.  If you could see fit to allow me into the program and use the current SpinRite beta, I promise not to blame you if I should ever develop an allergy to asparagus."



LEO:  Okay.



STEVE:  Uh-huh.  "For verification purposes, below is my original SpinRite purchase information.  The original email address is no longer preferred as the company is defunct."  He says:  "Who could compete with TiVo?  But you can reach me here on Gmail.  With anticipation, thanks."  So a couple things I need to clarify.  The work we're doing is on the technology, like most of the technology, actually all of the new technology that SpinRite 6 will be needing to go to 6.1.  And it's working.  I mean, it's like, done, with one weird thing in Germany and a ThinkPad 390 or something, if you stand it vertically and shake it with a USB drive.  I mean, it's like, okay, but I would like to know why.  So everybody is welcome to work with us in the GRC newsgroups.



On the other hand, because they're kind of NNTP old-school text-only funky, that's why I created the GRC forums at forums.grc.com.  This technology, and it's already calling itself ReadSpeed, that's going to be this benchmark, which is like the testing platform for the technology, it will be over on the web forums, which are much easier to use than the old-school textual NNTP newsgroup.  But that's where all the development is always being done.



So if you're someone who, like, enjoys that kind of thing, you're welcome to join us over in GRC newsgroups.  You just need to point a newsreader.  You have to have a newsreader.  Thunderbird can read newsgroups.  Gravity is my favorite newsreader I've spoken of before.  News.grc.com is the server.  And welcome.  But it's more friendly, user-friendly, and graphical.  And the reason I created the web forums is because I wanted something that would be a better way for us to deal with everybody on the podcast who wants to play with this and then easily provide feedback.  So that'll be there.  And then that will evolve into the SpinRite web forums as we get there.



So what'll happen is ReadSpeed will get the last dents polished out of it, and we'll probably discover some when we get a much larger testing audience, which is my goal for this.  Once that's done, then I switch into incorporating all of its technology into SpinRite 6 to create 6.1.  And at that point we will have SpinRite 6.1 betas, and anybody who's a 6 owner will be able to use that purchase information that this guy was talking about, the serial number from your copy or your transaction ID from your purchase.  And if you have neither of them, you can write to Sue, and she'll look you up and get them.  Those you then use to download the betas before we're officially finished.



So that's the whole deal in a nutshell, just as sort of a review to people.  Basically, soon, I will be announcing on this podcast that this thing I've been working on is available for download by anyone over in the forums.grc.com.  Come over, grab a copy.  You don't need to join the forums to do that.  You do need to join the forums in order to post and participate.  But hopefully within a couple weeks.



LEO:  Of course you can probably use SQRL to join those forums without any difficulty.



STEVE:  You can, as a matter of fact.  And people have said the most painless joining experience they have ever had.



LEO:  Back we go to the show.  And I've got to show these people the logo for SAD DNS.  



STEVE:  Awww.



LEO:  Awww.



STEVE:  It's sad.



LEO:  He's crying.  He's sad.



STEVE:  So a team of researchers, as I said, from the University of California at Riverside and the Tsinghua University in Beijing, presented their paper at the ACM Conference on Computer and Communications Security, that's CCS '20, which was held last week.  And it won the Distinguished Paper Award.



So, okay.  Before we go any further, let's step back and review DNS cache poisoning, which this podcast covered in great detail when it first happened 12 years ago.  That would have been, what, three years into the podcast.  It was a biggie for us at the time.  When a DNS resolver needs to look up the IP address of a domain on behalf of its user who has queried it, it in turn issues a query using the lightest weight means possible, which is a single UDP packet containing that query.  The UDP packet is addressed in turn to a more authoritative DNS server, asking it about some component of the DNS domain name path.  The reply packet, which is returned from the more authoritative DNS server, must be a reply returned to the same port on the first DNS server from which it was sent.  And the reply's internal DNS transaction ID must match a query that the DNS server currently has outstanding.



So that all just makes sense.  It was designed from the beginning.  It's been there from the start.  It was minimal.  It was inherently trusting, as was all of the Internet back in those quaint old days.  The whole system is admirably lean and very efficient.  But it inherently suffers from a series of now quite well known vulnerabilities.  For one thing, UDP is trivial to spoof.  Unlike TCP, where the famous three-way handshake among other things verifies the IPs of each endpoint in a conversation, a UDP packet is simply launched from the source IP it claims to have to whatever destination IP it chooses.  And that packet can contain whatever it wishes.  You know, just sort of like an Internet bullet that you can point wherever you want, and you're able to obscure where it came from.



So 12 years ago, during the summer of 2008 Black Hat conference, security researcher Dan Kaminsky presented his discovery of a massively widespread and critical DNS vulnerability that would have allowed attackers to send users to malicious websites, hijack email, and get up to all sorts of mischief.  It allowed for the poisoning of a DNS resolver's cache, basically causing the cache to contain a wrong IP address for a given domain.  Of course that would allow attackers to impersonate any legitimate website and steal data.



Now, okay, that was, what, 2008, so 12 years ago.  A lot's changed since then.  In today's world of HTTPS with certificate protection, this becomes more difficult.  But if a DNS cache is poisoned anywhere upstream of where Let's Encrypt, for example, does its lookups, then it's trivial to again obtain certificates for any desired website.  The flaw that Dan found allowed for arbitrary DNS cache poisoning, which at the time affected nearly every DNS server on the planet.  I say "nearly every" because the one brand of DNS - one - that was not vulnerable had been created by our old friend Daniel J. Bernstein, who had nine years earlier, back in 1999, told everyone not to take the mistake that they did, but no one paid attention.  He wrote his own DNS server, he did it right, and it was not vulnerable to this attack that Dan had found.



When Dan realized, Dan Kaminsky realized the extent of the vulnerabilities - that is, virtually all DNS servers could be easily poisoned - and what that meant for the integrity of the Internet, which depended, as it still does today, upon the integrity of DNS, he called Paul Vixie.  Paul was the well-known creator of several DNS protocol extensions and applications used throughout the Internet.  He told Paul about the bug that he'd found.  Together, they then called an emergency summit to Microsoft headquarters to discuss how to address this widespread problem and pulled in all of Paul's many contacts and vendor representatives.  That coalition worked silently to create a fix for the vulnerability before it was disclosed to the public.  All of the vendors simultaneously released patches for their products on July 8th of 2008.  I mean, this was that big a deal.



However, according to Dan at the time, they didn't actually repair DNS.  They just took a 16-bit transaction identifier which, for reasons of the protocol, could not be expanded beyond 16 bits.  And they added random UDP source ports as a hack to expand the query entropy from 16 bits to 32 bits.  In other words, DNS queries used to be issued from the fixed DNS service port 52, and the query contained a 16-bit transaction ID whose reply needed to match.  Even if the transaction ID was randomized, that's still only 64K possible transaction IDs.  So an attacker could stuff 64K replies into an awaiting DNS server, and one of them would be accepted as valid when it matched the transaction ID that was outstanding, thus poisoning the server's cache for anyone who then asked for that reply's DNS IP.



But by simply randomizing the DNS query's source port, instead of always issuing it from port 52, the change the entire industry made all at once on one day, by switching it to a random query source port, now any successful reply, that is, a successful attacker's reply, would need to match both the port and the transaction ID, thus expanding the query entropy from 16 bits to 32.  Once that had been done, an attack that used to take 10 seconds, that's what Dan had, and he demonstrated it to the group privately to get their attention, took 10 seconds to spoof a DNS query, going from 16 bits, which is, as we know 64K possibilities, to 32, which is now 4.3 billion possibilities, well, that no longer made random guessing attacks possible.  It eliminated this instantaneously successful attack.  And the industry breathed a collective sigh of relief about the bullet that they had dodged.



Okay.  As we know, just wanting to have systems upgraded doesn't make it so.  Therefore, coincident with that and the podcast when we talked about it, and also in the spirit of the ShieldsUP! service, I created GRC's DNS Spoofability Service.  It allows users to quickly and easily check the DNS servers they are using by virtue of their own Internet connection, typically their ISPs, but more recently any of the other popular third-party providers.  It analyzes the DNS query transaction entropy of those servers.  And back then, shortly after this had all happened, many users were still discovering that their DNS provider was using vulnerable DNS resolvers that were generating easily spoofable DNS queries.



The good news is, that is, that was 12 years ago.  That's much less so today.  It's rare that you run across a very poorly written server.  Okay.  So that was 12 years ago, 2008.  Things have been relatively quiet since that flurry of frenzied activity to dodge that bullet.  Until now.  This new group of researchers have titled their award-winning paper "DNS Cache Poisoning Attack Reloaded:  Revolutions with Side Channels."  Their paper explains their accomplishment with its introduction.



They wrote:  "In this paper, we report a series of flaws in the software stack that leads to a strong revival of DNS cache poisoning," they said, "a classic attack which is mitigated in practice with simple and effective randomization-based defenses such as randomized source port.  To successfully poison a DNS cache on a typical server, an off-path adversary" - "off-path" meaning an adversary that's not participating in the local network traffic - "would need to send an impractical number of" - and they say 2^32.  Actually on average half that, right, but still, that scale - "2^32 spoofed responses, simultaneously guessing the correct source port," which is 16 bits, "and the correct transaction ID," also 16 bits.



They said:  "Surprisingly, we discover weaknesses that allow an adversary to 'divide and conquer' that space by guessing the source port first, followed by the transaction ID.  This leads to only 2^16 plus 2^16 spoofed responses."  Otherwise it would have been 2^16 times 2^16.  You'd much rather have a plus there than a times.  They said:  "Even worse, we demonstrate a number of ways an adversary can extend the attack window" - which is to say that the time available to make all these guesses - "which drastically improves the odds of success."  And I had in here in my show notes a reminder of a time that we saw this before.  Remember that horrible vulnerability that was discovered in the - I wrote in my notes "WPA protocol," but it was actually - it was an aspect of it.  It was where you had the eight-digit PIN.  So was that WPS?



LEO:  That was WPS, yeah, where you press a button to - yeah, I remember that, yeah, yeah.



STEVE:  Right.  So you had an eight-digit PIN.  Now, normally that would be 100 million combinations and be impractical to guess.  But it was discovered that the first four digits could be guessed first independently and verified.



LEO:  So dopey.



STEVE:  Bringing that down to 10,000.  And it turns out, since the last digit of the eight was a check digit, then the final three, which is all you really had because you could calculate the last one, they could then be guessed and verified.  So you'd have a thousand.  So the guessing space was reduced from 100 million to 11,000.  The first 10,000 plus the second 1,000, so 11,000.  In other words, divide and conquer.  So we've seen this kind of thing before.



They wrote:  "The attack affects all layers of caches within the DNS infrastructure, such as DNS forwarders and resolver caches, and a wide range of DNS software stacks, including the most popular BIND, Unbound, and dnsmasq, running on top of Linux, and potentially other operating systems.  The major condition for a victim being vulnerable is that an OS and its network is configured to allow ICMP error replies."  And I'll explain exactly because this is very - this is diabolically clever.



They said:  "From our measurement, we find over 34% of the open resolver population on the Internet are vulnerable, and in particular 85% of the popular DNS services, including Google's 8.8.8.8" and also, elsewhere, 1.1.1.1, both vulnerable.  "Furthermore, we comprehensively validate the proposed attack with positive results against a variety of server configurations and network conditions that can affect the success of the attack, in both controlled experiments and with a production DNS resolver."  And they take pains in their paper to say "We got permission to do that. You know, we didn't do this without permission."



So their attack disclosure page provides a link to test one's own DNS servers.  So while I was preparing this report, I clicked the link, and I received "Your DNS server IP is 172.68.191.21.  It seems your DNS server is running Linux later than 3.18.  Since it is running the vulnerable version of OS that has not been patched yet, your DNS server is vulnerable.  The test currently only takes the side channel port scanning vulnerability into consideration.  A successful attack may also require other features of the server, for example, a supporting cache."  Then it says:  "This test is conducted on 2020-11-16" and the UTC time and date and so forth.



So what does this mean?  Separate from their report, their attack's description web page lays it out.  They said:  "'SAD DNS' is a revival of the classic DNS cache poisoning attack," they said, "which no longer works since 2008, leveraging novel network side channels that exist in all modern operating systems including Linux, Windows, macOS, and FreeBSD.  This represents an important milestone, the first weaponizable network side channel attack that has serious security impacts.  The attack allows an off-path attacker to inject a malicious DNS record into a DNS cache, for example, BIND, Unbound, dnsmasq.  The SAD DNS attack allows an attacker to redirect any traffic originally destined to a specific domain to his own server and then become a man-in-the-middle attacker, allowing eavesdropping and tampering of the communication."



Okay.  So that's sort of the broad strokes.  A bit deeper into their paper they lay out in some greater detail what they've done.  And this is what is so cool.  So as I said, once upon a time the port from which a query was generated was fixed at DNS port 52.  Was it 52 or 53?  Now I'm doubting myself.  But anyway, one of those two.  So the only random component of the query was the transaction ID.  That's what Dan realized, realized it was too small.  And so they started randomizing the source port of the DNS queries to get a 32-bit entropy for the query.



What these guys have figured out is a way to use ICMP as side channel feedback to derandomize the query port, that is, figure out the query port.  That collapses the guest space back to 16 bits, like it was in 2008.  And we now have, once again, practical DNS cache poisoning.  So in the depths of their paper they said:  "Historically, the very first widely publicized DNS cache poisoning attack was discovered by Kaminsky in 2008, who demonstrated that an off-path attacker can inject spoofed DNS responses and have them cached by DNS resolvers.  This has led to a number of DNS defenses being deployed widely, including source port randomization and other defenses such as DNSSEC.  Unfortunately, due to reasons such as incentives and compatibility, these defenses are still far from being widely deployed."  He didn't mean randomization.  Everybody does that.  He meant like DNSSEC.  Or they meant DNSSEC.



"To summarize, source port randomization becomes the most important hurdle to overcome in launching a successful DNS cache poisoning attack.  Indeed, in the past there have been prior attacks that attempt to derandomize the source port of DNS requests.  As of now, they are only considered nice conceptual attacks, but not very practical.  Specifically, one requires an attacker to bombard the source port and overload the socket receive buffer, which is not only slow and impractical, unlikely to succeed in time, but can also be achieved only in a local environment with stringent RTT [round trip time] requirements.  It is assumed that a resolver sits behind a NAT which allows its external source port to be derandomized, but such a scenario is not applicable to resolvers that own public IPs."



They said:  "In contrast, the vulnerabilities we find" - that is, that they have found and demonstrated - "are both much more serious and generally applicable to a wide range of scenarios and conditions.  Specifically, we're able to launch attacks against all layers of caches which are prevalent in the modern DNS infrastructure, including application-layer DNS caches, for example, in browsers; OS-wide caches; DNS forwarder caches, for example, in home routers; and the most widely targeted DNS resolver caches.



"The vulnerabilities also affect virtually all popular DNS software stacks, including BIND, Unbound, and dnsmasq, running on top of Linux and potentially other OSes, with the major requirement being the victim OS is allowed to generate outgoing ICMP error messages."  They said:  "Interestingly, these vulnerabilities result from either design flaws in UDP standards or subtle implementation details that lead to side channels based on a global rate limit of ICMP error messages, allowing derandomization of source port with great certainty."



They said:  "To demonstrate the impact, we devise attack methods targeting two main scenarios, including DNS forwarders running on home routers, and DNS resolvers running BIND and Unbound. With permission, we also tested the attack against a production DNS resolver that serves 70 million user queries per day, overcoming several practical challenges such as noise, having to wait for cache timeouts, multiple backend server IPs behind the resolver frontend, and multiple authoritative name servers.  In our stress test experiment we also evaluate the attack in even more challenging network conditions and report positive results.



"In this paper, we make the following contributions:  We systematically analyze the interaction between application and OS-level behaviors, leading to the discovery of general UDP source port derandomization strategies, the key one being a side channel vulnerability introduced by a global rate limit of outgoing ICMP error messages.  Two, we research the applicability of the source port derandomization strategies against a variety of attack models.  In addition, to allow sufficient time to conduct the derandomization attack, we develop novel methods to extend the attack window significantly, one of them again leveraging the rate limiting feature, this time in the application layer.  And, finally, three:  We conduct extensive evaluation against a wide variety of server software, configuration, and network conditions, and report positive results.  We show that in most settings, an attacker needs only minutes to succeed in an end-to-end poisoning attack.  We also discuss the most effective and simple mitigations."



Okay.  So the crux of what they have done is to arrange to eliminate the entropy creating query source port randomization.  As I said, if the DNS query source port can be determined, then the effectiveness of DNS spoofing and cache poisoning attacks return to their quite tractable pre-Kaminsky severity.  The reason ICMP comes into the picture is that an incoming UDP packet hitting a closed port will evoke an ICMP "port unreachable" error response, whereas the same packet hitting an open port won't.  Thus it's possible to probe a DNS server's ports by monitoring ICMP replies.  But it's not that easy, since all modern operating system IP stacks have evolved to deliberately rate limit ICMP error replies.



Old-timers among us will remember those good old days where it was possible to ping a server, an echo request ICMP, with a spoofed source IP.  And that server would dutifully reply with an ICMP echo reply to the apparent incoming source IP.  That's where the first DDoS attacks came from.  You would flood a whole bunch of machines out on the Internet with ping packets, ICMP ping packets having the IP of your target victim.  Those packets would bounce off of those servers, which would send ICMP echo replies all to the victim and flood their connection bandwidth.  Anyway, you can't do that anymore because there is per-IP rate limiting, and also whole server, in other words, global rate limiting on all now IP stacks.



Okay.  So how did these guys get around it?  This is what is just so clever.  They wrote:  "Even though a source port can be directly probed by any attacker IP, in this case for example as in unbound and dnsmasq," they said, "it is imperative to bypass the per-IP rate limit," they said, "present in Linux primarily, to achieve faster scan speed."  They said:  "We develop three different probing methods that can overcome the ICMP rate limit challenge."



They said:  "First, if the attacker owns multiple IP addresses, either multiple bot machines or a single machine with an IPv6 address, then it is trivial to bypass the per-IP limit.  IPv6 address allocation states that each LAN is given a /64 prefix, effectively allowing any network to use 2^64 public IP addresses.  We have tested this from a machine in a residential network that supports IPv6 and picked several IPs within the /64 to send and receive traffic successfully."  So that works.



Or:  "Two, an attacker who owns only a single IPv4 address, it is still possible to ask for multiple addresses using DHCP," which I didn't know.  They said:  "We verified that multiple private IPv4 addresses can be obtained on a home network.  In addition, we've tested this in an educational network, where a single physical machine is able to acquire multiple public IPv4 addresses through this method, as well."



And, finally:  "Three, if an attacker owns a single IPv4 address, and the above methods fail for some reason, for example, statically assigned IPs, then the last method is to leverage IP spoofing to bypass the per-IP rate limit and the global rate limit as a side channel to infer whether the spoofed probes have hit the correct source port or not, in other words, with or without ICMP responses."  And here's what they came up with.  And this is just what happens when a bunch of smart people are faced with a problem that nobody has had before; and, looking at what they know and the way the system works, they then engineer or invent, choose your term, a solution.



They wrote:  "As has been shown in the context of TCP recently, global rate limiting can introduce serious side channels.  Here we leverage the ICMP global rate limit to facilitate UDP port scans, which we describe next."  And it's a little creepy because this could generally be used for UDP port scanning on the Internet.  They said:  "In observing the maximum globally allowable burst of 50 ICMP packets in Linux, the attacker first sends 50 spoofed" - that is, we're talking about spoofed source IP - "50 spoofed UDP probe packets, each with a different source IP, thus bypassing the per-IP rate limit."  Right?  Because they're all going to be from a different IP.  "If the victim server does not have any source port open among the 50, then 50 ICMP port unreachable messages will be triggered," and they'll be sent out.



And they say:  "But they are not directly observable to the attacker since each of the 50 will be returned to one of the spoofed source IPs.  If the victim server does have open ports, then only" - it says five here, but it must be 49.  If it does have open ports, then "49 ICMP packets will be triggered, as the UDP probing packets will be silently discarded at the application layer."  He says:  "Now the attacker sends a verification packet using its real IP address, a UDP packet destined to a known closed port, such as 1.  It will either get no response, if the global rate limit has already been met and thus drained, or an ICMP reply otherwise."



Okay.  "Thus," they write, "even without receiving replies to the first 50 probes, the presence of an open port within a range of those 50 can be directly determined by inference.  If no port is found in the first batch, the attacker waits for at least 50 milliseconds for the rate limit counter to recuperate and reset, and then starts the next round," using the next sequential set of 50.



They said:  "Effectively, the scanning speed will be capped at about 1,000 per second.  It therefore takes a little more than 60 seconds to enumerate the entire port range of 65,536 ports."  Actually, it's 65,535, of course.  "Nevertheless," they said, "it is a winning battle as the attacker can simply repeat the experiment, and the probability that one experiment will succeed increases dramatically."



Okay.  So what these guys have done is to figure out a way to use modern ICMP rate limiting, essentially against the system that is rate limiting, as a side channel to probe a DNS server for its open port.  So what this does is it moves the DNS spoofability clock back 12 years to a point where DNS cache poisoning sent the industry into a frenzy.  Just incredibly cool research.



As I mentioned above, these days things are less panic-prone because the entire industry has switched over to HTTPS and to a certificate-based system to add authentication to privacy.  And of course in the process, you know, it's difficult to get a certificate for a domain.  You need to have a cert if you're going to spoof something that's on HTTPS.  But as I also noted, automated certificate services are already existing, and more are coming online.  So the practical vulnerability, while not hair on fire, is still there.  We haven't yet secured our domain name system, and it doesn't appear that's going to happen anytime soon.  So this is less urgent than it is supremely clever.  But I wanted to share it with everyone just for its cleverness.



They have a Q&A on their page.  They ask:  "Am I affected by the vulnerability?"  And answer:  "Likely, as long as you are using a vulnerable DNS service."  And then they suggest 8.8.8.8 and 1.1.1.1.



LEO:  Although I just checked Cloudflare, and 1.1.1.1 has been mitigated.  Cloudflare has jumped right on it, of course.



STEVE:  As we would expect them to.  Very cool.



LEO:  And they actually have an excellent blog post on this.



STEVE:  Oh, cool.



LEO:  And I also checked NextDNS, which is the DNS server I use, which I really love, and they also are mitigated.  So you should check with your provider.  And if it's Comcast, god bless.



STEVE:  Yeah, and there is a link on that page that allows you to make a quick check.



LEO:  Yeah, yeah.  Sorry.



STEVE:  So they said:  "How widespread?"  According to their measurements, "35% of open resolvers are vulnerable to the attack, 'open resolvers' meaning a resolver which will accept queries from the Internet."  They said:  "We also found 12 out of 14 public resolvers and four out of six routers made by well-known brands to be vulnerable."  In theory, any DNS server running the newer version of popular operating systems without blocking outgoing ICMPs, and they said only Windows blocks it by default, is also vulnerable.



So they asked:  "Has SAD DNS been patched?"  They said:  "Yes, we have worked with the Linux kernel security team and developed a patch that randomizes the ICMP global rate limit" - which is a clever solution - "to introduce noise into the side channel.  Please refer to Security Advisories for more recent updates."  In other words, if you can't count on it being 50, if Linux now changes its mind from 35 to 100, for example, then you've lost your side channel.  They've made the side channel much noisier.  You can't count on that 50 being a hard number.  Which makes it much more difficult to, well, arguably nearly impossible to perform that enumeration.



They said:  "Which versions of operating systems are affected?  Linux 3.18 through 5.10.  Windows Server 2019, which is version 1809, and newer."  They said:  "We did not test older versions.  macOS 10.15 and newer.  We did not test older versions.  FreeBSD 12.1.0 and newer.  We did not test older versions."  They said:  "The patch for Linux is integrated into 5.10 and backported to many stable versions.  However, we don't know how and when Windows, macOS, FreeBSD will patch this vulnerability."



LEO:  Now, this has to be running on the DNS server, not on your - it's not your system that would be patched.  It's the DNS server system; right?



STEVE:  Correct.  It's the DNS server which would no longer be issuing its queries.



LEO:  So it seems highly unlikely that many people are running Mac or even Windows DNS servers.  I'm sure they're almost all Linux.



STEVE:  Yes.  And this is more of an attack against public servers on the 'Net, which would then be fooling people who relied on those public servers, redirecting them to a bad guy's...  



LEO:  So they don't attack you.  They attack the server, hoping that it will then be spoofed when you go there, and you can get a bad guy site instead of Google.com.



STEVE:  Correct.  Anyway...



LEO:  It's really interesting, yeah.



STEVE:  Yes.



LEO:  And you would think, well, people must keep their Linux servers up to date.  But no, if you're running BIND, or unbound on a Linux server, you probably don't update very often at all.  That's why it's important to backport to stable...



STEVE:  Yeah, just leave it alone, you know.  If it's not broke.



LEO:  Yeah.  5.10 is very current.  So interesting, yeah.  As I said, great post at Cloudflare.  They say they have mitigated it.  And it says:  "As part of a coordinated disclosure effort, earlier this year the researchers contacted Cloudflare and other major DNS providers."



STEVE:  Good.



LEO:  So they have had plenty of time before this ACM conference to fix it.  But I bet you that a lot of the big ISPs like Comcast - I wonder.



STEVE:  Not Cox.  Cox is the one I tried last. 



LEO:  I don't think that test is completely definitive, though.



STEVE:  No, I think you're right.  I think all it's doing is doing a version check and saying, okay, this is a known vulnerable version of the underlying OS.



LEO:  Because they don't have time to do 50 pings from 50 IP addresses and all of that.



STEVE:  No.



LEO:  They're not actually attacking.  I would hope, anyway.  Very good.



STEVE:  This is the way we keep our Internet locked down is this kind of research by clever people writing papers and, again, responsibly disclosing, letting these things get fixed.



LEO:  Exactly.



STEVE:  And then they get to have the fun of saying, "Look what we figured out."



LEO:  Exactly.  Exactly.



STEVE:  Very cool.



LEO:  Yeah.  I'm glad you talked about this.



STEVE:  Now we have Happy DNS.



LEO:  Yes.  One hopes they're using Happy DNS from now on. 



STEVE:  Turn that frown into a smile.



LEO:  My friends, we've come to the end - I can't believe it, it goes so fast - of this particular episode of Security Now!.  You will find Steve Gibson and the show at his website, GRC.com.  Now, the first thing you should do when you get there is buy a copy of SpinRite, if you don't already have one.  That way you'll be in on the upgrade to 6.1 the minute it's available.  And as Steve mentioned, you could participate in the beta testing and the forums and all of that.  But you've got to be a licensed holder of a copy of SpinRite, so you want to get that now.  Free upgrade to 6.1 when that comes, for those who buy now.



You'll also find the show there, the 16Kb audio version for the bandwidth-impaired or those who don't really have very good hearing.  If you have a little bit better hearing, you might want the 64Kb version.  It sounds a lot better.  He also has perfect fidelity in the transcripts written by Elaine Farris, 100% perfect fidelity.  Those are great to have for two reasons.  One, you can read along as you listen, which really helps, at least for me.  I like to read the show notes as you're going through this.  The transcripts are even better.  But second, also, it is a great way to search.  Because they're searchable, and they're plaintext, it's a good way to find anything in any of the 793 episodes of Security Now!.  So take advantage of that, GRC.com, and all the other freebies that Steve has.  Read up on Vitamin D, by the way, a lot of evidence now that Vitamin D is very helpful in fighting COVID-19.  I just saw another study came out today.  So read up on Vitamin D.



Also our site has copies of the show, 64Kb audio and video at TWiT.tv/sn for Security Now!.  There's a YouTube channel devoted to Security Now!.  You can watch or listen there.  Best thing to do would be get a podcast application and subscribe.  That way you get it automatically, the minute it's available.  There are lots of those out there.  Steve, have a great week.



If you want to come back and watch us do this next time, we do it right after MacBreak Weekly.  This is a big long day, so we sometimes don't get to it till 1:30 or 2:00 p.m. Pacific.  That'd be around 5:00 p.m. Eastern time, 21:00 UTC.  Thank you, Steve.  We'll see you next week.  I can tell, he's giving me the salute.  He's ready to go.  We'll see you next time on Security Now!.



STEVE:  Bye, everybody.  I'm ready to read my Peter Hamilton.



LEO:  I thought you might be.



STEVE:  Woohoo.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#794

DATE:		November 24, 2020

TITLE:		Cicada

HOSTS:	Steve Gibson & Jason Howell

SOURCE:	https://media.grc.com/sn/sn-794.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we have a bunch of news on both the Chrome and Firefox fronts with patches, updates, and new features.  We have a comical bit of news from the ransomware front, and more troubling ongoing WordPress attack specifics, including a weird eCommerce site spoofing attack.  We look at the future consequences of ongoing vulnerability announcements coupled with their very incomplete patching, and Android's bold move right into the middle of the unbreakable end-to-end encryption controversy.  And then we'll conclude with a look at a large, multiyear (as in 11-year) advanced very-persistent threat state-based attack perpetrator known as "Cicada."



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  I'm Jason Howell, filling in for Leo this week.  Steve's going to cover the many patches and updates that are hitting Chrome and Firefox right now, a whole bunch of news on that front.  More attacks on WordPress.  RCS finally gets end-to-end encryption; I'm pretty excited about that.  And an 11-year threat called Cicada.  That, and so much more, next with Steve Gibson, breaking it all down for you next on Security Now!.



JASON HOWELL:  This is Security Now! with Steve Gibson, Episode 794, recorded Tuesday, November 24th, 2020:  Cicada.



It's time for Security Now!, the show where we talk about all the latest security news with none other than Steve Gibson.  I'm not Leo Laporte.  I'm Jason Howell, filling in for Leo.  But Steve, you are the man of the hour.  How are you doing today?



STEVE GIBSON:  Well, Jason, it's great to be with you once again.  You are an experienced Security Now! cohost, so we know how this goes.  You know how to do the show open and the close and so forth.  Forgot to ask you, do we have three sponsors today as usual?



JASON:  We do indeed.  We have three.  It's a jam-packed show.  Yes, "experienced" in the sense that I can sit here and be amazed at your incredible security knowledge throughout the course of the entire show, along with everybody that's watching and listening.  And then I throw in some ads from time to time.  That's my experience in the world of security.	



STEVE:  You're embarrassing me.  We have Episode 794 for, what is this, oh, this is the last Tuesday of November.  We're going to be in December next time.  This episode is titled "Cicada," C-I-C-A-D-A, after the insect.  Which is kind of appropriate.  It turns out that's the name that's been given to a very pernicious, very advanced, very persistent threat actor, which we're going to talk about because Symantec stumbled upon them a little over a year ago and has been watching what they've been doing.  And just it's a different sort of profile than where we've been spending a lot of time talking, for example, about overt public attacks, especially those made by ransomware groups, which live to be public.  We have a little bit of news about that, too.



But we've got a bunch of news on the browser front, both from Chrome and the Firefox projects - patches, updates, and features.  A little bit of comical news, strangely enough, from the ransomware front.  More troubling ongoing WordPress attack specifics.  WordPress has really been under, as our listeners know, under attack a lot recently.  We've got a weird ecommerce site spoofing attack.  Also I want to take a look at the future consequences of ongoing vulnerability announcements, coupled with their very incomplete patching, which is a theme that we've been seeing.



We've also got - and I was thinking of you, Jason, because this is about Android - Google's just-announced bold move right into the middle of the unbreakable end-to-end encryption controversy with an upcoming update to Android Messages, which is now in beta.  And I'm very impressed and pleased with the direction that Google has taken for implementing this.  And then, as I said, we'll wrap up with a look at this large multiyear, like 11-year at least, advanced, very persistent threat, state-based attack perpetrator.  And of course we always have a Picture of the Week.  This one is a little late because it has a Halloween theme.  But it was just too fun.  So I thought, well, we'll pick it up anyway.



JASON:  All right, Steve.  I love this Picture of the Week that you selected.  But tell us about it.  I think it's great.



STEVE:  So it just - it popped up on Twitter.  Thanks to one of my followers for posting it.  It's, as I said, sort of a Halloween theme.  It uses Venn diagrams to illuminate or illustrate various logical conjunctions.  We have the first one is Trick OR Treat, showing the OR of the two Venns.  And of course then we sort of have a carved pumpkin face there.  And then Trick AND Treat, showing just where the two circles overlap, and so we've squeezed the pumpkin face in there.  Then of course Trick XOR Treat, which is XOR of course being either of them, but not both, so that one is shown.  And then for all of those three - OR, AND, and XOR - the second line is the logical inverse, the "not" of that.  So NOR, NAND, and XNOR.



So anyway, just it wasn't specifically security related, but just a little fun thing for, as I said, a little late for Halloween, but still a nice picture for the podcast, a techie-oriented podcast.



JASON:  A little late for Halloween, but still I'm sure someone out there is willing, like up for the challenge of making this an actual reality and actually carving a pumpkin in this way.



STEVE:  And we're also, you know, we're on this side of Thanksgiving still, so it's all sort of that holiday thing.



JASON:  Totally.



STEVE:  You know, pumpkin pie of course is a big thing.



JASON:  Pumpkins are still appropriate.  It's cool.



STEVE:  Yeah, exactly.  So Chrome has moved to release 87.  In the process, it fixed 33 security vulnerabilities - 10 which were high severity, 11 medium, and two were rated low.  And to provide some sense for the nature of the high-severity flaws which were fixed, we had a use-after-free in payments, inappropriate implementation in filesystem, inappropriate implementation in cryptohome, a race condition in the ImageBurner, insufficient policy enforcement in networking.  And that's - we're going to come back to that in a second because that struck me as an odd - "insufficient policy enforcement" was the term they used for something that we just talked about two weeks ago.



Also insufficient data validation in WASM, that's the WebAssem component.  We had a use-after-free in PPAPI, a use-after-free in WebCodecs, a heap buffer overflow in the UI, a heap buffer overflow in clipboard management.  Also use-after-free in Web Codecs was awarded a $15,000 bounty, which was split between its two researchers who discovered it.  The other nine were all to-be-determined awards, which I thought was interesting.  So all of those were regarded as high severity.  And as we know, things like a heap buffer overflow in the UI, that's going to be exposed to the 'Net, potentially.  Clipboard, same thing.  Certainly WebCodecs are Internet-exposed.



So it's certainly - it's understandable that those 10 would be high severity.  Looking through the list of 33, though, it wasn't clear what was going on with this assignment of bounties.  And I don't know what the awarding logic is for those since most of the medium and low criticality vulnerabilities did have bounties set and awarded.  And they ranged also between 7,500 on the high end down to $500 on the low end.  So one thing is very clear, which is Google is not paying a fixed award amount for the bounties.  They apparently really do look at what went into it, maybe what having the vulnerability repaired means in terms of enhanced security, and they pay accordingly.



But what was interesting, I mentioned one of those 10, that so-called "insufficient policy enforcement in networking."  Well, that was referring to Samy Kamkar's CVE-2020-16022, which we talked about two weeks ago.  That was the NAT slipstreaming vulnerability.  And although I guess it can perhaps best be leveraged remotely with a browser - I'm sure it could best be leveraged with a browser, that's the obvious thing to do - it was never really the fault of any browser.  And it was enabled when it was discovered by all of the browsers.  So it wasn't Chrome's fault that they weren't already blocking SIP ports 5060 and 5061 from being targeted by browser code.  And I don't know that I would even call that a critical vulnerability.  I mean, yes, it was easily exploitable.  But it was, you know, okay, sort of a theoretical issue.



Anyway, what we got last Tuesday with update 87 is now outgoing connections to remote SIP ports 5060 and 5061 are now blocked.  And of course we can expect all other web browsers to be following suit before long.  And there were a bunch of other things fixed.  Google is keeping their details private, as they do, until the majority of users have updated their browsers.  Which it's interesting, too, because I had just fired up a machine.  I started Chrome, and I was still on 86 from the previous week.  I had to go into About Chrome and sort of wake it up.  And then it said, oh, hold on a second, and then it began, you know, I got a little spinning wheel, and I got updated to 87.  But it's interesting that even starting a new instance, it's not like I had a system running and Chrome had been sitting there for days.  It needed me to ask for it in order to get updated.



So anyway, so they're saying that they're not going to tell us anything more about what's going on until the majority of users are updated with the fix.  Which I think, you know, in practice actually means until no one really cares anymore and stops asking because those are no longer newsy.  And of course they're right.  We really don't care.  The details, I think, are useful for spotting sort of broader trends in what's going on and, as we often do hear, generating some conclusions about the nature of the problems that are being fixed and whether there's anything we can do moving forward to keep these things from continuing to happen.  And certainly they do teach us like how to avoid such vulnerabilities.  We've seen, for example, the generic problems with codecs being interpreters of a compression technology.  We're able to generalize the nature of these problems.



So I think that's where we are at this point in the industry.  Somehow, and we'll come back to this a little bit later when we talk about some Windows problems, we really do need to stop all of this nonsense and start getting serious about figuring out how to not make these mistakes in the first place because, even though Chrome is really good about quickly responding to problems and fixing them, we'll be talking, as I said, a little bit later about that that's really a rarity in the industry.



And I know Android is where you spend a lot of your time, Jason.  As we know, one third of Android devices are no longer, they're like pre-7.1.  They're not getting updated any longer.  And they're never going to be.  They'll eventually die is the way those problems get resolved.  In fact, it's very clear that's the only way that Windows 7 is going to stop being the second most popular desktop OS is that those Windows 7 machines will eventually just die.  And then anything that replaces them will be Windows 10.  Not that people wouldn't want to still have Windows 7, apparently; but you just won't be able to get it any longer.



So there were a handful of interesting new developer features for cookies and fonts added to Chrome with this release 87.  And they continued their sort of weird deprecation in Chrome of FTP.  Remember that when we went to Chrome 86, they only blocked FTP for 1% of Chrome's users.  Now, of course, 1% of by far the most popular web browser on the planet, that's a lot of people.  I guess they were just wanting to see, well, okay, let's see what happens if we turn off FTP, File Transfer Protocol, for 1% of our users.  Well, apparently the world didn't end.  Maybe no one even noticed.



So now, as of last week with 87, they're blocking half, just half, randomly chosen half of Chrome 87's users can't use FTP.  I don't remember the last time I tried.  And I think that's probably the case for virtually all of current web users.  So their plan is for the January release of 88 to finally kill off FTP completely.  There is a switch you can turn on, if you happened to be deprecated for FTP, and you need it for some reason.  But, boy, just go get a client.  Get an FTP client.  You should not be using your browser for FTP, and before you long you won't be able to.  So it's time.



They also, in 87, have some user-facing performance improvements.  87 now has what they call "page occlusion tracking" so that the browser can determine what's actually visible to the user and will throttle pages and tabs that are not currently visible.  And the other new feature that has finally landed for Chrome in Android is the so-called "back-forward cache" or "bfcache."  And I say to "finally land in Chrome" because both Firefox and Safari have had the equivalent of bfcache for years across both desktop and mobile platforms.  The technology is a local cache which is optimized for the use of the back and forward arrows.  When a page is initially loaded and set up, a lot of work goes into getting it ready, especially when there's a lot of JavaScript going on behind the scenes.  We know that there's a JIT (Just In Time) compilation of JavaScript, and pages are not JavaScript "light" typically anymore.  They are JavaScript "heavy."



Well, it turns out that Firefox and Safari have for years been very smart about holding a page's entire state, including its expensive-to-establish JavaScript state, such that when a user leaves a page, like by clicking on a link, if they should hit the back arrow to return to the page that they had previously left, that page can be instantly restored from a RAM-based history.  Maybe it's because Chrome has been doing so much plumbing work on page operation with WebAssem and with a V8 engine, they just didn't get around to working on caching the state when a user left.  Or maybe they just figured, well, we're going to be so quick to reestablish a state because we're so good that we're not going to take this approach.



Anyway, they've decided, no, we're going to use something called a "bfcache" in order basically to allow users to navigate backwards and forwards through a chain of pages and make that page-changing instantaneous.  So it is here in Chrome 87 for Android, and mainstream desktop versions of Chrome are expected to be receiving it in the future.  So I expect that Android users may notice a performance improvement.  We're saying "instantaneous."  I saw some reports that said a 20% improvement.  So, okay, it probably just takes some amount of time just to switch the page, just to get it on the screen and show it to the user.  Anyway, Safari and Firefox have been doing it for a while.  Chrome 87 now adds it for Android.



During last June's Apple Worldwide Developer Conference, Apple announced that all App Store app listings would soon be required to include an explicit privacy prompt label that lists all the data that apps collect from their users and what they're doing with it, how that data is being used to track users across apps.  Those Apple labels that were announced in June are scheduled to go live next month on December 8th.  And I bring this up because last Wednesday Google also announced that, starting on January 18th of next year, 2021, they would also be adding a new section  to the Chrome Web Store, where extension developers would be able to disclose what user data they are collecting and what they plan to do with that information.



After the 18th of January, a new Privacy Practices button will appear on each extension's Web Store listing.  And to get ready for the change, Google has already added a new section to their Web Store Developer Dashboard to enable extension developers to indicate what they're collecting and why.  So at this point, if we have any extension developers within earshot of the podcast, it would probably be a good thing, you've got, what, about a month and a half to go over, fill out that page for your web extensions so that when it appears on the user-facing side of the store January 18th, it'll be there.  I imagine in the future it'll be a requirement moving forward, and just nice to see that we're getting this improvement in explicit privacy disclosure.



So that's Google stuff and Chrome stuff.  Firefox 83 gets an HTTPS-Only Mode.  It is currently disabled by default, but this happened last week.  Security-conscious users using Firefox 83 or later will be able to go to, and here's where it is, in the URL about:preferences#privacy.  So about:preferences takes you to a page with a bunch of different goodies, and then the #privacy takes you to the privacy tab.  That's a long page.  So you then need to scroll all the way down to the bottom.



When you get there, there's something new:  HTTPS-Only Mode.  And Firefox describes it as:  "HTTPS, as we know, provides a secure encrypted connection between Firefox and the websites you visit," they write.  "Most websites support HTTPS.  And if HTTPS-Only Mode is enabled, then Firefox will upgrade all connections to HTTPS."  So there's three settings.  And actually I have a screenshot in the show notes, which is onscreen right now in the podcast, because that's what I immediately turned on, that is, "Enable HTTPS-Only Mode in all windows."  The middle setting is "Enable HTTPS-Only Mode in private windows only."  And then the default setting is "Don't enable HTTPS-Only Mode."



So while this is enabled, as it is for me, Firefox will attempt to connect to the HTTPS versions of websites when a non-explicit URL is provided.  And in fact I've talked about this many times.  It's like, it seemed quite a while ago browsers, for example, if you just put in GRC.com, browsers have for historical reasons tried, assumed that when the scheme HTTP whatever, S or not, was absent, to default to old school http://GRC.com.  That has seemed to be wrong for a long time.  That's like, we know, like the vast majority of sites have now switched to HTTPS.  So it seemed to me that specifying nothing ought to imply HTTPS.  And then maybe if that failed, then the browser should fall back to HTTP.



Anyway, what this change does is it finally changes that logic explicitly so that, if you don't specify, Firefox will go to https://.  And now, with HTTPS-Only Mode, it will always try HTTPS.  And if that fails, you will then be given a dialog explaining that we were unable to get to this in HTTPS.  You have manually enabled HTTPS-Only Mode, so you want to make an exception.  Which is like, this is exactly what we would like to have happen.  At this point, it seems to me they ought to just turn this on.  And, if you go to a site where there's a probably, you can't get there with HTTPS, then you should explicitly say, okay, fine, let me through HTTP.



I did, however, immediately worry that one possible huge problem with doing this might be that it would force all connections also to the localhost to be HTTPS.  This has been a concern for some time.  Interestingly, it should not be a concern.  It's sort of a moronic issue, that is, the idea of asking for a secure connection to your own machine.  Localhost, as a lot of our listeners I'm sure know, is the technical term for 127.0.0.1, which is a subnet defined as your own machine, that is, the machine you're running on.  It's the system's own local stack.  And if anyone has ever done a netstat on a Unix machine, you know that it is full of network servers on the local machine's IP stack.



It turns out that using IP and local sockets is one of the more elegant IPC (Inter-Process Communication), links available on any networked OS.  And it's gotten very popular on Windows, too.  And yes, Microsoft, it is possible for this IPC mechanism to be abused if something malicious were to somehow get into someone's machine.  But in no way does localhost in and of itself create any vulnerability.  Microsoft has, you know, Windows has never been a secure platform.  It's never been secure against local attack.



I run with a nifty on-the-fly spellchecker that watches everything I type.  If it were malicious, it could be functioning as a keystroke logger.  And anything else in the system could be, too, without any announcement.  That's the nature of Windows.  So if something evil gets into your machine, it's already game over.  So protecting the browser from something that's set up shop on localhost is crazy.  Yet despite that, Microsoft has been threatening for years to shut down its browser's local access to the localhost domain.  And every time they try, the world of actual users explodes because doing so breaks too many things.  Having localhost available is handy.  It's reliable.  And it's elegant.  Which is why it's being used quietly by so many systems.



And I'll also note that SQRL is among them.  SQRL clients run a little HTTP web server, and that's HTTP, not HTTPS, which listens on port 25519, for the browser's connection to the machine, which is a way that the authenticated URL is passed from the authenticating server to the SQRL client and then over to the browser to cut out any possible man-in-the-middle interception.  And it's a way that SQRL provides a high level of anti-hacking provision.  And localhost is just used widely.  So there's zero need for TLS on the local stack.  That makes no sense.  If the IP connection is an abstraction, you are connecting to the operating system.  And so there's no need for privacy, like encryption privacy, because nothing ever leaves the machine.  And there's no need for authentication because it's the OS.  It's the local systems.



Anyway, the good news is all of this, even though it hasn't really gotten through to Microsoft, this has already occurred to Mozilla and Google, and they're treating localhost as a presumed trusted exception to this HTTPS-Always rule.  So they're not going to break anything, and they really have no choice.  In addition to this cool HTTPS-Only Mode, this latest update also fixed 21 vulnerabilities in Firefox 83, including that bug that existed in, well, not in it anymore than it existed in Chrome.  But its use of the FreeType library that had been used in attacks - you remember the zero-day attacks against Chrome that also leveraged a problem in Windows.  We noted at the time that everything that used FreeType, which also allowed attacker-provided font glyphs, would be a potential target.  So web browsers were perhaps the biggest target of all since they fit all the requirements out of the box and were inherently exposing themselves.



That heap buffer overflow in FreeType is now also closed in Firefox as it was closed in Chromium and Chrome and presumably in all the Chromium derivative browsers, as well.  There was like a handful of other goodies that Firefox 83 brought to us.  Mozilla wrote that Firefox, they said, keeps getting faster as a result of significant updates to SpiderMonkey, which is the JavaScript engine.  They said we would experience improved page load performance by up to 15%, and page responsiveness by up to 12%, and reduced memory usage by up to 8%.  They said:  "We have replaced part of the JavaScript engine that helps to compile and display websites, improving security and maintainability of the engine at the same time."



They also said that pinch zooming will now be supported for Firefox users of Windows touchscreen devices and touchpads on Mac devices.  They said Firefox users may now use pinch to zoom on touch-capable devices.  Picture-in-Picture now supports keyboard shortcuts.  Let's see, what else.  Oh, and they said for the recently released Apple devices built with Apple Silicon CPUs, they said we can use Firefox 83 and future releases without any change.  They said this release, 83, will support emulation under Apple's Rosetta 2 that ships with macOS Big Sur.  And they said:  "We're working toward Firefox being natively compiled for these CPUs in a future release."  So that sounds like a good thing.  And they just concluded saying it's a major release of WebRender as they roll out Firefox also to users on Windows 7 and 8, as well as macOS 10.12 and 10.15.



JASON:  And we have just a little bit more in the realm of Firefox right now; right?  Big Firefox news week.



STEVE:  Yeah, I appreciated ZDNet's headline.  They said:  "Fearing drama, Mozilla opens public consultation before worldwide Firefox DoH rollout."  Of course, as we know, Mozilla wants to enable DNS over HTTPS, so-called DoH, in Firefox for all their users worldwide.  Although maybe the U.K. will remain an exception.  We'll have to see how that goes.  But once burned, twice shy.  Mozilla wants to creep forward a bit more cautiously this time, soliciting input from ISPs, governments, and companies before they flip that switch.



Last Thursday they initiated a period for public comment and consultation about the ways they could safely enable support for what was previously their controversial rollout of DNS-over-HTTPS.  My reference to "once burned" was to the backlash of criticism they encountered, and our listeners will recall last year, mostly in the U.K. over their stated plan to support DoH inside Firefox.  As we'll recall, U.K. government officials, law enforcement agencies, and even local Internet service providers, actually the service provider organization, criticized Mozilla using some quite over-the-top language, including declaring them the "Internet Villain of the Year," just because Mozilla wanted to protect their users from DNS games being played by those ISPs.  Those opposed to this claimed that it would help bad guys bypass enterprise firewalls and parental control blacklists.  You know, yes, villainy.



At the time, Mozilla chose to back off of their timeline as a result of all of this pushback, and agreed to delay deploying DoH inside the U.K.  But they did deploy it, as we've talked about since, for all Firefox users in the U.S.  And it's been under use at scale since earlier this year, like since February.  And Mozilla has always planned to roll out DOH to all of its users across the world, although they may still hold off in the U.K. because they have promised not to deploy it there after their first attempt.  So now the current consultation period exists as a way to give what they're calling stakeholders, you know, governments and ISPs, an opportunity to speak up or forever hold their peace.



This consultation period runs from last Thursday through January 4th of 2021.  So several months now to allow them, anybody who's opposed, to say, okay, look, this is what we want you to do.  Mozilla has promised to consider every reasonable and practical suggestion, whatever it might be.  But Mozilla has already addressed most of the DoH criticism that they received.  They have added a so-called "canary" domain that can be queried on managed networks to force Firefox to disable DoH support and defer to local enterprise policies for DNS management.  So that problem has been solved.



A lot of enterprise users were upset because they did not want the Firefox instances within their network to be setting up an encrypted tunnel that they didn't have any oversight over.  So now there is a mechanism, well established, for Firefox to back off of that in enterprise environments.  And also they've added support for more providers than just Cloudflare.  Again, at the first announcement there was this concern over the development of a monoculture, that everybody, all Mozilla users would be using Cloudflare as the sole provider.  Now you've got multiple choices.  And so Apple, Google, and Microsoft have also announced plans to support DoH protocol.  And having watched Mozilla stumble last year, they've all deployed enterprise-friendly DoH implementations from the start.  And of course Google's DoH support in Chrome has already gone live.



So anyway, it's like this kind of change upsets people.  It gives users more privacy and security at the cost of some other entities that may have been enjoying the ability to monitor DNS queries and see what users were doing.  That's not going to work in the long term.  And ISPs have also, as we expected, deployed their own DoH servers so they can say hey, you know, you're able to use DoH if you want to, and still stick with your own ISP.  So that's been a good thing.



I had an interesting little bit of ransomware news.  Aside from just noting that devastating ransomware attacks continue, I wanted to share the news of a new tactic being employed by the Egregor ransomware, which now announces its dastardly deeds and presence within an enterprise's network.  The ransomware gangs know that many businesses will attempt to cover up a ransomware attack to keep it from being public.  The enterprises will just claim like a generic network outage.  And oftentimes we're left guessing.  You know, the news reporting media is like, well, was that a ransomware attack, or did somebody trip over a cord?  What happened?  And in sufficiently large organizations, the cover-up of what actually happened typically is extended to include their own employees for fear of a news leak tanking their stock price and incurring their reputation damage.



So now, in a move clearly designed to increase the pressure and increase the likelihood of just exactly that kind of public leak, after an attack, the Egregor operation locates all of the available hard copy printing devices within a network and uses them to repeatedly print the announcement of their successful attack and ransom demands, for any employee to see on a printer.  They're announcing that this enterprise and its network has been taken over by ransomware, and here's the demand letter, and please send your bitcoin payment to the following address.  So, yeah.  That's happening now, too.  And if it ends up being an effective tactic, you can imagine that the other ransomware gangs will adopt it before long.



The Wordfence WordPress web application firewall company posted news of the latest in their ongoing and escalating attack on WordPress sites.  Their posting was titled "Large-Scale Attacks Target Epsilon Framework Themes."  They wrote:  "On November 17, 2020, our Threat Intelligence team noticed a large-scale wave of attacks against recently reported Function Injection vulnerabilities in themes" - that is, WordPress themes - "using the Epsilon Framework."  They said they estimate there are over 150,000 sites using this framework.



They said:  "So far today, we have seen a surge of more than 7.5 million attacks against more than 1.5 million sites targeting these vulnerabilities, coming from over 18,000 IP addresses."  They said:  "While we occasionally see attacks targeting a large number of sites, most of them target older vulnerabilities.  This wave of attacks is targeting vulnerabilities that have only been patched in the last few months."



In their announcement they then proceed to list the 15 WordPress Epsilon Framework themes that are known vulnerable to these attacks.  And at this point the attacks appear to only be probing, looking for vulnerable WordPress instances.  Presumably what's happening is they are accruing a master list of vulnerable targets.  And this makes sense since the use of 18,000 source IPs sounds, well, it must be a botnet being used as the scanning phase of a future targeted attack.  The Wordfence folks noted that both the probing attacks and the later exploitation use POST queries, you know, HTTP POST queries to admin-ajax.php; and, as a consequence, do not leave distinct log entries.



They've also confirmed that an exploit chain does exist to permit full remote code execution enabling a full-site takeover.  So obviously someone else is aware of this, as well:  7.5 million attacks against 1.5 million sites targeting the known install base of 150,000 sites where these vulnerable themes are being used.  So, boy, I mean, again, just another big problem for WordPress.  They have confirmed that a full exploit chain exists.  So this is going to end up in site takeovers as soon as they switch from aggregating their targets and probing to attack.



Jayant Shukla, who's the CTO and cofounder of K2 Cyber Security, told Threatpost in an email, he said:  "WordPress" - and we know this - "powers as much as a third of all websites on the Internet, including some of the most highly trafficked sites and a large percentage of ecommerce sites," which we're going to get to in a second, in the next story here.  He said:  "So WordPress security should be of top concern to organizations.  This latest attack on a recently patched injection vulnerability on WordPress sites which use the Epsilon Framework themes, is looking for sites that have neglected to install the latest updates."  And that's of course not surprising.



"As we know from past research," he said, "as many as 60% of successful attacks are on vulnerabilities that already have a patch to prevent its exploit.  Organizations," he said, "need to take the security of their WordPress sites more seriously, starting with keeping the plugins and software up-to-date and patched."  So, yeah, no surprise there.  No one listening to this podcast doubts that for a moment.  But we also know, apparently, how much easier that is said than done.



Okay.  So get this next issue.  A new cybercrime gang has been found to be taking over vulnerable WordPress sites to install hidden ecommerce stores with the purpose of hijacking the original site's search engine rank and reputation, and promoting online scams.  The attacks were discovered earlier this month when a WordPress honeypot that had been set up was targeted.  The honeypot was managed by Larry Cashdollar, a security researcher for the Akamai security team.  And we've looked at some of Larry's work before.  The attackers initially leveraged brute-force attacks to gain access to the site's admin account, after which they overwrote the WordPress site's main index file appending their own malicious code to the end of that index.



Although the malicious code was heavily obfuscated, Larry indicated that the malware's primary function was to act as a proxy to redirect all incoming traffic to a remote command-and-control server under the attacker's control.  This server hosted the actual attack logic.  The way the attack worked, a user would visit a hacked WordPress site.  The hacked code on the WordPress site would then redirect the user's request to the malicious command-and-control server.  If a user met certain criteria, and it was unclear what that criteria would be, but I have a hunch, the command-and-control server would instruct the original WordPress site to reply to the user with an HTML file containing an online store, which was pedaling a wide variety of mundane objects.



Presumably, this criteria would be designed to avoid detection by the site's actual admin and owner.  You know, if you went to your own site and saw some weird ecommerce store instead of what you expected, that's not what you would, you know, you would obviously immediately know you had been taken over, compromised, and you'd go about fixing that.  So the point is that some subset of visitors, instead of getting the site they expected, would get an ecommerce site with what were described as "mundane objects" for sale.  And presumably, if you actually ordered something, that must be the nature of this scam.  It's not like you're going to get your order fulfilled; right?  They would take your money and say thank you very much, and you would never get your KN95 masks or whatever was on sale.



Larry, the Akamai researcher, indicated that - get this.  During the time the hackers had access to his honeypot, which he set up, they hosted more than 7,000 ecommerce stores.  So what must be going on is that, based upon where you're coming from, like where you're located geographically based upon your IP address, they on-the-fly select the store for you to be displayed at this hacked WordPress presence.  7,000 ecommerce stores that they intended to serve to incoming visitors.  Which suggests that, as weird as this seems, it's no small operation.  It would take some effort to set up 7,000 different ecommerce presences.  And clearly it's intended to be a long-lived scam across a large base of WordPress sites.



Now, if all of this seems odd, like okay, this just seems bizarre, here's what's going on.  In addition, the hackers generated XML sitemaps for the hacked WordPress sites that contained entries for the fake online stores mixed in with the site's authentic pages.  And the attackers, after generating the sitemaps, submitted them to Google's search engine, then deleted the sitemap to avoid its detection.  So although this whole procedure seems harmless, it's clear that what they were going for in hacking WordPress sites with good search engine rankings was they were trying to leverage the ranking of the site in order to get this collection of bogus ecommerce sites visited.



And of course the problem is that by doing this to the site, they dramatically reduced the site's search engine ranking over time because, you know, basically it became a scammy spammy site that Google was not going to rank highly in the long term.  So this just seems weird and bizarre.  But it's what's going on because WordPress has pretty much gotten out of control from a security standpoint.



Okay.  So we have to talk about the fact that Windows and arguably some other high-profile services on the 'Net are just not being patched over the long term.  Here we are today, more than a year downstream of the BlueKeep RDP bug.  Remember the BlueKeep was described as a "preauthorization attack," meaning you didn't need authorization in order to attack an instance of remote desktop protocol.  Today, more than 245,000 Windows systems are still vulnerable to BlueKeep's complete authorization bypass on remote desktop protocol - 245,000 instances.  It's clearly the case that overall the biggest scandal on the security side of the IT industry today has to be the lack of timely or ever patching of highly public widespread remotely accessible vulnerabilities in our computer networks.



We will wrap up today's podcast by looking at some details of a group known by many names, one of which is APT10, which is, you know, they're a well-known Advanced Persistent Threat group.  Those details are interesting and sobering.  But the question of how such threat actors gain access to their victims is hardly a question in a world where, after more than a year, nearly a quarter million servers remain vulnerable to a now well-known, easily exploited problem. 



I looked at a chart of BlueKeep, and I had to do a double-take.  It's onscreen right now, on the video podcast.  This chart is a timeline of exactly one year, from November 15th of 2019 to November 15th of 2020, basically last week.  During that time, the number of open port 3389 dropped from 9% to just 6%.  Okay, now, in fairness, this was COVID-19 year; right?  So the work from home response to the novel coronavirus did put a sudden upward pressure on the whole terrain of remote access.



And we can clearly see its effect in the chart's rise through March and April.  That is, the incidence of open Port 3389 was dropping.  Then it kind of leveled off.  Then it went back up in March and April, and then it's been sort of declining, although it hit another little bump in August.  But still, we're talking about we're now at just shy of 6% of all IPs, 4.3 billion IPs; 6% of the Internet's IPs have 3389 open on them, which is just stunning to me.  We're now at 25% of the original 950,000 Windows machines that were initially discovered to be vulnerable to BlueKeep during that first scan in May of 2019.  So we were just shy of a million then.  Today we are just shy of a quarter million, nearly a year and a half later.



Okay.  Which, again, this is a problem for the security industry.  Today, in addition, separately, more than 103,000 Windows systems also remain vulnerable to the SMB Ghost vulnerability.  That's the, remember, Server Message Block v3 protocol problem that was discovered and patched back in March of this year.  Yet here we are in November, and 103,000 Windows machines still have SMB exposed, and they're still vulnerable to this exploit.  Either of these vulnerabilities allow attackers to take over Windows systems remotely and are considered some of the most severe bugs discovered and having been patched in Windows over the last few years.



But despite their severity, an incredible number of Windows systems have remained unpatched and are thus vulnerable to remote takeover.  So is it any wonder that I finally had to stop, like, enumerating each week's ransomware attacks, for fear of boring our listeners?  I mean, it's like, okay, yeah, fine.  Here's who's been attacked in the last week.  It's just it's crazy how many systems are vulnerable.



And in fairness, it's not just Windows.  A Czech researcher just compiled a list of outstanding vulnerabilities when they were discovered and fixed, what they were in, how many systems are unpatched against it, and the CVSS vulnerability score.  I've got the table in the show notes.  For example, Apache web server has a CVE back from 2019, it's 0211.  At the moment 3.357 million Apache web servers remain unpatched.  It's not super critical.  It's got a CVSS of 7.8.  But still, Apache web server.  Update Apache web server.  But no.



Squid, also a CVE from 2019, 1.2 million unpatched systems.  That one's 9.8 severity.  Microsoft IIS, 374,000.  That's got a CVSS of 10 out of 10.  Also, okay, get this one.  This has a CVE from 2015, 2015-1635, affecting Microsoft IIS.  Again, 374,000 with a severity of 10.  We know the Exim, the mail server, has been having problems.  Two of them, both from 2019, in one case 268,000, another one 264,000, both with CVSSes of 9.8.  We talked about that one previously.  Of course BlueKeep, we were just talking about the Windows RDP problem, 246,000.  That's got a CVSS of 9.8.



Heartbleed.  Remember Heartbleed?  That was 2014.  Guess how many OpenSSL instances are still online, susceptible to Heartbleed?  More than 200,000 - 204,878.  Now, yes, not readily exploitable.  We know it's very difficult to exploit.  You can, if you succeed, you can potentially obtain useful private keys.  So it's got a CVSS of only 7.5.  But still, it's six years ago, and 200,000 OpenSSL instances are still there with that.  SMB Ghost we were just talking about, the Windows SMB problem, 103,000, CVSS 10.  Top of the charts, 10.  WordPress, there's a problem from last year, nearly 84,000 instances out there with a CVSS of 8.8.  ProFTPD, 80,000, with a severity of 9.8.  And one other Exim from two years ago, from 2018, 76,000, more than 76,000 instances with a CVSS of 9.8.  



So the point is this is serious.  This is really a problem.  And it's possible to say, okay, yeah, that's not good.  But that's other people's machines and other people's networks.  But it's important to remain cognizant of the fact that there is a potential for cross-network contagion.  We've seen this earlier in the managed service providers where, for example, an MSP gets themselves infected, and the bad guys realize that they've hit the mother lode because now they have access to all the MSP clients' networks.



Remember when all of those dental services were getting hit with ransomware because they were all, all of these dental services had outsourced some aspect, and I think it was their health records management, to some managed service provider that was providing that as an outsourced service.  And suddenly all of those dentist offices got zapped because a common single managed service provider got themselves compromised.  We are becoming more deeply interconnected, and the trend is clearly one of increasing our outsourcing of various ancillary and non-mainline business functions such as order fulfillment, payroll management, and an increasing number of network and cloud-based infrastructure functions.



So I would argue that the upshot is that, while the networks under our own control may be battened down and secure, we're increasingly needing to implicitly trust that the growing number of external entities we're connected to are also similarly taking their own security seriously.  Now, when queried, they'll all profess to be totally safe and secure.  Who wouldn't?  But that means that most, if not every one of those companies represented in that table above would proclaim exactly the same thing, despite the fact that they're sitting there with systems that haven't been patched for years.



And Microsoft vividly demonstrates for us every single month that things are not getting any better.  It's not as if the critical buggy code problem has been solved.  So Microsoft, just Microsoft is leaving a lengthening trail of critical vulnerabilities in their wake.  These things are not getting fixed, yet more and more of them are being revealed every month.  Some percentage of each of them endures over time, creating this long tail, potentially a never-ending tail of trouble.  All the evidence shows that it's not until those machines eventually die that these problems are going to get patched.  That table above just proves it.  So maybe our listeners are right:  Three digits is not enough for this podcast.



JASON:  Now, before we get to the main event, this last story, I'm excited to see this news.  I was wondering if it was going to happen because I remember when Google initially launched RCS, it seemed like end-to-end encryption might not actually happen, like, oh, this is not part of this.  But the news sounds like is sounding positive for that.  



STEVE:  Yeah.  And the way they did it is just exactly right.  The listeners of this podcast know that end-to-end encryption is politically charged and a super hot topic.  The question is, how do we resolve this fundamental tension between individuals' desire and right to privacy, and law enforcement's, depending upon what country you're in.  In the U.S. we have a Constitution that protects us from unwarranted search and seizure.  But if you get a court order from a judge, then law enforcement has a warrant in order to search, the argument being that that's for the general public betterment.



Anyway, the problem, of course, happens when you have encryption that cannot be cracked.  So as we know, exactly as you were saying, Jason, traditionally Google has been using SMS.  And back in '07, so, what, 13 years ago, the replacement for it was technically designed, finished, and ratified - and we talked about it way back then - known as RCS, Rich Communication Services.  It's an open industry standard.



I thought it would be good to give it sort of a setting.  So I snipped the first paragraph from Wikipedia.  Wikipedia says:  "Rich Communication Services is a communications protocol between mobile telephone carriers and between phone and carrier, aiming at replacing SMS messages with a text message system that is richer, provides phone book polling for service discovery, and can transmit in-call multimedia.  It is part of a broader IP multimedia subsystem."  They said:  "It's also marketed as Advanced Messaging, Chat, joyn" - spelled J-O-Y-N - "SMSoIP, Message+, and SMS+."  They said:  "In early 2020 it was estimated that RCS is available from 88 operators throughout 59 countries in the world.  There are approximately 390 million users per month, and the business is expected to be worth $71 billion by next year, 2021."



So anyway, despite its specification and ratification way back in '07, the adoption of RCS has been somewhat lackluster.  But, you know, it does offer a number of new and useful features.  You can get typing indicators, meaning you know when someone at the other end is typing.  You know, iMessage has that, and that's sometimes interesting.  Presence information, location sharing, longer messages, and better media support.  So you get better quality photos and videos, chat over WiFi, knowing when a message has been read, sharing reactions, and better capabilities for group chats.  So it's like, you know, it's a set of capabilities whose time has certainly come.



And what's most significant, I think, from a political standpoint, is that this isn't all by virtue of some add-on.  It will be in the base Android OS.  And that's significant.  Last Thursday, Google said that they've completed their worldwide rollout of RCS and are moving into a new phase.  And here it comes:  adding native end-to-end encryption.  So Android's native messaging platform would potentially be able to offer the privacy and authentication features that we're all familiar with, from like Threema and Signal and WhatsApp and so on.  At the moment, end-to-end encryption in Android Messages, which is the Android app, is only available to those using the beta version of the app.  And of course it requires a beta version user to be at each end.  Their rollout is expected to continue into next year.



And the best news of all is that Google wisely chose not to roll their own solution.  At this point, end-to-end encryption has been added to the solved problems list, thus there is no need to do it again.  Google has adopted the very well-designed and already well time-tested Signal protocol.  So that just could not be cooler.  This means that Signal goes mainstream in Android moving forward.  And this is a big deal, and a big day, I would argue, for end-to-end encryption.  Essentially it means we have Signal for RCS built into Android's native Messages app.



Google said:  "Eligible conversations will automatically upgrade to be end-to-end encrypted."  Which means, as this happens, as existing devices update to having the latest Android Messages app, and certainly for all new Android devices moving forward, you just get automatic end-to-end encryption.  And given Android's spread and reach, they're currently three quarters of the entire mobile OS platform globally, with iOS being the other one quarter, and a few other also-ran OS platforms.  And given that no third-party app will be needed for automatic unbreakable encryption to be provided to its users in the future, there's no way to see this other than a big poke in the eye to law enforcement and intelligence services worldwide.  I have a feeling that we haven't heard the end of this intriguing encryption debate.  The ante has just been upped.



So I just think it's very cool.  Not only that Messages now is fully onboard with RCS, but the idea that it just bundles Signal in.  Boy, I mean, law enforcement and governments keep grumbling about end-to-end encryption.  It is a problem without a solution.  There is no way we know for there to be some sort of weakening that allows for selective encryption without breaking the value of encryption.  So I don't know how we're going to solve this problem.  I just - I don't think we do.  I think you get access to the data before it goes into the encrypted tunnel or after it comes out at the other end.  But you just have to give up on decrypting it in any way in transit.  And of course there's also the "data at rest" encryption problem of these devices really being resistant to anyone decrypting them without the unlocking key.  So yay for Google.  We'll see what this creates.



Okay.  So Cicada.  It was the group's use of the Zerologon vulnerability that first brought them to my attention.  But the more I dug into the background of their existence, the more interesting they became.  They are Chinese, state-sponsored and sanctioned, and a highly capable advanced persistent threat - we know that's APT - group known by several names:  Cicada, APT10, Stone Panda, and Cloud Hopper.  They've been involved in cyberespionage operations since at least 2009.  Their cyber intrusions are generally aimed at large international Japanese companies with attack presence, having been spotted in 17 geographical regions and across multiple business sectors.



And it's not just Japanese companies because affiliates or subcontractors which may well not be Japanese, but are connected to Japanese parents, are also targets.  They're an advanced persistent threat because they burrow into a large company's network and remain in place performing long-term intelligence gathering.  The business sectors they focus upon seem to primarily be automotive, pharmaceutical, and engineering sectors, as well as managed service providers.  The group uses what has become known as "living off the land" tools, meaning using what's available on a network.  And they do have custom malware which has been observed in their attack campaigns, including a custom malware that Symantec has named "Backdoor.Hartip," H-A-R-T-I-P.  They have not seen it being used by the group previously, but now they're seeing it everywhere, so it's a recent addition to their arsenal.



Among the machines compromised during the attack campaign were domain controllers and file servers, and there was evidence of files being exfiltrated from some of the compromised machines.  The attackers extensively use a newer technique known as "DLL side-loading" in the campaigns that Symantec has observed.  And they were also seen leveraging the Zerologon vulnerability that was patched in August of 2020.  So as we know, a few months ago it's been patched.  But lots of corporations haven't updated their internal machines.  Zerologon is beautifully suited for moving laterally within an organization, and we recently did a deep dive into one of the ransomware attacks which exactly and specifically use Zerologon for that purpose.



This DLL side-loading takes advantage of the Windows so-called "side-by-side" or WinSxS system to trick Windows into loading a malicious DLL for an application when that application is run.  DLL side-loading is becoming an increasingly popular means for sneaking malicious code inside of Windows operating processes, getting it into RAM.  And it's very effective in avoiding antiviral systems.



So it should be no surprise that the present campaign was first discovered when Symantec observed suspicious DLL side-loading activity on one of their customers' networks.  That triggered an alert in Symantec's Cloud Analytics technology which is part of their endpoint security, the Symantec Endpoint Security Offering.  The activity was brought to the attention of their analysts to verify that it wasn't a false positive.  Then it was passed up to their investigations team for further analysis.



Since Symantec's instrumentation is widely spread throughout the large customer base, once the so-called IOC (Indication of Compromise) was identified, they were then able to apply that across their entire coverage space to identify other previously unknown victim networks and enterprises and begin through the visibility that they had to get some sense for just how pernicious and widespread this thing was.  Also, once something like this is discovered, it's possible to scroll back through prior activity logs to reexamine previous behavior that wasn't appreciated for what it was at the time, and to carefully examine the timestamps on files that they now know to look for, which were not previously suspect.  This allows them to determine how far back an intrusion took place.



Although the Cicada group is known to have existed since 2009, in this case this campaign has been ongoing since at least mid-October of 2019 and up through the beginning of last month, October of 2020.  The attacking group has been active on the networks of some of its victims for a full year.  The campaign is very wide-ranging, with victims in a large number of regions worldwide.  They have found compromised corporate networks in the U.S., U.K., France, Belgium, Germany, the UAE, India, China, Hong Kong, Singapore, Vietnam, the Philippines, Taiwan, South Korea, and Japan.



So this one group is widespread.  And although it's unusual to see a Chinese government-linked group attacking companies within their own borders, that is, you noted that China was among those that I cited, many of the companies have Chinese subsidiaries of a larger Japanese organization.  So that explains why they got swept up in this.  It's because, yup, they're dealing with a Japanese organization.  And it may be a way of getting into the larger organization.  Here again, I was talking about having to trust all the companies that you are connected to.



Anyway, Symantec's research discovered similar DLL side-loading malware on every victim network.  And as I noted, the attacks employed a wide variety of the so-called "living off the land" dual-use and publicly available tools and techniques.  They use RAR for archiving.  Files are transferred to staging servers and RARed before exfiltration.  They are often encrypted and compressed, making them easier to extract and not set off any IDS systems, Intrusion Detection Systems.



A certutil is a command line utility in Windows that can be exploited and used for various malicious purposes such as to decode information, to download files, and to install browser root certs.  So again, living off the land, using things that are already present for malicious purposes.  And then there's ADfind, which is the command-line tool that can be used to perform Active Directory queries.  Csvde can be used to extra Active Directory files and data.



Ntdsutil can be used as a credential-dumping tool.  And WMIExec is used for lateral movement within a network and to execute commands remotely on other systems.  And of course we have PowerShell, bringing power not only to admins, but also to attackers.  And they upload their ill-gotten goods to legitimate Internet cloud file hosting services for exfiltration.  This, of course, makes sense, since such services are likely not to be blocked, and they're accessible for local use.



Observing the activity patterns, the amount of time attackers spent on specific networks varied widely, with the attacker spending a significant amount of time, in some cases being active for months on some networks of some victims, sometimes just a few days on other victim networks.  And in some cases the attackers would spend some time on a network, probably looking around to see what they've got, then would go away, having their attention directed elsewhere, only to resume activity on one of those networks at a later time.



So it's just, if we step back for a moment to switch our perspective away from ransomware to the nature of this or think about it, it's a bit astonishing and sobering.  Here we have a Chinese state-sponsored entity, a group, who have - and we didn't get from Symantec a sense of number, how many organizations this is.  But it's extensive.  They have infiltrated these networks.  They've established a long-term ongoing persistence in their networks.  They are able to connect anytime they want, move around hidden, unseen for years, exfiltrating what they're interested in.



It just seems to me, it's clear to us, that this one operation is not the only such thing that is going on.  We know with absolute certainty, thanks to WikiLeaks and Edward Snowden, that U.S.-based and thus inherently state-sponsored intelligence services in the U.S. have developed and are developing powerful tools for doing much the same thing.  We tend to focus upon the big, splashy, oh-my-god ransomware attacks which make headlines.  We were just talking about how now they're taking out ads on Facebook, in one case exposing Matthew McConaughey's private contracts, and now spitting out ransom demands on all of a company's printers.  But there's another very different, entirely covert, and I would argue far more insidious reality that goes largely unremarked because it doesn't want to be found, ever.  It wants to burrow into many enterprise networks, spread far and wide, establish covert observation posts from which they're able to sneak around, jump between networks.  If that company is connected to somebody else, whoops, well, that's how they get into somebody else's network - steal and exfiltrate highly sensitive corporate secrets.



And you know, if you're a nation-state like China, you couldn't care less about a ransom payment.  What you want is the detailed production flow for a highly effective COVID-19 vaccine.  And this is the way those sorts of secrets escape.  And we have heard our own domestic health vaccine researchers saying that China and Russia have vaccines that bear the signatures of U.S. work.  So this is not just fiction and fantasy.  This is really going on.  It's the world that we're in today, and it is quite sobering.



JASON:  Well, this year, especially, has been quite sobering, in combination with all of this, all of the myriad different directions that this stuff is going.  And this is just one aspect of that.



STEVE:  Yup.  So you have the big flashy ransomware attack, and then the flipside is APTs, Advanced Persistent Threats.  These things burrow in, they set up shop, and they stay as long as they can.  Wow.



JASON:  They get comfortable.  They take off their shoes for a while.  They make themselves at home.



STEVE:  They're cicadas, yeah.



JASON:  Exactly.  That's how they roll in 2020.  Steve, thank you so much.  Awesome stuff, as always.  Definitely want to remind people to go to GRC.com, where you can find everything you need to know about what Steve is working on, what he's writing about, podcasting about.  Everything is there.  SpinRite, of course, is there, Steve's hard drive recovery and maintenance tool.  You can actually get your copy there, also information about SQRL, of course.  You can find audio and video of this show.  Transcripts, that's the only place that you can find transcripts of Security Now! is at GRC.com.  So make sure and go there and check it out.



If you want to find this show on our site, you can do that, as well:  TWiT.tv/sn for Security Now!.  You go there, you'll find all the ways that you can subscribe to this show, audio and video formats, a link out to YouTube if that's where you like to watch the show.  Everything is there that you need to know, including the information about when we record.  We record live every Tuesday, starting at around 1:30 p.m. Pacific, 4:30 p.m. Eastern, 21:30 UTC.  And so you can go to TWiT.tv/live, actually, if you want to be part of the live show and see it recorded in real-time.  But we appreciate it when you subscribe.  That's the most important thing.  Subscribe, and you won't miss a single episode with Steve, and also with Leo when he's back next week.



Steve, thank you so much for another episode of Security Now!.  Always appreciated.  And thanks for inviting me to be here alongside you today.



STEVE:  Thanks for holding the fort down, Jason.  It was a pleasure working with you.  And till next time.



JASON:  All right, until next time.  We'll see you then on Security Now!.



STEVE:  Bye.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#795

DATE:		December 1, 2020

TITLE:		DNS Consolidation

HOSTS:	Steve Gibson & Jason Howell

SOURCE:	https://media.grc.com/sn/sn-795.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a couple of new and forthcoming Chrome features.  I'll quickly run though some new and notable ransomware casualties, including a couple of follow-ups.  We'll look at a critical flaw in the Drupal content management system, the big trouble with generic smart doorbells, an interesting attack on Tesla Model X key fobs, CA's adaptation to single-year browser certs, several instances of leaked credential archives, a critical RCE in a major MDM server, a bit about the Salvation Trilogy, and some extremely promising news about SpinRite's future.  Then we'll wrap up by taking a look at the consequences of the increasing consolidation of DNS service providers.  It's not good if staying on the Internet is important to you.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  We've got Drupal issues - yes, again.  We've got key fob hacks - yes, again.  Also we'll talk a little bit about why you should probably not buy that cheap knockoff video doorbell.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 795, recorded Tuesday, December 1st, 2020:  DNS Consolidation.



It's time for Security Now!, the show that covers your privacy and security online.  It does a little teaching, too.  And have some fun while we're at it.  And that's the guy in charge, right over my shoulder here, Mr. Steve Gibson of the GRC.com site.



STEVE GIBSON:  I suppose that depends upon your definition of "fun."  But, yeah.



LEO:  Oh, well, if you listen to this show, you know what I mean.



STEVE:  Yeah.



LEO:  I mean, if you think it's fun to write in assembly language, you've come to the right place.



STEVE:  So actually I have a little bit of news about that, too.



LEO:  Oh, good.



STEVE:  Allyn Malventano and I have been exchanging some mail.



LEO:  Oh, nice.  He's the king.



STEVE:  With some potentially really interesting news about or consequences for SpinRite.  But we'll get to that in a minute.  We're going to end up talking about an interesting research paper which was recently presented at one of the many ACM (Association for Computing Machinery) conferences about DNS consolidation and what has happened over the last few years, what the stats are, and what it means for the Internet in general and for how important you feel it is to keep your website online, whether it's an enterprise or a personal site or whatever.



But lots of stuff has happened.  We've got a couple of new and forthcoming Chrome features.  I'm going to quickly run through some new and notable ransomware casualties, including a couple of follow-ups on previous events.  We'll look at a critical flaw in Drupal's CMS.



LEO:  Again?



STEVE:  Their Content Management System.  Yeah, there's a critical need for anybody who hasn't updated recently.  We've got the big trouble with generic smart doorbells.  The NCC group took a look at 11 of them, and what they found was just chilling.  But shouldn't surprise us.  We have a little takeaway from that.  We've also got the interesting attack, the third actually by this developer, on Tesla's Model X key fobs.  We have a Certificate Authority's adaptation to single-year browser certs, which we were anticipating.  I got actually a note this morning from DigiCert.  Maybe it was yesterday morning.



Anyway, we've got several instances of leaked credential archives and what they mean, a critical remote code execution vulnerability in a major MDM server platform, you know, Mobile Device Management.  I have a bit of commentary on the Salvation Trilogy, not any spoilers, of course, but I'm at 92% and, oh, Leo.  Also some extremely promising news about SpinRite's future as a consequence of something that the benchmark has been revealing.  And then we're going to wrap up by taking a look at the consequences of the increasing consolidation of DNS service providers and what it means.  And of course we've got a fun Picture of the Week, as we always try to have.



LEO:  You have been very busy, haven't you.  



STEVE:  Yeah.



LEO:  Working hard, as always, on Security Now!.



STEVE:  Yeah.  So this Picture of the Week is a chart which shows - it's a two-axis chart where we have rows of time to crack a password, where we go from four characters up to 18 characters.  And then in columns of each of those rows is the complexity of the password at that length.  So a password that had numbers only; that had lowercase letters only; upper and lowercase letters; numbers, upper and lowercase letters; or, finally, numbers, upper and lowercase letters, and symbols.  And so five different classes of password complexity on one axis and password length on the other.  So what you get is an interesting diagram such that obviously in the upper left where it was four numeric password only, that's going to be instantly cracked.



LEO:  Even if it's a mix of upper and lowercase and numbers and symbols, four is just too few.



STEVE:  Exactly.  And then in the exact opposite corner, I don't even know what "7qd" - is that quadrillion, probably - seven quadrillion years.



LEO:  It's a long time.



STEVE:  Which, you know, is probably sufficient.



LEO:  And that's not even that long a password.  That's 18 characters.  That's not even that long.  Mine are much longer.



STEVE:  Yeah, with upper/lowercase.  And we're assuming it's not words, you know, it's random.  But anyway, so this is no revelation to any of our listeners.  But it's such a good chart that it's already, since I posted the show notes up on Twitter, I've seen it being retweeted, that is, this particular chart.  I went to its source, HowSecureIsMyPassword.net, and they've got something actually that kind of copies the Password Haystacks concept where, as you're putting in a password, it's showing you how long, although it doesn't show you all the fun stuff that Haystacks does.



Anyway, my point is that this chart would be good for our listeners to share with people who are unaware of, like, what it means because, you know, for example, you could, like, look up your password.  Okay, mine is 10 characters, and I've got upper and lowercase characters only.  Well, this says a month.  Now, of course there's a whole bunch of assumptions that are required.  We know all that.  But just to get the concept through.  I thought this was a really nice presentation.  So I wanted to share it with our listeners.



LEO:  How recent is this?  Is this modern computers?  And do we worry even about quantum computing, like suddenly all of this stuff takes seconds because of a quantum computer?



STEVE:  Well, so there's a perfect example of all the things that are unstated.  For example, is this brute forcing over the Internet, trying to get into an account?  Is it an offline hack where you're able to run, employ GPUs, or even more, bitcoin hardware acceleration in order to do SHA-256 at ridiculous speeds?  I mean, so this is meant to convey the concept of both complexity and length are factors, and to sort of give people a rule of thumb.  I mean, and frankly, you know, my Haystacks page is the same way.  It just sort of is meant to give you a sense of, like, longer is better.  More complicated is better.  So do that.



Okay.  So Chrome's Omnibox is becoming more "omni."  We were talking just before you hit the Record button on the podcast, Leo, about something that required Chrome in order to work.  I'm a Chrome user.  Like, for example, the show notes are composed every week in Google Docs.  And I just figure, might as well do that in Chrome because it's going to definitely like itself.



LEO:  Right.



STEVE:  So Firefox is open statically to my left.  And that's where my hundreds of tabs tend to accrue over time.  Chrome I sort of fire up just because it's convenient from time to time.  But so there was an interesting little blurb that I saw that Chrome was adding, which I think would appeal to our users.  And what that is, is the ability to put commands, like UI-related commands, into the omnibox, which is what they call the URL field, the point being you can put, like, search terms in, or URLs or whatever, and the browser will try, not always perfectly, by the way, sometimes it annoys me, but generally try to figure out what you're asking and do the right thing.



But how cool would it be if you could type in "clear cache" or "delete history" or "wipe cookies" or "update browser" or "incognito" or "edit passwords" or "edit credit card" or "translate this page."  That's coming.  It's not turned on yet.  It's being rolled out slowly over time.  But anybody who wants to can turn it on today.  If you put in the omni box "chrome://flags," that will bring you to the big repository of switches.  And you then need to search on that page.



This is a search field at the top.  Put in "omnibox suggestion."  That will reduce the huge number of options to three.  The first two are what you need to enable:  "Omnibox suggestion button row," enable that, and normally it's set to default, which means that Chrome or Google will eventually flip that on for you when they decide everybody wants this.  And then the second one, I don't know why it's called "pedal," but it's "Omnibox pedal suggestions," P-E-D-A-L.  You see this sometimes where programmers come up with some strange term, and it survives the UI, and it ends up surfacing for some reason.



Anyway, "Omnibox pedal suggestions" and "Omnibox suggestion button row."  Enable them both.  Then in the lower right you'll see that you've been presented with a Relaunch button.  So click that.  When it comes back up, you can type things into the omnibox command, like "wipe cookies," "delete history," "clear cache" and so forth.  Which is just kind of a cool feature.  It's worth noting that Chrome is not the first browser on the block to do this.  In fact, Firefox has had this since the spring of this year.  But it's not as obvious there.  I think the Mozilla people, being a little more conservative, were afraid that if you put in "clear cache," that might not be what a Firefox user wanted.  Google doesn't seem to worry about that.  You have to say "clear Firefox cache" in order for it to present you with a button.



What happens when you issue a command, or in the case of Chrome something that it thinks is sufficiently clear that you're talking to it, is that the upper suggestion in the little dropdown list of things that you might be asking becomes a button, which you can then click in order to immediately have that action take effect.  So anyway, just a cool thing.  As I said, Firefox you've got to add the word "Firefox" to get its attention, but also it tends then to false-positive less often.  So anyway, just a cool little feature.



Also, and this might be relevant to people who use Chrome with a gazillion tabs, you know, I don't know you can when tabs are like stuck in a horizontal row.  I have a gazillion because tabs themselves are horizontal so stacking them vertically is the only thing that makes sense.  And some day the world is going to figure that out, but that's okay.  There is now another forthcoming feature for Chrome where you can enable a tab search feature to have Chrome search for text, do an incremental search on the text of all the tabs you have open.



So I think this sort of signifies that we're reaching that point in browser development where we've run out of good ideas, or things that we really need, and so now they're sitting around, scratching their butts, thinking, hmm.  Okay, you know, we don't want to lay anyone off.  So what can we have them do?  Anyway, so if you start Chrome with "--enable-features=TabSearch," then a little button appears to the right of your row of tabs in Chrome, which if you click it, or if you do Ctrl-Shift-A for activate tab search, you're able to do an incremental search across all of your open tabs.  I never have more than five or six in Chrome because as I said, it's sort of - I just fire it up for the moment and then shut it down.  But for people who are big Chrome users, who end up getting, like, I know there's a tab here somewhere, this may be the thing that you've been looking for.



In ransomware news, a few things.  Delaware County, Pennsylvania has paid a half a million dollar ransom after their systems were hit by the DoppelPaymer ransomware last weekend.  And of course being Pennsylvania, that's on a lot of our politically focused people's radar because it was one of the loudly and hotly contested states in the U.S.'s recent presidential election.  So of course the first question anyone has is whether the ransomware attack, which was recent, may have had any effect upon the state's election networks.



So Delaware County was quick to state that the Bureau of Elections and the county's Emergency Services Department, neither of those were affected.  They're on a different network than the one that was hacked.  Sources said that the county's in the process of paying this half a million dollar ransom since it's insured for such attacks.  So they figure, hey, what the heck, let's pay the ransom, get the key, and get our systems back up.



We're hearing more about DoppelPaymer, and so I think this is one that we're going to be talking about, much as we've been talking about Sodinokibi and Ryuk and so forth.  It was derived from its predecessor, BitPaymer.  And it shares a large body of its code.  DoppelPaymer has been improved to add multithreaded encryption because of course that's what you want in your whole server encryption is speed.  So anyway, it's faster now.  And in an odd twist, the DoppelPaymer gang apparently advised Delaware County to change all their passwords and also modify their Windows domain configuration to include safeguards from the use of the Mimikatz program.  Now, it's not clear what those safeguards would be.  Maybe like explicitly look for Mimikatz.



Mimikatz, we've talked about it from time to time, it's an open source tool that's been around for about six years, since 2014.  It's commonly used by ransomware gangs to harvest Windows domain credentials when they get into a compromised network.  So it's one of those lateral movement tools.  It doesn't qualify as "living off the land" because it's typically not present on systems.  The ransomware needs to download a copy in order to use it.  But it is on GitHub.  And its author six years ago explained that he wrote it as a way to learn C and experiment with locating and extracting Windows credentials from the RAM of running systems.



So, yeah, it's very much like that Active Directory tool we were talking about a few weeks ago.  It wasn't ever really written to be used for malicious purposes.  But, boy, is it handy for those.  It extracts things.  It finds them and extracts them out of RAM.  And DoppelPaymer and this gang are using Mimikatz.



We did have some follow-up on Canon's attack.  Remember we talked about image.canon going down.  And I was remarking, it's like, wow, they've got their own top-level domain, .canon.  I guess if you have enough money you can say, hey, I want a TLD.  So Canon finally publicly confirmed what we all pretty much knew based on the evidence, was that they did suffer a ransomware attack in August, and the hackers stole data from the company's servers.  At the time, their cloud photo and video storage service, as I was mentioning, image.canon, went down, and it caused some loss of user data.



But we noted when we covered this on the podcast there was a long list of domains that were of Canon-related services that were all suffering outages.  Shortly after the attack, BleepingComputer obtained information showing that the outage had been caused by the Maze ransomware, M-A-Z-E.  And Maze told BleepingComputer that they had stolen 10TB of data...



LEO:  Ooph.



STEVE:  Yeah, including private databases, before they had triggered the file-encrypting malware on the 5th of August.  And interestingly, it turns out the trouble with at least the image.canon site they claim was unrelated to anything they did.  They confirmed that their actions did not extend to Canon's storage service.  So they have no reason to lie, I would think.  So just a coincidence.



Another recent victim was U.S. Fertility, which is the largest network of fertility centers in the U.S.  They've got 55 locations across 10 states.  And they were just recently hit by ransomware, encrypting a bunch of their systems.  And so they were suffering some outage.



I got a kick out of the fact that Ritzau, which is Denmark's largest independent news agency, refused to pay any ransom.  They were hit a week ago, last Tuesday.  Their spokesman said the Ritzau news agency - oh, they were founded in 1866 by Erik Ritzau, so they've been around for a while.  The spokesman said the news agency was subjected to an extensive hacker attack on Tuesday, and the hackers have subsequently demanded a ransom to release data.  Ritzau has refused to pay money to the hackers.



So anyway, they're a big, sprawling organization.  About one quarter of their more than 100 servers on their network were encrypted.  So their IT department immediately set to work restoring the systems and expected to have them up in a couple days.  So that's how you do it. You have your technology nailed down.  If the worst happens - and, boy, we're going to be seeing later in just this podcast, we will be looking at one thing after another that would have allowed ransomware guys to get in.  And what we know is there are as many ways in as there are employees, essentially.  So the only solution at this point is to be in a position where you can recover, and these guys clearly are.



This one actually touches on Chromebooks, which I thought was interesting.  Last Wednesday the Baltimore County - and there's a distinction here between Baltimore County and Baltimore City, as we'll see.  The Baltimore County Public Schools posted the news:  "BCPS can now confirm we were the victim of a ransomware attack that caused systemic interruption to network information systems.  Our BCPS technology team is working to address the situation, and we will continue to provide updates as available. For now, please don't use BCPS services."  And of course all of this hits, unfortunately, amid the COVID-19 remote learning phase, you know, virtual education, because we're seeing the expected winter increase in cases.  So school's out, essentially.



The Baltimore City Public Schools district, apparently distinct from Baltimore County, also published an alert on its website urging students to only use school-issued devices for virtual learning.  Baltimore City wrote:  "Students participating in virtual learning should only use City Schools-issued laptops or devices.  Do not use devices issued by Baltimore County schools, or your personal laptop or computer."



They said:  "Students without access to a City Schools-issued device will be granted an excused absence."  So reading between the lines, it sounds like there's some concern that the malware might crawl out onto devices connected to the County network, but not the City network.  Or perhaps Baltimore City has additional device protection on their devices.



But here's what I thought was sort of interesting.  Following last Wednesday's ransomware attack that hit the district's network, Baltimore County Public Schools has now urged students and staff to stop using their school-issued Windows computers and only use Chromebooks and Google accounts.



LEO:  That tells you something.



STEVE:  Uh-huh, yeah.  The update on their website says:  "We now know that BCPS-issued Chromebooks were not impacted by the cyberattack."  Okay, so that really does suggest that they detected that students' Windows-based computers may have been affected by this.  So perhaps the attack went out and put malware onto student-issued computers.  They said:  "You may now safely use BCPS-issued Chromebooks and BCPS Google accounts for students and staff.  Please do not use BCPS-issued Windows-based devices until further notice."  Oh, and school is out yesterday and through today at least.  Students are instructed to check in with the website to get an update and figure out whether they'll be able to safely reconnect.  So, boy, this is creating a mess.  



And lastly, just because it's big and significant, the French multinational production and distribution firm Banijay Group SAS, who we probably better know for the various brands they produce, which include "MasterChef," "Survivor," "Big Brother," "The Kardashians," "Mr. Bean," "Black Mirror," "Extreme Makeover:  Home Edition," and "Deal or No Deal," among a great many others, was also another recent victim of the DoppelPaymer ransomware.  Although they've only shared that they have suffered a cyberattack, and that some of their data may have been compromised, the DoppelPaymer ransomware gang is not only claiming responsibility, but proving their involvement by sharing several documents, presumably stolen from Banijay's systems.  DoppelPaymer is also taunting the French production group by referencing GDPR compliance issues and leaking an internal GDPR compliance document, among others.  So the crooks are having fun at these guys' expense.



Okay.  In security news, Drupal.  The Drupal security advisory is titled:  "Drupal core - Critical - Arbitrary PHP code execution."  Which is not good news.  That was issued last Wednesday.  And if any of our listeners are running Drupal-based systems and haven't yet updated, do it now.  It is a sweeping vulnerability.  Drupal 9.0 needs to be updated to 9.0.9; 8.9 needs to be updated to 8.9.10; 8.8 or earlier to 8.8.12; and Drupal 7 needs to be moved to 7.75.



So obviously this is a sweeping problem affecting a whole set of their various lines.  The project uses the PEAR (P-E-A-R) Archive_Tar library.  The PEAR Archive_Tar library has released a security update that impacts Drupal.  So this is another case like we saw with Google where remember they had the zero-day that was discovered because they were using the FreeType library font interpreter.  So this is another instance where the use of a third-party library has bit somebody using that library when a remotely exploitable flaw was discovered that can be referenced through the user of the library.



The advisory states that:  "Multiple vulnerabilities are possible if Drupal is configured to allow .tar, .tar.gz, .bz2, or .tlz file uploads and processes them."  They said:  "To mitigate the issue before fixing it, prevent untrusted users from uploading any of those file types."  So here, I mean, we know what this means.  This means that there is a glitch in this PEAR Archive_Tar library such that interpreting, when it tries to interpret the content of any of those files, it turns out it's possible to maliciously manipulate those files in order to get remote code execution.



So what makes this all the more urgent is that there are known exploits against these vulnerabilities, and some Drupal configurations are known to be vulnerable.  Of course, as we know, Drupal is a popular content management system.  As of Friday, over 944,000 websites, so just shy of a million, 944,000 websites are using vulnerable Drupal versions out of a total of 1.12 million, according to the official stats.  But it turns out even those stats probably underestimate the scope and scale of the vulnerabilities because only Drupal sites which are using the Update Status module are included in the data.  So that sounds like something that allows Drupal to keep track of sites.  So many more may be at risk.



Drupal is currently in fourth place among CMS systems on the Internet.  WordPress of course has the huge lead at 63.8% share.  Second is Shopify at 5.1.  Joomla is in third place at 3.6, and Drupal is at 2.5%.  But this just goes to show, even a 2.5% share of content management system puts it at 1.12 million sites.  And as I said, as of last Friday, just shy of a million of those, 944,000, are using vulnerable Drupal versions, and exploits are known.  So, yikes.  Update.



And unfortunately, I think this is another trend that we're seeing.  I mean, we've sort of seen it before, even back in the Stagefright exploit against Android, lo those many years ago.  That was a media codec exploit.  So it wasn't formally part of Android.  It was like, hey, let's use this codec pack in our OS, and got bitten by something that somebody else wrote.  So, you know, in this day and age it's difficult to be absolutely responsible for all the code that is running.  Even I, where I wrote all of my backend web server stuff, but I still have IIS as fielding the incoming inquiries.  It's just it's very difficult to be an island and get anything useful done.



LEO:  Okay.  On we go.



STEVE:  So hopefully it won't come as a surprise to any of our listeners to learn that they don't want to have off-brand no-name IoT smart doorbells.



LEO:  Yeah.  Yeah, that sounds right, yeah.



STEVE:  The likes of which are sold on Amazon and eBay.  You don't want those anywhere near your homes.  Matt Lewis of the NCC Group, and their researchers, took a look at the operation of 11 off-brand el cheapo bargain smart doorbells and found their intelligence to be somewhat lacking, shall we say.  Matt said:  "Our findings could cause issues for consumers and are indicative of a wider culture that favors shortcuts over security in the manufacturing process."  Okay, no big surprise there.  He added:  "However, we are hopeful that the much-anticipated IoT legislation will signal a watershed moment in IoT security.  Until this comes to fruition, we must continue to work together to highlight the need for basic security by design principles, and educate consumers about the risks and what they can do to protect themselves."



So, okay.  So first of all, this IoT legislation Matt's referring to, it's hopeful.  It's been moving along since its introduction in 2017 by Senator Mark Warner.  And it uses the typical "what can the government do" carrot-and-stick security requirements.  So, you know, you need to do these things in order to get a government procurement contract.  And it does include a bunch of stuff we need, so clearly some IoT security-aware people were involved.



The legislation, if it happens - and it's like it's still alive, and maybe it will.  It requires that vendors, for example, commit that their IoT devices are patchable, so yay for that.  Also that the devices don't contain known vulnerabilities.  If a vendor identifies vulnerabilities, that vendor must disclose them to an agency with an explanation of why the device can be considered secure, notwithstanding the vulnerability, and a description of any compensating controls employed to limit the exploitability and impact of the vulnerability.  And then based on that information, an agency's CIO could issue a waiver to request the ability to purchase the device.



The third requirement is that the devices rely on standard protocols, which only seems great.  Let's not roll our own and say, oh, this is better than anything else.  And then, fourth, the devices don't contain hard-coded passwords.  So that's obviously a really good thing.  It's going to be difficult, though, to do because, when you think about it, I mean, hard-coded passwords we know are bad.  But not having them is going to require some interesting workarounds.  So the bill is not yet law.  And there are exemptions in there that are so large you could drive a truckload of dumb doorbells through them.  So we'll see how this turns out.  But it's certainly true that having any sort of legislation would be a lot better than just what we have now, which is this totally unregulated environment.



Okay.  But specifically, of these 11 devices, two of the devices that these guys tested were manufactured by Victure (V-I-C-T-U-R-E) and Ctronics (C-T-R-O-N-I-C-S).  They had critical vulnerabilities that could allow bad guys, not surprisingly, to steal the users' home network password.  The flaws would also allow attackers to hack not only the doorbells, but also the residential router that the doorbell was connected to, and any other smart devices in the home, thermostat, other cameras, and even get into household computers.



And, for example, this Victure Smart Video Doorbell is its formal name, was found to be sending the customers' home WiFi network name and password, unencrypted, to servers in China.  So, you know, there is absolutely no need for a locally connecting WiFi device to export its local network credentials to anywhere.  But, you know, you buy some Victure smart doorbell from Guangdong, China and plug it in; and, I mean, you know, hey, look, it works.  Well, yeah.  But it's also sent your network credentials to China.  Maybe that's not a big problem.  But it doesn't have to do that.  There's no conceivable use case for it doing that.  So maybe that's not what you want. 



And remember, Leo, the visual that we set up on a podcast a few months ago?  Actually, we were talking about this after I had attached a few smart plugs to my network.  I wanted some simple timers.



LEO:  Oh, yeah, yeah, yeah.



STEVE:  And in fact I did add an IoT thermostat to my environment here, and I had also a humidity sensor and a separate logging thermostat.  And I could just imagine a globe showing - and of course in movies like "War Games" we see all the little lines tracing an arc through the upper atmosphere of incoming missiles.  Well, imagine all of the IoT devices in the U.S. with their connections back to servers in China.  I mean, that's where they're connecting.  That's where my doorbell - actually I don't have a doorbell.  That's where my thermostat and my IoT plugs are connecting, which of course is why I would argue it is crucial that they be on an isolated network, as all of mine are.  It's sort of, you know, when you picture that all of these tens, hundreds of millions of connections, we remember that story about the Trojan horse from olden times.



So anyway, Matt said:  "If stolen, this data [obviously] could allow a hacker to access people's home WiFi, enabling them to target their private data, access any smart devices they own," and so forth.  The researchers found that another device, bought from eBay and Amazon without any clear brand associated to it, it was literally a no-name smart doorbell, was vulnerable to the KRACK exploit.  That's the Key Reinstallation Attack that was discovered three years ago in 2017.  So these devices don't have up-to-date WiFi stacks.  Imagine that.  On the other hand, why would they?  Of course the KRACK attack opens any attached network to intrusion by allowing the network's WPA and WPA2 encryption to be cracked without much effort, given state-of-the-art cracking tools.



So of course, again, none of this comes as any great surprise.  But I think it's nice to examine some specifics from time to time because it's too easy to sort of wave off generalities.  The advice, of course, if you want to buy a smart doorbell, there is, I would say, very good reason, especially a smart doorbell.  You've got a video camera; right?  That anybody monitoring it can see what's going on out of your front door, can see when you all leave the house, can see when you come in, can watch what's going on around you.



Anyway, I would argue there's very good reason to stick with major brands.  You're going to pay more.  But, I mean, you have to care about security.  And, I mean, unless you take personal responsibility for what one of these devices does, you have to isolate it on its own network.  And I would argue, buy from a major brand.  Even if there's a problem.  And we know these things are going to have problems.  The problems will make the headlines.  The vulnerabilities will be found and cured responsibly and promptly as opposed to absolutely never.  So anyway, I just thought it neat that these guys took the time to just sort of say, let's take a look at these doorbells and see what they're doing.  And, yeah, to no one's surprise.



Now, the good news on the most recent of three Tesla key fob hacks is that it's not easy to do.  But it also shows that even well-designed devices can get hacked.  As Tesla found out for the third time, from this one researcher, and we've spoken of him before, Lennert Wouters (W-O-U-T-E-R-S), he is a Ph.D. student at the Computer Security and Industrial Cryptography group at the Catholic University of Leuven, that's KU Leuven - we've covered a bunch of the work coming out of there - located in Belgium.  He came up with - the press said he "discovered" this.  Well, I guess.  But it's not like he tripped over it, as we'll see.  But he worked out a method to overwrite and hijack the firmware of Tesla Model X - is that Model 10?  Is that how we say it, Model 10?



LEO:  Yeah.



STEVE:  Key fobs.



LEO:  No, no, I'm sorry.  Apple is 10.  Tesla is X.



STEVE:  Okay.  Model X.



LEO:  It's very confusing.



STEVE:  Thank you.  Because it's not Space 10; right?  It's SpaceX.



LEO:  Right, it's SpaceX, yeah.  No, it's a Model X, yeah.



STEVE:  So, okay.  So what this guy did, he figured out a way, a hack that would allow him to steal any car that isn't running the latest software update.  His attack only takes a few minutes to execute and requires inexpensive hardware.  But I'll explain it.  It's not that easy to do.  This guy, same guy, has previously produced successive successful attacks against Tesla's security in 2018 and 2019.  And now he adds 2020.



LEO:  He'd better get his Ph.D.  I'm just saying.  He deserves it.  He's earned it.



STEVE:  Yeah, yeah.  And you know that when he called the Tesla security people, they took his call.



LEO:  Oh, yeah, yeah.  And they fixed it, we should point out.



STEVE:  Yes.  So he explained that his third attack works thanks to a flaw in the firmware update process of the Tesla Model X key fobs.  It can be exploited using an electronic control unit, you know, the brains, the ECU, salvaged from an older Model X vehicle, which it turns out they've been around long enough, they can easily be acquired online, like from eBay or other stores or forums selling used Tesla car parts.  Wouters said attackers can modify the older ECU to trick a victim's key fob into believing the ECU belonged to its paired vehicle.  Right?  So you're using this ECU that you bought used to trick the victim's key into believe it's pairing with its own car.



Once that's done, once you've pulled off this trick, then the ECU is able to push a malicious firmware update out to the key fob over Bluetooth.  Since the key fob update mechanism was not being properly secured, they were then able to wirelessly compromise the key to take full control over it.  And subsequently, they could obtain valid unlock messages to unlock the target car later.



Okay.  So here's how the whole attack works, in practice.  The attacker approaches the owner of a Tesla Model X vehicle.  In this first phase of the attack, they must briefly get within about five meters of the victim.  So at that point they're probably at Bluetooth Low Energy.  Later it switches to full Bluetooth.  But at this point they need to be within five meters of the victim to allow the older modified ECU, that is, this spoofing ECU, to wake up and ensnare the victim's key fob.



The attacker then pushes the malicious firmware update into the victim's key.  Although this phase, after that initial contact, which can be brief, but it has to be close, now they're able to about to be about within 30 meters of the victim, and it takes about a minute and a half, about 90 seconds to execute the firmware push into the victim's key.  But that at least allows the attacker to put some distance between themselves and the targeted Tesla owner, thus reducing suspicion.  They don't have to hang around, like for a minute and a half.



Once the victim's key fob has been hacked, the attacker is then able to extract car unlock messages from the compromised fob.  The attacker then uses these unlock messages to enter the victim's car.  That gets them into the car.  The attacker then connects the older ECU to the hacked Tesla's car diagnostics connector, which is normally used by Tesla technicians to service the car.  The attacker uses this connector and another couple minutes to pair their own key fob to the car, which they are then later able to use to start the vehicle and drive away.



So essentially the attack is use an old ECU, get close to somebody with any not-yet-updated Tesla Model X for a total of about a minute and a half, most of which time you can spend at a distance.  That subverts the key in order to get it to release a bunch of unlock messages that it has stored.  The bad guy then uses those to unlock the car to get into the car and trick the car then into pairing it with a new key, essentially adding the attacker's key to the permanent paired list.  And then they've got a completely valid key that allows them to do anything that a valid owner of the car would do.  So again, not easy, but clever.



The downside is the attack uses a relatively bulky rig.  You know, this ECU is not small, so you've got to stick it in a backpack or a bag or maybe like in another car that's parked next to the victim or something.  But still, the attack is feasible.  And it's not expensive.  You need a $35 Raspberry Pi, a $30 CAN bus shield on the Raspberry Pi in order to connect to the Tesla's CAN bus, a modified key fob, that older ECU from a salvaged vehicle - apparently those are 100 bucks now on eBay - and also about a $30 lithium polymer battery in order to power the whole portable rig.



And of course, being a responsible lad, after discovering the bug and developing the exploit earlier this summer, he reported it to Tesla's security team in mid-August.  Only after Tesla began rolling out an over-the-air software update to all Model X cars did Lennert then publish his findings.  And the software update containing the fix is 2020.48.  So don't leave the garage without it.  



LEO:  That's an expensive vehicle.  So it may be a lot of work, but it's also justified if you can get it.  I mean, it's well over a $100,000 vehicle.



STEVE:  Yeah.  And, you know, again, it's a rolling computer.  It's funny, there's some commercial on some channel that I listen to where someone is saying, talking about someone's car, "Have you ever looked under the hood?  It's like a computer on wheels."  And I'm thinking, no, it's not "like" a computer on wheels.



LEO:  It is.



STEVE:  It is a computer on wheels.



LEO:  Yeah.  My Tesla was a beta computer on wheels, that's for sure.



STEVE:  Uh-huh.  And you were the beta tester.



LEO:  I was the beta tester.



STEVE:  What was it, that like reverse went out or something?



LEO:  Well, when we first got it, you would drive it thinking - I had it in reverse, I could have sworn.  But it went forward.



STEVE:  Oh, that's what it was; right.



LEO:  Yeah.  And it dinged a car in front of us in a driveway.  But then I called them, and they said, well, no, we were looking at the logs.  You didn't have it in reverse.  It's like, oh, I didn't realize you had logs.  So they record everything.  Geez, Louise.  And then there were a few other things.  The door kept closing on Lisa.  She didn't like that.  It's supposed to have all these sensors in it, but it turned out there really weren't that many.



STEVE:  That'll put you off a little bit.



LEO:  Yeah.  Finally at the point where she said, look, before you close the doors, because they're all automatic, you have to shout "Doors are closing" and wait for an acknowledgment that everybody's out of the reach of the door, especially those gull-wing doors because they clonk you right on the head.  And then they had a - I can go on.  You probably don't want me to.  But it had a seat that tried to eat us once.



STEVE:  I did hear you say at some point, it wasn't on this podcast, that you were not planning to buy another Tesla.



LEO:  No, I'm not.  No, I'm not.  Mostly it was - it wasn't the bad experience, although Lisa didn't like it.  It was just that there were issues with parts and delays and stuff.  And I just thought, I want to buy it from a company that actually makes cars for a living.



STEVE:  Well, and you were a pioneer. 



LEO:  I wanted to support Elon.  I did, yeah.



STEVE:  You were right there, first in line.



LEO:  And my next car is electric, but it's made by Ford.  Perhaps you've heard of them.  You know what, though?  I would trust Elon with security more than I would trust Ford.  Who knows?  The new Ford uses an app on the phone to open the door.



STEVE:  The good news is, nobody now...



LEO:  Wants a Ford.  Oh.



STEVE:  ...can use the excuse of, oh, we really didn't consider security.



LEO:  Right, exactly.



STEVE:  It's like, sorry, honey.  That ship has sailed.



LEO:  Yeah, ship has sailed.



STEVE:  So as we were expecting, certificate authorities have adapted to the new single-year certs.  Traditional high-reputation non-automated certificate authorities are reacting to the browser industry's decision - which as we know was initially instigated by Apple, but then quickly adopted with some sigh of relief because Google was trying this and couldn't get it to happen.  Apple just said, "We're doing it" - to enforce a maximum life on browser certs of 398 days.  And as we know, this went into effect on September 1st of this year, affecting any certificates issued from September 1st on.



And this morning - oh, it was this morning - I received a note from my chosen and quite favorite certificate authority, DigiCert, explaining the way their new multiyear plans would function.  The essence is what we expected.  Despite the shortening of individual certificate lifetimes, that is, the cert itself cannot be valid for more than 398 days.  It will now be possible to sign up in advance for a multiyear commitment.  DigiCert provides up to six years.  And as you'd expect, a longer commitment results in a lower cost per year, which seems fair since you are giving them your money upfront, and in return they're giving you a discount.  And once that's set up, you're in control of your own certificate renewal, able to reissue certificates at any time that's needed.



And in DigiCert's case this is essentially an extension of the system they've had in place for years.  I've mentioned on this podcast a number of times how convenient it has been to be able to issue a certificate at midnight on the weekend and receive it within minutes.  Essentially, DigiCert decouples the authorization of proving I am who I say I am from the issuing of certificates so that they do periodically need me to reverify my identity, my corporate affiliation and so forth.  They do all of that validation automatically every so often, which then frees me within those windows to issue certs whenever I want to.



So, you know, all certificate authorities are now needing to compete with ACME certificate automation, which of course was pioneered by Let's Encrypt.  And as we know, I used to use EV certs and proudly had the Gibson Research Corporation in green in the browsers.  But then the browsers made the decision across the board to deemphasize the display, any display that certs were Extended Validation.  And also because my use of subdomains had been growing, with sqrl.grc.com, forums.grc.com, news.grc.com, and EV certs do not support wildcards by policy, it just made more sense to switch from EV to OV, Organization Validation certs, which is where I am now.



So anyway, I still think that given the decidedly mixed blessing of certificate automation - yes, it makes them free.  It allows you to have encryption.  It really doesn't do the job you could get about authentication, though, because we know that the fraudulent issuance rate is exceedingly high with automated certs.  So there's a tradeoff.  And I still think it makes sense to add an indicator in a cert about whether it was issued by automation or under human supervision of some kind.  That, to me, that seems like a useful flag, but maybe that's just something, another thing users won't pay any attention to.  I don't know.



Unfortunately, nearly 50,000 Fortinet VPN credentials have been posted online, through no fault of Fortinet's, I should add.  Last year it was revealed and we talked about it at the time, that the FortiOS, which underlies the Fortinet VPN, was subject to a path traversal flaw.  It was assigned a CVE of 2018-13379.  And the NIST description of the vulnerability reads:  "An Improper Limitation of a Pathname to a Restricted Directory" - then it has in parens (Path Traversal) - "in Fortinet OS" - and it's got a range of OSes - "under their SSL VPN web portal allows an unauthenticated attacker to download system files via special crafted HTTP resource requests."



On August 28th of last year, 2019, Fortinet posted:  "At the recent Black Hat 2019 conference held in Las Vegas this past August 3-8, security researchers discussed their discovery of security vulnerabilities that impacted several security vendors, including Fortinet.  All of the vulnerabilities impacting Fortinet were fixed in April and May of 2019."  Meaning months before this disclosure, they got all this fixed.  And of course, being a responsible company, Fortinet had also worked to notify all of their users to update their systems.  And of course, despite their efforts to get their users to update, we know how that probably went.



The vulnerability allows Fortinet VPN system files - or allowed, I should say, in the past - to be obtained remotely and without any of that pesky authentication.  This is in the news today because a large, nearly 50,000 records worth, of previous Fortinet VPN logon credential information has recently surfaced on the dark web and is now being passed around.  It's a 7GB archive of individual SSL VPN web session files which contain session-related information including plaintext usernames and passwords and the IPs, both of Fortinet VPN users and the IPs they were connected to - banks, telecoms, government organizations from around the world.  I mean, Fortinet is a real company, so they've got a big high-end install base.



Since the aggregated and leaked archive contains all the login information needed, patching any still vulnerable or even previously vulnerable Fortinet VPNs at this point won't prevent any of their accounts from still being used.  So remediation, which Fortinet was very clear to explain in their disclosure, requires not only patching the VPN, but then also canceling and reissuing all of the previous VPN accounts because they may have been able to get loose.  So basically what was obtained, obtainable back then at the time, known before the Black Hat conference and foreclosed; but again, this is the problem we have in our industry with patches not being applied.  A bunch of people still got their logs exfiltrated from them.  So anyway, what we really need somehow is a way of closing this loop, of getting these connected systems updated, or at least getting notices to the affected individuals out in time.



And speaking of accounts, more than 300,000 Spotify accounts have been hacked.  The security industry has renamed what we once called a "brute force attack."  Now we're referring to these as "credential stuffing" because that's essentially the process.  You're stuffing credentials down into a form on a server or an API access point, trying to get a brute force success.  And of course, as we know, it's typically performed by taking a list of previously used usernames and passwords and just pounding away at some poorly protected service, attempting to get a successful logon.



And I say "poorly protected" because today, any service worth its salt will observe that some attacker at some IP is attempting to brute force their way in.  I mean, it only takes, what, five or six attempts with wildly different usernames and passwords to think, okay, this doesn't look legit.  And yes, a large multi-IP botnet could also be used so that it's not just one IP or a few IPs pounding on the service.  But okay, so it's a more diffuse attack.  But it's still trivial, or it should be, to quickly blacklist even a large number of IPs which are making repeated unsuccessful attempts to log in.  And when I say "repeated," the list it turns out was 380 million - 380 million usernames and passwords.



But Spotify doesn't do that.  And of course they just allowed this attack to go on.  Spotify provides no such protection, nor does Spotify provide multifactor authentication, which would have also successfully thwarted any sort of credential stuffing attacks.  So it should come as no surprise that Spotify's history has been defined by years of their users complaining that their Spotify accounts were hacked.  After passwords were changed, new playlists would appear in their profiles.  Their family accounts had strangers added from other countries.  That's what happens in today's world when authentication is weak.



VPNMentor produced a report titled "Spotify Targeted in Potential Fraud Scheme."  And in the report they wrote:  "We unearthed an Elasticsearch database containing over 380 million records, including login credentials and other user data being validated against the Spotify service."  In other words, this database showed that it had successfully been used to log into 300,000, actually between 300,000 and 350,000 individual Spotify accounts.  They said that the origins of the database and how the fraudsters were targeting Spotify were both unknown.  The hackers were possibly using login credentials stolen from another platform, another app or website and using them to access the Spotify accounts.



They said:  "Working with Spotify," they wrote, "we confirmed that the database belonged to a group or individual using it to defraud Spotify and its users.  We also helped the company isolate the issue and ensure its customers were safe from the attack."  So they started with about 380 million records, which allowed them to get into between 300 and 350,000 individual accounts.  So that meant they had a hit rate of around 0.1%, or like one in a thousand.  So certainly enough successes to be useful.



They notified, when they found this database on an Elasticsearch site, they contacted Spotify back in July of this year, informed them of the exposed database and the threat it would produce.  Spotify reacted immediately, initiated a rolling reset of passwords for all the affected users, and this database showed where login had been successful, where this username and password had successfully logged in.  It was flagged in the database as, yup, this is a good one.  So they got the database, performed resets for all affected users, and resolved the problem.



So, you know, the lesson for of course end-users we know.  Never reuse passwords; make them long and high-entropy; and if possible always add multifactor authentication when it's provided.  The lesson for Spotify and other services:  protect your users by spotting and proactively blocking clearly malicious authentication attempts.  It's easy to do.  Do it.  And immediately offer and promote time-based multifactor authentication, like why wouldn't you?  Crazy.



LEO:  It does seem rare to see a company that doesn't have two-factor these days. 



STEVE:  I know.



LEO:  I had no idea Spotify didn't allow two-factor.  That's crazy.  I'm surprised.



STEVE:  Maybe they don't want to make it difficult to logon, don't want to bite the bullet.



LEO:  Plus maybe they figure, oh, it's just a music service.  Who cares?



STEVE:  Right, that may be.  And in fact, when it talked about defrauding users, I thought, well, okay, it's not clear if you log in as a user, you know, normally you're not able to see your payment information.  So they wouldn't be able to get that.  That would be masked.



LEO:  The defrauding is adding Yevgeny to your family account.  Oh, my brother in Bratislava, yeah, of course.  He is good, good guy.  I love him.  Strange taste in music.  That's the worst thing that would happen.  You all of a sudden get all this weird music out of your taste in your suggestions.



STEVE:  Spam in your Spotify account.



LEO:  Why is he subscribing to all these criminal podcasts?  Yevgeny.



STEVE:  So last piece of news is that Mobile Device Management (MDM), as we know, is a popular means for enterprises to manage the configurations of their mobile phone fleet.  And because MDM servers, by nature of the way they work, must be publicly accessible to remotely manage those mobile devices.  They are a natural target for bad guys.  That means when a remotely exploitable code execution vulnerability is found, enterprises need to take heed.



One of the more popular MDM services platforms, MobileIron, is vulnerable to just such exploitation, which carries a CVSS score of 9.8, which while not 10, is up there.  The flaw was reported to MobileIron by Orange Tsai from DEVCORE.  It exists across various components of the platform.  Actually, I don't know the nature of it.  I didn't take any time to dig into it because it's been fixed, and everyone needs to update.  But it's in the MobileIron Core, which is a component of the MobileIron platform that serves as the admin console; and in MobileIron Connector, a component that adds real-time connectivity to the back end.



Also impacted is Sentry, an inline gateway that manages, encrypts, and secures traffic between the mobile device and the backend enterprise systems; and the Monitor and Reporting Database, which provides comprehensive performance management functionality.  So whatever this thing is, it's like a fundamental flaw in something about what MobileIron was doing.  Sounds like a big mess.  And it's certainly not one that any enterprise wants to have on the network.



MobileIron said in an update last week that it had been engaging in proactive outreach to help customers secure their systems.  And they estimate that 90 to 95% of all devices under mobile management are now being managed on patched and updated versions of the MobileIron software.  The company stated it will continue following up with the remaining customers where they can determine that they haven't yet patched the affected products.  So again, mistakes happen.  Maintaining tight lines of communication is the key.  And we really do need automated updating, or at the very least automated update notifications.  You know we're getting there.  But, boy, the progress is slow.



So I did just want to say that it's been a long slow burn, and frankly even sometimes a little bit of a slog since Peter Hamilton packs his novels with seemingly endless detail.



LEO:  Oh, man, it's long.  It's a trilogy.



STEVE:  Oh, my lord.  And sometimes you're like, why do I - do I really need to know about this?  But it all comes together.  And now I don't ever want it to end.  As you said, I'm at 92% of the third book, and oh, my goodness.  I will be rereading what I just read last night over again because it is so good.  And the other thing, I don't know what Peter has in store, but I still have 8% left.  And we've sort of wrapped up most of what I was expecting.  There is a big loose end.  But it feels like there may be a surprise because I will never forget the surprise, the breathtaking surprise at the end of "Fallen Dragon," where it's like this happens, and it's like, oh, I mean, and then suddenly everything that, I mean, you'd been set up for this surprise.  And so anyway, we know he's fully capable of doing this.  And anyway, I just wanted to say wow. You know, it was the - what was the first crazy series that he made really popular?  



LEO:  Was that "The Abyss" or the - oh, I love all of his stuff.



STEVE:  Yeah.  It was the very early stuff.



LEO:  Not the one with Al Capone.  Oh, "Pandora's Star."



STEVE:  Yes, yes, that's what I was thinking of.



LEO:  And then "Judas Unchained," the Commonwealth Saga.



STEVE:  Oh, my god.  And then "Pandora's Star."



LEO:  Yeah.



STEVE:  "Pandora's Star" and "Judas Unleashed."



LEO:  Yeah, unbelievable stuff.



STEVE:  Or "Unchained" or something, anyway.



LEO:  They call it the Commonwealth Saga, yeah.  Really good.  That's another trilogy.



STEVE:  That was just two.



LEO:  The one that I didn't like was Al Capone was - oh, that was just two, you're right - was "Chronicle of the Fallers."  I wasn't crazy about that. 



STEVE:  Yeah.  And in fact, yeah, the one with Al Capone, it kind of went off the reservation at some point.



LEO:  Yeah, it got a little weird.



STEVE:  It was like, uh, what?



LEO:  Literally, Al Capone is in it.



STEVE:  Yeah.  Okay.  In the "surprising news" category, the work on the ReadSpeed benchmark is tantalizingly close to completion.  I finally published a first release candidate, which had the effect of soliciting some additional testing, and the result was that we discovered a couple of final things that needed a little polish.  And I'll get back to that this evening.  But the benchmark has revealed something that's quite exciting.  So I reached out to Allyn Malventano, whom you know, Leo.



LEO:  Yeah, I'm trying to get you two together this week.  But king of SSDs, a piece of perspective, and then he got a job at Intel doing SSDs over there.  So he really knows his stuff, yeah.



STEVE:  Right.  So I sent him an email titled "Interesting SSD timing reveals ... something."  And I showed him what we were seeing.  And you and, I think next week, you and I will be looking at the same file.  So now he's over at Intel with a title of Storage Technical Analyst.  And I'll go into more detail about this soon, as soon as I have something for everyone to play with.  But it looks very much as though SpinRite will have an extremely bright future in SSD maintenance and repair.  The benchmark provides read timing resolution with an uncertainty of less than 200 picoseconds in its ability to  measure response time.



And it turns out that this could allow it to spot regions of SSD that are weakening long before they fail.  In the time domain, it would be like having a microscope with an extremely high magnification.  And what this reveals, it reveals the effects of mild regional slowdown, which it turns out is a natural consequence of SSD management through something known as the FTL, the Flash Translation Layer, which is the logic which manages the mapping of the underlying SSD media to its external presentation.



And it turns out that standard usage of many SSDs will result in a mild reduction in performance.  Many of the early testers of the benchmark are noting that the front of their SSDs are a little slower in performing than later on because the benchmark tests five locations on each drive:  the front of the drive at the 0%, the middle at 50%, and the end at 100.  And then also the two quarter points at 25 and 75%.  So you can sort of see, you know, one of the first things we saw was that the beginning of people's SSDs were slower, which was like, what?



Well, it turns out that usage causes fragmentation of the SSD, very much like, sort of akin to traditional hard drive fragmentation as a consequence of use.  There it's at the file system level.  Here it's actually below the logical access level.  But we're also seeing something very different, which is what caused me to send this note to Allyn.  It reveals when that FTL layer is having extreme difficulty reading a region of its media.  On today's multilevel cells, you know how like we used to have single-level cells, where you'd store either like zero charge or full charge, and that would mean that you could store one binary bit.  But now, of course, in this quest for greater density, if you were to store four levels of charge, then that would allow you to store two binary bits in a single cell.  What they're often doing now is what they call "triple level," but it's actually eight levels of charge and three bits per cell.



And in fact, Leo, believe it or not, this technology has gotten so crazy that SSDs will advertise what their maximum capacity is.  But they will, because it's more reliable, and you may never need maximum capacity.  They're even able to start out using one bit per cell until the whole SSD fills up at the one bit per cell level, and then dynamically start allocating two or three bits as you continue to fill up the SSD.



LEO:  Wow.



STEVE:  And in fact that may be, because SSDs are not allocating...



LEO:  Capacity goes up as time goes by.



STEVE:  Well, actually the bit density of the actual SSD capacitor is increased.



LEO:  Geez, Louise.



STEVE:  So that it goes from only storing a zero or a one; to storing a zero, one, two, or three; to storing a zero, one, two, three, four, five, six, seven as you actually need more of the capacity of the SSD.



LEO:  And that's part of the wear leveling, too, I would imagine.  It gives them - they can spread it out over the platter, whatever it is. 



STEVE:  Yes, yes.  But the multilevel cells are - they take longer to read.  I mean, sorry, well, actually they do take longer to read.  They also take longer to write because you're needing to write multiple levels into different cells.  And, I mean, it's nuts.



LEO:  It's amazing.  It's amazing.



STEVE:  Oh, Leo, the technology that's hidden behind these things is crazy.



LEO:  It's incredible, yeah, yeah.



STEVE:  So, and Allyn uses the term "cell drift" because that's another thing that can happen is that, you know, that's - in fact, we talked about this a long time ago where SSDs that were stored in a hot environment tended to lose their charge faster than those stored in a cold environment, which makes sense just in terms of electron activity.  Anyway, it turns out that on today's multilevel cells, this Flash Translation Layer may need to tweak its cell voltage thresholds in order to deal with what Allyn calls "cell drift," and/or apply extensive levels of error correction in order to recover a specific region's original contents.



What we are seeing, and what the benchmark reveals, is that you'll be cruising along and suddenly come to a grinding halt while a particularly troublesome region is being read.  And so what happens on lower end SSDs, they may not be using hardware acceleration in order to perform the error correction math on the fly.  So they're having to do a firmware algorithm in order to recover the contents of a specific sector that you're asking to read.



Anyway, it may be that identifying and then applying careful selective block-aligned rewriting, a future SpinRite will be able to literally recharge and realign these drifting cells to bring a possibly endangered region back up to speed.  And then, if an area cannot be repaired, then oddly enough, we may be back to the very early concept of marking a region as unreliable and taking it out of the file system.  And when you think about it, with the crazy size of today's mass storage, it makes a huge amount of sense to remove a tiny fraction of possibly unreliable storage since everybody has way more than they will ever be able to use.



LEO:  Right.



STEVE:  Anyway, when I suggested this in my email to Allyn, he replied.  He said:  "Actually, there's no need to map out clusters at the file system level, and this is one of the cases where it may be beneficial to go [and he put in quotes] 'old school SpinRite' and rewrite successfully slowly read sectors."  He said:  "Unlike hard drives, SSDs won't typically do any rewriting on their own, even if a sector was *very* [and he had in asterisks] difficult to successfully read.  So these very slow reading areas can be remedied by rewriting them.  You can minimize," he said, "an increase in media/FTL fragmentation by ensuring you do these operations in 4K or 8K aligned chunks and not just single sectors."



And of course, you know, we know that a future SpinRite would do both.  It would characterize the overall performance of the media to learn how it performs.  It would then identify any regions that are clearly operating far below average, and then first attempt to resolve the trouble with careful selective rewriting.  But if the region did not increase its read speed, if it refused to be healed, then it would do what SpinRite originally did back in version 1.0, which is to take that region out of the file system and relocate any data that it has to safety, and then allow SpinRite to be used on SSDs as a really proactive preventive management tool.



LEO:  That's really great news.  It makes SpinRite even more useful on SSDs.  That's great.



STEVE:  Yeah, well, and in fact, to our surprise a few years ago we started sharing testimonials from people whose SSDs and various types of thumb drives were being brought back to life by SpinRite.  And it was like, what?  Well, now we know how.  Oh, and I mentioned that SpinRite will be fast.  The benchmark is reading 544MB per second from a 500GB Samsung 860 EVO SSD when attached to a SATA III port.  That means that SpinRite will be able to perform this sort of whole drive performance scan in 919 seconds, or fewer than 15.5 minutes.



LEO:  Nice.



STEVE:  So it becomes practical and feasible again to use SpinRite for this.



LEO:  Nice.  It's exciting.



STEVE:  Yeah.  It's very, very fun.  And our listeners are all going to be able to find out how their drives, both spinning and solid-state, perform in this way.  I would imagine next week we'll have this thing ready.  So anyway, very cool.



LEO:  Can't wait.  Nice.



STEVE:  So DNS consolidation.  Despite previous teachable moments, such as when DynDNS - we all remember that, Leo, we talked about it four years ago, it was in 2016 - when DynDNS was attacked, and the result was huge swaths of the web became inaccessible.  What happened was our dependence upon fewer and fewer large providers - in other words, DNS consolidation - was revealed.  And since then it has only grown.  Today, for example, the research that was just performed reveals that if Cloudflare, AWS, or GoDaddy were to go down, around 40% of Alexa's Top 100,000 websites would also go down, due to a failure of their now-consolidated DNS.



And for those who weren't around when we covered this four years ago in 2016, Dyn, which was subsequently purchased by Oracle, Dyn is a provider of managed DNS services.  It was a victim of a massive DDoS attack by the Mirai botnet that crippled the company's operations and took down the DNS of more than 175,000 websites.  And although some sites managed to remain accessible thanks to well-configured secondary DNS servers that had been wisely kept on different networks, most sites were not prepared and remained down for nearly a day as Dyn worked to remediate the attack.



So a team of researchers at Carnegie Mellon University have conducted a large-scale study of the top 100,000 websites on the Internet to see whether and how those responsible for website operations reacted to this attack, if at all, four years ago, and how many are still operating with a single DNS provider and no effective backup.  Their 14-page research paper is titled "Analyzing Third-Party Service Dependencies in Modern WebServices:  Have We Learned from the Mirai-Dyn Incident?"  And for anyone who's interested, I have a link in the show notes to their 14-page paper.  It was presented during the ACM's Internet Measurement Conference last month, and in it they show that today, in 2020, 89.2% of all websites use a third-party DNS provider rather than managing their own DNS server.



So, you know, that's not so bad; right?  89.2% are using a third-party provider.  On the other hand, that's a lot of concentration because there aren't that many third-party providers.  And if those third parties go down, that takes out everybody who's using them.  So them needing to stay up is important.  And, yes, a company like Cloudflare is super robust, is doing everything it can to stay up.  But even mistakes happen, even if it's not a big attack.  In fact, we talked about there was a Cloudflare mistake of this sort, I don't know, a year or so ago.  And they fixed it quickly.  And we talked about it in detail.  It was a really interesting mistake in the management of their routing that caused everything, all their traffic to go to one place, which just collapsed it.



They also found, to make matters even more fragile than this concentration onto a few third-party DNS providers, that 84.8% of all analyzed websites relied upon a single DNS provider, without any backup redundancy to which they could switch in case of a failure or attack.  Now, I mean, I get it.  People don't understand, I guess, what that means.  Or maybe it's just not really that important that they stay online.  And so they're making a deliberate tradeoff of convenience versus reliability.  But the awareness of the need for DNS redundancy dates all the way back to the birth of DNS.



We're all techies listening to this podcast.  We've all seen at least two fields or a pair of DNS IPs appearing wherever configured DNS addresses are.  I mean, you always have two DNS IPs.  It's regarded as best practice to have redundant DNS servers on nonadjacent IPs, typically on differing Class C networks.  And of course for true redundancy, the further apart they are, the better.  It'd be great if they were actually on entirely separate providers.  But if the configured servers are actually sitting next to one another in the same rack, that is, if they're just, you know, it's like, hey, yeah, they deliberately - I know that, for example, Cox, I have IPs, they look like they're on different C Class networks.  But it's like, okay, what do you want to bet they're in the same room?  Anyway, if that's the case, any benefit is illusory, of course.



So the CMU team says that the number of sites having no effective redundancy has increased by 4.7% since 2016.  And they suggest that this demonstrates that the lessons website operators might have learned following the Dyn DDoS attack and outage were instead lost, if they even ever were learned, and forgotten.  They point out that while two of the top 100 sites - two of the top 100 sites - did add backup DNS servers since 2016, that means that 98 of the top 100 did not.  They also noted that smaller websites continue to use a single DNS service provider without any backup, and in most cases the operators of these smaller sites chose a large, well-known provider, thus contributing to the long-observed tendency toward the consolidation among ISPs.



In the show notes I have a chart from their paper which just sort of shows, based on the Alexa rank, whether you're in the top 100, 1,000, 10,000, or 100,000, what is the amount of third-party dependency, critical dependency, and how much and how often you have redundancy.  They say that the top three DNS providers - Cloudflare at 24%; AWS at half that, at 12%; and GoDaddy at a third of that, at 4% - are the single DNS providers of around 38% of the top 100,000 sites in the Alexa ranking.  And in addition, four DNS providers are the lone critical providers for more than half of the Alexa Top 100.  So four providers used by the Top 100.  So any intentional attack, or perhaps the occasional accidental network hardware or software failure at one of these three providers, could bring down a large chunk of the Internet.



And the researchers also observed that when the much broader Alexa Top 100,000 sites are examined to reveal an apparently much broader base of 10,000 DNS providers - so naturally when you look across a much larger cross-section, then you're going to see 10,000 DNS providers.  But most of those, 10,000 DNS providers, still have indirect dependencies back to only a handful of top tier providers:  Cloudflare, AWS, GoDaddy, Namecheap, or Oracle - which as we know was formerly Dyn - and a few others.  So for what it's worth, forewarned is forearmed.



And being aware of this is the point.  And after that it's a judgment call.  If anyone is in a truly mission-critical operation, I would argue that the added overhead of maintaining fully separate redundant DNS services is probably justified.  Just if nothing else, choose two different big guys to host your common DNS.  And you know, the amazing thing about the design of the DNS system, back from day one, is that it will automatically and transparently find and use a redundant DNS server.  It's like, that part works really well.  I've spent a lot of time looking at DNS.  The whole DNS spoofability test basically induces the user's computer to send out lots of DNS queries.  And so I've watched how the DNS server that was most recently used receives a single DNS query.  If it doesn't respond within a relatively short time, all the DNS servers that are configured on a system are then sent a copy of that DNS query.



So, I mean, if there's like any stutter in the primary server, the secondary one, I mean, it responds, the system deals with it so quickly that the end-user never has any idea.  So that's of course over on the user side.  Over on the corporate side, you want your sites to be hosted by well-separated DNS so that an outage in either still allows the whole system to continue.  And again, if it doesn't, it's like, if for you, if you were down during that DynDNS day, and all it meant was an unscheduled vacation, then okay.



LEO:  You're not mission-critical, clearly.



STEVE:  Yeah.  Maybe you don't care.  But if you're having a boss who absolutely wants you never to be down, it's just not that big a deal to set up a second DNS really somewhere else because the system beautifully will really use it.



LEO:  I'm pretty sure that's what we do here.  But I'd have to look more deeply.  We use DNS Simple, but I thing we also use AWS.  So we get both.



STEVE:  I don't.  Both of my servers are, you know, I'm at Level 3.  And I don't know geographically if they're separate.  But I'm using two Level 3 servers, so I'm not taking my own advice.  On the other hand, if I had to have an unscheduled vacation day, okay.



LEO:  So it was funny to hear you talk about Alexa as the website ranking company.  I completely forgot about them. 



STEVE:  Yeah, they're still around, yeah.



LEO:  They're still around.  And for a while I think I kind of didn't really trust their results because I think they were basing their measurements on you running an Alexa browser extension, that kind of thing.  But they've, I think, come a long way since then.



STEVE:  I remember in the very early days it was Mark Thompson who put me onto them.  And we used to compare our site rankings back in the day.  Now it's like, oh, you know, whatever.



LEO:  Who cares.  Yeah, remember that was a big deal?  And you'd get, you know, you'd have a little button you'd put, the Top 5% of the Web or whatever it was, on the bottom.



STEVE:  Yeah.  And of course there were only, you know, 27 websites back then.



LEO:  It was easy to do then, yeah.



STEVE:  So, you know, not a big deal.



LEO:  Amazon bought them, and I guess that's where they got the name for their Echo Assistant.  They figured, well, we already own it, so let's just use that.  We don't have to worry about copyright.  So yeah, it's Amazon now.  Which means it probably is - they have a pretty good handle on web traffic, I would imagine.



STEVE:  Yeah, you know, all indications are Amazon is coming on really strong.



LEO:  Yeah.



STEVE:  With their cloud offerings.



LEO:  Yeah.  They own the market; you know?  I mean, Google and Microsoft and Apple and others are trying to get in that market, but there's nobody bigger than Amazon.  They're really dominant.



Mr. Gibson, once again, a fascinating look at the way things work on this thing, this island we call technology.



STEVE:  And how they break when they don't.



LEO:  And how they break, which is a big part of it.



STEVE:  Or they don't when they break or something.



LEO:  Yeah.  They don't work when they break, and they break when they don't work.  You'll find Steve's work at GRC.com.  That's his website, GRC, the Gibson Research Corporation.  And he has lots of great stuff there, including his bread and butter, his one paid thing, which is SpinRite, the world's best hard drive maintenance and recovery utility.  And now I'm going to say the world's best SSD maintenance and recovery utility because you got some benefit just by being a hard drive tool.  But now with these new features, this is really exciting.



STEVE:  Yeah.  You and I are going to look at the output of the benchmark.



LEO:  Big breakthrough.



STEVE:  You're able to look at just the five numbers.  Or you can ask for four levels of granularity where it breaks the - it does a 1GB transfer, and it breaks it down into individual transfers within the whole transfer.  And it just, really, our listeners are going to go nuts.



LEO:  I think you're going to have to change the name, though, to something like Doesn't SpinRite or something, because there's no spinning.



STEVE:  Yeah, SitRite.



LEO:  SitRite.



STEVE:  SquatRite.  I don't know.



LEO:  SquatRite, no.  I'll veto that one right off the bat.



STEVE:  No, it's not good.



LEO:  It's still called SpinRite for historical reasons.



STEVE:  It's going to be SpinRite.  It's just got too much established rep.



LEO:  Oh, and but I think you want people to understand that now it does something for SSDs that you just couldn't do.  I mean, this is really exciting.  I'm thrilled.  Find out more.  Buy it.  Why not?  6.0 is there.



STEVE:  It'll run on Macs, too, by the way.



LEO:  You figured that one out.



STEVE:  Yeah.



LEO:  Recently?



STEVE:  Well, it's got to be a Mac that still has the, what is it, the Boot Camp.



LEO:  Oh, yeah, that's, yeah, so you...



STEVE:  And it's going to - oh, and also only Intel.



LEO:  Yeah, you're going to have a whole new world of Macs out there that you're going to have to figure out.



STEVE:  Yeah.



LEO:  Well, that's 6.3.  Or 2.  Or 7.



STEVE:  Yeah.



LEO:  6.0 is out now.  You'll be getting 6.1 automatically.  And you can participate in its development, as well:  GRC.com.  That's also where you'll find 16Kb audio versions of this show.  You'll also find handwritten transcripts by Elaine Farris so you can read along as you listen.  And he's got the 64Kb audio for those of you with sensitive ears.  That's GRC.com.



We have 64Kb audio plus video at our website, TWiT.tv/sn.  There's a YouTube channel devoted to Security Now!.  You can watch there.  Best thing, subscribe.  That way you'll get it automatically, the minute it's available.  You won't miss an episode.  This is one show you do not want to miss an episode.



We will be back as we always are, Tuesday.  Thanks to Jason Howell for filling in for me last week.  He did a great job.  I'll be back next week with Steve.  We have our "Best Of" coming up later in the month.  That's going to be a lot of fun.



STEVE:  And I'm going to be on the Christmas Special with you guys.



LEO:  Oh, I forgot, yes.  Yes, we decided to do OG Twits this year.  You know, normally we would like to fly you out and all that.  We obviously aren't going to be doing that.  But it's going to be the OG Twits on our TWiT holiday special.  That'll be a lot of fun.  I can't wait for that.  



STEVE:  That's going to be a great group - me, Paul, and Jeff.



LEO:  Yeah, on the 20th.  So make sure you make some time for that one.  Okay.  We do this show at 1:30 Pacific, 4:30 Eastern, 21:30 UTC every Tuesday.  You can watch live, and I hope you will.  Thank you, Steve.



STEVE:  Ciao.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#796

DATE:		December 8, 2020

TITLE:		Amazon Sidewalk

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-796.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  At the beginning of this podcast, you're going to receive some details about another update to Chrome, and news of a few new high-profile ransomware victims.  You'll learn about a breathtaking, remotely exploitable zero-click complete iPhone security compromise, as well as another significant big step forward for DNS privacy beyond DoH.  We'll explain the nature of another serious and probably lingering problem within many Android apps.  I have a few interesting bits of miscellany and SpinRite news to share.  And before this is over, you will have obtained a full working sense for exactly what it is that Amazon has created and why, with their Amazon Sidewalk neighborhood IoT network concept, coming soon to all of your Amazon devices.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, including one of the most breathtaking iPhone hacks ever.  Thank goodness it's been patched.  We'll also take a look at a replacement for DoH known as ODoH.  ODoH.  And Steve's going to analyze the security and privacy model of Amazon's Sidewalk technology.  Should you leave it on?  Steve answers that question next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 796, recorded Tuesday, December 8th, 2020:  Amazon Sidewalk.



It's time for Security Now!, the show where we cover your privacy, your security, how the Internet works and a whole lot more with this guy right here, Steve Gibson.  He's our Explainer in Chief from GRC.com.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again.



LEO:  Nice to see you.



STEVE:  As we cruise into December.  I got my phone.  My phone sent off a warning, talking about the California lockdown.  It was like one of those Amber Alert things.



LEO:  Yeah, yeah.  Don't go outside now.  You've got to stay home.  Stay home.



STEVE:  It's a strange time we're in.



LEO:  We should also mention that now that we're in December, we're getting ready for our Best Ofs.  There will be a Security Now! Best Of in two weeks, on the 22nd.  And then we'll have a brand new show on the 29th.  It's a little weird because of where Christmas is placed.  But also that you're going to be part of our TWiT special, our holiday TWiT on December 20th.  We decided to do OG TWiTsters, the original gangster TWiT team.  So it'll be you.  It'll be Paul Thurrott.  It'll be Jeff Jarvis.  It'll be me.  It's going to be a lot of fun.  And we'll just talk about the year gone by and some of the big stories of the year.  And then of course what's ahead for 2021.  So put your bookmarks in for December 20th for our holiday episode of This Week in Tech.  And then December 22nd for the special Best Of Security Now!.  But meanwhile, what's happening today?



STEVE:  So without question the most tweeted issue over the last few weeks, I mean, even my best buddy sent me a text saying, I just got this letter from Amazon, and this sounds really bad.



LEO:  That's interesting, because I thought people weren't paying any attention to it.  So I'm glad to hear there's some awareness.



STEVE:  Oh, no, no, no.  Well, of course - yeah.  And of course our audience is immediately, like, whoa, what do you mean you're going to be sharing my bandwidth with the neighbors?  How is that a good idea?  So this of course is referring to Amazon Sidewalk, which is the main topic of our podcast.  But we have a lot to cover, some really cool stuff.  At the beginning of the podcast, everybody's going to get some details about another update to Chrome and news of a few, I promise only a few, high-profile ransomware victims that are newly discovered in the last week.  Everybody's going to learn about a breathtaking remotely exploitable, and I know you feel the same way about this, Leo, zero-click complete iPhone security compromise.  And the details of it are fascinating.  We've also got a significant big step forward for DNS privacy beyond DoH.  And I love that this is more than just DoH because that just sounds like Homer Simpson, and we had to somehow get away with that.



LEO:  Now it's ODoH.



STEVE:  We're going to explain the nature of another serious and probably lingering problem with many Android apps.  I have a few interesting bits of miscellany, including as you and I were talking before the show what it is about the Apple M1 processor that makes it so agile with its ability to emulate the x86 Intel instruction set.  I've got a little bit more SpinRite news to share.  We of course were talking about the interesting discovery of timing that the ReadSpeed Benchmark has revealed.  And then we're going to, by the time this is over, everybody who listens to this will have a full working sense for exactly what it is that Amazon has created and why, with their so-called Amazon Sidewalk neighborhood IoT networking concept, soon coming to all of the Amazon devices that people may have or will be getting in the future.



LEO:  Yeah.  And it's opt-in.  You have to opt out.  It's by default turned on.



STEVE:  Right.  Well, so it's not opt-in.  It is you are in...



LEO:  It's opt-out, yeah.



STEVE:  ...unless you opt out, exactly.



LEO:  Yeah.



STEVE:  Well, we'll get into this in detail.  But for what it's worth, I understand what they're doing.  We coined the phrase "the tyranny of the default" a long time ago on this podcast.  If it required people to turn it on, it just wouldn't get off the ground.



LEO:  Can't do it, yeah, yeah.



STEVE:  So it makes sense.  The good news is, just from a standpoint of people questioning whether Amazon is doing the right thing, is that once the system is running, once it exists, when you install a new device, you will be asked one way or the other.



LEO:  Oh.  Oh, that's good.  Oh, that's good.



STEVE:  Yeah.  So it's only coming up defaulting to on for all the existing devices that are out there.  But from then on you will be explicitly asked.  So I think they're doing the right thing.  And as we'll see, they've really nailed in this in terms of the goal of what this is.  You know, 24 hours ago I had no idea.  Now I'm going to explain it all, and everybody's going to know.  And we do have of course a very cool Picture of the Week.



LEO:  Picture of the Week time.



STEVE:  So this is kind of a fun one, just a proof of concept.  You know, no one ever claimed that fuzzing, blurring, or pixelating passwords was secure.  You know, it's something you see often in photos or sometimes in screenshots where they'll, like, blur out something like the IP address or something that you don't want someone to know.  But this was a nice proof of concept because now we have proof that it is decidedly not secure.



This shows three lines of graphics.  The first is pixelized, that is, the result from dramatically reducing the resolution of the screen so that you end up with something very blocky.  But what's obvious to any of us who stop to think about this is that all of the information is still there.  It's just been altered.  So rather than lots of white space and a little bit of lettering, you've got these big blocks.  But they show the average amount of ink under that region.  And so thanks to the fact that text has only a fixed number of letters in its alphabet, there aren't that many possibilities.



So the second line shows their first stage of recovery of the original pixelated text.  And then, I mean, you can just read that.  But then they show the original as what was originally pixelated from.  Anyway, I just thought it was a cool little reminder that some things that look like, it's like, oh, no one's going to be able to figure that out, well, if they have to, I mean, if they really want to, all the information is there.  They just need to get a little clever.  Of course, we're all used to, as techies, the annoying zoom in on the license plate on the TV crime shows.



LEO:  Yeah, center, zoom, center, yeah.



STEVE:  Where the back of the car, you know, the license plate is like four pixels.  And, but, oh, boy, do they have some serious AI because they zoom in on this thing, and then they press the "sharpen" button.  And, yeah, you get the whole license plate back.  It's like, oh, thank you very much.  I wish I had one of those buttons around.  But of course no one does.



A little bit of browser news.  Very little.  Nothing earthshaking happened in the last week.  Chrome did again update its desktop builds, bringing them to 87.0.4280.88.  This closes eight holes that had been discovered by researchers, so nothing critical, nothing zero-day that was actually being exploited.  Just four high-severity problems and then four that were important.  So worth getting.  And this, again, as we know, Google and Chrome are my model for this is the way you do it.  You're notified of problems.  You fix them quickly.  You push them out to the world.  And, I mean, even if they were zero-days, and they were discovered being in use, the best you can do is remove those immediately.  So Google is good at doing that.



It turns out that the world's largest electronics manufacturer, a little company we've all heard of thanks to their relationship with Apple, Foxconn, has recorded revenue last year of $172 billion and over 800,000 employees worldwide.  Well, when you have that many employees, that's just that many more opportunities for someone to respond to a phishing email and click a link that they shouldn't have.  Their massive facility in Mexico, it's 682,000 square feet.  Leo, that's more than a half a million square feet.  That's got to be some serious building.



LEO:  That's big.



STEVE:  Whoa.  Enough to apparently house between 1,200 and 1,400 servers.  I mean, so this must be some serious data facility, as well.  Over the Thanksgiving weekend they got hit by malware.  The DoppelPaymer gang claimed to have encrypted those servers, between 1,200 and 1,400 servers.  They didn't really care about the measly workstations.  They just ignored those.  They first, however, stole 100GB of unencrypted data, then deleted between 20 and 30TB of server backups that they were able to remove.  And they're asking for a pretty penny.  I guess they look at $172 billion in revenue from Foxconn, and they're rubbing their hands together.  Maybe we'll find out what happened.  They wanted 1804.0955 - lord knows where they came up with that number - of bitcoin.  1804, which at today's current rate would...



LEO:  It's the commission, 095.



STEVE:  Just shy, well, it's just shy of 34, I'm sorry, $35 million.



LEO:  Oh, my god.



STEVE:  $35 million.



LEO:  OMG.



STEVE:  And so, you know, they think they encrypted a huge number of servers.  They deleted 20 to 30TB of backups.  There was some comment somewhere that I saw that there were maybe another 75TB they had not been able to get to, to delete, terabytes of backup.  They did, they exfiltrated 100GB of unencrypted data.  So maybe we'll find out what happens with this.  But anyway, there was a big chip that fell.  And I didn't realize, in doing a little digging into Foxconn, that Sharp and Belkin are subsidiaries of Foxconn.  These guys are huge.



LEO:  Yeah, yeah.  Unbelievable.  You saw that the latest trick with ransomware gangs is to call you up, literally, from a call center...



STEVE:  Yes, yes, call you on the phone.



LEO:  ...and say, "We see you're trying to get your data back.  Oh, I wouldn't do that if I were you."  These people are getting bolder and bolder and bolder.  $35 million.  Unbelievable.  Do you think Foxconn will pay?



STEVE:  It'll be interesting to see if we ever get a follow-up on that.  I mean, I'm sure that they're juggling their options.  Any of these companies are going to respond rationally.  So they're going to look at what got taken.



LEO:  Yeah, it's a business decision, yeah.



STEVE:  Pure business, from a pure business model.  How down are we?  It apparently did not get out of this one facility.  So maybe they just can go, oh, yeah, so one warehouse is in trouble.



LEO:  That's a lot of ransom.  That's such a huge amount that you've got to think...



STEVE:  That is, I really - and I think this plays off of what you were just saying about how bold these guys are getting.  Maybe they're also getting a little too cocky.  It's like, yeah, these guys are big.  Let's get $35 million.  And it's like, okay.



LEO:  The world's got to crack down on this. 



STEVE:  There must be some formula, like how many servers you encrypted times something gives you X bitcoin?  Because, like, where would they come up with 1,804.0955 bitcoin?  It's like, what?  Why not just 1,800?



LEO:  Yeah.



STEVE:  So, wow.



LEO:  So weird.



STEVE:  Meanwhile, Huntsville, Alabama City Schools district, which in 37 schools educates nearly 24,000 students, they were forced to send a note to the parents saying students, families, and faculty and staff should shut down their district-issued devices and ensure the devices remain off until further notice.  Additionally, stakeholders should avoid logging on any HCS, Huntsville City Schools, platforms at both home and school.  Yes, they were also a victim of ransomware.  As was the Metro system in Vancouver.  They were knocked offline by the Egregor ransomware, and all of the transit services printers began spitting out ransom demands.  As we know, that's another new tactic that's being taken by ransomware to essentially shame the victim into paying by making it more difficult for them to keep the news quiet.  Oh, and Egregor also got Kmart.  Apparently Kmart is already struggling.  It looks like the retail side didn't get hit.  Apparently it was their backend systems.  But they were hit by ransomware.



And lastly, a large online education company by the name of K12 Inc. has decided to pay a ransom.  They were hit by Ryuk ransomware in the middle of last month, in the middle of November.  They provide tailored online teaching curriculum for more than a million students that have used this K12 system.  Anyway, their concern is the privacy problem.  The Ryuk guys got into some back office systems that contained student data and other information.  So they decided to pay up in the hopes that, first of all, they were insured, so they weren't bearing the full brunt of that cost.  We don't know how much ransom they are paying or have paid.



But they're going to take the Ryuk crooks' word for their promise that they will not release the confidential data that the bad guys were able to obtain from their systems, and so they're going to cross their fingers and hope for the best there.  So yes, just to kind of keep it on everyone's radar, ransomware is the scourge of the security industry at the moment, or certainly one of.



The Apple iPhone vulnerability story is interesting.  And last week in a lengthy and painstakingly detailed 30,000-word report, which was written by Google's Project Zero's Ian Beer - Ian is someone whose work we've covered through the years, so his name  may be familiar to our listeners.  We learned, thanks to this report that Ian wrote, how he had spent the first half of this year.  Yes, six months.  But before explaining, Ian quotes from the February 2020 Offensive Con conference, during which its keynote speaker said:  "Exploits are the closest thing to 'magic spells' we experience in the real world.  Construct the right incantation, and gain remote control over a device."



So with that quote, this opens Ian's expos, which he began by saying:  "For six months of 2020, while locked down in the corner of my bedroom surrounded by my lovely, screaming children, I've been working on a magic spell of my own."  He says:  "No, sadly not an incantation to convince the kids to sleep in until 9:00 a.m. every morning, but instead a wormable radio-proximity exploit which allows me to gain complete control over any iPhone in my vicinity."  He said:  "View all the photos, read all the email, copy all the private messages, and monitor everything which happens on those phones in real-time."



So in other words, in the midst of distractions from his screaming kids, he successfully discovered and then fully developed a working, remote, over-the-air, zero-click, total compromise of any Apple iPhone.  And doing so was pretty much everything that Apple, as we know, has gone to such extremes to first totally prevent; or, if failing that, then to at least raise the bar of exploitation engineering so high as to make it incredibly difficult to weaponize.  Yet Ian succeeded.



In his own words, describing the situation, he wrote:  "Of course, an iPhone isn't designed to allow people to build capabilities like this.  So what went so wrong that it was possible?"  He said:  "Unfortunately, it's the same old story, a fairly trivial buffer overflow programming error in C++ code in the kernel parsing untrusted data, exposed to remote attackers."  He said:  "In fact, this entire exploit uses just a single memory corruption vulnerability to compromise the flagship iPhone 11 Pro device.  With just this one issue, I was able to defeat all the mitigations in order to remotely gain native code execution and kernel memory read and write."



He said:  "Relative to the size and complexity of these codebases of major tech companies" - like Samsung, Google, Apple, Amazon, any of the big guys - "...the sizes of the security teams dedicated to proactively auditing their product's source code to look for vulnerabilities are very small."  He said:  "Android and iOS are complete custom tech stacks.  It's not just kernels and device drivers but dozens of attacker-reachable apps, hundreds of services, and thousands of libraries running on devices with customized hardware and firmware."  And in fact a little bit later we'll be talking about one particular library over on the Google side.



So in other words, with today's massive custom codebases, and more focus naturally being placed upon the fun side of designing and shipping new features over the drudgery of examining code for vulnerabilities, it's inevitable that these systems will incorporate a wide range of flaws of varying severity.  You know, everyone knows that, generically, bugs of all kinds are being patched constantly.  That's, you know, every second Tuesday is a Patch Tuesday, and Microsoft fixes a hundred-plus bugs of varying severity.  So sobering though it is, it should come as no surprise, and it doesn't, that some of them, some few will be really bad.



Now, the good news is that this is Apple, not Android.  So the handsets were all updated back in May with the move to iOS 13.5.  And that's, as you noted over on MacBreak Weekly, Leo, the same update that gave us the COVID proximity tracking tech, that was back then in May.  So at that time this breathtaking vulnerability was quietly eliminated.  It wasn't, as far as we know, ever used.  But of course you never do know about these things.  You know, the fact that it was there raised some questions in Ian's mind, which we'll talk about.



LEO:  I think a nation-state might well have had - one of the reasons I think this is - it seems like a natural place to investigate.  You're going to talk about the exploit.  I won't talk about it.  But that's where I would have looked, too.



STEVE:  Yes.  The heart of the problem that Ian uncovered was in a proprietary Apple WiFi-based peer-to-peer mesh network protocol, again of their own design, known as AWDL, Apple Wireless Direct Link.  Being a peer-to-peer mesh protocol handler, AWDL needed to monitor and parse all WiFi network traffic.  Parsers are a form of interpreter in that they examine a flow of data for the purpose of attempting to understand it and to see whether it's relevant to them.  What Ian uncovered was that Apple's AWDL parser contained a flaw.  Knowing that, and arranging to exploit it in the environment that Apple has deliberately worked to make so hostile, are two very different things, but Ian succeeded.



And I should note that his paper, I mean, his write-up is just amazingly thorough.  It is a step-by-step walk through what it takes to do this.  And I would commend it - I have a link in the show notes - commend it to anyone who's interested in like how you go with Apple against all the mitigations that they have put in place, everything that they have done to, like, okay, even if you knew there was a problem, sorry, you can't get to it from here.



Ian noted that he is one guy who was working alone in his bedroom, albeit with some distractions; whereas the world currently contains, to your point, Leo, many powerful, massively resourced, nation-state, well-organized cyberwarfare groups.  Ian feels quite certain that when such resources are brought to bear, other currently unknown exploitable vulnerabilities, maybe this one before he found it, will almost certainly be and maybe are being right now uncovered.



So anyway, no need to go into great detail.  But the point was that, to your point, Leo, here is something that is having to listen, to look at WiFi packets.  Ian referred to them earlier as untrusted, meaning that they're not data packets wrapped in a WiFi envelope where you've already established a connection.  In order for this peer-to-peer system to work, things that just wander into range, where you're not exchanging a username and password, you're just accepting a connection among peers, inherently something is like sending out a beacon, and something is listening to all incoming traffic to see if it's a beacon.



And it turns out that he was able to - the iOS kernel has all of its symbols stripped.  And symbols are a huge benefit to understanding what's going on.  It turns out the macOS doesn't.  It does not, this region at least, doesn't strip symbols.  Which is very much more useful for developers who need to trace into something.  Or if something crashes, you're able to get a sense for where the crash was.  And it turns out macOS and iOS share the same AWDL.  So he was able to identify the problem, use the symbols macOS had to give him a leg up, and then map that over onto iOS.  Although he still had to perform the job of exploiting this, you know, turning it from a known vulnerability into a weaponized exploit.  Again, especially in the world that Apple has created to make that well nigh impossible, he was able to do it.  So really, really, really cool piece of research.



LEO:  Yeah, I think if you were going to look somewhere, you'd look at AirDrop and say, hmm, that's promising.



STEVE:  Well, yeah.  You would, I mean, depending upon your attack model, if you could briefly get your hands on the phone, then you look at the lightning connector, right, to see what you're able to do there.  But, boy.  And you made the point over on MacBreak Weekly that, I mean, this is wormable, meaning that...



LEO:  That's a big problem.



STEVE:  ...the contagion could spread.  Which meant, I mean, if somebody wanted to bring down the entire Apple iOS, at least iPhone ecosystem, they could have launched a worm into an environment.  This thing would have jumped from phone to phone everywhere.  I mean, like stick it, you know, start it off in a stadium, and every iPhone will be infected.  Those will then, at the end of the game, spread out all over and infect all the other iDevices within WiFi range.  I mean, and it's, like, you could have shut down iPhones globally, potentially.  So that didn't happen because Ian Beer works for Project Zero.



LEO:  Also because nation-states aren't real anxious about sharing their exploits either. 



STEVE:  Exactly. 



LEO:  So if Israel or Iraq or Iran or North Korea had it, they wouldn't have told anybody.  Or the NSA.  They wouldn't have told anybody.



STEVE:  Well, yeah.  And you have to wonder if, when this happened in May, there may have been some people here or abroad saying, ooh, you know, darn.  Somebody else found the thing that we had been using in order to just beautifully infect targeted iDevices wherever we wanted to.  So but again, look at the number of bugs that are constantly being fixed.  As I said, every so often there's a really bad one.  Well, that really bad one has been there typically for a long time.  So I think, you know, we spend a lot of time talking about this or that thing that got fixed and, whew, isn't that good?  But maybe the same guys are listening to the podcast going, yeah, Gibson, you just keep thinking that that's, you know, that we're in trouble now.  We don't care.  We have 12 others that allow us to do this.



Okay.  As I said before, I am so happy that DoH is not in the future what we're going to be talking about.



LEO:  Doh.



STEVE:  Because, yeah, exactly.  Now we have ODoH, O-D-O-H.  And you would be forgiven if you thought that ODoH stood for the Ohio Department of Health.



LEO:  Which it does, actually.



STEVE:  Which it does.  I googled ODoH.



LEO:  And that's what you found.



STEVE:  To see what else would come up.  And Ohio Department of Health was the first thing I got.  But I would not be surprised, if this thing gets traction and takes off, if they don't drop down Google's search results eventually because ODoH could be the thing.  We all know about DoH, D-O-H.  And if we choose to use it, it provides end-to-end encryption between our browsers, and also more recently our entire operating system, and a remote DoH-capable DNS resolving service.  As we know, by reusing the existing and quite mature certificate and protocol technologies of HTTPS, it very nicely does what it was designed to do.  It strongly prevents any local agency such as someone monitoring a hotspot or our local ISP from observing our DNS queries.  With DoH running, they see encrypted traffic that they cannot get into, and nothing else.



But there's still been one glaring privacy flaw in DoH.  It doesn't prevent the DoH service from knowing who's querying DNS and for what.  Since the DoH IP connection is point-to-point, the DoH resolver still knows the IP making the query and what domain they're querying for because it decrypts the encapsulated encrypted query in order to provide the answer.  So your local ISP may no longer know, but the person you're asking still does.



This is the problem that the new Oblivious, as it's called, it's Oblivious DNS over HTTPS, has been created to resolve.  And the solution is elegant because it's so simple.  Simply introduce a connection-forwarding middleman into the point-to-point link.  Add a third-party proxy which is unaffiliated with the DoH provider.  Then the user's connection to their DoH provider routes through the proxy, which in turn forwards the still-encrypted traffic to the user's chosen DoH provider.  Since the encryption is still encrypted end-to-end, from the user to the DoH provider, the proxy cannot see anything, can't see into the traffic at all.  So although it does know who's asking, it's completely blind to what they're asking for.



The DoH provider in turn, which decrypts the incoming traffic, knows exactly what the incoming connection is asking for.  But now it has no idea from whom the request has come, since it's receiving anonymized requests that have been forwarded to it through the intermediate proxy.  So it's beautiful.  I mean, it just adds an additional stage of blinding, just to the connection IP.  And already DoH had no deanonymizing information in it.  The actual query is just a DNS query, so there was nothing in the packet that needed to be sanitized.  We just need to sanitize the IP connection address.  And so routing the connection, the DoH connection through a third party, just a simple connection proxy, does it.



The concept has been co-developed by Cloudflare, Apple, and Fastly.  It was announced this morning by Cloudflare.  They already have a trio of qualified and fully independent privacy-committed ODoH proxy providers, and ODoH's formal specification is already moving forward through IETF standardization.



Eric Rescorla, who's currently the Chief Technology Officer, the CTO of Firefox, said:  "Oblivious DoH is a great addition to the secure DNS ecosystem.  We're excited to see it starting to take off and are looking forward to experimenting with it in Firefox."  And if any of our listeners really needed, for some reason, or wanted to be on the bleeding edge, it's technically possible to get ODoH working today.  But at the moment it takes jumping through a bunch of hoops.  And given the speed at which DoH appeared and became widely available, and how simple this addition is, I have the feeling that flipping a switch to enable ODoH isn't far away.  So I don't think people will have to wait very long.



LEO:  I'm sure Firefox and, because it's Apple, Safari will support it pretty quickly out of the box.



STEVE:  Yeah.  So Google Play Core Library problems.  Google provides Android app developers with a component called the Google Play Core Library.  The Android developer docs describe this component library by saying:  "The Play Core Library is your app's runtime interface with the Google Play Store.  Some of the things you can do with the Play Core include the following:  download additional language resources, manage delivery of feature modules, manage delivery of asset packs, trigger in-app updates, and request in-app reviews."



So it's an API, essentially, interface to the online Google Play Store that allows apps to interact with the various Play services from within the app itself.  So you could dynamically load additional code, additional levels of the game as needed, maybe pool locale-specific resources and of course interact with the review mechanisms.  And since this is the officially sanctioned and recommended way to do this, many popular, I would argue well-designed, Android apps utilize this library.  Those include Google's own Chrome, Facebook, the Android Facebook app, the Instagram app, WhatsApp, Snapchat, Booking, and even the Edge browser.  Facebook and Instagram alone account for five billion and one billion downloads respectively.



So just imagine the total number of Android apps worldwide that have historically incorporated this library at Google's behest.  And it's the right way to do it.  If your app has some need to interact with the Google Play Store after it's been downloaded and installed, this is the officially sanctioned way to do it.



Okay.  So the problem is a quite serious bug was discovered inside this very widespread common app library.  And because the library is linked into Android apps to become part of them, this isn't something that Google can fix with an Android update, even for those Android smartphones that would be receiving updates.



So what's the bug?  I'll quote the company with the oxymoron name "Oversecured" since this was their discovery.  They explained:  "The Google Play Core Library is a popular library for Android that allows updates to various parts of an app to be delivered at runtime without the participation of the user, via the Google API.  It can also be used to reduce the size of the main APK file by loading resources optimized for a particular device and settings - localization, image dimensions, processor architecture, dynamic modules, that all sounds really cool - instead of storing dozens of different possible versions."



They said:  "The vulnerability we discovered made it possible to add executable modules to any apps using the library, meaning arbitrary code could be executed within them.  An attacker who had a malware app installed on the victim's device could steal users' login details, passwords, and financial details, and read their mail."



So again, a well-meaning high-volume app installed on an Apple smartphone, I mean, I'm sorry, Android, on an Android device, it's got this library.  The library has a bug that allows any other app in the phone to utilize the bug to cause the well-meaning app to download whatever the bad guys want.  So essentially it allows any malicious app to penetrate Android's critical inter-app sandbox which exists solely for the purpose of isolating apps from each other to prevent them from accessing each other's stuff.  And although Google knew about this earlier this year, and immediately patched the vulnerability back on April 6th of 2020, apparently not all developers received the memo.



Check Point Research took a look at this just last week and explained what it means.  They said:  "When we combine popular applications that utilize the Google Play Core Library and the local code execution vulnerability, we can clearly see the risks.  If a malicious application exploits this vulnerability, it can gain code execution inside popular applications and have the same access as the vulnerable application.  The possibilities are limited only by our creativity."



They said:  "Here are just a few examples:  Inject code into banking applications to grab credentials, and at the same time have SMS permissions to steal the Two-Factor Authentication codes.  Inject code into Enterprise applications to gain access to corporate resources.  Inject code into social media applications to spy on the victim and use location access to track the device.  Inject code into Instant Messaging apps to grab all messages, and possibly send messages on the victim's behalf."



Anyway, we get the point.  It's bad.  And in their proof-of-concept demonstration, Check Point used a malicious app to steal a login authentication cookie from an older version of Chrome which was built using the original library.  Once in possession of the cookie, of course, now you can do session impersonation; right?  The attacker was then able to gain unauthorized access to a victim's Dropbox account.  So as I noted earlier, the library was updated back in April, eight months ago.



But last week Check Point identified 14 apps having combined downloads of nearly 850 million that are still vulnerable today, eight months later.  Within a few hours of their publishing their report, the developers of some of the named apps had released updates that fixed the vulnerability.  It only took them eight months public shaming and some outcry.  Check Point analyzed the Google Play Store contents and found that, overall, as of September, so a couple months ago, 13% of all Google Play applications used the Play Store Library.  So they were well written.  That was the right thing to do.  And of those, 8% were still using a vulnerable version of the library.



So, yeah, that's far fewer than all apps.  But it turns out that a few of them have massive download counts.  Like Microsoft's Edge for Android that was and perhaps still is vulnerable.  The specific 14 which were just those that they chose because they were popular and had high download counts, this was Check Point:  in the social category, Viber; the travel app, Booking; the business app, Cisco Teams; maps and navigation apps, Yango Pro (Taximeter), and also Moovit; the two dating apps, Grindr and OKCupid; Microsoft's Edge browser; and the two utilities, Xrecorder and PowerDirector.  All using, as of last week, vulnerable versions of the library.  Several of them have been fixed since.  But wow.



All the apps were written to do the right thing, to use Google's recommended library for interfacing with the Play Store after the app had been downloaded and run.  But their developers had not kept them updated when critical core flaws were discovered and fixed.  That's the mistake that they were caught making.  And you can't blame it on anybody.  Libraries need to be updated.  Of course we know that, what, a few months ago Google found the zero-day in their browser which was being used to leverage the flaw in the widely used font library.  So, you know, developers who are packaging, who are bundling libraries, are responsible for making sure that those get updated when necessary.  And this just hasn't happened.



So unfortunately, while, yeah, the big names, this will come to their attention, and they'll quickly scurry around.  I mean, all you have to do is rebuild the app using the new library.  So it's not like it's going to be a heavy lift to get this problem fixed.  But 13% of apps in the store are using this thing, and 8% of those.  And we know there are many apps in the Google Play Store.  So they will probably, many of them, never be updated.  They will remain vulnerable and always be creating a known vulnerability for their users.  If bad guys happened to know that a targeted individual had one of those apps installed, or maybe even arrange to get one of those apps installed, if they didn't already, it would then open them to vulnerability.  So anyway, it's an interesting twist, a widespread collection of apps, themselves containing a common vulnerability as a consequence of once having been built with a library that was later found to be vulnerable.  And no one's in a big hurry to fix it.



Oh, one thing that I forgot to mention in my coverage last week of the Tesla Model X key fob hack.  A friend of mine brought it to my attention.  I thought it was really poignant.  This was something that Lennert Wouters was quoted as saying in some other coverage.  He said of the Tesla Model X key fob:  "The system itself has everything it needs to be secure.  But there were just a few small mistakes that allowed me to circumvent all of their security measures."  I thought that was neat.  So it wasn't at all that they hadn't taken security seriously.  They had good security people doing a good job designing the security for the system.  But they made a couple little mistakes.  And that created a crack that Lennert was able to get in through.



LEO:  That'll do it.



STEVE:  Yup.  And Leo, I know you, I mean, you just can't stop talking about the miracle Apple M1 Arm processor chip.



LEO:  Oh, man.  I just love it.  It is, well, the thing that's surprising, and at first I was a little disgruntled because a lot of the things I wanted to use wouldn't work on it.  But that's changing very, very quickly.  Mostly it's just changing as soon as people get an M1, and then they go, oh, I need to switch this and this and this, and it's working.  So, boy, is it fast.  It's really remarkable.



STEVE:  So, and one of the things that people have remarked about is that it is arguably a better processor for running Microsoft Windows than Microsoft's own solutions.



LEO:  Yeah.  It's easily the speediest Arm chip out there.  But most Arm chips up to now have been built for low power.  And so this is - they're doing some amazing stuff with this.



STEVE:  So actually the same friend who brought the Lennert Wouters note to me shared with me using Thread Reader a thread that he found from somebody who was knowledgeable about what Apple did.  The thread reads:  "In case you were wondering, Apple's replacement for Intel processors turns out to work really, really well.  Some otherwise skeptical techies are calling it 'black magic.'  It runs Intel code extraordinarily well.  The basic reason is that Arm and Intel architectures have converged.  Yes, the instruction sets are different.  But the underlying architectural issues have become very similar.



"The biggest hurdle was memory ordering, the order in which two CPU cores see modifications in memory made by the other.  It's the biggest problem affecting Microsoft's emulation of x86 code on their Arm-based Surface laptops, with the result being high x86 emulation overhead.  So Apple simply cheated.  They added Intel's memory ordering to their CPU.  When running translated x86 code, they switch the mode of the CPU to conform to Intel's memory ordering.



"With those underlying architectural issues eliminated, running x86 code simply means translating those instructions into their Arm equivalent.  This is very efficient and results in code that often runs at the same speed.  Sometimes there isn't a direct equivalent.  So the translation results in slightly slower code.  But benchmarks show x86 being consistently at least 70% of the speed.  In any case, a surprising number of apps already run.  Apple seeded developer systems a few months back, allowing people to get their code ready.



"Normally, that wouldn't have been enough time.  When you recompile code for a new architecture, it usually breaks."  He says:  "But as I said above, Arm and Intel architectures have converged enough that code is much less likely to break, making recompiling easier."  And then he finishes:  "Apple has made surprising choices.  They've optimized JavaScript, with special JavaScript-specific instructions..."



LEO:  In hardware.



STEVE:  "...double-size L1 caches."



LEO:  Wow.



STEVE:  Yes, very smart.



LEO:  That's why my browser is so fast.



STEVE:  Exactly.



LEO:  It's amazing.



STEVE:  He said:  "And probably other tricks I don't know of.  Thus, as you browse the web, their new laptop will seem faster and last longer on battery because JavaScript has become far more efficient, even though other benchmarks show it roughly the same speed as Intel/AMD."  So again, Apple did some very, very clever things.



I also wanted to mention that a few months ago I told all of our listeners about the Windows app InitDisk which I had created along the way to - I needed updated USB prep technology for SpinRite, and I would also be needing that for the ReadSpeed Benchmark to allow people to easily create a bootable thumb drive that they'd be able then to boot their system with in order to use ReadSpeed to check the performance of their drives.  Since last week's podcast I finally finished all of the low-level driver and benchmark work, and I produced two release candidates.  The second one appears to be final and finished.  And actually I just made a tweak this morning since I got the podcast ready, and I was waiting for MacBreak Weekly to finish.  So there will be another little tweak.  But it's, I mean, basically it's done.



Two people had found two problems with InitDisk, so I fixed both of those.  One was a finicky security permissions problem that only manifested under Windows 10.  Fixed that without too much work.  The other was weird.  He was using it on a 1GB USB stick, and InitDisk was selecting 512-byte sectors.  I mean, 512-byte clusters, you know, single-sector clusters.  That's legal, and it got a lot of testing and never had any problem, but this one guy's BIOS didn't want to boot a USB that had been prepped that way.  So I fixed that, too.  I set a lower limit of a 4K cluster, which is actually part of the FAT32 spec.  So it now does that.  That fixed his problem, and his system now boots.  So anyway, for anyone who's interested, there is now a release 2 of InitDisk over at GRC, and everybody will be getting the benefit of that shortly when they play with ReadSpeed.



And speaking of ReadSpeed and SpinRite, I am pretty sure that next week's podcast will announce that the long-awaited benchmark is ready for use and testing by everyone.  I am really close to it.  The DOS-based drivers and benchmarking code is finished.  Now I'm working on the packaging of it into a version, essentially a version of InitDisk that doesn't just format and install FreeDOS, but also installs a turnkey "Just Press Enter" ready-to-run benchmark.  And actually most of that is already finished, as well.  Over the weekend I released a first proof-of-concept Windows app which works.  So I'm just in the process of getting it polished up.



But Leo, I wanted - we were talking about the read performance measuring last week.  I've got two shortcuts.  I'd like if you would to bring up the first one.



LEO:  Sure.



STEVE:  You can just click on the link in the show notes, or it's grc.sc/796.



LEO:  Ooh, it's tiny.



STEVE:  You'll probably need to zoom in on that.



LEO:  Need to zoom in, yeah.



STEVE:  So that first one is the verbose output from the benchmark.  A lot of that stuff will only be of use if I'm diagnosing a problem.  The second to the last big table shows - and this is on my grueling test machine.  I have 11 different drives with all makes and models of controllers and things, in order to give this a real workout.  So it shows the PCI bus location of everything, the BIOS's drive identification, then the type of device it is - SATA, IDE, or RAID.  A bunch of PCI information.  The port that it's on, SATA port or master or slave.  Which hardware interrupt line that controller has hooked.  And then some addressing information.



And here's one of the cool things.  You can see in that first table, the top line?  It says, under drive, it says <6.0> with little brackets around it.  That's because it's noticed that you've got a 6Gb speed drive hooked to a 3Gb SATA link.  Meaning that that drive could potentially perform faster if you stuck it on a SATA III 6Gb link.  It displays that information and calls it out sort of subtly there, when you use the verbose mode.  But if you just do nothing, and it sees that you do have a mismatched drive speed and SATA link, it specifically spells it out in English for the typical user who's doing that.



Then the last table there is the actual benchmark, where you can see 11 drives enumerated.  It shows the size of the drive, the drive's identity - you know, Samsung SSD 860 EVO 250GB.  And then there's, for each drive, five different locations, the measured performance of the drive.  And again you can see how very stable.  The Samsung shows 273.9 at the 0% location of the drive, then 274.0, 274.0, 274.0, 274.0 all the way across the drive.  So first of all, the drive itself is very stable.  But this benchmark is resolving four significant digits with perfect accuracy.  One thing you'll note, if we look at like Drive 82, it's an SSD, but the 0% column, the front of the drive, shows 72.1, this is in megabytes per second; whereas the rest of the locations at the 25, 50, 75, and 100% locations are up at its normal speed of 174.9.



Okay.  So now let's look at the second of these links, grc.sc/796a.  This is the result of adding a /1 after the ReadSpeed executable.  It breaks down the large - in every case we're timing the length of time required to transfer one gigabyte of data.  So first, if looking at the drive number on the far left, Leo, if you scroll down to 89, that's just my favorite because it demonstrates how solid this benchmark is.  That's 115GB OCZ-Vertex2 drive, Drive 89, if you scroll way down.



LEO:  Oh, okay.



STEVE:  You'll see the, yeah, 81...



LEO:  Yeah, yeah, yeah.  I just was looking at the single line.  Okay, here we go.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Now, look at those numbers.



LEO:  Very rock solid, huh.  Wow.



STEVE:  And so this is a solid-state drive, and every single one of them, with the exception of the very first one, but the other at 64 times five columns, 275.8 MBps.  So just solid.  The really interesting thing is if you scroll up and look at 82.  Here's an example.  This is an SSD.  This is the one that Allyn and I were talking about in our email correspondence, where you can see, whoops, now, here's a problem.  This thing...



LEO:  Look at this, as low as six.



STEVE:  Yeah.  It's nominally - and even 3.4 and 3.6.



LEO:  Geez.



STEVE:  So what's interesting to both of us, and will be to our listeners because, I mean, you'll be able to look at all of your drives like this.



LEO:  Can't wait.



STEVE:  Like something has brought this thing to a near standstill.  And in fact there is of course a progress bar on the screen as the benchmark is running.  And so you see the bar moving along, and then it just stops.  But it doesn't produce an error.  It just stops.  And it takes a long time, and then it says, oh, and then off it goes again.  So what we conjecture is, as I mentioned last week, that clearly this is a spot that this drive is having a serious problem reading.  Like nothing else, nowhere else on the drive is there this problem.



So the thing that is tantalizing about this is to see whether rewriting that location will, you know, it might induce the SSD to remove it from service when the SSD has the opportunity to.  Allyn noted that SSDs do not do their own rewriting, unlike hard drives that do.  So it needs stimulation in order to do that.  Or is the problem that the bits in a multilevel cell have drifted a little bit, "charge drift" as Allyn termed it, so that it's necessary to like put much more effort into reading them, and does that suggest that if they're allowed to drift even further, then it could become uncorrectable.  Or does this suggest that this is not a very high-end SSD?



And so they just didn't expend any hardware on error correction.  And so instead it's dropping into an algorithmic error correction figuring, well, the guy would rather wait than have, like, no data returned.  So we're going to do ECC.  Anyway, this does create a bunch of questions.  But it certainly does say, first of all, that this is a microscope the likes of which we've never had before into the detailed performance of something that we just take for granted, you know, solid-state drives.  And it suggests that a future SpinRite is going to be able perhaps to do a lot of preventative maintenance.



And as I mentioned last week, if you look at some of those numbers, 544 MBps is what this thing is obtaining in sustained transfer, which means that a half a terabyte drive, a 500GB drive can be scanned in a little over 15 minutes.  So that's about twice the performance I was expecting.  That means that 1TB in about half an hour, or 2TB an hour.  So this thing suddenly becomes practical to use as a preventative maintenance tool.  So anyway, very excited, and I expect to be announcing it next week.



LEO:  Sidewalk.  I'm really glad you decided to go deep on this.  I'm fascinated.  And I don't know what to think, to be honest.



STEVE:  Exactly.  And believe me, the press is in the same plight.  As I mentioned at the top of the show, Amazon has created quite a stir by sending letters to their customers who own compatible equipment.  My buddy is like Echo happy.  He's got them all over the place.  And the letter informs them that they will be automatically opted in to Amazon's forthcoming Sidewalk program.



Now, for anyone objecting to auto opt-in, you know, as we were talking about it before, I get it, I mean, like, why it makes sense for Amazon to do this.  But we know our listeners are special.  If you update today, your smartphone's app, even before Sidewalk goes live, you may preemptively disable your network's use of Sidewalk.  So my point is that - I just said the "A" word, I realize.  Hope I didn't trigger everyone's devices.  So it should be already there in Amazon's app for their devices, and you should be able to disable Sidewalk preemptively.



Okay.  In any event, their announcement has been met with no small degree of questioning, confusion, and concern over the propriety and the security of what they're doing.  The tech press has been carrying stories with headlines like, well, in fact, this is Fox Business said:  "Amazon to opt-in customers with Echo, Ring devices to new Sidewalk WiFi sharing feature."  And as we'll see, that's not quite true since it's not WiFi sharing.  But everyone here will know everything about it by the end of the podcast.



LEO:  It's LoRa.  LoRa.



STEVE:  Mashable was taking no prisoners.  They said:  "How to see if Amazon is stealing your Internet bandwidth for Sidewalk."  WGN-TV said:  "Got an Echo or Ring?  Soon Amazon will use them to share your Internet with a new Sidewalk network unless you opt out."



LEO:  Yeah, I think a lot of this is misleading.



STEVE:  CNET:  "Amazon Sidewalk has automatically switched on in your Alexa app.  It might be time to check your settings, if you have an Echo smart speaker or Ring camera."  TechHive:  "Welcome to Amazon Sidewalk.  Now, here's how to turn it off."  And Gizmodo was the least charitable:  "You Need to Opt Out of Amazon Sidewalk."  That was the headline of their story.  Then they said:  "Have you heard of Amazon Sidewalk?  Probably not.  But there is a good chance that you or someone you know has an Amazon Echo or Ring camera.  And if you own one of those devices and live in the U.S., or know someone who does, you need to tell them to opt out of the service as soon as possible."



So for what it's worth, I replied to my best friend, and I said, "You know, Mark, I don't think you need to turn it off."  And we'll see, of course, that's a matter of personal taste, but I will tell everybody exactly what this is about.



Okay.  So taking a deep breath, I have the 13-page Amazon Sidewalk Privacy and Security Whitepaper.  So this answers all the questions, at least in terms of design and intent.  As we know, you can't answer questions about execution.  It'll take security researchers and academics poking at it and analyzing it more deeply to do that, and time.  But let's begin by looking at Amazon's description and their hopes for what this is and why they think it's a good idea to do this.  And this is not brand new.  The news is that it's about to be unveiled.  But this description is dated more than a year ago, on September 27th, 2019.



Okay.  They said:  "Get connected convenience beyond your front door.  Many of the smart devices in our homes today rely on Bluetooth and WiFi connections to stream music to a nearby speaker or help a video doorbell notify us when a package is delivered.  But these connections only extend so far.  On the other end of the spectrum, 5G cellular is incredibly important when you need reliable, long distance, guaranteed delivery of data, but it can be complex.  In the space around homes, that leaves a middle ground for devices like sensors and smart lights that can benefit from low-cost, low-power, low-bandwidth connections."  So they're sort of setting this up as something between local WiFi and 5G, or whatever cellular.



They said:  "Customers shouldn't have to settle for connected devices that lose functionality past the front door, which is why we're excited to introduce Amazon Sidewalk.  Amazon Sidewalk is a new long-term effort to greatly extend the working range of low-bandwidth, low-power, smart lights, sensors, and other low-cost devices customers install at the edge of their home network.  Using the 900 MHz spectrum" - okay, so there's a big difference right there.  This is not a WiFi frequency.  Ham radio operators like you, Leo, know this as the "33-centimeter band."  Anyway:  "Using the 900 MHz spectrum, we are developing a new protocol we project can increase the connection range of these devices by more than one half mile/one kilometer."



LEO:  That's why you don't use WiFi.  It's too high-frequency.  It stops, 150 feet, yeah.



STEVE:  Correct, correct.  And 900 MHz has really good building penetration.



LEO:  Absolutely, yeah, yeah, yeah.



STEVE:  But at a cost of bandwidth.  If the carrier is a lower frequency, you can't modulate it that quickly.  And in fact, there is an incredibly clever modulation scheme known as LoRa we'll get to in a second which uses chirps, chirping up or chirping down, which, well, anyway.  We'll get there.



They said:  "With Amazon Sidewalk, customers will be able to place smart devices anywhere on their property and know they'll work great, even in dead spots where WiFi and Bluetooth won't reach.  Using the 900 MHz spectrum to help devices communicate is not new.  In fact, it's been around for decades, providing reliable secure connections for long-range devices like the radios used by emergency services and the digital pagers carried by doctors on call.  It's by combining this tested communications network with an innovative new protocol developed by Amazon that we arrived at Sidewalk, a new way for the next generation of low-cost, low-bandwidth sensors and smart devices to work together to create a secure network of long-distance connections bridging the connectivity gaps around our homes.



"The immediate benefit of a 900 MHz-based network is the ability to use your favorite connected devices even if they're located far away from the router inside your home.  Today, Ring Smart Lighting Bridges use connections in this spectrum to extend the range of smart lighting products, and soon additional devices including the latest generation Ring Floodlight Camera and Ring Spotlight Camera will also help customers extend the network connections around their homes and control those 900 MHz devices at much greater distances.



"Better network connectivity can also help keep devices safe and up to date.  Today, when customers place a smart device at the edge of their home network, poor network connectivity can prevent that device from receiving important feature and security updates.  By extending long-range, low-bandwidth connections using the Amazon Sidewalk network, customers won't have to worry about smart devices that don't have access to the latest security updates or work as intended because they're out of network range.



"In the near future, we also see the potential to help customers get more from 900 MHz connections in their neighborhoods, creating a broad network among neighbors that can be used to extend connectivity all the way to your mailbox out at the street where a smart sensor lets you know exactly when your mail has been delivered, or to a water sensor that lets you know it's time to water the garden in the backyard.



"For example," they said, "just a week ago" - now, this is a week ago a year ago - "Amazon employees and their friends and family joined together to conduct a test using 700 Ring lighting products which support 900 MHz connections.  Employees installed these devices around their home as typical customers do; and, in just days, these individual network points combined to support a secure" - and we'll get to security because of course that's super important, and I've got it nailed here in the podcast - "to create a secure low-bandwidth 900 MHz network for things like lights and sensors that covered much of the Los Angeles Basin, one of the largest metropolitan regions in the United States by land area.



"This neighbor-created network demonstrates the potential of Amazon Sidewalk - a broad coverage network, great for low-bandwidth, low-cost devices that require no complex setup or maintenance for customers.  But the benefits don't stop there.  With Sidewalk, we also see the opportunity to deliver new devices and experiences that delight our customers."



They said:  "As one example, this week we announced" - and this would have been a year ago - "Fetch, a compact, lightweight device that will clip to your pet's collar and help ensure they're safe.  If your dog wanders outside a perimeter you've set using the Ring app, Fetch will let you know.  In the future, expanding the Amazon Sidewalk network will provide customers with even more capabilities like real-time location information, helping you quickly reunite with a lost pet.  For device makers, Fetch also serves as a reference design to demonstrate the potential that devices connected to a broad, reliable network can provide to their customers.



"Extending the convenience of a long-range network will take time, but we're already working quickly to bring this future to life for customers.  For device makers, we plan to publish protocols that any manufacturer can use to build reliable, low-power, low-cost devices that benefit from access to long-range, low-bandwidth wireless connections.  In the meantime, you can sign up to be notified when more information is available."  And they finish:  "Amazon Sidewalk is a long-term effort, but we're excited to get started and can't wait to see what device makers build and how customers benefit.  The possibilities are endless."



Okay.  So clearly what they are planning and are in the process of bringing is a new radio which will be added to all of their Amazon devices.  And that new radio will be 900 MHz, the 33-centimeter unlicensed amateur radio band.  It also works with Bluetooth Low Energy, alternatively.  Now, of course Amazon has been selling devices for quite a while.  Today, all Echoes except for the first generation, so the second and third and fourth gens in 2017, 2019, and 2020 are all Sidewalk-compatible.  This year's fourth-gen Echo also has the 900 MHz radio.  All of the Echo Dots are Sidewalk compatible, but none of them have the 900 MHz radio.  So they're limited to using Bluetooth Low Energy.  The same is true for the Pluses.  There are five Echo Shows, and this year's Echo Show 10 is 900 MHz-capable.  And then those two devices they mention, the Floodlight Cam and the Spotlight Cam, those are both last year's devices, and they already have the 900 MHz radio.



So in the show notes I've got a link to this whitepaper which I've read and digested and understand.  In there they make a couple of points that I'll share.  They said:  "A simple control is provided to enable and disable participation in the neighborhood network.  When customers first turn on a new Sidewalk gateway device, they will be asked whether they want to join the network.  For customers with existing devices that are Sidewalk-capable, an over-the-air update will connect them to the network.  No action is needed.  These customers will first receive an email about the pending update and instructions for how to disable, if that is their choice."



So that's how, as I said at the top, that's how Amazon sort of walked this fine line of really wanting this network to take off, but recognizing that they are using the Internet connectivity of their customers in order to create, they hope, over time a true 900 MHz Wide Area Network which can do all kinds of stuff, like fitting into a gap that exists today.  And I think, for example, of the person who has a long drive from their home out to the end of their driveway where they have an automated gate, and they would like access to it, but WiFi won't reach.  This technology would be perfect for that.  And it might even be that the gate is using the Amazon Sidewalk bandwidth of the house across the street, which is closer than their own.  And I'll explain how this works and why it can be safe.



Amazon also said:  "As a crowd-sourced community benefit, Amazon Sidewalk is only as powerful as the trust our customers place in us to safeguard customer data.  To that end, this document outlines the steps we have taken to secure the network and maintain customer privacy.  These efforts are core to our mission and will continue to evolve and improve over time."  And, finally:  "The maximum bandwidth of a Sidewalk Bridge" - and I'll explain some of these terminologies.  There's five new definitions we have.  "The maximum bandwidth of a Sidewalk Bridge to the Sidewalk server is 80Kbps," they say, "which is about one 40th of the bandwidth used to stream a typical high-definition video.  Today, total monthly data used by Sidewalk-enabled devices, per customer, is capped at 500MB, which is equivalent to streaming about 10 minutes of a high-definition video."



So, I mean, the whole point of this, you know, nobody is going to use your Internet connection out literally on your sidewalk to download something.  That's not what this is.  You don't have, this is not an Internet protocol extension.  There's no IP, Internet Protocol, on this 900 MHz.  It is a message-passing, signaling level network.  So the overall network can be visualized by, well, can be visualized as consisting of five things.  There are gateways like the Ring Floodlight.  There are endpoints like a humidity sensor in your backyard.  There's the Amazon-operated, what they call the "Sidewalk Network Server."  And that's distinct from, and I'll explain how, from application servers which are the things that the endpoints communicate to.  And then there are message packets, which is the medium of communication.



So the gateways, which they also call Sidewalk Bridges because it is a bridge from either your WiFi or your wired LAN to this participation in the 900 MHz network, the bridges forward packets to and from the Sidewalk Endpoints and through your LAN connect to the Sidewalk Network Server which is Amazon's device.  The gateways right now are Amazon devices, like the Ring floodlight cam, that use this 900 MHz band, or Bluetooth Low Energy, to provide connection to the Sidewalk network.  At 900 MHz it either uses this LoRa (L-O-R-A) modulation or simple FSK (Frequency Shift Keying).



And LoRa is a very clever technology, which as I mentioned it uses bidirectional frequency chirps.  So it's inherently broad spectrum because a chirp is.  But it allows it to obtain extremely good range at very low bandwidth.  It makes good use of receiver sensitivity.  And because the carrier is actually chirping, it solves the problem of particular carrier frequencies being blocked, just naturally blocked by some substances.  You know, if something were in the way, which happened to be absorbing some particular band or a spike because it happened to be resonant at that frequency, it would absorb the energy.  But the chirp spans that so the chirp still gets through.  Anyway, the point is this is a very different technology meant for a very different application.



Okay.  So we have the gateways.  The endpoints, which they also call "Sidewalk-enabled devices," may be known as edge devices, endpoints, or applications.  They're able to roam around on the Sidewalk network by connecting to Sidewalk gateways, whether your own or somebody else's.  The system is completely agnostic about whose gateway you're connecting to, and it makes that secure.  The endpoints are low-bandwidth, low-power smart products like leak sensors, door locks, lights, or devices attachable maybe to valuable things like luggage tags or a pet which is wandering around.  The endpoints can be built and maintained by Amazon or by third-party developers, so the system is open.



The gateways can also act as an endpoint themselves and receive Sidewalk benefits like maintaining functionality when the device falls offline.  And that's interesting.  For example, it would mean that if your own router and cable modem froze, your Sidewalk-enabled IoT devices like lighting or your door lock would normally fall offline.  But this allows them to remain connected, thanks to a neighborhood-wide active Sidewalk network that would allow it to automatically ride over someone else's bandwidth - again, not exchanging lots of data, but down at the message-passing level.



We have the Sidewalk Network Server, which is Amazon's.  It's responsible for verifying that the incoming packets, and I'll explain this in a second, are coming from authorized Sidewalk devices, routing packets to the desired destination, which is an application server, or in the other direction to an endpoint or a gateway.  And it also keeps the network time synced.  Time is an important component here, as we'll see.  They have very cleverly used time to cryptographically rotate all of the IDs of all of the devices, exactly analogous to the six-digit PINs that we're all used to now with our one-time passwords.  So everything needs to know what time it is.  But given an agreement about time, this is how tracking is prevented over time.  But anyway, I'll explain that in a second.



Finally, the Application Servers are different from Amazon's what they call the Sidewalk Network Server.  The Sidewalk Network Server is the protocol endpoint, but that then forwards the packets, routes them to the Application Servers.  So, for example, the company that provided the moisture sensor in the backyard or the leak detector, it would have its own app and its own server, which today we are connecting to, if you have WiFi.  In the future it would be able to work over Sidewalk.



So the Application Servers are managed by the endpoint  manufacturer, which could be Amazon or some third party.  So, for example, say that the garage door opener manufacturer Genie were to create a smart Sidewalk-enabled garage door opener.  It would normally be connected to your home WiFi, and it would normally be offering Sidewalk connectivity to your neighborhood.  But reciprocally, it would also be able to use the neighborhood's Sidewalk network if, for example, your WiFi was not available.  So if you needed to reach it while your home LAN was down and you weren't, you know, your router hung or your cable modem froze or something, the Genie Application Server would route through Amazon's Sidewalk Network Server to reach your Sidewalk-enabled garage door opener via a neighbor's Internet connection.  And all of this is transparent.  And the last component are Packets, also known as Messages, which are the things exchanged between the Endpoints and the Application Server going both directions through the Gateways and Amazon Sidewalk Network Server.



So that's the architecture.  Looking at it, the network's design reveals that Amazon has put a great deal of time, attention, and design work into creating a system that provides the security controls that Amazon requires for the network to operate safely while also blinding Amazon to all of the network's messaging traffic.  Amazon can see nothing about the messaging level.



Our listeners know well about the Onion Router network, this concept of - it's termed an "onion" because it's consecutive shells of encryption.  Well, that exactly mimics the design of this network.  Sidewalk uses three layered wrappings of encryption.  The innermost encryption is the application layer, which protects the privacy and security of the communications between the endpoint, like out in your backyard, and the application server which needs to talk to that device.



So this is the layer that does the actual signaling work, the message passing.  And it is end-to-end encrypted using the state-of-the-art means that we know of to do that today.  So that creates an encrypted tunnel between the far extremes.  The application layer encryption is then in turn encrypted, also at the endpoint.  So the endpoint encrypts first for the application server.  Then it encrypts that for the Amazon Network Server.  This conceals and protects the Sidewalk packet as it's moving over the air.  And the plaintext data encrypted by this layer is accessible only to the endpoint and the Amazon Network Server, nothing in between.



And then, finally, what they call the "Flex Layer" is added at the gateway device.  So the endpoint encrypts twice, once with a key known only to the application server.  Then it encrypts that with a key known only to Amazon's Network Server.  That goes over 900 MHz to the Sidewalk gateway device.  It encrypts that for the Amazon Network Server using a trusted and tamperproof reference for message-received time and adds an additional layer of confidentiality.  That's then what it transmits, either over your wired LAN or WiFi, to Amazon's Network Server.



So as I noted above, ultimately the communication is between the endpoint devices and their application servers, with the Sidewalk gateway devices and Amazon's Network Server functioning as intermediaries.  So consequently the innermost wrapper of encryption is end to end between endpoint device and the device's matching application server.  Neither the gateway that facilitates the communication at the neighborhood end nor the Amazon Network Server that facilitates the communication over the Internet are able to see anything about what's being transacted.



And looks like I quoted from Amazon's document.  They said:  "Amazon has carefully designed privacy protections into how Sidewalk collects, stores, and uses metadata.  Sidewalk protects customer privacy by limiting the amount and type of metadata that Amazon needs to receive from Sidewalk endpoints to manage the network.  For example, Sidewalk needs to know the endpoint's Sidewalk ID to authenticate the endpoint before allowing the gateway to route the endpoint's packets on the network.  Sidewalk also tracks a gateway's usage to ensure bandwidth caps are not exceeded and latency is minimized over a customer's private network."



They said:  "Information customers would deem sensitive, like the contents of a packet sent over the Sidewalk network, is not seen by Sidewalk.  Only the intended destinations, the endpoint and application server, possess the keys required to access this information.  Sidewalk's design also ensures that owners of Sidewalk gateways do not have access to the contents of the packet from endpoints," whether or not they own those endpoints which may be using their bandwidth.



"Similarly, endpoint owners do not have access to gateway information.  The Sidewalk Network Server" - that's Amazon's - "continuously 'rolls,' or changes transmission IDs" - they call them "TX-IDs" - "and Sidewalk Gateway IDs every 15 minutes to prevent tracking devices and associating a device to a specific user.  The IDs use a time-based cryptographic system like our TOTPs so that the endpoints are continuously and autonomously reidentifying themselves using a periodically changing ID, and the Amazon server shares the underlying key and thus can determine who's who.  But no one monitoring the metadata could determine whether the same or some other device was communicating" from one series of events to another.



From the view of the endpoint, the device using someone's gateway device, it's only able to view information that pertains to the normal operation of its device, whether the smart light is on or off.  It's unable to see routing information or even what gateway, for example, if it's not owned by its owner, the smart light is receiving support from, nor any information about that gateway and the gateway's owner.  The gateway information is encrypted behind the Sidewalk network layer and the flex layer.  So again, it's a well-designed system of deliberate blinding layers so that only the information needed is visible.  Everything else is encrypted in a lower level layer.  And the  thing down at the low level has no awareness of what's going on at the higher level.



From the viewpoint of the gateway device, it is unable to see what the endpoints, whether or not they're owned, are receiving from their gateway.  They have no idea what types of endpoints are connected, nor the times in which they are connected, or information about the owner of the endpoint.  All of that information is encrypted as it passes by the Sidewalk Application Layer.  At the far end, the application server is unable to see any information pertaining to the gateway owner because that's been stripped by Amazon's Sidewalk Network Server.  It only has access to the endpoint information, since those outer wrappers and metadata, like the gateway ID, will have been removed by Amazon's Network Server.



And as we would hope, the registration time establishment of unique identifying credentials assure that only trusted and known devices can enter the Sidewalk network, which prevents unauthorized devices from joining.  The Sidewalk Network Server, the Application Server, and each Sidewalk device, both the gateways and the endpoints, are provisioned with a unique set of Sidewalk credentials that are used during the Sidewalk device registration process to mutually authenticate each device's identity and to derive unique session keys for use between them.  Rolling encryption keys are periodically derived from their respective session keys.



Amazon also noted that to protect their customers' privacy, the routing data that they were necessarily using to link the location of a known endpoint device to perhaps someone else's gateway  by network but also probably by geographic location  is deliberately wiped and discarded on a rolling 24-hour basis.  So it's only retained for a day.



So that's the system.  It's not neighborhood WiFi.  It's an encrypted IoT low-speed communications signaling solution.  It's initially primarily Bluetooth Low Energy, since all of Amazon's various devices have that.  And we know that's, what, 30 feet maybe, 10 meters, so not a great distance.  But over time all new Amazon devices will certainly include this newer 900 MHz radio that will really start to give the system some useful range.  And as I said, while it certainly will need to survive a deeper analysis by crypto people and academic analysts, it's clear that they really thought this through.  They worked hard to create and deliver a state-of-the-art secure messaging solution.  And if it were to succeed, we might be in a world where a cool low-frequency, low-bandwidth, low data rate message passing network was pervasive.  And it would allow things that right now have a hard time staying connected to be connected.  So I think it's cool.  That's what Sidewalk is.



LEO:  We're going to rely on you to keep an eye on this and kind of fill us in on the risks because of course it's really unfortunate.  Mashable's not alone, Business Insider, every publication, looking for traffic - I want to underscore that - looking for traffic and saying, oh, my god, it's opt-out.  And, I mean, it could be bad.  I think there's a kind of a kneejerk reaction, "Not with my bandwidth, you don't."  But it's not - it's a tiny amount of bandwidth.  And you made a really good point.  You're also getting bandwidth from your neighbors.  So it probably is a zero-sum, I mean, it's all going to balance out if you use it.  And, you know, if you've got a dog, and you get one of these collars, you'll use it.



I think there are a lot of potential uses for this.  And it'd be really a shame for us to lose the benefit of Sidewalk because of imagined or overblown privacy concerns.  If there are some - and that's why we're going to count on you.  Because if there are some, or security issues, we want to know about it.  I know you're going to keep an eye on it.  But if there aren't, I don't think, just because Mashable wants to get viewership, we should assume that when they say it's a privacy nightmare, that it really is.  And sounds like it's not.  Sounds like it's well designed.



STEVE:  I completely agree.  I think it is as well - one of the things that we're seeing is, and I've said this so many times, all of these problems are solved.  We now know how to do secure end-to-end encryption.  We now know how to rotate keys based on time, using a crypto algorithm.  We know how to do all of this.  And so the idea of successive layers of encryption, where at each layer only the information that's necessary is available to the layer above and not below, I mean, it's clearly designed right.  Whether it's implemented right, whether dumb third parties create bad implementations, I mean, you know, there are some things you can't help.



LEO:  Always possible.  They've done that with WiFi, you know.  I mean, that doesn't mean WiFi's a bad thing.



STEVE:  Right.



LEO:  So, yeah, and this is why people have to listen to this show because we know that you will give us a reasoned - you're not link baiting.  You're the opposite.  You're going to give us a reasoned look at this.  And, I mean, at first it sounds a little sketch, potentially.  But it sounds like they've done the right thing.  And this is my problem with just kind of this blanket privacy thing is you could lose some real benefits.  If there is no risk, then let's go for the rewards.



STEVE:  Well, Leo, had the privacy people been involved in the design of the Internet, we would still be waiting for it.



LEO:  That's a good point.  We wouldn't have email, that's for sure.  No websites.



STEVE:  It would have never happened.



LEO:  Yeah, no, that's for sure.



STEVE:  It would have never gotten off the ground.



LEO:  This is actually a little different because it's been designed from upfront to be secure and private, as opposed to the Internet, which was not designed that way by any means.



STEVE:  Yeah, you wouldn't be able to drive because there would be taut string connecting paper cups all over the world.



LEO:  Yeah.  But we'll keep an eye on it.  You know, I've been going back and forth.  Should I turn it off?  Should I leave it on?  And I think the problem is it only works to the degree that everybody leaves it on.



STEVE:  That's right.



LEO:  If nobody uses it, then it's not going to do anything, and then it's another technology just down the tubes.



STEVE:  It's like the COVID contact tracing.



LEO:  Yeah.



STEVE:  You know, it's like, you know...



LEO:  Right, right. 



STEVE:  Yeah, I see nothing wrong with it.  The design is solid.  They thought this thing through.  And it may be the kind of thing, I mean, so they're going to end up seeding the world with these devices. 



LEO:  Yeah.



STEVE:  They will exist.  And so they could urge people later to please reconsider, maybe give you a discount on your Amazon Prime if you turn it on, because they'll know if you've turned it on.  I mean, there's all kinds of things that could happen.  But it can't happen unless the protocol is designed and designed well, if they can demonstrate that they are really not misusing people's bandwidth, and if the radio hardware is in place.  Well, the radio hardware is going to be in place.  And so I think...



LEO:  Yeah, it's amazing, isn't it, actually.



STEVE:  ...once that happens, you know, we then might start to see some compelling use case for it.  I mean, it is sort of a chicken-and-egg thing.  You and I remember when people were saying, well, the web doesn't make sense because there's no...



LEO:  There's nothing on it.  No one's on it.



STEVE:  Nothing there yet.  And then people were saying, yeah, and if nothing there, then one's going to go there.  So no one's ever going to put anything there if there are no people to look at it.  It's like, yeah, well, it happened anyway.  Just like chickens.  We got chickens.



LEO:  It's actually a very interesting play that only Amazon can make.  Although I should point out LoRa goes well beyond Amazon.  It's been around for a while.  In fact, it's a French technology.



STEVE:  Yes.



LEO:  So others could potentially implement it.  But who else has this many IoT devices spread out all over the country?



STEVE:  Right.



LEO:  Thank you, Steve.  That's Steve Gibson.  You know him from GRC.com.  SpinRite, you ever hear of that?  Yeah, the world's finest hard drive maintenance and recovery utility, now for more than just spinning drives.  I'm really excited now that I know SSDs are going to benefit so much.  I can't wait to try that benchmark on the new Mac.  So let me know the minute it's available.  Do I have to sign up to get in some beta program to do it?



STEVE:  No, no, no.  Everybody will be able to get it next week.  



LEO:  So exciting.  We'll talk about it next week.  If you go to GRC.com, get SpinRite.  But then you can also get copies of this podcast.  Steve has a couple of unique versions, a 16Kb audio version, really tiny, shrunk down.  There's an even smaller human-written transcription so you can read along as you listen.  That's all at GRC.com, along with a 64Kb audio.  We have 64Kb audio and video available at our site, TWiT.tv/sn.  There's also a YouTube channel for Security Now!.  Every show is up there.  You can subscribe in your favorite podcast client.  It's been around for a few years, so you should be able to find it.  Just search for Security Now! and subscribe, and that way you'll get it automatically.



Steve is on the Twitter at @SGgrc.  That's the place you can DM him.  His DMs are open.  If you have a thought, a suggestion, a tip, a leak, a funny picture for his Picture of the Week, you can tweet him.  You can also go to the feedback form at GRC.com/feedback.  And if you get a copy of SpinRite now, you'll be first in line to get a copy of 6.1 when it comes out.  That'll be a free upgrade for you.  So another good reason to get it.



I have to get my serial number.  I have to call your guy and get my serial number so I can update.  Thank you, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, buddy.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#797

DATE:		December 15, 2020

TITLE:		SolarWinds

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-797.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week is crammed with news leading up to our holiday break.  Chrome is throttling ads.  There's new cross-browser as insertion malware.  We have a new term in the ransomware world.  We have last week's Patch Tuesday, a jaw-dropping policy leak from Microsoft, trouble for Cisco's Jabber, an embarrassing vulnerability in many D-Link VPN servers, the brief Google outage, more horrific news of IoT network stack vulnerabilities, another WordPress mess, the 2020 Pwnie Awards, the welcome end-of-life of Flash, JavaScript's 25th birthday and free instruction classes, a bit of closing the loop, and SpinRite news.  Then we take a full reconnaissance dive into what happened with the monumental and in so many ways horrific SolarWinds supply chain security breach.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about Patch Tuesday, a retrospective; and a new classification system Microsoft's using that might be just a little bit, oh, I don't know, self-serving?  The Pwnie Awards are in.  I don't know if this is good or bad.  And then Steve's going to break down this massive hack from Russia, the SolarWinds attack, what we know so far.  Coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 797, recorded Tuesday, December 15th, 2020:  SolarWinds.



It's time for Security Now!, the show where we protect your security and privacy online, holiday edition.  Steve Gibson is here.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you for, well, this is not the last podcast of the year.  We're actually...



LEO:  Almost.  We got one more.



STEVE:  We're off next week, but we're back the podcast before New Year's.



LEO:  And you are kept warm today by the MITS Altair.



STEVE:  Ah, very nice.



LEO:  It's an Altair 8800.  This is that kit that you ordered, and we ordered.  It's the Altair-Duino by Chris Davis.  And it's a really great simulation running, oddly enough, on an Arduino, which is probably faster than the original Altair was.  But thank you to Burke McQuinn, who is a master with a soldering iron and was able to solder this hundreds of little tiny pieces together to make that.  It's beautiful.



STEVE:  Very cool.



LEO:  It's a nice replica.  Did you use the original Altair ever?



STEVE:  No.  I was...



LEO:  You had mini computers.  You didn't need a micro.



STEVE:  That was after, yeah, after the DEC PDP stuff.  And I think I was busy.  I was over on the Apple side, although I did end up using all of the software for the light pen, the LPS II for the Apple, I wrote under CPM, so on a CPM-based machine, with a cross-assembler, which cross-assembled...



LEO:  Holy cow.



STEVE:  ...from that over to the 6502.



LEO:  Did you not have an Apple that you could do that with?



STEVE:  Oh, no, I absolutely did.



LEO:  You just liked the tooling on CPM?



STEVE:  Yeah, exactly.  The tooling, the editor, the compilers.  I had a hard drive, the Corvus hard drive.



LEO:  Oh, I remember that, yeah.



STEVE:  Yeah.  And so there was, like, none of that was ready or really there yet over on the Apple side because CPM was, you know, we had the S100 bus, and it was a very mature system.  And actually I did the programming on - it was called, I think it was called a SoftCard, an Apple II SoftCard.



LEO:  Oh, that's right, that's right.



STEVE:  That had an 8088 and allowed you to run CPM on your - and sort of like dual boot, run CPM on your Apple.



LEO:  Your Apple, yeah.



STEVE:  So you used the motherboard, the power supply, the keyboard monitors and things; but it was actually a CPM environment.  So, yeah, it was a - I miss those days where, you know, you had some idea what was going on with your computer.  I tried bringing up the Blob Opera on Chrome, and it just like literally brought my system to its knees.  I don't have any fancy soundcard or anything about sound, and it did mention at the bottom that it needs some advanced sound stuff.  I'll try it on Windows 10 tonight.  I'm on a Win7 machine.  So maybe Chrome with Win7 it doesn't like, or maybe it's some conflict.  Anyway, my point is that things have gotten so far advanced from where we were back then.



LEO:  Well, this thing is running an Arduino, but it says it's about the same speed as the original, emulating 64K of RAM, which would have been horrifically expensive back in the Altair day.  Can emulate an i8080 or a Z80.  Z80 runs at a reduced clock speed of 2.6 MHz.  It's got Altair extended BASIC.  I remember it was Bill Gates who wrote the original BASIC for Altair.  That's what got Microsoft all started.



STEVE:  Yeah.



LEO:  It's kind of cool.  Kind of amazing.  And it was only a couple hundred bucks and about $3,000 worth of Burke's time.  And so...



STEVE:  Still a bargain.



LEO:  Yes, still a bargain.  What are we talking about today?  I can guess, but I'm curious.



STEVE:  We're absolutely going to talk about the big, I mean, the sort of "monumental" I don't think is too big a word, in fact it's the word I used in the show notes, this SolarWinds attack, basically a supply chain attack.  My original working title for the podcast was Supply Chain Risks because there was one other one also.  We have more problems in TCP/IP stacks for IoT devices.  But this week is crammed with news leading up to, as I mentioned, to our holiday break next week, although we'll have a best-of show on.



We've got Chrome throttling ads.  We've got a new cross-browser ad insertion malware.  A new term being used now in the ransomware world.  We've got last week's Patch Tuesday retrospective, a jaw-dropping policy change/leak, I guess, from Microsoft, that I'll be anxious to have you ask Paul and Mary Jo about.  We've got trouble for Cisco's Jabber; an embarrassing vulnerability in many D-Link VPN routers.  Just a quick note about the brief Google outage that happened, I guess it was yesterday, early morning Pacific time.  More horrific news of IoT network stack vulnerabilities, as I referred to.  Another WordPress mess.  The 2020 Pwnie Awards.



The welcome end-of-life of Flash, oh my god it's finally here.  JavaScript's 25th birthday with some free instruction classes available, one per week throughout the rest of the year.  I wanted just to put it on our listeners' radar because JavaScript is the language now.  We have a bit of closing-the-loop and SpinRite news.  And then we're going to take what I called in my notes a full reconnaissance dive into what happened with this monumental and in so many ways horrific SolarWinds supply chain security breach where we still don't know everybody who was affected because mostly probably because they don't want us to know.



LEO:  Yeah.  Lot of companies use this SolarWinds package.



STEVE:  Yes.  They've confirmed that 30,000 of their 300,000 customers had it, and that it affected at least 18,000 of those customers.



LEO:  Wow.



STEVE:  And among them is like the Who's Who of government and commercial business.  So anyway, we're going to get to that.  We've got a fun Picture of the Week.  So I think a great podcast, jam-packed for our listeners.



LEO:  Jam-packed.  Full of good stuff.  All right.  I was hoping you would do the SolarWinds thing.  I'm really interested in what happened there.  It looks like that might be the most significant hack in a long time.  And we may never know.



STEVE:  Yeah, that's how it's being regarded.  And the way it was found, how it might have been missed, how long it's been there, what it is, and the interesting macro key that they've got, macro keyboard combination that they've got programmed at the Russian Embassy, where they just hit a particular key, and it spits something out.  So anyway, lots of fun to talk...



LEO:  In Soviet Union, keyboard types for you.  Picture of the Week, Mr. Gibson.



STEVE:  So this one, I don't know, maybe it's tangentially related to security.  But I found it in my Twitter feed.  One of our listeners sent it to me.  And I showed it to Lorrie, and she thought it was just adorable.  So I thought, oh, okay, fine.  So it's been in the stack, and it has popped to the top of the stack.



LEO:  It's cute.  It's kind of a dad joke, but it's cute.



STEVE:  Yeah.  So it's a four-frame cartoon.  The first frame is this odd sort of thing, you're not sure what you're looking at, but it looks like something stacked in a hat and coat.  Oh, and the sleeve is not fully filled.  And this thing is at a ticket counter, says, "One adult ticket, please."  And the ticket guy frowns and says, "I can tell you're three sheep in a trenchcoat."  And the top sheep of the stack says, "Are you sure?"  And the ticket guy says, "Yes.  Look.  One, two, three."  And then in the next frame... 



LEO:  [Snoring]



STEVE:  ...he's fallen asleep because of course he was counting sheep, so that's going to happen.  And our strange stack of three sheep has decided to go into the movie and not be harassed by the ticket agent.  So anyway, like I said, I'm not sure what that's about, like why that's on the podcast, but it got Lorrie's endorsement, so I thought, what the heck.



LEO:  Identity and access management, right there in a nutshell.



STEVE:  Ah.  There it is.



LEO:  See?



STEVE:  Thank you, Leo.  I needed to put a caption on the picture, yeah.  And spoofing your identity.



LEO:  Yes.



STEVE:  So we talked about this approaching some time ago.  And I remember it was interesting because of the heuristics that the browser, Chrome, was going to be applying.  It has begun to roll out and has been spotted in the wild.  And that's the so-called "Heavy Ad Intervention" which is now present in all of our Chromes, since we're all on 87.  So it affects both, nicely, third-party ads and Google's own AdSense, so they're not biasing, I mean, they'd probably get in trouble if they were.  They're not biasing ad treatment.  It's being, as are many of these things Chrome does, rolled out gradually.



I think we're, what, are we at the 50% FTP mark?  Or maybe we're at the - I've forgotten where we left off.  But they're doing the same thing with FTP.  It's like, okay, now these people don't get to use it.  Now these people don't get to use it.  Now almost no one gets to use it, like they're waiting for someone to complain.  Well, I don't think anybody's going to complain if heavy ads, that is, ads which Chrome decides are abusing their users' experience are blocked.



But I definitely wanted mine turned on.  And so I know that a lot of our users will, although already I'm running with uBlock Origin, which makes my experience so much more tolerable than what most people see.  But you can go to chrome://flags.  And if you put into the search term, if you put in "heavy ad," that will return two choices.  The first one is Heavy Ad Intervention, and the second one is Heavy Ad Privacy Mitigations.  So I enabled the first one.



They were both set to default, which gives Chrome control over this stochastic process of deciding who's going to get it and who isn't.  Anyway, mine's enabled now.  And the Privacy Mitigations is disabled.  What I'm assuming that does, the description says:  "Enables privacy mitigations for the heavy ad insertion.  Disabling this makes the intervention deterministic.  Defaults to enabled."  That's, you know, someday.  So what that must be is they recognize that it would be possible for someone to deliberately create a false-positive heavy ad in order to detect whether your browser was deterministically blocking that.



So in other words, it would be one bit worth of tracking signal.  And so it's just sort of refreshing to see that the world is like so worked up now over the issue of privacy that even something like this, where it's like, yes, I want heavy ad mitigation, darn it, they're like, well, yeah.  But you know, if you say that, we that would help us know who you are.  It's like, okay.  So I'm only going to say it sometimes.  Which is of course what this second privacy mitigation does.  But anyway, I just wanted to point out that it's there.  Anybody who wants it in Chrome can turn it on, and then bad ads won't show.



Speaking of bad ads, Microsoft 365 Defender Research Team posted a blog titled "Widespread malware campaign seeks to silently inject ads into search results and affects multiple browsers."  They named this thing, I don't know why, Adrozek, you know, "Ad" as in advertising, A-D-R-O-Z-E-K.  Really rolls off the tongue.  So one of the things that makes this malware noteworthy is that it is widely cross-family and multibrowser.  It affects Edge, Chrome, Yandex, and Fox uniformly.  And although its most prominent feature is unwanted ad injection, it not only injects ads, but the malware also exfiltrates any of the browser's stored credentials that it may have access to.  You know, and that's when you tell your browser rather than your password manager that you want it to save things.



Unfortunately, if you're up in a browser's business, you can figure out what credentials it has saved because in order for it to send them, they cannot be encrypted.  So that's a problem.  So of course that could cause - exporting your credentials could cause significantly more harm than some unwanted ads injected into search results.  I saw some pictures of it.  And, yeah, it shows you what you would normally see would be Google results on a Google search, and instead like the whole first page is these bogus ads stuck in, tied to keywords.  So it's trying to get ad payment benefits.



Microsoft said:  "We call this family of browser modifiers Adrozek.  If not detected and blocked, Adrozek adds browser extensions, modifies a specific DLL per target browser, and changes browser settings to insert unauthorized ads into web pages, often on top of legitimate ads from search engines.  The intended effect is for users, searching for certain keywords, to inadvertently click on these malware-inserted ads, which lead to affiliate pages.  The attackers earn through affiliate advertising programs, which pay by amount of traffic referred to sponsored affiliate pages.  Cybercriminals abusing affiliate programs is not new," Microsoft wrote.  "Browser modifiers are some of the oldest types of threats."  In fact, remember, it was that Adaware thing that I found in my browser, one of those old BHOs, remember Browser Helper Objects, that caused me to write the first antispyware because it was spyware.  It had gotten in unannounced and unasked for.



Anyway, Microsoft said:  "However, the fact that this campaign utilizes a piece of malware that affects multiple browsers is an indication of how this threat type continues to be increasingly sophisticated.  In addition, the malware maintains persistence and exfiltrates website credentials exposing affected devices to additional risks."



So anyway, it was surprisingly sophisticated.  Disables browser updates to prevent its configuration modifications from being reversed.  And it even establishes a Windows service to gain persistence over the long term.  So that if you did something that tried to get rid of it, the service would keep running and say, hmm, and then put itself back.  So it's a serious issue.  Microsoft was tracking this thing's compromise of more than 30,000 PCs per day.



So the good news is I'm sure that Microsoft's security people became aware of these threats, and shortly thereafter so did Windows Defender Protection Suite.  So it might be a good idea for some piece of mind just to ask Defender to perform a full scan of your various Windows systems from time to time.  And that takes some time.  There's no way around that.  As the author of SpinRite, I'm all too aware that actually reading everything on your system will take some time.  So I just thought while I was putting the show together I would do that.



So I started up a full scan on my Win10 machine.  And Defender says go ahead, use your machine while it scans in the background.  But I did notice that it aggressively throttles its scanning so as not to interfere with your use of the computer in the foreground.  So it's probably better to choose a time when you are about to be away from your machine and fire it up at that point.  So when it was all done, while I was assembling the notes, I noted that it took 90 minutes, and it scanned 5,797,899 files.



LEO:  That always blows me away when I see that.



STEVE:  And Leo, after the scan was finished, I just stared at that number.  I remembered fondly, and this takes us back to our Altair days, I remember when our hard drives had seven files on them.



LEO:  Yeah, yeah.



STEVE:  Now the number of files has seven digits.



LEO:  It's amazing; isn't it?



STEVE:  You know, I do miss those days.



LEO:  Yeah, yeah.



STEVE:  So an interesting new term of art.  I just thought I would add this to our vocabulary.  It's termed "Double Extortion" on the ransomware front.  It's being used with increasing regularity, so I thought I would add that to everyone's lexis.  The term is "double extortion."  It originated with Check Point last April, referring to the double threat of encryption plus public exposure of proprietary data if the victim should choose not to pay up.  As we know, some companies will be extremely sensitive to the reputation damage they might suffer, not to mention maybe even the potential liability if the news of their breach should become widely known.  So henceforth that embarrassment strategy will be known as double extortion.



This is the third Tuesday of the month.  The first one was right on the 1st.  So this was one of those months where the second Tuesday was the earliest it could possibly be.  And of course your first thought upon hearing that last week Microsoft patched 58 known vulnerabilities across their various products might be to think, wow, only 58 this month.  That's way fewer than the more than 100 we've been beaten down into accepting as normal this year.  But then, when you stop and look closer, you realize that more than one third of those 58, 22 in total, are all remote code execution vulnerabilities.  Wow.



So, and because several of them are on Exchange Server and in SharePoint, both which have natural exposures to the Internet, I hope that everyone has by now made time to get those updated, although none are zero days, meaning that none are known to be under exploitation at the time of their discovery.  A total of nine of those 22, all of which are remote code execution, are rated critical, and some are not difficult to exploit once they become known.  We know that bad guys rejoice now every month, whether it's the holidays or not, and quickly work to reverse engineer Microsoft updates in hope of working out an effective exploit before hapless Windows users update their vulnerable machines for those now known problems.



And of course this is especially true when they're enterprises running servers that they would like to avoid rebooting and having offline during a patch cycle.  Maybe that explains the reticence to do that.  Well, and of course sometimes updates actually do tank a machine so that they don't want to do it without, like, making a full image so they're able to roll back if they need to and so forth.  Anyway, among these 58 that Microsoft fixed this month, last week, was a bug in Microsoft's Hyper-V virtualization technology.  It was exploitable via a malicious SMB packet and would allow remote attackers to compromise virtualized sandbox environments, which of course Hyper-V was designed to protect from, but not so much.  So yes, as always, don't wait to update for long.



Oh, and, okay.  Speaking of Microsoft updates, here's a little bit of tid that caught my eye.  The news was about a zero-click wormable vulnerability in Microsoft Teams.  Before this was fixed, it would have allowed an adversarial attacker to remotely compromise a target's machine simply by sending them a specially crafted chat message.  The reception of the message would have enabled zero-click remote code execution on that system.  This discovery was reported to Microsoft at the end of August, on the 31st, by Oskars Vegeris, a security engineer with Evolution Gaming.  Microsoft addressed the issue at the end of October.



In Oskar's write-up he said:  "No user interaction is required; exploit executes upon seeing the chat message.  The result is a complete loss of confidentiality and integrity for end users  access to private chats, files, internal network, private keys, and personal data outside MS Teams."  So, like, really, really bad.  And it's cross-platform.  It affects Microsoft Teams for Windows, for Linux, for macOS, and even the web version.  And as I said, as a consequence of the zero-clickness, it can be made wormable so that upon receiving a chat, that machine executes with the user needing to do nothing and is able to then send chats out to, for example, maybe everybody that they have a chat history with, and it could explode.  So very much like the iOS problem that we talked about last week.



So here's what just brought me up short.  This is obviously quite serious.  It's zero-click.  It's wormable.  It's a remote code execution vulnerability.  And it was assigned no CVE designation by Microsoft.  Why?  Microsoft said, and I quote:  "It is currently Microsoft's policy not to issue CVEs for flaws in products that automatically update without user interaction."  What?  So I haven't tracked down the policy, but this seems like a change.  It would be very interesting if you were to ask Paul and Mary Jo about this tomorrow.



LEO:  Okay.



STEVE:  So could Microsoft's solution to the embarrassment of hundreds of CVEs being patched every month to simply redefine problems by whether or not they will automatically be repaired?  If so, it's a whole new ballgame.  This would suggest that anything that auto updates like Windows would no longer have any actual vulnerabilities.  After all...



LEO:  It's going to be fixed.



STEVE:  ...Windows is now, by this definition, a continually moving target that's always in flux.  So Leo, those are not actually vulnerabilities at all.  They're just some miscellaneous things, like remotely taking over a Microsoft Teams user by sending them a chat message, that haven't been finalized yet.  But don't worry, we're working on it.  It's not worth bothering yourself about.  Okay.  So, right, we're not going to assign those any vulnerability numbers.  Don't worry about it.  No CVEs here.  We fixed it.  Because, after all, it updated, and it's not a problem anymore.  Right.



Cisco is Jabbering.  They've been having recurring trouble keeping their chat system secure.  They have again attempted to patch their Jabber conferencing and messaging application against a critical vulnerability that made it possible for attackers to execute malicious code that would spread from computer to computer, once again with no user interaction required.  You know, we're going to have to see one of these happen at some point because we keep finding them before the bad guys do, and at some point some bad guy's going to say, oh, this is going to be fun because everyone keeps talking about these, but no one ever does it.  So here goes.



The discoverers of the trouble, Watchcom Security, explained what's been going on.  They said in their TL;DR:  "Three months ago, Watchcom disclosed four high-severity vulnerabilities in Cisco Jabber.  One of the vulnerabilities allowed Remote Code Execution by sending specially crafted chat messages  a problem that everyone seems to be having.  The vulnerabilities were reported to Cisco, and a patch was issued.  Shortly after, one of Watchcom's clients requested a verification audit of the patch to ensure that the vulnerabilities had in fact been sufficiently mitigated."  Whoops.



Three of the four vulnerabilities Watchcom disclosed in September have not been sufficiently mitigated.  Hello, Cisco?  Are you listening?  Is anyone home?  Watchcom reported that Cisco released a patch that fixed the injection points they had reported, but the underlying problem was not fixed.  And consequently, Watchcom was able to find new injection points that could be used to exploit the same underlying vulnerabilities.  All currently supported versions of Cisco Jabber client from 12.1 through 12.9 are affected.



So for the sake of clarity they assigned three newish vulnerabilities CVE numbers to distinguish them from the original similar vulnerabilities which were disclosed to Cisco in September, and Cisco just sort of said, oh, whoops, and put a little putty on them or, you know, I don't know, a piece of Scotch tape.  They explained that these newfound vulnerabilities have the same impact as the original and range in severity from medium through critical.  As such, two of the vulnerabilities can be used to gain remote code execution.  And Cisco, as I said, didn't really bother to fix them.



The most severe vulnerability is a cross-site scripting vulnerability that can be used to achieve remote code execution by escaping from the Chromium Embedded Framework, the CEF sandbox.  This vulnerability does not require user interaction and, again, is wormable.  Since the payload is delivered via an instant message, this means it can be used to automatically spread malware without any user interaction.



The second vulnerability can be exploited to collect NTLM - you know, that's NT LanMan, LAN Manager - password hashes from unsuspecting users.  In a very clever hack, by sending a message that contains a malicious image tag, an attacker can induce the victim's Cisco Jabber client, which is apparently based on the Chromium Embedded Framework.  They can get the Jabber client to interact with a file share under the attacker's control.  If the file share requires authentication, the victim's NTLM password hash will be sent to authenticate the victim, and thus the bad guy can capture the LanMan hash.  That's actually been done in the past, but not in this context.  So these are guys who know what they're doing and said, hey, you know, here's how we could get a Jabber client to give us some more useful information.



The third vulnerability involves the custom protocol handlers used by Cisco Jabber.  These protocol handlers are vulnerable to command injection because they failed to consider URLs that contain spaces.  By including a space in the URL, an attacker can inject arbitrary command-line flags that will be passed to the app.  Since the app uses, again, CEF, the Chromium Embedded Framework, and accepts Chromium command-line flags, several flags that can be used to execute arbitrary commands or load arbitrary DLLs exist.



So again, a clever hack.  Cisco apparently asleep at the switch on this.  You know, the first patch round that Cisco implemented filtered some of these.  Just, I mean, they didn't actually fix the problem.  They just said, oh, okay, we'll prevent that bad thing that Watchcom found from happening.  But they didn't, as I said, get to it.  So hopefully this time.



Watchcom wrote, in their conclusion of their disclosure, something that I thought was worthy of the whole story.  They said:  "The continued existence of these vulnerabilities, even after the first patch, highlight the complexity of modern software and the challenges developers face when trying to secure it.  When choosing to use frameworks such as CEF, it is important to consider their security implications.  Security should also be considered in every step of the development process, both in the initial planning stages as well as during implementation and maintenance."



They said:  "This also serves as a reminder that software acquired from external vendors also pose a risk to organizations' IT security.  It's important to be aware of these risks and take steps to mitigate them.  Watchcom recommends regular audits of third-party software for security vulnerabilities."  And of course amen to all that.  This is one of the things that we've been talking about a lot recently is there have been serious issues where external libraries like this Chromium Embedded Framework in this case are just dropped in.



It's like, oh, look, we just got a browser.  Like in our Jabber.  How cool.  It's like, uh, yes, except you've got the whole browser.  You've got a browser that will accept command-line options, and you're allowing spaces in URLs to get past to it.  So bad guys can send it something that will cause it to execute whatever they want.  That's now under their control.  So, I mean, it's easy to recognize that this is kind of a thing that you can just miss in oversight, but it's going to cause problems.



D-Link VPN servers have some embarrassing vulnerabilities, three of them.  They were discovered by the guys at Digital Defense and were subsequently responsibly disclosed to D-Link four months ago on August 11th.  D-Link finally confirmed the issue in an advisory on the 1st of December, so two weeks ago, adding that the patches were under development for two of the three flaws, which have now been released to the public.  The flaws are high-risk and, as I mentioned, a little embarrassing.  They are security vulnerabilities affecting D-Link's widely sold VPN router models DSR-150, 250, 500, and the DSR-1000AC, and other VPN models running the same DSR family.  It affects current firmware versions 3.14 and 3.17.



Even if the devices, these VPN servers, are secured with strong passwords, the vulnerabilities have left millions, because these things are widely used, millions of home and business networks open to attack.  And we know, just because D-Link has said, oh, new versions of the firmware are on our website, okay, of millions of home and business networks, how many are going to update?



LEO:  Zero?  One percent?



STEVE:  I know.  It's just, I mean, Leo, it just seems like it's out of control.  You can hardly blame Microsoft for saying, okay, wait a minute, we're going to redefine "vulnerability."



LEO:  Yeah, not a vulnerability.



STEVE:  Because they provide these vulnerabilities, a full authentication bypass allowing remote attackers to execute arbitrary commands on those devices through specially crafted requests.  And did I mention that these were particularly embarrassing?  The flaws originate from the fact that the web management interface, exposed publicly, uses Lua CGI, which is fully accessible without authentication and lacks any server-side filtering.  This makes it possible for an unauthenticated attacker to inject malicious commands that will be executed with root privileges.  And this works over the Internet-facing WAN interface.  So as always, the takeaway for our listeners, if you or your enterprise are using any of these quite popular D-Link VPNs, be very sure to obtain an update to the most recent firmware with some priority because these are being attacked in the wild.  



LEO:  If you turn off WAN administration, that would also work; right?  You have to have...



STEVE:  Yes.



LEO:  You have to be WAN accessible.



STEVE:  Yes.



LEO:  And we do recommend everybody do that on every router unless you absolutely need it.



STEVE:  Absolutely.



LEO:  Yeah.



STEVE:  Yeah.  We'll actually talk in a minute about an issue of that relating to WordPress.  I just did want to really briefly mention that Google suffered an outage.  Nothing to see here.  The conspiracy folks stepped into a brief, multi-hour, I mean, it was only a few-hour vacuum, with various attack theories and nonsense.  But Google quickly dispelled those.  Google first acknowledged the trouble at 4:20 in the morning our time, Pacific time, on the West Coast.  They posted:  "We're aware of a problem with Gmail affecting a majority of users.  The affected users are unable to access Gmail.  We will provide an update by December 14, 2020" - so that's yesterday morning.  So at 4:20 - oh.  So this was at 4:12 Pacific time - "detailing when we expect to resolve the problem.  Please note that this resolution time is an estimate."



Then three hours later, at 7:20 a.m., they explained.  Well, kind of.  They said:  "Today, at 3:47 in the morning Pacific time, Google experienced [what they called] an authentication system outage for approximately 45 minutes due to an internal storage quota issue.  This was resolved at 4:32 a.m. Pacific time, and all services are now restored."  So unusual as that was for Google, it was not an attack, nothing untoward.  Just whatever an authentication system outage is.  Sounds like it's a backend thing that authenticates people's Gmail access.  And if that's down, then everything that it authenticates would be down.  So, yeah.



Last Wednesday, during Black Hat Europe 2020, researchers from Forescout Technologies presented their paper titled: "How Embedded TCP/IP Stacks Breed Critical Vulnerabilities."  In their teaser synopsis for the conference they said:  "In the past few years, there's been a rise in critical vulnerabilities affecting embedded TCP/IP stacks which had remained undiscovered for over a decade.  The direct, unauthenticated, and sometimes cross-perimeter network exposure of these stacks, the often privileged portions of the system they run in, and their position at the top of opaque supply chains complicating vulnerability management efforts make for a highly dangerous mix resulting in periodic waves of critical vulnerabilities affecting billions [with a 'b'] of devices across industry verticals.  But contrary to what many assume, the fragility of these fundamental components isn't limited to specific vendors or older, closed-source stacks alone.



"In this talk, we will present over a dozen" - and actually well over - "over a dozen new vulnerabilities" - and they of course mean newly discovered vulnerabilities - "in multiple widely used embedded TCP/IP stacks deployed in everything from networking equipment and medical devices to industrial control systems.  We will discuss the nuances in their exploitability and potential impact and demonstrate a proof of concept against a yet-to-be-disclosed high-profile target.  In addition, we will present the first quantitative and qualitative study into vulnerabilities affecting embedded TCP/IP stacks showing a clear pattern to the affected components and features, as well as the root causes of the vulnerabilities that affect them.  Finally, we will provide concrete advice on how to mitigate and manage vulnerabilities affecting billions of devices in the absence of centralized patching and notification efforts."



And of course the absence of centralized patching and notification is one of our big hobbyhorses on the podcast because it is such a problem.  So needless to say, their presentation is quite a meal.  That's the introduction to their 47-page paper.  I've got a link to it in the show notes.  But stepping back a bit, they coined the name Amnesia:33 because they uncovered a set of 33 vulnerabilities collectively impacting four different open source TCP/IP protocol stacks, one known as Micro IP; the second, FNET; the third is picoTCP; and the fourth is Nut/Net.  They are commonly used in IoT (Internet of Things) and embedded devices.



As a consequence of improper memory management, successful exploitation of these flaws could cause memory corruption allowing attackers to compromise devices, execute malicious code, perform denial-of-service attacks, steal sensitive information, and even poison DNS cache memory.  In real-world scenarios, the attacks could play out in various ways, disrupting the functioning, for example, of a power station to result in a blackout, or taking smoke alarm and temperature monitor systems offline by using the DoS vulnerabilities, meaning it's, as we know, trivial to crash these things.



And so if you've got an embedded device that doesn't have a so-called "watchdog timer," which is able to notice that the device hung and then perform a physical restart, you know, well-designed systems tend to; really inexpensive things just don't.  They just - it doesn't occur to them.  That would cost an extra penny to put into the hardware, so we'll save that.  Many millions of devices from an estimated 158 different vendors are vulnerable collectively to these Amnesia:33 discoveries, with a possibility of remote code execution allowing an adversary to take complete control of a device and using it as an entry point on a network of IoT devices to then move laterally.



And of course we've also been talking a lot about lateral movement, thanks to the Zerologon flaw that allows somebody that gets into an enterprise to easily compromise the Active Directory system and move laterally throughout the network.  This allows them to establish persistence, co-opt their compromised systems without any outward appearance of compromise, thus setting up shop.  And of course our topic for today is, as we'll see, is big on that.  So if we imagine that nation-state actors are greedily mopping up all available exploits everywhere they appear, then this research from Forescout was likely greeted with a great deal of mopping because IoT devices are exploding in number.



Forescout said that:  "Amnesia:33 affects multiple open source TCP/IP stacks" - yup, those four - "that are not owned by a single company.  This means that a single vulnerability will exist across multiple codebases, multiple development teams, multiple companies and products, which presents significant challenges to patch management."  You know, there's not one person to notify.  And oftentimes these things are forked.  They'll take, they'll thank you very much, take the source code repository in-house and then do their own modifications from there, thereby never getting the benefit of the original repository's fixes, which these guys would be happy to provide.



So they say:  "Because these vulnerabilities span a complex IoT supply chain, Forescout cautioned it's as challenging to determine which devices are affected as they are hard to eradicate."  Right?  Because they're just embedded.  You don't know which TCP/IP stack is in that smart thermometer or in that smart plug or in the remote webcam.  That just, like, comes with it.  It's embedded.  So they stem from out-of-bound writes, buffer overflows, lack of input validation.  You know, basically running the gamut of a well-meaning but casually designed, oh, look, it works.  You're welcome to use it.



And unfortunately it's got lots of problems.  These guys found 33 different ones.  So there are critical remote code vulnerabilities in this Micro IP, picoTCP, and Nut/Net.  They have been disclosed.  They're publicly known.  Each of them has a CVSS score of 9.8.  So yeah, remote code vulnerability, trivial to exploit.  Some of the vendors who do utilize these stacks are being responsible.  Vendors such as the very well-known Microchip Technology, they're using this open source stack.  And Siemens, whose products are affected by these vulnerabilities, have released security advisories about them.  But again, that's the exception to the rule.  There's two companies.  That leaves 156 others.  As Forescout put it:  "Embedded systems such as IoT and operational technology devices tend to have long vulnerability lifespans" - okay, there's a new term to coin, "long vulnerability lifespans," meaning, right, they never get patched.



They said:  "...resulting from a combination of patching issues, long support lifecycles, and vulnerabilities trickling down, highly complex and opaque supply chains, or sometimes not trickling.  As a result, vulnerabilities in embedded TCP/IP stacks have the potential to affect millions, if not billions, of devices across vertical markets and tend to remain a problem for a very long time."  The problems disclosed were severe enough for the CISA, you know, our U.S. CISA, to get involved and to urge awareness.  But that didn't appear to have much impact when they urged companies to update against the Microsoft Zerologon vulnerability earlier this year.  Asking IoT vendors, random vendors, probably most in China, to patch their unpatchable devices seems a clearly doomed exercise in futility.



So what's our course of action?  What's our takeaway?  My feeling is that we must treat our IoT gadgets with the assumption that they are compromised and rigorously relegate them to their own isolated networks.  If you're able to access your various IoT devices from outside your home, then it's clear that you and they do not need to share a common network.  Your untrusted IoT LAN should coexist with your trusted LAN.  But they should not have any contact with one another.  And they don't need it.  You know, I'm not suggesting that we're seeing like broad-based intrusions.  We're not at this point.



But I would not be surprised if there isn't some sort of IoT-pocalypse at some point where these things, they're just like, there's such a critical mass of them, all connected out of this country, that they just don't represent such low-hanging fruit that it will be impossible for them not to be abused.  Let them attack each other on their own LAN segment.  Don't let them get to your main operating LAN where you've got your PCs.  And as I said, if you can change your home temperature when you're out roaming around away from the house, or turn plugs on and off and things, you're already on a separate network.  That demonstrates that your trusted LAN does not need to have contact with your untrusted IoT LAN.  And this need for network segmentation I would argue has never been greater.



Then we have another WordPress mess.  I got a kick out of the subhead that ZDNet chose for their coverage of this.  Their headline was "Zero-day in WordPress SMTP plugin abused to reset admin account passwords."  And their subhead was "A patch was released earlier this week; but many WordPress sites remain unpatched, as usual."  So, yes, the word is getting around that the fact that patches are released, well, that's good.  But it's necessary, but not sufficient.



So first off, as we know, the term "zero-day" has unfortunately become synonymous with "bug."  The press is tending to call everything a zero-day because it sounds a lot more serious.  It was meant to sound more serious.  But referring to everything as a zero-day will ultimately render the term worthless.  In this case, refreshingly, it really is a zero-day, although that's not good for the people whose WordPress sites have been hacked.  Hackers have been using a design mistake, coupled with a dumb configuration setting, of a popular WordPress add-on to easily reset the admin passwords on WordPress sites.  The add-on is considered popular because it's installed on more than half a million sites.  The hacking has been underway for some weeks, and the patch for the design error was made available last Monday.  Thus it is a true zero-day vulnerability.



The add-on in question is called "Easy WP SMTP."  Of course we know that's Easy WordPress Mail, right, email, SMTP, Simple Mail Transfer Protocol.  Obviously a plugin that lets site owners do something, in this case configure their SMTP settings for their site's outgoing emails and add features to it.  One of the features it boasts is the option to enable debug logging to see if the emails are getting sent out successfully or not.  That feature causes the system to log all email headers and the email body that is set.  And that email log is located in the plugin's well known installation directory:  /wp-content/plugins/easy-wp-smtp.  Thus that's no mystery.



But the team at Ninja Technologies Network (NinTechNet) discovered that, although Easy WP SMTP v1.4.2 and earlier, which was current before last week's update, although it gives the log a fancy random name, like "5fcdb91308506_debug_log.txt," oh, nobody is ever going to figure that out; right?  The plugins folder where this default directory, where this log is, lacks any index.html file.



So when the site is being hosted on servers with directory listing enabled, hackers can view the directory, see the fancy named email log, and view its contents.  Now they can see everything being sent out.  Then they cause the blogging site to send its admin a password reset email, refresh the view of the sent email log, capture the password recovery link, and take over the site.  So no rocket science here, folks.  Just, whoops, a problem with a plugin, more than half a million of these things out there.  And sites are being compromised right and left.



I mentioned before that while I was hosting my own WordPress blog, I was horrified by the idea of the site's admin login form being public.  The idea that anyone in the world could enter the well-known URL of the admin login and be looking at a prompt for a username and password to log in as me was appalling.  So one of the first belt-and-suspenders things I did was to completely block access to any admin-related pages  first and foremost the front door  from any remote IPs other than mine.  As we know, the public IPs we're assigned by an ISP are relatively static, so it's just as simple as using a .htaccess file; or, in my case, a web-config file because I'm using IIS to filter incoming page requests.



If my IP did happen to change so that I would also be locked out of my own admin page, then I would need to log onto the server which is hosting the site, which I would do using a certificate-tied SSH client  obviously not merely a username and password.  Then I would update the access control with my new remote IP and again be able to get to the page.  So my point is I'll never know what attacks that bit of superstition might have thwarted.  But the idea of exposing my WordPress login page to the world just made me shiver, as I hope it would any of our listeners.  And again, it's easy to be a little proactive and just keep that front door closed.



And always the advice is really, really, really minimize your use of third-party plugins for WordPress.  It must be that it is coming under additional scrutiny.  Maybe that and a combination of over time it's gotten more popular.  Lots of people are setting up sites.  Bad guys want to just create, you know, we talked about it the other day, some weird - they were compromising WordPress-based ecommerce sites to put up weird bogus shopping sites, some crazy stuff.  But apparently there's money in it, so that creates pressure to create the compromises.



Also last week at Black Hat Europe was the 2020 Pwnie Awards.  As we know, the Pwnies are to our cybersecurity industry what the Oscars and the Razzies are to the movie industry, you know, both the best things and the worst things in their category.  Every year cybersecurity researchers are invited to nominate and vote for both the best and the worst in our industry.  This includes selecting the best and most ingenious vulnerabilities discovered during the past year and also the worst vendor responses and epic fails that put their users at risk.  Traditionally, the Pwnies have taken place in August, you know, the summer in Las Vegas, during the Black Hat Las Vegas.  But this year with COVID-19 pandemic virtualizing conferences, it was decided that the Pwnie Awards would be moved to Europe's Black Hat conference.



So among the results are many things we've talked about during the year.  The best server-side bug went to BraveStarr, a remote code exploit in the Telnet daemon on Fedora 31 servers.  The best client-side bug went to a zero-click MMS attack on Samsung phones.  The bug was discovered by Google's Project Zero team, so that one they kind of kept in-house.  But that was the best client-side.  The best privilege escalation bug, of course, that's Checkm8, the unpatchable hardware jailbreak for seven generations of Apple silicon.



LEO:  I want to see the thank you speeches for this, the acceptance speech.  On behalf of all of my collaborators, I want to say [laughter].



STEVE:  The best crypto attack went to Zerologon, which as we know is a bug in Microsoft's Netlogon authentication protocol that can be performed by adding a bunch of zero characters in certain Netlogon authentication parameters.



LEO:  These are moving targets.  There's a worse one tomorrow.



STEVE:  Yes.  Actually there was a worse one two days ago.



LEO:  Yeah, right.



STEVE:  This horrible, well, it's the topic of our podcast.



LEO:  Right, we'll get to it.



STEVE:  Then we had the most innovative research went to TRRespass, with two R's.  That was bypassing the TRR protections on modern RAM cards to carry out Rowhammer attacks on them.  The most epic fail was Microsoft for CurveBall, a bug in how the company implemented elliptic curve signatures on Windows, allowing for easy spoofing of HTTPS sites and legitimate apps.  And, finally, the epic achievement award went to Guang Gong, a known Chinese bug hunter, for discovering three different bugs that allowed remote takeovers of Android Pixel devices.  So the Annual Pwnie Awards brought back some of the things that we've covered in the last year, not surprisingly.



Also, not a flash in the pan.  Adobe's infamous Flash player was anything but a flash in the pan, as we know.  It was released 24, Leo, 24 years ago.  Wow.  In January of 1996.  And of course back then web pages just laid there.  They didn't do anything.  They were predominantly static HTML.  JavaScript, it turns out, was just beginning to happen.  But it didn't have any of the new browser features to drive with scripting, so its application back then was very limited.  But Flash added a complete, self-contained, content-authoring, local interaction and animation facility.  You know, you could write working games in Flash, and many developers did.



And because it was a world unto itself, it was inherently browser agnostic.  If a browser had a Flash plugin, the content would run, period.  Didn't matter which browser, although there weren't that many back then, either.  It really was quite something for the era.  And it was immediately adopted by developers to create interactive content for the web.  As we know all too well, however, Flash's Achilles heel was that it was originally written, like most of the software of that era, with virtually no regard for security.  And it was never really able to recover from that lack of security legacy.  It was much like the Internet back then.  The fact that it ran at all was regarded as a miracle.  Security wasn't even a thought, let alone an afterthought.



But thanks to the incredible progress made in turning our browsers into fully programmable web application hosting containers that they are today, driven by JavaScript, there are more than 1,444,231 add-on JavaScript function libraries.  And we now have a very mature and formalized DOM, the Document Object Model, that allows a web page's presentation to be fully accessible and manipulatable by JavaScript.  Consequently, the only thing that has kept Flash alive has been the residual inertia still remaining from its once total dominance over that aspect of what it offered.  So against that backdrop, last week Adobe released their final update ever, which includes a kill switch, which will go into effect next month.



LEO:  Wow.



STEVE:  And reminded the world that Flash is finally once and for all being extinguished forever.  And it's not as if no one has received notice.  It was way back in 2017 that Adobe, Microsoft, Google, Apple, and Mozilla made a joint announcement that they would be retiring support for Adobe Flash Player at the end of 2020.  Well, that day has come, finally.  In their final Flash player release notes, Adobe said:  "We want to take a moment to thank all of our customers and developers who have used and created amazing Flash Player content over the last two decades.  We are proud that Flash had a crucial role in evolving web content across animation, interactivity, audio, and video."



And indeed it did once.  But beginning next month, Chrome, Safari, Firefox, Edge, IE11, and other Chromium-based browsers, which is like everybody else, will remove Flash from their bodies, and it will become impossible to put it back.  So long and farewell, and phew.  Wow.  And, you know, it has been fading.  We haven't, you know, we used to - Flash breaches were just a constant source of, unfortunately, of content for the podcast.



LEO:  Oh, yeah, yeah.



STEVE:  And it's been fading.  Believe it or not, it's not gone.  There are going to be some enterprise things that die next month.  It's just amazing.  But there are probably things that are - they're still working.  The source has been lost.  Wouldn't even matter now if you had the source because it's Flash.  And so it's just going to stop working next month.



LEO:  I get a lot of calls.  I've been getting calls on the radio show from people saying, "What do I do now?"  And I say, "What do you mean, what do you do now?  Nothing."



STEVE:  No kidding.  No kidding.



LEO:  Well, I don't think - I think they think there are sites that are using Flash that have long ago probably switched to other HTML5 technologies.  Like YouTube hasn't used Flash in years.  So I think they think they're using it.



STEVE:  And often when you see a site that tells you you have to install it, it's malware.



LEO:  Yeah, don't, yeah.



STEVE:  It's telling you, it's like, oh, here, click this link.



LEO:  You need Flash.



STEVE:  You need Flash in order to view the site content.



LEO:  Yeah, right.



STEVE:  It's like, what?



LEO:  No website that wants visitors would still be running Flash.  So I told them don't do anything.  Don't worry about it.  Get rid of it.  You'll be fine.



STEVE:  Yes, yes.  And speaking of its formal welcome replacement, while I'm on the topic of browser coding and automation, as I mentioned at the top, JavaScript is celebrating its 25th birthday, and we're in the second week of free courses being offered, one per week, at JavaScript.com.  So the site says - as you would imagine, it's www.javascript.com.  And the site says:  "To celebrate one of the most popular languages in the world, we're making five of our expert-authored JavaScript courses free each week in December."



And I apologize for not catching it last week.  That was the first week of the free courses.  The second week is available, and there's still three, four, and five.  And I looked over the summary of them, and they look wonderful.  So I'm not vouching for them, but just based on the topics that each one covers, if you're interested in JavaScript, if you want to buff up on your JavaScript, JavaScript.com.  You can sign up and get one free course.  There are four weeks of them starting this week for the remainder of the month.  So looks like it might be useful.



LEO:  Yeah.



STEVE:  Two bits of closing the loop.  David P. Vallee said:  "Hi Steve.  Listened to the Amazon Sidewalk podcast."  That was last week.  "Sounds like Amazon did everything imaginable to protect customers.  The question that occurs to me is how often does the Internet connectivity of a single home go down?  If the carrier drops, everyone's IOT devices will go out in a large radius, way beyond the range of Sidewalk.  Since IoTs use a small amount of bandwidth, for a home to need this, they would need a complete failure of either their router or modem.  When's the last time yours, or a friend of yours, had a router crash?  Thanks again for a great podcast."



Well, okay.  I probably used a poor example.  And I was reaching for, in the example of the Genie garage door, the garage door that would, if your network went down, it would just use your neighbor's, I mean, it would.  Mostly the concept here is to create a WAN; right?  The example they gave of their Amazon employees who just all took some gadget home, and all automatically L.A. Basin, the Los Angeles Basin, was completely covered with Sidewalk access, 900 MHz connectivity.  So that's really the point and the whole goal.  And I think it's very cool.



Skynet, who tweets from @fairlane32, said:  "I'm excited about Amazon Sidewalk in that if you could get pets that are microchipped onto the Sidewalk network, it may be possible, providing a lot of people participate, to locate them if they're ever lost.  Imagine being able to find those dogs and cats that get loose.  And with all the established social media groups using the network, you could possibly be able to find lost pets within hours, not days or weeks."  He says:  "But are those microchips transmitting on the 900 MHz spectrum?"



So I did want to clarify.  The microchips that I think he's talking about are not the tags, which are collar-based tags.  The microchips are little RFIDs.  They need to be pinged with energy.  They don't contain a battery in them.  It's just basically for serializing things.  So you could have a lost pet, and if it went to a vet or got to a vet who had a chip reader, then that would tell them who the pet belonged to potentially if you were registered. 



But in the Sidewalk example that Amazon gave, and this is working technology, it's a tag like the size of a square square; right?  You know, like an inch on a side and not very thick.  But it contains probably a 2032 or a 3032 mercury cell that'll last for some length of time.  And then, yes, that thing is on the 900 MHz network.  And also probably not persistently.  It probably pings the network to sort of save battery and periodically announce its location, which would allow then some finding knowing which part of the network was receiving the information.  And that would go to Amazon and then to the application server that would then be able to close the loop.  So anyway, just two interesting bits from our listeners.



InitDisk, the free USB thumb drive formatting tool, is now at Release 4.  I mentioned it had been updated to 2 last week.  It's had two more releases.  We are overall at the release candidate stage for this project, the ReadSpeed project, where we've been for a couple weeks.  But a diminishing number of minor things are still popping up here and there.  My feeling is that it's much better to deal with them in our currently relatively quiet setting with people who've become very familiar with the project, than ignoring those edge cases and putting them off until a much broader public release.  So as very anxious as I am to get all of this work into the hands of a much wider audience, it makes more sense to first get it as right as possible.



And so to give you a sense, last week we found a system whose BIOS did not like the Master Boot Record which I was using on the original couple InitDisk releases.  And that was the MBR, the Master Boot Record, from Windows 2000, which is a highly regarded way to boot.  And I deliberately chose it for its maturity and its assumed compatibility.  But that system did like the MBR from Windows 7 because remember the Master Boot Record is a little table of four entries describing the partitions that follow.  But it's actually executable code.  So it matters what's in there.  It's not just the table.



The BIOS doesn't know about an MBR.  It just knows to jump to the beginning of the first sector of the media, which then is a series of instructions that takes control, scans the table, looks at the entry, and then jumps out to the proper partition and runs its first sector in order to begin booting the OS.  Anyway, we're now, as a consequence of having discovered that there was a system that didn't like the Win2K, we're now using Win7 as the Master Boot Record.  And so far nobody's had a problem with it.  We got an increase in compatibility, which of course is my goal.



Also somebody had a USB thumb drive that just refused to work on his Win10 machine.  He was able to bring up a temporary Win7 PE system where it would work.  And since my clear goal has been to create a single USB formatting utility that easily and always works everywhere for everyone, I needed to figure out what was going on.  We struggled with that one for a couple days, trying all kinds of different things, until I realized that something about the history of that particular USB stick and his particular Windows system had to be the problem.  So now InitDisk explicitly deletes any prior drive mounting history for that device as it's formatting it.  And it completely cured his problem.  So again, who knows how many other people would have been hit by that.  Now they won't be.



Oh, and then a couple of people have dying drives that are in really bad shape, so bad that they barely benchmark.  But I was able to improve the error handling on the benchmark so that it would keep looking for a nearby block of storage where it might be able to succeed.  That's now much more robust.  So of course the upshot of all this is that our already public InitDisk utility is now at Release 4, and it's better than ever.  And this is the technology that the ReadSpeed Benchmark Windows prep  utility will be using, as will the next SpinRite.  So because we're going to be off next week with a Christmas flashback best-of edition, that's two weeks before you're going to hear from me again.  And I'm sure I'm going to be telling you that it's ready for you to all play with.  So I'm excited about that.



LEO:  Oh, that would be exciting.  So you're going to start working hard on Christmas.



STEVE:  I'll start off the New Year with that good announcement, yup.



LEO:  All right.  Let's talk about SolarWinds.  First of all, what is SolarWinds?  It's a security tool?  



STEVE:  No, SolarWinds is a company that produces an extremely popular network management system.



LEO:  Network management, okay.



STEVE:  Yeah.



LEO:  It's like a dashboard or something.



STEVE:  Oh, no, no.  I mean, it's a physical appliance.



LEO:  Oh, it's an appliance, oh.



STEVE:  Like for example it contains, unfortunately, all of the credentials on the network.  And like it specializes in managing them for large organizations and enterprises.



LEO:  Okay.



STEVE:  So, I mean, it's not something that you want to have compromised.



LEO:  Absolutely not.



STEVE:  Okay.  So the story begins with last Tuesday, a week ago, last Tuesday's news and admission from FireEye that they were hacked.  Now, they're a $3.5 billion security company, one of the largest of its kind in the world.  It's 16 years old, founded in 2004.  FireEye has more than 8,500 customers spread across 103 countries, and more than 3,200 employees worldwide.  So I mean, this is like a serious big security firm.  We've talked about FireEye often in the past.  They've not been on our radar for a while, but I remember their name came up a lot years ago.



So in his disclosure of this event, their CEO, Kevin Mandia, explained at that time what they knew.  So this is one week ago today, so it was on the 8th.  He said:  "FireEye is on the front lines defending companies and critical infrastructure globally from cyber threats.  We witness the growing threat firsthand, and we know that cyber threats are always evolving.  Recently, we were attacked by a highly sophisticated threat actor, one whose discipline, operational security, and techniques lead us to believe it was a state-sponsored attack.  Our number one priority is working to strengthen the security of our customers and the broader community.  We hope that by sharing the details of our investigation, the entire community will be better equipped to fight and defeat cyberattacks."



He said:  "Based on my 25 years in cybersecurity" - this is the FireEye CEO - "and responding to incidents, I've concluded that we are witnessing an attack by a nation with top-tier offensive capabilities.  This attack is different from the tens of thousands of incidents we have responded to throughout the years.  The attackers tailored their world-class capabilities specifically to target and attack FireEye.  They are highly trained in operational security and executed with discipline and focus.  They operated clandestinely, using methods that counter security tools and forensic examination.  They used a novel combination of techniques not witnessed by us or our partners in the past.



"We are actively investigating in coordination with the Federal Bureau of Investigation and other key partners, including Microsoft.  Their initial analysis supports our conclusion that this was the work of a highly sophisticated, state-sponsored attacker utilizing novel techniques.



"During our investigation to date, we have found that the attacker targeted and accessed certain Red Team assessment tools that we use to test our customers' security.  These tools mimic the behavior of many cyberthreat actors and enable FireEye to provide essential diagnostic security services to our customers.  None of the tools contain zero-day exploits.  Consistent with our goal to protect the community, we are proactively releasing methods and means to detect the use of our stolen Red Team tools.



"We are not sure if the attacker intends to use our Red Team tools or to publicly disclose them.  Nevertheless, out of an abundance of caution we have developed more than 300 countermeasures for our customers and the community at large to use in order to minimize the potential impact of the theft of these tools.



"Consistent with a nation-state cyberespionage effort, the attacker primarily sought information related to certain government customers.  While the attacker was able to access some of our internal systems, at this point in our investigation we have seen no evidence that the attacker exfiltrated data from our primary systems that store customer information from our incident response or consulting engagements, or the metadata collected by our products in our dynamic threat intelligence systems.  If we discover that customer information was taken, we will contact them directly."



Okay.  So that was exactly one week ago today.  Then, two days ago, on Sunday, the other big and startling shoe dropped.  We'll stay with Kevin for the moment.  His Sunday update posting was titled:  "Global Intrusion Campaign Leverages Software Supply Chain Compromise."  They had discovered, FireEye discovered the  bad guys' point of entry.



Kevin wrote:  "In our announcement on December 8th we stated we would provide updates as we discovered additional information, in order to ensure that the broader community is aware of the evolving threats we all face.  As part of that commitment, we want to provide you with the following update on our investigation.



"We've identified a global campaign that introduces a compromise into the networks of public and private organizations through the software supply chain.  This compromise is delivered through updates to a widely used IT infrastructure management software, the Orion network monitoring product from SolarWinds.  The campaign demonstrates top-tier operational tradecraft and resourcing consistent with state-sponsored threat actors.



"Based on our analysis, the attacks that we believe have been conducted as part of this campaign share certain common elements.  First, use of malicious SolarWinds update, inserting malicious code into legitimate software updates for the Orion software that allow an attacker remote access into the victim's environment; a light malware footprint, using limited malware to accomplish the mission while avoiding detection; prioritization of stealth, going to significant lengths to observe and blend into normal network activity; and high OPSEC, operational security, patiently conducting reconnaissance, consistently covering their tracks, and using difficult-to-attribute tools."



He said:  "Based on our analysis, we have now identified multiple organizations where we see indications of compromise dating back to the spring of 2020, and we are in the process of notifying those organizations.  Our analysis indicates that these compromises are not self-propagating.  Each of the attacks require meticulous planning and manual interaction.  Our ongoing investigation uncovered this campaign, and we are sharing this information consistent with our standard practice.



"We have been in close coordination with SolarWinds, the Federal Bureau of Investigation, and other key partners.  We believe it is critical to notify all our customers and the security community about this threat so organizations can take appropriate steps.  As this activity is the subject of an ongoing FBI investigation, there are limits to the information we're able to share at this time.  We have already updated our products to detect the known altered SolarWinds binaries.  We are also scanning for any traces of activity by this actor and reaching out to both customers and non-customers if we see potential indicators.



"FireEye's mission is to make our customers and the broader community safer.  We are methodically uncovering and exposing this campaign piece by piece and working to prevent future attacks.  It will require coordinated action by public and private organizations to fully expose and mitigate this threat, and we intend to continue our efforts."



So then the interesting technical details.  They begin by setting the stage, writing:  "FireEye has uncovered a widespread campaign that we are tracking as UNC2452.  The actors behind this campaign gained access to numerous public and private organizations around the world.  They gained access to victims via trojanized updates to SolarWind's Orion IT monitoring and management system.  This campaign may have begun as early as spring 2020 and is currently ongoing.  Post-compromise activity following this supply chain compromise has included lateral movement and data theft.  The campaign is the work of a highly skilled actor, and the operation was conducted with significant operational security."  Then they get into the details.



"'SolarWinds.Orion.Core.BusinessLayer.dll' is a SolarWinds digitally signed component of the Orion software framework that contains a backdoor that communicates via HTTP to third-party servers.  We are tracking the trojanized version of this SolarWinds Orion plugin as Sunburst."  So that's their name for the malware.  And I'll just take a moment to note that this Trojan was digitally signed by SolarWinds, I've seen a picture of the cert, on March 24th of this year.  And once SolarWinds customers updated their systems to incorporate this malicious, though signed, properly signed by SolarWinds component, those customers were trojanized.



So the tech goes on:  "After an initial dormant period of up to two weeks, it retrieves" - this now malicious DLL - "retrieves and executes commands, called 'Jobs,' that include the ability to transfer files, execute files, profile the system, reboot the machine, and disable system services.  The malware masquerades its network traffic as the Orion Improvement Program (OIP) protocol and stores reconnaissance results within legitimate plugin configuration files, allowing it to blend in with legitimate SolarWinds activity."



I mean, this thing is deeply stealthed.  I mean, and even the DLL, they had to first get the DLL, reverse engineer it so that they could add their malware to it, and create a new DLL that did everything the old one, the original SolarWinds DLL did, plus add their trojan functionality, and then get that into the right place at SolarWinds so that, when they did the next update, it would get updated.  Or maybe they actually did, they got the source code repository - that probably makes more sense in retrospect - added their stuff to the source code repository, and then when the next DLL was built from the master source, along with it went the Trojan.  It was signed legitimately starting on March 24th of this year.  And every one of their customers, they have 30,000 users of this particular Orion technology, and they know that 18,000 of those 30,000 updated and installed this DLL, and it went live.



"The backdoor," they write, "uses multiple obfuscated block lists to identify forensic and antivirus tools running as processes, services, and drivers."  So, okay.  That means that this malware's deep knowledge of SolarWinds application software and network operation means that it was not a coincidental intrusion into SolarWinds, either.  So we started talking about FireEye, who found this in their network, and that set off the alarms for the industry. 



But SolarWinds was breached at some time before that as part of the setup for this.  The bad guys would have had to first see whether they could somehow arrange to get their malware merged into SolarWinds' codebase so that it would then be signed and sent along with the next update and subsequent updates.  They targeted SolarWinds because updates to this company's products would successfully spread any inserted compromise far and wide.  This was clearly a huge effort.



The tech note says multiple trojanized updates were digitally signed from March through May of 2020 and posted to the SolarWinds updates website.  And I have a link to one of them in the show notes - although HTTPS is turned into HXXPS, and there's brackets around the dot of the dotcom so that it's not an active link - for anyone who's interested.  That trojanized update file is a standard Windows Installer Patch file that includes compressed resources associated with the update, including the trojanized SolarWinds.Orion.Core.BusinessLayer.dll component.



Once the update is installed, that malicious DLL will be loaded by the legitimate SolarWinds.BusinessLayerHost.exe or SolarWinds.BusinessLayerHostx64.exe, depending upon system configuration.  After a dormant period of up to two weeks, the malware will attempt to resolve a subdomain of avsvmcloud.com.  The DNS response will return a CNAME record that points to a command-and-control domain.  The command-and-control traffic to the malicious domains is designed to mimic normal SolarWinds API communications.  Of course, this would allow the malicious traffic to slip through malware-aware intrusion detection systems.  The list of known malicious infrastructure is available on GitHub's web page.



"FireEye," they wrote, "has detected this activity at multiple entities worldwide.  The victims have included government, consulting, technology, telecom, and extractive entities in North America, Europe, Asia, and the Middle East.  We anticipate there are additional victims in other countries and verticals. FireEye has notified all entities we are aware of being affected.



"We're currently tracking the software supply chain compromise and related post-intrusion activity as UNC2452.  After gaining initial access, this group uses a variety of techniques to disguise their operations while they move laterally.  This actor prefers to maintain a light malware footprint, instead preferring legitimate credentials and remote access for access to a victim's environment.  This section will detail a few of the notable techniques and outline potential opportunities."  So there's a lot more in this that gets us down into the weeds.



So these folks were really clever.  The more details that emerge, the more you realize how much time and attention the malware authors put into this campaign.  For example, the IP addresses used for the campaign were obfuscated by VPN servers which were deliberately located in the same country as the victim so that the victim was using near country IPs, not for example some IP in Russia or China or somewhere that might itself have raised suspicion.  Local VPN server endpoints were set up just for this purpose.



So what we know:  SolarWinds networking and security products are used, as I said, by more than 300,000 customers, including Fortune 500 companies, government agencies, education institutions.  They used to have a page, SolarWinds did, bragging about all their customers by name.  But gee, I wonder what happened?  It's disappeared from the Internet.  And I looked on the Internet archive, and it had been removed from there, too.  So they're not at the moment bragging about their customer base, since that would provide a list of targets.



They also serve several major U.S. telecommunications companies, all five branches of the U.S. military, and other prominent government organizations such as the Pentagon, the State Department, NASA, the NSA, the Postal Service, NOAA, Department of Justice, the Office of the President of the United States.  So it's not difficult to imagine the frantic scurrying that has been going on over the past several days.  We don't know when exactly FireEye learned what we now know they know.  So there may have been like early access within the government before they made their Sunday posting.  The U.S. Department of Homeland Security, the U.S. Treasury, and the U.S. NTIA are all confirmed victims.



In an SEC filing, SolarWinds confirmed that the trojanized updates were installed by more than 18,000 of their customers.  They're a major government contractor, with regular customers including CISA, U.S. Cyber Command, the DOD, the FBI, the Department of Homeland Security, the VA, and many others.  And imagine being the U.S. NSA and learning that since March an extremely well-designed and carefully used spying agent has without doubt been operating within your network.  We don't know what protections the NSA might have.  But we know that they were unaware of it because this thing has been out in networks, 18,000 of them, since March of 2020 worldwide.  Maybe the NSA has fully separate networks, that this Orion SolarWinds product was only on the administrative staff network and not on the internal networks.  But there's no way this is not a huge event.



Citing industry sources, Reuters reported that despite a broad install base for the Orion platform, the attackers appear to have focused only on a small number of high-value targets, leaving most Orion customers unaffected.  And, of course, this is exactly how you would act if you had just landed the "golden goose" of all intrusions, arranging to have itself installed into many ultra-high-value targets.  You would want to protect that.  You would not want to be attacking low-value targets where the opportunity of being discovered was too high, not worth what you'd get in return.



Other people familiar with the situation told the Wall Street Journal that the Russian foreign intelligence service is believed to be behind the attacks and that "hundreds of thousands of government and corporate networks" have been opened to potential risk, making it a notable attack that goes far beyond the garden variety espionage attempt.  Now, hundreds of thousands of government and corporate networks, that seems like a bit of an hysterical exaggeration.  But it's true that any networks that were accessible by any of the compromised networks would have been put at risk through lateral motion.



And Leo, at the Russian Embassy in Washington, D.C., someone pressed a keyboard macro which apparently automatically typed the response:  "The reports are unfounded attempts of the U.S.  Fake Media to blame Russia."



LEO:  Of course.



STEVE:  Anyway, yeah.



LEO:  It is hard to attribute these things.  How is it that they seem so confident that it is Russia and Fancy Bear and all that?



STEVE:  Maybe we will learn.



LEO:  Kind of the fingerprint, in a way, of how these guys operate?



STEVE:  Again, because this is an ongoing investigation, they're not saying at this point.  But they are saying that it is Fancy Bear.  If SolarWinds knows how the bad guys gained that first foothold within their enterprise network, they're not saying yet publicly.  And of course the enduring trouble is that networks are networks of computers.  We all know that once a single computer has been infected with malware, the nature of malware means that it's never possible to fully trust that machine again.  You and I, Leo, have been talking about this for years.  You just don't know that you've got it all.  And this of course would be especially true for this presumed ultra highly sophisticated attacker.



But what makes matters so much worse is that it wasn't a single machine that was attacked, but a highly connected network management system which itself in turn had access to any number of other machines on the network.  We know how good these perpetrators are, so they may well have planned ahead for the day that their hack was discovered by planting entirely different malware in targets they don't want to lose access to after the way they got in has been closed.  I'd be surprised if they hadn't.



And to make matters worse, it turns out that Orion had been, and I'm using the past tense, a highly trusted component which by design was trusted to hold and deploy credentials, including the Domain Admin, Cisco/Router/Software root and enable credentials, ESXi and vCenter credentials, AWS/Azure/Cloud root API keys, and much more.  If you had the malicious Orion component on your network, all of those credentials must be considered to have been compromised now.



And let's not forget that these cretins had been crawling around since the end of March of this year.  The mistake they made  and they probably didn't make it until they had already done a lot more damage elsewhere  was in attempting to crawl around within FireEye's network.



Something tipped off FireEye to the presence of this extremely stealthful intrusion.  If it weren't for FireEye's detection, SolarWinds would still be unwittingly distributing malicious components, and this probably Russian espionage campaign would still be going strong.  So it was just the fact that a week ago something happened that FireEye noticed and said, what, wait, whoa, whoa, what is that?  And that's the only reason we know about this.  It's been since March 24th that that cert was signed containing the first update that was malicious.  So since then, some group believed to be Russian had access.  And we know from FireEye's forensics that these guys were really, really, really good.  They did not want to get caught.  They wanted to stay.



LEO:  Wow.  It's an amazing story.  And I think we'll never really know the whole story.  I mean, this is not the kind of thing that [crosstalk].



STEVE:  True.  It'll blow over.  And maybe the next presidential administration will put some sanctions on Russia for this behavior, if attribution can be made sufficiently clear.  We'll see.



LEO:  And the tools that they got, the FireEye tools, do we know much about them?  



STEVE:  Yes, actually.  Because FireEye is so embarrassed, they have published a whole bunch of stuff on their GitHub page.  So there is, like, they now no longer feel that these tools are proprietary.



LEO:  No point in keeping them secret, yeah.



STEVE:  Yup.



LEO:  This kind of reminds me a little bit about when the NSA hacking tools were breached, and they caused endless problems as they were reused in malware attacks.



STEVE:  Right.



LEO:  So, yeah, it's bad when these things get out.  Among other things.  All right, Steve.  Well, I was hoping you would cover this because this is - the story broke on Sunday, right before TWiT, and there wasn't much to say at that time.  I've been watching it with interest.  And now we know so much more, even in a couple of days.  So thank you for doing that update.



If you listen to this show, there are a few ways you can get it.  The first place to go is Steve's site, GRC.com.  He has 16Kb audio versions.  Sounds a little tinny, but it is a small file.  That's the advantage of that.  Even smaller, not much probably, is the text version of it.



STEVE:  It's searchable.



LEO:  It's searchable, which is nice.  And of course thanks to Elaine Farris for doing that.  He also has 64Kb audio.  That's all at GRC.com.  As soon as you get there, if you don't already have a copy of SpinRite, the world's best hard drive maintenance and recovery utility, the world's best SSD maintenance and recovery utility we now know - at least when you get 6.1 out it will be; right?  That's very exciting.  If you buy it now, you get 6.0, you will get 6.1, and you'll also be able to participate in the development of it, which is rapidly coming to a close.  So this would be a good time to pick up SpinRite:  GRC.com.  There's lots of other free stuff there, including of course the world famous ShieldsUP!, which gave the phrase "stealthed" to - even Apple uses "stealth."



STEVE:  Yeah, it's important.



LEO:  Yeah, everybody - it became the phrase.



STEVE:  Yeah, it became the jargon, yeah.



LEO:  Thanks to Steve.  We have 64Kb audio and video at our website, TWiT.tv/sn.  You can also of course get it on YouTube.  There's a YouTube channel for Security Now!.  You can subscribe in your favorite podcast player.  That's a good way to get it, so you get it automatically.  If you have questions for Steve,  couple of ways you can reach him.  His Twitter account is open to direct messages from all.  That's @SGgrc.  He also takes feedback at GRC.com/feedback.  We have a forum, twit.community.  Actually, go to www.twit.community if you want to sign up for that.  That uses SQRL, by the way.  If you have a SQRL account, you can sign up there easily.  We also have a live chat that's going on now and all throughout the day and night at irc.twit.tv.



All right, Steve.  We shall talk again in two weeks.  Remember next week's the best-of.  But we'll be back on the 29th with a look back at the year.



STEVE:  Right.  And we should remind our listeners that I will be on the Sunday show with you.



LEO:  The 20th, yes, this Sunday.  A very special OG TWiTsters episode with Steve, Jeff Jarvis, Paul Thurrott, and me.  That'll be a lot of fun.  I always look forward to these holiday episodes.  Thanks, Steve.  We'll see you next week, I mean in two weeks, on Security Now!.  Bye-bye.



STEVE:  Yeah, bye.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#799

DATE:		December 29, 2020

TITLE:		Sunburst & Supernova

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-799.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week, as we end 2020, we look at Chrome's backing away from a security initiative; Firefox's move to further thwart tracking; all of the browsers once again saying "No!" to Kazakhstan; the formation of a new industry-wide Ransomware Task Force; this week's widespread WordPress security disaster; the return of Treck's insecure embedded TCP/IP stack; and, yes, finally, the long-awaited announcement of the release of the ReadSpeed Benchmark which serves as a testbed and proof of operation for the next generation of SpinRite.  Then we look at everything more that has come to light three weeks downstream from the first revelations of the SolarWinds-based massively widespread network intrusion and compromise.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Yes, we're doing one last show in 2020, and we've got to wrap up the biggest story of 2020, the biggest hack of living memory, which means probably the biggest hack of all time.  He's going to give us the update on SolarWinds and Sunburst and Supernova, plus a lot of security news.  Yes, that's one area where the news never sleeps.  Steve Gibson is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 799, recorded Tuesday, December 29th, 2020:  Sunburst & Supernova.



It's time for Security Now!, the last show of 2020.  Yes, we have a brand new live show with this guy right here, Steve Gibson of GRC.com.



STEVE GIBSON:  And I think everybody is unified in saying good riddance to 2020.



LEO:  Oh, my god.



STEVE:  What a horrific year this has been.



LEO:  I can't remember a worst year.  Just awful. 



STEVE:  It's too bad, too, because I like the number.  It's all round and nice and clear sight, 2020.  But oh, my goodness.



LEO:  It should have been a good year.  It should have been.



STEVE:  Yeah.  So we're going to look this week at a bunch of stuff.  We do have a lot of news because of last week's best-of.  I went back all two weeks from now looking for everything that had happened since.  And, not surprisingly, a bunch of stuff happened.  Chrome is backing away from a security initiative of theirs for interesting reasons.  Firefox is moving to further thwart tracking, using again a really interesting, cool technology.  All of the browsers are collectively once again saying no to Kazakhstan.  We have the formation of a new industry-wide Ransomware Task Force, which is just good to see happening because of the scourge that's been this year.  We have, of course, the week's widespread WordPress security disaster du jour; the return of Treck's insecure embedded TCP/IP stack.



And, yes, finally, the long-awaited announcement of the release of the ReadSpeed Benchmark that I've been working on basically for six months, ever since I finished working on the USB boot prep stuff.  So basically here we have this year's work product ready for release.  And of course it serves as a testbed and proof of operation for the next generation of SpinRite.  And then we're going to conclude by looking at everything more that has come to light three weeks downstream from the first revelations of the SolarWinds-based, massively widespread, network intrusion and compromise.  So this Security Now! Episode 799, perfectly numbered for the end of the year, is "Sunburst & Supernova."  And I think another great podcast for our listeners.



LEO:  Can't wait.



STEVE:  We even have a, you were probably going to just say, also the bonus of it being a sponsor-free podcast.



LEO:  Commercial-free.  You know how at the end of the year all the radio stations do "And now another 99 minutes of rock and roll, commercial free, without interruption."  Let's tell you the honest truth.  Nobody's buying ads this time of year.  So it's not because we love you.  We do.  But no, we're not going to pause, we're just going to roll right through with our Picture of the Week.



STEVE:  And what's interesting, Leo, is that I would imagine our listenership goes up this time of the year because people have more available time to listen to...



LEO:  Don't get me started on the crazy wherefores and whys of advertising.  It's a nutty business, nutty, nutty business.



STEVE:  As you said, we do have just a fun Picture of the Week.  This, just based on the typography, anyone who's ever been a New Yorker reader will recognize that this really looks like it came from The New Yorker, although CartoonStock.com and CartoonCollections.com have their little watermarks on it.  But anyway, it's got two kids running a lemonade stand.  And normally the lemonade stand will have the price posted on it somewhere; right?  It'll say "10 cents," or I guess more recently "25 cents."  Anyway, this lemonade stand says nothing, just says "Lemonade."  And then in the foreground we have a man and a woman.  He's holding one of the cups, and apparently he's telling her, "It's free, but they sell your information."



LEO:  Oh, god.  That's a perfect cartoon for 2020.



STEVE:  It is, indeed.



LEO:  Now, I should tell you, because you'd normally need some breaks during the show for caffeination or hydration, that if you want I can do some jumping jacks, sing a song, do some tap dancing.  At any point, I'll be here.  You just say "Help me, help me," and I will take over.



STEVE:  And Leo, unless they're listening to it on the live stream, they probably have a pause button that they could press.



LEO:  Oh, that.  Oh, yeah.



STEVE:  If nature were to call.



LEO:  Oh, good point, yeah.  Never thought of that.



STEVE:  However, they will not be needing their fast-forward button in this episode, so we can get right in here.  We've got Chrome 87, which it turns out is quickly backing away from insecure form warnings.  We've had some fun from time to time at Google's expense with the way they tend to roll out new features that might have an impact on some of their visitors.  The most recent of these was that very gradual deprecation of the Chrome browser's FTP services, remember, where first only 1% of Chrome users were going to be denied FTP URLs.  It was like, really?  Anybody still uses FTP?  But again, Google is being nothing if not cautious.



But in this case, their very cautious approach is maybe easier to understand in the wake of a change that was just made in the most recent and still current Release 87 of Chrome, which is what we've got now, which they then immediately needed to roll back in an incremental update as a result of a surprising hue and cry from their users.  The change was one that we covered before it happened.  We were anticipating this.  And that's the enforcement of secure form submission with a warning if the form's target URL is not set to an HTTPS URL.



And when we talked about it, about that this would be coming to Chrome 87, I commented at the time that this announcement surprised me because I had assumed that everyone had long ago been enforcing secure form submissions.  It was years ago that we originally noted on the podcast that, even though nonsecure pages might themselves be just HTTPS, they could still be submitting their form data securely since it wasn't the URL of the submitting page, but rather the URL to which the form was sending its data as a query that really mattered.



And of course, while that was true, it was also still unadvisable to submit anything from an HTTP page since, being HTTP, anyone being able to establish a man-in-the-middle position would be able to edit the page's contents to, for example, have the page send the form's data elsewhere.  But in any event, with the release of 87, Chrome 87, Google finally joined the club of browsers that are enforcing secure form submission.  And again, surprisingly late.



So what went wrong?  Google apparently implemented their solution differently from everyone else's, since it began, at the release of 87, it began producing scary warnings shortly after it went live.  The trouble arose because, as we know, what web pages do is generate queries; right?  Web browsers query remote servers.  And so the way data is submitted is kind of a kludge.  They submit data in a query.  And queries can either be GETs or POSTs.  And in the case of a form, although you technically can send the data over a GET URL, that's considered really bad form.



So normally the URL is just some script, typically, running on the server; and the actual data which is sent is in a POST query in that query body, which contains the actual data being submitted.  And of course since it's a query, everything the browser does is a query, the server then responds.  And a typical response might be to return a page saying, you know, "Welcome back, Joey.  You have successfully logged on," or whatever.  But a more complex reply in the form of a redirect of the browser to another server URL domain might also happen.  It would be just as valid.  You know, the server in responding to the query can do anything it wants.  And it turns out doing that, that is, sending the user somewhere else, is also somewhat common.



What Google learned the hard way was that some of these form submission redirect responses are to nonsecure HTTP URLs.  And this doesn't represent any threat to the user-submitted data since the original form submission URL would be to an HTTPS URL, so the form's data will be transmitted with the encryption privacy and certificate authentication provided by HTTPS.  And wherever the receiving server wants to then bounce its user is really up to it.  But Chrome was originally or initially, at this launch of 87, it was being faithful to Google's HTTPS-or-die philosophy.  So it freaked out when, even after the form had been submitted, the user's browser was then bounced to a nonsecure HTTP page for whatever reason.



The user would receive a warning that was designed to be scary.  The warning was, you know, a big information icon, and it said:  "The information you're about to submit is not secure.  Because the site is using a connection that's not completely secure, your information will be visible to others."  Well, first of all, that wasn't true.  This would be presented after the data had been submitted, and the browser was then bounced somewhere else.  So, I mean, this was really a bug in Chrome's implementation.



So anyway, upon the release of Chrome 87, Google began receiving complaints from websites that their users were suddenly receiving these bogus warnings about insecure form submissions.  And it didn't take Google long to determine that it wasn't the submission itself that was triggering the error, but rather the post-submission redirect.  And so shortly after Chrome 87's release, Google's software engineer Carlos Joan Rafael Ibarra Lopez stated that they are disabling the feature in Chrome 87 to "adjust" it so HTTP redirects after a secure form submission do not generate a warning.  He wrote:  "After considering the unexpectedly large impact this change had on form submissions that involve redirects through HTTP sites, we've decided to roll back the change for Chrome 87.  We expect the configuration to be out later today, at which point it will take effect on the next Chrome restart."  He says:  "I'll ping this bug with updates."



He continued:  "We are planning to reenable the warnings in Chrome 88, tentatively going to stable on January 19, 2021; but warning only on forms that directly submit to http://, or that redirect to http://, with the form data preserved through the redirect so it won't trigger for the cases mentioned in this bug where the http:// hop did not carry the form data.  That being said," he said, "I still encourage sites to keep https:// throughout the whole redirect chain, as http:// steps will compromise user privacy by exposing the form target location, even if no form data is being exposed."  And then he says:  "Apologies for the issues caused by this new warning."



So apparently everybody else who has already been warning of insecure form submission did it the right way and didn't care if the follow-on redirect was HTTP because no one else is having the problems that suddenly Chrome 87 started to trigger when Google decided to do this.  And again, I'm really surprised that only now is Google doing this.  The only explanation is that their metrics must have shown that too many sites were still doing this, and it would have caused too many problems.  So they must have been deliberately holding back while continuing to push HTTPS everywhere until their own telemetry showed that, okay, the submissions that we are actually seeing are all to HTTPS.



So at that point they turned it on, but missed the fact from their pre-turn-on telemetry that there were redirects that were HTTP, and their implementation was actually buggy in producing a warning, a bogus warning.  And in fact even in what he posted, it still sounds like they're not actually telling the truth.  I mean, the idea that an HTTP redirect would carry different information than an HTTPS redirect, well, that's just not true.  So they're like, okay, not wanting to completely say, yeah, well, we just screwed up the way we implemented this.  But anyway, it's fixed.



This is really interesting about Firefox.  As we know, the original designers of the HTTP protocol understood that having browsers download the same static content over and over and over from a remote web server would be really dumb.  So from its first days, browsers employed local storage caching to effectively incrementally and conditionally move some of the remote web servers' more static data over to the users' side of the connection.  And this was managed by a clean and simple mechanism that allowed any web content to indicate for how long it was allowed to be cached.  And content could specify, for example, a "max age" for itself, and also a "not valid after" expiration time and date.  This would cause locally cached data to self-expire.



And if a browser already had something in its cache that a new page was requesting the redisplay of, it could send a new query for that existing content with an "if modified since" header which would tell the receiving server when the cached content had been received, and the server could then check with its local copy of the content to see whether that local content had been modified since the browser had received and stored its cached copy, and then the remote server would only - it would send back a reply, I think it's a 302, not modified, meaning go ahead, there's been no change at our end, at the server end.  Go ahead and immediately, instantly, redisplay from your local cache.  Otherwise it would send a "200 HTTP OK" with an updated copy of that cached content.  The point is caching has always been and is crucial to the performance of our web browsers.



The bad news is, unfortunately, because it inherently stores evidence of a user's browsing history, caching itself is subject to tracking and privacy abuse.  And we've seen this two years ago, Spectre and Meltdown and the whole idea of things like branch prediction which could be probed for which branches were taken inside an Intel silicon.  Anything that leaves any evidence of the past, we keep seeing examples of how that can be probed in order to create various sorts of vulnerabilities.



And, for example, recall that clever hack we talked about, where a tracking facility, in the case of a browser, a tracking facility would create an off-canvas link with a URL that it wanted to probe.  And then it would allow that to be rendered by the browser out of sight, and then it would check the link's rendered color, knowing that the browser would color previously visited links differently than new links.



So there's another, like, anything that is happening, there is enough industry behind tracking that somebody will figure out a way to take advantage of that.  So the problem is that today's browsers have been storing all of their cached content in single large pools without regard for the domain which sourced the cached item.  And this has led to trackers probing the shared cache pool for its content.



The World Wide Web Consortium, the W3C, has a response to this, which is known as "client-side storage partitioning," also known as "network partitioning."  And it's coming to our Firefox browsers with Release 85 of Firefox next month, in January of 2021.  According to Mozilla, the following network resources are not currently partitioned, but they will be, starting with the next release of Firefox 85.  Get a load of this:  the HTTP cache, the image cache, the favicon cache, connection pooling, style sheet cache, DNS, HTTP authentication, speculative cache, the font cache, HSTS, OCSP, intermediate CA cache, TLS client certificates, TLS session identifiers, prefetching, preconnect, and the CORS preflight cache.



In other words, all of these things are currently being cached to improve the experience of users, and that's going to change.  All of that is client-side state history data that could, unless proactively prevented, be sniffed by third-party domains, by advertisements, by third-party JavaScript libraries running in our web pages.



And while Mozilla's deployment of this new W3C standard client-side storage partitioning will be the broadest implementation of partitioning so far, turns out it's not the first.  The prize for being the first goes to Apple, who began partitioning Safari's HTTP cache seven years ago, in 2013.  We talked about this happening at the time.  And Apple then followed through by partitioning even more of their client-side data years later that was part of their tracking prevention campaign.



Google recently partitioned Chrome's HTTP cache.  That was just last month in Chrome 86.  And the results were felt immediately as Google Fonts lost some of its performance when fonts could no longer be stored and be shared globally in a global HTTP cache.  So unfortunately we're in this cat-and-mouse game where the technologies we're implementing just to improve the user's experience, in this case by caching content locally, is being, and there's no other way to say this other than abused, by this massive industry that wants to track users, I mean, and will expend obviously lots of time and effort to do so.  I mean, to me it feels like it's unfortunate we just simply can't outlaw all of this because it is not the way these systems were intended to be used.  And it's only being repurposed for abuse.



The Mozilla team has indicated that they expect to see some similar performance hits when Firefox's cache partitioning is brought online.  But they are committed to taking that hit in order to improve the privacy of Firefox users.  And Mozilla did say that one positive side effect of their deployment of comprehensive client-side partitioning is that Firefox 85 will finally be able to block supercookies, which are those files that abuse the shared storage medium in order to persist in browsers and allow advertisers to track user movements across the web.  In creating this really strict partitioning, supercookies will just stop working in the future.  So some nice mechanisms moving forward in Firefox.



One more bit of good browser news, which is that browsers are once again saying no to Kazakhstan.  We've reported this, all of these efforts incrementally through the years on the podcast.  And we reported some time ago that the government of Kazakhstan had been requiring their citizens to install a Government of Kazakhstan CA root certificate into each of their machines.  And of course we know why.  This would allow the government to perform what I would call "no complaints" man-in-the-middle interception of all web traffic of any and all of their citizens.



A Kazakhstan proxy would accept the remote connections from remote servers, decrypt, inspect, and then reencrypt the traffic under the Kazakhstan CA's identity, which would then be trusted because the Kazakhstan citizen's machine would have had installed a matching root CA.  So Google, Mozilla, Apple, and Microsoft all together said, "No you don't."  All four of those companies' browsers were recently updated to block any and all use of that root certificate.



A thread on Mozilla's bug reporting site first reported that this new certificate was discovered in use just over three weeks ago on December 6th.  The Censored Planet website later reported that the certificate worked against dozens of web services that mostly belonged to Google, Facebook, and Twitter.  So, you know, Instagram and WhatsApp and the various properties that each of those major social media sites own.  And I guess, you know, you've got to give these Kazakhstan government cretins credit for trying.



Remember back in 2015 the Kazakhstan government formally applied to have their root certificate included in Mozilla's trusted root store program.  But once it came to light that their entire purpose for this was to use the certificate to intercept their citizens' data, Mozilla denied the request.  And then shortly afterwards the government required its citizens to manually install its certificate when it couldn't get Mozilla to do so for them, but that attempt failed after organizations took legal action.



And then, more recently, August before last, in 2019, all browsers blocked a similar attempt.  And our listeners may recall the Kazakhstan government's dubious statement at the time.  Reuters reported that "Kazakhstan has halted the implementation of an Internet surveillance system criticized by lawyers as illegal when the government described its initial rollout as a 'test.'"  State security officials claimed they were trying to protect people in Kazakhstan from hacker attacks, online fraud, and other kinds of cyber threats.  Uh-huh, right.  Kazakhstan's president said in a tweet back then that he had personally ordered the test, which showed that protective measures would not inconvenience Kazakhstan Internet users.  The president said, don't worry, nothing to see here.  There are no grounds for concerns.



So anyway, they have tried this yet again; and, once again, they've been blocked.  Back in August of 2019, we conjectured that the only feasible path for Kazakhstan, if they really insisted upon doing this, would be to create a Kazakhstan national web browser, and that then that would be the only one that would be allowed to work in-country.  But of course the problem is these days it's the mobile platforms that have become dominant, and it is unlikely in the extreme that either Apple or Google or Microsoft would allow such a privacy-violating browser to be hosted in their app stores.  So its use would be strictly constrained to desktops, and it's not feasible to kill the operation of mobile applications these days.



LEO:  It's so hard to be an evil dictator these days.  I just...



STEVE:  Isn't it.  It really is, Leo.



LEO:  It's so frustrating.



STEVE:  That darn technology just bites you every time.



LEO:  Gosh darn it.  Man.



STEVE:  So at this point it's Browsers 3, Kazakhstan 0.  And that doesn't look like it's going to change anytime soon.



We have an interesting announcement of the newly formed Ransomware Task Force, the RTF.  The newly christened Ransomware Task Force is a group of 19, I guess they're loosely related, security firms.  We'll talk about them in a second.  Oh, yeah, well, security firms, tech companies, and nonprofits, which include Microsoft and McAfee.  Last Monday the group announced their plan to form a coalition to deal with the rising threat of ransomware.  The group will focus on assessing existing technical solutions that provide protections during a ransomware attack.  The RTF will commission expert papers on the topic, engage stakeholders across industries, identify gaps existing in current solutions, and then work to form a common roadmap to have issues addressed among all members.



The group's target is the creation of a standardized framework for dealing with the ransomware threat across all market segments.  The single framework will be based upon an industry consensus rather than individual random advice received from single contractors.  The 19 initial founding members reflect the group's commitment to building a diverse team of experts.  We've got Aspen Digital that describes itself as a policy maker group; Citrix, of course, the equipment vendor; the Cyber Threat Alliance, which is a cybersecurity industry sharing group;  Cybereason, a security firm; the CyberPeace Institute, which is a nonprofit dedicated to help victims of cyberattacks; the Cybersecurity Coalition, another policy maker group; the Global Cyber Alliance, a non-profit dedicated to reducing cyber risks; the Institute for Security and Technology, a policy making group; McAfee, of course; Microsoft; Rapid7.  Resilience, who are a cyber insurance provider, you can imagine they would like some help in this industry.



We've got the SecurityScorecard, a compliance and risk management organization; the Shadowserver Foundation, a non-profit security organization; Stratigos Security, cybersecurity consulting firm; Team Cymru, which is, we know, we speak of them often, a threat intelligence firm.  The Third Way is a think tank; the UT Austin Strauss Center, a research group; and the Venable LLP, a law firm.  So this Ransomware Task Force website, including full membership details and leadership roles, will be launched next month, in January of '21.  So I am sure that we'll be covering that.  And that's expected to be followed by a two- to three-month sprint to get the taskforce up and running and off the ground.  So it's going to be interesting to see how this develops and what they may be able to produce.  And it's just nice to see people stepping up, recognizing that we've got a problem here that could use some industry-wide consensus putting our heads together.



So this week in WordPress.  We have once again more than five million WordPress sites in critical danger thanks to their use of a popular plugin called Contact Form 7, which looks to be a nice outfit.  As I dug into this a little bit, I was impressed by what I saw from Contact Form 7.  If nothing else they are being responsible.  In this case, the trouble arises from a lack of sufficient filename sanitization in the plugin's file upload filter.  This allows a file of the form, you know, anything, xyz.php\t.jpg to be seen by the upload filter as a benign JPEG image file.  What could possibly go wrong?  Whereas it will be seen by the PHP interpreter as a valid PHP script, the trick being to use a so-called "double extension," you know, .php\t.jpg, and different components of the system parse that double extension filename differently, which therein causes the problem.



In this case the flaw has a CVE designation of 2020-35489.  Yes, we've got your CVEs.  Get 'em right here, 35,489.  And Astra Security, during a security audit for a client whose WordPress site was using the Contact Form 7 plugin, is where this was found.  A representative from Astra Security said:  "Seeing the criticality of the vulnerability and the number of WordPress websites" - more than 5 million - "using this popular plugin, we quickly reported the vulnerability. The developer was even quicker in issuing a fix."



As I said, impressed by Contact Form 7, whose domain is ContactForm7.com.  They didn't even bury this down in some obscure URL.  If you go to ContactForm7.com, right at the top of the home page it says:  "Contact Form 7 5.3.2 has been released.  This is an urgent security and maintenance release.  We strongly encourage you to update to it immediately."  And they said:  "An unrestricted file upload vulnerability has been found in Contact Form 7 5.3.1 and older versions.  Utilizing this vulnerability, a form submitter can bypass Contact Form 7's filename sanitization, and upload a file which can be executed as a script on the host server.  So props to them for stepping right up and alerting everyone.



And it was interesting, I was curious because this was a chronological listing of postings.  So I didn't have to scroll down very far, only down to August 24th of this year, so in the late summer, where I found "Heads-up about Auto-Updates."  They posted:  "WordPress 5.5 has introduced the auto-update feature for plugins and themes.  Keeping plugins," they wrote, "and themes updated to the latest version is a key factor in managing your WordPress site securely.  We strongly recommend you enable auto-updates for the Contact Form 7 plugin, but you should also be aware that there are risks involved in the use of auto-updates.



They said:  "In the following cases, consider disabling auto-updates and doing an update manually."  And there's three bullet points.  First, you use plugins that extend the functionality of Contact Form 7, that is to say, an add-on plugin.  So in this case I guess plugins can have plugins.  The second, you use a theme that overrides the CSS style rules of Contact Form 7; or, three, you apply coding customization of some sort to Contact Form 7.



They said:  "In those cases, updating Contact Form 7 or one of the plugins or themes that affect Contact Form 7 might bring about incompatibility risks between them.  And if you do it automatically, you might not even realize problems are occurring on the site."  They said:  "Managing your site's security is your responsibility.  Update your plugins and themes in a proper way.  If there is a plugin or theme that is an obstacle to updating other parts, you should make a decision to remove it."



So again, here we have a problem.  The fundamental problem is that well-meaning amateurs are able to create compelling plugins for WordPress which take the base WordPress system, whose security is pretty good, and completely wreck it.  The plugin authors aren't doing it on purpose.  But they're just not security expert PHP authors.  And it turns out there are all kinds of ways to get around well-meaning PHP scripts.  And this is like a weekly theme now for Security Now!, is how many tens of millions of WordPress sites are vulnerable to the most recently discovered problem.



So, boy.  If you're going to run, if you're going to host a WordPress site - and first off, don't.  But if you want to, the only way to do it is to really sequester a machine, maybe make it a VM if you don't have lots of hardware, really sequester it so that it has its own private SQL database.  Don't reach out and go touch like a common SQL store where you have everything else in your enterprise.  Give it its own local SQL instance on that virtual machine, and firmly firewall it so that it only has access to send and receive web, email, and DNS traffic.  And do your best to just really firewall and sandbox that thing because all the evidence - oh, and don't install plugins.  If you can in any way resist the temptation from, oh, this looks great, you know, whoa.  Just really try not to.  So wow.



It's disturbing when really widespread problems come back again.  And in this case we have the U.S. cybersecurity infrastructure and security agency that we're hearing more and more about.  It's a division of the DHS, the Department of Homeland Security.  This is CISA that has been very active in talking about the amazing SolarWinds attacks.  There's been lots of production of warnings and things.



In this case, they have warned of newly discovered critical vulnerabilities in the low-level TCP/IP software library developed by Treck that, if weaponized, could allow remote attackers to run arbitrary commands and mount denial-of-service attacks.  The specific four flaws affect Treck's widely used TCP/IP stack v6.0.1.67 and earlier, and were reported to Treck by Intel.  Yes, because Intel is one of the users of this widely used, IoT-embedded TCP/IP stack.  And you can just imagine where Intel has this thing.



Two of these four are rated critical in severity, and here's the problem.  Treck's embedded TCP/IP stack is deployed worldwide in manufacturing, information technology, healthcare, transportation systems, and elsewhere.  The most severe of the four is a heap-based buffer overflow in the Treck HTTP Server component that could permit an adversary to crash/reset the target device and even execute remote code.  It carries a CVSS score of 9.8 out of a maximum of 10.  And of course we know what that means.  Being in the HTTP server, any embedded device or IoT gizmo that exposes an HTTP service onto the public Internet, whether or not it provides strong access authentication, could nevertheless be compromised remotely.



The second flaw is an out-of-bounds write in the IPv6 component, which received a CVSS score of 9.1, so not 9.8, but still it's critical because it could be exploited by an unauthenticated user to cause a denial-of-service condition via network access.  So not exploiting remote code, but crashing the system remotely.  But if that system were a critical industrial control system, controlling something and needing to stay up, crashing it could be bad.  The two other vulnerabilities are an out-of-bounds read in the IPv6 component that could be leveraged by an unauthenticated attacker to cause a denial of service and an improper input validation in the same module that could result in an out-of-bounds read of up to three bytes via network access.  Okay, again, those both had much lower CVSSes.



Now, this next part I really like.  Get a load of this.  The CISA's disclosure said:  "Treck recommends users to update the stack to v6.0.1.68 to address the flaws.  In cases where the latest patches cannot be applied, it's advised that firewall rules are implemented to filter out packets that contain a negative content length in the HTTP header."  Yeah.  I love that.  So the hacks involve sending HTTP queries containing a negative content length.  So there is presumably code that's checking for a content length that's greater than some value.



But as we know, in two's-complement binary encoding, a signed negative value will appear as a very large unsigned positive value when it's interpreted by logic that's expecting to receive an unsigned length.  So a typical signed/unsigned type confusion problem.  Presumably somewhere they're doing a signed comparison.  But if you put in a negative value, like a minus sign in front of it, the interpretation code blows up and allows you to compromise the stack.



And here's the most daunting bit.  If the name Treck and the idea of disastrous TCP/IP stacks might be ringing some bells, it did when I ran across it, that would be because we first encountered these guys this past summer in June with the so-called Ripple 20 attacks, which were, remember, 19 different horrible security problems in Treck's massively widely used embedded TCP/IP networking products.  They named the large set of vulnerabilities "Ripple 20" due to the ripple effects that are inherent when problems exist at one end of a long supply chain.  The potential devastation will ripple out to affect hundreds of millions of devices.



And in fact, at the time it was estimated that Treck had, what was it, 105 different customers, and that these vulnerabilities probably affected more than a billion devices.  So to those 20, or actually 19, we can now add four new ones that are obviously trivial to exploit if you do your homework.  And in this case Treck's customers range from one-person boutique shops to Fortune 500 multinational corporations, including HP, Schneider Electric, Intel, Rockwell Automation, Caterpillar, Baxter, as well as many other major international vendors in medical, transportation, industrial control, enterprise, energy, oil and gas, telecom, retail, commerce, and other industries.



And, you know, we talked about this last summer, as I said, when these first 19 flaws were brought to our attention.  But it's made, you could argue, even more chilling today in the wake of the massive SolarWinds Sunburst intrusions.  It's one thing to know intellectually that probably most of our IoT devices are highly vulnerable to remote attack and takeover.  But what really puts a sharp point on that is the idea that we now know without any question that there are entities bearing us malice who also have the capability to turn these theoretical vulnerabilities into fully practical attacks.



At this point, because all of these IoT devices already have left the gate - I mean, they're installed.  There are billions of them - cameras, webcams, security cameras, home alarm systems, doorbells, I mean, just everything.  They're out there.  And they're all on the Internet.  They all have TCP/IP stacks.  It truly is chilling that this is happening.  And, you know, the next podcast is going to be 800.  That leaves us with 200, or actually 199.



LEO:  Don't remind me.  Don't remind me.  We've got 200 left today.



STEVE:  Yes.  So I think we're still going to be having some interesting podcasts before the curtain drops on this.



LEO:  But it'll all be fixed by 999; right?  After that it's all over.



STEVE:  Oh, exactly, Leo.  We're going to scrap all of these first-generation IoT devices, and we're not going to have any more problems.



LEO:  Kazakhstan's going to have a root certificate, and all's right with the world.  It's just a matter of time, 200 episodes.



STEVE:  Wow.  Wow.



LEO:  Wow is right.



STEVE:  I have a bit of closing-the-loop feedback.  Anthony Lipke tweeted.  To @SGgrc, he said:  "I remain a fan of Newgrounds, a flash site."  And Leo, you ought to put in www.newgrounds.com.



LEO:  Dare I?



STEVE:  Just to see what it looks like.



LEO:  I've been getting calls like this all month from people who say, oh, no, my favorite site's on Flash.



STEVE:  Yeah.  This looks like the Revenge of Anime and eight-bit pixel stuff.  Anyway, Anthony says:  "I haven't seen something take that place for games and animation.  That said, they're part of great efforts to preserve the content.  You're likely already aware, but it seems worth mentioning besides just saying Flash is dead."  And, you know, I am sympathetic.  I mean, holding on, preserving Internet history and culture is kind of cool.  One could argue that the GRC.com website is inherently preserving Internet history because, yes, a lot of my graphics are blocky like eight-bits.



LEO:  Well, I should point - he'll get onto his thing.  But the Internet Archive has done - there's a Flash emulator, and they've done a great job, because that's their job, of preserving some of the stupidest Flash sites you have ever seen.  But it's part of our, you know, "Peanut Butter Jelly Time" is part of our culture.  So I agree with you 100%.  But the way to do this is not to keep sites like that alive, or to try to somehow save Flash.  By no means.  Let's let time move on.  But acknowledge that these were important in their day, yeah.  I completely agree.



STEVE:  Right, right.  So I did a little bit of digging around, and I discovered, because there is a concern out on the Internet, like okay, we need to still have Flash running.



LEO:  No.



STEVE:  So what can you do?



LEO:  No, we don't.  Stop it.



STEVE:  Well, certainly not in our browsers.  It was the browser.  It was the embedded Flash Player.  I mean, but Leo, I also agree with you.  I mean, it's like, yes, we have HTML5.



LEO:  Yeah.  You don't need AmigaDOS.  You don't need any, you know, this stuff's over.  We don't need it anymore.



STEVE:  Yes.  For those who are unwilling to move on, you can still get a standalone Adobe Flash Player if you google "flash player projector content debugger."  I've got the link to it in the show notes.  It is available, standalone, does not run in a browser, for Windows, Mac, and Linux, being published by Adobe.  My guess is you probably ought to get it soon because maybe Adobe, when they sunset Flash, like maybe in two days, on January 1st, this may go away.  But it's there now.



And then the other thing is there's something called BlueMaxima.org, and they have a Flashpoint web game preservation project.  And they said:  "Internet history and culture is important, and content made on web platforms including, but not limited to Adobe Flash, make up a significant portion of that culture."  Okay, well, I guess that's debatable.  They said:  "This project is dedicated to preserving as many experiences from these platforms as possible, so that they aren't lost to time.  Since early 2018, Flashpoint has saved more than 70,000 games and 8,000 animations running on 20 different platforms.



"Flashpoint was started in January 2018 by BlueMaxima in an attempt to outrun the disappearance of content prior to the death of Flash.  It has since evolved into an international project involving over 100 community contributors, encompassing both web games and animations created for numerous Internet plugins, frameworks, and standards."  So BlueMaxima.org/flashpoint.



LEO:  Yeah.  This is an emulator.  It's kind of like a Nintendo emulator or something like that.  That's fine.



STEVE:  Yup.  Yup.  So I just wanted to give Anthony his due and to say, yes, we do acknowledge that there is valuable historical culture and blocky eight-bit graphics so you can still be there if you want to.



LEO:  There's also a WebAssem Flash emulator, and there's one written in Rust called Ruffle.  This isn't going to go away.  Emulating Flash is easy.  Well, relatively.  But please, let's not try to save these sites online.  Let's get rid of them now.



STEVE:  And so I can announce...



LEO:  Uh-oh.



STEVE:  ...that ReadSpeed is ready.



LEO:  Yes.



STEVE:  Although this particular timing was never my plan, the first release of ReadSpeed Benchmark went widely public on Christmas Eve.  I tweeted it to my Twitter audience, and I am now formally inviting this podcast audience to give it a try.  The code had settled and had been stable for quite some time.  And I'd had time to get ReadSpeed's home page at GRC ready.  I annotated a sample run from my own large multi-drive test system, and I made an 11-minute video walkthrough of that Benchmark running with my own voiceover commentary highlighting the various events of interest which occur during that Benchmark.  So I thought it's finally time to let the world have a crack at it.  It's on the freeware page.  It's under Freeware Utilities ReadSpeed.  Or if you just google "GRC ReadSpeed" you'll find it.



And, interestingly, in parallel, there's been a lot of research work going on over in the SpinRite development newsgroup regarding SpinRite's ability to improve SSD performance.  So check out this before-and-after benchmarking of an OCZ Vertex 3 SSD.  One of the guys just posted this yesterday.  The Benchmark normally just summarizes the performance of a 1GB read at five different locations.  But you can add a /1, /2, /3, or /4 to request the display of greater and greater levels of granularity.  The cool thing is in this first chart you'll see that the 0% point of this OCZ Vertex 3, this is an SSD, it was reading that first gig at 300MB per second.  The second, at the 25% point, it was 320MB per second.  And at the middle, 324.



If you look then down at the numbers below the 0% line, you'll see that they're not really good.  There's a 177.9, then an 89.0.  These are equivalent megabytes per second for the individual pieces, individual requests.  But now look at the second chart.  This is after running a Level 3, a SpinRite Level 3 on that OCZ Vertex 3.  We went from 300MB per second to 354, 320 to 353, 324 to 352 and the rest.  And if you look at the same detail breakdown, it's all been repaired.  It's up to 360.



LEO:  Is that from trimming?  Or what is it doing?



STEVE:  No, because SpinRite is trimming naive.  It doesn't know about trimming yet.  That is, what we are seeing is that these big slowdowns are caused by bit errors which are requiring error correction code.  And so SpinRite in rewriting these regions is fixing the sectors.  It is exactly like it used to be in the days of hard...



LEO:  On spinning drives, yeah.



STEVE:  Yes.  Exactly like in the days of spinning drives.  So we're definitely seeing that SpinRite - we already knew that SpinRite could fix SSDs.  We've been sharing reports of those anecdotally for years of, like, my SSD died.  I "spunrote" it, and now it works again.  It's like, oh, okay, I guess that there will be a future for SpinRite.  Well, it's going to be even brighter than we thought because in the future SpinRite will be looking at the timing of the scan it does.  It will first do a characterization pass to learn about the performance of the SSD, and then go back and do spot repair of all the areas which are clearly in trouble of future failure and bring them back up to speed in the process.



So anyway, it's looking like we're going to be having a lot of fun for a number of years to come with SpinRite.  And there you're showing the annotated results of the Benchmark on my machine.  I then have in text some of the things that I found that were there.  And then that page has an 11-minute video that shows the Benchmark actually running as it goes.



LEO:  I just wish I could run this on a Mac.  



STEVE:  Yup.



LEO:  Nope.  That requires DOS, and that's life, yeah.



STEVE:  Also, just one other little last bit is that last week I announced InitDisk 4's release.  We ran across a weird problem.  We were having a situation, there were some anecdotal reports that InitDisk would sometimes produce a write error.  It turns out that someone in the SpinRite dev group had a USB stick that was producing that error.  So I got him to send me an image of that stick, and I was able to recreate the problem.  It only happened under Win10, not under Win7.  So it's something that Microsoft changed in Windows 10.



What I learned was that, if you were trying to run InitDisk - or for that matter ReadSpeed because they share the same technology, as will SpinRite and Beyond Recall.  If you were trying to reformat a USB drive under Windows 10, again, not other Windows, which had not been partitioned, because InitDisk is putting a partition sector down because we found that gives you better compatibility over time, Windows 10 would just freak out.  So I fixed that.  There is now InitDisk Release 5, and that was the last thing I needed to do before ReadSpeed was ready because, as I said, it inherits the same technology.



So lots of cool stuff coming out as Christmas presents for everybody.  And again, if ReadSpeed works for you, then so will SpinRite 6.1.  It uses the same technology.  It is basically a proof of technology for the new drivers that I will then, now, starting in 2021, shortly be moving over into SpinRite in order to create 6.1.  So lots of fun holiday news on that front.



Okay.  So we wrap with everything we've learned since our podcast two weeks ago and since the three weeks ago surprise disclosure by FireEye of the SolarWinds intrusion.  The malware that was first found was given the name Sunburst.  We now have a second piece of malware.  It's been named Supernova.  And it should not surprise anyone that more intelligence is being continually uncovered about this event, which is being called the biggest computer hack in history.  I'm sure all of us watching any television, any news shows over the last couple weeks, it was like, "the big hack."  And, I mean, it was a big deal.  And of course we should mention, Leo, that we had a great TWiT Sunday show.



LEO:  Yes.  People should watch that.



STEVE:  So any of our listeners, yes.  Any of our listeners, we got a lot of positive feedback about the "old guy" show on TWiT on Sunday. 



LEO:  Yeah, that was the December 20th version.  We did talk a lot about SolarWinds.  But it's an ongoing story.  I also feel like it's one that nobody knows what to do with because it doesn't seem like there's much we can do with it.  



STEVE:  No.  So one thing I want to clear up first was that two weeks ago I said that SolarWinds Orion was an appliance.  That was incorrect.  It's just a software system that can be loaded and run on any qualifying Windows system.  So I wanted to correct that for the record.  Not an appliance, it's just software.  And to my mind, the biggest revelation since the initial discovery of that Orion.dll being hacked, signed, and then delivered to approximately 18,000 SolarWinds customers via a software update is now that compelling evidence has been found of a second entirely separate backdoor in SolarWinds offerings.  The evidence leads forensic investigators to believe that this second, now it's being named the Supernova backdoor, was planted by a second threat actor.  And at this point, if you had any equity stake in SolarWinds, you're probably not happy because they've taken a serious reputation hit.



The second piece of so-called Supernova malware is an extremely sophisticated web shell which was also planted in the code of Orion's network and their applications monitoring platform.  It enabled the attackers to run arbitrary code on any of the machines hosting the trojanized version of the Orion software.  The web shell, it's a modified version of a legitimate .NET library DLL named "app_web_logoimagehandler.ashx dot" and then a serial number "b6031896.dll" that's present in SolarWinds Orion software.  And that DLL was very cleverly designed to get its nefarious job done while proactively evading automated defense mechanisms.



So again, this shows a high-level adversary, and it is believed a different high-level adversary.  So by design, the Orion software uses this DLL to expose an HTTP API which allows the host to respond to other subsystems when querying for a specific GIF image.  In his technical report, published on the 17th, Matt Tennis, a senior staff security researcher at Unit 42 of Palo Alto Networks, wrote that the malware could slip past even careful manual analysis since the code implemented in the legitimate DLL is innocuous and is of relatively high quality.  From Matt's introduction to this second threat, we also learned something significant about the attackers that hasn't been widely reported.



Matt wrote:  "The actors behind the supply chain attack on SolarWinds' Orion software have demonstrated a high degree of technical sophistication and attention to operational security, as well as a novel combination of techniques in the potential compromise of approximately 18,000 SolarWinds customers.  As published in the original disclosure, the attackers were observed removing their initial backdoor once a more legitimate method of persistence was obtained."  In other words, the attackers used their initial backdoor intrusion mechanism only until they were able to obtain keys to the front door, at which point the backdoor mechanism was shut down and went quiescent to avoid any chance of its detection.



In describing this second Supernova backdoor, Matt writes:  "The analysis shows that the threat actor added into the legitimate SolarWinds file four new parameters to receive signals from the command-and-control infrastructure.  The malicious code contains only one method, DynamicRun, which compiles on the fly the parameters into a .NET assembly in memory, thus leaving no artifacts on the disk of a compromised device.  This way, the attacker can send arbitrary code to the infected device and run it in the context of the user, who most of the time will have high privileges and visibility on the network.  It is unclear," he wrote, "how long Supernova has been in the Orion software, but a malware analysis system shows a compilation timestamp of March 24th, 2020."



And when I saw that, I thought, what?  The timing of that may seem to be very close to the March 6th, 2020 signing of the first instance of the original Sunburst backdoor.  But we have also learned that the initial intrusion by the first actor into SolarWinds was likely made back in the previous October 2019.  And that's news.  Okay.  Let me say that again.  We have since learned that the initial intrusion that the first actor into SolarWinds made was likely the previous October 2019.  What was discovered was a benign do-nothing change was found in the SolarWinds source code base dating back to October 2019.  It literally does nothing.  I have a picture of the decompiled source that was produced by a JetBrains decompiler showing that this call that was added does nothing but return. 



LEO:  That's interesting.



STEVE:  It literally does nothing.



LEO:  Why would you put that in?



STEVE:  The researchers conjecture that the change was injected just to allow them to determine whether this change would, A, go undetected; and, B, eventually be disseminated out into SolarWinds' global customer base.



LEO:  This is just a test.



STEVE:  Yes.  So the bad guys were SolarWinds customers.  Obviously they had access to all of this stuff in order to reverse engineer it.  So they infected the codebase back in October of 2019.  Didn't make a change that did anything.  But they wanted to see whether a subsequent update that they would receive from SolarWinds would contain that modification.



LEO:  And be signed and get through any security.



STEVE:  Yes, yes, yes.



LEO:  By the way, this is exactly what the Russian - what Fancy and Cozy Bear do.  They're very cautious and careful and step-by-step.  And it seems to be they often do test runs of their hacks.



STEVE:  Yes.  



LEO:  I mean, I'm sure there are many fingerprints that lead people to think it's - I think it was Cozy Bear they thought it was.



STEVE:  Yes.



LEO:  But that's, I bet, one of them.  I mean, what hacker does that?  Let's see, let's make sure it works before we go too far.



STEVE:  Well, and what, October?  It's like that's six months that they waited.



LEO:  Yeah, very patient, yeah.



STEVE:  So, yeah, they're in for the long term.



LEO:  That's a nation-state hacker, not somebody trying to get ransomware over the top, yeah.



STEVE:  Yup, exactly.  Matt says that this second intrusion was based upon the findings, that is, this Supernova bears the hallmarks of an advanced hacking group that took compromise via a web shell to a new level.  He wrote:  "Although .NET web shells are fairly common, most publicly researched samples ingest command-and-control parameters and perform some relatively surface-level exploitation."  In other words, he said that taking a valid .NET program as a parameter, that is, you're taking the program, they're feeding the program into this modified HTTP as a query parameter, which then performs an on-the-fly compilation assembly so that the remotely provided code is then running in memory, makes Supernova a rare encounter, as it eliminates the need for additional network callbacks aside from the initial command-and-control request.  Most web shells run their payloads in the context of the runtime environment or by calling a subshell or process such as CMD or PowerShell or Bash.



Microsoft believes that this Supernova web shell is likely the creation of a different adversary than the one that was first discovered by FireEye.  Microsoft wrote:  "In an interesting turn of events, the investigation of the whole SolarWinds compromise led to the discovery of an additional malware."  Now, you can imagine that these other guys are not happy because they engineered this different way and were apparently operating unseen for who knows how long.  I mean, remember that that was, what, March 6th?  So this second group has also been in and mucking around since March 6th.  So they're not happy that the first group got caught because, as Microsoft says, this led to the discovery of an additional malware that also affects the SolarWinds Orion product, but has been determined to be likely unrelated to this compromise and used by a different threat actor.



LEO:  Oh, that's such bad news.  Oh, my god.



STEVE:  I know.



LEO:  It's Swiss cheese.



STEVE:  Yeah, it's a mess, Leo.  And one argument for this theory is that, unlike the Sunburst DLL that slipped into SolarWinds source code repository and that was validly signed, Supernova does not carry a digital signature, suggesting that that second group were not in a position to do that.



Kim Zetter, writing for Yahoo! News, added some good detail to the saga.  He wrote:  "Hackers who breached federal agency networks through software made by a company called SolarWinds appear to have conducted a test run of their broad espionage campaign last year, according to sources with knowledge of the operation.  The hackers distributed malicious files from the SolarWinds network in October of 2019, five months before previously reported files were sent to victims through the company's software update servers.  The October files, distributed to customers on October 10th, did not have a backdoor embedded in them, however, in the way that subsequent malicious files that victims downloaded in the spring of 2020 did, and these files went undetected until this month.



"A source familiar with the investigation told Yahoo News: 'We're thinking they wanted to test whether or not it was going to work and whether it would be detected.  So it was more or less a dry run.  They took their time.  They decided to not go out with an actual backdoor right away.  That signifies that they're a little bit more disciplined'" - or I would say a lot more disciplined - "'and deliberate.'"



Okay.  One other little interesting bit is the original Sunburst malware, which was discovered by FireEye, used a Domain name Generation Algorithm to obscure the lookups that it was doing to find its command-and-control server.  And let's not forget that this was successful until whatever it was that FireEye discovered.  The cool thing is, as part of its detection avoidance system, the malware incorporated its own internal kill switch, that is, the malware had a kill switch.  So working together, Microsoft, FireEye, and GoDaddy have decided to cause the malware to shut itself down.



After the obscure domain name is generated as a subdomain of avsvmcloud.com, a DNS Address record lookup is performed by the malware.  The resolved address is checked against a hard-coded list of networks, basically to determine whether it is being probed, one of which happens to belong to Microsoft.  And if the IP address matches any of those networks, the malware will update a configuration key named "ReportWatcherRetry" to prevent its own further execution and will then terminate itself permanently.



So of course the reason this is done is that malware wants to detect when it is being run in a sandbox, right, when researchers have found a copy of it and are working to see what it does.  So one of the things that researchers will typically do is they will see that it's making DNS queries, and they will grab those and change them to a non-routable IP.  So sure enough, the IP kill switch list starts off with 10.0.0.0/8; 172.16.0.0/12; 192.168.0.0/16; 224.0.0.0/3; some IPv6 IPs; and then 20.140.0.0/15, which is a Microsoft IP block.  And there are three others.



So in working with GoDaddy, they arranged to have the avsvmcloud.com return this Microsoft IP, which could then, across the entire world, no matter where the malware was, it would see that, freak out, flip the ReportWatcherRetry switch, and then terminate itself in order to go quiescent.  But also note that the IP address querying for the domain's A record can be obtained, which is where GoDaddy comes in, to reveal the IP of the local DNS server resolving for any still-active malware.  Thus it's possible to determine who has any still-active intrusion.



So GoDaddy was the DNS provider.  They began collecting their records and finding all the IPs of anybody making those wacky queries to avsvmcloud.com.  That gave them a list of the DNS servers that were servicing the malware, and that allowed them to determine which organizations were infected.



There was another piece of this, also.  As we've often noted, of course, once a bad guy has been crawling around inside a network, especially a huge and complex network, and especially a highly skilled bad guy, it's never really possible - and this is to your point, Leo - to know that everything that they may have done while they were inside there has been found and reversed.  Remember, it's quite possible for malware to take up residence inside a printer, you know, we've talked about some years ago that did that, or a security camera, or pretty much anything else these days.



FireEye was quoted by the tech press, saying:  "In the intrusions FireEye has seen, this actor moved quickly to establish additional persistent mechanisms for access to victim networks beyond the Sunburst backdoor.  This kill switch will not remove the actor from victim networks where they have established other backdoors."  Meaning, yeah, sure, we've shut down the way they got in.  But one of the things we've seen them do is immediately establish backup ways to remain in after that backdoor has been shut down.



The U.S.'s CISA followed up, talked about the ongoing discovery of the breadth and the depth of this attack, saying:  "This APT actor" - Advanced Persistent Threat actor - "has demonstrated patience, operational security, and complex tradecraft in these intrusions.  CISA expects that removing this threat actor from compromised environments will be highly complex and challenging for organizations."



And one final point is that the obfuscation used by the domain name generator has been reverse engineered.



LEO:  Oh, good.



STEVE:  And logs, yes, logs.  Scroll down and look at the image, Leo, on the last page of the show notes.  Logs of previous DNS queries have been obtained and decoded.  This resulted in the discovery of many additional infected corporations who have not yet gone public with any disclosures.  And a bunch of them are quite tasty.  The biggest names on the list include the likes of Cisco, SAP, Intel, Cox Communications, Deloitte, Nvidia, Fujitsu, Belkin, Amerisafe, Lukoil, Rakuten, Check Point, Optimizely, Digital Reach, Digital Sense, and probably MediaTek.  So in the show notes we have a snapshot picture of some of them that have been decoded.  So we've heard a lot about the various public organizations that have been attacked, and government organizations.  But, boy, you can imagine there were some Christmases that were ruined by this disclosure in early December.



LEO:  No kidding.  So they now think there are two different, unrelated threat actors?



STEVE:  Yes.



LEO:  That's even worse.



STEVE:  Yes.  Yes.



LEO:  Because, I mean, that's the two we found.



STEVE:  Yes.  And the code of this web shell, the second one, as I mentioned, there is, I mean, it's sort of sad, too, because this DLL allows other components of Orion to query for a GIF, like to put a logo on the user interface.  That's what it does.  And so they slightly modified the HTTP server that this DLL runs to allow it to accept .NET source code...



LEO:  Terrible.



STEVE:  ...as a query parameter.



LEO:  Terrible.



STEVE:  So it then compiles whatever the attacker wants and runs it with the system privileges that this system is running under, not forking out a shell which would then be running under the user's privileges.  So it is a devastatingly clever hack and attack, and arguably worse than the first one we learned about.



LEO:  Yeah.  And yet I think the takeaway is...



STEVE:  If there's two...



LEO:  If two, there's more, and it was too damn easy.  So we're kind of in trouble.  I mean, I think maybe the notion of a secure system has to be rethought.  You start from scratch.



STEVE:  It's an oxymoron, Leo.



LEO:  It's an oxymoron.  It's really terrible.



STEVE:  I know.  It's disheartening.



LEO:  I don't know.  I don't know.  At this point you just - it's like privacy in general.  It's like, well, it's over.  So now what?  Security is history.  And that's why I think people feel like, well, what do we do?  It's not like...



STEVE:  Yeah.  And what's really interesting is that they have stayed a step ahead because we went from don't let bad guys in  to then saying, okay, well, maybe we can't keep them out, so we're going to have intrusion detection systems to detect them when they're in.  But they deliberately designed their traffic to look like valid traffic.  So the IDS that's like inspecting everything would go, yeah, nothing to see. Everything looks fine.  Meanwhile, .NET code is going by and is being compiled in RAM.



LEO:  Yeah.  But it's also hard to think what the end game is because, all right, they're in there.  Now what are you going to do?  I mean, is it industrial espionage?  Is it military espionage?  I would hope that at this point people in the military, for instance, are saying, okay, well, it's now back to zero-trust architectures.  We have to do a better job.  I don't know what the answer is.



STEVE:  Well, and it's why I've been preaching network segmentation now for quite a while.



LEO:  Yeah.  That's key.  That's key.



STEVE:  When it became so clear that we really cannot trust our IoT devices.



LEO:  Right.



STEVE:  They just have to be running on an isolated subnetwork within enterprises and within our own homes for peace of mind.  And it's a fun project for the holidays for our listeners.



LEO:  Yeah.  Steve Gibson, I'm so glad we didn't take this last show of the year off.  It's always important to get every bit of security information we can get.  And there's no better guy to get it from than Steve.  If you want to take a look at his new Benchmark, if you want to get a copy of the current version of SpinRite and be in line to get the next version the minute it comes out, it's all at GRC.com.  That's his website, the Gibson Research Corporation.



While you're there, you might want to check out the show because he puts 16Kb versions of the show, 64Kb versions, and very nicely human-written transcriptions up at GRC.com.  So you can get the show there.  You can get it from us at TWiT.tv/sn for Security Now!.  There's a YouTube channel.  You could subscribe there.  Or you could just get your favorite podcast application and subscribe and pick - we have video as well as audio - pick the version you like, subscribe.  You probably not only don't want to miss an episode, but I'm thinking you want to collect them and keep them because this is kind of an archive of the history of the world in the 21st Century that's just fascinating.



STEVE:  From Honey Monkeys on.



LEO:  Yeah, I mean, it's just fascinating.  And this SolarWinds thing is kind of the icing on the cake, I mean, not in a good way, but wow.  We do the show on Tuesdays, right after MacBreak Weekly.  That's about 1:30 Pacific, 4:30 Eastern time on Tuesdays, 21:30 UTC.  You can watch us do it live at TWiT.tv/live.  There's audio and video streams there.  Chat with us at irc.twit.tv.  Steve takes messages, direct messages.  He's open to all on Twitter, @SGgrc.  Or GRC.com/feedback if you've got questions, thoughts, comments.  And otherwise we'll see you next week because that's a brand new year.



STEVE:  And I'll also just mention, I forgot to mention that, if anyone just wants to take sort of a passive look, the forums.grc.com, the top of them are a set of forums, ReadSpeed Benchmark topics, where you'll find Booting DOS, Running ReadSpeed, ReadSpeed Results, ReadSpeed Problems, and ReadSpeed Release History.



LEO:  Nice, nice.



STEVE:  But just scrolling through ReadSpeed Results you can  immediately get a sense for what people are seeing, and lots of interesting dialogue there.  The forums have really taken off.  And of course I built them to allow us to have a public means of exchanging conversation about this work, and then SpinRite next.



LEO:  Nice.



STEVE:  And I can't wait to get started on SpinRite in 2021.



LEO:  Nice.  Very nice.  Yup, 2021, January 5th there'll be Episode 800.



STEVE:  Yay.



LEO:  We begin our last couple of hundred episodes.



STEVE:  The countdown.



LEO:  The countdown.  Thanks, Steve.  Have a great week, and I'll see you next time on Security Now!.



STEVE:  Thanks, buddy.



Copyright (c) 2020 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#800

DATE:		January 5, 2021

TITLE:		SolarBlizzard

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-800.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we open the New Year taking a longer look at fewer topics since the bad guys were apparently enjoying their New Year holiday, too.  So we look at an interesting kludge that's been forced upon Chrome by ill-mannered antiviral scanners.  We need to warn all enterprise users of Zyxel network border security products of another recently discovered built-in backdoor.  We look at the rise in IoT compromise swatting attacks and a series of new flaws and vulnerabilities in the PHP Zend and Yii frameworks.  We have a quick bit of miscellany to share, then I want to explain a lot about the value of trimming SSDs and newer SMR drives.  And we'll conclude by catching up with what will hopefully be the last news, for a while at least, of the disastrous SolarWinds breach and intrusions.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with a defunct football; a very bad AV security practice that Chrome has had to do something maybe even worse to fix.  We'll talk about the built-in password access in 100,000 Zyxel firewalls, VPN gateways, and access point controllers; an update on SpinRite 6.1; and a whole lot more.  Security Now! is coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 800, recorded Tuesday, January 5th, 2021:  SolarBlizzard.



It's time for Security Now!, the first show of 2021, Show 800, 800 episodes.  Steve Gibson, GRC.com.  Congratulations.



STEVE GIBSON:  I love that, 800 today.



LEO:  Yeah, wow, wow.  Well done. Feels like 800 years.



STEVE:  Yeah, well, it makes the math easy to do, Leo, because we know now that we have 199, counting this one, to go.



LEO:  True, true.



STEVE:  Before I run out of three digits, and then we're going to have a real dilemma on our hands.



LEO:  Well, we do, what, about a hundred - no, no, 50 a year, 52 a year.  So we've got time.



STEVE:  Yeah, we've got four years.  We've got four years.



LEO:  We've got four years, yeah.  There you go.



STEVE:  So this week we're going to open the new year taking a longer look at fewer topics since the bad guys were apparently enjoying their New Year's holiday as much as the rest of us were.



LEO:  Good.



STEVE:  Not much happened, really.  But there were some interesting things.  We're going to take a look at an interesting kludge which I will remind our listeners is really one of my favorite words.  Now that I know what "penultimate" means, we're going to all be talking about "kludge," which has been forced up on Chrome by ill-mannered AV scanners.  We also need to warn all enterprise users of Zyxel's network border security products, in which have been recently discovered another built-in backdoor, which is just unconscionable.  We're going to look at the rise in IoT compromise swatting attacks.  Really, this one's going to bone-chill you, Leo, because I know you, and you're just going to...



LEO:  Uh-oh.



STEVE:  And Lisa will be vindicated in her decision not to have any cameras inside the house.



LEO:  Oh, geez.



STEVE:  And also we have a series of new flaws and vulnerabilities in the PHP Zend and Yii, I guess that's how you pronounce it, Y-I-I frameworks.  We have a quick bit of miscellany to share.  And then I want to explain a lot about the value of trimming SSDs and newer SMR drives as a consequence of something which has just come up.  And I do have something of an announcement.  And then we're going to conclude by catching up with what will hopefully be the last news, maybe for a while at least, of the disastrous SolarWinds breach and intrusions, which is the reason that this podcast is titled "SolarBlizzard."



LEO:  It's more than wind.



STEVE:  And we do have kind of a blast from the past Picture of the Week.  So I think another fun podcast for our listeners.



LEO:  Good, good.  First one of the new year.  Did you have a good New Year's?  Did you do anything fun?



STEVE:  Yeah.  No.  Lorrie has some pretty bad asthma.  So she's already a little bit respiratory compromised.  And so we're double extra careful about exposing ourselves to any environment where COVID could happen.  She had been doing grocery shopping early in the morning.  Like when I would get up and head off, as I sometimes do, at 5:30, she'd take that opportunity to go be the first person at the grocery store, under the theory that there were just fewer COVID germs floating around in the air.  But now we've taken to using InstaCart and just having somebody else go pick up things.



LEO:  I think it's better, yeah.  Especially because you're in the L.A. area.  All the ICU beds are full.



STEVE:  Yeah.  And then she, like, wipes down everything.  I mean, even though somebody else picked it up.  And things that are delivered to the front door, they sit for a few days.



LEO:  Yeah, let them age.



STEVE:  Unless, I mean, so...



LEO:  Good, I'm glad you're taking care of yourselves.



STEVE:  So no, so we really are - and the fact that, at this point, if we only wait a few more months...



LEO:  So close.



STEVE:  Because we're in our mid-60s, we'll probably qualify, as the vaccine becomes available, to be vaccinated.  And once we're on the other side of that and have measured our antibody response to verify that it worked, then the game changes.



LEO:  Party.



STEVE:  I can't wait to get out of the house and go support all my favorite restaurants because I miss that.



LEO:  We were talking on TWiT, you know, the last time this happened, 1918, the Roaring Twenties happened after it was over.  I think we're going to have a Roaring Twenties here, too.  I hope so.  I look forward to it.



STEVE:  Well, and it is the case that restaurants are one of the most impacted things.



LEO:  I hope they survive, yeah.



STEVE:  And they never, I mean, restaurants are running on a razor-thin margin as it is, yes.



LEO:  Anyway, yeah.  We've had a lot of closings here in Petaluma.  There's just a lot of empty storefronts all over town now.



STEVE:  Yeah.  In the future they'll recover.  I don't even know if my favorite places are still around.  I'll go visit them after I've been vaccinated.



LEO:  All right, Steve.  Shall I show everybody this amazing Picture of the Week?



STEVE:  And you know, Leo, while you were talking, I was thinking, you know, maybe this was not time-based.  This might have been event-based.  I don't remember now.  Because I remember worrying about if I ever needed to change the battery, if I opened it up, would it lose its code.



LEO:  Oh, would it lose - yeah.



STEVE:  But maybe, I don't remember if I was worried about it losing its time or losing the key, the cryptographic key.



LEO:  But you have to press a button on this; right?  So that's why, you might be right, it might be button press; right?



STEVE:  Yeah.  Although that also could have just been to energize the display, so they were wanting to keep the power consumption down.  Anyway, we were talking cryptically about what we used to call the "PayPal Football."



LEO:  My first dongle.



STEVE:  Yeah.  And it looks to me from the display, I mean, it's been so long I haven't looked at it or thought about it.  But it looks like it's eight digits, for one thing.  So this picture was tweeted from one of our listeners to me with a little tear in his eye.  Rather than showing the apparently eight-digit code, it shows "batt 05."  And maybe that's the battery level, or I think it's just an error code saying battery is low, you'd better get this thing replaced before long.  Mine, I still have mine.  There it is.



LEO:  I'm sure it's going to be somewhere, yeah.



STEVE:  It's completely off.  I press it, and it doesn't even bother saying...



LEO:  This one was for PayPal.  But it was my first authenticator.  You know, shortly thereafter they added other ways of doing it, including text messaging and so forth. 



STEVE:  Right.  Well, so actually this was from VeriSign.  And so it was privately labeled by PayPal, but it was actually produced by VeriSign, and remember that they also had some eInk credit cards.



LEO:  Yes, yes.



STEVE:  And those were definitely event-based because they really had to be lean on power consumption.  But the point is, even this may have been event-based because, when you gave the number, I think one of our sharp listeners, as I recall, noticed that the least significant digit incremented.  Every time you pressed it, it looked like you got random gibberish, but when someone pointed it out, it was like, I'll be darned, he's right.



LEO:  Well, that's not good.



STEVE:  Like the least significant - well, and the point was that helped it deal with, I think, deal with time-based drift because it would - so you were only losing one digit of entropy by having the least significant digit increment.  Still, you had seven, which was even more than today's six because, you know, the standard that we settled on is a six-digit PIN which changes every 30 seconds.  So anyway, I just thought this was kind of cool.  I mean, back in the early days of the podcast, this was the first attempt at a multifactor authentication scheme.



LEO:  That's right.  That's how long we've been doing this.  This predates authenticators and all.  Now, an authenticator is a time-based one-time password, so it hashes the current time of day with a secret number to get that six digits.  How would event-based work?



STEVE:  Well, Yubico's are not time-based.  They are event-based.



LEO:  They don't have a clock; right.  Yeah.



STEVE:  The YubiKey, yes, it changes every time you do it.  So in the time-based, they're using a clock to drive the cipher that produces the digits.



LEO:  And I could see how that would work because the site you're on in the app also knows the time, and they could then compare it.  But how would they know what would be the right number if it's event-based?



STEVE:  And that's the problem.  So in the Yubico it's a counter which increments every time you press it.  So the idea is that there the individual sites are not empowered to determine the code.  They forward the code to Yubico that keeps the synchronized counter in its server; and it says, yup, that's a valid code for this person.  And then upon receiving it, they then increment it on their end.  So basically your device and a central server are maintaining a synchronized count by virtue of you from time to time sending them the most recent display from your device.



LEO:  Oh, that's interesting.  I had no idea.  And the YubiKey code is very, very long.  Some of it's static.  The most significant stuff is characters, is key-specific; right?



STEVE:  And that identifies you to the server so that it knows which database entry to go look at.



LEO:  Ah, of course; right.



STEVE:  Instead of needing to, like, look at them all and go, wow, who is this?  We don't recognize this person.



LEO:  Right, right.  That's very - I never even thought about that.  I thought, well, must have a clock in there.  All right.  Clever.



STEVE:  Yeah, cool.  So, okay.  We appear, and we'll touch on this in several different instances today, to be having more and more problems with the collision of evil forces with the forces of good, which are of course working to thwart the forces of evil efforts.  We've seen, for example, how it's no longer sufficient for code to simply be signed with a certificate, like that solves the problem.  Because today, as I experienced when I got a new certificate, newly minted code-signing certificates are not initially trusted, no matter the reputation of the certificate's signer or signee.



After all, since fraudulent certificates are possible, the only safe presumption must be that anything new that hasn't had time to earn itself a reputation must be mistrusted by default, even if it means generating some worrisome false positive alarms for users, until that reputation has been obtained or earned.  And even after going through all the trouble of obtaining a certificate and waiting while it earns a reputation for itself, the recent SolarWinds Orion experience has just demonstrated for the world that even code signed with a long-trusted certificate can still be evil.  So, yeah.  Everything is a mess.



Just yesterday I received a report in the GRC forums that McAfee AV was declaring one of ReadSpeed's DOS files, Splash.com, to be a trojan.  Okay.  Splash.com is a splash screen program that I wrote for ReadSpeed.  It is literally a splash screen.  When it's run, it puts the VGA adapter into 16-color 640x480 graphics mode.  It sets the color palette to the optimal 16 colors for the image.  Then it decompresses the image, whose data is the rest of the program, into the VGA's screen memory.  Since most of the screen is black, with only little blips of nonblack, I wrote a simple run-length compressor for that purpose.  And Splash.com contains a matching run-length decompressor.  So it must be that the random binary noise that's contained within the body of the program, by the purest of coincidences, matches some heuristic signature, causing McAfee to believe that Splash.com, a DOS program, is a trojan.



So last night, out of curiosity, while I was assembling this podcast, I decided to introduce Splash.com, which I just recently assembled from source code myself, I introduced it to VirusTotal to see how widespread this false positive was.  I put a screenshot of the top of VirusTotal's display in the show notes.  So it shows two out of 60 engines detected this file.



And as you can see, the scan is dated 1/05/2021, so that's in UTC, so that was last night.  The size is 15.2K, and exactly two engines said, "Whoa, Danger, Will Robinson.  You have a DOS trojan."  And that's McAfee that thought it was the Waft, whatever that is.  Daft is more likely.  And then McAfee-GW-Edition.  So yes, two McAfee engines, nobody else in the known universe, two out of 60 thought this was a problem.  And yeah, you know, if this actually was a trojan, you'd have to feel kind of sorry for it, Leo, since it would be running in...



LEO:  In DOS.  What are you going to find?



STEVE:  ...16-bit DOS, with hardly any memory around, and no Windows OS API to attempt to subvert.



LEO:  Can it read FAT-16?



STEVE:  No privilege to elevate to.  No return-oriented code to jump to the end of.  No TCP/IP stack.  The Internet would just be a far-off dream.



LEO:  Was it a TSR?



STEVE:  No.  No, it's not even - doesn't even try to stay resident.  The moment you - you either hit Escape or Enter, depending upon whether you want to go into the Benchmark or go to DOS prompt.  So it would be stranded and cut off from the world, sitting there, like, twiddling its little trojan thumbs.



LEO:  Apparently SpinRite will also trigger VirusTotal.  There's something about your assembly code, dude.



STEVE:  No one's ever seen anything like it.  Huh.  This is suspicious.  Nobody writes assembler any longer.



LEO:  It's assembly?  Holy cow.



STEVE:  Only crazy hackers do that.



LEO:  Yeah, Dave Redekop ran it, and three engines think SpinRite is up to no good.  That's hysterical.



STEVE:  Well, actually there is an interesting back story to that.  Presumably - now, how big is that?  Is it like a hundred and something K?



LEO:  169K, yeah.



STEVE:  Okay.  So that's the Windows EXE, which is not signed because, when I wrote the ecommerce system, back when SpinRite 5 was current in the early 2000s, digital signatures hadn't happened yet.  And the way SpinRite works at the moment is that every licensed version has the user's name and the serial number burned into the copy of the EXE.



LEO:  Oh, that's clever.  That's a good idea.



STEVE:  Yeah, so they're all getting their own custom EXE.  What that would have meant is that I would have had to do on-the-fly signing.  And as a matter of fact, I was just researching how to do that.



LEO:  Oh, yeah, because the signature's different for every one; right.



STEVE:  Yes.  And so the fact that it is, as David's drop of this onto VirusTotal noted, since SpinRite is not signed, that raises arguably a flag.  And what I was just researching the night before last was how to do automated EV signing of code because before long, happily, testers are going to want to be downloading SpinRite, and I'm going to want it to be signed, unlike SpinRite 6 that has just never been signed.  Well, catch up with the 21st Century, Gibson.  So we will be signing all future versions of this stuff.



LEO:  Good, good, good, good.



STEVE:  Yeah.  So anyway, all of that brings us to what inspired this preamble, which is a brand new instance of the cure often causing more trouble than the thing it's attempting to prevent.  We have the news that AV programs, antiviral programs, have adopted the practice of preemptively locking newly appearing files out of an abundance, or perhaps an overabundance, of caution.  They're doing this until that new file can be scanned and given the AOK for use by the system.  So it turns out that under Windows 10 this new preemptive practice has been creating some trouble for Chrome.



And the cure for this involves, as I said before, one of my favorite terms:  "kludge."  Wikipedia defines "kludge" as:  "A workaround or quick-and-dirty solution that is clumsy, inelegant, inefficient, difficult to extend, and hard to maintain."  And Wikipedia said:  "This term is used in diverse fields such as computer science, aerospace engineering" - where you really don't want a kludge; but, you know, duct tape - "Internet slang, evolutionary neuroscience" - where, yeah, pretty much humans are a kludge - "and government," where, yeah, that speaks for itself.



So what was Google's solution to antiviral scanners preemptively locking the files it was trying to work with?  Retry the operation until it succeeds.  Okay.  This is so sad.  It makes a mockery out of the term "computer science."  There's no science here.  This kludge was, you know, it's like, oh, we couldn't read the file?  Let's try again.  Couldn't read it?  We still can't?  Okay, let's try again.  Wait, we still can't?  Okay, let's try again.  This kludge was recently placed into the Chromium commit-queue, and thus into Chromium, to address Bug 1099284.



The posting reads:  "Retry ReplaceFile to protect against antivirus."  And the text says:  "Antivirus programs and other scanners may briefly lock new files which can lead to frequent problems with saving bookmarks and other files that use the ImportantFileWriter," which is the name of some function in Chromium.  They said:  "This attempts to deal with this by retrying the racy ReplaceFile step a few times."  And they said:  "This change also adds instrumentation to record how many retries are needed, for future tuning.  It also moves the SetLastError call as close as possible to the function that will consume the last error code."  And then they concluded:  "This is done only on Windows because it's hoped to be the only place where it happens."  So, you know...



LEO:  I bet you they're right.



STEVE:  ...if you're catching the failure and retrying until the operation succeeds, it's not clear to me how maintaining a record of how many retries were needed helps. I'm sure they realize that this is a horrific solution.  So perhaps adding some instrumentation makes it seem more highfalutin and covers up the fact that it's a horrible kludge.  And of course Google is the victim here, not the culprit.  From the standpoint of any program that's using the OS, the culprit is clearly the third-party afterthought add-on antivirus system which has effectively broken and significantly destabilized the underlying operating system.



So now all OS client programs like Chrome, Chrome happens to be the only one that we're seeing here who has preemptively hit this problem and is attempting to deal with it.  Think about it.  All client programs of Windows are, what, supposed to add retry code to their logic in order to deal with a badly written AV scanner that's causing the OS to transiently return errors?  No, okay.



If the authors of these AV scanners are listening, and I hope they are, please consider this.  Since any AV scanner that is doing this would need to hook the operating system's file system API, the proper way to do this is to suspend any OS client thread that's requesting access to any file that the AV system has not yet cleared for access.  Then, once the file has been cleared, the thread that was attempting to access the blocked file would be allowed to continue.  The request would succeed, and everyone would be happy.  Chrome wouldn't be forced to loop on waiting for the file to be ready for it, which apparently it's a bookmark, so it just created.  And apparently it then wants to open it in order to have an update of the bookmarks.  And that's mysteriously failing because the AV has jumped in and locked it out from underneath it.  That's just horrible.



So in that case the only thing that a client might notice if the AV were working correctly would be that the operating system call for the file took a bit longer than normal to complete.  But only real-time operating systems provide guarantees of maximum call response time.  And no one who has ever used Windows would confuse it with a real-time operating system.  So again, whatever this AV thing is that's doing this, it has broken the operating system significantly with this behavior, by causing files which it's scanning to be locked and thus failing a call that should otherwise succeed.



And so this is one of these problems where the cure is worse than the thing that it's trying to prevent.  There's nothing malicious about your bookmarks that Chrome just updated.  And yet the AV system is causing Chrome to fail.  What it should do is suspend any call which is trying to access a file that is currently being scanned, then decide one way or the other if it's okay or not and pass the call through, which keeps the OS from failing and allows the AV to be a good citizen in the OS, rather than causing these sorts of problems.  But, you know, this is what we keep hitting on these days is where problems are being caused by the things that are supposed to protect us - which, Leo, is why you and I are both saying no to these third-party add-ons.



LEO:  So did they ever indicate which AV is doing this?  Is it more than one?



STEVE:  No, they didn't say.  I imagine they know.



LEO:  Oh, I'm sure they know.



STEVE:  And they probably don't want to, you know, yeah.



LEO:  Some crappy AV probably, yeah.



STEVE:  Let's hope.  Let's hope there aren't many of them.  So I titled this one "zyfwp/" - that's all lower case, by the way.  Then we have "PrOw!aN_fXp."



LEO:  What is that?



STEVE:  If you just listen to this, you now have the ability to log into more than 100,000 Zyxel firewalls, VPN gateways, access point controllers on the Internet.  It's unbelievable.  Another, because this also happened in 2016, another hard-coded admin privilege backdoor account has been found that affects more than 100,000 Zyxel devices that can grant attackers right now, that are on the Internet, root access via either the SSH interface or the web admin panel.  And as ZDNet put it in their coverage, and I agree, they said:  "The backdoor account, discovered by a team of Dutch security researchers from Eye Control, is considered as bad as it gets in terms of vulnerabilities."



So owners of these devices, I mean, hopefully our listeners, if they have any Zyxel devices, by all means update.  They are advised to update systems as soon as time permits and, in any event, to immediately, if not sooner, disable external access, if you can - and it's not clear to me that it's possible, for reasons I'll explain in a second - to the device's SSH and web admin access.  Until that's done, anyone from DDoS botnet operators to state-sponsored hacking groups and ransomware gangs could abuse this backdoor, and I guarantee you they're at it right now, to access vulnerable devices and pivot to internal networks for additional attacks.



And here we are, 2021; right?  No one can any longer be naive enough to imagine that these backdoors would exist, be publicly known, be fully documented now.  I just read out the username and password because it's no secret, unfortunately.  It's going to happen.  So the device models affected include many of Zyxel's top products from its line of business-grade, not home devices as was the case in 2016, business-grade devices which are typically deployed throughout private enterprise and government networks:  the Advanced Threat Protection (ATP) series, which is used primarily as a firewall, except apparently it has a now publicly known backdoor; the Unified Security Gateway (USG) series, typically used as a hybrid firewall and VPN gateway; the USG FLEX series, used also as a hybrid firewall and VPN gateway; the VPN series, which is obviously a VPN gateway; and the NXC series, which is used as a wide-area network access point controller, a WLAN.



So since the roles of these devices place them at the Internet-facing edge of a company's network, once they're compromised, attackers are able to pivot and launch attacks against internal hosts.  And again, after what we've been through in 2020, one should imagine that this is going on.



So at this time patches are available from Zyxel for four of the five device families:  the ATP, USG, USG Flex, and the VPN series.  Patches for the NXC series are expected this Friday, January 8th.  In an interview with ZDNet last week, IoT security researcher Ankit Anubhav said that Zyxel should have learned its lesson from a previous incident that took place in 2016, our listeners may recall since we discussed it at the time.  Back then it was tracked as CVE-2016-10401.  Back then Zyxel devices contained a secret backdoor mechanism that allowed anyone to elevate any account on a Zyxel device to root, using the superuser password "zyad5001."



Ankit told ZDNet, he said:  "It was surprising to see yet another hardcoded credential in Zyxel products especially since Zyxel is well aware that the last time this happened, it was abused by several botnets."  He noted that the "zyad5001" password is still present in the arsenal of most password attack-based IoT botnets.  They'll give it a go on the off chance that it may still work and give them root access.



But of course this time the situation is much worse.  While the 2016 backdoor was a powerful elevation of privilege, it still required attackers to first gain access to a low-privileged account on a Zyxel device.  So they could then elevate it to root.  Today's backdoor grants attackers direct access to the device without any preconditions.  And Ankit observed that, he said:  "Unlike the previous exploit, which was used for Telnet access only, today's vulnerability requires even less expertise since it's possible to directly use the credentials on the port 443 web panel."  And, finally, the targets will be far more interesting to higher end attackers.  The 2016 flaw impacted home routers, whereas today's mess affects enterprise-grade devices.  



The Dutch researcher who found the backdoor in his own Zyxel USG40 performed an - oh, and by the way, he simply dumped the firmware and looked at it.  And there were the credentials sitting in the firmware, exposed for anyone to see.  So this also begs the question, who else may already have found this and known about it, and for how long?  The good news is a reputable researcher saw it, found it, verified it, and reported it responsibly to Zyxel.  I have a link to Zyxel's vulnerability report where they titled it "Zyxel Security Advisory for Hardcoded Credential Vulnerability."  And of course this can't be a surprise.  They did it; right?  It's in their firmware.  So the story of why this happened is, in my mind, as interesting as the fact that it did.



So get a load of what Zyxel says in this credential vulnerability report.  They said:  "Zyxel has released a patch for the hardcoded credential vulnerability of firewalls and access point controllers recently reported by researchers from EYE in Netherlands.  Users are advised to install the applicable firmware updates for optimal protection."  Yeah.  And they said:  "What is a vulnerability?  A hardcoded credential vulnerability was identified in the 'zyfwp' user account in some Zyxel firewalls and Access Point controllers.  The account was designed to deliver automatic firmware updates to connected access points through FTP."



Okay.  Then they said:  "What versions are vulnerable?  What should you do?  After a thorough investigation" - which, you know, okay.  They said:  "...we've identified the vulnerable products" - good for them - "and are releasing firmware patches to address the issue, as shown in the table below.  For optimal protection" - optimal protection, mind you - "we urge users to install the applicable updates."  And they said:  "For those not listed, they are not affected.  Contact your local Zyxel support team if you require further assistance."  Okay.



LEO:  Well, at least it could be patched.  That's good.



STEVE:  Yeah.  So, you know, first of all, what is wrong with this picture?  This doesn't really pass the smell test.  They claim to have deliberately hardcoded, knowingly, right, remote admin access credentials throughout their enterprise-grade product line for the purpose of delivering automatic firmware updates to connected access points through FTP.  Okay.  So maybe they're just extremely inept, or perhaps they're not telling the truth.  For one thing, the FTP port is not the one that's open.  It's the HTTPS port which is open and authenticates on these login credentials.



So more than anything else, this looks very much like an on-demand backdoor access to more than 100,000 enterprises.  And, you know, you wonder if Western users should worry that Zyxel is a Chinese network equipment manufacturer located in Taiwan.  I don't know.  But it just really is, I mean, you almost have to say that this could not have been deliberate because, if it were an attempt to put a deliberate backdoor into their products, they would have done a better job than just having the username and password in plaintext in the code.  I guess actually the researcher did say that it was a hashed password, so he apparently ran the hash through a hash breaker in order to determine what it was.  But the point is, it wasn't difficult for him to discover, and anybody else who was curious could have done the same thing.



And also my feeling is, if you want to know, if anyone wants to know how to do automatic updates, just look around.  Update clients, like they're saying these enterprise-grade security products are, don't hold listening ports open, waiting for updates to be sent in.  No.  No one does that.  Update clients periodically phone home to check in with the mothership to see whether anything has happened recently.  That's what Windows does; right?  That way no listening ports are ever externally exposed.



And the only thing a client needs to do upon receiving an update is to use a built-in public key to decrypt a hash of the file to verify its authenticity before copying it into its own firmware.  Only the authorized publisher of the product's firmware would have the matching private key that's used to encrypt the updated firmware's hash and include it for verification of the firmware's authenticity; right?  So this is easy to do.  But instead, Zyxel is saying, well, we've got servers with open ports listening for incoming connections, and they will accept them if they authenticate with this username and password which is in our firmware.



I mean, if that's true, that's insanely wrong.  And if they're saying this is the way we're handling updates is that we're going to be like listening for some sort of a FTP push update delivery system onto our clients, I mean, if that's the case, nobody should ever be using Zyxel equipment again.  And in fact, just the fact that they seem unable to do this in a secure fashion should put anyone off of them.  I used to like them.  The hardware seemed solid and well constructed.  I have a Zyxel dumb Internet switch around here somewhere, but I haven't used it for years because it was a 10/100.



But anyway, they have apparently failed to learn from their previous fiasco in 2016, and I'd stay as far away from these guys as I could.  If you do own their equipment, by all means, go get an update.  Apparently it's up to you to do so, despite the fact that they are claiming that their products auto update by receiving, you know - so, what?  Does Zyxel have a list of all the IPs of all their equipment out on the public Internet, and calls them with updates?  I don't know.



LEO:  That wouldn't make sense at all.



STEVE:  Again, as I said, it does not pass the smell test.



LEO:  A lot of times those backdoors are left in for in-factory testing or, I don't know, I mean - I don't know.  This doesn't seem...



STEVE:  Yeah.  The bad news is more than 100,000 of them are out there.



LEO:  Doesn't seem nefarious.  I mean, like what would be the point in doing that?



STEVE:  Yeah.  Maybe it just, I mean, or maybe they don't want it to look nefarious, so they did a really clumsy job of it.



LEO:  Just a bad job of it.



STEVE:  You know, say oh, well, obviously it wasn't on purpose.



LEO:  Just to be clear, by the way.



STEVE:  Because look how stupid we are.



LEO:  They're Taiwanese.  They're not Chinese.  So it's not like this is a Communist China plot to spy on us.  They're Taiwanese.  So, yeah, I don't know what the motivation would be.  Who knows?  It's a bad practice, obviously.



STEVE:  Yes.  Not well-designed technology.  Okay.  So Leo, this is a little uncomfortable, but it's important.  Swatting goes IoT.  So as I'm sure everyone knows, the practice of swatting, you know, SWAT as in Special Weapons and Tactics, involves pranksters, malicious pranksters calling police to report a nonexistent emergency which, if it were real, would necessitate a forced entry, weapons drawn, heightened alert response from local law enforcement.



Of course, local law enforcement has no way of knowing whether any given call for help is real or a dangerous and expensive prank.  So they might well be required to assume it's real, and that has certainly been the case in the past.  Swatting attacks are like a real thing.  Now, the U.S. Federal Bureau of Investigation, our FBI, is bringing awareness to an emerging trend where swatting victims' smart home security systems, and not just one or two, are being used to first launch and then observe swatting events.  Last week the FBI posted a public service announcement titled "Recent Swatting Attacks Targeting Residents With Camera and Voice-Capable Smart Devices."  I have a link to the public service announcement in the show notes.



The FBI wrote:  "The Federal Bureau of Investigation is issuing this announcement to warn users of smart home devices with cameras and voice capabilities to use complex, unique passwords and enable two-factor authentication to help protect against 'swatting' attacks," their own word in their announcement.  They said:  "Smart home device manufacturers recently notified law enforcement that offenders have been using stolen email passwords to access smart devices with cameras and voice capabilities and carry out swatting attacks."  Then they tell us what swatting is.



And they say:  "Offenders often use spoofing technology to anonymize their own phone numbers to make it appear to first responders as if the emergency call is coming from the victim's phone number.  This enhances their credibility when communicating with dispatchers."



So they said:  "How is this version of swatting carried out?  Recently, offenders have been using victims' smart devices, including video- and audio-capable home surveillance devices, to carry out swatting attacks.  To gain access to the smart devices, offenders are likely taking advantage of customers who re-use their email passwords for their smart device.  The offenders use stolen email passwords to log into the smart device and hijack features, including the livestream camera and the device's speakers.  They then call emergency services to report a crime at the victims' residence.  As law enforcement responds to the residence, the offender watches the livestream footage and engages with the responding police through the camera and speakers.  In some cases, the offender also livestreams the incident on shared community online platforms.



"The FBI is working with private sector partners who manufacture smart devices to advise customers about the scheme and how to avoid being victimized.  The FBI is also working to alert law enforcement first responders to this threat, so they may respond accordingly."  And so they end this announcement explaining to use strong email passwords, practice strong cyber hygiene, complex passwords that you've not used elsewhere, don't reuse the password that you use for your email, use multifactor authentication and so forth.  So bottom line, be really diligent about all of the good security practices we all know that we should be employing.



And so what we have here is another new way in which a failure to secure our perimeter might be used against us.  And for what it's worth, this style of livestreaming of intrusion isn't new.  Around Christmas a year ago, the publication Vice reported on a podcast called "NulledCast," which livestreamed to content-sharing platform Discord an incident where criminal actors hijacked a Nest and Ring smart home video and audio to harass the residents in creepy ways.  And so I don't mean to creep everyone out, but this is what was shown.  And I was thinking about, as I mentioned at the top of the show, Leo, how you had mentioned that Lisa didn't want cameras spread around the house.



LEO:  No.  Especially that drone.



STEVE:  Yeah, exactly.  One incident captured a man talking to young children through the device in their bedroom, claiming to be Santa.



LEO:  Oh, I remember that, yeah.  That was terrible.



STEVE:  Yeah.  Vice reported last year, and they said:  "In a video obtained by WMC5 - Action News in Memphis, Tennessee - courtesy of the family, you can see what the hacker would have seen:  a viewpoint that looms over the entire room from where the camera is installed in a far corner, looking down on the children's beds and dressers while they play.  The hacker is heard playing the song 'Tiptoe Through the Tulips' through the device's speakers.  And when one of the daughters, who is eight years old, stops and asks who's there, the hacker says, 'It's Santa.  It's your best friend.'"



So Vice also reported finding posts on hacker forums offering simple Ring credential stuffing software - which as we now know, "credential stuffing" the term for brute forcing - as little as $6 for the software.  And to their credit, Ring is responding.  By February of 2020, Ring had rolled out an added layer of security beyond its already mandatory two-factor authentication, which is the familiar one-time six-digit code to log on.  They also now have alerts when someone logs onto the account, and tools to control access by third-party service providers which could also be breached.  And Ring is also preparing to roll out, well, to roll out end-to-end video encryption, which was originally slated for release by the end of 2020.  It'll probably happen soon.



Ring's announcement last September 24th said:  "With end-to-end encryption, your videos will be encrypted on the Ring camera, and you will be the only one with the matching key stored on your mobile device that can decrypt and view your recordings."  So we could argue that should have always been there, but this is the way we learn.  And it is going to be there soon.  So the takeaway is the more our digital technology becomes intertwined with our analog lives, the more inherent exposure our analog lives are going to be having to flaws in the digital domain.



So I guess I just, you know, it becomes increasingly important to really take security seriously.  Clearly, people who are not security-conscious have a single password, probably for everything.  And yes, they used it for their email, and their email account got compromised by some website breach somewhere.  And they also use it to log into their Ring account.  And so not surprisingly, bad guys figured this out and took advantage of it.  Wow.



So we have a new serious problem in the PHP Zend framework.  Many of our podcasts through the second half of 2020 contained mentions of potentially serious WordPress vulnerabilities; right?  It got to be sort of a weekly event.  It's like, okay, what's the latest disaster in WordPress add-ons?  WordPress, of course, is written in PHP.  And somewhat incredibly, where a server's implementation language can be determined from a scan, 79.1% of those servers are hosting sites implemented in PHP.  So effectively 80%, rounding up, of the servers where the implementation can be determined, it's PHP.  And well-known sites written in PHP include Facebook, 360.cn, Wikipedia, Zoom, Microsoft, VK.com, and of course WordPress.  And two sites of note which recently switched to PHP are the Washington Post and Trip Advisor.



So PHP is clearly the current website implementation language of choice.  And its usage is not declining.  Its usage on the web has remained absolutely flat at 80% over the past year and a half.  The runners-up, you know, the also-rans, are Active Server Pages, Ruby, Java, and Scala, which together consist of the remaining 20% of website implementation languages, with Active Server Pages having the lion's share of those.  So it would be possible to simply write a site from scratch in PHP, and many people have.  But over time, web authors noticed that they tended to be writing and rewriting the same things over and over because there are so many things that different websites have in common.  So what this suggested was that PHP was still a little too low-level.



So frameworks were born to function as a sort of meta language function and class library implemented in and running on top of PHP.  And these PHP frameworks provide classes which abstract many of the common ways which all sites work, and the things that all sites need to do.  You know, like authenticating a user.  Why write that login code again from scratch?  Or storing site session data in a backend database.  Why create that all over, every single time that you're being asked to create a website?  So, yeah, obviously, lots of things that sites do are the same.  And by creating a class framework structure, this allows site creators to focus more on the site and less on the redundant mechanics of implementing a site from a very low-level language.



So against this background, we have newly discovered trouble in one of PHP's more venerable frameworks, Zend.  Zend is currently in use by more than 570 million installations.  And it's the most used framework by enterprises.  We've talked in the past about deserialization bugs in the context of Java, where a complex Java data structure needs to be stored or to be communicated.  So it's a bit like compression and decompression, and the decompression or deserializing phase is inherently an interpreter.



Unfortunately, as we've said, those who write the interpreters often implicitly assume that their serializer, which may always produce a sane and trustworthy serialization, is the only source, or will be the only source of the data that they are later being asked to deserialize.  And that assumption often leads to security flaws.  When attackers are able to provide the object to be deserialized, real trouble begins.



And sure enough, here we are again yesterday.  An untrusted deserialization vulnerability was disclosed in the Zend framework, which currently has, as I said, 570 million installations.  This flaw can be exploited by attackers to achieve remote code execution on PHP sites, maybe as many as 570 million of them.  The vulnerability is being tracked as CVE-2021, the first CVE we're discussing in 2021, 3007.  And from postings on GitHub, this also appears to impact Zend's successor project, known as Laminas, due to the fact that a significant amount of Zend's code, not surprisingly, was simply moved over into the new project's codebase.  The vulnerability exists in the most recent, and essentially it's the last Zend framework, 3.0.0, because now Zend has become Laminas.



The good news is no exploits have been released so far.  But then this just happened yesterday, so we'll stay tuned to see whether this ends up being turned into a weaponized attack.  At this point, I looked, and I could not find - I found instances of this coverage of this vulnerability everywhere.  No response yet from the PHP.  It was in, unfortunately, in the "destroy" routine.  And of course destroy is an often-called function.  Anytime you have a dynamic language where you are instantiating and then later destroying objects, you're going to be calling that a lot.



And in another PHP-related, but unrelated to Zend, posting yesterday, another deserialization vulnerability was also discovered and disclosed by the German RedTeam Pentesting group.  This one was found in the PHP framework Yii, Y-I-I.  I have a link to their full disclosure in the show notes, for anyone who's interested.  In their posting, the RedTeam guys note that insecure deserialization was #8 on OWASP's Top 10 list of web application security risks.  And Check Point mentions presentations about PHP deserialization flaw exploitation dating as far back as 2010, so 11 years ago.



This isn't news.  This isn't a new thing.  But it's the generic problem of deserialization in PHP has long been recognized and is obviously still present today, 11 years after it began being talked about.  And it's sitting there.  I think this OWASP Top 10 had it on their list in 2017, and it's there today.  So given PHP's crazy popularity, 80% of all websites, and the increasing intrusion pressure that we seem to be witnessing, I won't be surprised if we're talking more about deserialization flaws in PHP in the future.  And Leo, now for a little extra pain.



LEO:  Okay.



STEVE:  I will note that bitcoin is currently trading at $32,883.



LEO:  You want to feel more pain?  Goldman Sachs says they expect it to get to $146,000 in the next two or three years.



STEVE:  Oh, no kidding.



LEO:  How many did you have, 50?



STEVE:  Well, okay.  Now, the good news is one of your insights is the only thing that is providing me with solace.



LEO:  What's that?



STEVE:  Because you commented that, had I not formatted and installed Windows on top of my bitcoin wallet, I would have traded them for dollars a long time ago.



LEO:  Sure.  Oh, yeah.  When it hit a hundred bucks you would have traded it; right?



STEVE:  Yes, I would never - I would never.  Well, we started feeling the pain when it originally touched on $20,000, like a while ago.  That's where this happened and where it was like - in fact I think I did.  Actually I went around and I made absolutely sure that I did not have a copy of my wallet anywhere.  And I didn't.  I'm absolutely sure of that.



LEO:  Well, in some ways I feel happy that I can't unlock my wallet because I can't trade it in.  So I'm just going to, you know, as it goes up, I watch it, and I think, I really need to unlock that wallet.



STEVE:  $100,000.  That would be $5 million.



LEO:  And then it starts to really hurt, yeah, yeah.



STEVE:  Oh, boy.  It really does hurt, yeah.  I have had some fun tweets from people saying, you know, back when you talked about it, I think it was worth, what, 50 cents for a coin?



LEO:  If that.  It wasn't even that.



STEVE:  And that's - right.  And that's why, 50, oh, well, that was fun.  Format.



LEO:  Yeah, 25 bucks, big deal.  No one had any idea.  And that's why whatever I did with my wallet, I didn't, you know, I should have used LastPass and stored it.  But it didn't matter.  There was nothing in it.  It wasn't worth anything at the time.



STEVE:  Well, and you know, the brilliance of it, we talked about it at the time, is that the curve of the rate of bitcoin production was preordained.  It was going to plateau and level out.  And it's been following the curve that Yakatomi or whatever his name was...



LEO:  Satoshi Nakatoma.



STEVE:  That's actually - Nakatoma.  Satoshi, just Satoshi, right.



LEO:  Satoshi, yeah.



STEVE:  Yeah, so wow.



LEO:  Nakamoto, yeah.



STEVE:  Nakamoto, right, yeah.  I was joking because Nakatomi Towers was the building in "Die Hard."



LEO:  That's right.  That's right.



STEVE:  That was under attack.



LEO:  So, yeah, it got to 34,000 over the weekend.



STEVE:  Oh, Leo.



LEO:  It's a bubble.  It's just a bubble.  It's not, you know, it's got no real...



STEVE:  I don't think so.  I don't think so.



LEO:  Just keeps going up?



STEVE:  I think the fact that it is substantial and has become substantial, it has established itself as a storage of value, which it's, I mean, that's what it's going to be.  There are currency exchanges.  The IRS has woken up.  They're going to want their piece of the action.  And so, yeah, it's a real thing.



LEO:  It's amazing.



STEVE:  So, ha.  But again...



LEO:  What a world.  What a world.



STEVE:  I would never have known to hold them, so what the hell.



LEO:  It's a cruel, cruel world.



STEVE:  Oh.  And one of our listeners just sort of thought to correct me, and I thought, well, what the heck, I'll correct the record.  I referred to Yahoo News's Kim Zetter as "he" last week.  And it turns out "he" is a "she."



LEO:  Ah.



STEVE:  So in my show notes I actually used Kim's name.  But when I was just being a little more breezy, I said "he."  But no.  Sorry, Kim.  Not that you care, but we all know you're a she now.



Okay.  ReadSpeed and SpinRite.  We are continuing to see some, well, actually a flood of very interesting results from our podcast listeners who are experimenting with ReadSpeed and their SSDs.  So I have a link to a GRC forum post from last Wednesday by someone named Dale.  And I've got the data here in the show notes, so we don't even really need to bring the post up.  He wrote:  "Hi.  This WD 500GB Blue SSD was purchased 18 months ago and installed in a nine-year-old computer that served mainly, until recently, as a PLEX server, which probably accounts for the low speed in region 0."



And so he posts a run of the ReadSpeed Benchmark.  And the Benchmark log puts a timestamp, so you can see when it was that it was taken.  And so I got a kick out of the fact that this was at 12/28 at 16:19 was when he did this one.  And so it shows the drive identity information.  And what's really interesting is that for the first gig of that drive it shows that it was reading at 17.9 MBps, which is a snail crawl.  17.9 is lower than the inner cylinder of an old hard drive.  The 25% is at 349.3.  Then the 50% and 75% are at 544.7 each, exactly.  And the 100% is at 541.4.  So then he says in his posting, after running SpinRite at Level 3, and then we have, and the thing that I got a kick out of is that this one - okay.



So the first one is at 12/28 at 16:19.  This one is at 12/30, meaning two days later, at 13:06.  And so, yes, SpinRite currently probably did take two days to run on his half-a-terabyte WD SSD.  But it did.  It elevated the ReadSpeed of the beginning of that drive from 17.9 MBps to 326.5 MBps.  It elevated the 25% point from 349.3 to 532.7.  And then, interestingly, it dropped the 50% and 75% from their - each had 544.7, dropped them to 531.6 and 531.3, and the end to 534.5.  So what does all that mean?  Dale concluded...



LEO:  Yeah, why would they drop?



STEVE:  Exactly.  And that's why I want to talk about this.  It's really interesting what's actually going on.  He concluded by writing:  "Nice, way to go, Steve," because the Level 3 scan hugely, from 17.9 to 326.5, bumped up.  And similarly, the 25% point.  So I very much appreciate Dale's enthusiasm for the fact that the read performance of the first gig of his 18-month-old half-a-terabyte Western Digital SSD jumped from 17.9 to 326.5.  Obviously a huge improvement in his device's read performance.  And it's very likely that much more than that first gigabyte of the drive was similarly improved.  We don't know because currently we're only looking at the first gig.  SpinRite'll do much more than that, of course.  It'll do the whole drive.  Given how slow the front of his drive was, it had to be that the drive was struggling significantly to read back its data.



So this huge recovery of performance must also signify an improvement in the drive's future reliability.  At this point there is every reason to believe that this was a data-protecting thing that he did.  But there is a tradeoff that anyone doing this needs to be aware of.  And I wanted to talk about this so that everyone doesn't start running SpinRite Level 3 on their SSDs without considering this.  This tradeoff is apparent in exactly the question you asked, Leo, in Dale's 50% and 75% benchmark location numbers.  His SSD's read performance in that region appears to have dropped from 544.7 MBps to 531 MBps.  And I say "appears" because that's not actually what happened.  Those regions of Dale's SSD were not slowed down by passing SpinRite over them.



Instead, Dale's SSD now believes that those regions are in service and containing valid data, rather than knowing them to be blank.  And that is the important change.  SSDs and recent SMR (Shingled Magnetic Recording) format spinning drives maintain a logical to physical mapping layer.  When they are powered up, like for the first time, well, actually each time, this mapping is loaded into their onboard RAM for high-speed access.  Logical sectors are what the user sees at the SSD's interface, and physical regions are where that data is actually stored.  The creation of this separation, this abstraction layer, is the way SSDs perform wear leveling, by spreading repetitive writes to the same logical regions across different physical regions of the media.



Okay.  Now, one might imagine that at the start, a fresh and empty SSD would have a one-to-one mapping layer with all of its logical sectors uniformly mapped out across the physical medium with, like, everything's just ready to go.  But that's not the case.  A brand new unused SSD has an empty mapping table because, if nothing has been written to the SSD, there's nothing to read back.  So any read from an unused SSD doesn't even bother looking at the SSD's physical storage media.  That mapping layer already knows it's empty.  So in response to a read, the SSD instantly returns sectors of zeroes.  And thus its read performance appears to be amazing.  It saturates its interface's capacity.



And that's what those two 544.7s in Dale's 50 and 75% points were.  They weren't the speed of his SSD.  He had never written anything there ever.  And so the SSD knew that those regions were empty, and it just sent back zeroes as fast as the SATA III interface would carry them.  And that is 544.7 MBps.  That's the theoretical maximum speed for a SATA III interface.  Okay.  But once a SpinRite Level 3 refresh pass was made over the entire drive, rather than being partially empty, now its mapping table is full, with every logical sector assigned to an actual physical region of the SSD's storage medium.



So after SpinRite's pass over the SSD, the ReadSpeed Benchmark revealed the true read performance of the drive's media.  And it was quite a respectable 531.6 MBps.  Not very much slower than a SATA III link's maximum speed.  And we did observe that the frighteningly slow front region of the drive is now running far faster, and probably far more reliably for the future than it was going to before.  But there's also a new problem, which SpinRite in the future will be fully aware of and will handle automatically, but which SpinRite of today does not.



And the easiest way to express what a current SpinRite Level 3 pass has done would be to say that SpinRite will have fully untrimmed the SSD by writing across its entire logical surface, thereby leading the SSD to believe that the entire SSD is in use.  So leaving an SSD in an untrimmed state doesn't damage it in any way.  But it can impede the performance of future writes to those regions.  Okay.  So in order to write to an SSD's media, you know, the actual physical medium, the electrostatic storage capacitors of its cells must first all be discharged and drained of their electrons.  And only then can they be charged back up to the varying voltage levels required to represent the data bits which are being stored in each cell.



The hitch is that the erasing can only occur in relatively large page blocks which always contain multiple sectors, multiple logical sectors.  So if the SSD knows that one of these page blocks already has all of its cells discharged and drained and empty, it's able to bypass the discharge phase and much more quickly write new data, a sector for example, into that empty region.  All it has to do is charge up that sector's cells in a page that it already knows is blank.  But if the SSD believes that all of the logical sectors within a region may be containing valid data, because they have been previously written, if only by SpinRite performing a Level 3 pass, then in order to write one sector into that page, the entire page must first be read.  Then the entire page must be discharged and erased.  Then the entire page must be rewritten with only that one sector of its data changed.



And even when a lot of data is being written, not just one sector, writing one sector into a page is the worst case.  Often you're writing all of a page's sectors.  But even then, such that all of the sectors filling an entire page are being written, knowing that a page is already empty and discharged of all of its data allows the SSD to skip the discharge phase.  It wouldn't bother reading it if it knew it was all going to be rewritten, but it would still need to discharge it all.  But if it knows that the page is already empty, it skips the discharge phase and simply charges up the page's cells with their new data.



The process of informing an SSD that its logical sectors do not contain any useful data is known as "trimming."  And all modern operating systems are now, today, trim-aware.  And we've talked about this in the past.  In fact, we talked about this not long ago when it was found that Windows 10 was attempting to trim its hard drives.  It turns out that in that case this was being done in error by Windows 10.  And it was generating kernel exception traces in its logs.  But it turns out it's not as nuts as it might seem, since the latest SMR, as I mentioned, Shingled Magnetic Recording drives, actually share many of these same characteristics as SSDs.  And they do support and can benefit from the trim command.



And in fact there are instances of the same behavior being reported by the ReadSpeed Benchmark where SMR drives are reporting impossibly high performance in some of their regions because they're not actually being read.  The drive knows there's nothing there, so it just squirts zeroes back at 544.7 MBps.  So a trim-aware operating system is continually updating the SSD or SMR drive with information when specific sector ranges no longer contain active file system data.



The most common example would be whenever a file is permanently deleted from the file system, rather than being moved into a trash container.  When the SSD receives this trim information, it will likely unlink those storage pages from its sector mapping table and may place them onto a garbage collection list, which causes them to be scheduled for erasure in the background so that, when more storage is needed, already emptied pages will be ready to receive new writes.



And as I've mentioned before, SpinRite's awareness of its drive's contents will be raised from the drive's surface where it is today to include popular file systems.  The various flavors of FAT and NTFS will probably be added first, followed by the various file systems supported by Linux and other important OSes.  And this awareness will allow SpinRite to first of all run far more quickly on sparsely populated drives and to trim any empty regions that it might have the occasion to write to.



Now, the good news is today's operating systems often have the ability to trim on demand.  For example, in Windows 10 the PowerShell command is Optimize-Volume space -DriveLetter space and then for example C: or whatever, space, then -ReTrim space -Verbose.  And I have that down at the end of page 11 of the show notes.  When you run that, you are telling Windows 10, please retrim this drive letter.  Which is to say please go through the operating system and send trim commands to the SSD or SMR drive for all the known empty locations in the drive's file system.  And the good news is also various Linuxes also have trim facilities which are often invoked periodically through CRON.  So it may well be that Linux is just going to sort of catch up over time with any file system deletes that have been done.



So until we have a SpinRite that's aware of the file systems on our drives, and I'm doing nothing now other than working toward that goal, anyone who runs ReadSpeed and discovers slow performance at the front of their drive, which postings into the GRC forum are revealing to be surprisingly common, and who then chooses to perform a Level 3 SpinRite scan to fix those regions, could stop SpinRite before it gets out into the nether regions of the drive which are unused, or let SpinRite refresh the entire drive, which might result in having the drive take defective regions it discovers out of service.



Then, after booting back into your operating system, ask your OS to manually perform a full trimming of the drive, which will release and unmap all of the drive's unused space.  And after some period of time, the drive will have gone around and done its garbage collection, essentially preemptively erasing all the data from those now trimmed regions so that they are ready, standing by in a free page pool which the drive will automatically pull into service as it needs to do writes.



So there is everything we know about trimming.  And, boy, it's so cool to see this actually happening using ReadSpeed and SpinRite.  Oh, and of course, after you did the retrim command under Windows 10, you could rerun ReadSpeed again.  And I imagine Dale probably will.  I'd love to see his results.  And what you should find is the end of the drive will be back up at that impossibly high performance of 544.7 MBps because essentially the retrim has again told the SSD, don't worry, there's not actually anything that you need to worry about out there, so you're free to return zeroes.  Very cool stuff that we are seeing.



Oh, and the other thing you might try is just do a Level 2 first.  We don't exactly know why, but what we're seeing is just performing the Level 2 scan is bringing a lot of the performance back.  It's not really necessary to do a full refresh.  And of course a Level 2 is only a read pass, unless SpinRite actually sees some problems, in which case then it will drop down into a higher level to actually do some repair work.  So you might try a Level 2 first.  It's also a lot faster than a Level 3 because it's just breezing along doing writes, and the Benchmark is demonstrating that a lot of the performance at the front of these drives is recovered after a Level 2.



And speaking of SpinRite, Leo, Sunday evening, two nights ago, I posted to my progress tracking blog over in the forums an entry titled "I am at work on SpinRite v6.1 code."  I posted:  "10 days after ReadSpeed's release, the shakedown test of the benchmark's new hardware drivers has been a tremendous success.  We have identified only one problem with a system in Denmark using an old ASRock motherboard.  I've located and purchased one of them in Germany, and it's on its way.  So when it arrives, I'll see what needs to be done to get the drivers running on it, too.  But aside from that single problem, as far as we know, this new technology in ReadSpeed is ready for SpinRite's use.  So today, Sunday, January 3rd, 2021, I successfully assembled SpinRite's 31 assembly language source code files and created a working DOS executable.  Now I begin the work of incorporating the new drivers into SpinRite."



And in fact the show notes, which you had onscreen there a second ago, Leo, show an image I snapped of Visual Studio's Solution Explorer panel showing SpinRite 6's file set, and the new project SpinRite 6.1 in the header there.  So I am officially at work incorporating the drivers, which they have just turned out to be, well, as I said, surprisingly robust and ready to go.  I mean, as far I'm concerned, as fast as I can get them into SpinRite, we're going to have 6.1.



LEO:  How exciting.  Very good news.



STEVE:  Okay.  And our wrap-up with SolarBlizzard.  A new flaw was discovered in SolarWinds Orion software.  As we know, the way the bad guys were able to get their malicious Sunburst, as it's been called, malware deployed into victim networks was by poisoning SolarWinds' source code repository so that all new builds of their - I've got the hiccups.  It's not a Skype dropout, it's me hiccupping.



LEO:  It's a diaphragmatic dropout.



STEVE:  Okay.  Slow down, Steve.  So that all new builds of their executables would automatically and surreptitiously include the attacker's trojan.  Now we're learning the details of a different authentication bypass vulnerability which also exists in the Orion software, which may have been leveraged by adversaries as a zero-day - in other words, the bad guys, it may be different bad guys, knew about it - to deploy the other Supernova malware into specific targeted environments.  According to an advisory published by CERT, the SolarWinds Orion API that's used to interface with all other Orion system monitoring and management products suffers from a security flaw, it's been designated 2020-10148, that could allow a remote attacker to execute unauthenticated API commands, thus resulting in a compromise of the SolarWinds instance.



The advisory states:  "The authentication of the API can be bypassed by including specific parameters in the Request.PathInfo portion of a URI request to the API, which could allow an attacker to execute unauthenticated API commands.  In particular, if an attacker appends a PathInfo parameter of 'WebResource.adx,' 'ScriptResource.adx,' 'i18n.ashx,' or 'Skipi18n' to a request to a SolarWinds Orion server, SolarWinds will set the SkipAuthorization flag, which allows the API request to be processed without requiring authentication."



And remember that SolarWinds' updated security advisory of December 24th made note of an unspecified vulnerability in the Orion platform that could be exploited to deploy rogue software such as Supernova.  The details of the flaw had remained unknown until now.  So this is probably what that was.



Basically, I mean, I hope this was a bug.  I mean, it looks like of deliberate.  But let's hope not.  Let's hope that was just, I mean, the fact that you use the PathInfo, and you append Skipi18n, and that causes it to set the skip authorization flag, eh, okay.  Again, Leo, as you said, it may be that this has fallen on hard times from a development standpoint.  And as you also said of the Zyxel mess, sometimes lazy developers just put that stuff in so that they have access if they should ever need it.  And but imagine being an enterprise customer and learning that, well, yeah, there's a backdoor in the product you purchased from these guys in case they ever need to get in.  What?



LEO:  Unh-unh.  No.  No.  Eh.



STEVE:  And finally, last Thursday's Microsoft - and I had to double-take on this.  They're calling it the Soroagate.  I went, what?  Sororogate.  Sororagate?



LEO:  Solorigate.



STEVE:  Yes, thank you, Solorigate.



LEO:  That's not a good word.



STEVE:  So it was like, okay, Microsoft.



LEO:  Not a good word.



STEVE:  Microsoft Internal Solorigate Investigation Update.  It provided some interesting news, including that unauthorized access had been gained to some of Microsoft's source code.  Okay.  So that on its face sounds bad.  But the posting also shares some interesting philosophy, which I thought our listeners would really find interesting. 



Microsoft wrote:  "As we previously reported, we detected malicious SolarWinds applications in our environment, which we isolated and removed.  Having investigated further, we can now report that we have not found evidence of the common TTPs (Tools, Techniques, and Procedures) related to the abuse of forged SAML tokens against our corporate domains."  You know, the forged authentication tokens was one of the things, one of the IOCs, the Indications of Compromise, which was found to be common and often abused in networks.



Anyway, they continue:  "Our investigation has, however, revealed attempted activities beyond just the presence of malicious SolarWinds code in our environment.  This activity has not put at risk the security of our services or any customer data, but we want to be transparent and share what we're learning as we combat what we believe is a very sophisticated nation-state actor.  We detected unusual activity with a small number of internal accounts; and, upon review, we discovered one account that had been used to view source code in a number of source code repositories.  The account did not have permissions to modify any code or engineering systems, and our investigation further confirmed no changes were made.  These accounts were investigated and remediated."



And, now, here's the really interesting part:  "At Microsoft, we have an 'inner source' approach, the use of open source software development best practices and an open source-like culture, to make source code viewable within Microsoft.  This means we do not rely on the secrecy of source code for the security of products, and our threat models assume that attackers have knowledge of source code.  So viewing source code is not tied to an elevation of risk."



And that was news to me.  I think that's cool.  So I wanted to share that.  And it would be interesting to know whether this is the way Microsoft has always operated, or whether this philosophy represents some new enlightenment in the era of them being Linux-friendly and purchasing GitHub and all that.



LEO:  Yeah.



STEVE:  Yeah.  So that was very cool.  And of course, as we know, that's the right way to design things.  We've talked often about how the great step forward in the evolution of cryptography was not needing to keep your algorithm a secret, but publishing the algorithm and letting the academics go crazy and write Ph.D. theses and then having a key which you keep secret.  And so the algorithm is keyed.



LEO:  And in contrast, I remember reading that one of the things SolarWinds executives often pooh-poohed is the security of open source software, saying we're closed source, so you can trust us.  Oh, well.



STEVE:  That's right.



LEO:  Oh, well.  Great show, Steve.  I know the bad guys took a break last week.  Don't worry.  They're coming back.  No fear.  Oh, boy, are they coming back.



STEVE:  Yeah, they want to keep us busy here on Security Now!.



LEO:  Yeah, yeah.  They're providing fodder.  We do this show every Tuesday, right after MacBreak Weekly, just about 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  If you like to watch us do it live - which has its advantages and disadvantages.  You can see the before and after show chatter, but on the other hand all the swear words are still in and - no, no.  We don't really edit the show very much.



STEVE:  All of Steve's hiccups are still in.



LEO:  All the hiccups are still in it.  You can watch the livestream at TWiT.tv/live.  It's behind the scenes, the making of, that kind of thing.  If you're watching live, you should chat with us live at irc.twit.tv.  On-demand versions of the show are available at Steve's site, GRC.com.  He's got 16Kb audio, 64Kb audio, and transcriptions, which is very nice, plus the show notes:  GRC.com.  While you're there, pick up a copy of SpinRite.  If you buy 6.0 now, you'll get an upgrade, free upgrade to 6.1, plus you get to participate in the development of 6.1, which as you can see is quite active right now.



STEVE:  Yes, baby.  That's beginning now.



LEO:  Yeah.  We have 64Kb audio and video at our site, TWiT.tv/sn.  There's a YouTube channel devoted to Security Now!.  And of course you can subscribe in your favorite podcast client, and that way you'll get it the minute it's available of a Tuesday afternoon.  Our TWiT survey is on.  We do this once a  year at the beginning of the year.  As you know, we don't want to, nor do we have the ability really to gather information about who listens to this show.  We make it voluntary.  And it's helpful for us in selling the show and telling potential advertisers who's listening and so forth.  If you want to participate, the survey is online now at TWiT.tv/survey21.  It's our 2021 survey.  Shouldn't take more than 15 minutes.



I know a lot of you feel like "I've got to complete this.  I've got to get every answer."  You don't have to answer every question.  Answer it as best you can.  We always will get the people saying, "Well, I use four different operating systems.  You only mentioned three."  Don't worry about it.  Do the best, you know, give us the best information you can within the limits of the survey.  It is honestly very helpful.  When we can usually get 10, 20, 30,000 people to take it, I think it's statistically valid and makes a big difference in selling.  So thank you.  That's what keeps us on the air, of course:  TWiT.tv/survey21.



Steve, I've now embarked on Volume 2 of the Salvation Trilogy.



STEVE:  Yay.



LEO:  Really good.  You were absolutely right.  And, boy, on Sunday, I was berated by our TWiT panel for not having watched "The Expanse" yet.  So I started that last night.  You're right, it's quite good.



STEVE:  It is.  You need to, you know, it's a complex plot.  It's a little political with the Belters and the Martians and the Earthers.  But, oh, and boy, wait till you get to - like some of those battle scenes, they did some of the best space battle stuff I've ever seen made.



LEO:  I'm watching it and thinking, how are they doing the weightlessness stuff?  Are they underwater?  What are they doing?



STEVE:  It's really good.  



LEO:  It's very realistic.  Maybe they fly the Vomit Comet.  I don't know.  But it really looks - it looks good.  And the CGI is excellent, and it's a great script.  Of course, I have the novels, which you long ago recommended.



STEVE:  Yes.



LEO:  And I'm torn whether I should read the novels before I watch the show.  But I guess I'll watch the show and then read the novels.



STEVE:  I think you should watch the show.  I think that what the novels do is serve to anchor it.  It's so often the case that the best movies come from good writing of an underlying novel.



LEO:  Yeah, yeah.  "The Expanse," that's on Amazon Prime.  And it's beautiful.  I decided to watch it on the 4K TV; and, man, it looks good.



STEVE:  I forgot, I didn't ask you whether you had a chance to see "In the Shadow of the Moon."



LEO:  Not yet, not yet, not yet.



STEVE:  Okay.



LEO:  I wrote it down.  It's on the list.  Can't wait.



STEVE:  No problem.



LEO:  Yeah.  All right, Steve.  Have a great week, and stay safe.  We'll see you next week on Security Now!.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#801

DATE:		January 12, 2021

TITLE:		Out With the Old

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-801.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we address critical updates for Firefox and all Chromium-based browsers and a potentially unwelcome, but reversible, change coming to Firefox.  We look at another new tactic being employed by ransomware gangs; an update on ransomware's profitability; a bogus-seeming announcement from Intel during yesterday's CES; and the first use, on this podcast, of the term "teledildonics."  Following that, we have some residual SolarWinds news, the formation of a security screw-up crisis management group, news of the inevitable attacks on Zyxel users, the mass exodus from WhatsApp following their plans to force all metadata sharing, and a sci-fi note about "The Expanse."  Then, inspired by the amazing amount of old code I have rediscovered inside SpinRite, I will take our listeners back to the roaring '80s with a look at how far we have come from DOS v3.3, whose maximum partition size was 33.5 megabytes.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and we have lots to talk about.  Backspace is back, baby.  Steve will explain.  We'll also talk about Intel's CES announcement claiming their new processor can detect ransomware.  Can it?  Plus Steve's got a new security scale.  He calls it the "Cheeto scale."  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 801, recorded Tuesday, January 12th, 2021:  Out With the Old.



It's time for Security Now!, the show where we cover your security online, your privacy, how things work, how bad it's getting, how good it's getting, all that stuff with this guy right here, live long and prosper, Steve Gibson.  Wait a minute.  I've got to put the thumb out; right?  That's the key.



STEVE GIBSON:  That's right.  Thumb out.  Oh, Leo.



LEO:  I can't do it with my left hand.



STEVE:  Do I have a show for us today.



LEO:  What's the topic?



STEVE:  Well, the title is "Out With the Old," which was inspired after I got back into SpinRite 6's source code and realized how much crap was in there to deal with the things that we were having to deal with back in the 1980s and '90s at the beginning of the PC era.  And so first it was just going to be kind of like, you know, I'll just mention it.  But I just think our listeners will really find it interesting.  The old-timers will be going, oh, I remember when DOS had a 33.5MB partition size limit, believe it or not.  And younger viewers are going to be like, what?



So anyway, we've got so much to talk about.  We have critical updates for Firefox and all of the Chromium-based browsers, and a potentially unwelcome, but reversible, change coming to Firefox.  We're going to look at another new tactic being employed by the ransomware gangs, or at least one of them; an update on ransomware's profitability; a bogus-seeming announcement from Intel which was made yesterday during their CES announcement of the 11th Gen Core processors.  Well, I did dig in to see if there was anything to it, and now our listeners will...



LEO:  Oh, I can't wait.	



STEVE:  ...be left with no question about how I feel.  And we have the first use on this podcast of the term "teledildonics."



LEO:  Teledildonics.  Get it right.



STEVE:  Dildonics.  Oh, you're right.  Sorry, Leo.  Teledildonics.



LEO:  As anybody knows.



STEVE:  Yes.  Following that, we have some residual SolarWinds news, the formation of a security screw-up crisis management group, news of the inevitable attacks on Zyxel users, the mass exodus from WhatsApp following their plans to force all metadata sharing for users of their platform, a quick sci-fi note about "The Expanse."  And then, as I said, inspired by the amazing amount of old code I have rediscovered inside SpinRite, I'm going to take our listeners back to the Roaring '80s with a look at how far we have come from DOS 3.3.  Oh, and we do have a Picture of the Week for the ages.  This is just - this is so good.  It came without caption, and I thought, that's a Cheeto.  So, yeah.



LEO:  That could mean a lot of things.  Let's see.  I've got my T-bar stuck.  Wait a minute.  All right, good.  All right.  Unstuck the T-bar.  We've come a long way, baby.  That's the name of the subtitle on this show.  All right, Steve.  I'm ready with the Picture of the Week.  It does look like a Cheeto.



STEVE:  This is wonderful.  What we have is an attempt to show by clear visual analogy the effect of security when your username is admin and your password is admin.  In other words, it's probably what the default was for the device that came with it.  Versus a username of KoLpVXriw.  That's just the username.



LEO:  That's interesting.  Do you agree with that?  Because most places use your email as the password.  It would be, you know...



STEVE:  Oh, yeah, much better.  



LEO:  Why use something easily deduced, yeah.



STEVE:  Yeah, exactly.  So yeah, not using your email is definitely better.  Of course they do that because when you cannot remember that your password was set to I*$j">?ui$5, they need to be able to email you, to your username, a password recovery link.



Okay.  So by way of visual analogy, I'm sure our users are familiar with this very simple slider kind of door lock where there's a slider with a knob that rides in a slot.  And in order to lock the door you slide it over, and the end of it goes into a hole cut in a plate.  It's like a very simple door lock.  Well, that would be too secure if your username was admin and your password was admin.  So in this picture that sliding piece has been removed, and a Cheeto has been inserted.



LEO:  But Steve, it's a crunchy, flaming hot Cheeto.  Not your average Cheeto.



STEVE:  Better, it's a long, thin Cheeto, yes, in order to perform its task.  But it is probably a very good analogy for the equivalent security offered by leaving your username and password both set to their default.  And by comparison, over on the right side, where it takes a minute to enunciate the username and password, we've got multiple, redundant, all in parallel, different technologies.  That door might as well not exist.  It ought to just be a wall that runs right across there.



So anyway, this came from a Twitter follower.  Thank you so much for this.  I happened to dig back into some of his earlier DMs to me, and I found it.  I said, oh, this is too wonderful.  Yes, because the slider would be too secure.  If it's admin/admin, you need to put a Cheeto in there, Leo.  And then it's about the right amount of security.



So Firefox and Chromium have both already been patched for critical updates that were found in them.  Of course the two most important Chromium-based browsers are Chrome and Edge, but also pretty much everything else is Chromium now except for Safari.  They all required, and it's nice to be able to use the past tense, updating to remove critical remote system takeover bugs.  So these were bad.  And, you know, this would be much bigger news if all of our browsers did not enjoy near real-time updating.  And in fact a bit later we're going to see what's underway now with those Zyxel security endpoints we discussed last week, which do not auto-update.



But in the case of Firefox, this is a 2020 CVE, 16044, carrying the title "Use-after-free write when handling a malicious COOKIE-ECHO SCTP chunk."  And the description explains that a malicious peer could have modified a COOKIE-ECHO chunk in an S - it's hard for me to pronounce this because, I don't know, SCTP doesn't roll off the tongue - an SCTP packet in a way that potentially resulted in a use-after-free.  They said:  "We presume that with enough effort it could have been exploited to run arbitrary code."



Now, we don't often talk about SCTP because I have a hard time pronouncing it.  But it is the Stream Control Transmission Protocol, kind of a hybrid of UDP and TCP, and it was originally intended for use within the telecommunications Signaling System 7, SS7, that whole mess.  And being a hybrid of UDP and TCP it does run over UDP, so that's its underlying carrier envelope.  But it still provides TCP's fault tolerance, reliable delivery, and in-sequence transport of messages, all which, as we know, are missing from UDP, which is just kind of best effort, and we're not sure when or if or in what order the packets are going to arrive.  And like TCP, and unlike UDP, it also handles congestion control.  So basically it's sort of a light TCP.



But unlike either of them, SCTP provides multihoming and redundant paths to increase resilience and reliability.  It was standardized by the IETF in RFC 4960, so it's a real thing.  And although the first reference implementation appeared in FreeBSD 7, support for it is widely present.  In any event, the way Firefox uses it, each received SCTP packet contains a COOKIE chunk to facilitate a corresponding reply from the browser's cookie.  A COOKIE-ECHO chunk is a snippet of data sent during the initialization of the SCTP connection with the browser.  And as Mozilla said, the implementation had a flaw that, given sufficient motivation, could be remotely abused.



Mozilla didn't credit anyone with the discovery.  We're not sure where it came from.  Nor did they state whether it was actively being exploited in the wild.  Maybe they found it being abused and thought, ooh, let's fix this now.  But given that our browsers are strict clients of servers, although Mozilla said nothing more, it sounds as though the perpetration of this attack would have required an evil server to send the malicious COOKIE-ECHO chunk back to the browser.  This means that it would have required a watering hole attack, drawing browsers, presumably a specific targeted individual, to a malicious site where this vulnerability would have been exploited.  But the point being that it's not just something you could get easily.  In any event, thanks to auto-updating, we Firefox users are protected.



On the Chromium side, the researchers at Tenable, who found and responsibly reported the bug to Google, believe that it's bad enough to rank it as critical, although both Google and Microsoft classify it as only high in severity.  And it's unclear what the back story is on this one, too.  It's an out-of-bounds bug that was originally found and reported by Tencent Security Lab researcher Bohan Liu, who received credit for his work.  But the bug dates back to a Chrome for Android security bulletin which Google published in October of 2020, when it was also classified as only high severity after its discovery the month before, in September.



So it's a flaw in Chromium's V8 JavaScript and WebAssembly engine.  At the time, the bug was also classified as high severity.  It's identified as an out-of-bounds write in V8.  And today, neither Microsoft nor Google explain why the October 2020 CVE, which is 15995 bug, has popped up again and apparently was just recently in need of fixing, enough that all of our browsers got revved, all the Chromium browsers.  But in any event, that was one of an additional 12 Chromium bugs that were reported by Google with, not surprisingly, a one-for-one duplication echoed by Microsoft.



And it's occurred to me that whoever it is over at Microsoft whose job it is to report bugs in Edge now has it very easy.  They copy, and they paste.  They copy, and they paste.  Then they go to lunch.  Because just Chromium bugs is all they're dealing with.  The majority of the bugs, these 13 in total, were rated high severity and were predominantly use-after-free bugs.  And they earned their respective discoverers or teams $20,000 each.  So, cool to report things responsibly.  And as we've said, if you're good at doing this, you could maybe make it a career.



Unlike the SCTP flaw that was fixed in Mozilla, which due to its nature requires a watering hole-style attack, as I mentioned, vulnerabilities in the Chromium V8 engine are directly exploitable by code that's downloaded from any website, including from an instance of malvertising, even on a highly reputable site.  So, good that these things got found and removed, found by the responsible reporters and then quickly revved.  And again, browsers, I guess they weren't first; right?  Well, maybe they are because they're updating even more frequently than Windows.



But this notion of anything connected needing to take responsibility for its own security, that's clearly the model of the future.  I would argue that the browsers are the best at that because they're just doing it all the time.  Windows, due to the practical problems of breaking it which cause IT people to lose their minds - it was the case once upon a time, right, Leo, that Windows would just be pushing updates at any time, and that was causing such trouble that they said, okay, fine, we'll aggregate them.



LEO:  They consolidated it, yeah.



STEVE:  And only do them monthly.



LEO:  That was mostly for IT departments because individuals probably don't care as much, but IT departments really don't like updates.  So it's better if it's once a month.



STEVE:  Yeah.  So the question is, and this is a feature we're losing in Firefox, to change the page or stay where you are?  Seven years ago Blair McBride, over at Mozilla, opened a question about what Firefox's Backspace key should do.  He opened a Mozilla bug report, although it's not a bug, but the Bugzilla system is just the common way they manage all issues of any sort.



And so seven years ago he wrote:  "Pressing Backspace does different things depending upon where the cursor is.  If it's in a text field, not surprisingly, it deletes the character to the left. If it's not in a text input field, it's the same as hitting the Back button.  Whether to keep this behavior has been argued" - and then he has in initial caps - "For A Very Long Time.  It's confusing for many people," he suggests, "but we've assumed it would break muscle memory for many people.  However, the muscle memory argument was mostly an assumption.  As far as I know, we didn't have useful usage data until now."  He says:  "So now we have, or can get, useful usage data to either back up the muscle memory argument, or to squash it once and for all and remove Backspace as a shortcut for navigation."



Okay.  This is seven years ago.  "During the past seven years there has been a long and winding and storied thread accruing comments, observations, and opinions" - and lots of feelings - "until 12 days ago the issue was declared resolved, and a long outstanding question for Firefox's handling of the Backspace key was at long last answered," or at least resolved.



They wrote:  "We should not overload common user actions."  And for those who are not familiar, "overload" is a term that comes out of object orientation where you can put more functionality into an existing expression which then uses the context of the expression to determine what it does.  It's kind of cool, but it can also be confusing.  And that's exactly the problem here. We're talking about overloading common user actions, meaning that the Backspace key would be context dependent.



Anyway, they said:  "With Backspace, it behaves as you would expect in one context, deleting text; but in another subtle context, text box not selected, it has a destructive action."  Now, the reason they call it "destructive" is maybe you were filling in data in a form, and you had a lot, you know, you'd worked at it for a few minutes.  And then somehow the insertion point was not in the form, but you didn't realize that, and you hit Backspace, intending to remove a character that wasn't going to get removed.  And that was interpreted by Firefox as hitting the Back button, thus clearing, stepping you back before you received the form, losing all of that work.  Thus they call it "destructive."  That's what they mean.



So they said:  "This creates a high likelihood scenario for a common user behavior, deleting text, to trigger a less likely user behavior, which is using a keyboard shortcut to navigate back."  They said:  "This investment resolves the overloaded function and closes the gap on user behavior," which is a strange way of putting it.  But, they said:  "Firefox is the only browser using the Backspace key" - meaning today - "as a keyboard shortcut for navigating to the previous page on a tab.  This was originally implemented to follow IE's behavior.  We don't go to the previous page if you use the shortcut inside a text input.  There are several reasons that make a good case for removal of the shortcut."



And, let's see, the argument to retain Backspace keyboard shortcut for muscle memory for users migrating to Firefox or using Firefox along with another browser does not apply anymore.  Edge has now replaced IE as a default Windows browser without a similar shortcut.  And they mention that Alt + Left Arrow is the only keyboard shortcut now available for this.  Chrome also only implements Alt + Left Arrow because, again, Chromium is common to both browsers.  And, they said, Chrome had this shortcut and removed it because of user data loss risks.



So they finish:  "The Backspace key shortcut on Firefox is by far the keyboard shortcut with highest usage, with 40 million" - and they use the abbreviation MAU (Monthly Active Users) - "which is well above Find in Page," which actually I use a lot, that has 16 million monthly active users, "or Page Reload," which is 15 million monthly active users.  They said:  "This raises concerns that our users are suffering usability issues and data loss issues from hitting this keyboard shortcut by mistake."  In other words, they can't determine whether it was deliberate or a mistake.  But they're noticing it's getting hit a lot, 40 million more than search in a page or reload the page.



So anyway, but because Backspace is so popular, and this podcast is a favorite among the more technically oriented, I would not be surprised to learn that a good percentage of those 40 million monthly active users who are using Backspace to deliberately go back to the previous page might be listening to this podcast and suddenly be confused or annoyed to discover that its use for that purpose has finally come to an end.  We're currently at Firefox 84, that is, after those critical updates that I just mentioned.  That brought us to 84.  The change has been merged, this change in the handling of Backspace has been merged into the Firefox Nightly 86 builds.  So we can expect to see Backspace's behavior being neutered once 86 makes it to the main release channel.



The good news is that the Boolean setting for it can be turned back on.  As usual, you put about:config into the URL of your Firefox browser and hit Enter.  That brings up a bazillion settings.  Oh, you now have to agree to accept the awesome responsibility that accompanies making any changes behind the scenes and then search for the string "browser.backspace."  One item will be found.  It's browser.backspace underscore something, I don't even remember now what it was.  But just search for "browser.backspace," and you'll find it.



The option in my Firefox 84 was Boolean "0," and that does give you page-changing Backspace behavior that we've always had.  I experimented with it.  I set it to "1" and then restarted Firefox, assuming that I had to.  I didn't actually check that.  And that, sure enough, causes Backspace to be ignored when you're not entering text.  And so the point is this is already in there, and it's in about:config, one of Firefox's bazillion settings.  So this suggests that, with release 86, they're going to simply flip that existing zero to a one in order to flip the default behavior of Firefox.  And so anybody who will miss that can easily go in and turn it back to zero, as it is today.



A couple notes about ransomware.  Security researchers following the flow of bitcoin transactions from the victims of Ryuk's ransomware into the bad guys' pockets estimate that the Ryuk operation has netted at least, that is, they've been able to track at least $150 million.  They discovered that Ryuk's operators primarily use two legitimate cryptocurrency exchanges to cache out the bitcoin from paying victims into fiat money, regular money.



Two threat intelligence companies, Advanced Intelligence and HYAS, tracked 61 bitcoin wallets attributed to the Ryuk malware enterprise.  They discovered that the cryptocurrency moves from an intermediary to the - it's H-U-O-B-I, Huobi maybe, and Binance exchanges.  When Ryuk victims pay the ransom, the money first passes through a broker, who passes it to the malware operators.  The money then goes through a laundering service before getting to legitimate cryptocurrency exchanges or being used to pay for criminal services on underground markets.



The researchers explained that in addition to the large and well-established Huobi and Binance exchanges, there are significant flows of cryptocurrency to a collection of addresses that are too small to be an established exchange and probably represent a crime service that exchanges the cryptocurrency for local currency or another digital currency.  One of the largest transactions involving a Ryuk wallet found during this investigation was more than $5 million in a single transaction, or 365 bitcoin at the time.  But that payout was not the largest ransom ever paid.  In an earlier report, Advanced Intelligence said that the largest payment confirmed to these attackers was 2,200 bitcoin, which converted to $34 million at the time.



LEO:  Jesus.  Holy cow.



STEVE:  $34 million, Leo.  You could buy yourself a whole new, like, everything.  Network and servers, I mean, wouldn't you love to know what company thought, well, yeah, we should pay that?



LEO:  Good lord, yeah, wow. 



STEVE:  The average ransom value received by Ryuk is 48 bitcoins.  So they're making money.



LEO:  Even then, that's a lot, yeah.



STEVE:  Yeah, even that.  Another highly profitable ransomware gang we've talked about often is REvil, or Sodinokibi, who announced through a public-facing representative that they made $100 million in one year from extorting their victims.  They said that their goal was to make $2 billion.  As we know, their affiliate-based program does potentially allow them to grow and expand their rate of incursion.  A few months ago we noted that they had ended their "We have all the people we need for now" status and are again seeking to recruit new affiliates into the fold.  So they're in a growth phase at the moment.



Okay, now, yesterday during the 2021 CES, right, the Consumer Electronics Show, with great fanfare, Intel announced that their 11th-generation Core vPro CPUs will have support for their boot-protecting Hardware Shield and something known as Threat Detection Technology (TDT).  This Threat Detection Technology, they claim, will be able to "detect ransomware attacks at the hardware silicon level, many layers below antivirus software."  Now, okay, naturally that was of interest to me.  So I spent some time digging a bit deeper into these claims.  And frankly, it's nonsense.



LEO:  Yeah, sounds like nonsense.



STEVE:  It appears to be pure marketing hype.  The press - I know.  The press release said:  "Intel TDT uses a combination of CPU telemetry and ML" - of course that's now one of the buzzwords, Machine Learning - "heuristics to detect attack behavior.  It detects ransomware and other threats that leave a footprint on Intel's CPU performance monitoring unit (PMU)."  They said:  "The Intel PMU sits beneath" - they ought to just call it the PU - "sits beneath applications, the OS, and virtualization layers on the system and delivers a more accurate representation of active threats" - and I'm shaking my head while I'm reading this - "system-wide."  They said:  "As threats are detected in real-time, Intel TDT sends a high-fidelity signal that can trigger remediation workflows in the security vendor's code."  Okay.  What we have there is an example of some creative writing.



LEO:  Yeah, no kidding.



STEVE:  The biggest malware threat faced by the enterprise we know today is ransomware.  And nothing has been able to slow it down so far.  But wait.  Intel has a new chip, and it has a hardware ransomware detector built-in.



LEO:  Wow.



STEVE:  That can finally, yeah, it can finally put an end to this scourge.



LEO:  Woohoo. 



STEVE:  So quickly cancel your short position on Intel stock.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Yeah, and instead buy as much as you can, kids.  Intel's future is once again bright.  Except of course none of that is true.  The marketing guys apparently met with the engineering guys, and they asked:  "Okay, so the Gen 11 vPro processors have this, what, you call it a PMU?  What's it good for?  How can we sell that?"  And the engineering guys scratched their heads a bit and said:  "Well, in theory, since the PMU is seeing everything that's going on at the processor core level, it's impossible to hide anything from it.  Really, truly impossible.  So that means that, if something malicious was going on anywhere in the system, even if it was tucked away inside a virtual machine, it would have to affect the PMU."  Whereupon the marketing guys interrupted and said:  "Hold on.  Wait a minute.  Does that mean that the PMU could detect ransomware?"  And the engineers said:  "Well...."  And the marketing guys said:  "Perfect.  Now we can sell the crap out of this thing."



To give you a feel for the flavor of this nonsense, Stephanie Hallford, Intel's Client Computing Group Vice President and General Manager of Business Client Platforms, was quoted to say - that doesn't fit on her business card, by the way, it has to wrap around the back:  "Ransomware was a top security threat in 2020.  Software alone is not enough to protect against ongoing threats.  Our new 11th Gen Core vPro mobile platform provides the industry's first silicon-enabled threat detection capability" - wow, that sounds great - "delivering the much-needed hardware-based protection against these types of attacks.  Together with Cybereason's multi-layered protection, businesses will have full-stack visibility" - because, again, that's another buzzword.  You've got to have "full-stack" in there somewhere - "from CPU telemetry to help prevent ransomware from evading traditional signature-based defenses."  And then the press release noted that although Cybereason will be the first to support detecting ransomware using hardware indicators, other security vendors will most likely tap into it in the future.



Okay.  So I wanted to provide some preemptive context for this announcement in case any of our listeners encounter the news of an Intel breakthrough in ransomware prevention.  It didn't happen.  I will double-dip guarantee you that a system that's full armed with this nonsense is every bit as vulnerable as the systems we have today.  Could it possibly be of some value?  Sure.  But only if you knew precisely what to look for in advance, and only if regular system activity didn't constantly throw up false positives.



At first blush, it sounds amazing that by being down so low in the silicon there's no way for the actions of ransomware to avoid detection.  That would be true.  But the trouble with being so low down in the silicon is that all context is lost.  Down there, you have no idea what's going on up above.  You see registers being loaded and unloaded.  Math is happening.  Jumps are being taken or not.  Memory is being read and written.  Subroutine calls are being made and returned from, and transitions are being made among various OS privilege rings.



But it's all completely anonymous.  There's absolutely no context.  Everything, everyone is reading and writing registers, doing math, retrieving and storing to memory, making OS calls.  So there's no way to know what any of that actually means down there.  Maybe a malware prevention system operating up at the application layer could augment everything it already knows with the information that will someday be available from an Intel 11th-generation vPro processor which contains the optional extra cost PMU.  Maybe.  But even getting to maybe seems uncertain to me.  So, yeah.



LEO:  So the PMU just really is seeing microcode or assembly language level stuff.



STEVE:  Yeah.  It's just seeing instructions.  It's just seeing instructions. 



LEO:  I guess if there were a typical signature for ransomware, an instruction only ransomware used or something like that, you might say, well, that's suspicious.  But I can't imagine it looks that different.



STEVE:  Unfortunately, there ain't no such thing.  One of the problems is ransomware looks like just another application.



LEO:  Yeah.  It's encryption.



STEVE:  It's running, and it's reading and writing things and doing stuff.  



LEO:  Yeah.  Wow.



STEVE:  So Leo, we now have the strange case of the male chastity cage.



LEO:  Oh, about time.  I can think of some people who should wear this.



STEVE:  Yeah.  On the lighter side, I suppose, unless you're unfortunate enough to be wearing one, we'll remember those bizarre IoT chastity devices for men that we briefly covered some time ago.  It's the Cellmate, I guess as in cell phone, it's the Cellmate Chastity Cage, a bargain at $169.  That's for the small model.



LEO:  Oh, I need a large, I'm sorry, I can't...



STEVE:  As I've taken to say more recently, "What could possibly go wrong?"  Although perhaps "What is wrong with this picture?" would be more fitting in this instance.  So it should come as no surprise to anyone that the software behind these devices - would that be firmware?  Anyway, behind these devices...



LEO:  It's all hardware, baby.



STEVE:  Yeah, the hardware.  But hopefully not while you're wearing this thing.



LEO:  Ow.



STEVE:  ...was not of the highest grade.  Last October, researchers at Pen Test Partners published details about a serious vulnerability that allowed a remote attacker to take control of any Cellmate device.  They began their disclosure with the observation:  "In this research, it helps to have an open mind and to not be judgmental."



LEO:  I'd rather have an open chastity belt.



STEVE:  Yeah.  In an effort to keep, I guess, it a bit tongue-in-cheek, they obtained a subdomain of the .GS top-level domain which allowed them to post their serious and authentic security research at the easily remembered domain, InternetofDongs.



LEO:  Oh, geez.  Oh, god, I'm so sorry.  So sorry.



STEVE:  In their TL;DR they summarize the situation in a series of bullet points:  Smart Bluetooth male chastity lock, designed for user to give remote control to a trusted third party using mobile app/API.  Multiple API flaws meant anyone could remotely lock all devices...



LEO:  Oh, no.



STEVE:  ...and prevent users from releasing themselves.



LEO:  Oh, no.



STEVE:  Removal then requires an angle grinder or similar, used in close proximity to delicate and sensitive areas.  Precise user location data is also leaked by the API, including personal information and private chats.  You know, "Get me out of this thing."  Vendor initially responsive, then missed three remediation deadlines they set themselves over a six-month period, finally refusing to interact any further, even though majority of issues were resolved in migration to v2 API, yet API v1 inexcusably remained available.  And I should say "remains [current tense, present tense] available."



The researchers wrote:  "We are not in the business of kink shaming.  People should be able to use these devices safely and securely without the risk of sensitive personal data being leaked.  The security of the teledildonics field is interesting in its own right."



LEO:  Oh, yes.



STEVE:  "It's worth noting that sales of smart adult toys has risen significantly during the recent lockdown."



LEO:  Well, that makes sense, yes.



STEVE:  And I suppose this brings new meaning to the term "lockdown," Leo.



LEO:  And by the way, on a related note, I want to announce a new sponsor for the show, ManEscaped, which is software to help you get out of your chastity belt, if you inadvertently get locked in.  ManEscaped.com.  Okay, go ahead.  That was ad number two.



STEVE:  Okay.  So in describing the risk to users, they wrote: "We discovered that remote attackers could prevent the Bluetooth lock from being opened, permanently locking the user in the device.  There is no physical unlock.  The tube is locked onto a ring worn around the base of the genitals, making things inaccessible.  An angle grinder or other suitable heavy tool would be required to cut the wearer free.  The user's location, their plaintext password, and other personal data was also leaked, without need for authentication, by the API."



They said:  "We had particular problems during the disclosure process, as we would usually ask the vendor to take down a leaky API whilst remediation was being implemented.  However, anyone currently using the device when the API was taken down would also be permanently locked in.  As you will see in the disclosure timeline at the bottom of this post, some issues were remediated, but others were not.  And the vendor simply stopped replying to us, to journalists, and to retailers.  Given the trivial nature of finding some of these issues, and that the company is working on another device which poses even greater potential physical harm," and they said in parens "(an internal chastity device), we felt compelled to publish these findings at this point."



So somewhat predictably following the disclosure, an attacker started targeting Cellmate mobile app users.  Thus this is in the ransomware section of the podcast because they were being asked to pay 0.02 bitcoin, around $270, at the time of the attacks in order to have their device released.  All of these things have been locked, and users are now having to pay to be released.  So thus we witness the rare birth of a new class of ransomware.



So yesterday's post by Kaspersky Labs was titled "Sunburst Backdoor.  Code overlaps with Kazuar."  It's K-A-Z-U-A-R, a known Russian sourced malware.  And in their post, following their de rigueur "What is Sunburst" reminder, as if anyone reading a Kaspersky posting doesn't already know, they introduce us to what they have found.



They wrote:  "In a previous blog, we dissected the method used by Sunburst to communicate with its command-and-control (C2) server and the protocol by which victims are upgraded for further exploitation.  Similarly, many other security companies published their own analysis of the Sunburst backdoor, various operational details, and how to defend against this attack.  Yet, besides some media articles, no solid technical papers have been published that could potentially link it to previously known activity."



They said:  "While looking at the Sunburst backdoor, we discovered several features that overlap with a previously identified backdoor known as Kazuar.  Kazuar is a .NET backdoor first reported by Palo Alto Networks in 2017.  Palo Alto tentatively linked Kazuar to the Turla APT group, although no solid attribution link has been made public.  Our own observations indeed confirm that Kazuar was used together with other Turla tools during multiple breaches in past years.  A number of unusual, shared features between Sunburst and Kazuar include the victim UID generation algorithm, the sleeping algorithm, and the extensive use of the FNV-1a hash."



Okay.  So on the podcast we've never had occasion to talk about the FNV-1 hash because it's not cryptographically secure.  FNV are the initials of the hash's inventors - Fowler, Noll, and Vo.  What the hash can boast of is its very small implementation size, and its speed, and its fully tunable output length.  The hash operates in a very simple loop.  The current hash is multiplied by an FNV prime value; then a byte of input is XORed into the result.  That's repeated until all of the input has been consumed.  And I looked at the actual code implementation in Kaspersky's posting, and it's like, five instructions.  So it's going to be screamingly fast.  And it provides a way for them to create a very fast lightweight hash.



Anyway, the Kaspersky Report goes on in great detail, showing reverse-engineered code from Sunburst and Kazuar, and specifically addresses the problem and challenge of false-flag deception where attribution is deliberately misdirected.  And finally, after a long posting, they conclude, saying:  "These code overlaps between Kazuar and Sunburst are interesting and represent the first potential identified link to a previously known malware family.  Although the usage of the sleeping algorithm may be too wide, the custom implementation of the FNV-1a hashes and the reuse of the MD5+XOR algorithm in Sunburst are definitely important clues.  We should also point out that although similar, the UID calculation subroutine and the FNV-1a hash usage, as well as the sleep loop, are still not 100% identical."



They said:  "Possible explanations for these similarities include:  Sunburst was developed by the same group as Kazuar.  Or the Sunburst developers adopted some ideas or code from Kazuar, without having a direct connection, like they used Kazuar as an inspiration point.  Or both groups, Dark Halo/UNC2452 and the group using Kazuar, obtained their malware from the same original source.  Or some of the Kazuar developers moved to another team, taking knowledge and tools with them.  And finally, or the Sunburst developers introduced these subtle links as a form of false flag in order to shift blame to another group."



So still, at the moment, now weeks downstream of this, and with no little amount of attention and focus being brought to bear, we do not know which one of these options is true.  While Kazuar and Sunburst may be related, the nature of this relation is still not clear.  Through further analysis, it's possible that evidence confirming one or several of these points may arise.  At the same time, it's also possible that the Sunburst developers were really good at their operational security and didn't make any mistakes, with this link being thereby an elaborate false flag.  In any case, this overlap doesn't change much for the defenders.  Supply chain attacks, as we know, are  some of the most sophisticated types of attacks these days, and they've been successfully used in the past by APT groups.



The Kaspersky guys note:  "To limit exposure to supply chain attacks," they said, "we recommend the following:  Isolate network management software in separate VLANs.  Monitor them separately from the user networks.  Limit outgoing Internet connections from servers or appliances that are running third-party software.  Implement regular memory dumping and analysis, checking for malicious code running in a decrypted state using a code similarity solution."



And that's actually, that third one is very cool.  That's one of the ways that Kaspersky's proprietary tools operate is that we know that polymorphic encryption is used to prevent signature analysis by AV tools.  Each instance of the malware is encrypted under a different key so that it looks like completely different random gibberish.  And even the decryption algorithm that must be somewhere in the decrypted blob, that's dynamically generated so that it never looks the same twice.  But what's common among all of those is, once it's decrypted and running in RAM, it's the same item every single time.  It is highly repetitive.  But it's only once it's in memory that you're going to see that.



So anyway, as we know, Kaspersky is a Russia-based security firm.  They've taken a lot of heat about that over the years.  We've touched on that from time to time.  Does that color their conclusions?  We don't know.  Attribution, as we know, in cyberspace is incredibly difficult.  And it remains so.



As for the U.S. government, last Tuesday our intelligence and law enforcement agencies here in the U.S., including the FBI, CISA, the ODNI, and the NSA, jointly published a statement.  They said, speaking of this massive attack:  "This work indicates that an Advanced Persistent Threat actor, likely Russian in origin, is responsible for most or all of the recently discovered ongoing cyber compromises of both government and non-governmental networks."



So, okay.  The press jumped on this as the U.S. government formally accuses Russia.  And it's like, okay, wait.  They said "likely."  And, you know, frankly, "likely Russian" certainly falls far short of being definitive.  And at this point it seems that the inherent difficulty of attribution in cyberspace is what rules the day.  And I'm, frankly, impressed that they're not claiming proof that they don't have.  And the problem is it's just difficult to prove.  I heard you recently, I think it was on some other podcast, Leo, talking about the problem of attribution in cyber.



LEO:  Yeah.  Right.



STEVE:  It's just, you know, it's so possible to set up a false flag, to deliberately bounce IP traffic through someone else or to use someone else's code, which anybody can get by reverse engineering, in order to set up something that looks like it's the work of those people.  So you just don't know.



LEO:  Turla is another Russian group, though, thought to be Russian.  So Kaspersky wanted to defer responsibility...



STEVE:  Oh, to really point fingers elsewhere, yeah.



LEO:  Yeah.  I think they would choose something that's not Russian.  So, yeah.  I do think, though, that it's completely credible.  These guys are so good that they copied or intentionally put those false flags in there.  Or maybe they had the source code for Turla and just said, ah, that works well.  We'll just borrow that.



STEVE:  Well, yeah.  And you'd have to think also that, as you say, being as good as they are, they would recognize the chance of the connection being made.  Or maybe they just don't care.



LEO:  Or maybe they don't care, yeah.



STEVE:  Yeah.  You know?  We're going to stay hidden as long as we can.  Once we're no longer hidden, well, then it doesn't matter.  And also, unfortunately, what are you going to do about it?



LEO:  Yeah, that's really the big point.  So, what are you going to do?



STEVE:  Yeah, what are you going to do?  



LEO:  What are you going to do?



STEVE:  So in SolarWinds news, we also talked about the trouble that the SolarWinds Corporation would likely be facing in the future.  Predictably, a class-action lawsuit has been filed by shareholders of SolarWinds' beleaguered stock.  The named defendants in the suit are SolarWinds President Kevin Thompson and Chief Financial Officer J. Barton Kalsu.  The suit alleges that the executives violated federal securities laws under the Securities Exchange Act of 1934.  And embedded in the suit was a bit of information that raised my eyebrows.  Among the many other grievances enumerated by the plaintiffs was the fact that the SolarWinds update server used the password "solarwinds123."



LEO:  "Password123," I think.  Wasn't it password123?



STEVE:  I think it was solarwinds123.



LEO:  Solarwinds123, wow.



STEVE:  So again, wouldn't be a big stretch.  It's not the first thing you would guess; but, wow, it's certainly not uppercase Z`q and so forth.



LEO:  It's more on the Cheeto side, yeah.



STEVE:  Solarwinds123, it's better than a Cheeto, yeah.  In fact, Leo, that's got to be one of our new, you know, we have TNO, Trust No One.  And now we have "Better than a Cheeto."  Or maybe "Beats a Cheeto," yeah.



Okay.  So the Krebs Stamos Group.  In a bid to manage the security side of the mess created by the SolarWinds hack, SolarWinds has hired a freshly founded consultancy known as the Krebs Stamos Group.



LEO:  I like the name.



STEVE:  I do.  And boy...



LEO:  Which Krebs is it?  Not Brian.



STEVE:  It's not Brian.



LEO:  It's Chris Krebs, yeah, former...



STEVE:  And what's cool is the URL.  .GROUP is a TLD, so they are KS.group. 



LEO:  Oh, that's a good URL, yeah.



STEVE:  Krebs Stamos Group.  So the front page banner of that page - actually it's not the front page, it's the only page of their new website - declares:  "Krebs Stamos Group helps organizations turn their greatest cybersecurity challenges into triumphs."  And in the case of SolarWinds, well, good luck with that.



LEO:  Can they turn my bitcoin into dollars?  That's what I want to know.



STEVE:  Yeah.  And yes, both of those names should be familiar to our listeners.  Krebs is not Brian Krebs, it's Chris Krebs, the original and now previous head of the United States CISA, who while still head of CISA had the unwelcome temerity to publicly state that the recent U.S. presidential election was the most secure ever.  Whereupon Chris became the previous head of CISA.



And Stamos is of course Alex Stamos, Facebook's former CISO and founder of the Stanford Internet Observatory.  As we know, shortly following the multiple Zoom security debacles in early 2020, Alex has been helping Zoom manage their new security challenges.  Presumably now this will fall under the Krebs Stamos Group umbrella.  And it's going to be interesting to see where this duo pops up in the future.  As the industry's highest profile security disaster response group, I have the feeling that we're going to be seeing more of them.



Maybe, speaking of which, maybe Zyxel - is that how you pronounce it?  Zyxel?



LEO:  I always say "Zycel."  I don't know if that's accurate or not.



STEVE:  Zyxel, yeah, that's sounds...



LEO:  Used to have a Zyxel modem, way back when.  It was a 56k baud modem.



STEVE:  Yeah, it was originally really good hardware.



LEO:  They were the best modems, yeah.



STEVE:  Yeah, yeah.  So last Tuesday, right while we were talking about the new threat facing the more than 100,000 Zyxel VPN and other security endpoint customers, they've got a whole family of security endpoints, GreyNoise Intelligence was observing that the previously unknown "zyfwp" account name had been added to SSH scanners and was now being actively probed across the Internet.



LEO:  Of course.  Of course.



STEVE:  Uh-huh.  Why wouldn't you?  Johannes Ullrich, of the SANS Internet Storm Center last week said:  "Likely due to the holidays, and maybe because the discoverer of the backdoor account did not initially publish the matching password, widespread exploitation via SSH had not started until now.  But we are seeing attempts to access our SSH honeypots via these default credentials."  Ullrich said the scans started last Monday afternoon, stemming from one IP, 185.153.196.230.  And more scans from other IPs, 5.8.16.167 and 45.155.205.86, joined throughout this week, that is, past week.



He said:  "The initial IPs scanning for this are all geolocating back to Russia.  But other than that, they are not specifically significant.  Some of these IPs have been involved in similar Internet-wide scans for vulnerabilities before, so they are likely part of some criminal infrastructure."  Of course this backdoor account is now widely public, and so it permits an incredibly serious risk because anyone on the Internet can now use it to create new VPN accounts to give themselves access to internal networks or to port-forward internal services to make them remotely accessible and exploitable.  It is looking like it's going to become a horrific disaster.  I have a hunch we'll either see a big jump in ransomware attacks, or just news of people becoming victims to this.  I don't know, 100,000 of these, and they're in back rooms.  They're in closets.  And then Zyxel says, oh, be sure to update.  Hello, who?  Wow.



Meanwhile, up until now, WhatsApp's privacy policy opened with the claim that "Respect for your privacy is coded into our DNA."  Remember that?



LEO:  Mm-hmm.



STEVE:  They said:  "Since we started WhatsApp, we've aspired to build our services with a set of strong privacy principles in mind."  Well, that was then.  I think it was 2016.  The news that the respect for the privacy of WhatsApp's user metadata is being lost has triggered a mass exodus from Facebook's in-house communications platform over to Signal, where no user metadata is ever collected.



Back in 2016, WhatsApp gave its users a one-time ability to opt out of having account data turned over to Facebook.  But now their updated privacy policy, taking effect next month, on February 8th, changes that.  One month from now, users will no longer have that choice.  Some of the data that WhatsApp collects and will be sharing includes users' phone numbers, other people's phone numbers stored in address books, profile names, profile photos, location information, transactions and payment data, device and connection information, status messages, including when a user was last online, and diagnostic data collected from app logs.



And so, yeah, they may not be seeing what you're saying, but they have and will shortly be using every other last scrap of available metadata.  Under the new terms, Facebook reserves the right to share collected data across its family of companies.  And in some cases, such as when someone uses WhatsApp to interact with third-party businesses, Facebook may also share information with those outside entities.  This privacy agreement update is a 180 compared with last year's privacy policy whose enforcement began last July.  It states that users are able to choose not to have their WhatsApp account info shared with Facebook to improve the company's ads and products.  But under the changes to the policy, users will now be forced to accept sharing their data with Facebook to continue using their account; or, as an alternative, delete their account.



WhatsApp's notification reads:  "By tapping AGREE [all caps] you accept the new terms and privacy policy, which take effect on February 8, 2021. After this date, you'll need to accept these updates to continue using WhatsApp."  So given the supreme lack of subtlety shown, it really does feel like a bit of a bait and switch.



On the other hand, I mentioned that Signal was experiencing a mass influx of ex-WhatsApp users.  It turns out that Signal's infrastructure was for a while a bit unprepared and overwhelmed by this rush.  BleepingComputer reported last Friday that Signal had now recovered from sign-up delays which had previously been affecting its user verification process.  When setting up Signal for the first time, users must verify their mobile number using verification codes sent by Signal.  And Leo, you noted that this is sort of an unfortunate loop that Signal is requiring.  There are some other good end-to-end encryption solutions that don't require that.



Anyway, the surge in new users switching to Signal overwhelmed the verification service, causing significant delays across various mobile providers.  Of course that's the sort of problem you'd like to have.  Signal tweeted on the 7th, when they were finally beginning to recover, that was last Thursday:  "Everyone should be able to register without delay again.  Thanks to all of the carriers who flipped the right switches so that people can keep switching."  I don't know what that means.  Maybe they got shut down due to a tweet storm or an attempt to do too many SMS messages in a short period of time. 



On the 8th Signal tweeted:  "New users in Europe should be able to register without delay again.  We will continue to work with carriers to keep delivering a record-high number of Signal verification codes.  The Signal service itself is operating normally.  Thanks for your patience."  Later the same day, on January 8th:  "Some new users are reporting that Signal is slow to display their Signal contacts.  We're adding more capacity to keep up with all the new people searching for their friends on Signal.  Hang tight."



The next day, on the 9th, they tweeted:  "Not to sound like a broken record about broken records, but we're aware of the registration delays while creating a new account.  Carriers are making adjustments on their side to keep delivering verification codes as quickly as possible."  This must have been a mass exodus.  Later on the 9th:  "Even though we're still breaking records, verification codes are back in the groove.  Delivery delays have been eliminated across multiple cellular providers, so things should be more ASAP when you join the app."



And, finally, on the 10th, which was Sunday, two days ago, they tweeted:  "We continue to shatter traffic records and add capacity as more and more people come to terms with how much they dislike Facebook's new terms.  If you weren't able to create a new group recently, please try again.  New servers are ready to serve you."  So, wow.



LEO:  That's great.  I'm really happy to hear that.  I hope people make the shift.  Be great.



STEVE:  Yeah.  And I guess certainly Facebook has the right to whatever terms and conditions they want.  I'm sure there are lots of users that will still use Facebook because it's, I mean, still use WhatsApp because it's part of the Facebook family of properties, and getting more relevant ads is what they want.  So it's like, okay.  But lots of users are clearly a little annoyed.  And notice that, again, this is not anyone's conversation that is being decrypted.  This is just all the metadata.  So it does also feel like people are beginning to understand more about the subtleties of the difference between your conversation versus metadata.



LEO:  Thanks to Apple really exposing that, yeah.



STEVE:  Yeah.  Yes, and Apple has been moving in the other direction, as they know.  They're getting better about requiring apps to be very clear about exactly what they're going to be doing with their users' data.



So I did want to just take a moment to mention "The Expanse" on Amazon Prime.  We first talked about "The Expanse" many years ago, when it was - it was initially, for the first three years, it was a Syfy property.  And when it had been announced, I remember Mark Thompson telling me that it was coming, and he was excited.  He had read...



LEO:  You loved the novels, I know.



STEVE:  Yes.  He had read them.  I immediately read them because, as we know, the books are always better.  Although, boy, I just started rewatching it.  I know that you have.  We talked about this last week or the week before.  Lorrie had never seen it.  I was a little worried that it might be a little too out in the weeds for her.  But she's tolerating it, at least.  And I just have to say I had forgotten how good it was.  I mean, it is really good.  I mean, you need to really pay attention.  There is some problem, like with articulation, where it's like, what did she just say?  But it doesn't - that kind of stuff really doesn't matter.  And they're speaking in a language that they made up, little snippets here and there which are just to provide some color.  And again, not important to the plot.



But for what it's worth, so what happened was, it was incredibly popular on Syfy.  And they chose to not continue the series, not because it wasn't super popular and the production values weren't, like, amazingly high, especially for the Syfy channel, but over some contractual problems with distribution.  Things got - I don't remember.  I don't know what the details were.  But they just said, okay, fine, if that's the way you're going to be, somebody, then we're not going to do it again.



A crowd-funded airplane was financed to fly circles around Amazon headquarters, trying to get Bezos to pick it up.  And Jeff did.  And what I found interesting was the ratings have...



LEO:  I didn't know that.  That's why it got picked up.  Wow.



STEVE:  Yeah.



LEO:  I had no idea.



STEVE:  And the ratings have only gone up since then.  It is now - the last few seasons are 100% on Rotten Tomatoes.  And it's always in the high 9s on IMDB.  So anyway, for what it's worth, again, there is a lot of, like, well, in fact, at one point Lorrie said, "I hope this is not going to be constant shooting."  And it's anything but.  I mean, my concern is that it was a little too much internecine political machinations between Earth and Mars and those out in the Belt, the Belters.  But I just think it's wonderful.  So just a heads-up to our listeners that - and it's on Amazon Prime.



LEO:  Yeah, you probably get it free, yeah.



STEVE:  You're a Prime user, probably get it for free.  And boy.  And five seasons now.  And I think maybe I saw the first three before, so I'm having no problem rewatching them.  As I said, I forgot how really high quality it was.  And before long I'll be going past where I read in the novels out into new territory.



Okay.  So the title of the podcast is "Out With the Old," inspired by my previous week of digging around inside SpinRite.  I've frankly been amazed as I've been encountering and remembering how much functionality I managed to cram into this system over time.  And it made me think back.  There were so many kludges - my favorite word again - perpetrated upon the industry as our early PCs kept outgrowing their modest beginnings.  Of course Gates was famously quoted saying, you know, the previous CPM machines were absolutely limited to 64K of RAM.  And Bill was quoted as saying, when the IBM PC came out with 640K, whoo, 10 times as much, "Oh, we'll never need more than that."



Anyway, one of the many problems was that mass storage size grew beyond anyone's wildest expectations.  And as we know, in the 40 years since the PC's August 12, 1981 - so Leo, this August 12th the PC will be 40 years old.  And we're 40 years older, my friend.  But this pace of mass storage growth has never let up.  So to remain useful, SpinRite had to deal with every weird thing a system might do.  For example, when the total sector count limit was reached, device drivers were created to deliberately misrepresent the size of sectors on the system's media.  If you couldn't have more sectors, at least the sectors you could have could be made larger.



Physical sectors transferred from devices, the actual physical devices, have always been 512 bytes.  But an intermediate device driver would tell DOS that the mass storage device was using, for example, 4096-byte sectors.  So that's what DOS would see.  And that's the way it would format the drive.  All file system data structures would then occur in what was actually eight physical sector multiples rather than the truth of one physical sector.  And this was fine for DOS since it really didn't care how big sectors were.  It believed what it was told.



But of course SpinRite was accessing the drive directly and beneath any device driver.  So it needed to juggle this 8-to-1 - and it wasn't always 8-to-1, it could be any multiple of logical versus physical sector reality.  And that juggling had to happen for everything SpinRite did.  And remember that the very popular DOS at the time, v3.3, DOS 3.3 was like the one we had for a long time at the beginning.  It had a - get this - a 32MB limit.  32MB.



LEO:  Per file.  Per file. 



STEVE:  No, no, no, no.  DOS 3.3's entire partition, the C partition.



LEO:  Only 32 megs?



STEVE:  Yes, 32 megs.  It was actually 33,554,432 bytes.  Where did that come from?  It came from DOS's logical sector number, which back then was 16 bits.  DOS had a 16-bit sector number.



LEO:  Of course, most people didn't have hard drives that big, so it was okay.



STEVE:  Right.  You could get - you could choose.  Do you want 5MB or 10MB?



LEO:  I remember when I got a 20MB drive.  I was so excited.



STEVE:  Oh, Leo.



LEO:  That was that new MFM technology.  So 32MB probably at the time seemed fine.  We'll never need that much.



STEVE:  The 20MB was the Seagate ST-225 drive.



LEO:  That's right.  Boy.



STEVE:  So 16 bits gives us 65,536; right?  64K in binary sectors.  You multiply 65,536 sectors by 512 bytes per sector, and you get 33.55 and some megabytes.  That was the largest possible partition that DOS 3.3 could handle.  And it's interesting.  As I was thinking about all this, while we're talking about PC history, when I encountered that 33.55MB limit, I was reminded of something I wrote long ago.  One of the ideas I had when I was writing the InfoWorld TechTalk column was to design what I called "Steve's Dream Machine," where every component was carefully selected for cost-effectiveness and value, like this is the motherboard you want, and exactly why.  This is the RAM you want, and exactly why.  And so on.



Well, there was a Miniscribe 3650 drive that was 42MB under its rated MFM encoding, but it was high-quality enough to handle RLL's 50% storage increase, bringing it up to 64MB when formatted with an RLL controller, which was - and the Adaptec 2372, that was my choice of the best controller.  And it turned out that the drive advertised fewer cylinders than were required to deliver a second partition because, okay, if you have a 42MB drive, but you hook it to an RLL controller, now it's at 64MB.  But DOS 3.3's maximum partition size is 33, or 32 binary megabytes.  So you've got to have two partitions because you can't just have one.  The drive's now too big for the maximum DOS partition.



So it turned out that the drive advertised fewer cylinders than were required to deliver a second partition of the maximum possible size under DOS 3.3.  Although they weren't advertised, the required additional cylinders were physically there.  And I discovered that they worked.  So one of the coolest hacks I used and promoted for Steve's Dream Machine was to format the drive further toward its spindle to obtain additional storage.  Then FDISK could create a C and a D that each contained the absolute maximum size of a DOS partition, that 33-plus million sectors.



And, you know, it was a gimmick.  But it was fun, and the concept was quite popular back then.  And I thought, I wonder if this is still online?  Because I know that a lot of InfoWorld ended up getting put online.  I actually found, if anyone is interested, it is sort of a blast from the past, I found the text of that original InfoWorld column online.  It was titled "A Hard Disk Drive for Steve's Dream Machine."  And I excerpted the relevant portion.



I said:  "The Miniscribe 3650 is not quite officially RLL certified, though I hear rumors that it's about to be, simply because it works so well.  I've tested many of them myself, and the bright boys at Northgate Computer Systems who turned me on to this drive in the first place are shipping thousands with RLL controllers in their 286 AT compatibles.  They've had no problems. I'm quite comfortable with the 3650 and RLL encoding.



"Finally, the 3650 is rated as having 809 cylinders, though it actually has 852.  I've been low-level formatting mine out to 842 cylinders.  Then, under DOS 3.3 with RLL encoding, you get two maximum size 33.4MB DOS partitions!  They couldn't be any bigger!  Sixty-seven fast megabytes in an inexpensive half-height drive is hard to beat."



LEO:  Stand back.  Whoo.  Whew.  Wow.



STEVE:  Wow.



LEO:  Somebody typed that in, by the way.  That's hand-typed from your column.



STEVE:  Hand-transcribed from the column.



LEO:  That's hysterical.



STEVE:  So anyway, as I was saying, DOS back then was designed to manage a maximum of 64K sectors.  But if you needed more storage, you could add a device driver to lie about the size of each of those sectors to obtain many times the storage.  And I wrote this as I was - this just came to mind as I was writing this.  I think there was a company called OnTrack that bundled its driver with many hard drives at the time.



LEO:  Yeah, I remember it, yeah.



STEVE:  Which is a device driver that did that with many hard drives.  Because, you know, if you were a Seagate or a Western Digital or a Miniscribe or anybody who was making larger hard drives, yet DOS was stuck at 32MB, then you needed some way of letting the user get to all of their hard drive storage.  So I'm sure OnTrack made a bundle because there was one of those little 5.25 floppy with every hard drive you bought which installed that device driver on the fly.



LEO:  Yup, yup, yup.



STEVE:  And it did this lie.  It told DOS that its sectors were much larger so that its 64K sectors would now span a much larger drive.  Anyway, SpinRite, because of its unique position in this, it had to have code to straddle that lie.  It had to operate with DOS's view of logical sectors while at the same time working with the actual underlying true 512-byte physical sectors.



So the history of our early PCs is littered, and it really has become littered, with storage size limitations because no one ever expected what happened.  The original hard drives were limited to 1024 cylinders, 16 heads, and 63 sectors.  So that's 10 bits per cylinder, only 4 bits per head, and 6 bits for the sector.  The sector count was 63 because for some reason no one knows, there never was a sector zero.  Sectors were always numbered from one.  But that set of size limitations imposed a larger 504MB upper limit on hard disk size.  If you worked around that limitation, or in order to work around that limitation, early BIOSes used a byte for the head number.  So now you could have 255 heads, or 256 actually, zero to 255.  That led to all of those wacky cylinder head sector, remember the CHS translation schemes where...



LEO:  Oh, yeah.



STEVE:  ...you were like, oh, my god.



LEO:  Oh, what a nightmare that was.



STEVE:  Yes.



LEO:  I can only imagine coding for it.  I mean, bad enough we had to use it.



STEVE:  Exactly.  I had to penetrate that translation lie.  But even so, the limit then was 7.84GB.  And even the early ATA spec which expanded the cylinder count out to 64K cylinders, you know, 65,536, a full 16-bit cylinder number finally, not just 10 bits, it still had only 4 bits in its registers for 16 heads.  So more translation needed.  You'd translate the heads up and the cylinders down.  But it did allow for 255 sectors.  So then you could now get 127.8GB using BIOS head translation with an ATA drive.  So it's just been, like, one after another short-sighted design which we kludged ourselves around.  Oh, and Leo, then came along the monkey wrench of on-the-fly partition compression.  Oh, my god.



LEO:  Was that Stacker and stuff like that?



STEVE:  Yes, exactly.  Stacker from Stac Corporation.  And Double...



LEO:  Oh, god.  This is all coming - Double Disk, was that it?  Double...



STEVE:  Double something or other.  Double Trouble.



LEO:  Yeah.  Oh.



STEVE:  Now, because a compressing device driver had been added between DOS and the underlying mass storage, what DOS was seeing was an entirely fictitious drive partition with an amount of free space that was fluctuating based upon the dynamic compression ratio of all the data that had been stored so far.  Again, SpinRite needed to bracket any on-the-fly compression driver, sometimes seeing the drive from DOS's bizarre and dynamically changing perspective, and relating that to what was still happening down at the drive's actual true 512 bytes per sector reality.  It was all a horrific mess.  But SpinRite just had to work in any and all situations.  It needed to, and it did, figure all of that out and just deal with it so that users could simply run it no matter what their system was doing, and it would just work.



And one other piece of SpinRite engineering that I recently encountered in the last week and had completely forgotten about was that SpinRite might be writing to a file into its own detailed technical log, recording everything it found and did back onto the same drive it was working on.  That drive would have a file system on it, and SpinRite might be low-level reformatting and/or extensively pattern testing the hard drive track containing the sectors of the file system to which SpinRite was writing its log because it's going through DOS, and it has no control over where DOS writes the file.  And that could be happening while it was working on the track underneath those file system sectors.  And there might be a device driver lying about the size of the sectors, and another one compressing those sectors so that they weren't even really sectors anymore, just elastic storage abstractions.



So what does SpinRite do?  I virtualized access to the track that SpinRite was working on.  SpinRite would read, and if necessary recover, all the data on a track, lifting it into a RAM-based track buffer.  Then I would intercept any DOS and BIOS access which matched the current cylinder and head that I was working on and would redirect those reads and writes to that pseudo track in SpinRite's track buffer.  In that way it was possible for SpinRite to write its log file through DOS, through whatever device drivers might be present and in the way, and to give DOS simultaneous access to the same track that SpinRite was currently working on - reformatting, changing its sector interleave, and perhaps pattern testing for defects.



And of course, yeah, the much easier solution would have been to simply tell SpinRite's user that they cannot log to the same drive SpinRite is running on.  But since it was possible to reengineer or to engineer a way around that limitation, I had to do it.  And SpinRite does.  Now, today, of course, all of that is, I don't know, water under the bridge, over the dam or something.  The problem is all of that crap is still there, even though none of it is useful and none of it is doing anything any longer.  And it's getting in the way because I'm having to constantly take all of that into consideration with everything I do because the hooks, the tests, the double checks for all of those exception conditions are laced throughout the code.



Today, sectors are only 512 bytes.  They are never something else.  Yet I'm constantly multiplying or dividing by logical sectors per physical sector, or the logical sector size, which are two terms in SpinRite's code everywhere.  And of course on-the-fly compression is gone.  And everything has become so much simpler, simply by expanding everything's true addressability.  Yet all of the code for handling all of the kludges that predate today's relative simplicity remain functional and in the way.  And of course there's SpinRite's current limitation.  As we know, 32 bits is about 4.3 billion.  It's the number of IPv4 addresses on the Internet.



And notice that 32 bits was no longer enough for the Internet, either.  Well, it's no longer enough for our mass storage.  If we take 4.3 billion, 32 bits, as a sector count, and we multiply it by 512 bytes per sector, that brings us to 2.2TB, the absolute maximum size of any drive whose sectors can be accessed with 32 bits.  To get around that, as I already have with the new drivers in the ReadSpeed Benchmark, which SpinRite will be inheriting, all of the rest of SpinRite needs to have its sector addressing expanded from 32, well, I'm going to go to 64, although currently it's 48.  The current state of the art in the ATAPI spec for all of our state-of-the-art drives is 48 bits of sector addressing, which up from 32, that's going to hold us for a long time because that's, what, 16 bits more.  So it's 64K times 2.2TB.  So, yeah, that ought to be enough for a while.



Anyway, for the sake of convenience in code, I'll go to 64, so twice 32.  But all of the existing data structures and all the code that operates upon them needs to change.  And that's not a problem, but all of the old crap code that serves absolutely no purpose any longer would also need to be changed, if I was going to drag it along, or simply be removed forever.  My one goal - and of course the hint is the title of this podcast, "Out With the Old."  My one goal is to get SpinRite 6.1 out the door in the shortest possible time.  The more I think about it, the more I'm sure that saying goodbye to all of that crap which I once labored over and loved - I mean, it was kind of fun looking at it in the last week - is the way to go.



What this essentially means is that SpinRite 6.1's users are going to wind up receiving a much newer and updated solution, more than just strapping these new drivers onto the existing aging code.  And another problem is that SpinRite's traditional one-track-at-a-time approach is deeply embedded throughout the code.  I mean, that's, you know, SpinRite was born as a one-track-at-a-time sector re-interleaving tool.  And as I've said before, the reason it does data recovery is I realize, if I'm going to low-level reformat a track and move the physical sectors around to different positions in order to improve the system's performance, I only have that one last time to get the data off the track.



So I built the best data recovery that I knew how to build.  And of course that ends up being SpinRite's claim to fame still today, even though it's been decades since any low-level formatting was actually possible on hard drives.  They're all one-to-one interleaved, and they manage sector defects on their own.  So despite that fact, even SpinRite 6 still deals with single tracks at a time.  So that has to go out the window also.



As we know, SpinRite's primary deliverables will be that it will once again be able to operate upon drives of any size, meaning 48 bits' worth of sectors - yes, 64K times 2.2TB - and that it will do so with all possible speed.  I cannot issue track size operations to drives to get them to run at maximum performance.  That's too much per command overhead relative to how fast today's drives are.  I need to be transferring the maximum 32,000 sectors at a time.  And wait a minute, 32,000.  Okay, so that is, I am transferring half of what used to be DOS 3.3's maximum partition size per transfer in the new ReadSpeed Benchmark, and that's what I'll be doing with SpinRite.



And of course all of SpinRite's data recovery has always operated upon exactly one physical sector at a time.  But this, too, needs to be rethought in the era of drives which use larger actual physical sectors.  Logically they still say sectors are 512 bytes.  That has never changed.  But we know that modern drives often actually do have 4096-byte sectors.  And SSDs are well known to be storing their data in memory pages which are multiples of many physical sectors.  So all of that needs to get fixed.



And of course we then have the future.  If this was to be SpinRite's final dying gasp, the goal would be to just make it work and be done with it.  But all evidence is that we are at the start, I think, of a significant renaissance for SpinRite.  We've learned that today's mass storage engineers have been up to all manner of shenanigans, with the focus of designing products so that only a tolerable percentage will fail before their warranty period has lapsed, and also that any data loss will go unnoticed.  This is not to say that these products do not deliver stunning performance and capacity.  They do.  I feel my age when I think about how large today's drives are and how inexpensive they are.



But the nature of economics has always driven any designs and their designers to squeeze out every last possible drop of performance and capacity, while regarding some failure as inevitable and tolerable, even if that's never what any purchaser feels.  Warrantees only refer to the device's functioning, never to the user's data.  So my point is all of that old code in SpinRite has no future.  And we'll be able to get to a SpinRite 7 after SpinRite 6.1 or 6.2, whatever, if I am able to then take SpinRite's new and stripped down code and move it forward.  But I cannot move it forward as is.  It's just dragging far too much useless history along.



So the conclusion I've reached is that I should remove all of the creaky old code, which is in the way, during the sector addressing expansion from 32 to 48 bits while dropping the equally creaky old cylinder head sector and track abstractions and incorporate an awareness of true physical sector size into SpinRite's data recovery operations.  And in the interest of getting this out the door, I will largely leave SpinRite's funky textual UI as is, which will deliver what everyone most wants, a blazing SpinRite that they can again use on drives of any size, with performance that makes that truly practical.



So anyway, I just - when I opened SpinRite up and began looking at what I was going to have to do, I thought, wow, I really have moved so far away, Leo, from the days of a 32MB partition size limit.  And then I was seeing this logical to physical,  I go, oh, my god, remember OnTrack that, like, you would use that to set your system up in order to get a partition of a useful size.  Wow.



LEO:  It's amazing.  It really is.  The thing is, SpinRite has been around for a long time.  Most other programs don't have this kind of history.  So you've been dealing with this since hard drives began.  What's cool is you're entering the SSD era and being just as useful.  I think that's really interesting, myself.



STEVE:  Yeah, yeah.  It's really got me revved up.  So I'm going to get SpinRite 6.1 out to everybody, and then on to 7.



LEO:  Good.  Thank you, Steve.  And I love it, frankly, I love it that you're keeping the old text-based interface because why not?  Why not?  You don't need drop shadows and 3D GUIs or anything.  It gets everything done.  I actually use a lot of, you know, they call it TUIs, Textual User Interfaces.  I use a lot of TUI apps.  And I think they're great.  Nothing wrong with that.  Saves you a lot of time.



STEVE:  In fact, I was just talking about that over in the SpinRite group.  I'm sort of thinking, planning ahead where I'm going to go.  And I like the idea of using the Windows PE, the Preexecution Environment, because Microsoft allows it to be used for setup and recovery purposes.  So it falls exactly within my usage.  It doesn't have a shell.  But, oh, and it will only run for 72 hours, three days.  And so that's plenty of time with the new - no, no, it's plenty of time with the new SpinRite. 



LEO:  Really.



STEVE:  Because it'll be able to do things in hours.



LEO:  Oh, boy.



STEVE:  Yeah, yeah, yeah.



LEO:  Yeah.  I didn't realize that it was going to be that much faster.  That's fantastic.



STEVE:  Oh, Leo, it is, yes, it screams.



LEO:  Wow.  Well, soon.  You can go get a copy of SpinRite right now, and a copy of this podcast.  Get two things done, kill two birds with one stone, as they say.  Go to GRC.com.  Pick up SpinRite.  When you buy 6.0 now, you're automatically buying an upgrade to 6.1, plus you get to participate in the testing as we get closer and closer to the release.  GRC.com.  You also get 16Kb versions of this show, 64Kb versions of this show.  Transcripts, which is great if you like to read along while you listen.  That's all at GRC.com, plus a lot of other stuff, all free, Steve's hangout.  You can leave him feedback there at GRC.com/feedback.  Or on Twitter he's @SGgrc, and you can DM him there.  His DMs are open.  So if you've got a question, a comment, a suggestion, a Picture of the Week...



STEVE:  Or a Picture of the Week.



LEO:  A Picture of the Week.  Always [indiscernible] your Cheetos, @SGgrc.  We've got 64Kb audio plus video of the show at our website, TWiT.tv/sn is the actual direct link.  There's a YouTube channel.  There's also, well, probably the easiest thing to do is subscribe in your favorite podcast application, and that way you'll get it automatically.



Beginning of the year means it's time for the annual TWiT Survey.  We're taking a deep dive into who you are, what you like, what you don't like.  It's helpful for us as we design shows, but it's also frankly helpful for us with advertisers.  And that's our bread and butter at this point.  That's what keeps us going.  So if you'd like to help us out, shouldn't take too long.  Don't answer any question you feel uncomfortable with.  Just go to TWiT.tv/survey21, our 2021 TWiT Survey, TWiT.tv/survey21.



Steve, have a great week.  Enjoy your rewatch of "The Expanse."  I'll enjoy my first watch.  And we'll see you next time.



STEVE:  Yeah, it's so good.  And mostly I'm enjoying being up to my elbows in SpinRite.  As you said, it's been around for 40 years.  It is venerable.



LEO:  When you look at the code, do you, like, remember when you wrote that, or what was going on when you wrote that?



STEVE:  No.



LEO:  No.  You don't have - but you do, when you look at it, you look at it and you know what's going on; right?



STEVE:  Yes.  My coding style fortunately was already mature enough.  But, I mean, I was leaving comment trails.  I had comment blocks.  And I've always been a believer in long variable names.



LEO:  Nice.



STEVE:  So everything sort of documents itself.  So you won't find my code having a QZD constant or something.



LEO:  No, no, no.  Do you use a lot of macros?  I know MASM supports it.



STEVE:  Yeah.  Yeah, MASM supports macros.  And I have a whole bunch.  In fact it's one of the things that's made it difficult for me to open source my code because I've got fully custom headers, fully custom macros, my own libraries, and all this stuff that I've built over time.



LEO:  Yeah.  But that speeds it up.  I remember when I was doing assembly coding.  If you have good macros, it's almost like high-level coding.  You don't have to do moves and jumps as much because you've got a macro that does it all.



STEVE:  Right.



LEO:  Fun.  I kind of miss those days.  It was really fun.  But Steve's on it, you know.  That's the key, Steve's on it.  We'll talk to you next week, Steve.



STEVE:  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#802

DATE:		January 19, 2021

TITLE:		Where the Plaintext Is

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-802.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at one aspect in which Chrome and Chromium differ, and then at a bit of growth news from the DuckDuckGo folks.  Google's Project Zero reports on some terrific detective work, and we look at last week's Patch Tuesday.  There's also Microsoft's pending change to the flaws which enabled last year's Zerologon debacle, and the NSA's interesting statement about enterprises and the DoH protocol.  We look at the research that cracked the secret key out of Google's supposedly uncrackable Titan FIDO U2F dongle, and we catch up with a bit of listener feedback.  Then we wrap up by looking at various aspects of the frenzy caused by WhatsApp's quite predictable move to incorporate its users' conversation metadata into Facebook's monetization ecosystem.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  Our first Patch Tuesday of 2021.  Not a record-breaker, only one zero-day.  Just one?  Just one.  We'll also talk about a flaw, a side-channel attack in Google's Titan Security Keys.  Uh-oh.  And Steve explains why you probably don't have to worry about how secure your Messenger is anyway.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 802, recorded Tuesday, January 19th, 2021:  Where the Plaintext Is.



It's time for Security Now!.  Oh, I know you've been waiting all week.  I know we have a lot of people, oh, can't wait till Tuesday, Security Now!.  Here's the guy, Steve Gibson.  Yay, the man you've all been waiting for from GRC.com and our security guru.



STEVE GIBSON:  We ought to really consider renaming the podcast  What Could Possibly Go Wrong?



LEO:  Oh, there's plenty, isn't there, Steve.  Oh, man.



STEVE:  Indeed.  So the title of this one came to me, well, I sort of stumbled on it when I was sort of laying out the case that I'll be making at the end of the podcast.  So at the moment, the title "Where the Plaintext Is" might not be immediately obvious.  But it ends up being a fun title when I end up pulling the pieces together.  This is Security Now! #802 for January 19th of 2021.  Lots of interesting stuff to talk about.  We're going to look at one aspect in which Chrome and Chromium differ.  Because the difference has never really been clear.  Turns out Google realized that there was one difference they should have been better enforcing than they were.



Then we're going to take a look at some nice growth news from the unfortunately named DuckDuckGo folks.  Google's Project Zero has reported on some terrific detective work they've done and also asked a really important question that we'll take a look at.  We're also going to do a little bit of a look back at last week's Patch Tuesday, what lessons there were there, what happened; and also at Microsoft's pending change in the flaws, or the remediation I should say of the flaws, which enabled last year's Zerologon debacle.  That's coming with next month's Patch Tuesday, but just want to make sure all of our listeners are ready for it in the IT environment.



Also the NSA's interesting statement about enterprises and, I would say, "and" the DoH protocol, but maybe "versus" the DoH protocol would be putting it better.  We're going to look at the research that cracked the secret key out of Google's supposedly uncrackable hardware Titan FIDO U2F dongle.



LEO:  Oh, interesting.



STEVE:  Yeah.  And then we catch up with a bit of listener feedback, which allows me to tie up a couple loose ends from our "Out With the Old" podcast last week.  Then we're going to wrap up by looking at various aspects of the frenzy caused by WhatsApp's quite predictable move to incorporate its users' conversation metadata into Facebook's monetization ecosystem.  And that brings us back to the title of the podcast, "Where the Plaintext Is."



LEO:  Oh, boy.



STEVE:  And of course we do have a fun Picture of the Week.  So I think a great podcast for our listeners.



LEO:  It wouldn't be Security Now! without a Picture of the Week, would it.



STEVE:  Thanks to our fabulous listeners who send me a constant trickle of these things, yes.



LEO:  All right.  Are we ready for the Picture of the Week, Mr. G?



STEVE:  So this is just fun.  Just a cute little cartoon.  We have an aviator flying a little one-man jet fighter kind of thing.  And he is seen to be saying, "DAMN!  Cloud computers!!" because he's flying through a bunch of clouds where they are laced with computers.  And of course they're bouncing off of his airplane.  One of them says "Bounce!"  One says "Pock!"  I got a kick out of the fact that one of them is "Ping!"  And there on the back it says "Cron!" as it bounced off the machine.



LEO:  Oh, that's funny.



STEVE:  Yeah.  So anyway, just sort of fun little cartoon of yes, a different meaning of the term "cloud computers."



LEO:  Very funny.



STEVE:  You don't want to actually have computers in the cloud because...



LEO:  No, you don't.



STEVE:  ...you might fly through them, and then that would be bad.  So when is Chrome not Chromium?  We all know that Google's worldwide leading Chrome browser is based upon the open source and very solid Chromium core.  And this tends to beg the question, how are Chrome and Chromium similar and different from one another?  Because as we've said, you've got Safari and Firefox, and then everything else is now Chromium.  One of the Chromium-based browsers is Chrome, but there's a whole bunch of others that are all based on the Chromium core.



So at least one way in which Chrome is meant to be different from Chromium is in the way Google-specific features that are available only in Chrome operate.  These are things like Chrome sync and Click to Call, or signing into the user's Google account and transacting personal sync data - bookmarks, passwords, history, open tabs, settings, preferences, and in some cases even payment info saved in Google Pay.  That's meant to be Chrome-specific.



Well, it turns out the Chrome API provides direct hooks - that is, the Chrome API as opposed to Chromium API.  The Chrome API provides direct hooks into those services that no other third-party web browser is meant to have.  Yet Google Chrome Engineering Director Jochen Eisinger explained that during a recent audit they discovered that some of the third-party Chromium-based browsers were integrating features - whoops - that were only intended for Google's use with Chrome.  These APIs were intended to be private and specific only to Google Chrome.  But apparently there was no enforcement of that.  They were never intended to be integrated into any non-Google, non-Chrome browser use.



He declined to indicate which browsers had integrated Chrome sync without authorization, but he did say that Google would be blocking this unintended behavior starting on the 15th of March, so two months from a couple days ago.  By removing access to Chrome sync for other Chromium web browsers, it will remove their ability, which apparently they've had kind of quietly, to integrate the Chrome sync API to sync their users' data to all devices where they're logged into their Google account.  However, Google did explain that users who have accessed private Google features such as Chrome sync while using third-party browsers will still be able to access this synced data locally or in their Google account, depending upon their sync settings.  They'll also be able to manage their data by going to the My Google Activity page, as well as downloading it from the Google Takeout page, and/or by managing it, also delete it by going there.



So anyway, I thought this was sort of interesting, that Google is very generously sharing the Chromium engine with all other browsers.  It doesn't seem to be hurting Chrome's market share any.  But there was some stuff that was like, no, no, that's just for us, which they weren't enforcing before.  So they're now going to add some enforcement to that, so that it only runs in their own browser.  And again, not a big loss for anybody, just sort of one fewer feature that they shouldn't have had.  But you can still get it if you just go to the Google pages themselves.



Though it's not a browser, this bit of news is related to our browsing.  Not long ago we talked about the privacy-centric DuckDuckGo search engine, and I had some fun talking about, well, actually, Leo, you were clueing me in on some children's game after which this search engine was unfortunately named.  And we imagined that, much as "google it" has obtained a generally understood meaning, that perhaps someday the same will happen with "duck it."  Although I'm not holding my breath on that one.



LEO:  Yeah, maybe not, yeah.



STEVE:  Yeah, I don't know.



LEO:  Is that what they're pushing?



STEVE:  I'm hearing some people saying, I saw someone said "duckduck," and I don't think that works, either.



LEO:  No.



STEVE:  So, you know, this is the cross this poor guy's going to have to bear in deciding to name his search engine DuckDuckGo.  I mean, okay.  Maybe, since Google was kind of whimsical, they could get away with it.  But no.  Anyway, despite its name, the good news is it is actually a serious contender in the rather rarefied search engine space these days.  So I wanted to take a moment to share a milestone that it reached for the first time last Monday.  Last Monday for the first time in its 12-year history, DuckDuckGo recorded its first day ever of more than 100 million user search queries.  For the past two years, DDG - which is a less painful abbreviation - has been in a period of sustained growth, and especially since last August, when they began seeing more than two billion search queries a month on a regular basis.



Okay.  Now, to give that some context, however, since that seems like a lot, right, two billion search queries a month regularly, Google does five billion a day.  So, okay, they're not at Google's level, obviously, yet.  But they're growing.  I put a chart in the show notes which is interesting.  This shows it anchors on last Monday, well, actually Monday before last, but it shows the 14-day region around there, starting with January 1st, where they were at 77.1 million queries.  And then they get up into the mid- to high 80s.  And then on the Sunday before that Monday, on the 10th of January, they were at 94.8 million.  And then Monday they went to 102.  They've since, on the Tuesday-Wednesday-Thursday, they didn't quite make 100 million, but they were in the very high 90s - 99, 98, 97.



So anyway, they're there.  And clearly the idea of searching without dragging all of Google's tracking and advertising baggage along is appealing to people.  They have also, I wanted to note, expanded beyond their own browser URL as the only way to get there.  They've got mobile apps for Android and iOS, as well as a dedicated Chrome extension for DuckDuckGo browsing.  And in a tweet last September they indicated that the apps and extension have been installed more than four million times.



Oh, and in another win for the company, DuckDuckGo has been selected as the default search engine in the Tor browser.  Remember once upon a time that was Firefox.  Now DuckDuckGo.  And it will often appear as the default search engine in the private browsing modes of several other browsers, which is kind of nice.  You switch into private browsing, and you get a privacy-oriented search engine as part of that.  So anyway, just to sort of keep it on our listeners' radar.  I wouldn't be at all surprised if our privacy and security-conscious users are counted among many of DuckDuckGo's users.  Despite the name.



Last Tuesday Google's Project Zero published a six-part series which takes a very deep analytical look at a discovery the group made a year ago, that is, during the first quarter of last year.  Last week I was talking about watering hole attacks where a browser vulnerability, in this case it was that SCTP protocol vulnerability, where unlike a JavaScript vulnerability which is occurring locally using code in your browser, in this case in this SCTP protocol, in order to be exploited, the user would have needed to visit, often being lured to a so-called "watering hole" server.  So I especially appreciated the way Google framed this campaign of theirs.  Here's how they began the first of these six pages in this very substantial posting.



They said:  "At Project Zero we often refer to our goal simply as 'make zero-day hard.'"  This is not the first time we've talked about this.  I think it's exactly the right goal.  They said:  "Members of the team approach this challenge mainly through the lens of offensive security research" - as opposed to just responding to, how do they prevent.  They said:  "And while we experiment a lot with new targets and methodologies in order to remain at the forefront of the field, it is important that the team doesn't stray too far from the current state of the art.  One of our efforts in this regard is the tracking of publicly known cases of zero-day vulnerabilities."  In other words, they look, really look at each of them and ask a bunch of questions about them.



They said:  "We use this information to guide the research.  Unfortunately, public zero-day reports rarely include captured exploits, which could provide invaluable insight into exploitation techniques and design decisions made by real-world attackers."  They said:  "In addition, we believe that there is a gap in the security community's ability to detect zero-day exploits.  Therefore, Project Zero has recently launched our own initiative aimed at researching new ways to detect zero-day exploits in the wild.  Through partnering with the Google Threat Analysis Group (TAG), one of the first results of this initiative was the discovery of a watering hole attack in the first quarter of 2020, performed by a highly sophisticated actor."



They said:  "We discovered two exploit servers delivering different exploit chains via watering hole attacks.  One server targeted Windows users, the other targeted Android.  Both the Windows and the Android servers used Chrome exploits for the initial remote code execution.  The exploits for Chrome and Windows included zero-days.  For Android, the exploit chains used publicly known n-day exploits."  And of course referred to as "n-day" because, as I've often noted, they're only true zero-days if they are not previously known.  So if it's a publicly known thing, then by definition it's an n-day.  Then they said:  "Based on the actor's sophistication, we think it's likely that they had access to Android zero-days, but we did not discover any in our analysis."



So I have a picture in the show notes of the chart that they provided along with this analysis, where they show on the left incoming, a number of affected websites - 1, 2, ... to N.  And those websites deliver a pair of iframes which have no contact or affiliation with each other, other than that they are sourced from the same set of servers.  And then one iframe will pull content from the Windows exploit server, because remember an iframe itself is a reference to some third-party server that it pulls content from to fill the frame.  The other iframe pulled its content from the Android exploit server.  So both of them would do that.  And presumably they only pull content based on the platform they find themselves running in.



So if the Windows content-pulling iframe sees it as running on a Chrome browser on Windows, then it pulls the content.  And whereas the Android iframe would just leave itself inert and pull nothing.  Whereas if it finds that it's running Chrome on Android, then the Windows iframe would not bother pulling iframe exploits into its frame, whereas the Android iframe would.  So from that point, then, the Windows exploit iframe performs some Chrome renderer exploits, and the Android exploit, if it's on Android, performs one of a number of Chrome renderer exploits, those being the problems that Google discovered being exploited by this particular attack.



So, and of course, one of the things you note is that, since the multiple servers apparently are serving this content, this could well have been a malvertising campaign since, as we know, ads run in iframes on their hosting pages.



Anyway, so they continue their explanation, saying:  "From the exploit servers, we have extracted" - so the beauty of this is that they discovered this campaign while it was underway, which is what differentiates it from the typical zero-days they learn about from third parties.  They found this one, which allowed them to extract a great deal of knowledge about the attackers because it was still alive.  So they said:  "From the exploit servers, we have extracted renderer exploits for four bugs in Chrome, one of which was still a zero-day at the time of the discovery," meaning that they found something they didn't know about, a bug they didn't know Chrome had when they saw this thing working.



They also found two sandbox escape exploits abusing three zero-day vulnerabilities in Windows, and a privilege escalation kit composed of publicly known n-day exploits for older versions of Android.  And of course we know, unfortunately, older versions of Android are really much a large population of Android.  So even though they're publicly known, they're still very likely to be active.  They said:  "The four zero-days discovered in these chains have been fixed by the appropriate vendors."



And they said:  "We understand this attacker to be operating a complex targeting infrastructure, though it didn't seem to be used every time.  In some cases, the attackers used an initial renderer exploit to develop detailed fingerprints of the users from inside the sandbox.  In these cases, the attacker took a slower approach, sending back dozens of parameters from the end users device before deciding whether or not to continue with further exploitation and use a sandbox escape.  In other cases, the attacker would choose to fully exploit a system straight away, or not attempt any exploit at all.  In the time," they said, "we had available before the servers were taken down, we were unable to determine what parameters determined the 'fast' or 'slow' exploitation paths."



"The Project Zero team," they said, "came together and spent many months analyzing in detail each part of the collected chains.  What did we learn?  These exploit chains are designed for efficiency and flexibility through their modularity.  They are well-engineered, complex code with a variety of novel exploitation methods, mature logging, sophisticated and calculated post-exploitation techniques, and high volumes of anti-analysis and targeting checks."  So these exploits were themselves operating very defensively.



They said:  "We believe that teams of experts have designed and developed these exploit chains.  We hope this blog post series provides others with an in-depth look at exploitation from a real-world, mature, and presumably well-resourced actor.  The remaining posts in this series share the technical details of different portions of the exploit chain, largely focused on what our team found most interesting."



They said:  "We include detailed analysis of the vulnerabilities being exploited and each of the different exploit techniques; a deep look into the bug class of one of the Chrome exploits; and an in-depth teardown of the Android post-exploitation code."  They said:  "In addition, we are posting root cause analysis for each of the four zero-days discovered as a part of these exploit chains.  Exploitation aside, the modularity of payloads, interchangeable exploitation chains, logging, targeting, and maturity of this actor's operation set these apart.  We hope that by sharing this information publicly, we are continuing to close the knowledge gap between private exploitation, what well-resourced exploitation teams are doing in the real world, and what is publicly known."



And again, this is chilling, a bit like the whole SolarWinds revelations were.  The idea that there is this kind of high-level, sophisticated, methodical, careful, and clearly in many cases very targeted use of currently unknown vulnerabilities sort of should be sobering for us because the idea is that these actors know whose systems they want to get into, whose Android phones they want to penetrate, whose Windows systems they want to penetrate.  They arrange to get them to visit a server somehow hosting some content which then puts these iframe payloads onto their browser window.  We know that the chances are very high that an Android user will be using Chrome, a Windows user will be using Chrome, and they found ways to break through, you know, these renderer exploits, as in page rendering exploits.  So they have rendering flaws that let them escape from Chrome's deliberate containment, and then they go about doing what they want to do.



For anyone who's interested in following up, I do have a link to this Google Project Zero blog page, which is the first of this multipage presentation, for anyone who's interested.  But what I thought to be the single most important phrase in what I read was where the Project Zero guys wrote:  "In addition, we are posting root cause analysis for each of the four zero-days discovered as part of these exploit chains."  The key words there were "root cause analysis."  In other words, "Oh, crap.  We just found another zero-day."  Yeah.  Always definitely better to have found it than not.  But much better for it never to have existed in the first place.



So, rather than just fixing it and saying "Whew" and then going to lunch, let's instead order in and spend lunchtime asking ourselves how this fault was introduced in the first place, and what takeaway lessons we can learn to preemptively prevent anything like this from happening again.  That is essentially what they're doing.  They are looking at every one of these zero-days carefully, the code that surrounds it.  How did it happen?  And I think this is exactly what needs to be done.  And clearly the continuing prevalence of software bugs which beleaguer our industry suggests that examining root causes occurs far too infrequently.



I've commented here on the podcast in the past that I truly love solving problems and puzzles with code.  For me it's a passion and a craft.  So whenever I find a bug in my own code, as I've said before, I come to a dead stop, and I spend some time asking myself and exploring how that bug happened in the first place.  What was I thinking?  Exactly what did I get wrong?  Is it likely to have happened elsewhere?  Do I have a bad habit that needs correcting?  In other words, rather than being embarrassed about a bug, be informed by it.  Some incorrect way of thinking caused it.



And so I would submit that the only way for any craftsman to improve at their craft is to rather carefully examine and understand their mistakes.  Certainly, Leo, we know this is the case with chess; right?  The reason all of the really high-end masters record every move of their game is they're going to take a look at that later and spend a lot of time examining the board at each stage and understand why they lost the game.



LEO:  You bet, yeah.



STEVE:  If in fact they did.  At a certain point it's the only way.  You're just not going to get better by hoping to do better next time.  At some point you really have to understand the nature of the mistakes you're making in order not to make them again.  And there have been instances where I have found a bug where I realized, oh, my god, there are others of these.  And I've designed...



LEO:  That's a bad feeling.



STEVE:  ...designed a regular expression, a regex, which will find the other places where I almost certainly did the same thing wrong, and fixed other ones.



LEO:  It's hard for people because we're blind to our own mistakes often.  It's so hard to do your own debugging because you stare and you stare and you stare at the code, and you go...



STEVE:  Looks great.



LEO:  Looks great.  I don't understand.  I can't, you know.  But I agree with you.  There is a certain sport to it, as well.  It's kind of fun.



STEVE:  Oh, it is.  And when you are stepping through the code, and the debugger shows you, okay, I'm moving this into EAX, and it's like, wait a minute, I just wiped out what was there, which I'm going to be needing two steps later.



LEO:  It must be so easy to do that in assembly code because any modern high-level language has all sorts of protections so that you avoid that kind of thing.  But it's all on you in assembler.



STEVE:  Well, it is.  But what I like about it is nothing is hidden.  There are no, like, ooh, I meant for this to be unsigned, and now blah blah blah.  It's like, no, there's no such thing in assembler.  So, yeah.  We have the first Patch Tuesday of the year 2021.  Okay.  So we didn't break any records.



LEO:  Aw.



STEVE:  And that's the good news.  We had a total of 83 vulnerabilities.  And we were like over a hundred several of the early months last year.  Ten of those 83 were Microsoft classified as critical, and another was a zero-day, which we'll get to in a moment.



LEO:  Ooh, not good.



STEVE:  Yeah.  Not good.  But good that it's patched, and hopefully everybody's updated their machines.  I just got the little notice while you were talking, Leo, that this machine, this Windows 10 machine that I'm Skyping on will be restarting, but not during the podcast, fortunately.  Two of the critical vulnerabilities that were fixed were remote code execution vulnerabilities in two codecs.  One was a Microsoft DTV-DVD video decoder, and the other was the HEVC video extensions, which just had a problem recently.  So yes, yet again.



There was also a remote code execution vulnerability in the GDI+ library, the Graphics Device Interface, and a critical memory corruption vulnerability in Microsoft Edge, in the browser.  The remaining five critical remote code execution vulnerabilities were all found and fixed in Microsoft's RPC, the Remote Procedure Call runtime, which is really not where you want to have remote code execution vulnerabilities because RPC is inherently exposed on the network.  The biggie was the zero-day that was found in Microsoft Defender, that is, in the AV system, being executed in the wild.  They had found a mistake in Defender.  And when the malware was being scanned by Defender, it took it over.  So, whoops.



LEO:  Oh.  Oh.  Oh.



STEVE:  It's being tracked as CVE-2021-1647, a remote code execution flaw in Microsoft's Malware Protection Engine component, mpengine.dll.  Sometimes when I look at Task Manager and browse through what the heck is going on, I'll see, oh, yeah, mpengine.dll.  So the good news is mine on Windows 7, I don't even know if it's good or bad, come to think of it, but let's hope not.  Most of them now are on Windows 10.  Oh, and a proof-of-concept exploit for the flaw is public.  So we don't have any indication of how widespread the exploitation is or was, nor anything about its nature.  But we do know that it was discovered taking over instances of Defender.  So by now we are post-patch by a week.  I'd imagine that everyone has updated and rebooted.  If not, I don't think this is like a pants-on-fire problem.  But at least know that there is a bad problem that was a zero-day that was fixed.  So good to reboot when you can.



Also, with next month's Patch Tuesday, which will occur on February 9th, we have the final second phase of Microsoft's Zerologon remediation.  As we know from its extensive abuse last year after its discovery and patching, which did very little to prevent it from being exploited post-patch.  Thich demonstrates how little patching is, amazingly, going on.  This was the Zerologon flaw in Microsoft's previously believed to be more secure than it turned out to be RPC Netlogon protocol, which provided the perfect means for attackers to move laterally within an organization after they had once established a foothold somewhere.  It allowed them to effortlessly log onto the enterprise's Master Domain Controller, which then literally gave them the keys to the kingdom.



So the first of the two patches was in August, which fixed the security problem between Windows devices to reinforce truly secure Remote Procedure Call communications for machine accounts on Windows devices, trust accounts, as well as all Windows and non-Windows Domain Controllers.  In other words, as of August, Windows to Windows RPC was secured.  But there's a large population of non-Windows devices that are also users of RPC.  They were not previously understood to be as insecure as we came to understand they were because RPC, the Netlogon protocol, turned out you could put some zeroes in some fields, and everything would be just fine.



So since August, IT admins have been able to log all non-secure use of RPC by various devices within their infrastructure in order to help them prepare for what's going to happen on February, which is drop-dead day for all non-Windows devices, which have had this period, sort of a grace period, during which they could get themselves updated to be using secure RPC as have all Windows systems since August.  After February 9th, Domain Controller enforcement mode, as it's called, will be enabled by default.  Domain Controller enforcement mode requires that all Windows and non-Windows devices use secure RPC with Netlogon secure channel, unless customers explicitly override that.  And, you know, good luck to you, if you choose to.



You can force it off if you've got some non-compliant device still in your system that you have to still be able to support.  But at that point, Microsoft is going to just wash their hands of you and say, okay, this is not our fault, if you now get ransomware that uses the fact that you've allowed non-secure channel Netlogon because you have some thing that you just have to still keep using that refused to be updated, some legacy box of some kind, and its publisher is gone, but you have to keep using it.  Who knows what the scenario would be.  But hopefully that's not the case.  Next Patch Tuesday the final bit of deliberate insecurity of the Netlogon protocol will be eliminated.  So hopefully everybody will be able to step up at that point.



Now, in an interesting posting from the NSA, they are - the NSA, the National Security Agency are warning against outsourcing of DoH services.  In their seven-page advisory titled "Adopting Encrypted DNS in Enterprise Environments," which they posted last Thursday, the NSA warned against outsourcing DoH services to a third-party provider.  Which at first glance might seem a little odd.  But, okay.  So here's their executive summary.  The first bit of it is, yeah, a little obvious to all of us.



They said:  "Use of Internet relies on translating domain names like 'nsa.gov' to Internet Protocol addresses."  Right.  "This is the job of the Domain Name System (DNS).  In the past, DNS lookups were generally unencrypted, since they have to be handled by the network to direct traffic to the right locations.  DNS over Hypertext Transfer Protocol over Transport Layer Security (HTTPS), often referred to as DNS-over-HTTPS (DoH), encrypts DNS requests by using HTTPS to provide privacy, integrity, and 'last mile' source authentication with a client's DNS resolver."  All that's true, in case any of you haven't been paying attention in the last couple years.



Then they said:  "It is useful to prevent eavesdropping and manipulation of DNS traffic.  While DoH can help protect the privacy of DNS requests and the integrity of responses, enterprises that use DoH will lose some of the control needed to govern DNS usage within their networks unless they allow only their chosen DoH resolver to be used.  Enterprise DNS controls can prevent numerous threat techniques used by cyber threat actors for initial access, command and control, and exfiltration."



So they said:  "Using DoH with external resolvers can be good for home or mobile users and networks that do not use DNS security controls.  For enterprise networks, however, NSA recommends using only designated enterprise DNS resolvers in order to properly leverage essential enterprise cybersecurity defenses, facilitate access to local network resources, and protect internal network information. The enterprise DNS resolver may be either an enterprise-operated DNS server or an externally hosted service.  Either way, the enterprise resolver should support encrypted DNS requests, such as DoH, for local privacy and integrity protections, but all other encrypted DNS resolvers should be disabled and blocked.



"However," they said, "if the enterprise DNS resolver does not support DoH, the enterprise DNS resolver should still be used, and all encrypted DNS should be disabled and blocked until encrypted DNS capabilities can be fully integrated into the enterprise DNS infrastructure.  This guidance explains the purpose behind the DoH design and the importance of configuring enterprise networks appropriately to add benefits to, but not hinder, their DNS security controls.  The following recommendations will assist enterprise network owners and administrators to balance DNS privacy and governance."  And I will blessedly spare all of us from any further of that.



But for what it's worth, I completely agree with every sentence in that Executive Summary.  I think they got it all exactly right.  The only issue I might take is wondering about the value, let alone the necessity of enabling DoH within the enterprise at all.  I really don't see what value it provides if your internal LAN has encrypted DNS or not.  Maybe that's a function of how big the encrypted LAN is.  I mean, for example, once upon a time HP was, what, it was 15-dot.  I think 14-dot and 15-dot.  And if they somehow glued all of that into one single massive enterprise LAN, then okay, maybe it would make sense to perform some encryption, just because you've sort of created at that point kind of a quasi public LAN, it's so big.



But I really take their point.  I think what they're responding to is that there are a lot of individuals inside of the enterprise that are saying, hey, cool, I can blind my enterprise's IT to everything I'm doing.  You know, tech and privacy-minded employees might want to sneak their browser traffic out of the organization without being monitored.  But we always remind everyone that the use of employer networks is the employer's to oversee and regulate.  So I would think that enterprises would be entirely correct to block the use of DoH and require browsers to use standard DNS and the organization's DNS with whatever added security filtering and malware detection the enterprise might wish to deploy.  And yeah, bring up DoH in the enterprise and then users' browsers can use that.



But anyway, I appreciated, I guess, the NSA just kind of pointing out that circumventing all of an enterprise's controls by immediately tunneling out to an external provider is probably not the right thing to do.  So anyway, this posting of the NSA was picked up by all of the various security monitoring websites.  So I just thought I'd take a moment to say, yeah, I think I see their point completely.



A side channel in Titan.  The guys at NinjaLab performed a classic side-channel attack on Google's Titan FIDO U2F security key.  By watching it work, while monitoring its electromagnetic RF radiation, they successfully extracted its embedded, super-secret, deliberately designed to never be extracted, private key.  Yeah.



LEO:  Is it the same private key in all the Titan keys?



STEVE:  No.  Each key had its own.



LEO:  No.  Each key has its own, of course, yes.



STEVE:  Yes.  But the whole point is all of the crypto is done on key.



LEO:  Right.



STEVE:  So it never exposes that private key.  And once you have it, then you are 100% able to spoof the presence of that key.  That's the whole point.



LEO:  Do you have to have physical access to the key?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  So I'll explain all this in a second.  We've talked about side-channel attacks a lot in the past.  Sometimes the power drawn by a device while it's performing cryptographic operations will fluctuate a little bit.  Sometimes the power supply, we've talked about this, on a computer might emit different sounds.  Or perhaps the timing required to perform an operation will vary.  It could be anything.  The coolest way of stating the goal of avoiding any possibility for a side-channel is that nothing about the behavior of a device should vary as a function of any internal secret bits.



So taking timing as an example, the time required to perform some operation, typically the pattern of conditional jumps taken in the code, should be completely independent of the secret being kept.  That is, you should never have a jump taken or not based on bits of a secret key.  That would be just really bad.  So the bits of the secret key must not cause the algorithm's code path to vary, as one of the base requirements for avoiding side-channel attacks.  The fact is, some things are feasible to hold constant; but others I would argue, much as I argued against Intel's claim of having a ransomware detector in their processor last week, I would argue that some things really do fall below one's ability to control.  Such as the instantaneous electromagnetic radio frequency radiation of an integrated circuit that's doing the work.



LEO:  Yeah.  You can't really - I guess you could wrap it in tinfoil.  I don't know.



STEVE:  Yeah.  And the problem is, then you unwrap it.  I mean, even if you put like a lid on it, well, you pop the lid, and there it is.  So the NinjaLab guy said:  "The Google Titan security key is a FIDO U2F hardware device proposed by Google, available since July 2018, as a two-factor authentication token to sign into applications - for example, your Google account."  They said:  "Our work describes a side-channel attack that targets the Google Titan Security Key's secure element" - and that's the NXP, which used to be Philips, they renamed, NXP A700x chip - "by the observation of its local electromagnetic radiations during ECDSA (Elliptic Curve DSA) signatures, the core cryptographic operation of the FIDO U2F protocol.  In other words, an attacker can create a clone of a legitimate Google Titan Security Key."  Period.



"To understand the NXP Elliptic Curve DSA implementation, find a vulnerability and design a key-recovery attack, we had to make a quick stop on Rhea (R-H-E-A)."  That's the NXP J3D081 Java Card smartcard, they said, that is freely available on the web.  "This product looks very much like the NXP A700X chip and uses the same cryptographic library.  Rhea, as an open Java Card platform, gives us more control to study the Elliptic Curve DSA engine."



So that was very clever.  They realized that these two chips, the one they knew nothing about and the one they could know everything about, were very similar.  So they trained themselves up using the open source full everything is known about it version, and then cross-applied that to the one they didn't know anything about.



They said:  "We could then show that the electromagnetic side-channel signal bears partial information about the Elliptic Curve DSA ephemeral key.  The sensitive information is recovered with a non-supervised machine learning method and plugged into a customized lattice-based attack scheme."  Okay.  So they said:  "Finally, 4,000 ECDSA observations were enough to recover the known secret key on Rhea and validate our attack process.  It was then applied on the Google Titan Security Key with success, this time by using 6,000 observations, as we were able to extract the long-term Elliptic Curve DSA private key linked to a FIDO U2F account created for the experiment."  In other words, the golden goose, the keys to the kingdom.



Then they said, as a cautionary note, they said:  "Two-factor authentication tokens like FIDO U2F hardware devices' primary goal is to fight phishing attacks.  Our attack requires physical access to the Google Titan Security Key, expensive equipment, custom software, and technical skills.  Thus, as far as our study goes, it is still safer to use your Google Titan Security Key or other impacted products as FIDO U2F two-factor authentication token to sign into applications rather than not using one."  And by the way, the Yubico uses the same Philips chip.  So it was conjectured that it would be subject to the same side-channel attack.



They said:  "Nevertheless, this shows that the Google Titan Security Key and other impacted products would not avoid unnoticed security breach by attackers willing to put enough effort into it.  Users that face such a threat should probably switch to other FIDO U2F hardware security keys, where no vulnerability has yet been discovered."  And I'm thinking, well, okay, but it hasn't been discovered until it has been.  So the point is, don't let bad guys take your Google Titan Security Key.



LEO:  And if you do, if you lose control of it, just deauthorize it, and then they can't do anything with it.  Every single dongle-related site that I use my YubiKey on has the ability to remove a YubiKey and add a new YubiKey.  I've done it many times.  I mean, the saving grace on this is they have to have access to the key.  



STEVE:  Right, right.  And some secrets cannot be kept.  And the fancier the system is that tries, the more likely it is to have some behavior that gives it away.  Unlike a time-based one-time token, which uses symmetric cryptography, where each end needs to share a private key, systems like FIDO and also my own SQRL, use asymmetric public key cryptography where the user holds their private key, and the remote end holds their public key.  This significantly reduces the risk to the user and to the system, since the public keys never need to be kept secret.  The takeaway for this hardware token hack is not to be too glib about the idea that the hardware token's private key cannot possibly be extracted.  It clearly can be, if someone is sufficiently determined and, as you said, Leo, if you accept the challenge of some hacker who says, oh, let me borrow your...



LEO:  You don't need your key; do you?



STEVE:  Yeah, don't let him have your key.



LEO:  You wouldn't give him your house key.  Don't give him your Titan key, either.



STEVE:  That would be a bad idea, yeah.



LEO:  Just borrow your house key for five seconds.



STEVE:  Speaking of tokens, I got an interesting tweet from Robert Rosenberg which I got a kick out of.  He said:  "Several podcasts ago, you were discussing the PayPal football."  He says:  "Well, I did it.  I took it apart."  He says, in parens:  "(You've got to be careful, but it's not hard.)"  He says:  "Found the battery type, bought one, and put it in.  Next time I dealt with PayPal, I used the now-working football, and PayPal took it.  They authenticated on my dead-for-years token."  And he says:  "I'm guessing it's a press-based one-time password, not a time-based one-time password."



And I completely agree with Robert.  I think that we must have known that once, but I forgot, since I do recall, as I've mentioned before, noting that our listeners discovered that one of the digits was a simple modulus 10 counter.  So it must have been that they waited for it to turn off, then pressed it again and noted that one of the digits was simply incrementing 0 through 9 and back again.  So it isn't clock-based.  There wasn't a timer in there.  That really makes a lot more sense, just in terms of all the problems that you would have with it becoming out of time sync.  A smartphone doesn't have that problem because it's on the cellular network and is getting a constant update of its clock.  So anyway, just very cool, Robert.  Thank you for sharing.  If anyone's interested, if anyone still has the football, you can change the battery and bring it back to life.



LEO:  Good to know.



STEVE:  Very, very cool.  Peter Sinclair said, regarding "Out With the Old":  "Great show."  He says:  "Steve took me right back to the '80s.  I agree with you stripping out the old code from SpinRite 6.1.  We still have our 6.0 or older copies if we want to run it on any heritage drives we might have lying around."  And I wanted to mention I'm so glad that Peter noted that, since I had forgotten to explicitly mention last week that all owners of SpinRite will continue to have access to previous versions 5 and 6.



Just yesterday, I removed support for diskette drives from the 6.1 code.  Again, since they are so different from all other mass storage drives, and there was a bunch of explicit special case handling support for diskettes laced throughout the code, which is almost doing nobody any good.  But diskettes are a medium that can benefit significantly from SpinRite.  And every so often someone, typically an archeologist, will come up a diskette that's no longer readable, but that still contains some important data.  In such cases we suggest they download SpinRite 5, which all SpinRite 6 owners are able to do, because oddly, for some reason, v5 appears to do a better job on diskettes than v6.



And believe me, this has and continues to bug me.  I've spent hours staring at the code, and I can't explain why that's the case.  But I very clearly remember testing this, and SpinRite 5 was better than SpinRite 6 on diskettes.  So anyway, since 6.1 won't even see the diskette, you will be easily reminded to go get an earlier version of SpinRite.  And they cohabitate on your SpinRite boot USB or CD or whatever.  So it's easy to have them all around.  Anyway, just wanted to thank Peter for allowing me to remind our listeners that, as we move forward, it's not like the old versions die or don't work anymore or can't be used any longer.  They do still exist.



LEO:  Do you offer them for download, though?



STEVE:  Yeah.



LEO:  You can go there?  Nice.



STEVE:  You're actually to actually - yeah, you're able to actually, in the download link, just change it to SpinRite 5, and you get that version of SpinRite.



LEO:  That version, yeah.  That's really good.  That's cool.



STEVE:  Yeah.  And finally Oaksong, tweeting as @oaksong, he said:  "@SGgrc, glad to know I can still use those OnTrack managed drives."  And we know he's joking, or hope he's joking.  But here again, SpinRite 6.1 won't have any support for that.  It'll just look at, I mean, it'll see the drive and run, but it won't see the wacky partitions that it contains, whereas SpinRite 6 will.  So everybody will be able to use SpinRite 6, if you do run across an OnTrack managed drive.



LEO:  Who knows; you know?  I bet there's some out there.  Maybe even storing some bitcoin wallets.



STEVE:  Given our listeners, Leo, I guarantee it.



LEO:  Saw the guy who's offering $20 million to some town, I think it's in New Jersey, if they will find his discarded hard drive with hundreds of millions of dollars of bitcoin on it.



STEVE:  Ohhh.



LEO:  And the other one, the guy who put it on one of those locked hard drives, he only has two more...



STEVE:  Right, he's got two guesses left.



LEO:  He says:  "I've come to grips with it."



STEVE:  Ohhh.



LEO:  Ohhh.  His is worth 240 million.  Yikes.  That's a life-changing amount of money, I think.  "Where the plaintext is."



STEVE:  So WhatsApp has shown us that it's not only Zoom's CEO Eric Yuan who is deftly able to somehow locate the exact center of a large pile of poo to step in.



LEO:  Nicely put.



STEVE:  In Eric's case, well-meaning though he was, every time he opened his mouth in a well-meaning attempt to clarify something, he made things worse, often much worse.  And now, over the past week, in an apparent gross misunderstanding of why their own users were using their secure messaging product in the first place, WhatsApp, as we know, has managed to trigger such an exodus from their platform that the two primary alternatives, Telegram and Signal, have never seen such increases in their user base.



And in fact Signal has continued having trouble staying online amid the deluge.  We reported last week that Signal was struggling to authenticate the torrent of incoming users since they require an SMS messaging loop, and the cellular carriers were apparently having scaling issues of their own.  Then that trouble apparently migrated from the authentication side to the service itself.



For example, this triggered Signal outages and a tweet last Friday from Edward Snowden.  Edward tweeted:  "For those wondering about @SignalApp's scaling, #WhatsApp's decision to sell out its users to @Facebook has led to what is probably the biggest digital migration to a more secure messenger we've ever seen.  Hang in there while the Signal team catches up."  And then signed Edward Snowden, January 15, 2021.  And the rush may have been further accelerated when Elon Musk simply tweeted the two words "Use Signal" to his 42.6 million followers.



LEO:  It's so powerful.  It's amazing.  Just amazing.



STEVE:  So one of the questions that inevitably arises from any use of a free service is why is it free, and who is paying for this?  This, of course, reminds us of the famous joke:  "Well, yeah, we do lose money on each one.  But don't worry, we make it up in volume."  So this is one of the reasons why, if I were to use any third-party messaging app, and I don't because I just don't have any need for any, I would still choose Threema, which is paid for one time, although there are some enterprise subscription deals.  And that one time generates operating revenue for the company.  Oh, yeah, and as I mentioned, their so-called "Threema Work" product for the enterprise has a subscription model.  So again, we understand how they are monetizing.



And just as a reminder, since I mentioned Telegram and Signal, I just checked in with Wikipedia to see what they said about Threema.  They said:  "Threema was founded in December 2012 by Manuel Kasper.  The company was initially called Kasper Systems GmbH, German.  Martin Blatter and Silvan Engeler were later recruited to develop an Android application that was released in 2013.  In summer 2013, the Snowden leaks helps create an interest in Threema, boosting the user numbers to the hundreds of thousands.  When Facebook took over WhatsApp in February 2014, Threema got 200,000 new users, doubling its user base in 24 hours.  Around 80%, eight zero percent, of those new users came from Germany, which I guess makes sense since it's a German company.  By March 2014, Threema had 1.2 million users.  In spring 2014, operations had been transferred to the newly created Threema GmbH.



"In December 2014, Apple listed Threema as the most sold app of 2014 in the German App Store.  In 2020, last year, Threema expanded with video calls" - we talked about that at the time - "plans to make its codebase fully open source, as well as introduce reproducible builds and Threema Education, a variation of Threema intended for education institutions."  And, finally, Wikipedia is up to date.  "During the second week of 2021" - which is to say, last week - "Threema saw a quadrupling of daily downloads spurred on by controversial privacy changes in the WhatsApp messaging service.  A spokesperson for the company also confirmed that Threema had risen to the top of the charts for paid applications in Germany, Switzerland, and Austria.  This trend continued into the third week of the year with the head of marketing and sales confirming that downloads had increased to 10 times the regular amount, leading to 'hundreds of thousands of new users each day.'"



So, yeah.  If I had any need for private messaging, Threema would be my choice.  I would carefully and manually exchange my Threema public key with the people I need to converse with secretly, and that would be that.  When I was working with Rasmus on the SQRL XenForo integration, at his suggestion we used Signal, not because we needed any super secrecy, but because it had a convenient Windows desktop client, and we were in different time zones.  So we were able to easily exchange messages, screenshots, and links that way.  And when we happened to both be awake at the same time, our interaction would go interactive.  And it was comforting to know that our exchanges could not be intercepted and decrypted.  But these days that's sort of expected; right?



But I'm interested in the massive effect that was driven by WhatsApp's statement that they intend to share messaging metadata with Facebook's other businesses.  It's as if everyone using WhatsApp believed that Facebook purchased WhatsApp out of the goodness of their heart in order to offer the entire world a free messaging service without any strings.  As we noted above about the influx to Threema when Facebook announced their purchase of WhatsApp in the first place, even back then not everyone believed in the free lunch theory.



So when Facebook dropped their other shoe about their plans for further monetizing their WhatsApp users, no one should have been surprised.  It's always been clear that sooner or later Facebook would do this.  And if they cannot peer into the conversations,  then they'll at least collect everything they're able to from the outside.  It seems to me that knowing who I'm talking to and when, and for how long, and where we're located, is an intrusion.  But hey, it's free.



The problem was that they made, I think, too large a change all at once.  It's like the old joke about how to boil a frog.  You don't toss a frog into boiling water because it will jump right out.  Instead, you place the frog into cold and comfortable water, then slowly turn up the heat.  In retrospect, Facebook should have patiently and very slowly chipped away, little by little, at the privacy of their WhatsApp users through a series of much smaller privacy incursions.  There is a very non-zero switching cost associated with changing messaging platforms.  Right now Twitter is full of people complaining that they just switched to Signal, but no one they know is there.  So it's not enough just to make the move, you need to move your entire community.  And that's often difficult in the extreme.



So if Facebook had instead chipped away at their users' privacy, at each step the user would reconsider the switching cost of leaving WhatsApp, where all of their friends already are, and they might recall their disappointment the last time they tried.  Versus the loss of just one additional little privacy aspect that really doesn't matter that much anyway; right?  And if that had been the strategy, it seems clear that many fewer would have left.  Now, of course, they've said, oh, wait a minute, we're going to postpone for 90 days, and everybody misunderstood what it was we were doing.  We're going to try to be much better about communicating this.  Right.



And of course, as we know, instead of understanding that this incremental approach should have been taken, WhatsApp and Facebook, it sort of seems like maybe they got a little too big for their britches and lowered the boom on their users all at once, as we talked about last week, the "agree to this or else you will be disconnected" approach.  So anyway, no wonder the result has been a mass exodus.  The truth is, I think, essentially no users understand the underlying technology and privacy guarantees of the messaging systems they're using.  And in fact the illusion is enough.  Everybody wants the illusion of complete privacy, even if they don't actually have much.  Just tell them that they do.  Tell them it's good.  Tell them it uses military-grade encryption.  Tell them how many billions of years it would take for the world's largest supercomputer to crack their grocery list.  But whatever you do, don't mention that a simple keystroke logger would render every bit of that fancy technology completely superfluous.  They don't want to hear that.



Out of curiosity, I googled the phrase "secure messaging apps," wondering what would come up, and I received a list of links:  10 Most Secure Messaging Apps - Best Encrypted Chat App.  10 Messaging Apps Comparison.  The Best Encrypted Messaging Apps You Should Use Today.  Best Encrypted Messaging Apps, Tom's Guide.  The Most Secure Messaging Apps for Android and iOS 2020.  That was hosted by AVG.  And one of our sponsors actually of this show came up with the last link that I was quoting here, The Best Private and Secure Messaging Apps in 2021, brought to you by ExpressVPN.



So does any of this matter?  No.  As we know, there are subtle differences between apps and their underlying technologies.  Through the years we've covered them all, right here on the podcast.  Mostly the differences boil down to the way the various apps exchange and manage their users' keys, since the keys are everything.  But here's the bottom line.  Any proper use of encryption turns the conversation on the wire into maximum entropy noise, with no discernible patterns and no feasible means of decrypting what's intercepted over the wire ever.  Yes, your grocery list is safe.  But - and this is the point - that is the only protection that any of these apps can provide.  That's it.  Period.



The only thing that any of these apps can guarantee is that while the data is in motion between endpoints, it is utterly infeasible for it to ever be decrypted.  That's the only guarantee, and they all have it.  But any keystroke logger defeats any of these apps, no matter how many layers of military grade encryption have been employed after the keystrokes have been logged.  And of course I'm using the term "keystroke logger" because it's such a clear and well-understood term.  It stands in for the concept that I want to convey, which is that on-the-wire encryption no longer means anything about our actual true privacy.



If you look at the packets moving across today's Internet, unlike the Internet of 15 years ago, when we began this podcast,  all you will ever see today is packets full of noise.  Just 100% random bits of noise.  Today it's all noise.  It's all encrypted.  And no one bothers looking at it because anyone who wants to know what's in those packets also knows quite well that the encryption problem has long since been solved and that none of that noise on the wire can be decrypted.  The apocryphal story of the infamous bank robber Willie Sutton applies here.  The story goes that a reporter once asked Willie why it was that he robbed banks.  And Willie was said to reply, "Because that's where the money is."  Updating the story to 2021, a non-technical supervisor at the NSA might ask one of their top technical managers why all of the agency's work has been diverted to investments in keystroke logging, to which the technical manager would reply, "Because that's where the plaintext is."



The point I hope to make is that, barring some implementation mistake, none of this "What's the best messaging app" conversation matters in terms of its security.  The real world has moved on.  We've long observed that the best camera is the one you have with you.  Similarly, the best messaging app is the one shared by the people with whom you wish to communicate, period.  All other things being equal, I would choose the one with a clear and simple economic model that I understand and that makes sense to me.  If I don't care about my metadata being monetized, about Facebook tracking everyone with whom I communicate, then WhatsApp, whose economic model clearly requires it to eventually be snooping on me, would be just fine.



But if I do wonder who's paying for this service, and if I would prefer it to be very clearly me in exchange for not having the fact of my communications being monetized, then Threema would be my choice.  But in any event, the privacy provided by encryption should no longer factor into the equation because it doesn't matter at all.  Anyone who wishes to have access to the content of our conversations will go after the plaintext, before it's encrypted or after it's decrypted.  And I do remain uncomfortable with the autonomous key management offered by many of these systems, including iMessage.  But that's also splitting hairs and really doesn't matter either.  If I really cared to have a private conversation, I would never use a smartphone at all.



LEO:  Yeah, I think that's fair.  You said it before.  Take off your clothes.  Go in the middle of a field.  



STEVE:  Yes.  And then get taken away and locked up in the loony bin.



LEO:  But a secure nut, and that's what's important.  



STEVE:  Yes.  Yes.  Yeah, exactly.  You meet with somebody you trust, leave all your electronic devices in your cars, go into the middle of a field with a big thick comforter, throw the comforter over you...



LEO:  Hide your mouth because there's lip readers.



STEVE:  Yes, exactly.  Throw the comforter over you and then whisper to each other.  Any use of technology today, and your privacy is just a hope.  It's just a, well, no one's probably listening.  And you're probably right.  Any of this is secure.  Like when Rasmus and I were using Signal back and forth, well, it was cool.  It's got industrial grade triple scoop encryption.  But I'm just wanting to say, okay, which link was that?  You know?



LEO:  Yeah, there's a lot of privacy theater, I guess, in the world.



STEVE:  It really feels like much to do about nothing.  And if you're a WhatsApp user and also a Facebook user, you've already - you're being tracked up the you know what.  So who cares if your messaging app joins the community?



LEO:  It's January, and it's time for the TWiT audience survey, the annual survey.  Helps us understand our audience so we can make your listening experience even better.  Completely anonymous, and it only takes a few minutes.  So go to TWiT.tv/survey21 to take it.  And thanks in advance.



That's Steve Gibson.  And he's a ray of truth in a cloudy world.  If you like this show, you can listen to it when we do it every Tuesday.  You can actually listen live.  We kind of keep a livestream going for all of our shows so you can watch it behind the scenes.  We do the show Tuesday, 1:30 - shoot for, anyway, 1:30 Pacific.  That's 4:30 Eastern.  It's 21:30 UTC.  The live audio and video streams are at TWiT.tv/live.  If you're watching live, the chat room's live also, and it's a good place to go hang out with other people watching the show:  irc.twit.tv.



We have on-demand versions of the show.  Actually Steve's got the most interesting variants.  He has a low-bandwidth 16Kb version, which doesn't sound great, but at least it's small.  He also, speaking of small files, probably the smallest file is the text file of the transcript written by Steve's commission by Elaine Farris, who does a wonderful job.  So you can read along as you listen or just read.  It's very useful for searching, too, because you can search the transcripts and find the point of the show that you want to listen to.  That's all at GRC.com, Steve's website.  He also has 64Kb audio there:  GRC.com.



While you're there, pick up a copy of SpinRite.  If you get 6.0 now, you'll get 6.1 the minute it comes out for free.  You'll also get to participate in development and the beta testing process.  SpinRite, of course, the world's best hard drive maintenance and recovery utility.  Lots of free stuff at Steve's site, too.  It's a fun rabbit hole to fall down into and browse around.



We have audio and video at our website, TWiT.tv/sn.  All the shows are at TWiT.tv, but this show is TWiT.tv/sn for Security Now!.  You can also, if you listen on your schedule, asynchronously, chat with us at our TWiT forums, that's www.twit.community.  We have a Mastodon instance, if you want to join the Fediverse, that's twit.social.  You're welcome to join there.  We'd love having you.  And of course you can always get a copy of the show from YouTube, there's a YouTube channel, or subscribe in your favorite podcast client.  You'll get it automatically the minute it's available.  I will see you next Tuesday, I guess, Steve.  Have a great week.



STEVE:  Yay.  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#803

DATE:		January 26, 2021

TITLE:		Comparative Smartphone Security

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-803.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at the updates in release 88 of both Chrome and Edge with their evolving password manager features.  We also look at two recent headshaking consequences of the hard end of life for Adobe's Flash.  Ransomware gangs have added another new incentive for payment, and additional details continue emerging about last year's SolarWinds attacks.  We have newly disclosed discoveries from a Google Project Zero researcher, and I spend a bit of time wondering out loud how we're ever going to change the low priority that's currently being given to serious security problems that don't directly inconvenience end users.  And we finish by examining a very useful analysis of the comparative security of iOS and Android recently published by Johns Hopkins' Matthew Green and team.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We answer some important questions.  Should you use your browser's password manager?  Should the South African Revenue Service have used Flash?  We'll talk about the SolarWinds hack.  And then, finally, Matthew Green's head to head between Android and iOS. 	Which is the most secure?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 803, recorded Tuesday, January 26th, 2021:  Comparative Smartphone Security.



It's time for Security Now!.  Lo and behold, here he is, the man of the hour.  He appears magically every Tuesday over my left shoulder, Mr. Steve Gibson.  Hello, Steve.



STEVE GIBSON:  It's just like magic, Leo.



LEO:  Just like that.



STEVE:  It's just, you know, and I have somehow this 20-page PDF all just like popped into existence.



LEO:  I'm sure you'd love that to be a little more magical.  You do so much work on this show, and I don't think I say it enough.  I'm very grateful because this is an amazing feat you pull out.  I mean, this is longer than writing a column for InfoWorld, for sure; right?



STEVE:  It's way more than that.  I know that our listeners appreciate it.  I get a lot of feedback from you and from them.  And I don't know how to do less.  I just, you know, stuff is happening, and I want to talk about it.  In fact, I got a little...



LEO:  We're going to put that on your tombstone:  "He didn't know how to do less."	



STEVE:  I didn't know how to do less, yeah.



LEO:  That's great.  I love it.



STEVE:  So this week we're going to look at the updates in releases 88 of both Chrome and Edge with their evolving password manager features.  And, you know, it was inevitable that browsers were going to get more aggressive about being password managers.  It just sort of seems like a natural thing for them to do.  And really, in retrospect, it's weird that it's taken them so long to get there.



We're going to look at two recent headshaking consequences of the hard end of life for Adobe's Flash, which I think caught people by surprise because they probably didn't realize that Adobe had put a time bomb in the most recent Flash versions that was going to cause it to simply say no after January 11th, which it did.  Also ransomware gangs have added another new "incentive" - I should have had that in quotes - for payment.



And additional details continue emerging about last year's SolarWinds attacks.  Microsoft has done just a beautiful reverse-engineering analysis that we're going to take a look at this week.  We also have newly discovered or disclosed discoveries from yet another Google Project Zero researcher.  And then I'm going to spend a bit of time wondering out loud how we're ever going to change the low priority that's currently being given to serious security problems that don't directly inconvenience end users.  When they do inconvenience end users, they get fixed.  When they don't, we're busy.  We have other things we need to do. 



LEO:  That's really interesting.  I hadn't thought about that.



STEVE:  And this sort of follows from what this Project Zero researcher found when she looked at other chat systems.  And they're not having problems, but they're also not secure.  So anyway, I have a sort of a little bit of a walk back in history I think our listeners may find interesting and that maybe we'll be able to draw some analogies from.  And we're going to finish with a very useful analysis of the comparative security of iOS and Android, which was recently published by our friend Matthew Green from Johns Hopkins, thus the title of today's Security Now! Episode 803, "Comparative Smartphone Security."



LEO:  I think a lot of people would be interested in that.  I don't know if you've been following it.  It's a little timely because Apple just pushed out a fix to iOS and iPadOS for three what looked like zero-days.  They say they're being actively exploited today.



STEVE:  Wow.



LEO:  So this is topical.



STEVE:  And I learned about them from the MacBreak Weekly podcast and went over to my phone and said, "Update yourself."



LEO:  Now.



STEVE:  And so it's currently down, doing that.



LEO:  Yeah.  There are two WebKit vulnerabilities - WebKit's used throughout iOS - but also a kernel vulnerability.  And apparently - Apple's pretty tight-lipped as usual about what's going on with security.  They just fix it.  But apparently they're keeping - and I thought I'd ask you about this.  They're keeping the name of the person who submitted the bug secret.  And if it was Project Zero, you know, if it was Tavis, there'd be no point in keeping it secret.  I'm wondering what that signifies.  That whoever submitted the bug probably got a bug bounty, but did not want their name revealed, is interesting.



STEVE:  Huh.  Well, it's interesting too because WebKit bugs, of course, that's going to be a high exposure flaw because Safari is I'm sure WebKit-based.  And so everything you do using WebKit could be a potential entry point.  So anyway, good for them for getting onto it.



LEO:  Well, that's the good news.  But I'm very curious what Matthew Green has to say.  We'll get to that in just a little bit.  All right, Steve.  On we go.  Do you have a picture for us today?



STEVE:  We do.  We have one.  This sort of ties into what I'll be talking about later.  I titled this "The Unfortunate Reality of Perverse Incentives."  It's just a one-frame cartoon.  It shows a hackeresque kid being taken away in handcuffs by an officer, and he says:  "I broke into the website to help you."  And the kind of stuffed-shirt business executive, kind of a Mr. Billingsley guy with a cigar, he says:  "Thanks, but it's better if we don't know the site is insecure."  Which, you know, we see examples of that; right?  Like the court discovery process will acquire internal communications, emails, and learn that executives knew of a problem that they for whatever reason...



LEO:  Didn't want to know.



STEVE:  ...chose not to deal with.



LEO:  Right.



STEVE:  And they'd much rather not know than know and take no action.



LEO:  Well, and we know, I know a lot of people, including Randal Schwartz, who have gone to jail because the company did not want that pen test information and decided, oh, we're going to just prosecute you for doing that.  It happened, yeah, it happened, was it - oh, who did it happen to at The New York Times?  Yeah, you've got to - yeah, it's wrong, yeah.  That's all there is to say.  It's wrong.



STEVE:  So during this past week, both Chrome and Edge have beefed up their browsers' built-in password managers.  Chrome 88 was released a week ago on the 19th, and I think Edge was two days later, on Thursday, last Thursday.  And, you know, I still don't understand this.  But I'm using Chrome daily.  It's sort of my - I always have a Firefox instance up sort of statically.  But I'll just fire up Chrome to check something real quickly.  Even so, it wasn't until I went to About Chrome a week later that it was induced to move itself from 87 to 88.  So again, I don't get it.  So for what it's worth, if our listeners are interested in playing with this new stuff, you may need to go to About Chrome and give it a little kick in the butt to get itself updated.  Presumably it would happen eventually, but these updates never - I never seem to get them when they're supposed to be around.



So once that's done, one of the nice things about Chrome's password system, which it is in the process of enhancing, is its quick ease of access.  You can use the menu system to search for passwords, but the term "passwords" has multiple hits in various places, so that's less than ideal.  You can use the URL chrome://settings/passwords.  That takes you to the right place.  But the niftiest and easiest to remember way to get there is just to click on your circular logged in picture or avatar in the upper right-hand corner.  And underneath the little menu that you get is a little skeleton key, which is meant to be passwords.  It's the leftmost icon there, directly beneath your name and email address, which takes you directly there.



Google's security blog that announced this was titled "New Year, new password protections in Chrome."  Under their topic of "Easily fix weak passwords" they said:  "In Chrome 88, you can now complete a simple check to identify any weak passwords and take action easily."  That's kind of funny, too, because I thought, oh, that's interesting, I'll do that.  And it said, "You've got a weak password."  And I thought, what?  No.  And when I went to look what it was, it was something that was kind of a honeypot.  So it was one that I had left deliberately weak somewhere.  So it's like, oh, okay, good.  That's just fine.



Then also, under "Edit your passwords in one place," they explained that, thanks to Chrome 88, this update:  "Chrome can already prompt you to update your saved passwords when you log into websites.  However, you may want to update multiple usernames and passwords easily, in one convenient place.  Starting with Chrome 88, you can manage all your passwords faster and easier in Chrome Settings on desktop and iOS."  Then they said that "Chrome's Android app will be getting this feature soon, too."  So not quite ready for Android.



And then they wrap up by saying:  "The new features with Chrome 88 will be rolled out over the coming weeks, so take advantage of the new updates to keep your passwords secure.  Stay tuned for more great password features throughout 2021."  And it's unclear to me what they're saying is coming because it looks to me like it's all there right now.



LEO:  Yeah.  For years we said don't use the browser password vault.  For a long time Chrome kept it in cleartext, which was kind of problematic.  You think it's safe now to do that?



STEVE:  The problem I still have is that it's, to use the term we typically use relative to Apple, it's a walled garden.  I mean, for me, as I mentioned, I have Firefox, and I have Chrome.  And so of course I have my chosen password manager is in both.  And so I get cross-make, cross-browser-make synchronization, and also the ability to run, like to have the password vault which is separate from that, that I'm able to browse.  So for me, a password manager is still a worthwhile extra.



But certainly for - I can certainly see a lot of users who just want it, you know, they're just like Chrome people, or they're just Firefox people or whatever.  So to help them do a better job, to make using unique complex passwords easier, I guess I would say that, even though there's still a vulnerability, for example, when you're logged into Chrome, you can go to that passwords page and say, show me my passwords.  And it does.  So in a shared computer environment you want to be very careful to be logging out of Chrome because if anybody is able to get to your Chrome browser, and your smiling face is up there in the upper right-hand corner, there's nothing to protect your passwords from being viewed.



So the local compromise is still present, and they don't really seem to have fixed that because it would cause trouble.  But the big problem, as we know, that everybody has is that, because password management is a hassle, people are still, even today, not using long, complex, and unique passwords.  So that's the exposure is out on the Internet is where the real problem seems to be, more than on the local side.  So all things being equal, yeah, I would argue, compared to not using a browser's password manager, I mean, first choice, use a third-party password manager because then you're portable.



The other problem is, if all your stuff is in Chrome, you really can't use any other browser if you wanted to.  That other browser doesn't have all your stuff.  So there is some lock-in associated with using a single browser's system.  And of course they're all doing cloud sync now, so at least you're able to be multisystem, even if you're mono browser.



Edge also did an update, that is, Microsoft's Stable Channel, also version 88.  They've added a password generator.  They said:  "Microsoft Edge offers a built-in strong password generator that you can use when signing up for a new account or when changing an existing password."  They said:  "Just look for the browser-suggested password dropdown in the password field; and, when selected, it will automatically save to the browser and sync across devices for easy future use."



And it's funny, we talked last week about how Google had found out that the other Chromium users were using features that were meant to be Google Chrome browser-specific.  And I was wondering, since they've been focusing a lot of their attention on Chrome 88, if that wasn't what caused them to say, hey, wait, wait a minute.  There's, like, people we're not authorizing are using our API.  So they may have stumbled on it for that reason.



Anyway, so both Edge and Chrome are clearly working to beef up their password managers.  And again, I kind of wonder what took them so long.  I've been using LastPass, what, more than a decade.  Didn't we decide it was, like, a long time ago?



LEO:  Yeah, yeah, long time, yeah.



STEVE:  Yeah.  And then the browsers, which is like it's a natural place for a password manager to live, I guess for the user who's not going to install a third-party client.  When you're using Chrome, as most people in the world are, and it says, you know, you're being prompted to create an account, and it pops up and says, how about using this, and don't worry, I'll save it for you, who's not going to say yes?



LEO:  I always turn that off because it's annoying.  No, I understand.



STEVE:  Oh, Leo.  It's really annoying.



LEO:  Apple does the same thing with Safari.  It's a little different because it's - and again, it's not cross-platform.  But if you live in the Apple ecosystem, it's everywhere you use it, on iOS, iPadOS, and macOS.  So that's a little different.  My real question - and I know Apple is doing it right.  They're very secure.  My real question is can I trust Firefox and Chrome's in-browser password storage?  Is it secure enough, if I wanted to use it?  I agree with you about the cross-platform issues.



STEVE:  Remember our standard lesson, which is, if the browser knows the password without asking you for anything, which is required for convenience, that means that it's there, and it's decrypted.  It's available.  It's very much like our original example of this principle was the DVD and DVD encryption.  It's like, well, if the DVD player is able to show you a movie, and you're not just seeing random static on the screen, then it's got the keys, and it's using them.  So it's sort of inherently the case that there is some risk.  But notice that's also the case with LastPass.  Anything which is able to fill passwords in for you without every single time challenging you about your own identity, that says that that is available.



And in fact that was one of the things that I did in SQRL, of course, was I did this kind of a tradeoff.  You would have to identify yourself with your full SQRL password once per session, meaning like when you turn the computer on, or when you come back from unblanking it, or you haven't used it for some length of time, and all of those things you were able to control.  After you did that, it reencrypted the secret that it had been able to decrypt only when you gave it your full password.  It reencrypted it with the first "n" characters.



So the requirement was every time you authenticate, you are being prompted; but it was only, for example, by default the first four characters of your password.  And you could just go bing bing bing bing on the keyboard.  And since the number of characters was not a secret, there was no reason to require the user even to hit Enter.  So it was just bing, bing, bing, bing.



LEO:  That's as bad as you can get, yeah.



STEVE:  But here was the catch.  If you mistyped any of those four, it then washed that secret, that reencrypted secret out of RAM immediately so that you were then required to enter your full password.  So it was sort of a nice interactive tradeoff that didn't inconvenience the user, but still resulted in dramatically more security than we typically have now, where I'm not ever being harassed by LastPass or Safari, for example.  I do like the LastPass integration in iOS now because now I'm able to have LastPass provide the passwords to Safari instead of storing them in yet one more place.



LEO:  Right.



STEVE:  And I guess that would be a useful note for security is not to spread this stuff around too much because the more you do, the more opportunities there are for a mistake.



LEO:  Yeah.  It's got to be hard to design these things.  You've got to think of every possible avenue for exfiltration and so forth.  Somebody's in the chatroom saying that Edge doesn't actually know the password in the clear.  They use hashes.  And I imagine that would be the kind of best practice is not have a cleartext copy of the password, but just a hash, and you could compare hashes; right?



STEVE:  That can't be true because it has to provide the in-the-clear password...



LEO:  Oh, it has to fill it in, of course.



STEVE:  ...to the website.



LEO:  That's right, yeah, yeah.  Interesting.



STEVE:  Yeah.  What that person is confusing with is the other feature which they're now beginning to add, is the "Have any of your passwords appeared in known breaches."



LEO:  Right, right.



STEVE:  And so that's where...



LEO:  He did hashes with a [crosstalk] component, yeah.



STEVE:  Yes, yes, yeah.  And so you're able to do that with a hash.  But you have to have the password in the clear.



LEO:  But you're right, they have to fill in the password, yeah, yeah.



STEVE:  Yup.



LEO:  That's a good point.  I didn't think about that.



STEVE:  Okay.  So get a load of this.  We know that Flash has been end of life.  In a wonderful news report whose headline was "Adobe Flash Shutdown Halts Chinese Railroad for Over 16 Hours Before a Pirated Copy Restores Ops."  The subhead:  "This is what happens when you run a railroad network on Flash."  This appeared in TheDrive.com, which is a website - actually I've been there before.  I don't remember what occasion I had.  But it describes itself as the "one-stop shop for all things automotive."



The author of the story, who clearly knows a bit of tech, he explains what happened.  He said:  "Supportive of everything from browser games to live streaming, Adobe Flash was the Internet's favorite multimedia platform with reason.  Even in its heyday, though, Flash wasn't universally loved; it had security holes, could be tough to optimize, and wouldn't play ball with all browsers, especially those on mobile devices."



He says:  "When HTML5 hit the scene, Flash began to fall out of favor; and in July 2017, Adobe announced it would cease support at the end of 2020, giving users three and half years to switch to new software."  He says:  "This message, however, didn't reach all corners of the IT globe.  And when Flash's 'time bomb' code went off on January 12th, it did more than just make nostalgic browser games harder to revisit.  It brought an entire Chinese railroad to a standstill.



"According to a report in Apple Daily, the problem reared its head for China Railway Shenyang in Dalian, Liaoning just after 8:00 a.m. on Tuesday, January 12th.  Per an event timeline outlined by GitHub, the head of a switching station reported being unable to access the railroad's timetables, which they normally did through a browser-based Flash interface.  Over the next half hour, reports of similar failures poured in from across the network, with as many as 30 stations implicated, according to a CR Shenyang statement reported by a Chinese blog."



Anyway, they said:  "Only after technicians went online to research bug fixes did they learn of the global Flash shutdown, news of which seemingly didn't penetrate the insular Chinese Internet.  A translation of the GitHub timeline suggests restoring software backups temporarily restored service around noon, though outages returned again at around 2:00 p.m." - yeah, when updates updated - "and later on in the evening.



"CR Shenyang's response team then reportedly began exploring a reversion to older software systems, its options apparently consisting of an unspecified Microsoft-based setup, or an archived, pirated version of Flash without the 'time bomb' code.  Technicians settled on the latter, and around 1:00 a.m. on the 13th, CR Shenyang successfully brought one of its stations fully online.  By 2:30 a.m., all but one route was back in service, and the railroad's Y2K21 nightmare was behind it."



LEO:  It can't have been easy to write a Flash program to control the entire railroad.  But I guess they hired somebody who knew his Flash.  I mean, it was a language,



STEVE:  Yes.  This problem was not unique.  Google's well-known software engineer, Ryan Sleevi, tweeted:  "South African Revenue Service decides to develop and distribute their own browser, specifically to reenable Adobe Flash."



LEO:  Oh, please.  Oh, my god.



STEVE:  The page says:  "Dear Taxpayers and Traders:  SARS" - which is the unfortunate abbreviation of South African Revenue Service.  "SARS apologizes for the inconvenience and service disruption caused by the discontinuance of the Adobe Flash Player.  We are pleased to inform you that an alternate SARS Browser solution has been implemented which affords you the ability to complete and submit the Flash-based forms not migrated to HTML5" - and of course none of the poor African taxpayers know what any of this means - "in the interim, while we complete the migration.



"The SARS Browser enables access to ALL [in caps] eFiling forms, including those that require Adobe Flash, thus maintaining compliance with your filing obligations.  Please note that existing browsers such as Chrome and Edge will continue to work for all forms already migrated with the major and high-volume ones being Income Tax - PIT, Provisional Tax, CIT, and Trusts - Value Added Tax, Pay as You Earn, and Excise.  You are please requested to use the SARS browser should access to the forms not yet migrated be required, which include" - and then they've got form designation Registration, Amendments, and Verification Form; Transfer Duty; Financial Certificate Information; Financial Declaration; Tax Compliance Status Request; Dividends Tax Transactions Information; and Withholding Tax on Interest.



"Please note that the SARS browser will require software to be installed on your PC and is currently compatible with Windows devices only.  This SARS browser deploys as a separate application and can only be used to access the SARS eFiling website and SARS Corporate website.  It cannot be used as a browser for general Internet browsing."



So basically they apparently gave priority, as they should, to the most important forms, which they are scurrying, or scurried, to move off of Flash when this caught them by surprise.  And some of them are now supported under HTML5.  But this balance of forms are still dependent upon Flash, which no longer works.  So their solution has been to create their own browser to host  some old version of Flash.  There actually is a thread on GitHub about how to patch a current version of Flash to remove the time  bomb, so that exists and has been done.  Of course you can't use any of our current browsers because they're all no longer willing to host Flash, period.  So you've got to go to wherever they got, I mean, we realize that their own browser, what is it?  Is it some earlier version of something?  Did they take something open source and cobble it together?  Who knows.  But, boy.



LEO:  I doubt they wrote it from scratch.



STEVE:  No, you can't.



LEO:  I mean, if they're stupid enough to use Flash for their tax forms, they're clearly not smart enough to write a browser.



STEVE:  No, no.  And so you can imagine that, I suppose...



LEO:  [Crosstalk] more effort to do that than it would have been to just take those forms...



STEVE:  Yes.



LEO:  Oh, so stupid.



STEVE:  Yes.  And I suppose that not even JavaScript was ready for primetime way back when Flash was offering a powerful client-side scripting environment.  So if back then one wanted to be performing on-the-fly form content validation before submission, you know, with like dropdown lists that would then change things that the form showed, which checkboxes were enabled and so forth.  You know, the things we do now with JavaScript, then maybe 20 years ago Flash would have been the best solution.  



LEO:  Oh, yeah.  I wouldn't fault them for choosing Flash in the beginning.



STEVE:  Right.



LEO:  Just for using it still.



STEVE:  For three and a half years the world has known it's ending.  And I guess clearly it must have been the fact that they didn't know there was a time bomb, that it would actually stop working on January 12th, when it was like, oh, crap.



LEO:  It is unbelievable.



STEVE:  So now that the threat of an expensive ransomware attack is quite real, investments have been made in the ability to restore from backups; right?  That was the, you know, the news of ransomware has spread like wildfire through corporate America.  There is a high danger that you're going to get hit with this because it seems unstoppable.  So if you don't want to pay an increasingly large, it seems, demand, then tell your IT department, okay, we know that you've been telling us for the last 10 years that we need to give you more money so that you can do better backups.  Okay.  We're giving you that budget now because ransomware.



So obviously, today, more than just a few years ago, when a company suffers a ransomware attack, many more are as a consequence able to restore from backups and thus avoid the need to contact the attackers.  The first response to this lack of need to pay the ransom was, as we know, to exfiltrate files before their encryption and then release a few as proof of possession, and threaten to release many more if a ransom was not paid.



But if the offer to decrypt encrypted files and an agreement to never leak and to destroy sensitive and perhaps personal information are both insufficient to bring a company and its C-Suite executives to heel, how about subjecting the organization to a prolonged DDoS attack?  That's the latest attack strategy being added to post-ransomware attacks:  blast them off the Internet until they agree to cooperate and pay.  This new trend was first seen last October.  It was being employed at the time by the SunCrypt and the Ragnar Locker gangs after their attacks.



But now a third player, the Avaddon ransomware gang, has also begun using DDoS attacks to take down a victim's site and network until they contact them and begin negotiating.  Brett Callow, who is the threat analyst for Emsisoft, said:  "It's not at all surprising to see threat actors combining ransomware and DDoS attacks.  DDoS is cheap, easy, and in some cases may help convince some companies that speedy payment is the least painful option.  The more pressure the criminals can put companies under, the better their chances of extracting payment."



So add that to the list of things that happens to you.  Although it's kind of weird because of course a DDoS attack is entirely orthogonal to a ransomware attack.  I mean, anybody could be contacted and be held at ransom for DDoS.  It's like, you know, pay us some bitcoin or we're going to blast you.  That doesn't seem to be happening.  It's only when the company's only suffering a ransomware encryption and exfiltration of their data, and I guess they're just being pounded into submission at this point.



SolarWinds attack details continue to emerge.  As we know, digital attack forensics takes time.  And most of it requires very careful reverse engineering of code which has been carefully designed to thwart exactly that kind of analysis.  So it's not just like random script kiddy code that's Python source, where you just look at it and go, oh, this is what it does.  Especially in the case of the SolarWinds threat actors, we know, and we're going to know a lot more in a minute, about how incredibly good they were at their craft.  So they designed their stuff to make it very difficult to figure out what it was doing.



So we would expect to be learning more about this largest known attack in history over time.  And indeed, last Wednesday the 20th, in a joint posting by the Microsoft 365 Defender Research Team; their Threat Intelligence Center, that's the MSTIC that we often talk about; and the Microsoft Cyber Defense Operations Center, that's a new one, the CDOC, we learned a great deal more.  For what it's worth, it's only more worrisome.



Microsoft's joint disclosure was titled:  "Deep dive into the Solorigate second-stage activation, from Sunburst to Teardrop to Raindrop."  Microsoft begins their quite lengthy disclosure with a summary of what everyone knows, but quickly adds some new detail, which is interesting.  They said:  "More than a month into the discovery of Solorigate, investigations continue to unearth new details that prove it is one of the most sophisticated and protracted intrusion attacks of the decade.  Our continued analysis of threat data shows that the attackers behind Solorigate are skilled campaign operators who carefully planned and executed the attack, remaining elusive while maintaining persistence.  These attackers appear to be knowledgeable about operations security and performing malicious activity with minimal footprint.



"In this blog, we'll share new information to help better understand how the attack transpired.  Our goal is to continue empowering the Defender community by helping to increase their ability to hunt for the earliest artifacts of compromise and protect their networks from this threat."  They said:  "We have published our in-depth analysis of the Solorigate backdoor malware - also referred to as Sunburst by FireEye - the compromised DLL that was deployed on networks as part of SolarWinds products, that allowed attackers to gain backdoor access to affected devices.  We have also detailed the hands-on-keyboard techniques that attackers employed on compromised endpoints using a powerful second-stage payload, one of several custom Cobalt Strike loaders, including the loader dubbed Teardrop by FireEye and a variant named Raindrop by Symantec.



"One missing link in the complex Solorigate attack chain is the handover from the Solorigate DLL backdoor to the Cobalt Strike Loader.  Our investigations show that the attackers went out of their way to ensure that these two components are separated as much as possible to evade detection.  This blog provides details about this handover based on a limited number of cases where this process has been observed to occur.  To uncover these cases, we used the powerful cross-domain optics of Microsoft 365 Defender to gain visibility across the entire attack chain in one complete and consolidated view.  We'll also share our deep dive into additional hands-on-keyboard techniques that the attackers used during initial reconnaissance data collection and exfiltration, which complement the broader TTPs from similar investigative blogs such as those from FireEye and Volexity."



And so I'm going to skip over a lot of that nitty-gritty because it's interesting, for anyone who's interested, and I've got the link in the show notes.  But here's the cool bit that is understandable.  They said:  "An attack timeline that SolarWinds disclosed in a recent blog showed that a fully functional Solorigate DLL backdoor was compiled at the end of February 2020" - okay, so early in 2020, last year - "and distributed to systems sometime in late March.  The same blog also said that the attackers" - and this I did not know - "removed the Solorigate backdoor code from SolarWinds' build environment in June of 2020."



They said:  "Considering this timeline and the fact that the Solorigate backdoor was designed to stay dormant for at least two weeks, we approximate that the attackers spent a month or so in selecting victims and preparing unique Cobalt Strike implants as well as command-and-control infrastructure.  This approximation means that real hands-on-keyboard activity most likely started as early as May.  The removal of the backdoor generation function and the compromised code from SolarWinds binaries in June could indicate that by this time the attackers had reached a sufficient number of interesting targets, and their objectives shifted from deployment and activation of the backdoor, so-called 'Stage 1,' to being operational on selected victim networks, continuing the attack with hands-on-keyboard activity using the Cobalt Strike implants."



So as I said again, that was news to me.  I assumed that the SolarWinds build and update delivery system had remained infected, but that's not the case.  As Microsoft observed, it didn't need to keep offering infected DLLs once all of the major targets had already updated and received the infection.  Essentially, they'd already gotten out over the course of, what, six months?  Well, March, April, May, June.  So maybe four months.  And then again, in observing the highest level of care, they removed the source of the infection so that the SolarWinds DLL would then be clean, and further updates would remove it from the systems that had previously received it and had already moved from Stage 1 into Stage 2.  So an act of deliberately eliminating the tracks of how this all happened.



So one of the coolest things Microsoft found was the way the original SolarWinds infection created this arm's length execution path in such a way that the original infection stood a maximum chance of remaining undetected, even if its downstream consequences were detected.  Remember that the moment that it was discovered that a signed SolarWinds DLL was the root source of the infection, that would have brought down the entire operation.  And as we know, that is what eventually happened at FireEye.  But the obfuscation was successful for a very long time.



So here's how Microsoft explains what they found.  They said:  "We spent countless hours investigating Microsoft Defender telemetry and other signals from potential patient-zero machines running the backdoored version of SolarWinds DLL.  Most of these machines communicated with the initial randomly generated DNS domain" - remember that it was blah blah blah dot avsvmcloud.com, they said - "but without significant activity.  However, we saw limited cases in May and June where the initial DNS network communication was closely followed by network activity on port 443 (HTTPS) to other legitimate-looking domains.  On these handful of machines, we performed deep inspection of telemetry.



"We know that the Solorigate backdoor only activates for certain victim profiles.  And when this happens, the executing process, usually SolarWinds.BusinessLayerHost.exe, creates two files on the victim disk:  a VBScript, typically named after existing services or folders to blend into legitimate activities on the machine; and a second-stage DLL implant, which is a custom Cobalt Strike loader, typically compiled uniquely per machine and written into a legitimate-looking subfolder underneath C:\Windows."



And so in other words, on a per-infection target, they created a VBScript that was uniquely named to fit into what was going on on that particular machine and custom-wrote and compiled a unique, they called it the Cobalt Strike Loader, again for that machine.  So one of the things this did was it meant you could not compare infected systems.  You wouldn't find any obvious indications of compromise that were the same because they were essentially doing per-target customization.



Microsoft said:  "At this point the attackers are ready to activate the Cobalt Strike implant.  However, the attackers apparently deem the powerful SolarWinds backdoor too valuable to lose in case of discovery, so they tried to separate the Cobalt Strike Loader's execution from the SolarWinds process as much as possible.  Their hope is that, even if they lose the Cobalt Strike implant due to discovery and detection, the compromised SolarWinds binary and the supply chain attack that preceded it will not be exposed.



"The attackers achieved this by having the SolarWinds process create an Image File Execution Options (IFEO) Debugger registry value for the process dllhost.exe."  And I'll just insert an aside here.  This is a known and official way of causing Windows to attach a debugger to a process at startup.  If you want to put a given Windows process under debugging, sometimes it's not enough to attach the debugger after the process is already initialized.  Like there may be initialization code that is where the problem is.  So you need Windows to start the debugging like from the moment the process goes into RAM.  The way you do that is by using one of this Image File Execution Options Debugger registry values which causes Windows to automatically load something into that process, a space.



This of course can also be used for malicious purposes.  So the SolarWinds process first created one of these entries for the dllhost.exe.  That execution process triggers a launch of wscript.exe which is configured to run that VBScript file which has been dropped earlier and had been waiting.  The VBScript in turn runs the rundll.exe, which activates the Cobalt Strike DLL using a clean parent/child process tree which is completely disconnected from the SolarWinds process.



So essentially, by using this sanctioned Windows hook in the registry to cause the DLL host to invoke wscript.exe, there was a complete separation of these two events.  Meaning that anybody who did discover the Cobalt Strike DLL and the way it got executed would only see that it was tied to this debugging.  Oh, and once it runs, it removes the IFEO value from the registry to also clean that up so you can't even figure out how this thing got started, if you look at it after it's running.



So anyway, their full posting, as I mentioned, is super long and wonderfully detailed, for anyone wanting to really get down into the nitty-gritty.  But in the section "Additional attacker tactics, anti-forensic behavior, and operational security," Microsoft nicely summarizes some more detail to give us a more complete sense for the frightening skill and tradecraft that the designers of this attack deployed.



They said:  "As mentioned, the attackers behind Solorigate are skillful and methodic operators who follow operations security best practices to minimize traces, stay under the radar, and avoid detection.  During our in-depth analysis of the attacker's tactics, techniques, and procedures (TTPs) seen through the lens of Microsoft 365 Defender's telemetry, we observed a few techniques that are worth disclosing to help other defenders better respond to this incident and use hunting tools like Microsoft 365 Defender advanced hunting or Azure Sentinel queries to search for potential traces of past activity.



"Some examples of why these attackers stand out for their operational OPSEC methodology and anti-forensic behavior are listed below."  And they have six, or five.  First:  "Methodic avoidance of shared indicators for each compromised host.  As discussed in the previous section, each Cobalt Strike DLL implant was prepared to be unique per machine and avoided at any cost overlap and reuse of folder name, file name, export function names - those are internal to the DLL - command-and-control domain and IP, HTTP requests, timestamp, file metadata, config, and child processes launched."



They said:  "This extreme level of variance was also applied to non-executable entities, such as WMI persistence filter name, WMI filter query, passwords used for 7-zip archives, and names of output log files."  I mean, so what we're looking at is an absolute lack of laziness.  I mean, true discipline for every single entity that they infected.  They said:  "Applying this level of permutations for each individual compromised machine is an incredible effort normally not seen with other adversaries and done to prevent full identification of all compromised assets inside a network or effective sharing of threat intel between victims."



Second:  "Camouflage and blending into the environment.  Tools and binaries used by the attackers, for example ADFIND" - Active Directory Find - "legit tool were always renamed and placed in folders that mimicked existing programs and files already present on a machine.  This blending was not just used for files, but for other elements.  For example, WMI persistence filters were created with names and queries matching other scripts present in affected organizations."  This is just stunning.



Third:  "Before running intensive and continued hands-on-keyboard activity, the attackers took care of disabling event logging using AUDITPOL (audit policy) and re-enabling it afterward.  In a similar way, before running noisy network enumeration activities such as repeated NSLOOKUP and LDAP queries, the attackers carefully prepared special firewall rules to minimize outgoing packets for certain protocols.  The firewall rules were also methodically removed after the network reconnaissance was completed."  I hope this is terrifying everybody.  This is just - it's terrifying me.



"Lateral movement activities were never executed without preparation.  To increase the likelihood that their activities remain undetected, the attackers first enumerated remote processes and services running on the target host and decided to move laterally only after disabling certain security services."  And finally they said:  "We believe that the attackers used timestomping to change timestamps of artifacts and also leveraged professional wiping procedures and tools to complicate finding and recovering of DLL implants from affected environments."



LEO:  I like "timestomping."  I'm going to keep that in my back pocket there.



STEVE:  Timestomping, yes.  Stepping back to take stock in all that we have learned, any sane Infosec technologist would be right to be seriously worried.  My feeling is that as damaging as these attacks were individually and on their own, its almost more worrisome outcome for the attackers is for us to have obtained this much greater appreciation for their skill and their dedication to detail.  I mean, it has without question  sobered up and heightened the level of attention that the Defender industry now realizes it needs to deploy.



And remember, none of us should forget for a moment that were it not for the fact that they targeted FireEye, and that their presence eventually tripped some monitoring alarms that the attackers were unaware of - because as we've just seen, if they knew about it, they would have either aborted or they would have disabled those monitoring alarms.  Something tripped them up.  If that had not happened, this would all still be ongoing right now.



LEO:  Wow.



STEVE:  And Leo, on that happy note, let's take our second break.



LEO:  And it's funny because there's not a lot of reporting anymore on this.  It's kind of taken the back seat because I think...



STEVE:  Old news.



LEO:  Well, but also I think part of the problem is it doesn't feel like there's much we can do about it.  It's like, yeah, they're in there.  What do you want to do about it?  You know?  It's like the deed is done.



STEVE:  Yeah.  The good news is, I think, that this level, I mean, so for Microsoft to post this...



LEO:  I'm glad they're paying attention, yeah.



STEVE:  Yes.  Any companies, for example, who thought, oh, you know, we're busy.  I mean, yeah, who isn't?  We don't have enough money.  Yeah, who does?  We don't want to, like, deeply invest in internal network monitoring surveillance.  Well, think about that again, folks.



LEO:  Yeah.



STEVE:  You know, reconsider the cost of not doing that.  You need an intrusion detection system that can spot something that is doing this, and you need to hide it.  That's the other thing we've learned.  The fact that it's possible for the bad guys to see machines and then remotely enumerate their running processes, you know, a lot has been learned.  I think that's key.  I agree, Leo, that on the general public level, it's like, oh, well.  Maybe the Russians hacked us.  What's for lunch?



LEO:  Yeah.  I hope we're doing the same back to them.



STEVE:  On our internal level, you know, this has to have really sobered up the defense industry.



LEO:  And it should, yeah.



STEVE:  Yes.



LEO:  And I have to say, and probably somewhat due to this, I notice Biden has been starting to appoint people to cybersecurity roles, and really beefing up cybersecurity, and picking some, I think, some good people, knowledgeable people, not just figureheads, to do it.  So I think that's the other side of it is that you're going to see, I hope you're going to see the U.S. government be very proactive about this.  They've got to be.



STEVE:  Yeah, appointing people who are anti-cybersecurity to run cybersecurity, that's...



LEO:  Yeah, that's not a good idea.  It's less of a good idea.



STEVE:  Nah, that's not a good idea.



LEO:  Yeah.  On we go with Steve Gibson and more security news.



STEVE:  So it turns out that Malwarebytes was also attacked.



LEO:  Oh, I saw that, yeah.



STEVE:  Yeah.  Last Tuesday Malwarebytes posted a notice with the headline:  "Malwarebytes targeted by nation-state actor implicated in SolarWinds breach."



LEO:  Yikes.



STEVE:  And they said:  "Evidence suggests abuse of privileged access to Microsoft Office 365 and Azure environments."  And I wanted to share their short summary posting because it's impressive.  It contains additional important details and also helps to highlight the nature and need for a true security community.  This is what we're going to have to be doing moving forward.  So they wrote:  "A nation-state attack leveraging software from SolarWinds has caused a ripple effect throughout the security industry, impacting multiple organizations.  We first reported on the event in our December 14th blog and notified our business customers using SolarWinds, asking them to take precautionary measures.



"While Malwarebytes does not use SolarWinds, we, like many other companies, were recently targeted by the same threat actor.  We can confirm the existence of another intrusion vector that works by abusing applications with privileged access to Microsoft Office 365 and Azure environments.  After an extensive investigation, we determined the attacker only gained access to a limited subset of internal company emails.  We found no evidence of unauthorized access or compromise in any of our internal on-premises and production environments.  We received information from the Microsoft Security Response Center on December 15th about suspicious activity from a third-party application in our Microsoft Office 365 tenant, consistent with the tactics, techniques, and procedures (TTPs) of the same advanced threat actor involved in the SolarWinds attacks.



"We immediately activated our incident response group and engaged Microsoft's Detection and Response Team (DART).  Together, we performed an extensive investigation of both our cloud and on-premises environments for any activity related to the API calls that triggered the initial alert.  Our investigation indicates the attackers leveraged a dormant email protection product within our Office 365 tenant that allowed access to a limited subset of internal company emails.  We do not use Azure cloud services in our production environments."  And I'll just pause to take a note.  Here's another instance of why it's good to turn things off and remove things you're no longer using.  So they had a dormant email protection product  that they were no longer using, but it was still there.



LEO:  Still running, yeah.



STEVE:  And it turns out that was the way in.  Exactly.  They said:  "Considering the supply chain nature of the SolarWinds attack, and in an abundance of caution, we immediately performed a thorough investigation of all Malwarebytes source code, build, and delivery processes, including reverse engineering our own software.  Our internal systems showed no evidence of unauthorized access or compromise in any on-premises and production environments.  Our software remains safe to use.



"As the U.S. Cybersecurity and Infrastructure Security Agency (CISA) stated, the adversary did not only rely on the SolarWinds supply-chain attack, but indeed used additional means to compromise high-value targets by exploiting administrative or service credentials.  In 2019, a security researcher exposed a flaw with Azure Active Directory where one could escalate privileges by assigning credentials to applications.  In September 2019, he found that the vulnerability still existed and essentially led to backdoor access to principals' credentials into Microsoft Graph and Azure AD Graph.



"Third-party applications can be abused if an attacker with sufficient administrative privilege gains access to a tenant.  A newly released CISA report reveals how threat actors may have obtained initial access by password guessing or password spraying in addition to exploiting administrative or service credentials.  In our particular instance, the threat actor added a self-signed certificate with credentials to the service principal account.  From there, they can authenticate using the key and make API calls to request emails via MSGraph.



"For many organizations, securing Azure tenants may be a challenging task, especially when dealing with third-party applications or resellers.  CrowdStrike has released a tool to help companies identify and mitigate risks in Azure Active Directory."  And then they conclude in their topic "Coming Together as an Industry."  They said:  "While we have learned a lot of information in a relatively short period of time, there is much more yet to be discovered about this long and active campaign that has impacted so many high-profile targets.  It is imperative that security companies continue to share information that can help the greater industry in times like these, particularly with such new and complex attacks often associated with nation-state actors.



"We would like to thank the security community, particularly FireEye, CrowdStrike, and Microsoft, for sharing so many details regarding this attack.  In an already difficult year, security practitioners and incident responders responded to the call of duty and worked throughout the holiday season, including our own dedicated employees.  The security industry is full of exceptional people who are tirelessly defending others, and today it is strikingly evident just how essential our work is moving forward."



So I agree.  I think that it's clearly the free and open sharing of the details of what is found in these attacks, you know, not considering it proprietary, not holding it close, but saying, look, this is what we found.  In this instance, for example, Microsoft and FireEye being so open allowed Malwarebytes to get a much better sense for the nature of the infiltration into their own network.  So as if we didn't already have sufficient cause to be worried about the SolarWinds threat actor, and that previous Microsoft blog should just chill anybody, now we learn that this incredibly potent adversary is also not a one-trick pony.  Not only were they also mounting this other entirely different attack, they were doing so at the same time as they were carefully and delicately rooting around within the world's highest end corporate and government networks.  So, wow.  



And this next piece put me to thinking, as you'll see, because I'm going to do a little thinking out loud after I explain what was found.  And I titled this "It seems that wherever we look we find problems."  We'll all recall that critical flaw that was found in Apple's implementation of FaceTime early in 2019.  Remember, the flaw made it possible for users to initiate a FaceTime video call and eavesdrop on their callees by adding their own number as a third person in a group chat, even before the person on the other end accepted the incoming call.  Apple responded by immediately taking FaceTime's group chat feature offline until the oversight was fixed, as it was in a subsequent update.



But the interesting nature of this flaw captured the attention of a Google Project Zero researcher named Natalie Silvanovich.  She describes what made this flaw so different and interesting to her, as follows.  She wrote:  "On January 29th, 2019, a serious vulnerability was discovered in Group FaceTime which allowed an attacker to call a target and force the call to connect without user interaction from the target, allowing the attacker to listen to the target's surroundings without their knowledge or consent."



She wrote:  "The bug was remarkable in both its impact and mechanism.  The ability to force a target device to transmit audio to an attacker device without gaining code execution was an unusual and possibly unprecedented impact of a vulnerability.  Moreover, the vulnerability was a logic bug in the FaceTime calling state machine that could be exercised using only the user interface of the device.



"While this bug was soon fixed, the fact that such a serious and easy to reach vulnerability had occurred due to a logic bug in a calling state machine, an attack scenario I had never seen considered on any platform," she wrote, "made me wonder whether other state machines had similar vulnerabilities, as well.  This post describes my investigation into calling state machines for a number of messaging platforms including Signal, JioChat, Mocha, Google Duo, and Facebook Messenger."



And I have a link in the show notes for anyone who's interested.  Again, super detailed.  I'm going to skip all that, but cut to the chase here.  So in her very detailed posting, Natalie proceeds to explain how WebRTC sessions are established between a caller and a callee, and how unless particular care is taken in the interactive handshaking between the endpoints, which is managed by a state machine, a number of exploits are possible, arising from subtle mistakes made in the implementation of the governing protocol's state machines.



So again, for anyone who's interested in the details, the link is here.  So I'm only going to share what Natalie's subsequent research uncovered.  As with Apple's prepatched FaceTime, many other apps, turns out, allowed calls to be connected without interaction from the callee, while also potentially permitting the caller to force a callee device to transmit audio and video data.  And as I noted, the common root cause were logic bugs within the signaling state machines, which Natalie described as a "concerning and under-investigated attack surface of video conferencing applications."



So four things she found.  For Signal, this was fixed in September 2019, thanks to her analysis.  An audio call flaw in Signal's Android app made it possible for the caller to hear the callee's surroundings due to the fact that the app didn't check if the device receiving the connect message from the callee was the caller device.  Whoops.



Number two, both JioChat (this was fixed last summer, July of 2020), and Mocha (fixed in August of 2020).  Adding candidates to the offers created by Reliance JioChat and Viettel's Mocha Android apps that allowed a caller to force the target device to send audio and video without a user's consent.  The flaws stemmed from the fact that the peer-to-peer connection had been set up even before the callee answered the call, thus increasing the "remote attack surface of WebRTC."



Third, actually fourth if you consider that we had two last time, Facebook Messenger, which was recently just fixed in November of 2020.  A vulnerability that could have granted an attacker who's logged into the app to simultaneously initiate a call and send a specially crafted message to a target who is signed in to both the app as well as another Messenger client such as the web browser, and begin receiving audio from the callee device.



And, finally, Google Duo, fixed last December.  A race condition between disabling the video and setting up the connection that in some conditions could cause the callee to leak video packets from unanswered calls.  So I titled this piece "It seems that whenever we look we find problems" because that seems to be today's reality.  Natalie wasn't driven to examine these communication applications because of any known flaws.  She was just wondering whether anything might be wrong when she saw a  problem in FaceTime that she realized might be endemic.  And she discovered, after looking, significant logical flaws behind many other apps' use which could be leveraged for surreptitious surveillance.



The complexity of today's apps is exploding.  And the bar for what an app must do to competitively succeed keeps being raised.  Those raising the bar are throwing together huge functional blocks of code without a deep understanding which is required to consider or even be aware of the security and edge-case use implications created by these massive conglomerations.  Need real-time audio and video chat?  No problem.  Just drop in and hook up a WebRTC library.  Wave at the camera.  Can you see yourself on the other end?  Yes?  Great.  We're done.  Ship it.



And of course when one app does this, those competing with that app are forced to follow suit because reviewers never see the logic flaws that interested Natalie.  Reviews create app feature grids filled in with red and green squares showing which apps offer which features.  So anyone whose app has a glaring red box highlighting a missing feature is in a big hurry to go grab some barely understood third-party library, drop it in, hook it up, wave at the camera, and push out a new feature release.  And I'm not sure, and this is the point here, how or why this is ever going to change.  Some things do change.  I still have, and Leo you probably do, too, the CTRL-S habit.  



LEO:  Oh, yeah.



STEVE:  As I call it.



LEO:  All the time.  Constantly.



STEVE:  Yup, which was developed from the need to constantly save our work.



LEO:  Because it crashed.  Everything crashed.



STEVE:  Because back - exactly.  Back at the dawn of all this, you never knew when the app or the operating system you were using was going to freeze up, which was something that generally happened multiple times per day, without any warning.  Now, that doesn't generally happen anymore, not like it once did.  But the problem is, everything is driven by economics.  When apps and OSes crashed, and work was lost, users were unhappy.  This created an economic cost because there was an incentive to seriously consider trying a different word processor or whatever app, or even change OSes.  Consequently, apps and OSes no longer crash like they once did.



But not one of the users of these audio and video conferencing apps were ever inconvenienced by the logical flaws in their internal state machines which enabled eavesdropping on them.  They might be annoyed if the app didn't offer the turn-my-face-into-an-elf option.  So of course every app needs to offer that, or suffer the red grid cell.  So I think we're in trouble because users and reviewers do not and cannot perceive security flaws.  They only see features.  IoT devices pay no economic toll for using a TCP/IP stack that's riddled with critical flaws.  Nor for not providing any aftermarket means for updating them.  Doing so would be expensive.  But no rational product designer in China is going to invest in anything that doesn't provide an economic advantage.



So I see three possibilities.  Back in the early days of electrical household appliances, which were playing with dangerous voltages and currents, someone needed to establish a standard for things like the thickness of insulation and the presence of a grounded plug to minimize shock hazard in the event of an internal failure.  As with today's computer security, consumers were unable to evaluate the safety or lack thereof that had been designed into their toasters and their vacuum cleaners.  Consequently, there was no economic benefit associated with adding manufacturing cost to make appliances more safe.  Insulation costs money.  A grounded three-wire cord is more expensive than one with just two wires.



Things were a mess until Underwriters Laboratories with their UL Seal of Approval became a household term.  Now consumers could look for a UL Seal to assure them that some white lab-coated scientist had dropped the toaster they were considering purchasing into a tub of water to see what would happen.  And if the toaster did the right thing, it would get the seal.  And the similar-looking but less expensive toasters next to it on the same shelf, but lacking the UL Seal of Approval, would go unsold.  Since there was no way Mom was going to expose little Johnnie and Susie to any dangerous appliances, the UL Seal was soon effectively required, and all toasters had to invest in the additional manufacturing cost required to earn themselves the seal.



And of course later the famous Consumer Reports served a similar role.  Consumers who took one look under the hood of a car they were considering purchasing quickly realized that they were unable to evaluate what they saw.  Nor were they able to perform their own crash testing.  So they needed to rely upon a neutral, highly reputable, independent testing organization to help them choose.  So perhaps something like Underwriters Laboratories or Consumer Reports will emerge.



But the other inevitability I think is the heavy hand of government regulation.  Seatbelts do save lives.  Many people object to being told to buckle up.  And no auto maker wanted to put them in.  There was no obvious economic benefit for doing so, and even a liability if the belt appeared to malfunction when it was needed.  And automotive pollution standards fall under the same category.  They're good for society collectively, though expensive for automakers and consumers individually.  If given a choice, pollution standards would never have occurred voluntarily.  The government needed to force it.  Anyone who remembers what the air in Los Angeles once looked like  and yes, you were actually able to see the air in L.A. - or what Beijing looked like more recently can appreciate that sometimes government regulation against short-term economic interest is required.



SolarWinds has been a massive wakeup call to many of the world's government legislators.  But the attacks inherently targeted and affected large public and private organizations.  More than anything, it demonstrates the level of malign intent and energy that is focused against the U.S. and other international organizations.  I would not be surprised if we eventually discover that something similar has been going on with some subset of the hundreds of millions of U.S. consumer networks that are increasingly hosting IoT devices with unknown security flaws.  It may be the wakeup call we need to get serious about the security of our devices.  Because I don't know what else will do it.



I've got those $5 Govee plugs, and they work great.  But there's no way I'm fooling myself that there's anything secure about them.  It's getting a turn-on/turn-off signal from China twice a day.  And as a consequence, it is well isolated on its own network.  But I and some subset of the listeners of this podcast are probably the only people doing that today.  Maybe we're being overcautious.  But, boy, I would not want my internal home network exposed to IoT things that are reaching back to, I'm sure, well-meaning Chinese companies and their servers because there's no telling what they're able to do.



So anyway, I don't know how we fix this problem that security is not something you can perceive.  It's a feature that goes unappreciated by consumers.  And it is arguably expensive to create.  Look at all of the work that Apple and Google go into, and we'll be talking about that in a moment, to enhance the security of their platforms.  Saying that they have it is a massive selling point.  And all of the IoT devices say, oh, this or that security.  But then we learn that the networking stacks they're all based on are buggy as hell.  So it's a mess, Leo.



LEO:  Yeah.



STEVE:  I just had a note here in the show notes to comment that I am now in the last season of "The Expanse," and OMG.



LEO:  It's keeping up the quality, huh?



STEVE:  Oh, my lord.  No, actually I would say it's better.



LEO:  Better.



STEVE:  IMDB has increased the rating in the last seasons to - maybe it's 10.  It's 9.8 and 9.9, if not 10.  And I see it.  Amazon took it over for seasons 4 and 5.  There's going to be a 6.  And they had a six-season arc ready for when Amazon took it.  So that would be up through nine seasons total.  And the way it's set up - and I can't say anything without being a spoiler.  But the way the plot evolves, it could continue going, much as the first Star Trek was on a five-year mission just to go see what was out there, so plenty of time.  Unfortunately, we only got three years of that mission.  But it is open-ended.



And Leo, I just, as I'm sitting there watching it, I'm thinking, my god, this is science fiction.  This is science fiction.  We don't get science fiction.  I mean, like, "Avatar" was the last thing, or I guess Johnny Depp has done a couple things, and Tom Cruise apparently loves doing science fiction movies.  So we've had some from him.  But boy, it is just so good.



LEO:  Chris Nolan's doing some good science fiction.  I think "Interstellar" was pretty good.



STEVE:  Yes.  Long, but really good.



LEO:  "Tenet"?  I just watched "Tenet," and it was interesting.  It's more like...



STEVE:  Oh, Leo.  If your brain hasn't melted down after watching "Tenet," "Tenet" is like, oh, my god, I mean, whoa, that's literally...



LEO:  I enjoyed it.  It's kind of James Bond meets time travel sort of.  



STEVE:  Oh.  James Bond meets time travel, and Dr. Seuss does time travel.  Oh.  Oh, whoa.



LEO:  It's a time pincer movement.  Time pincer movement.



STEVE:  Oh, it is a...



LEO:  Did you not like it?  I think you walked out of it, didn't you?



STEVE:  It is a mind "eff," is what it is.  If you try to actually understand it, you will hurt yourself.



LEO:  Yes, I did.  Yeah, don't try to make any sense of it.  But it's fun.



STEVE:  Really, do not try to actually understand it.  Just sort of let it wash over you and go, okay, well, I have no idea what's happening.



LEO:  No idea.



STEVE:  But, you know, some people are walking forward, and some people are walking backward.



LEO:  Yeah.  I like that, yeah.



STEVE:  And, okay.  Oh.



LEO:  Oh, lordy.  I've started "The Expanse," and I'm looking forward to it.  I want to find some time because it's so much.  There are so many episodes now.  I want to find a chunk of time that I can watch it.



STEVE:  Well, and the warning, yes, the warning is it is complicated.  Lorrie imagines herself able to play with her iPad while watching a show at the same time.  Consequently, she said last night, "Honey, I have no idea what's going on."



LEO:  Oh, I do the same thing, yeah.



STEVE:  "I have no idea what's happening."  And it's like, "Okay, well, I could tell you."  But she doesn't have much patience for that, either.  So it's okay.



LEO:  Yeah, I know those feelings.



STEVE:  Yeah, but, I mean, the good news is, after the beginning few seasons, you kind of get - you learn the politics of the solar system.  And then it's still there, but you're not on a learning curve anymore.  You're kind of like, okay, good.  And you know who the various people are.  You still can't understand what the Belters are saying half the time, but that's okay because it's not important.  Anyway, I'll just say wow.  Amazon Prime, "The Expanse."  Anybody who is dying for some good science fiction, it is really well done.  And Leo, it's so easy to take the visuals for granted.  It's just beautiful work.



LEO:  Mm-hmm.  It is, yeah.  All right.  We would normally take a break here, but we won't because everybody's dying to hear about comparative smartphone security.



STEVE:  So, yes.  A team of security researchers at Johns Hopkins led by cryptographer, security technologist, and associate professor of computer science, our friend Matthew Green, decided to take a serious look at the comparative security offered by the Apple iOS and the Google Android smartphone platforms.  To host the results of their analysis, they grabbed the domain SecurePhones.io.  So, easy to remember:  SecurePhones.io.  And I've got three links in the show notes to that home page, the main page, and the PDF, for anyone who wants them.  So here's how they framed the intent, goals, and a very brief summary of their research because the PDF is 120 pages long, 119 pages long.



They said:  "In this work we present definitive evidence, analysis and, where needed, speculation to answer three questions:  Which concrete security measures in mobile devices meaningfully prevent unauthorized access to user data?  In what ways are modern mobile devices accessed by unauthorized parties?  And, third, how can we improve modern mobile devices to prevent unauthorized access?"



And they said:  "We divide our attention between two major platforms in mobile space, iOS and Android.  And for each we provide a thorough investigation of existing and historical security features, evidence-based discussions of known security bypass techniques, and concrete recommendations for remediation.



"In iOS we find a powerful and compelling set of security and privacy controls, backed and empowered by strong encryption, and yet a critical lack in coverage due to underutilization of these tools leading to serious privacy and security concerns.  In Android we find strong protections emerging in the very latest flagship devices, but simultaneously fragmented and inconsistent security and privacy controls, not least due to disconnects between Google and Android phone manufacturers, the deeply lagging rate of Android updates reaching devices, and various software architectural considerations.  We also find in both platforms exacerbating factors due to increased synchronization of data with cloud services."



They said:  "The markets for exploits and forensic software tools which target these platforms are alive and well.  We aggregate and analyze public records, documentation, articles, and blog postings to categorize and discuss unauthorized bypass of security features by hackers and law enforcement alike. Motivated by an increasing number of cases since Apple versus the FBI in 2016, we analyze the concrete impact of forensic tools and the privacy risks involved in unchecked seizure and search.  Then we provide in-depth analysis of the data potentially accessed via common law enforcement methodologies" - meaning subpoenas - "from both mobile devices and accompanying cloud services.



"Our fact-gathering and analysis allow us to make a number of recommendations for improving data security on these devices.  In both iOS and Android we propose concrete improvements which mitigate or entirely address many concerns we raise, and provide ideation towards resolving the remainder.  The mitigations we propose can be largely summarized as the increased coverage of sensitive data via strong encryption, but we detail various challenges and approaches towards this goal and others."



And they conclude:  "It is our hope that this work stimulates mobile device development and research toward increased security and privacy, promotes understanding as a unique reference for information, and acts as an evidence-based argument for the importance of reliable encryption to privacy, which we believe is both a human right and integral to a functioning democracy."



So as I said, the detailed analysis is 119 pages.  And for anyone who's interested in a much greater level of detail, it is a goldmine reference.  But for the podcast, here's a summary of the team's findings and conclusions for each platform.  They said:  "In Apple iOS we found a powerful and compelling set of security and privacy controls, backed and empowered by strong encryption.  However, we also found a critical lack in coverage due to underutilization of these tools."



Now, specifically, four things:  "Limited benefit of encryption for powered-on devices.  We observe that a surprising amount of sensitive data maintained by built-in applications is protected using a weak 'available after first unlock' (AFU) protection class, which does not evict decryption keys from memory when the phone is locked.  The impact is that the vast majority of sensitive user data from Apple's built-in applications can be accessed from a phone that is captured and logically exploited while it is in a powered-on, but still locked state."  So hello, Apple.



Number two:  "Weaknesses of cloud backup and services.  Use of Apple iCloud, unsurprisingly, transmits an abundance of user data to Apple's servers, in a form that can be accessed remotely by criminals who gain unauthorized access to a user's cloud account, as well as authorized law enforcement agencies with subpoena power."  And of course this has been long known.  But they're highlighting it.  "More surprisingly, we identify several counter-intuitive features of iCloud that increase the vulnerability of the system."



Third:  "Evidence of past hardware" - SEP, that's the Secure Enclave Processor - "compromise."  They said:  "iOS devices place strict limits on passcode guessing attacks through the assistance of a dedicated processor known as the Secure Enclave Processor (SEP).  We examined the public investigative record to review evidence that strongly indicates that as of 2018, passcode guessing attacks were feasible on SEP-enabled iPhones using a tool called GrayKey.  To our knowledge, this most likely indicates that a software bypass of SEP was available in the wild during this timeframe."



And finally:  "Limitations of end-to-end encrypted cloud services.  Several Apple iCloud services advertise end-to-end encryption in which only the user with knowledge of a password or passcode can access cloud-stored data.  We find that the end-to-end confidentiality of some encrypted services is undermined when used in tandem with iCloud backup service.  More critically, we observe that Apple's documentation and user settings blur the distinction between 'encrypted' such that Apple has access, and 'end-to-end encrypted' in a manner that makes it difficult to understand which data is available to Apple.  Finally, we observe a fundamental weakness in the system:  Apple can easily cause user data to be reprovisioned to a new, and possibly compromised, HSM" - Hardware Security Module, meaning an iOS device - "simply by presenting a single dialog on a user's phone.  We discuss techniques for mitigating this vulnerability."



So that's the Apple side.  They said:  "In Android" - repeating what they said in their summary - "we found strong protections emerging in the very latest flagship devices, but simultaneously fragmented and inconsistent security and privacy controls, not least due to disconnects between Google and Android phone manufacturers, the deeply lagging rate of Android updates reaching devices, and various software architectural considerations."



And now we get specific.  First:  "Limited benefit of encryption for powered-on devices.  Like Apple iOS, Google Android provides encryption for files and data stored on disk.  However, Android's encryption mechanisms provide fewer gradations of protection.  In particular, Android provides no equivalent of Apple's Complete Protection encryption class, which evicts decryption keys from memory shortly after the phone is locked.  As a consequence, Android decryption keys remain in memory at all times after first unlock, and user data is potentially vulnerable to forensic capture."



Second:  "Deprioritization of end-to-end encrypted backup.  Android incorporates an end-to-end encrypted backup service based on physical hardware devices stored on Google's datacenters.  Unfortunately, the end-to-end encrypted backup service must be opted-into by app developers and is paralleled by the opt-out Android Auto-Backup, which provides encryption keys to Google servers."



Third:  "Large attack surface.  Android is the composition of systems developed by various organizations and companies.  Because the development of these components is not centralized, cohesive integrating security for all of Android would require significant coordination, and in many cases such efforts are lacking or nonexistent."  That sort of ties in with my notion of the conglomeration of libraries that weren't authored by the people who are pulling them all together.  You just don't know what the interactions are going to be.



Fourth:  "Limited use of end-to-end encryption.  End-to-end encryption for messages in Android is only provided by default in third-party messaging applications.  Many native Android applications do not provide end-to-end encryption, the exceptions being Google Duo and, more recently, the Android Messages application."



And, finally:  "The availability of data in services."  They said:  "Android has deep integration with Google services such as Drive, Gmail, and Photos.  Android phones that utilize these services, the large majority of them, send data to Google, which stores the data under keys it controls - effectively an extension of the lack of end-to-end encryption beyond just messaging services.  These services accumulate rich sets of information on users that can be exfiltrated either by knowledgeable criminals via system compromise, or by law enforcement via subpoena power."



They conclude:  "We also found, in both iOS and Android, exacerbating factors due to increased synchronization with data and cloud services."  So anyway, that pretty much wraps this up.  They've taken a deep dive, looked comprehensively, obviously, at both platforms.  For anyone who wants a lot more detail, it is available in this 120-page PDF.  And nothing was hugely surprising.  It's mostly a confirmation of what we know and/or have assumed from previous experience with both platforms.



However, I would argue that the prevalence, the persistence of the decryption keys in a locked device is an issue.  Clearly Apple is doing it so that locked devices can show you things on the locked device screen.  It would be a user inconvenience to need to unlock your device for the thing to be alive at all.  So this is clearly a tradeoff that they've tried to make.  But it is the case that in order to provide those features on a locked device, you need to leave the keys.  If the data is decrypted after a reset and a power-on, then that is to say until the first unlock, then you have to keep those keys around, if the thing's going to do anything without needing the user to reauthenticate themselves.



And in the case of Android, we now know that everything is available in RAM for forensic analysis.  So from a consumer standpoint, the takeaway is turn the device off in order to get true protection.  Don't rely on the fact that the device is locked to protect you.  And I would argue that it's useful to have pulled all of this information together, very useful, into a single coherent and comparative report.  And while there's not very much individuals can do to address these shortcomings, other than, as I said, keep in mind turning your device off if you're in an area where you're concerned that you might lose control of it in any way.  It does give Apple and Google some issues to ponder, as hopefully this podcast does every week.



LEO:  It's interesting, though, there's no real, like, solid, "This is better than that."  "That's the one to use."  Anything like that.



STEVE:  Yeah.  I don't think they wanted to put themselves in that position.



LEO:  No, no, yeah.  It's more complicated than that, too.



STEVE:  It is.  Exactly.  It is.  And the largest problem, they make it clear, is the iCloud, the whole involvement of a cloud.  When you're going to do that, when you're going to have backup, I mean - and many people have noted, hey, I bought another phone, and I logged in, and suddenly all my stuff is here.  Well, you know, what does that mean?



LEO:  It was stored somewhere.



STEVE:  Uh-huh.



LEO:  It was somewhere.  Fascinating stuff.  Always very informative, very useful.  Thank you, Steve.  I really, really appreciate this.



We do Security Now! of a Tuesday afternoon about 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  If you want to get the freshest copy, that would be watching it live.  There's live audio and video at TWiT.tv/live.  Chat with us live if you're listening live at irc.twit.tv.  You can get it on demand, too, though.  Steve has 16Kb versions.  That's the smallest audio version.  Sounds like Thomas Edison in the early days of the wax cylinder, but it's small.  There's the advantage of that.  He also has 64Kb audio.



Maybe the smallest version is the text transcription created by an actual human being, Elaine Farris, who does such a good job.  I think people like to read along as they listen.  I know that, Steve.  But you can also use it to search for any point in any podcast.  That way you can go right to the show you want.  Now that there's 803 of them, it probably is very useful.



Steve also puts his show notes up there, which include that 20-page of notes that he just talked about, so that's also very useful.  And that has links plus the Picture of the Day.  So in fact that's like a nice little magazine.  You should make that a newsletter or something.  That's valuable stuff.  I'll leave that to you.



We have 64Kb audio and video versions - holy cow, talk about a giant file - at our website, TWiT.tv/sn for Security Now!.  There's a YouTube channel dedicated to Security Now!.  And let's see.  Oh, yeah, you can also subscribe.  It's a podcast.  That means you can get it automatically the minute it's available just by subscribing, and in future you'll get every episode.  Find your favorite podcast client.



If you do listen on your own time, we have an asynchronous - we have several asynchronous forums.  Steve has his own forums at GRC.com.  They're excellent and very active.  We have forums at www.twit.community.  We have a Mastodon instance.  We're part of the Fediverse at twit.social.  I should encourage you, if you go to Steve's site, GRC.com, you should definitely pick up a copy of SpinRite, if you don't already have one.  Currently version 6, but 6.1 is in process.  If you get 6 now...



STEVE:  In process.



LEO:  ...you will get 6.1 when it comes out; and you get to participate, too, in the development of 6.1.  It's getting closer and closer.  While you're there, check out the rest of the great stuff.  There's a whole ton of free stuff at GRC.com.  You can leave him feedback at the website, GRC.com/feedback, or on his Twitter feed.  His DMs are open, as the kids say, @SGgrc.  I never heard a kid say that ever.  But they are:  @SGgrc.



STEVE:  They now say things like "dope."  Like what the hell?



LEO:  Dope.  I don't know, that's - they don't even say "dope" anymore.  I don't even...



STEVE:  And "hundred percent."  Hundred percent.



LEO:  Hundred percent, that's a big one, yeah.



STEVE:  Hundred percent.



LEO:  Mr. Gibson, thank you so much.  Have a wonderful week.



STEVE:  Buddy, always a pleasure.



LEO:  All right.  We'll see you next time on Security Now!.



STEVE:  Right-oh.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#804

DATE:		February 2, 2021

TITLE:		NAT Slipstreaming 2.0

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-804.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine another instance of a misbehaving certificate authority losing Chrome's trust.  We cover a number of serious new vulnerabilities including an urgent update need for the just-released Gnu Privacy Guard; another supply chain attack against end users; a disastrous 10-year-old flaw in Linux's SUDO command; and, thanks to Google, some details of Apple's quietly redesigned sandboxing of iMessage in iOS 14.  I'm going to share something that I think our listeners will find quite interesting about some recent architectural decisions for SpinRite, and then we'll conclude with a look at the inevitable improvement in NAT bypassing Slipstreaming.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got lots to talk about.  Flaws in GPG you're going to want to fix right away.  Same thing with SUDO, an exploit that's been around for - Steve holds up his 10 fingers.  I counted 10 years.  Wow.  We'll also talk about BlastDoor, the new protection Apple snuck into Apple Messages.  Google found out about it, though, and told the world.  It's all coming up next.  Steve will tell you on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 804, recorded Tuesday, February 2nd, 2021:  NAT Slipstreaming 2.0.



It's time for Security Now!, the show where we cover the security news of the world and help keep you safe online with this guy right here, Mr. Steve Gibson of the Gibson Research Corporation.  Hello, Steve.



STEVE GIBSON:  Leo.  Great to be with you again for our 804th episode for 2-2-21, Groundhog Day.  And maybe it's fitting that it's Groundhog Day because the title of today's podcast is NAT Slipstreaming 2.0.



LEO:  Redux.  Okay.



STEVE:  We've talked about that.  We introduced the concept of NAT Slipstreaming in November, shortly after Samy Kamkar had figured out a way to, for a remote server, whether it was serving JavaScript or a malicious ad, anything that could run JavaScript in your browser could trick your NAT router into opening up a reverse mapping through its firewall on other ports, which had various deleterious effects.



Well, that was then.  The browser makers immediately moved to keep that from happening.  But I quote Schneier again lower in the podcast, reminding us that attacks never get weaker, they only ever get stronger.  We're back now with 2.0, a far more powerful and worrisome attack.  But we're going to wrap up with that.  We're first going to examine another instance of a misbehaving certificate authority who has finally - and after five years of misbehavior, I would say it's time to lose Chrome's trust.



LEO:  Oh, boy.



STEVE:  We're going to cover - yeah.  That's never good.  It's like, sell that stock short.



LEO:  Oh, boy.  Actually, Google's stock just went through the roof this morning, by the way.



STEVE:  Yeah, I saw, it did like a straight line.



LEO:  Yeah, yeah.  They had very good earnings, yeah.



STEVE:  We're going to cover a number of serious new vulnerabilities, including an urgent update need for the just-released Gnu Privacy Guard.  GPG has a newly induced bad problem.  We've got another supply chain attack, this time not aimed at corporations, but more at gaming end users.  We have a disastrous 10-year-old flaw in Linux's SUDO command, believe it or not.



LEO:  Yes.  I got an update to SUDO yesterday, and I thought, hmm, yeah.



STEVE:  Good.  Unfortunately, think of all the Linux systems out there that won't.



LEO:  Oh, yeah, yeah.



STEVE:  And thanks to Google we have some details of Apple's quietly redesigned sandboxing of iMessage which they implemented in iOS 14.  I'm also going to share something that I think our listeners will find quite interesting about some recent architectural decisions that I've just made in the last, well, actually it was something that was an aha moment yesterday about SpinRite.  And then we're going to conclude with a look at the inevitable improvement in NAT bypassing slipstreaming.



LEO:  Ooh.



STEVE:  So I think another interesting podcast for our listeners.



LEO:  Ooh, as always.  Okay, Steve.  Picture of the Week?



STEVE:  Well, I think this is a pretty simple one.  It was in my queue of...



LEO:  It actually made me laugh.



STEVE:  Yeah.  So we've got two guys sitting side by side, each at their own terminal.  And the guy on the left says to the guy on the right, "So why are you going onto the Dark Web?"  And we see the screen of the guy on the right that says "Dark Web," and it's a black screen that's got a skull.



LEO:  Skeleton skull.



STEVE:  Right.  And then below it says "Welcome!  And have a great day!"  Anyway, the answer to the first person's question is, "I forgot my password, so I need to go look it up."



LEO:  Yeah, they know.  That's a variant on the, oh, you lost your data?  Don't worry, the NSA has a copy.



STEVE:  Exactly.  Exactly.  So okay.  As we know, our certificate-driven web server system of trust is based upon a chain of trust, actually many chains of trust, where each chain is anchored by a signing authority's root certificate.  That root cert contains their public key, which matches their secret key used to sign the certificates which are presented by web servers when people browse to them.  So with that model, any web server presenting an unexpired identity declaration certificate that has been signed by any of the browser's trusted certificate authorities will be trusted.  And of course the signature is verified because it can be verified against the public key which the browser has in its root store.



As we know also, those of us who have been listening to this podcast for a while, several times in the past few years we've covered the interesting and often fraught news of signing authorities either deliberately abusing or inadvertently failing to properly authenticate the identities of those whose certificates they sign.  The inevitable result is that they lose the privilege of having their signatures trusted by the industry's web browsers, which effectively renders their signatures useless and therefore worthless.



And we're here again today.  Google has just announced that they intend to ban and remove support from Chrome for certificates issued by the Spanish Certificate Authority Camerfirma, C-A-M-E-R-F-I-R-M-A, Camerfirma.  That revocation of trust will go into effect once Chrome 90 hits the release channel in mid-April, so about 2.5 months from now.  And at that point Chrome will no longer trust any Camerfirma signatures.  So this of course means that none of the otherwise valid TLS certificates that have previously been signed by Camerfirma will be seen as valid by Chrome.  So all of the web servers currently serving certificates signed by Camerfirma will be invalid for all Chrome users.



And as we know, once upon a time this wasn't taken so seriously, back at the beginning of the podcast.  If that happened, you'd go, okay, fine, yeah, you know, I'll go anyway.  But no.  These days we're taking this all much more seriously.  And I don't even know if you're able to force Chrome past an invalid signature on a cert.  I should probably know that.  But anyway, so since untrusting any certificate authority's root cert instantly ends that aspect of the CA's business, and also punishes their previous customers whose signed certificates no longer function, the decision to do this is always made only after the faulting party has been warned many times, and only after it's become clear that, for whatever reason, their conduct is placing the greater Internet at risk.



So in this instance the final decision to drop trust for Camerfirma's certificates comes only after the company was given more than six weeks to finally explain a string of 26 incidents.  And frankly, I'm going to share three of those.  And those are - I would call them "compound failures" because, I mean, calling them 26 is really condensing the number.  The incidents detailed by Mozilla, sort of stored there, date back to March of 2017.  I've got a link in the show notes for anyone who's interested in more detail than I'm going to provide, but you'll be convinced here in a minute.



The two most recent problems of these 26, and again counting very generously, occurred just last month, in January, even while and subsequent to Camerfirma being notified that it was under probationary investigation the month before, in December of 2020.  The incidents paint a clear and disturbing picture of a company that has failed, and not just once, but seems determined to fail to meet industry-wide agreement on the quality of their product and the security standards they must hold in return for the privilege of issuing TLS certificates for website operators, software makers, and enterprise system administrators.



As we know, and we've talked about - because it's sort of a fascinating aspect of the whole public key infrastructure.  In a sense, traditional certificate authorities are printing money; right?  You pay them hundreds of dollars, and they make sure that you're who you say you are.  And then they press a button which spits out a signature which essentially, I mean, they are bearing some cost to run this bureaucracy and to verify your identity.  But you're paying them for some bits which, you know, they're very special bits.  It takes them to make those bits.



So, but that's the point.  It's in return for printing money, their conduct has to meet standards.  And looking over the list of Camerfirma's 26 transgressions, it appears very clear that they have failed over many years to deserve what was an initial presumption of trust that they were given by the industry's web browsers, assuming that this was a serious business that was going to take its responsibilities to heart.  But that hasn't happened.  And so that trust that was originally given is being rescinded.



Okay.  So here's just three that made sense to share.  Issue R - and I think they start at A.  Issue R was titled "Failure to disclose unconstrained sub-CA."  And this was named "DigitalSign."  Now, okay.  So remember that it's possible for a certificate authority not only to sign the end certificate for a web server, for example, but to sign a sub-certificate authority, that is, a subsidiary certificate.  And "unconstrained" means that that sub-CA certificate is not constrained against doing its own signing.  So essentially they were giving their trust to a third party and allowing them to do anything they wanted to, to sign any certificates.  And so their trust would flow down to that sub-CA.



And there are situations where like a business entity, a subsidiary - we'll talk about one in a second, another one of theirs, MULTICERT.  But this one, DigitalSign, you can do it, but part of the requirements are that you acknowledge that.  You tell the industry that this is what you've done because obviously this is a very powerful thing.  You're basically giving away the right to sign things.  So in April of 2018 Camerfirma failed to disclose an unconstrained sub-CA, despite Mozilla requiring in November of 2017 that such disclosures be complete by April 15th of 2018.  No explanation was provided by Camerfirma as to the cause of this omission, nor were effective controls provided that would prevent such Mozilla policy violations in the future.  So that's one of the three.



So here's a big compound one.  That was Issue R.  Here's T:  "Failure to disclose unconstrained sub-CA," and this one is MULTICERT.  And this has date ranges from 2018 through 2020.  And the issue reads:  "In the course of resolving Issue R" - that's the one I just mentioned - "it was further discovered in July of 2018 that Camerfirma had failed to disclose two additional sub-CA certificates" - they're just doing this whenever they want to - "operated by MULTICERT.  Mozilla policy required that such sub-CAs be disclosed within one week of creation.  Camerfirma's explanation at the time was that they failed to consider that the person responsible for disclosing into the CCADB" - the organization to which you need to disclose - "would be unavailable, and that the backup for that person would also be unavailable.  They resolved this by adding a backup to the backup, in case the backup fails.



"However, the disclosure in the CCADB turned out to be incorrect and misleading, as Camerfirma disclosed that they operated the sub-CA when in fact it was externally operated.  At the time, this was only detected because Microsoft had disclosed the CP/CPS they had for MULTICERT's root, which participated in Microsoft's root program.  Camerfirma's explanation was that the person responsible for disclosing was overloaded, and that three people would be responsible for disclosures going forward."  And this is all still T; right?  This is one.  This is considered one problem.



"In 2019, Camerfirma failed to provide correct audits for MULTICERT.  Their explanation was that they only had one person responsible for" - I think this is in someone's garage in Spain - "one person responsible for communicating with their sub-CAs, and had failed to consider that the person responsible for communicating with sub-CAs and disclosing into CCADB would be unavailable.  They stated that they intended to prevent such issues from recurring in the future by purporting to implement additional steps."



And finally, still Issue T:  "In 2020" - that is to say, last year - "Camerfirma again failed to properly disclose sub-CAs operated by MULTICERT."  So their previous assertions that they were going to fix these previous problems weren't fixed.  "They erroneously reported them as covered by Camerfirma's CP/CPS.  Their stated reason was because these new sub-CAs were not covered by the new audit from MULTICERT yet, although the expectations for how to disclose had been previously communicated by Kathleen Wilson."  So again, they were told.  They didn't do it.



And finally, Issue X, which was again about this MULTICERT sub-CA.  There's mis-issuance from 2018 through 2019.  "In August of 2018, within weeks of having received a cross-signed sub-CA from Camerfirma" - that is relating to Issue T - "MULTICERT issued several certificates that violated the ASN.1 constraint for organizationName field length.  Camerfirma's response was that both they and MULTICERT would now regularly check crt.sh for certificate lint violations."



Then, later:  "In October of 2018, it was discovered that MULTICERT had mis-issued 174 certificates with an incorrect qcStatements extension."  So they're just not even - they're not doing this right.  "In response to the report that was provided, MULTICERT revoked the certificates and then mis-issued new certificates with a validity period greater than 825 days" - which is illegal - "to replace those the following month.  Further, after reportedly fixing the underlying issue, MULTICERT again mis-issued another certificate having a validity period greater than 825 days."  Which, you know, their system shouldn't do.  What, do they have someone typing it in manually?  Oh, I'm sorry, we used the previous year calendar by mistake.  I mean, really.



But anyway:  "During the course of this investigation, MULTICERT also failed to revoke on the timeline required by the BRs" - the baseline requirements - "in order to give the customer more time to replace certificates."  That's right.  "In March of 2019 it was discovered that MULTICERT's certificates also had insufficient entropy, containing only 63 bits of entropy, rather than the required 64."



So again, those are just three - they call them three, that's more like 13 - of the 26 issues that have been compiled since 2017.  And, okay, maybe having 63 bits of entropy rather than 64, you know, you have a stuck bit, is not a big deal.  But in the CA business, which as I said can be, if you behave yourself, a money-printing goldmine, it is about the details and about rule following.  And every rule has been established for some good reason over time.  They didn't just make up a bunch of rules because they were sitting around saying let's make this harder to be a CA.  They're all there for a reason.



And if a CA is sloppy about something as simple as the amount of entropy in their certs, and of course that's an important thing to have, then it begs the question, what else are they doing wrong?  And if their system can somehow issue certificates with illegal validity periods greater than is allowed, again, what else are they doing wrong?



So through the years we've discussed the walk of shame made by the StartCom subsidiary of WoSign - oh, and by the way, StartCom ended up doing some business with this Camerfirma group.  I didn't share those mistakes, but they're there.  And remember Diginotar, of course, and even Symantec.  In each case, trust in those companies' certs was revoked.  Diginotar filed for bankruptcy.  And as we know, Symantec, whose certificate-signing name was essentially ruined by their own misconduct, sold their certificate authority business to DigiCert.



So at this point the other browser makers have been silent on Camerfirma.  And I just think that's because Google is a first mover here.  Chrome has clearly made the right decision, so I'd expect to see similar announcements being made by Apple, Microsoft, and Mozilla before long.



LEO:  Oh, yeah.  This list is from Mozilla, so clearly they're well aware of it.  It doesn't seem that malicious.  It seems sloppy; right?  I mean...



STEVE:  Yeah.  Agreed.  Agreed.  Although...



LEO:  But you make an excellent point.  Here's your opportunity to make a lot of money.  Why be sloppy?



STEVE:  Oh, Leo.  Could I have that business, please?



LEO:  I know, I know.  We just paid - I use DigiCert, among others, for our certs.  And I just got another one.  It's expensive.  I spent more than a thousand bucks for the cert.  It was a wildcard cert.  And they were good.  They called, you know, the business line.  I had to figure out a way to answer the business phone, which was - that was an interesting...



STEVE:  Yeah, in fact, Sue does that for me.  And so we have a standing deal.  I say, okay, Sue, now DigiCert's going to be calling sometime this morning.  Are you going to be around?



LEO:  Make an appointment, yeah.



STEVE:  Because you need to answer and say, hi, I'm a breathing human.



LEO:  Right, right.  No, I was really glad that they went the extra mile, you know.  It was inconvenient, but they did it.  And this was a renewal.  This wasn't even, like, they already had verified me.  So yeah, you kind of want these guys to do it right.  I really think this.



STEVE:  Well, and of course, as I've said before, there is now, of course, certs are also available for free; right?



LEO:  Let's Encrypt.



STEVE:  The ACME Protocol with Let's Encrypt.  It'll do that for you.  But Let's Encrypt is also where all the malicious certs are.



LEO:  Right.  



STEVE:  That is, all of the soundalike, lookalike, Unicode hack domain names, you go to any of these things, they have, whoa, yeah, look, I've got TLS.  Yes.  Let's Encrypt is my certificate.  So I would not be surprised if at some point there isn't an indication that is surfaced on our browsers about whether there was any validation of this assertion made by a human in the loop, or was it just automation?  To be fair to Let's Encrypt, their goal was to encrypt the Internet.  And they have done that.



Unfortunately, we rely on certificates for two things:  not only encryption, but authentication.  And that's the problem with Let's Encrypt is that, because it's a bot system, it's an automated certificate issuance, I mean, this could have been done 20 years ago if we wanted to.  It's not hard.  But that just means that there's no assertion of the identity behind the company.  And that's why I'm happy to have my relationship with DigiCert is that at some point I wouldn't be surprised if there isn't something that says, okay, yeah, you're encrypted, but we're not sure who you're talking to.



LEO:  It's also the case that there is no standard price; right?  The prices vary.



STEVE:  True.  And for what it's worth, the way DigiCert works, especially now that certs have had their maximum issuance lifetime renews...



LEO:  Yeah, I got my new one-year cert; right.



STEVE:  Right.



LEO:  But I bought two years.



STEVE:  Well, and that validation probably lasts you two years.  That is to say they decoupled the validation of your identity from the issuance of certs so that - and this is what's been so handy for me.  I'll, like, in the middle of the night on a holiday weekend I'll say, oh, you know, I really want forums.grc.com.  And I go over to DigiCert and make myself a cert, which...



LEO:  Because GRC.com has already been validated.



STEVE:  Correct.



LEO:  Yeah, yeah.



STEVE:  Correct.  And so I'm able to do that.  But I could even reissue a GRC.com cert if I wanted because my point is every so often, separate from issuing, they perform the "Are you still you" dance.  And that bumps their calendar forward.  And then within that window you can do anything you want to.



LEO:  That's interesting.  I didn't know that, yeah.



STEVE:  And I mean, like, night or day, yeah.



LEO:  That's in response to Let's Encrypt because they really do want to be a little bit easier; right.



STEVE:  They have to be, yeah, exactly.  They have to make that tradeoff.  Okay.  So after Camerfirma is gone - and presumably, like I said, if I had stock I'd sell it - there will still be plenty of certificate authorities for browsers and consumers both to trust.  So it's not like we don't have enough of them.  Everyone will probably well remember the day I clicked on the list of certs in my root store, just about fell over when it was more than 400 because I remembered when there were five of them.



And so the best thing that probably comes from this, from this sort of banishing, is the sobering reminder to all the other CAs, even non-top tier, I mean, DigiCert is like top tier.  I'm always - sometimes I'll look at some good website cert, wondering, and there it is, "Signed by DigiCert."  And I think, yup.  So Camerfirma, okay.  But these non-top tier guys, I mean, here Camerfirma's like, well, the person who we needed to do this had a backup, but I guess the backup needs a backup because, you know, it's like, what?



Okay.  So the point is, behave yourselves.  If you've got a growing list of, like, mistakes over in Mozilla's collection pile, you ought to start thinking about taking it seriously because at some point the boom is going to be lowered on you, and you're not going to be able to print money anymore.  Turns out it's not a right, it's a privilege.



Okay.  So hopefully people who are using GPG are on some list somewhere, and this will be old news.  But an urgent update is needed of the recently released Gnu Privacy Guard.  Version 1.9.0 was recently released, just a few weeks ago, on the 19th of January.  Libgcrypt is an open source crypto library as part of GPG, one of GPG's modules.  Last Thursday our old friend Tavis Ormandy, whom we haven't heard from recently, of course of Google's Project Zero, publicly disclosed the existence of a heap buffer overflow in libgcrypt which was due to an incorrect assumption in the block buffer management code. 



Tavis wrote - and I just hit the spacebar, and I went way down.  Tavis wrote something.  I'm sure he did.



LEO:  I can read it.  Here, I'll be Tavis Ormandy.



STEVE:  Very good.  Actually, I found it.  But you want to read it?



LEO:  No.  I was just going to give him some sort of nerdy voice, which is probably not the best thing to do.



STEVE:  Oh, thank you, Leo.  He said:  "Just decrypting some data can overflow a heap buffer with attacker-controlled data.  No verification or signature is validated before the vulnerability occurs."  He said:  "I believe this is easily exploitable."



LEO:  He said:  "I believe this is easily exploitable."  How about that?



STEVE:  I'm sure that's what he said.  Sounded like Daffy Duck, maybe.



LEO:  I am nervous now because I do use GPG.  So I'm going to have to check and make sure I'm on the...



STEVE:  Make sure you're at 1.9.1.



LEO:  1.9.1, okay, yeah.



STEVE:  So Tavis forwarded his findings to the developers responsible for libgcrypt.  And as soon as the report was received, the team published an immediate notice to users:  "[Announce] [urgent] Stop using Libgcrypt 1.9.0!"



LEO:  Oh.  Oh, boy.



STEVE:  Yeah.  "In the advisory, principal GnuPG developer Werner Koch asked users to stop using v1.9.0 as a new release had begun to be adopted by projects including Fedora 34 and Gentoo.  A new version of libgcrypt, v1.9.1, was released in a matter of hours" - because it wasn't a hard problem, it was just a bad problem - "to address the severe vulnerability which was even too new to have had a CVE number assigned."  That's the way you want your security folks to operate.  Like, it's already done by the time the CVE gets issued.



In an analysis of the vulnerability, cryptographer Filippo Valsorda, whom we've referenced in the past, suggested that the bug was caused by memory safety issues in C - oh, imagine that, has anyone ever heard of that? - and may be related to efforts to defend against timing side-channel attacks.  So what we have is an instance of an attempt to mitigate one potential threat, creating a new, very real vulnerability where none existed before.  So as a consequence, users who had upgraded to libgcrypt 1.9 are being urged to download the patched version as quickly as possible.  In other words, a trivial problem to exploit.  The GPG developers agreed with Tavis's assessment of the bug's severity.  They said:  "Exploiting this bug is simple, and thus immediate action for 1.9.0 users is required."



LEO:  You'd need physical access to the machine, though; right?



STEVE:  No, no, no.



LEO:  Oh, you wouldn't.



STEVE:  This is a send-somebody-email exploit.



LEO:  Oh, god.  Okay.



STEVE:  Yeah, yeah, yeah.



LEO:  I have 1.9.0 on my Mac here, so I'm upgrading it right now.



STEVE:  Yeah, good.  So thank goodness, or thank Google, for Tavis.



LEO:  Yes.



STEVE:  But you have to wonder what would have happened if Tavis had not been on the ball?  How long would this newly introduced serious flaw have lingered within the GPG code?  It's clear that when a skilled developer examined the code, Tavis - without the inherent bias of the code's author, and as we've often said, it's very difficult to see one's own mistakes - the problem was apparent.  Tavis just saw it.  So that suggests that malicious coders, whom we know are unfortunately every bit as talented as the world's best, might also be scouring the world's open source, looking for exactly such flaws.



So to me this suggests two things.  First, we really need to appreciate how brittle our current coding and code is, and try much harder to just leave things alone that are already tried, tested, and true.  Stop messing with code that works.  Stop trying to make things better that are just fine the way they are.  Really.  The second thing is that we really need to reconsider our coding practices.  We need implementation languages that inherently do not allow these sorts of mistakes to be made in the first place.  Such languages exist.  But they're not macho and fun to use.  Consequently, a highly critical security-oriented cryptographic library for the widely used GPG is written in C, the lowest level, most macho language, with the worst security track record.



LEO:  Okay.  I might argue that assembly is even lower level macho.



STEVE:  Actually, I'll be getting to there in a second.  



LEO:  Okay.



STEVE:  That could be owing to the fact that so much code is still being written in C, but it's also owing to the fact that the language provides exactly zero protection from doing anything the programmer wants.



LEO:  By design.



STEVE:  Yes.  Which is why it's appealing to cowboys.



LEO:  Right, right.  Everybody loves C.



STEVE:  Yes.  And yes, I know.  I wrote SQRL in assembler.  So who am I to speak about the need to use safe, high-level languages when security matters.



LEO:  Do you have static type checking in assembler?  I don't think so.



STEVE:  I'm just saying, Leo, everybody else should do it.



LEO:  Yes.



STEVE:  Everybody else.



LEO:  None of you are good enough to be using assembler.



STEVE:  And that's of course the problem; right?



LEO:  Right.



STEVE:  Everybody thinks that everybody else should do it.



LEO:  I'm good enough, yeah.  I can do it.



STEVE:  With a foreseeable outcome that still today no one does.



LEO:  Yeah.  Everything should be rewritten in Rust except for SpinRite.  I'm just saying.



STEVE:  So good luck and god bless and be sure to update your GPG code.



LEO:  I just did, 1.9.1.



STEVE:  Nice.



LEO:  Thank you, MacPorts.  A good example is SUDO.  You were talking about how long this could have gone undetected?  SUDO was nine years, I think; right?



STEVE:  Ten.



LEO:  Ten.



STEVE:  It was 2011.



LEO:  Yeah.  Undetected.  And it allowed a local user to escalate to root.  That's not good.



STEVE:  Oh, yes.  We're getting there.  We're getting there.



LEO:  Oh, sorry, I didn't want to preempt you.



STEVE:  No.  So we have another interesting supply chain attack and a little bit of interesting takeaway, I think.  So the company BigNox, B-I-G capital N-O-X, is a Hong Kong-based company which publishes, among other products, an Android emulator for PCs and Macs called NoxPlayer.  The website claims that they have over - that is, the BigNox website - that they have over 150 million users spread through more than 150 countries and speaking 20 different languages.  Though the BigNox follower base is predominantly Asian, based on what ESET found - I'll get there in a second - the NoxPlayer is generally used by gamers to play mobile games on their PCs.



So the discoverers of something fishy going on were our friends and recent TWiT network sponsor ESET.  They spotted a highly targeted surveillance campaign involving the distribution of three different malware families via tailored - and here it comes - malicious updates to selected victims in Taiwan, Hong Kong, and Sri Lanka.  ESET spotted the first signs of something going on last September, and the compromise continued until "explicitly malicious activity," as they put it, was uncovered just last week, which prompted ESET to report the incident to BigNox.  ESET wrote:  "Based on the compromised software in question and the delivered malware exhibiting surveillance capabilities, we believe that this may indicate the intent of intelligence collection on targets involved in the gaming community."



So to carry out the attack, the NoxPlayer update mechanism served as the vector to deliver trojanized versions of the software to users which, upon installation, delivered three different malicious payloads, including, for example, the Gh0st RAT, you know, "RAT" as in Remote Access Trojan, which is used to spy on its victims, capture keystrokes, and gather sensitive information.  Separately, they found instances where additional malware like the Poison Ivy RAT was downloaded by the BigNox updater from remote servers controlled by the threat actor.



So ESET wrote:  "Poison Ivy RAT was only spotted in activity subsequent to the initial malicious updates and downloaded from attacker-controlled infrastructure."  Now, unfortunately, BigNox in Hong Kong was not very helpful when they were contacted by ESET, who wrote of this.  ESET said: "We have contacted BigNox about the intrusion, and they denied being affected.  We have also offered our support to help them past the disclosure in case they decide to conduct an internal investigation."  In other words, ESET was, you know, this is now a page.  I've got the link in the show notes here to their full disclosure.  So this was going to put BigNox in the spotlight.



So anyway, for one thing, if anyone hearing this is a user of BigNox's NoxPlayer, you probably need to take responsibility yourself, because it doesn't sound like BigNox is prone to, for making sure that you didn't receive any malware.  This link in the show notes contains some IOCs, Indicators of Compromise, which anyone who's worried can check for on their own system.  The intrusions appear to be gaming world-centric and highly targeted.  So it doesn't look like it's a big widespread campaign.



ESET said:  "In comparison to the overall number of active NoxPlayer users, there is a very small number of victims.  According to ESET's telemetry, more than 100,000 of our users" - meaning ESET's users - "have NoxPlayer installed on their machines.  Among them, only five users received a malicious update..."



LEO:  Wow.  That's surprising.



STEVE:  Yeah, "...showing that Operation NightScout," as they termed it, "is a highly targeted operation."



LEO:  Ah.



STEVE:  Yes.  Yeah.  And again, as we know, the more people you infect, the greater the opportunity for discovery.  And but it was probably the infection of those five users that overlapped with ESET's being in their system watching what was going on that put ESET onto this behavior in the first place.  So anyway, those victims, as I mentioned, are in Taiwan, Hong Kong, and Sri Lanka.  They said:  "We were unsuccessful finding correlations that would suggest any relationships among victims."  On the other hand, they've got, you know, all they're seeing is those five that happened to be using ESET.  Who knows overall because BigNox is saying that they've got 150 million users, not 100,000.  So it may also be that ESET's overlap with targeted victims wasn't very big.



They said:  "We were unsuccessful finding correlations that would suggest any relationships among victims.  However, based on the compromised software in question and the delivery malware exhibiting surveillance capabilities, we believe this may indicate the intent of collecting intelligence on targets somehow involved in the gaming community."  And then in their posting details and diagrams, the precise operation of the NoxPlayer update system is explained.  And after that they conclude:  "We have sufficient evidence to state that the BigNox infrastructure" - and then we have some domain names, res06.bignox.com - "was compromised to host malware, and also to suggest that their HTTP API infrastructure at api.bignox.com could have been compromised.  In some cases, additional payloads were downloaded by the BigNox updater from attacker-controlled servers."



So the malware didn't always come from BigNox itself.  Sometimes somehow there was a URL change, and in fact that's what they said:  "This suggests that the URL field provided in the reply from the BigNox API was tampered with by attackers."  And, you know, they said HTTP API.  I didn't look closely enough to see whether it was actually HTTPS.  Of course, if they have an unencrypted API, then anyone anywhere in line could intercept and tweak the URL in the reply field.



So what we have is a much smaller scale version of the now-infamous SolarWinds intrusion which one way or another leveraged the software updating channel to quietly slide malware into a victim's machine.  And this sort of put me in mind of things you and I used to say, Leo, which we've sort of revised ourselves since.  But once upon a time I believed that I could successfully take responsibility for not getting my own system infected.  You know, we've talked about this through the years.  Don't download anything that a website tells you you need.  That's never going to end well.  Don't click on links in sketchy email.  Be very wary of anything you download from a third-party download repository.  Whenever possible, go to the source.  Get the thing you want directly from the publisher and so on.



But today we all need to face the fact that we no longer have that control over our own machine's destinies.  Many of the tools, utilities, and widgets that we use are being periodically updated.  For me, Notepad++ comes immediately to mind because it is constantly wanting to update itself.  Not only is that annoying, since it seems to be working just fine for me, but it's also inherently dangerous.  If their build process or their update server were to get compromised - and we've covered stories in the past where that has happened to well-meaning organizations - in a very short time, and remember it even happened to Lenovo at one point, in a very short time a huge number of Windows users would be infected because their instances of Notepad++ said, oh, I've got a better, shinier version.  And everyone would say, oh, got to have that.  Maybe it's better somehow.



The point is that the fact that they have this leverage over an install base of Notepad++ users puts them in the crosshairs of the bad guys.  It makes them a high-value target.  Bad guys would love to get their malware just automatically downloaded into all of the Notepad++ users in the world.  So for me, the solution is Windows Defender, which I now no longer recommend only to others.  I look at it, and it's the green little happy house with the flag on it down in my tray.  I depend upon it, as well.  And since at the moment I'm sitting in front of a Windows 7 machine, I'm thankful to Microsoft for continuing to update Win7's Defender, even though they have otherwise abandoned Windows 7 and wish I wasn't still using it - well, I and nearly half of all the other desktops that are running Windows in the world.



So I was recently stating that any responsible company needs to be performing continuous network intrusion detection surveillance because defenses have become too porous compared to the external pressure that exists to get in.  And in an exact analogy at the personal level, I believe that today's end users must deploy their own local surveillance within their machines.  It's no longer the case that our actions explicitly invite stuff in.  And so if we don't do that, nothing will bite us.  Anything that we've got which is saying oh, there's an update available, click here to get it, you already trust that thing because it hasn't bitten you before.  But at any moment it could.



So I'm a 100% now subscriber to the idea that you need something that is vigilant in your system that is looking at everything that goes on.  And I know Defender's working.  I have, like, some old C drives archived on a semi-offline drive, and sometimes I'll open them and search for something that I know I had then.  And back then I had a directory of well-marked malware.  And sure enough, Defender pops up and says, what the hell are you doing?  And it's like, okay, relax, it's okay, this is just, you know, I'm a security guy.  I do research.  I have this stuff for a reason.  But so it's just sort of nice when it goes off and I go, oh, yeah, that is true.  I forgot about that directory.  Maybe be a good time to delete it, as a matter of fact.



So anyway, I thought it was interesting that here we've got at the user level individuals being targeted and surveilled, which has put me in mind of the shift that we've had.  Here I'm arguing that everything needs to update itself; right?  I don't know.  Notepad?  Just leave my Notepad alone.  It works just fine.  In fact, I think maybe I should turn off automatic updates because I've just convinced myself that this is a real danger.



Apple has quietly put iMessage in a sandbox in iOS 14.  The new code was discovered, reverse engineered, described and documented by Google Project Zero's Samuel Gross.  And I thank Elaine for the pronunciation.  The first time I talked about him I said "Grobe" because it's G-R-O and he has like a funky...



LEO:  That's S-S.



STEVE:  Exactly.  And so Elaine, always alert to these things, sent back a little note saying, uh, Steve, that's an S-S in German.  It's like, oh.



LEO:  It's a special symbol there for that, Ja.



STEVE:  Samuel Gross of Google's Project Zero wrote:  "On December 20th, Citizen Lab published 'The Great iPwn,' detailing how 'Journalists Were Hacked with Suspected NSO Group iMessage Zero-Click Exploit.'"  He said:  "Of particular interest is the following note:  'We do not believe that the exploit works against iOS 14 and above, which includes new security protections.'"



Now, he said:  "Given that it is almost now exactly a year ago since we published the Remote iPhone Exploitation blog post series" - and we covered that at the time.  They were amazing and extensive.  He said:  "...in which we described how an iMessage zero-click exploit can work in practice and gave a number of suggestions on how similar attacks could be prevented in the future, now seemed like a great time to dig into the security improvements in iOS 14 in more detail and explore how Apple has hardened their platform against zero-click attacks."  And of course that means that your phone could receive iMessages which, without you doing anything, just the receipt of the iMessage could be enough to give the attacker either access to your phone that you don't want them to have or some information that allows them to incrementally get to a point where they're able to succeed.



Now, what's cool about this, what Google has done, that is to say, reverse engineering iOS 14, is that Apple is famously mum about this.  They just say, "Oh, it's better, but we want more."  So Samuel provided more.  He said:  "The content of this blog post is the result of a roughly one-week reverse engineering project, mostly performed on an M1 Mac Mini running macOS 11.1, with the results, where possible, verified to also apply to iOS 14.3, running on an iPhone XS."



Now, I'll just stop there to note that, remember, it's virtually impossible to look inside an iPhone at this point.  But what we do know is that Apple is reusing the same code systems, both in the iPhone and in macOS.  And macOS is far more open to poke around in.  And so we've talked about this happening before, but I wanted to remind our listeners that what we're now beginning to see is the iPhone's behavior being inferred from and then later verified from the behavior in the much more accessible macOS.



So Samuel said:  "Due to the nature of this project and the limited timeframe, it is possible that I have missed some relevant changes or made mistakes interpreting some results.  Where possible, I've tried to describe the steps necessary to verify the presented results and would appreciate any corrections or additions."  He says:  "The blog post will start with an overview of the major changes Apple implemented in iOS 14 which affect the security of iMessage.  Afterwards, and mostly for the readers interested in the technical details, each of the major improvements is described in more detail while also providing a walkthrough of how it was reverse engineered."  And that's of course way more than we need to get into here.  The main things that Apple did are of interest.



He says:  "At least for the technical details, it's recommended to briefly review the blog post series from last year for a basic introduction to iMessage and the exploitation techniques used to attack it."  Okay.  So the four things Apple did, he said:  "Memory corruption-based zero-click exploits typically require at least the following pieces:  One, a memory corruption vulnerability, reachable without user interaction and ideally without triggering any user notifications.  Second, a way to break ASLR remotely."  Right?  Address space layout randomization remotely.  You need to gain information about that.  "A way to turn the vulnerability into a remote code execution, third.  And then, fourth, likely a way to break out of any sandbox, typically by exploiting a separate vulnerability in another operating system component, for example, a user space service or the kernel."



And certainly in years past, when we've talked about the way the Pwn2Own attacks have succeeded, it was often by doing what he was referring to, chaining vulnerabilities.  One vulnerability gets you here.  Then from there you're able to use a second one to move to a different location and so forth in a chain.



Okay.  So he describes three things that Apple has done to essentially zap all four of those things.  The first is the BlastDoor - great name - the BlastDoor Service.  He said:  "One of the major changes in iOS 14 is the introduction of a new, tightly sandboxed BlastDoor service which is now responsible for almost all parsing of untrusted data in iMessages," he says, and he gives an example of a function inside.  He says:  "Furthermore, this service is written in Swift, a mostly memory safe language which makes it significantly harder to introduce classic memory corruption vulnerabilities into the code base."



LEO:  Woohoo.



STEVE:  So of course this is exactly what I was just talking about.



LEO:  Swift is not C.



STEVE:  It's not C, and it's not assembler, exactly.  And it is exactly this.  That's the way you want to write your code to parse untrusted data and write that service in Swift so that the service itself will be highly resistant to attack.  So then in his presentation he shows us a rough diagram of iMessage message processing pipeline, which is this big grid of arrows pointing everywhere.



And then he continues:  "As can be seen, the majority of the processing of complex untrusted data has been moved into the new BlastDoor service.  Furthermore, this design with its seven-plus involved services allows fine-grained sandboxing rules to be applied."  He says:  "For example, only the IMTransferAgent and apsd processes" - whatever those are - "are required to perform network operations.  As such, all services in this pipeline are now properly sandboxed, with the BlastDoor service arguably being sandboxed the strongest."



The second thing of the three that Apple did, rerandomization of the dyld - that's probably dynamic load - shared cache region.  He says:  "Historically, ASLR on Apple's platforms had one architectural weakness.  The shared cache region, containing most of the system libraries in a single prelinked blob, was only randomized per boot, and so would stay at the same address across all processes."  He says:  "This turned out to be especially critical in the context of zero-click attacks, as it allowed an attacker, able to remotely observe process crashes, for example through timing of automatic delivery receipts, to infer the base address of the shared cache and as such break ASLR, a prerequisite for subsequent exploitation."



He said:  "However, with iOS 14, Apple has added logic to specifically detect this kind of attack, in which case the shared cache is rerandomized for the targeted service the next time it is started, thus rendering this technique useless.  This should make bypassing ASLR in a zero-click attack context significantly harder or even impossible," he says, "apart from brute force" - which would mean guessing, just guessing blindly and hoping you get lucky about the cache's location - he says, "depending upon the concrete vulnerability."



And finally, third, exponential throttling to slow down brute force attacks.  He said:  "To limit an attacker's ability to retry exploits or brute force ASLR, the BlastDoor and imagent services are now subject to a newly introduced exponential throttling mechanism enforced by the launch daemon, causing the interval between restarts after a crash to double with every subsequent crash," he says, "up to an apparent maximum of 20 minutes."  He says:  "With this change, an exploit that relied on repeatedly crashing the attacked service would now likely require in the order of multiple hours to roughly half a day to complete instead of a few minutes."



And anyway, so then for the remainder of his disclosure Samuel lays out the details of what he found.  I've got the link in the show notes for anyone who really wants to, you know, is curious about exactly how Apple did these things.  It seems to me in today's climate it is this sort of anticipatory design for security that's needed.  After the troubles that surfaced in iOS 13, Apple did not simply patch those individual flaws and leave everything else alone.  Instead, they fundamentally rearchitected the entire iMessage processing system to preempt entire classes of next-generation attacks.  And it's the right thing to do.  iMessage has an exposure to the world.  It's the way unsolicited stuff can come into your phone.



And so rather than assuming that, oh, those were the last bugs we're ever going to have, Apple said, okay, those are not the last bugs we're ever going to have.  We keep fixing them.  So let's change the architecture.  Let's look at, if we have a bug, how can we keep it from compromising the user?  And that's what they did.  And one could argue that it should have always been that way.  But what we've been witnessing is a slow but sure, constantly rising threat level.  Through the life of this podcast, the 15 years that we've been doing this, we've watched the threat level go from people putting scripts in email because they thought it was funny to nation-states deeply infiltrating U.S. corporate and government networks surreptitiously.  I mean, it's a whole new game.



So Apple has been in the middle of it all, through all of this.  And without question, lessons are being learned, hopefully by the entire industry.  And that's what I think makes Samuel's sharing of what Apple won't tell us so valuable.  If Apple hides this innovation, then the rest of the industry isn't able to go, ooh, yeah, maybe we should do that, too.  To me, there's little doubt that future systems will be designed with these sorts of mitigations built in from the get-go.  But only if those who are implementing them are willing to share what's going on.  There's no way that bad guys knowing this is being done is going to help them.



The way Apple did this, it is limiting the amount of and rate of knowledge that a bad guy can obtain.  And mitigation really is what this is because Apple is saying, okay, we keep trying to fix problems.  Bad guys keep finding them.  Let's change the system so it doesn't matter if they find them.  We're still going to do our best to fix them, but let's add a really strong effective sandboxing around iMessage, which is what they've done.  So props to Google and Samuel for taking the time to do this reverse engineering and then share it with everybody else.  It raises the bar of what a responsible provider needs to do to protect their own users.  So bravo.



And Leo, as you said earlier, for the past 10 years the command all of us who have used Linux and Unix know as SUDO turned out to only be pseudo secure.  Last week a very serious bug came to light in the command - this is where you do not want it - the command line parser of Linux's powerful SUDO command.  As we know, SUDO allows non-root users to temporarily elevate their rights to obtain some root privileges.  This is typically done for performing maintenance and various system-level things that your typical user, even if you're the only user on the system, the modern security architecture says everybody should be running with reduced rights all the time, and you only selectively and briefly raise your rights in order to do stuff.  And that's essentially what Windows provided with the whole UAC architecture where you've got to say yes.  The screen goes dark, and you get a dialog, and then you say yes, I want to do this.  And that then switches your credentials briefly in order to allow you to do that.



So Qualys discovered the problem.  They wrote:  "The Qualys Research Team has discovered a heap overflow vulnerability in SUDO, a near-ubiquitous utility available on major Unix-like operating systems.  Any unprivileged user can gain root privileges on a vulnerable host using a default SUDO configuration by exploiting this vulnerability."



They said:  "SUDO is a powerful utility that's included in most, if not all, Unix- and Linux-based OSes."  FreeBSD has it, so it's everywhere.  "It allows users to run programs with the security privileges of another user.  The vulnerability itself has been hiding in plain sight for nearly 10 years.  It was introduced" - it'll be 10 years in July - "introduced in July of 2011 with commit 8255ed69 and affects all legacy versions from 1.8.2 to 1.8.31p2 and all stable versions from 1.9.0 to 1.9.5p1 in their default configuration."



They said:  "Successful exploitation of this vulnerability allows any unprivileged user to gain root privileges on the vulnerable host.  Qualys security researchers have been able to independently verify the vulnerability and develop multiple variants of exploit, and obtain full root privileges on Ubuntu 20.0, Debian 10, and Fedora 33.  Other operating systems and distributions are also likely to be exploitable."  And yeah, anything that was packaged in the last 10 years.



"As soon as the Qualys research team confirmed the vulnerability, Qualys engaged in responsible vulnerability disclosure and coordinated with SUDO's author and open source distributions to announce the vulnerability."  So when that happened, the maintainers of SUDO followed up last Tuesday, the 26th of January, saying:  "A serious heap-based buffer overflow has been discovered in SUDO that is exploitable by any local user.  It has been given the name Baron Samedit by its discoverer."  I have no idea...



LEO:  No, that's a play on the voodoo god Baron Samedi.



STEVE:  Ah.  Thank you, Leo.



LEO:  He was evil.  That is hysterical.  Baron Samedit.



STEVE:  Baron Samedit, yeah.  "The bug can be leveraged to elevate privileges to root, even if the user is not listed in the SUDOers file.  User authentication is not required to exploit the bug."  So the concern here, beyond this, I mean, I'm sure that our listeners who maybe have Linux deployed in environments where there might be unauthorized users with access to it who should not be able to gain access, you're going to want to update your instance of SUDO immediately.



But the concern is that the Internet is full of systems - and this speaks to your point, Leo, you made before - which quite naturally depend for their security upon the proven strength of the Unix/Linux account privilege model.  And this now well-known flaw punches right through that.  There are doubtless countless systems where an unprivileged user account is easily available with minimal authentication requirements.



LEO:  Not good.



STEVE:  Such systems are utterly dependent upon their security for that unprivileged account remaining unprivileged.  But any Linux system that went online anytime after July 2011, 9.5 years, will contain this flaw until and unless it is updated.  And we know that Linux is embedded everywhere.  And everything we've seen demonstrates that most of those systems will never be updated.  They're everywhere.  So to repurpose a now-famous phrase, "Stand back and stand by."



LEO:  It's an Evil Maid attack, though; right?  Again, you'd have to be at the keyboard to do that.  Most people - you can't...



STEVE:  No.



LEO:  No?



STEVE:  No.  You don't need to be at the keyboard.  Any online account, any non-root online account can do this.  So it is exploitable.



LEO:  But you're at the keyboard of that online account.



STEVE:  Sure.



LEO:  You can't get onto my Linux server unless you have a login, and that's not using SUDO.  That's using SSH or something like that, which is much more secure.



STEVE:  Well, but you could also see scenarios where the privilege model is relied upon.



LEO:  Right.



STEVE:  There is a low-privilege login.  



LEO:  If you have a user account, yeah, absolutely.  Every university is just going to be vulnerable.  Yeah, yeah, yeah.



STEVE:  Exactly.  Exactly.



LEO:  I'm hoping - I'm just logging into update.  I forgot, see, this is a perfect example.  I updated all my desktop Linux machines.  But I've got my server in the other room, which I never log into, I haven't updated in a long time.  Got to update that; right?  Yup.  Yikes.



STEVE:  And you're also right that this is a goldmine maybe for initial network intrusion, but definitely for post-intrusion lateral movement within an organization.



LEO:  Yeah.  Once you're on that system, right, now you can escalate, yeah.  Wow.



STEVE:  Yeah.  Okay.  So I want to share a progress report that I wrote yesterday for my blog over on GRC's forums.  And I've had this experience before.  Anybody who's done any journaling probably has.  I did a lot of journaling when I was in high school.  And I would open my journal and decide I wanted to write about some personal subject.  And even though I went in thinking I knew everything about it, invariably a paragraph or two in I would think of something that had never occurred to me before.  And I decided that the act of making myself write it out longhand, it kept those ideas in my brain longer, and it gave them a chance to associate with other new ideas.



So this literally - I had a major, like, eureka event yesterday about the future of SpinRite.  And I sort of started out what I have here in my notes as that blog posting.  But then I expanded upon it because there was a lot more context.  So I started by saying:  "February 1st Progress Report.  Much has transpired since my previous January 3rd announcement that work on SpinRite 6.1 has commenced.  To plan for what SpinRite 6.1 would and would not be, I needed to know how I was going to solve SpinRite's imperative need to boot on UEFI systems that no longer offer a traditional BIOS fallback.  So while beginning to work on SpinRite, I was also searching for any means to add BIOS support to a system that doesn't currently have any.



"The firmware which boots a system is intimately tied to its hardware.  That's why systems need firmware in the first place.  This means that it's not possible to simply run any BIOS on whatever hardware happens to be present.  So I was hoping that someone, somewhere, might have created a UEFI-to-BIOS translation layer which would allow for BIOS calls to be translated into their UEFI equivalent.  That would allow SpinRite to load such a translation layer, then boot the BIOS-dependent DOS, and then reuse everything that SpinRite already is on any UEFI system.



"But, unfortunately, nothing like that exists; and no one has ever created such a thing because the need for something like that only exists due to SpinRite's unique and continuing dependence upon the legacy of 16-bit DOS.  So that search provided some needed clarity.  The only way to move SpinRite forward would be to finally, after 35 years, end its dependence upon the BIOS and DOS.  So I began looking around for the optimal environment which would host SpinRite's future."



And I'll spare everybody the blow-by-blow.  That's all over in the spinrite.dev newsgroup where all of this conversation was happening earlier in January.  But for what it's worth, we looked at everything.  Linux; using Windows PE, the Pre-Execution Environment; the ReactOS; various other hobby OSes; and many of the various embedded OSes like VxWorks.  In the end, I settled upon an extremely lightweight real-time operating system for embedded applications which is called the "OnTime RTOS32."



What I love about it is essentially it is able to host Windows applications, within limits, in an embedded environment.  So it allows executable code to be written, tested, and debugged under Windows, which is still my preferred development environment; and then that PE format executable is repackaged for operation under its own loader and environment.  And it supports booting from either a BIOS or UEFI firmware.  But what that meant was that, in order to get to UEFI, I would need to dramatically change the operating environment.



Operating under DOS and the Intel processor's real mode, as SpinRite has always done, means that two 16-bit registers are always being referenced in order to access memory.  And the way this is done is a bit funky.  The bits in a 16-bit segment register are left shifted 4 bits to create a 20-bit value whose lower 4 bits are always zero.  Then a 16-bit offset register or value is added to that 16-bit result.  So the 16-bit offset register means that you can access a 64K, anything in a 64K region at one time, and the 16-bit segment register determines where that accessible 64K byte block is located with a granularity of 16 bytes.



So together this is the way the Intel real mode has always worked.  This is what allows for addressing of 1MB of memory because that's what 20 bits gives you.  So it's a funky way of synthesizing a 20-bit address using two 16-bit values.  And this of course is where the Intel 8080 and 8086's 1MB memory limit came from.  So Intel's later chips have 32-bit registers, like in Windows, and in any other, like Linux, Unix, I mean, any 32-bit OS uses a simple flat memory model where 32 bits directly allows you to specify the address.  Period.  You're done.  And as we know, 32 bits allows the addressing of 4GB.  That's 4.3 IPv4 addresses on the Internet.  Those are 32-bit addresses.



So back when I wrote SpinRite, initially in 1985, I embraced segmentation.  That's the way the Intel chip works, and that's all we had back then.  So, for example, in SpinRite, when you rotate through SpinRite's screens, each of those screens is referenced by a 16-bit segment with each screen starting at offset zero within its own segment.  On the one hand, it's messy; but it can be incredibly efficient and economical if you design to it.  And it is Intel's legacy, and I designed to it.



So the problem moving forward is that only the Intel 16-bit real mode, or the 16-bit virtual 86 mode, has the hardware that performs this segmentation math.  So there's no future there.  If the chip is not in one of the 16-bit modes, you don't have segmented memory. So for the past three weeks or so my plan had been to finish SpinRite 6.1, and that that would be the final release of SpinRite to run in a 16-bit DOS environment, and that only made sense because any further investment in the 16-bit environment would not be portable to the future.  So it just doesn't make any sense to invest more time and energy there.



My plan had been, and I described this over in GRC's newsgroup where we discussing this, to just bite the bullet and start over in a 32-bit flat memory environment, reimplement SpinRite from scratch, probably as a text mode command line utility, the way ReadSpeed is right now, get it all running, get all the functionality there, and then later move it into a graphical environment.  The aha moment that I had just yesterday was - and now I'm like, I'm back in SpinRite.  I've got the new memory manager is running.  It's got simultaneous access to all of the system's memory.  I've merged a bunch of the code from SpinRite and ReadSpeed.  So that's how I'm spending my days now, and I'm making really good progress.  And maybe it's the comfort with it that allowed me to see this.



But just it hit me.  I'm not stuck using segmentation.  I mean, I am with SpinRite's current code.  But I can port 16-bit SpinRite into 32-bit land because all the segmentation is explicit in SpinRite.  And so my plan now, after 6.1 is finished and published, and everyone's able to use it and play with it, I'm going to then port the 16-bit SpinRite as it is into a 32-bit environment.  It'll be hosted on this OnTime RTOS32.  It'll look exactly as it does now because that's the way to get it done fast.  And that will then give us a SpinRite that can boot on either DOS or UEFI, and it will be 32/64-bit code that can then continue to grow in the future.



So anyway, an interesting set of constraints that had to be worked through.  But I've been thinking about it now for about a day, and I'm really happy with having sort of found a way out of this corner that SpinRite's age had painted me into.  So I'm very excited to be making great progress with 6.1, and to have a way of not having to scrap everything in order to move over to UEFI and then continue working on the additional drivers that I want to add to it.  So anyway, I just thought our listeners would find it interesting.



Slipstreaming 2.0.



LEO:  All right.  It's Groundhog Day, after all.



STEVE:  It is.  It was Episode 792 of Security Now!, which we recorded last November the 10th, titled "NAT Firewall Bypass."  And perhaps we should have added a 1.0 to it in anticipation of the technique's inevitable evolution.  Thus today's podcast bears the title, "NAT Slipstreaming 2.0."  I'll begin by reminding everyone where we were in November, and quickly place that first-generation exploit into context against today's second-generation exploit.



The original NAT Slipstreaming attack relied on a victim within an internal network, tucked safely, they thought, behind their NAT router, who would click on a link or just visit a website which was running JavaScript, would then run JavaScript on their browser, as every website and ad now does.  That would open an incoming path, using some very clever packet hacking, open an incoming path from the Internet to the victim's device.  So that was bad enough back then that all of our browsers quickly moved to block outbound access to a few additional remote port numbers through which the traffic had to go in order to trigger the NAT router's Application Layer Gateway, which I'll get to in a second.



So today's upgrade of NAT Slipstreaming extends this attack by allowing the remote attacker to trick the NAT into creating NAT traversal mappings to any device on the internal network, not only to the victim's device, which originally and unwittingly did something, clicked a link, visited a site with a malicious ad or whatever.  As we know, many devices located on our internal LANs may be fine there, but they were never intended to be exposed to the Internet.  How many times have I talked about services that should never under any circumstances poke their heads out onto the Internet?



So this is precisely what v2 of NAT Slipstreaming allows.  Many embedded devices have minimal local security, if any, because they correctly presumed that they would only ever be accessible to local users.  An example is an office printer, which can be controlled through its default printing protocol or through its internal web server.  And we've talked about how printers, the firmware in printers could be subverted, and malware can actually live in a printer until it's rooted out.



Well, it turns out this provides a means for the malware to get into the printer in the first place.  Or maybe an industrial controller that uses an unauthenticated protocol for monitoring and controlling its functions.  Or an IP camera that has an internal web server displaying its feed, which is only available, supposedly, internally and maybe has default credentials which are not a problem because it's never going to be accessed from the outside.  This second-generation variant of the NAT Slipstreaming attack can access these types of interfaces from the Internet, which results in attacks that range from a nuisance to potentially sophisticated ransomware attacks.



Okay.  So in addition to network interfaces of devices that are unauthenticated by design, many unmanaged devices may also be vulnerable to publicly known but currently unpatched vulnerabilities; right?  I mean, there's like all kinds of vulnerabilities that exist in devices that just no one ever gets around to patching.  These could be exploited by an attacker who is able to bypass the NAT firewall to initiate traffic that can trigger known weaknesses on devices behind the NAT.



So to gain some sense for this, in a recent study, Armis's researchers found that 97% of industrial controllers which were vulnerable to URGENT/11, which is something we talked about at the time, were left unpatched more than a year after the critical vulnerabilities were first published.  So there were initially 100% of industrial controllers that were vulnerable to this.  The URGENT/11, to remind our listeners, was a set of 11 zero-day vulnerabilities which were discovered in the VxWorks embedded operating system, the most embedded OS today.  And of those 100%, 97 are still vulnerable a year later.  They just - they didn't get fixed.  Embedded OSes are not going to get updated.



So those things are sitting there with well-known vulnerabilities.  The only thing protecting them is that bad guys out on the Internet can't access the embedded OS.  This thing provides them a means to do so.  80% of Cisco devices which were vulnerable to the CDPwn vulnerability still are, nearly a year after those critical vulnerabilities were published.  So again, you definitely don't want to allow a NAT router to be abused using this new more powerful slipstream approach.



So the original discoverer of this, Samy Kamkar, he described the summary of attack which he discovered, the original one.  He said:  "NAT Slipstreaming allows an attacker to remotely access any TCP/UDP service, bypassing the victim's NAT/firewall just by having the victim visit a website or causing their browser to run JavaScript contained within an online ad."



Okay.  So as we know, strict NAT traversal rules are straightforward, simple, and elegant.  They amount to only accept incoming return traffic from remote IPs and ports that recently received outbound traffic.  That's all there is to it.  Right?  So traffic is seen going out of the NAT router.  The NAT router makes a note of it, actually creates an entry in a mapping table such that when return traffic comes back from the same IP and port that it went to, the router knows who to send it to back on the inside of the LAN.  And as I've often said years ago, this forms a sort of a beautiful firewall, automatically.  Unsolicited traffic just hits the NAT and, because it wasn't expected, and it isn't part of a communications that was initiated from inside, it goes nowhere.



But Samy's original inspiration was to observe that those simple and straightforward NAT traversal rules, or really that one simple and straightforward traversal rule, often needs to be bent in order to accommodate the needs of more complex network protocols.  Works great for email and for web surfing.  Not so, for example, in the case of Active FTP, which is an example we used before, where the outbound control connection tells the remote FTP server what port to connect to it inbound.



For that to operate transparently through NAT, because the remote FTP server is going to try to initiate what will look like an unsolicited connection to the NAT router, it requires that the NAT router be looking inside the outbound FTP traffic to actually read out of the packet the outgoing port specification which the remote FTP server's going to receive, and then automagically reroute the remote FTP server's new and technically unsolicited connection through to the proper expected port on the client machine of the LAN.  So in other words, it's got to get very involved in the protocol.



So collectively these are all known as ALGs, Application Layer Gateways.  Application Layer because it is at the application that the packets are carrying.  The network layer would be the packets themselves.  The application layer is what's in the packet envelopes.  And so the ALGs require the router to be aware of the content of the packets passing through it, rather than just the fact of the packet.  It can no longer just look at the destination IP and port.  So under the, in my case, I looked at this last night, under the NAT Passthrough tab of the WAN section of one of my Asus routers, it provides for PPTP, L2TP, IPSec, RTSP, H.323, SIP, PPPoE Relay, and FTP.  Those are the Application Layer Gateways that this very capable router is able to provide.



Conservative as I always am, when first setting up that network I immediately disabled all of those ALG passthroughs since I have no need for them.  Or so I thought.  Consequently, I was quite puzzled when the Verizon LTE Network Extender - I've talked about this once before on the show.  Lorrie and I are somewhere with a really bad cell coverage, so they just can't use Verizon at all.  It's like, no bars.  So I got one of those little femtocell boxes.  But I noticed that when I hooked it up and plugged it in, it wouldn't connect.  Just could not find its network.



So digging through the FAQs, I noticed that it mentioned its use of IPSec.  And I thought, ah, I know what's wrong.  So I went back into the router, turned on just the IPSec NAT traversal passthrough, and it came right up on the network.  So it is the case that you might find that you need some of these things.  But again, conservatives' security best practice is absolutely positively turn off things you don't know you need.  And as it happens, as a consequence of that approach, that network that I configured was never vulnerable to v2 of this NAT traversal attack.



Okay.  So what happened with the first and second generations of NAT Slipstreaming?  It turns out that there is an even more insidious Application Layer Gateway present in our routers than Samy had originally exploited.  Researchers at Armis were intrigued by what Samy originally found.  They had done some research before, but hadn't really wrestled it to the ground.  When they saw Samy's posting, they immediately dusted off what they had done before and pushed it across the finish line.  And of course, as we know, I quoted Bruce Schneier at the beginning of the show, "Attacks never get less powerful.  They only grow more powerful."



The guys at Armis said:  "Building upon Samy's ideas, and combining them with some of our own, led us to the discovery of the new variant.  This new variant is comprised of the following newly disclosed primitives.  Unlike most other Application Layer Gateways, these ALG functions in our routers, the H.323 ALG, when supported" - and it is widely - "enables an attacker to create a pinhole in the NAT Firewall to any internal IP, rather than just the IP of the victim that clicks on the malicious link.



"Then WebRTC TURN" - that's the Traversal Using Relay around NAT - "WebRTC TURN connections can be established by browsers over TCP to any destination port.  The browser's restricted ports list" - that is, this thing that the browsers did in November to prevent this - "was not consulted by this logic, and was therefore bypassed.  This allows the attacker to reach additional Application Layer Gateways such as the FTP and IRC ALGs using ports 21 and 6667, respectively, that were previously unreachable due to the restricted ports list.  The FTP ALG is widely used in NATS and firewalls."  So their point was, first of all, if you have H.323, that's a powerful Application Layer Gateway for abuse.  If you don't, then the support for WebRTC TURN can be abused to bypass the restricted ports list that are currently protecting our browsers from initiating this kind of traffic.



And they said:  "This also defeated the browser mitigations introduced shortly after Samy first published the NAT Slipstreaming attack which added the SIP port 5060 to the restricted ports list, but did not block the port from being reachable via a TURN connection."  And they said:  "H.323 is a VoIP protocol similar to SIP, which is also quite complex.  For a network of VoIP phones to function properly, while having a NAT somewhere inside the topology, an H.323 Application Layer Gateway is required.  The H.323 ALG needs to translate IP addresses that are contained within the application layer H.323 protocol packets, and open holes in the NAT in certain scenarios."  Actually it's when call forwarding features are used.



They said:  "Most ALGs only need to worry about at most two addresses to translate within a session, the IP address and ports of both sides of the TCP connection.  However, H.323 is a telephony protocol and supports call forwarding.  Therefore, in this case, one party within the session can refer to a third-party IP address belonging to the VoIP phone that the call should be forwarded to.  Most H.323 ALGs support this feature."



So the upshot of all this is that a single H.323 packet sent over TCP port 1720 that initiates call forwarding can open an external pinhole through the NAT to any TCP port of any internal IP on the network.  Thus NAT Slipstreaming just got a whole lot more powerful.  The Armis blog about this contains full details for anyone who wants more.  I've got the link in the show notes.  They tested many routers and found virtually all of them to be vulnerable to full port and IP exploitation, meaning that they were able to open remote attacker access to any IP and port behind the NAT.  Since all of these attacks bounced scripts and network packets off of our web browsers, they then responsibly disclosed what they had found to all browser vendors.



So in a quick timeline, November 11th of 2020 was the coordinated disclosure of the new variant initiated with Chromium, Mozilla, and Apple.  So I think our podcast on the v1 was November 10th.  So the day after, the Wednesday, after we did that podcast, these guys had already jumped on this, and they began a coordinated disclosure.  On January 6th, so last month, Chrome release 87 contained the patch mitigating the new attack variant.  On the 7th, the next day, Microsoft Edge inherited it from Chrome, so Edge 87 got the same patch.  On the 14th, a week later, Safari released v14.0.3 beta that contains a patch, and it has since gone of course mainstream.  And on the 26th of last month Firefox released 85 that contains a patch against the attack.  And this was kept quiet and embargoed until all of our mainstream browsers were protected.



So recalling from our coverage of this last November, our browsers responded to the first slipstreaming revelations by blocking HTTP and HTTPS access to ports 5060 and 5061.  Now, as a consequence of Armis's second-generation exposition, all of the browser vendors realize, holy crap, that doesn't even begin to be sufficient.  So now all of the browsers are blocking outbound HTTP, HTTPS, and FTP access to ports 69, 137, 161, 1719, 1720, 1723, and 6566 TCP ports.  Google said at the time, I mean, now they're acknowledging.



They said:  "The NAT Slipstream 2.0 attack is a kind of cross-protocol request forgery which permits malicious Internet servers to attack computers on a private network behind a NAT device.  The attack depends on being able to send traffic on port 1720 (H.323).  To prevent future attacks, this change also blocks several other ports which are known to be inspected by NAT devices and may be subject to similar exploitation."



So this is sort of a fool me once, shame on you, but they're not going to only block 1720 this time.  They're going to say, okay, what other ports are NAT routers looking at, and let's just shut this whole thing down.  So that's been resolved by our browsers.  But I would argue that this is a perfect time to look at the configuration of your routers.  Because I think the other lesson here is to always turn off any unneeded features of your router.  You wouldn't have thought that these things could be abused.  Turns out Samy figured out how to do it.



As a consequence of my very conservative approach, my own network wasn't ever vulnerable to any of this because, as I said earlier, I had already disabled all that.  Then one of them bit me.  The lack of IPSec, it turns out, well, I have a need for it.  So I turned only that one back on, and everything is good again.  And I'll keep in mind in case I do something, I don't know, I don't use any VoIP, but I would need to turn one of those on if I did.  So it's good that our browsers are protecting us better if your router doesn't have abuse prone Application Layer Gateways in the first place.



LEO:  And, you know, you can turn them on if you need them.



STEVE:  Right.



LEO:  Yeah.  So if something breaks, turn it back on.  But I think it's a good idea.  Turn everything off and wait and see what happens.



STEVE:  Exactly, yeah.



LEO:  It's true, you know, this is true everywhere.  Same thing on a Network Attached Storage.  You might be tempted to turn on bunch of services you don't use.  Don't.  Turn them off.



STEVE:  Right, exactly, exactly,



LEO:  You know what everybody should do is go over to ShieldsUP!.  Just check.  See what services your router's saying hello to.  Knock on the door.  You want everything stealthed.  I've learned that over the years.



STEVE:  Yup.



LEO:  That's where you can get a copy of this show while you're there:  GRC.com.  Steve's got 16Kb audio, 64Kb audio.  It's the sole and only source for 16Kb audio and transcriptions, beautifully written by Elaine Farris, so you can read along, even with the "Gross."  And she's got the, what is that called, the eszett, something, she's got that funny - did she put the little funny "ss" in there?



STEVE:  Yeah.  Yeah.  And in fact I copied it from wherever it was that I saw his name.



LEO:  Copy and pasted in, yeah.



STEVE:  And put it into my own show notes so I could be official also.



LEO:  Hard to find it, yeah. 



STEVE:  So I could be official also.



LEO:  Yeah.  I recognize it from Strasse, the German word for street.  You see it in Strasse.



STEVE:  Ah.



LEO:  All that at GRC.com.  While you're there, pick up a copy of SpinRite.  We're getting to the end of the development cycle for 6.1.



STEVE:  Oh, yes, yes, yes.



LEO:  I can feel it.  But get 6.0.  You'll get a free upgrade to 6.1, and you can participate in the final beta tests and so forth.  The world's best hard drive maintenance and recovery utility, getting better all the time.  Soon we'll be saying the world's best hard drive and SSD recovery utility.  I guess we could say that now, frankly.  



STEVE:  It refuses to die, Leo.  It just will not die.



LEO:  A program that will not die.  You can get 64Kb audio and video files at our website, TWiT.tv/sn.  There's a YouTube channel.  If you're a YouTube kind of person, subscribe to the Security Now! YouTube channel.  Best thing in my opinion would be to get your favorite podcast client and subscribe there.  And we're asking, everybody is asking for reviews these days.  If you leave reviews on Apple's podcast platform, that's always helpful for people, "What is this Security Now!?  I never heard of this."  Scratch scratch scratch.  Just say "Just download it and listen."  And then you'll want to listen to all 803 other episodes.



STEVE:  And you won't need your Sominex.



LEO:  Well, you might need your Vitamin D and your zinc.  But you won't need the melatonin.  There you go.  No.  It doesn't put you to sleep.  It's fascinating.



STEVE:  No.  Doesn't put me to sleep.



LEO:  It's fascinating.  No, you work hard on this, I know.  I appreciate it.  Steve can be messaged on Twitter:  @SGgrc.  If you follow him there, you'll get updates to when the show's available.  He puts show notes up there.  But again, he can take messages there or at GRC.com/feedback.  It's been a fun day.  Thank you, Steve.  Go back to your knitting.  I know you're [crosstalk].



STEVE:  Now, when we last talked you were going to get four inches of rain.  Did you get...



LEO:  Got it.  Got it, yeah.



STEVE:  Wow.



LEO:  Yeah.  And now it's a beautiful clear sky.  It rained yesterday, too.  We got a lot of rain.  The big atmospheric river missed us by a few miles to the south.  But we still got a lot of rain.  The main thing we're looking for, and probably you, too, is snow pack.  I don't know about Southern California, but in Northern California all of our water is up there in the Sierra, and we have to get that runoff in the spring.  And so we want heavy snow, and we got that.



STEVE:  Yeah.  Yeah.



LEO:  We got that, yeah.



STEVE:  Yay.  That's good.



LEO:  Thank you, Steve.  Have a great week.



STEVE:  Okay, buddy.



LEO:  We'll see you next week on Security Now!.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#805

DATE:		February 9, 2021

TITLE:		SCADA Scandal

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-805.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we begin with a collection of interesting and engaging news surrounding Google's Chrome browser.  We look at a high-profile Windows Defender misfire, and at new WordPress plugin nightmares.  We check in on the world of DDoS attacks and cover the meaning of three new critical vulnerabilities in SolarWinds software.  We have a bit of closing-the-loop feedback from our listeners, an update on my work toward the next SpinRite, and then we look at a near-miss disaster in a poorly designed industrial control system.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  A trio of Chrome issues.  There's a new DDoS attack, a new amplification attack using the Plex Media Server.  There are three new SolarWinds vulnerabilities you need to know about.  And then we'll wrap things up with a closer look at the attack at the small-town Florida water facility.  It was a SCADA attack.  The details, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 805, recorded Tuesday, February 9th, 2021:  SCADA Scandal.



It's time for Security Now!, the show where we cover your security online, your privacy, the way things work, protecting yourself.  This is the guy right here, Steve Gibson from the Gibson Research Corporation.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.



LEO:  Good to see you.



STEVE:  Great to be with you again, as always.



LEO:  I see you've got the soldering iron out.  Are you making something?



STEVE:  Yes, doing a little construction work, that's true, yeah.



LEO:  Someday that Speak & Spell will work again.



STEVE:  And there are always things more interesting to than cleaning up around here, so...



LEO:  Absolutely.



STEVE:  So that never kind of - it's sort of a constant entropy battle.



LEO:  It's life, yeah.



STEVE:  Which I'm generally losing.  You know, at some point with one's car, it stops getting more dirty because as new dirt arrives, old dirt falls off.  So you reach a homeostasis.  



LEO:  That's so Steve.  No, that's good observation, Steve.



STEVE:  I guess it's actually equilibrium as opposed to homeostasis.  



LEO:  Your car reaches filth equilibrium.



STEVE:  A dirt equilibrium where it's just like, okay.  And then when you get used to that it's like, okay, looks fine to you.  Neighbors are like, who is this guy?



LEO:  Well, as long as they don't start writing stuff in the dirt, you're all right.



STEVE:  I actually used to be known by my local car wash people.  They were really neat, and they took good care of me.  I haven't seen them in a year because...



LEO:  Yeah, me neither.



STEVE:  ...I don't want them in my car.



LEO:  No, exactly.  You know, there's things you can do without.  It's not the end of the world if you don't get a car wash.



STEVE:  But Leo, it is so cool when a tank of gas lasts six months because that's like a whole new thing.  You don't have gas, I realize, any longer.  But many of us still do.



LEO:  I remember making a note back in November when I got the Audi filled up.  I thought, this is the last time I'm going to a gas station.  That was kind of a wild thought, yeah.



STEVE:  So we got some interesting stuff for our 805th episode of February 9th.  This is - I wanted to call it Super Tuesday, but it's Patch Tuesday.  So we'll be talking about what happened today next Tuesday.  But we've got a collection of interesting and some engaging news surrounding Google's Chrome browser.  I was going to use the word "trifecta," but that apparently only applies to betting.  So instead it's just a trio.  We're also going to look at a high-profile Windows Defender misfire.



We have a couple new WordPress plugin nightmares, and maybe a suggestion for those of our listeners who have WordPress and can't get away from it for whatever reason.  We're also going to check in on the world of DDoS attacks inspired by a particular media server.  Plex has a problem.  It's turned out that the bad guys have found, I don't remember now how many thousands, but many tens of thousands of Plex server protocols online, and have figured how to bounce traffic off of it to add it to their DDoS attacks.  But it also gives us a chance to sort of check in on where the industry is in DDoS.  And the numbers are sort of daunting.



We've also got three new critical vulnerabilities found in SolarWinds software.  And the way they've been found and what it means about the things that haven't been found in other software I think is significant.  So we're going to talk about that.  We've got some closing-the-loop feedback from our listeners.  I'm going to give a quick update to my past week's work with SpinRite, heading toward the next one.  And then I just want to finish with the issue that titled this podcast "SCADA Scandal."  S-C-A-D-A is of course the acronym or the abbreviation for the industrial control system technology that runs pretty much everything.  There was a near miss that occurred in a little town in Florida last Friday.



LEO:  Was that a SCADA system?



STEVE:  Yeah.



LEO:  I didn't know that.  Ah.



STEVE:  Yeah.  And, boy, I hope it serves as a wakeup call because there are, like, several things wrong with this story.  I mean, like with the facts which are true about the story, the things that should not be the case.  So I think an interesting discussion about that.  And of course we have a fun Picture of the Week for our - I was going to say for our listeners, well, not so much.  Mostly for our viewers.



LEO:  Yeah.  We'll subtitle this one "Why You Don't Want More Lye in Your Water."



STEVE:  Yeah.



LEO:  Wow.  I didn't - oh, good.  I can't wait.  I'm fascinated to hear this story.  On we go with your Illustration of the Week, your Picture of the Week.  I'm going to show its original source because I recognized it immediately, the great talents of Randall Munroe at xkcd.  I love his stuff.  And this one's right on.



STEVE:  Anyway, so what we have is an industrial-scale Venn diagram with the caption, "I have a hard time keeping track of which contacts use which chat systems."  And so we've got a large Venn circle of email, lots of people in there, with a large overlap between those users who are SMS because of course that's just simple messaging service.  Then we've got two little people all by themselves using AIM; remember that?  And also ICQ.  There's only one person in that circle.



LEO:  And that's still around, I found out the other day.  I'm stunned.



STEVE:  No kidding.



LEO:  Yeah.



STEVE:  Wow.  I had a really low numbered ICQ account.



LEO:  I still do.



STEVE:  Because by some weird account - yeah.  Anyway, we've got Skype, Slack, iMessage, Facebook Messenger, Instagram DMs, Twitter DMs, Zephyr, BBMs.  I guess that's what - BBM.  That was Blackberry.



LEO:  Blackberry Messenger, yeah.



STEVE:  WhatsApp, IRC, Signal, Hangouts, Snapchat, WeChat...



LEO:  I was on every one of these, I think.  Oh, I was never on WeChat.



STEVE:  God.  And so, Leo, actually the Venn diagram could not  be stretched to include you in all of these circles because you're in too many of them.



LEO:  I'm in all of them.



STEVE:  It's got, like, Zephyr.  Oh, also we have "the chat tab in an old Google Doc" was one of them.



LEO:  We use those every day on the shows.



STEVE:  There's two people there.  And then we have someone writing on the wall of a bathroom, so there's that chat mode.  Apache Request Log, a Telegram, I mean, anyway, so a lot of fun with this.  And just but it's true, you know, the problem with being so heterogeneous is it's annoying when you've got people spread all over the place.  I'm not sure why - oh, I was going to say I'm not sure why Rasmus and I were not using iMessage because I think he's an iPhone person, because we were using it when we were synchronizing in Sweden during our European trip to talk about SQRL.  But it's because Signal has a desktop client, and one of my biggest annoyances with Apple is that they're hostile to anything that's not iOS or Mac.  So Signal was something that we were able to use.



But there's, again, a sort of an example of sometimes you're pulled to a different application because you need to do something that the one you're using doesn't support for whatever reason.  Anyway, just a fun observation that - and we were just talking about, as people are abandoning WhatsApp because they're concerned about the change of its privacy terms, they were moving to Signal.  And we talked about last week there was some guy, or I guess it was the week before, some guy saying, yeah, I switched to Signal.  And he's like looking around, there's nobody here.  I don't know anybody who also uses Signal.  So, yeah.



Okay.  There were three things that all happened last week affecting Chrome.  First off, at the end of the week, actually I think pretty much everything was Thursday.  Saying only that the extension contains malware, Google unceremoniously removed an extremely popular Chrome extension known as The Great Suspender.  And if nothing else it deserves a note for its name.  They pulled it out of the Chrome Web Store and caused two million plus of the Chrome browsers, where it had been previously installed, to immediately remove it from themselves.



The Great Suspender was very popular with those wishing to run Chrome in memory-lean environments.  Chrome tabs are known to consume a great deal of RAM.  And The Great Suspender's claim to fame was that it could suspend tabs and release their memory back to the system while kind of keeping the tab there as a placeholder so that it wouldn't cost the user any RAM, but they would sort of have the comfort of there being a tab there that they knew they could go click on.  It would have to reload the whole thing.  But still, that was what The Great Suspender did.



Last November, things began to turn sour in Great Suspender land.  It was an open source app that was hosted on GitHub.  And a November 3rd posting on GitHub which was the beginning of a thread which garnered 449 comments started off with the TL;DR saying - so this is November 3rd, so we're turning the clock back from what just happened on Thursday.  The person who began the thread said:  "The old maintainer appears to have sold the extension to parties unknown, who have malicious intent to exploit the users of this extension in advertising fraud, tracking, and more."



He said:  "In v7.1.8 of the extension, published to the web store but not to GitHub, arbitrary code was executed from a remote server, which appeared to be used to commit a variety of tracking and fraud actions.  After Microsoft removed it from Edge for malware, v7.1.9 was created without this code.  That has been the code running since November, and it does not appear to load the compromised script.  The malicious maintainer remains in control, however, and can introduce an update at any time."



LEO:  That's the problem.  That's the problem.



STEVE:  Yes.



LEO:  The updates aren't screened.



STEVE:  Correct.  Well, there's just too much, as we know, Leo.  I mean, if you look at what's on the Play Store now, it's completely out of control.  On the other hand, it's wide open, and lots of opportunities there.



Okay.  So the more detailed discussion that followed I thought was interesting.  And I've sort of excerpted some of the best bits of that.  The original developer was a person, @deanoemcke, I guess, it's D-E-A-N-O-E-M-C-K-E.  So I'll just got with @deanoemcke.  So it was said that he chose to step back from the extension last June of 2020.  As a replacement maintainer, he chose an unknown entity who controls the single-purpose @greatsuspender GitHub account.



They wrote:  "Much was suspicious about this change, including mention of payment for an open-source extension, and complete lack of information on the new maintainer's identity.  However, as the new maintainer did nothing for several months, it was originally believed that there was a failed transfer.  In October 2020, the maintainer updated the Chrome Store package.  The update raised red flags for some users because the changelog was not modified, and there was no tag created in GitHub.



"On investigation, it appeared that the extension was now connecting to various third-party servers, and executing code from them.  This led a few users to panic.  However, on closer investigation, it appeared that the third-party servers were part of an alternative to Google Analytics, and the changes shipped along with a new, though unexplained, tracking deactivation.  It appeared that deactivation worked.  We would later discover that this was wrong.  The discussion continued, however, because the new update also requested additional permissions, including the ability to manipulate all web requests."



As we know, we've talked about this in the past about Chrome.  This lets the extension do whatever it pleases - inserting ads, blocking sites, forcible redirects, whatever.  This change was supposedly in order to enable new screenshot functionality, but that was unclear and probably shouldn't be needed.



"Furthermore, the Web Store extension," they wrote, "has diverged from its GitHub source.  A minor change in the manifest was now being shipped on the Chrome Web Store, which was not included in GitHub.  This is a major concern, though again it has a possible innocent explanation.  While some think it is illegal, given the license on the code, this may not be a GPL violation.  Because the minified script is not part of the extension, the license does not apply to it.  Because of Web Store rules, the extension itself can be unpacked and inspected in full human-readable form, likely satisfying the copyleft restrictions.



"As a final red flag," they wrote, "no part of the Web Store posting has been updated to account for this.  @deanoemcke remains listed as the maintainer, and the privacy policy makes no mention of the new tracking or maintainer.  It has been several months since the transfer, but almost nothing reflects that change.  @deanoemcke did respond to the thread after a significant delay.  He confirmed much of what is above, including that the secret changes are limited to analytics and are disabled by the flag.  However, he hasn't yet clarified what his relationship or basis of trust with the new maintainer is, nor has he explained why the initial post mentions a 'purchase.'



"On November 6th, someone named @lucasdf discovered a smoking gun that the new maintainer is malicious.  Although Open Web Analytics is legitimate software, it does not provide the files executed by the extension.  Those are hosted on the unrelated site http://owebanalytics.com, which turns out to be immensely suspicious.  That site" - it's written here in GitHub - "was created at the same time as the update and is clearly designed to appear innocent, being hosted on a public web host and being given a seemingly innocent homepage from the CentOS project."  Yes, Leo.



"However, the site contains no real information other than the tracking scripts, appears to have been purchased with bitcoin, and is only found in the context of this extension.  Most importantly, the minified JavaScript differs significantly from that distributed by the actual OWA," the Open Web Analytics project.



So anyway, I'll finish quoting this writer by observing that he's being extremely kind in his description of this clearly bogus owebanalytics.com site, which shows this CentOS page.  So I went over, I was curious, to http://owebanalytics.com to take a look around.  First of all, it's http, not https.  So I thought, ah, I should probably switch that to https to see what its certificate looks like.  Well, the certificate has a 90-day life, so we wouldn't be surprised to learn that it is signed by Let's Encrypt.  But what's weird is that the common name on the certificate is cdn.owebanalytics.com.  And that doesn't have an IP address associated with it, and a website.  So I was thinking, maybe the article was wrong, and the actual domain was cdn.owebanalytics.com.  But as I said, there's nothing there.  So the common name doesn't match.



Anyway, I've got a link to the thread for anyone who's interested.  And as you immediately responded, Leo, this is sort of generally a problem with extensions overall is that they often have a long history.  They acquire a bunch of users.  And it's possible for them to sort of go sideways.  But it's easy to imagine that some party with less than completely charitable intentions might offer someone, who originally developed and has been thanklessly maintaining a free browser extension that's been steadily growing in popularity through the years, some cash to buy them out of their thankless maintenance role.



And you can see how that might be an appealing opportunity after many years of tireless effort.  The seller, who likely still feels some responsibility for their project, hopes that it's all going to work out and wouldn't want to disparage the project's new owner.  Yet there's probably some reason why control of a well-regarded and highly used open source extension was worth some money to its purchaser.  And indeed there were some activities discussed back in November, as I noted, that appeared to provide some hint of what was to come.



So we don't know what finally happened to trip an alarm to cause Google to yank the extension completely from the Chrome Web Store.  But the writing was certainly on the wall.  And we've talked before about web browser extensions being allowed to have the power to filter and modify all web content, not just through them, but all web content coming to and from the browser.  As we know, something like uBlock Origin needs to do that.  It's not just running on a single tab.  It's an extension which is extending the browser as a whole.  So that certainly presents a sobering danger.  We know that Chrome has made policies, we've talked about this in the past, where extensions need to have some reason for performing this sort of behavior.  They also need to be fully reverse engineerable by anybody who wants to see what a minified script is doing.  They need not to be obfuscating themselves to an unusual degree.



So anyway, the GitHub thread did note at the end that The Great Suspender has been removed from the Chrome Web Store.  They said:  "To recover your tabs, see issue #526."  It turns out this has been an issue in the past.  They said:  "The code in the GitHub repository is currently safe.  The most recent tagged release happened before the transfer of ownership."  And they wrote:  "To use that version, and avoid needing to finagle URLs, enable Chrome Developer Mode, download and extract a copy of the code" - meaning from GitHub - "then navigate to your extensions menu and select Load Unpacked Extension."



So if anybody has been inconvenienced by this, or you want The Great Suspender, it is still available.  And I guess that's sort of a side effect benefit of whoever it was who took this over never bothering to port their changes back to GitHub.  Actually, they should have been created on GitHub and used from that.  But anyway, let's hope that whoever purchased the extension lost money on the deal and that they and others will be disincentivized from attempting to purchase and subvert other browser extensions.



What we've just witnessed is a worrisome reality of our current web browser ecosystem.  I know that I and many of our listeners rely heavily on extensions, both for Chrome and Firefox.  And I would never want to have to use browsers without them.  But it is the fact that we're often using extensions that are developed by people who love them, like the guy who did uBlock Origin, Gorhill, who seems like a grumbly old curmudgeon.  But I'm sure glad that he cares as much as he does, and I appreciate his efforts.



The second thing that happened in Chrome Land was that on Thursday, Tenable and Microsoft both provided information about the otherwise under-mentioned, to put it lightly, update to Chrome that occurred also on Thursday.  Tenable's posting explained what they know, and I'll extract a couple bits from what they wrote.  I have a link to their full posting in the show notes.



"On February 4th, Google published a stable channel update for Chrome Desktop," Tenable wrote.  "This release contained a single security fix to address a critical zero-day vulnerability that had been exploited in the wild.  The vulnerability is a heap buffer overflow vulnerability in Chrome's V8 engine whose discovery is credited to Mattias Buelens.  He reported the flaw to Google on January 24th.



"Google noted that they are 'aware of reports that an exploit' for this vulnerability 'exists in the wild,'" they wrote, "which we interpret to mean that in-the-wild exploitation attempts have been observed.  Google's bug report for the vulnerability is unsurprisingly restricted to allow users time to apply the relevant patch," meaning the update to Google.



"In an interesting timing," they said, "this flaw was disclosed to Google just one day before a significant revelation from Google.  On January 25th, Google's Threat Analysis Group (TAG) published a blog posting detailing the discovery of an ongoing campaign" - which we'll talk about in a minute, it's sort of really fascinating - "conducted by nation-state actors believed to be in North Korea, which is targeting security researchers who are interested in collaborating on vulnerability research."  In other words, unwittingly collaborating.



"The report specifically mentioned that the threat actors circulated a link to their potential victims to a malicious website that led to successful exploitation on systems that were fully patched at the time for both Windows and Google Chrome.  This was corroborated by Microsoft, which published their own blog post about the attacks, surmising that the Google Chrome zero-day was likely used to target researchers."  Meaning North Korea had set up a full false flag operation targeting other security researchers.  What Microsoft discovered and shares is amazing and kind of horrifying.



Microsoft said:  "Over the past several months, the Threat Analysis Group has identified an ongoing campaign targeting security researchers working on vulnerability research and development at different companies and organizations.  The actors behind this campaign, which we attribute to a government-backed entity based in North Korea, have employed a number of means to target researchers which we will outline below.  We hope this post will remind those in the security research community that they are targets of government-backed attackers and should remain vigilant when engaging with individuals they have not previously interacted with."



Microsoft wrote:  "In order to build credibility and connect with security researchers, the actors established a fake research blog and multiple Twitter profiles to interact with potential targets.  They've used these Twitter profiles for posting links to their blog, posting videos of their claimed exploits, and for amplifying and retweeting posts from other accounts that they control.  Their blog contains write-ups and analysis of vulnerabilities that they have publicly disclosed, including guest posts from unwitting legitimate security researchers, likely in an attempt to build additional credibility with other security researchers."



They said:  "While we are unable to verify the authenticity or the working status of all of the exploits that they have posted video of, in at least one case the actors have faked the success of their claimed working exploit.  On January 14th, 2021, the actors shared via Twitter a YouTube video they uploaded that proclaimed to exploit CVE-2021-1647, a recently patched Windows Defender vulnerability.  In the video they purported to show a successful working exploit that spawns a command shell, but a careful review of the video shows the exploit is fake.  Multiple comments on YouTube identified that the video was faked and that there was not a working exploit demonstrated.  After these comments were made, the actors used a second Twitter account" - which by the way they also control, but pretending that they don't - "to retweet the original post and claim that it was not a fake video.



"The actors have been observed targeting specific security researchers by a novel social engineering method.  After establishing initial communications, the actors would ask the targeted researcher if they wanted to collaborate on vulnerability research together, and then provide the researcher with a Visual Studio Project.  Within the Visual Studio Project would be source code for exploiting the vulnerability, as well as an additional DLL that would be executed through Visual Studio Build Events.  The DLL is custom malware that would immediately begin communicating with actor-controlled command-and-control domains.  An example of the VS Build Event can be seen in the image below."  And they provided that in their posting.



"In addition to targeting users via social engineering, we have also observed several cases where researchers have been compromised after visiting the malicious actors' blog.  In these cases, the researchers followed a link on Twitter to a write-up hosted on blog.br0vvnn[.]io; and, shortly thereafter, a malicious service was installed on the researcher's system and an in-memory backdoor would begin beaconing to an actor-owned command-and-control server.



"At the time of these visits, the victim systems were running fully patched and up-to-date Windows 10 and Chrome browser versions.  At this time we're unable to confirm the mechanism of compromise, but we welcome any information others might have.  Chrome vulnerabilities, including those being exploited in the wild" - that is, ITW, in the wild - "are eligible for reward payout under Chrome's Vulnerability Reward Program.  We encourage anyone who discovers a Chrome vulnerability to report that activity via the Chrome VRP submission process."



And of course note that it is now believed that this was just patched, this was the just-patched Chrome zero-day that was being used to compromise the systems of trusted security research collaborators.  So they finish, saying:  "These actors have used multiple platforms to communicate with their potential targets, including Twitter, LinkedIn, Telegram, Discord, Keybase and email.  We are providing a list of known accounts and aliases below."  Which they did in their disclosure.



They said:  "If you have communicated with any of these accounts or visited the actors' blog, we suggest you review your systems for the indicators of compromise (IOCs) provided below.  To date, we have only seen these actors targeting Windows systems as a part of this campaign.  If you are concerned that you are being targeted, we recommend that you compartmentalize your research activities using separate physical or virtual machines for general web browsing, interacting with others believed to be in the research community, accepting files from third parties, and your own security research."



So, wow.  So here was a high-end, focused, deliberate, multi-month campaign launched by, it's believed, malicious actors in North Korea that put together an entire fake front, looking like one of the growing number of security research groups who were then reaching out to the real research community, opening up invitations to collaborate.  They were running a blog.  They were faking videos of things that they had accomplished for themselves, engaging the research community, and using two different methods in this case, one a malicious Visual Studio project that had an extra little DLL of malware that would launch when you launched the project.



And then separately, using a previously unknown at the time that was effective against fully patched Windows 10 and Chrome, a zero-day, to compromise the systems of people who clicked on a link that was posted in one of their Twitter feeds.  So I guess the moral of this one would be you just can't be too careful.  Security researchers hopefully are sandboxing their own research systems.  I would imagine they would be, you know, off from the rest of their networks, because they are going to be doing research that is highly vulnerable.  I remember back in the day when I was first looking at viruses on DOS systems, back when viruses lived on floppy disks because that was the only way they could go around.  This was all pre-network and pre-Internet.



LEO:  Yeah.  We had a machine painted bright red in the studio at The Screensavers that we would try things like Melissa on.  And of course in those days air-gapping a computer was pretty common because, you know.  But this was air-gapped and bright red so that nobody would be tempted to use it.



STEVE:  Yeah.



LEO:  It's a little harder now.



STEVE:  Yeah.  So our third story, and this is really interesting.  This one was carried by every security-related news outlet last week.  It's just sort of an interesting twist.  The discovery of a unique use of Chrome's sync feature for command-and-control and data exfiltration.  Also last Thursday a Croatian security researcher - who I'm certain would appreciate just being referred to by his initials BZ rather than have me attempt to pronounce his name, which has no vowels.  Last Thursday, he discovered that a malicious Chrome extension was abusing the Chrome sync feature as a way to communicate with a remote command-and-control server to exfiltrate data from infected browsers.



As we know, multiple Chrome web browsers, which are logged into the same Google account, will automatically share and synchronize their configuration settings - tabs, favorites, extensions, browser history and so forth.  Each browser connects to the Google mothership to check in.  And then Google hands out updates as needed to whichever other browsers may check in while logged into the same account.



So what's sort of diabolically clever about this is that this communication, which will be encrypted under Google's own security certificates because the Chrome browser is contacting, I think it's client4.google.com, would typically go completely unnoticed by anyone.  It would slip right through any corporate firewalls.  Data could be encoded, for example, into long Base64-encoded URL tails, and Google would simply send them out to other browsers that are logged into the same account.



So this researcher in Croatia whose initials are BZ said that the incident he investigated found that attackers gained access to a victim's computer.  But because the data they wanted to steal was inside an employee's portal, they downloaded a Chrome extension onto the user's computer and loaded it via the browser's developer mode that we were just talking about before for The Great Suspender.  The extension, which posed as a security add-on from security firm Forcepoint, contained malicious code that abused Chrome's sync feature as a way to allow attackers to control the infected browser.  In this way, the extension could be used as an exfiltration channel from inside corporate networks to an attacker's remotely located Chrome browser instance, or as a way to remotely control the infected browser from afar, thus bypassing any local security defenses.



BZ explained that blocking access to the Chrome sync server at client4.google.com would not work because that domain is used for many other things, such as Chrome, to detect an Internet connection.  So instead of doing that, BZ urges companies to use Chrome's enterprise features and group policy support to block and control what extensions can be installed in the browser to prevent the installation of rogue extensions like the one he investigated.



And actually, I would say that would be a useful belt-and-suspenders approach.  I haven't looked into this, but presumably we all have group policy controls in our systems.  And if it's possible to use group policy to block Chrome from installing anything that you don't deliberately install, that would seem to be a useful thing to do for anyone who wanted to harden their Chrome install.  It's certainly useful in an enterprise environment.  But it would probably be equally applicable for individual users.



I reached up and restarted those three machines.



LEO:  Oh, they're blinking.



STEVE:  So those watching will be glad to know that the lights are flashing again.



LEO:  Our audience is really interesting.  They're very focused, not just on the show, but on all of the details.  So when my machine stops or, you know, last week they said, "What's the deal with Steve's lights?  They're not blinking."  If this clock is not here, they get all upset.



STEVE:  Well, and Leo, I'm sure both of us recognize that all of the talking heads on TV now are talking from their homes.



LEO:  I love that.  I do the same thing.



STEVE:  And so it's really, you know, you're like looking around, read the books, see what the books are.  Oh, yeah.



LEO:  I love doing that.  You know what, I hope we don't go back to the old way.  Don't go to the studio.  Everybody should just stay home.  We've got the technology.



STEVE:  So following on the heels of this Chrome news, we have the little whoopsie that Defender, Windows Defender, thinks Chrome is malware.



LEO:  Well, it kind of is.



STEVE:  Yeah.



LEO:  It may not be completely wrong after those three stories.



STEVE:  Yeah, with a subhead of "No good deed goes unpunished."  No sooner had Google quickly updated Chrome last week to remove the zero-day flaw in its V8 engine, which as we know is being actively exploited in the wild to attack security researchers, than Microsoft's Enterprise version of Windows Defender decided that Google's modifications were malicious.



LEO:  Oh, that's hysterical.



STEVE:  The high end, Microsoft Defender Advanced Threat Protection (ATP), which is the commercial version of the otherwise ubiquitous Defender AV which we're all using in our Windows machines, and that's Microsoft's premier enterprise security solution, it was having a bad day and labeled Google's browser update a trojan, a backdoor trojan.  Based on Twitter reports posted by dismayed sysadmins, Defender ATP was detecting multiple files which are part of last week's Chrome, it was v88.04324.146.  And I noticed I was already at 150.  So they've tweaked it again since.



They said it was containing a generic backdoor named - it was a PHP backdoor, PHP/Funvalget.A.  Though this might have normally been met with somewhat more calm, of course in this case Defender's alerts raised some alarm and quite a bit of stir in enterprise environments due to the recent multiple software supply chain attacks that we've all been made quite aware of recently.  So sysadmins were awaiting a formal statement from Microsoft to confirm that the detection was indeed a false positive and nothing to worry about.



Fortunately, the built-in, no-charge, free version of Microsoft Defender AV that we all have in our personal Windows 7, 8, and 10 machines, was not suspicious of this new release of Chrome, which on one hand is fortunate, or it would have been a far more widespread mess.  But it does make one wonder about the detection differential between Microsoft's commercial and the consumer AVs.  Why exactly did the enterprise AV freak out, whereas the consumer AVs remained quiet?  Does that mean we're getting less protection on the consumer AVs?



Anyway, Microsoft did later confirm that this Funvalget trojan, PHP trojan, for those Chrome files, were indeed a false positive, due to what Microsoft termed "an automation error."  I guess that's technically true, whatever the heck that means.  And I suppose they needed to call it something because calling it what it really was, a false positive, probably couldn't get past the PR folks at Microsoft.  Like no, no, no, no, you can't call anything a "false positive."  Come up with some other name.  That would be, what, in fact it's just kind of an automation error.  Oh, yeah, that's fine.  No one will know what that means.



So I should mention that over the past few years I have had to exclude my local Windows Defender from poking into many of my own development directories.  Unless I do that, shortly after I build a new executable from source, Defender will slide up a red warning from the lower right of the screen, saying not to worry, it's all good, Defender has found and removed the threat that just appeared.  Of course that's my own code, just freshly built from source.  So it couldn't be any cleaner.  And recently they've all been, like the work that I've been doing has all been DOS executables.



And I noted previously that if, you know, if any malicious trojan were actually to find itself running in DOS, which it probably couldn't even do these days, it would not be happy.  What must be upsetting Defender, because I'm having now to whitelist all the work that I'm doing, it must be that it's the lack of digital signatures on my freshly built EXEs.  We've seen through experimental evidence that Defender now places a lot of weight upon the reputation of the certificates which sign today's executables.  It's gotten to the point where it's difficult to keep Defender from complaining when any executable is not signed.



LEO:  That must be a problem for all developers.  That's ridiculous.



STEVE:  Yeah.  It absolutely must be.  I mean, it's just - it's crazy.  I mean, these things have become...



LEO:  They're EXEs?  They're not .coms?



STEVE:  Yeah, they're EXEs.  Which is I'm sure what Defender looks at and immediately digs into.  And so think about how - we know how many bazillion different malicious things they're looking for.  And so it's just going to be the case that somewhere in an EXE there's going to be a collision of some little fingerprint that matches enough to upset Defender.  And then it looks and sees, oh, and look, there's no signature.  Well, when in doubt, protect the user.



And of course today we know that Windows refuses, Windows itself, the OS, refuses to load any unsigned device drivers into its kernel.  Device driver signing is no longer optional.  Developers can force the issue by disabling Windows driver signing enforcement, as it's called.  But I'll bet that the way things are going, we're not far from the day when Windows will be elevating that requirement to the desktop.  And, boy, that'll cause a big uproar.



LEO:  Well, Apple does that already.  Apple's already doing that, yeah.



STEVE:  Yes.  Yeah.  And I don't think we're far away from that in Windows.  There might be something like a UAC dialog that users are forced to push past whenever they wish to run any unsigned executable.  And that would of course, from a social engineering standpoint, that would tend to cause developers to start signing their EXEs.  The problem is certificates are not free.  There is no "Let's Sign" equivalent of Let's Encrypt.



LEO:  Apple has two layers.  They have signing and notarizing.  And they will not open an app that's not notarized unless, you know, you have to know how to jump through hoops.  It's not even a UAC escalation.  You have to actually jump through hoops to get the thing opened.  Their gatekeeper is very aggressive.



STEVE:  Oh, yeah, UAE.  I mean UAC.



LEO:  UAC.  I don't know.  Did you say UAE?  I said [crosstalk].



STEVE:  I have UAE in my show notes.



LEO:  Oh, okay.  UAC.  All right.  We both got it wrong.  You know, I don't want to derail you, but it must be - how do you develop a program like SpinRite, which is a DOS program, you know, the normal cycle for development is you write, compile, and run; write, compile, run.  But for you, you can't - you're writing and compiling on Windows; right?  Or are you working in DOS?



STEVE:  No, I am, I'm testing under DOS; but I am writing and assembling.  And it turns out it was surprising difficult to do this.



LEO:  I bet. 



STEVE:  Because I have some tools which have been abandoned, and they're 16-bit tools.  I found this thing called vDos.  There's like DOSBox, and there's, you know.  And of course there's Virtual Box, and there's a bunch of things.  But there's one funky thing called vBox EXE.



LEO:  So it lets you run DOS in a virtual machine.



STEVE:  Yes.



LEO:  Ah.



STEVE:  Yes.  And it's funny because when you launch it, it will read a config.sys and an autoexec.bat from your current directory.



LEO:  Oh.



STEVE:  So what I did was...



LEO:  You automatically launch SpinRite.



STEVE:  Well, no, no.  Here's I'm just building, so I have to do my linking.  I use a 16-bit linker in order to link 16-bit DOS code.  And then I use a program to process my symbol files for the DOS debugger, which is only 16-bit code.  It was called Periscope, and it was...



LEO:  I remember Periscope.



STEVE:  ...written by a guy named Brett Salter, who unfortunately passed away a few years ago.  I reached out to Brett to say hey, believe it or not, Brett, I'm still using Periscope, and it turns out he's not still breathing oxygen.



LEO:  I remember his name.  Wow.



STEVE:  Yup, yup.  And then I also contacted Bob Smith, who was the author of 386 to the Max.  It was my favorite memory manager back then.



LEO:  You're still using that?



STEVE:  Yup.  And Bob is still around.



LEO:  Wow.  So that's interesting.  That makes sense.  So at least you can do it all on the same machine.



STEVE:  Yes.  So I'm doing it all on the same machine.  And then the problem I recently had was that in order to be in DOS, I want to debug with symbols.  So the DOS box needs access, I mean, I want to debug with source. 



LEO:  Right.



STEVE:  So the DOS box needs access to the source code.



LEO:  And the symbol tables, yeah.



STEVE:  So for a while I was loading the whole Windows for Workgroups 3.1 IP stack in DOS and running a Windows for Workgroup client in order - and then I would use share to map the development directory into the C drive under DOS so that the code running there could see the source code on my Windows machine from in DOS.



LEO:  Wow.



STEVE:  Well, that all worked - and that's how I developed ReadSpeed.  That all worked until I started working on SpinRite 6.1 because SpinRite itself is way bigger.  ReadSpeed was 19K.  And so that was no problem.  SpinRite is a couple hundred K.  And so the problem was the full DOS network stack took up way too much memory, along with the debugger and its symbol table, which was itself 160K.  So there wasn't enough room.



Fortunately, one of the guys in the GRC SpinRite dev group had done some work and played around with using a packet driver.  Instead of using the TCP/IP stack and then Windows for Workgroups 3.1, there are packet drivers for all these old network adapters.  And the packet driver is super tiny, but all it is is just packets.  So it turns out someone created - there's an FTP server, an FTP client, but also the equivalent of Wget.  There's an HTTP GET command which is transient.  So now my build process under Windows, whenever I do a build, and it's just an Alt+A, assembling, it just takes - it's like instantaneous. 



LEO:  Sure.



STEVE:  So I just use it for syntax [crosstalk].



LEO:  Oh, yeah, all the time, yeah, yeah.



STEVE:  I'm building constantly.  Every time I do that, it zips all of my assembly code and the header files into an sr.zip.  And then when I switch over and run the debugger, the act of starting the debugger launches the HTTP GET in order to pull, using the packet driver.  Now I've got 400K of RAM because I got rid of all of the IP stack in Windows for Workgroups.  So it pulls the zip over, uses PKUNZIP, Phil Katz's old UNZIP, in order to unzip the files into an assem directory in DOS.  And then the debugger says, oh, look, here's all the source code.  So believe me, Leo, when I move, when I finally say goodbye to DOS and the BIOS, and I switch to SpinRite 7, where I'll be operating under a 32-bit mode, I mean, it's just - it's barely possible to still develop this way.  I mean, I'm having to get very creative.



LEO:  I'm impressed as hell.  That's amazing.



STEVE:  In order to do that.



LEO:  That's amazing.  Wow.



STEVE:  It does work, yeah.



LEO:  See what he does for us, folks?  Nice job, Steve.  Thank you.



STEVE:  So anyway, we do have another critical WordPress plugin problem, and I have a suggestion for anyone - I will end this with a suggestion for anyone who is still using WordPress.  In this case, we have now more than 800,000, .8 million, WordPress sites vulnerable to - I gave myself the hiccups by not breathing while I was just talking here.



LEO:  I don't blame you.



STEVE:  I get so excited about SpinRite.



LEO:  People say, "Why is Steve still using those old operating systems?"  Now you know why.  You don't want to go to Windows 10 because it's just going to - what a nightmare it's going to create.



STEVE:  Yeah.  And under XP everything still worked because it still ran 16-bit code.  I was still using Brief. 



LEO:  I know, I know.



STEVE:  As my programmer's editor back then.



LEO:  Well, your fingers knew the way.



STEVE:  Yeah.  And with WordStar keystrokes because that was like the right way to do it back then.



LEO:  Little footnote on that.  The creator of MicroPro, the company that distributed WordStar, Seymour Rubinstein, died last week, in his late 80s, I think.  But he was kind of a legend down here in Sausalito as the man who put WordStar in the market.



STEVE:  Yeah.  And, boy, that was the word processor to use. 



LEO:  Yeah.  All right.  Hiccups are gone.



STEVE:  Okay, so, yes, thank you.



LEO:  I scared you with WordStar.



STEVE:  More than 800,000 WordPress sites all share a very popular plugin called NextGEN Gallery.  NextGEN Gallery allows sites to accept uploads of photos in batch quantities to import metadata and edit image thumbnails.  So apparently 800,000 WordPress sites think that's a good idea.  Whatever they're doing, they're wanting to use this plugin.  The bad news is that researchers discovered two CSRF (Cross-Site Request Forgery) flaws.  One is critical, and the other is high severity.  A patch was released to address the flaws in version 3.5.0 of NextGEN Gallery.



So first, if anyone who's listening to this is using NextGEN Gallery on their WordPress site, make sure that you've running 3.5.0 or later.  It's been available since the middle of last December, so the researchers had responsibly waited until yesterday, Monday the 8th, before publicly disclosing the details of the flaw, which are now public.  So that ups the ante on anyone's need to make sure they're running the most recent version.



Ram Gall, who is with WordFence, who we'll be talking about in a minute because I think this thing is worth taking a look at, he wrote in their disclosure of the vulnerabilities yesterday of, he said:  "A critical severity vulnerability that could lead to remote code execution and stored cross-site scripting vulnerabilities.  Exploitation of these vulnerabilities could lead to a site takeover, malicious redirects, spam injection, phishing, and much more."  So his description of the vulnerability demonstrates the competence of these guys.



He said:  "We initially reached out to the plugins publisher, Imagely, the same day, and provided full disclosure the next day, on December 15th, 2020.  Imagely sent us patches for review on December 16th, and published the patched version, 3.5.0, on December 17th."  So you couldn't ask for any better find, notify, full disclosure patch and update availability.  Of course the only thing missing from this cycle is, of those 800,000 people using it, because it is inherently publicly exposed, how many of them are now running 3.5.0.



Ram Gall said:  "Wordfence Premium users received firewall rules protecting against these vulnerabilities on December 14th, 2020.  Sites still running the free version of Wordfence, which is what I'm going to be recommending by the end of this, received these rules 30 days later, on January 13th."  But still a full month before public disclosure.  Well, no, wait a minute.  Public disclosure was yesterday, so three weeks.



He said:  "NextGEN Gallery" - this plugin - "is a popular WordPress plugin designed to create highly responsive image galleries.  It is clear the plugin's developer took care to integrate security in the code of the plugin.  NextGEN Gallery has a single security function" - the function name is is_authorized_request - "that is used to protect most of its settings."  And I've got a link to the full disclosure in the show notes where he shows this PHP function.  He said:  "This function integrated both a capability check and a nonce check into a single function for easier application throughout the plugin.  Unfortunately, a logic flaw in the is_authorized_request function meant that the nonce check would allow requests to proceed if the nonce parameter was missing, rather than invalid."  Whoops.  



"This opened up a number of opportunities for attackers to exploit a cross-site request forgery.  One feature of NextGEN Gallery is the ability for administrators to upload custom CSS files to be used to style galleries.  While the file uploaded had to end with the .css extension" - and you know where this is going, folks - "it was possible to upload arbitrary code with double extensions, in other words, file.php.css.  While these files would only be executable on certain configurations, such as Apache/mod_php with an AddHandler directive, this could still result in remote code execution on any vulnerable configurations.



"Unfortunately," he wrote, "it is also possible to achieve code execution even on configurations not vulnerable to double extensions.  NextGEN Gallery has a separate feature that allows users to specify how galleries are viewed via a 'Legacy Templates' feature" - why does that sound scary? - "which also uses the is_authorized_request function for security.  Thus, it was possible to set various album types to use a template with the absolute path of the file uploaded in the previous step, or perform a directory traversal attack using the relative path of the uploaded file, regardless of that file's extension, through a CSRF attack.



"This would result in local file inclusion and remote code execution, as the uploaded file would then be included and executed whenever the selected album type was viewed on the site.  Any JavaScript included in the uploaded file would also be executed, resulting in a cross-site scripting problem.  As a reminder, once an attacker achieves remote code execution on a website, they have effectively taken over that site.  Cross-site scripting can likewise be used to take over a site if a logged-in administrator visits a page running a malicious injected script.



"This attack would likely require some degree of social engineering, as an attacker would have to trick an administrator" - that is, just this final aspect - "into clicking the link that submitted crafted requests to perform these actions.  Additionally, performing these actions would require two separate requests, though this would be trivial to implement, and we were able to do so during our testing.  Finally, the site would require at least one album to be published and accessible to the attacker."



So that's what they posted.  And I'm impressed by these WordFence people.  We've run across them several times in the past year as WordPress problems have been receiving increased scrutiny, both from attackers and from security researchers.  So I'm glad that I am no longer running WordPress on any of my own servers.  But I understand that others may have little choice.  As I noted above, WordFence offers both a free and paid version of their WordPress firewall.  And if I had to be running WordPress, I would give WordFence a serious look.  They really do appear to be on the ball and quite worthwhile.



Since it is plugins that appear to be causing all of this trouble, if you happen to be running WordPress lean, with no plugins, then I would say it's a safe step to skip it.  But if you are a plugin user, and you just can't resist adding goodies to your WordPress installation, then I would definitely add one more.  I would add WordFence and then consider what their pricing structure looks like and whether it might be, depending upon your use of WordPress, if it's mission-critical, I think they were $99 a year for their full-paid, single-site protection.  And having these guys watching your back I think makes an awful lot of sense if you're a WordFence user.



I did want to just check in on DDoS attacks.  We haven't talked about DDoS for a long time, but last Thursday the site NETSCOUT posted a notice about the abuse of Internet-exposed Plex Media Servers and their SSDP protocol, which of course we've spoken of often.  SSDP is - I'm looking for it here in the notes.  It's the UPnP protocol, but I'm blanking on what it is.  I'll run across it here in my notes.  Anyway, we've not talked about DDoS for a while.  What NETSCOUT wrote I thought was interesting.



They said:  "Plex Media Server is a personal media library" - of course, as we know - "and streaming system which runs on modern Windows, macOS, and Linux OS."  I've got it running in my Drobos for a number of applications.  They said:  "...along with variants customized for special-purpose platforms such as network-attached storage devices, external RAID storage, digital media players, et cetera."  They said:  "Upon startup, Plex probes the local network using the [it's called] G'Day Mate (GDM) network/service discovery protocol to locate other compatible media devices and streaming clients.  It also appears to make the use of SSDP probes to locate Universal Plug and Play gateways on broadband Internet access routers which have SSDP enabled."



So once again, this is another reason for always disabling SSDP, the public side Universal Plug and Play, unless you know you need it.  They said:  "When a Universal Plug and Play gateway (UPnP) is discovered via this methodology, Plex attempts to utilize NAT-PMP to instantiate dynamic NAT forwarding rules on the broadband Internet access router."  In other words, to open a port to itself so that it is available and discoverable on the Internet.  And I have no idea why.  This is just insane.



On January 7th of this year, Baidu Labs, in a Chinese language weblog post, described a UDP reflection/amplification DDoS attack vector leveraging Plex Media Server instances running versions of the Plex software prior to 1.21.  In early February 2021, NETSCOUT Arbor were notified that reflection/amplification DDoS attacks appeared to be leveraging abusable Plex Media Server instances which were actively taking place on the public Internet.



Okay.  So first of all, the Plex Media Server has this functionality where, when it comes up, it will check with the gateway to see if your router has UPnP enabled, as they typically do now because it's a feature we can advertise, like all of those ridiculous protocol gateways that I talked about disabling last week, the web application protocol gateways.  In this case, it will find typically a Universal Plug and Play gateway, use SSDP (Simple Service Discovery Protocol) to talk to it, and arrange to map a port through to itself, presenting itself on the public Internet because what could possibly go wrong?



According to an announcement published on Plex's website on February 5th, Plex Media Server instances which had either been deployed on a public-facing network DMZ or in an Internet datacenter, or with manually configured port-forwarding rules which forward specific UDP ports from the public Internet to devices running Plex Media Server, or which are behind a router with UPnP operating, can potentially be abused as part of possible DDoS attacks.  So at least Plex is aware of this.  The problem is that how many Plex users are aware of this?



They said:  "These actions could have the effect of exposing a Plex UPnP-enabled service registration responder to the general Internet, where it can be abused to generate reflection amplification DDoS attacks.  In order to differentiate this particular attack vector from generic SSDP reflection amplification, it has been designated as Plex Media SSDP, or PMSSDP.  To date" - and get this - "approximately 37,000 abusable PMSSDP reflectors/amplifiers have been identified on the public Internet."



So yes, it's the default; right?  By default, it reaches out and checks for Universal Plug and Play.  By default, consumer routers have that enabled.  By default, it will create a mapping back to itself.  And as a consequence, 37,000 of these Plex Media Servers are poking their nose out onto the Internet, and now they're of interest to attackers.  They may not be able to log onto them or care what's there.  But there is a server which they're able to bounce packets, DDoS traffic off of.  And being SSDP, it is UDP.  Which means you don't have to have a TCP handshake.  UDP, as we know, is perfectly spoofable.  So you're able to lie about your source IP, send a packet there, and that device will bounce a larger packet back to presumably you, but if you've spoofed your IP, to your DDoS attack target.



So they said:  "Amplified PMSSDP DDoS attack traffic consists of SSDP, HTTP/U, meaning an HTTP protocol over UDP, responses sourced from ports 32414 and 32410, or abusable Plex Media Server instances and directed towards attack targets.  Each amplified response packet ranges from 52 bytes to 281 bytes in size for an average amplification factor of about 4.68 to 1."  So not a huge amplifier, but there's 37,000 of them sitting there on the Internet just hoping you're going to send a UDP packet off of them that they can increase in size and bounce toward your target.



They said:  "Observed single-vector" - so we're going to have the term "single vector" and "multi vector" now is the jargon of DDoS attacks.  "Observed single-vector PMSSDP reflection/ amplification DDoS attacks range in size from about 2Gb to 3Gb; multi-vector, meaning 2 to 10 vectors; and omni-vector, which is considered 11 or more vectors."  Meaning where vectors are different things that packets are bounced off of.  So the PMSSDP would be one vector among many.  So if attacks are only based on PMSSDP, that is, the Plex Media Server, those attacks are typically around 2 to 3Gb.  But there are multi-vector, 2 to 10 vectors, and omni-vector, 11 or more vector attacks, which incorporate now PMSSDP as one of their multiple vectors because again, 37,000, why not?  "Those range from the low tens of Gbps up to 218 Gbps."  So that is to say, more than one fifth of a terabit per second.



They said, this is NETSCOUT:  "As is routinely the case with newer DDoS attack vectors, it appears that after an initial period of employment by advanced attackers with access to bespoke DDoS attack infrastructure, PMSSDP has been weaponized and added to the arsenals of so-called booter/stresser DDoS-for-hire services" - booter as being booted off the Internet - "placing it within the reach of the general attacker population."



They said:  "To date, more than 5,500 PMSSDP" - meaning single-vector - "reflection/amplification DDoS attacks have been observed on the public Internet, leveraging approximately 15,000 distinct abusable PMSSDP reflector/amplifiers," meaning approximately 15,000 distinct Plex Media Servers.



They said:  "It should be noted that a single-vector PMSSDP reflection attack of 2 to 3Gb in size is often sufficient to have a significant negative impact on the availability of targeted networks, servers, and services.  The incidence of both single-vector and multi- or omni-vector attacks leveraging PMSSDP has increased significantly since November of 2020, indicating its perceived utility to attackers."  In other words, they've added the Plex Media Servers to their bag of tricks for these omni-vector/multi-vector attacks because, again, you've got tens of thousands of them, so why not?



And I'll just finish with the question, or answering the question, just how prevalent have DDoS attacks become these days?  To answer the question, BleepingComputer opened an email dialog with Richard Hummel, who's NETSCOUT's Manager of Threat Intelligence.  Richard wrote that:  "The total number of Plex Media SSDP attacks from January 1st to present day clocked in at approximately 5,700, compared to the more than 11 million attacks in total we saw during the same timeframe."  That was from January 1st of 2020, so that's a year and a month, or a year and a month and a half, 11 million DDoS attacks.  So, wow.  There are plenty of them.



So three more new vulnerabilities have been discovered in SolarWinds software.



LEO:  Three more.  What?



STEVE:  Yeah.  I hope this podcast's listeners are aware of the extremely disturbing fact that we keep encountering instances of what I'll term the principle of "Wherever we look, we discover new problems."  Today, problems are being discovered in two ways.  First, the old-fashioned way, where we discover malware in some system, then reverse engineer the malware to discover how it got in.  And we looked last week at the extreme measures the SolarWinds hackers went to in order to avoid exactly that form of reverse engineering.  Remember they, like, worked to decouple the execution of the malware with the way it got into the system.



The new modern way of finding vulnerabilities is apparently simply by looking closely at pretty much anything and discovering that, oh, look, it's full of security weaknesses.  Who knew?  It's this new second reality that has turned vulnerability discovery into a potential career.  Just find some company that has the wisdom to offer bounties for the discovery of their bugs, then take a close look at their code.  And before long, you can probably use cash to buy yourself a new car.



Last week another case illustrating this disturbing truth just came to light thanks to the many researchers who have been looking more closely for the first time ever at the code being shipped by SolarWinds.  Of course we know what motivated them to do so.  The whole security industry took a look at SolarWinds code to figure out what the heck?  So Trustwave's most recent security labs blog, posted last Wednesday, was titled "Full System Control with New SolarWinds Orion-based and Serv-U FTP Vulnerabilities."  For anyone interested, I've got the link in the show notes for the full posting.  I'll just excerpt two bits from it.



Martin Rakhmanov posted in the first person, saying:  "In this blog, I will be discussing three new security issues that I recently found in several SolarWinds products.  All three are severe bugs, with the most critical one allowing remote code execution with high privileges.  To the best of Trustwave's knowledge, none of the vulnerabilities were exploited during the recent SolarWinds attacks or in any in-the-wild attacks.  However, given the criticality of these issues, we recommend that affected users patch as soon as possible.  We have purposely left out specific proof-of-concept code in this posting in order to give SolarWinds users a longer margin to patch; but we will post an update to this blog that includes the proof-of-concept code on Feb. 9th."



Okay, now, he didn't give anyone much time.  This was posted last Wednesday.  Today is Tuesday the 9th; and sure as anything, the proof-of-concept code has been added to the blog.  So it's now public.  Yet another set of new ways of exploiting the SolarWinds code that was current as of last week.  There are now public proofs of concept for the following disturbing three new vulnerabilities.  SolarWinds Orion platform we have CVE-2021-25274, and they're sequentially numbered 275 and 276.



The first one, improper use of Microsoft Message Queue, could allow any remote unprivileged user the ability to execute any arbitrary code with the highest privilege.  Okay.  Doesn't get any worse than that; right?  Any unprivileged user remotely to execute any arbitrary code with the highest privilege.



The next one, SolarWinds credentials are stored in an insecure manner that could allow any local users, despite privileges, to take complete control of the SolarWinds Orion database, which is credential store is what it is.  From there, one can steal information or add a new admin level user to be used inside SolarWinds Orion products, essentially neutering all of its authentication; right?



And third, SolarWinds Serv-U FTP for Windows.  Any local user, regardless of privilege, can create a file that can define a new Serv-U FTP admin account with full access to the C root drive. This account can then be used to log in via FTP and read or replace any file on the drive.  This is unbelievable.



So it's really not here my intention to single out SolarWinds. Yes, they're currently and deservedly in the hot seat.  But we would be wrong to assume that we just happen to be finding all manner of serious problems with the only company whose offerings have recently been closely scrutinized; right?  The only sane assumption, until we learn otherwise, would be that the software published and in use widely by many other similar entities would crumble just as quickly, if and when it were to be subjected to a similar level of close expert scrutiny.



The entire industry just assumed that SolarWinds was sufficiently good and careful about network security in the beginning.  Which is what they were selling, after all.  Their whole offering is a security product.  And it probably said that somewhere on their website, that it was very secure, right next to their customer list, which has since been taken down, as I noted before.  So because such close expert scrutiny is expensive, no one is doing that to most of the industry's software.  There are exceptions like web browsers, which we talk about constantly, that are very intensely scrutinized because they're such a high-profile target.  But we now believe that highly skilled and talented Russian attackers were caught having closely scrutinized SolarWinds' systems and code.



But the evidence begs the question, what other software company's work has this same group also examined closely?  And what did they find?  Any sane person looking at the evidence would have to think with all the problems that are being found in SolarWinds products, it's probably not the case that there are not other similar products in other places that have not been carefully examined.  We talk about high-profile companies.  Cisco has constant problems with their stuff because people are looking at them.  But there are many other companies that are like SolarWinds, that are widely deployed, widely used, and no one is looking at their stuff.  The problem is bad guys may have an incentive to be doing just that.  Good guys don't have the incentive.  Good guys are busy doing other things.



So I will close the loop with three bits of feedback from our listeners.  Ndom91, who has a Twitter account and tweets under that moniker, said:  "@SGgrc Steve, I love you, your work, and the show.  But for the love of god, it's called 'lib' like 'libertine,' and not 'libe' like 'library.'"



LEO:  See, it is a library, though.



STEVE:  I know.



LEO:  I call it "lib," too, but I don't know if there's a correct pronunciation.  What's his assertion?  What's correct?



STEVE:  He's referring to the libgcrypt segment in Security Now! last week, 804.



LEO:  You've always said "libe," though.



STEVE:  I have always said "libe."



LEO:  Because it's short for "library."



STEVE:  I've also always said "jif," not "gif."



LEO:  I've always said "lib," only because that's how I've always read it, like libgcrypt.



STEVE:  Yeah.  And I've always said it "libe" because it's a library, not a lib-rary.  I didn't go to the lib-rary as a kid in elementary school.  I went to the library.



LEO:  But who's the guy who determines this?  There's no...



STEVE:  Yeah.



LEO:  I'll tell you what.  I've always said because we're saying it out loud, in many cases for the first time anybody's said it out loud except in private conversations, we get to decide what it is.



STEVE:  Yes.  Lorrie has formal medical training.  I'm trying to pronounce medical terms that I've only ever read.  And she's constantly correcting me, saying, uh, honey, it's pronounced this way.  It's like, oh.  Okay, fine.



LEO:  I've always said like "libsodium" or "libgcrypt."  But, you know, to each his own.  I wouldn't correct you.  I don't think that that's...



STEVE:  Anyway, if anybody else is like desperately upset with me for saying "libgcrypt," you've just had your day.  That's the end of it.  I'm not changing.  But at least it's been aired.  Meanwhile, Dave Stricker, tweeting from at @strickdd, said:  "You seem to be sending mixed signals on this week's SN.  In the past you've indicated that everything should have an auto-update mechanism.  This week it sounds like you don't trust them.  Is it just Notepad++ you don't trust, or is it because it prompts to update whereas Chrome does it in the background?"



And David, you're absolutely right.  This is one of those situations, I don't know what Catch number it is.  It's not exactly 22.  Things that are bad should be updated.  Things that are good should not be updated because they might go bad.  How's that?  Anyway, there's no good answer.  We're all screwed, basically.  But then - actually, that'd be a great name for the podcast, Leo.  Wouldn't it?  Welcome to We're All Screwed Podcast #805.



LEO:  Well, it's a little late for that.  I like Security Now!.



STEVE:  Might be hard to get advertisers.



LEO:  Yeah.



STEVE:  So, finally, AndyMan7 tweeting from @Man7Andy, says:  "Hello, Steve.  Big fan of Security Now.  I recall you mentioning a remote desktop management tool on one of the shows, but can't remember the name.  Would you help remind me what that was, and if you have any recommendations for a safer tool for IT people to do remote sessions to PCs?"  Okay.  I'm glad you asked, AndyMan.  The tool is simply called Remote Utilities. It is at www.remoteutilities.com.  And I continue to be so impressed with it.



Lorrie uses it constantly, literally continually, daily, to manage the array of remote laptops which are being used by her clients who are doing at-home neurofeedback training.  My tech support guy, Greg, who has a computer repair consultancy business on the side, has completely switched over to using it and has hundreds of machines under remote management.  And I'm increasingly using the system to manage several of my own machines.  It is an absolute win.  The other thing I love about it is that it is purchased once and is not a subscription.  And they offer a free license.



They said:  "Our free license allows you to add up to 10 remote computers in your Viewer address book.  You can use the license free in a business and personal setting.  Only one free license key is allowed per individual, company, or organization.  For more information, see our EULA."  And if you need more than that, their "buy it one time, use it forever" is also reasonably priced.  So anyway, I'm so glad you asked, Andy.  These guys really deserve a look.  Over in my blog on forums.grc.com I've created my own thread of my favorite things, just sort of a place to hold the things that I like most.  Sync.com is there.  Syncthing is there.  This, Remote Utilities, is there.  I just wanted a place to just state, these things deserve people's attention, and I think use.



So anyway, RemoteUtilities.com.  These guys are great.  And, boy, I mean, it's Remote Utilities because it's actually more than just a remote desktop thing.  You can do like remote registry, remote file transfer, a whole bunch of different things.  And lots of authentication.  I use the one-time password, a time-based one-time password compatible with any of the authenticators.  So, for example, when I'm connecting to one of my machines, I have to give a password and then a six-digit token which is part of, you know, I have the OTP Auth is my favorite OTP app on iOS.  So anyway, just can't say enough good things about them.



I did want to mention, I posted a long posting I'm not going to read here, yesterday to GRC's spinrite.dev group.  The subject was "Discovering System's Mass Storage Devices."  That's the screen that comes up.  It's mostly blank, with a little window in the middle that says "Discovering System's" on the first line, and then "Mass Storage Devices..." on the second line.  And then at the very bottom it has a flashing "Working."  Anybody who's ever used SpinRite is familiar with this screen.  I find that I still have a stress reaction to it because, if SpinRite was going to hang somewhere...



LEO:  That's where it would break.



STEVE:  That's where it would break.  And I'm sure that, if Greg has nightmares in his sleep, it's this flashing "Discovering System's Mass Storage Devices" because people complain:  "I started SpinRite, I was all excited, and I waited an hour."  Anyway, the reason I'm bringing it up is that I've just finished completely rewriting the code which is underneath that, is behind that.  



LEO:  That's probably a hard thing to do.



STEVE:  Well, and I didn't really intend to completely rewrite it. 



LEO:  You must use the operating system to do that.  Or no?  No, I guess you can't.  



STEVE:  No.  Now, well, so now, because I'm using the BIOS less and less, now I'm scanning the PCI bus doing a complete enumeration of every device on the PCI bus, checking to see what it is, whether the device declares itself to be mass storage.  If it's a mass storage declaration, then I look at what type of mass storage.  If it's an ATA/IDE/AHCI device, which SpinRite  now understands, then I look at the hardware registers that it is declaring.  I then access the registers, perform a sanity check on them, and then talk to - enumerate the drives that are attached, and then ask them for their drive identity information, their sizing information, their capabilities.  Basically behind the scenes I'm fleshing out a huge data structure that describes all of the devices that SpinRite is able to talk to.



Once I'm through with that, then I go through a process that I call "BIOS association" because I need to know which of those things I have just found the BIOS already knows about.  And so to do that I have hashed as part of that process the boot sector on all of those devices, and I have deliberately left them in an error condition.  So then I use the BIOS to read the boot sector of device 80, which is the first BIOS device, and I hash that, then I perform a hash comparison of all of the hashes that I have found of all of the boot sectors of the hardware that I have found, hoping that I will get exactly one match - not zero, and not more than one, because in that case it means I have found which physical hardware device the BIOS is calling 80, in which case I add that to this database, and I go to the next BIOS device.



So I scan through all the BIOS devices, reading all of the signatures.  If I don't get a one-for-one boot sector hash match, then the act of reading the device from the BIOS will have cleared the error condition that I deliberately left the hardware in.  So then I look through - I update all of the error conditions of all of the hardware, hopefully finding exactly one that is no longer in error, in which case I have my second strategy for performing the BIOS to physical drive matching.  



LEO:  Wow.



STEVE:  Once all that's done, I then look to see whether I did get BIOS matches for all of the hardware.  If not, then I add to this database the BIOS devices for which I do not have hardware driver support.  So, for example, for SpinRite now, because I'm only doing AHCI and ATA IDE, other devices like USB connected or NVME connected, those will be supported by the BIOS.  So those get added.  And once that's all done, I look to see whether there are any hardware devices that did not have BIOS support, in which case they would not be labeled with BIOS designations, so I assign them numbers 1, 2, 3, and up.  All of that is happening behind the screen that is flashing "Discovering System's Mass Storage Devices."



The point is I just rewrote all of that because I looked at the old code, and I realized, okay, I know how to do this so much better than I did 20 years ago.  So the announcement that I was making to the group is that little anxiety-provoking flashing thing is going away.



LEO:  Woohoo.



STEVE:  I decided it will be too much fun to animate that process.



LEO:  To show what you're doing, yes.



STEVE:  Yes.  That's what it's going to do.



LEO:  That's a great idea.  I love that.



STEVE:  And so it'll bring up a big empty window and show the PCI bus being scanned, and then devices being found, and it'll go bloop bloop bloop bloop bloop bloop bloop.  It can't make that sound, unfortunately, because we're DOS.  And besides, people tend to hate the sounds that I have SpinRite making anyway.  But so that was what I wanted to say.



LEO:  I'm sure you'll get somebody to volunteer new sounds if...  



STEVE:  There's going to be - that screen that is tremendously anxiety provoking, both for SpinRite users and for Greg and for me, that's going away, to be replaced by - actually it will have a nice diagnostic benefit also because, if it does actually get stuck somewhere, we will know where.  And so I'll then have something to work from.



LEO:  That's great.  That's really impressive, yeah.



STEVE:  A cool advance.  And that gives you a little sense for what is going on behind the scenes.  It's a simple-looking screen; but, yeah, as you said, Leo, there's a lot happening.



LEO:  That's a hard thing to do, historically, yeah, enumerate all the devices attached to a computer.  Not easy.



STEVE:  Okay.  The story that this podcast was named after.  Okay.  We turn our attention to the small city of Oldsmar, Florida, home to approximately 15,000 residents.  Oldsmar lies about 16 miles northwest of the much more widely known city of Tampa, Florida.  The first signs that anything might be amiss at Oldsmar's municipal water treatment plant appeared last Friday morning, when a plant operator noticed someone had remotely accessed a system that controls chemicals and other aspects of the water treatment process.  The operator reportedly didn't think much of the event since his supervisor and coworkers regularly logged into the remote system to monitor operations.



But then later that same day, in the early afternoon, around 1:30, the operator watched as someone remotely accessed the system again.  He could see the mouse on his screen being moved to open various functions that controlled the water treatment process.  This unknown person then opened the function that controls the input of sodium hydroxide, popularly known as lye, increasing it by 111 times.  The intruder increased the level of sodium hydroxide to 11,100 parts per million from the normal proper level of 100 parts per million.



Lye, or sodium hydroxide, is used in very small amounts to treat the acidity of water and to remove metals.  It's also the active ingredient in liquid drain cleaners.  And, yes, in higher levels such as 111 times normal, it is highly toxic.



LEO:  But your drains would be clean, so that's good.



STEVE:  Well, yes.  Your pipes would be clean, and not only the pipes in your house, unfortunately.  Had the change not been reversed almost immediately, it would have raised the amount of the chemical to toxic levels.  And I'll pause our story here to wonder why it is even possible to adjust through automation the amount of lye to a level which is 111 times normal and clearly poisonous.  That seems like a fundamental oversight in the design of the system.  Sure, perhaps allow a range of 0 to 200%, but certainly not up to 11,100%. That's just loony.



LEO:  Shouldn't be on the meter.  It shouldn't be on the meter.



STEVE:  No, no, it shouldn't go that high.  As they say, the stereo does not need to go to 11,100.



LEO:  No.



STEVE:  It should just go to 10.



LEO:  Yeah.



STEVE:  Fortunately, the operator, who was watching this happen, immediately changed, like grabbed his mouse and changed the setting back to the normal 100 parts per million.  And supposedly, even if the malicious change had not been immediately reversed, other routine procedures within the plant would have caught the dangerous level before the water became available to residents.  I guess it wasn't actually in the flow, it was in some tank being mixed or something.  Probably true because if it needed to precipitate out metals, then it may have been added as part of the prep for a big vat.  And it apparently takes anywhere between 24 and 36 hours for treated water of that sort to get into the supply.  So in this case no poison water ever escaped.



The local county Sheriff's Department, however, there was a press conference held, and questions were asked.  The Sheriff's Department did not immediately respond to questions asking whether the utility required personnel to use two-factor authentication to gain remote access to interfaces such as the one that was breached in Oldsmar.  The Reuters news agency, citing an interview with managers, reported that TeamViewer was the application used to gain remote access, but the department didn't immediately respond about the requirements for authentication.



Jake Brodsky, an engineer with 31 years' experience working in the water industry, said it's not at all uncommon for water utilities to make such interfaces available remotely.  While he frowns on the practice, he said that the managers were probably correct in stating that the public was never in any danger.  In an interview, Brodsky said:  "There's a bunch of different things water utilities look for; and if they see anything out of kilter, then they can isolate the storage water.  The danger here is relatively minimal as long as you catch it soon enough, and there are multiple checks before that happens."



Of course, if intruders can remotely tamper with a process, they may also be able to tamper with the safety redundancies in place.  This was obviously not a sophisticated attack.  I mean, why would you do it at 1:00 p.m. in the afternoon?  Do it at 2:00 a.m. and maybe it would go unseen.  Anyway, if Brodsky were advising Oldsmar on better securing their water treatment plant, he said:  "The first thing I'd probably do, and this almost doesn't cost anything, is you disable remote access," he said.



LEO:  Yeah.



STEVE:  When remote access is required - yeah, gee, what a concept - as is occasionally the case, connections should be manually allowed by someone physically present, and the access should time out after a brief period.  He said:  "I can't imagine leaving a connection like that open and exposed to the world.  This is cheap and easy," meaning to add some protection.  "All you do is call the operator, and you get the access you need."



So, you know, stepping back from this, there has been so much talk and no obvious action through the years about the vulnerability of these SCADA systems, SCADA being the abbreviation for Supervisory Control and Data Acquisition.  That's the generic term for all of these things that manage nuclear reactors and water treatment plants and pretty much anything.  I believe that we are probably incredibly vulnerable in this country.  There are too many instances like this where convenience has completely dictated policy and completely trumped security.



I sincerely hope that managers who are responsible for the operational security of their industrial plants of every description hear about what happened in Oldsmar and take it to heart.  With any luck, it may have been a wakeup call.  I'm glad it has gotten the attention that it has because this was not a highly skilled attack.  And it is horrifying to think that something like this, if an attacker, I mean, it just seems like there is so much exposure.  If you rely on the feedback only from a screen with onscreen meters, it would be so easy for someone to reset the meter to make it look like it was reporting 100 ppm and have it set to 11,100.  And who would know?  



LEO:  The thing that I find interesting is that the person who got in seemed to know his way around pretty well.  I mean, if you gave me access to that system, it might take me a while to figure out how to turn the lye setting up.  It seems like an inside job to me.  I don't know.



STEVE:  I'll bet you there are people in Russia who know water treatment plants.



LEO:  Know that software and know how it works, yeah.



STEVE:  Yeah.



LEO:  I mean, the fact that it's on the public Internet is crazy, just obviously crazy. 



STEVE:  It is crazy.  And Leo, we know that you know your way around GUI interfaces.  I'll bet, if you were looking at the screen - and apparently this person did poke around at things first.



LEO:  Oh, okay, okay.



STEVE:  There was some poking around.  The mouse pointer didn't go directly to the lye setting.  It opened various things.  And then the person said, ooh, lye, that sounds bad.  Let's turn that up.



LEO:  Wow.  What a story.  Wow.  Yeah, I hope it's a wakeup call.  But we've seen stuff like this before.



STEVE:  I know.



LEO:  And the worst thing is, if it is Russian or some sort of nation-state, they often do these kinds of probes.  It is weird they did one in the afternoon.  But maybe it's the middle of the night in Russia.  I don't know.



STEVE:  Yeah.  Maybe [crosstalk].



LEO:  They would know better, I think.  What time is it in Florida?



STEVE:  Maybe they weren't the brightest bulbs in Russia.



LEO:  Maybe not.  But often they do these probes just to see what's possible.  Well.  It's just fascinating.  Are we done?



STEVE:  We are.



LEO:  I think we can call it a day for Security Now!.  Oh, no, don't cry, it's okay.  It's going to be all right.  You know why?  Steve's going to be back next week, Episode 806.  He's starting to work on it right now, I can tell.  We do Security Now! every Tuesday, 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  If you want to stop by and watch us do it live, that would be the freshest version, straight, you know, as we're actually creating it.  You can go to TWiT.tv/live.  There's live audio and video streams of everything we do there, day and night.  There's always something going on.  If you're watching live, chat live:  irc.twit.tv.  Join the nice bunch of people who are also watching the show live.  On-demand versions of the show are available from Steve's site, GRC.com.  He actually has some unique versions, a 16Kb audio version.  Does anybody download that anymore?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  When I, like, make a mistake and fumble finger...



LEO:  You hear about it.



STEVE:  I hear about it.  So, yup.



LEO:  16Kb, that's for the bandwidth-impaired.  Probably mostly Australians.  I don't know, I just feel like they suffer, you know.  There's also 64Kb audio, which is the standard.  There's even a transcript, which is written by Elaine Farris.  It's a human-written transcript, very useful.  You can read along.  My son is going through all the Security Now! episodes now looking for any information about my bitcoin password.  It drives him nuts because, as bitcoin goes up, it's now - I probably shouldn't tell you, Steve - $47,000.



STEVE:  Oh.



LEO:  And I said, "It's making you crazy, isn't it.  Isn't it."  "Yes," he says.  "It's making me crazy."  Anyway, but that's a good thing.  The transcripts let you search, it's a text file, and then jump right to that part of Security Now!, so very, very useful.  While you're there, by the way, pick up SpinRite.  6.0's the current version, but you will automatically be upgraded to 6.1 the minute it comes out.  You can also participate in the ongoing development of that in the forums and so forth.  So it's really a good time to get SpinRite, if you for some reason haven't yet purchased the world's best hard drive maintenance and recovery utility.



We have 64Kb audio and video on our site, TWiT.tv/sn.  It's available on YouTube.  There's an entire dedicated YouTube channel for Security Now!.  You can subscribe there.  Actually, the best subscription I think would be in your favorite podcast player because then it would download it automatically and have it ready for you the minute you get in the car or you go to bed or wherever you listen to your podcasts.  So do subscribe.  I think it's a good idea.  Steve will be back next week.  So will I.  I'm sure there'll be something to talk about.  We haven't run out yet.



STEVE:  I just checked.  341 downloads of Episode 802.  So, yeah.



LEO:  There you go.  Thank you, everybody.  Glad you like the 16Kb version.  See, it's worth it.  All right, Steve.  Have a great week, and I'll see you next week.



STEVE:  Thank you, buddy.  Right-o.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#806

DATE:		February 16, 2021

TITLE:		C.O.M.B.

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-806.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we'll begin by following up on last week's headline-making attack on the Oldsmar, Florida water treatment plant with new details that have since come to light.  We'll then take a look into last week's Patch Tuesday event and at some of the sadly broken things that have once again been fixed.  Also, anyone using Adobe's PDF tools, Acrobat or Reader, needs to update.  We're going to look at a dangerous Android App with 1.8 billion (with a "b") users, and at Microsoft's note about the rise of web shells, which dovetails nicely into this week's WordPress add-on disaster.  I'll briefly update about my past eventful week with SpinRite, which includes a 25-second movie of new SpinRite code running.  Then we'll take a look at the recent discovery of the largest list of email and password combinations ever compiled, and what we can each do about it.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got lots to talk about.  An update on that hack on the water company in Florida.  Massachusetts has some ideas for what they can do next time.  We'll also talk about Patch Tuesday.  Wow, some doozies in there, including a patch for the Microsoft Fax Server.  Might want to get that one.  And then we'll talk about the Android app with more than a billion users that's laden with malware.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 806, recorded Tuesday, February 16, 2021:  C.O.M.B.



It's time for Security Now!, the show where we cover your privacy, your security, your overall appearance on the Internet with this guy right here, Steve Gibson.  He is your Internet groomer at GRC.com.



STEVE GIBSON:  Okay.



LEO:  I guess.  I don't know where I'm going with that one.



STEVE:  Yes, okay.



LEO:  Hi, Steve.



STEVE:  So good afternoon, my friend.  So a lot of stuff to talk about today.  The podcast is COMB, which is the abbreviation for Compilation of Many Breaches.



LEO:  Compilation of Many Breaches.  Okay.



STEVE:  Yes, COMB.  It just came out a little over a week ago, and it's - I have it in the show notes - something like 3.1, 3.27, 3.some, like three billion unique email addresses and password combinations all in plaintext.  And so we know that hackers do this.  We know that sites lose control of their backend databases.  There's been over time a migration from passwords in plaintext to passwords poorly hashed, meaning like one iteration and no salt.  Then we got into the multi-iteration, and then we got into the salt, and then we got into the per-user salt. 



So over time the quality of the protection being offered in the sites' databases has improved, but they do keep losing control of them.  And of course the bad guys, those who maybe don't have the skills to go and leverage SolarWinds-style attacks, it's like, well, let's build compilations of all the usernames and passwords.  Anyway, a new big one has come out.  We haven't talked about this idea of email address and password lists for a while.  So I thought it would be fun to sort of take a look at where the state of the art is, how have these lists grown over time, what does it mean that they're getting older and thus staler, and so probably less relevant, but new ones are being added.



Anyway, that's what we're going to talk about here as we wrap things up for the week.  But we've got some follow-up on last week's podcast title.  And the big headline grabber, I saw it on lots of news reports, the attack on the Oldsmar, Florida water treatment plant.  It really got people's attention when you say, you know, 111 times more lye being added to the drinking water.  They said, what?  What?  So we've got more details about that.



We're going to take a look at or into last week's Patch Tuesday event for Windows at some of the sadly broken things that have once again been fixed.  Also anyone using Adobe's PDF tools, Acrobat or Reader, needs to update.  There was sort of a very important update for that also last week.  Normally I don't talk about Android apps.  But in this case an app is being very irresponsible about its design, and it has 1.8 billion with a "b" users.



LEO:  Oh, wow.



STEVE:  So what we need to talk about.  I even knew the name, SHAREit.  It's like, oh, yeah, heard about that.



LEO:  Oh, yeah, yeah, yeah, yeah, lot of people downloaded that, yeah.



STEVE:  Uh-huh, yes.  And they're all in trouble.  Also, we're going to take a look at Microsoft's interesting note about the rise of web shells, which dovetails nicely into this week's WordPress add-on disaster.  I'm going to briefly update about my past eventful week with SpinRite, which includes a 25-second movie of the new SpinRite code that I talked about last week, now running.



And then we're going to take a look at, as I mentioned, this recent discovery on the dark web of a massive compilation - sorted, organized, searchable, indexed, database query-able, it's got all the bells and whistles - and what it means.  And of course we always have a great Picture of the Week.  This one is really apropos.  I thought I was going to have a story about what it ties to, but that story is too big.  So it's next week's topic.



LEO:  Oh, interesting.  Oh.  But it is very, you're right, it is so true.



STEVE:  It's just perfect.



LEO:  Yeah.  And it looks like it's xkcd once again.



STEVE:  Looks like it.



LEO:  Got to give Randall Munroe a lot of credit.  He did a very good xkcd this week on how mRNA vaccines work by comparing them to the Death Star plans from Star Wars.  And I think it actually is probably the best description of how an mRNA vaccine works I've ever read.  So it's good.



STEVE:  Very cool.



LEO:  Just go for the exhaust port; okay?  Okay, Steverino.  Picture of the Day.



STEVE:  Yeah.  This is great.  It's kind of difficult, I mean, if anyone sees it, they'll instantly get it.  But to describe it for our listeners rather than our viewers, imagine a big construction of blocks of different sizes representing software modules, and they're all kind of piled up on top of each other, kind of like a house of cards of all different sizes, some up on their end, others standing on top of them, you know, balancing really precariously.  I'm sure there's some wooden block game of this sort where you have to keep adding blocks to it, and then you have to start taking them away kind of thing, to have the whole structure stay together.



Anyway, the point is that in this particular construction, down at the very bottom of this very complex, multi-hierarchy, tiered conglomeration is one little kind of a peg standing on its own, and the whole thing is labeled "All Modern Digital Infrastructure," to sort of represent that, yes, this is the way today we build these things.



LEO:  It's like a house of cards out of blocks.  It's just, like, nutty, yeah.



STEVE:  Exactly.  Exactly.



LEO:  Jenga, maybe.



STEVE:  It's all modules coming from here and there that are conglomerated together, and they've all got - they rely on an API below them, and they expose an API to their upper surface, and something else hooks onto that.  And it's all kind of glued together.  Anyway, this one little stick down at the bottom is labeled - oh, I should also explain that this little stick down at the bottom is basically supporting the structure of this entire thing such that, if this stick were removed, it's immediately clear that the entire thing would just tumble off to the right and fall apart in a billion pieces.  So this little stick is labeled, "A project some random person in Nebraska has been thanklessly maintaining since 2003."  And, I mean, this is funny because it's so true.



LEO:  Yeah.  OpenSSH or NACL or, yeah.



STEVE:  Yes.  Pick your - right, right.  Pick your super popular, it sort of became a de facto standard when no one was looking.  And now...



LEO:  One guy.



STEVE:  Everything is built on it.  Yeah.



LEO:  One guy.



STEVE:  It's Felix in Nebraska.



LEO:  Felix, he's in charge.  And he's, by the way, people yell at him all the time.  They're constantly complaining.  Nobody's giving him any money.  He's doing it out of love.  This is really kind of the way it is.



STEVE:  Because it's not handling the triple back tick expansion of some random command.  And it's like, you need to add this.  And he's like, okay, well, you know, no.  Anyway, so the point is, okay, we all are depending upon Felix more than we are aware.  Until he says, "I'm done."



LEO:  The hell with it.



STEVE:  And then it's like, wait, wait, wait, wait, wait, no.



LEO:  It's not worth it.  Yeah, yeah.



STEVE:  So in a variation on Felix, we have Oldsmar, Florida.  As I mentioned last week, I hope the scare of the kind of near miss that we had might serve as a bit of a wakeup call, not only to other water treatment facilities, but also to sort of the larger industrial control sector in general, whose security pretty much must be wanting.  I mean, what we always see is that anything we've never looked at closely is full of holes.  And the only reasons our browsers are as strong as they are from a security standpoint is that we're just like - they're getting so much attention.  But those things that don't get attention, they're like Felix with his little peg up there, and just hope that it stays where it is.



Well, as it turns out, later last week, something kind of like that might have happened, at least in small part.  The State of Massachusetts Department of Environmental Protection posted a cybersecurity advisory for public water suppliers with the subtext, "How public water suppliers can guard against cyberattacks on water supplies."  And I don't know, like, who put the State of Massachusetts Department of Environmental Protection in charge of the larger water supplier world.  But at least they were the ones who made the statement, and it did get picked up far and wide by a lot of the press.



So it's a little bit more specific to this particular issue than I was hoping for since it must be that the security problems with industrial control extend to every application of the SCADA control systems that operate all this stuff.  But it did offer in its advisory a few interesting new tidbits about the attack which were not public knowledge when it occurred 11 days ago.



Okay.  So what they said was, open letter:  "Dear Public Water Supplier.  We appreciate your attention to cybersecurity and the recent incident in Florida.  Here's a more specific description of the events and suggested protective measures."  They wrote:  "The FBI, Department of Homeland Security, U.S. Secret Service, and the Pinellas County Sheriff's Office have issued a joint situational report that concerns the water sector.  The EPA is providing crucial information from this report to the WSCC" - I don't know what that is, water system something council or something maybe [Water Sector Coordinating Council] - "and the GCC" - which I'm sure is not the language - "for awareness," they wrote.  "EPA recommends that all water systems implement the mitigation measures listed at the end of this report where applicable."



They said:  "On February 5th, 2021, unidentified cyber actors obtained unauthorized access on two separate occasions, approximately five hours apart, to the Supervisory Control and Data Acquisition (SCADA) system used at a local municipality's water treatment plant."  Of course we all know this.  "The unidentified actors accessed the SCADA system's software and altered the amount of sodium hydroxide," they said, "a caustic chemical used as part of the water treatment process.  The water treatment plant personnel immediately noticed the change in dosing amounts and corrected the issue before the SCADA system's software detected the manipulation and alarmed due to the unauthorized change."  Okay, well, so that was good to know.



LEO:  That's news.  That's good, yeah.



STEVE:  That there was some backup in case somebody was literally asleep at the console and not kind of curious about why the mouse pointer was mysteriously moving itself around the screen.  Which, you know, he saw five hours before and didn't think twice because, yeah, that happens because they do have remote access of that sort.



LEO:  And they all have the same password.  Did you see that?



STEVE:  I know.  I know.



LEO:  Oh, my god.



STEVE:  I know.  "As a result," they wrote, "the water treatment process remained unaffected and continued to operate as normal."  So they said:  "The unidentified actors accessed the water treatment plant's SCADA controls via remote access software, TeamViewer" - of course you used TeamViewer in your previous presentation of our sponsor, Leo, appropriately.  They said:  "...which was installed on" - and there's some confusion about this.  They're saying one of the several computers at the water treatment plant.  I've seen other reports that said on all the computers at the water treatment plant.  But there is universal agreement that they are, regardless, all sharing the same login authentication.



So they said:  "...which was installed on one of several computers the water treatment plant personnel used to conduct system status checks and to respond to alarms or any other issues that arose during the water treatment process."  In other words, SCADA.  They said:  "All computers used by water plant personnel were connected to the SCADA system and used the 32-bit version of the Windows 7 operating system.  Further, all computers shared the same password for remote access."  So that was the red flag that went up.



LEO:  Yeah, no kidding.



STEVE:  "All computers shared the same password for remote access and appeared to be connected directly to the Internet without any type of firewall protection installed."  Okay.  So, I mean, like, really?  Not even behind a router?  Maybe that, you know, who knows?  So they said:  "Recommended Mitigation."  I mean, so that reminds you of Windows 98, right, back then.  Anyway, recommended mitigation:  "Restrict all remote connection" - so this is what went out in this announcement, this advice:  "Restrict all remote connections to SCADA systems, specifically those that allow physical control and manipulation of devices within the SCADA network.  One-way unidirectional monitoring devices are recommended to monitor SCADA systems remotely."  Meaning you can look, but you cannot change.



They said:  "Install a firewall software/hardware appliance with logging and" - this would be good - "ensure it's turned on."  Because that would be good.  "The firewall should be secluded and not permitted to communicate with unauthorized sources."  Okay.  "Keep computers, devices, and applications, including SCADA/industrial control systems software, patched and up-to-date.  Use two-factor authentication with strong passwords.  And, finally, only use secure networks and consider installing a virtual private network (VPN)."  And they concluded with:  "Implement an update and patch management cycle.  Patch all systems for critical vulnerabilities, prioritizing timely patching of Internet-connected systems for known vulnerabilities and software processing Internet data, such as web browsers, browser plugins, and document readers."



Okay.  So everyone who listens to this podcast will have pretty much become security-aware enough for none of that advice to be the least bit surprising.  And, you know, it does sound a little bit generic; right?



LEO:  Well, it's a start.  I love it that they're using Windows 7, shared TeamViewer password, I mean, you couldn't do it any worse.  And it's open to the public Internet, apparently, not secluded.  I don't know if secluded's the right word.  That sounds like it's in a quiet little grove, a forest grove.



STEVE:  Give it a vacation.



LEO:  Yeah.  But I get the point, absolutely, yeah.



STEVE:  So there has been some speculation about the timing of the attack within the security industry because that massive database breach or reveal that I mentioned which contains 3.2 billion unique email/password pairs was leaked online just three days before the attack.  That database contained 13 entries relating to the Oldsmar facility, that is, those containing the domain ci.oldsmar.fl.us.  We'll be discussing the details and consequences of the publication of this massive list at the end of today's podcast.  But in my mind it would be a huge coincidence for the two to be related, given that the newly leaked list contains, as I said, 3.2 billion entries.



So what happened is that a security firm, after seeing the Oldsmar, Florida exploit, queried this newly released database and found, yes, 13 entries that were relevant.  But given that you have 3.2 billion entries, you could probably put just about anything in there, and you'll get some results.  So I think that a more plausible explanation was offered by Christopher Krebs, the former and founding head of the U.S. Cybersecurity and Infrastructure Security Agency, CISA.  In Congressional testimony, Chris told a House of Representatives Homeland Security Committee last Wednesday that the breach was very likely the work of a disgruntled employee, or maybe ex-employee.  And I think that is extremely likely.  This is not to excuse the obvious lack of security throughout the installation.  When you hear that all the machines are using the same password, like when that news gets spread widely, okay, you already have some serious security egg on your face.



One other note is that, especially since the pandemic, TeamViewer has become to remote control what Zoom has become to teleconferencing.  But whereas the pressure of its public exposure and its very public security failures rapidly matured Zoom's security, as we talked about starting about a year ago, TeamViewer has remained pretty much unchanged, and those knowledgeable about TeamViewer are not impressed.  Many of those within the industrial control industry who have been interviewed since the Oldsmar incident have observed, unfortunately, that they often see TeamViewer installed at sites, and just shake their heads.  Yeah, it works, but it's anything but secure.  And the reason it's chosen by Johnny to manage his grandparents' PC when they get tangled up with what button to press, is that it is so drop-dead simple to use.



And I'll note that TeamViewer does offer multifactor authentication.  But of course you need to turn it on.  And if the problem was a disgruntled employee, they might have current credentials.  If it was an ex-employee, then of course somebody who was at the Oldsmar facility in charge of security, and you wonder whether the phrase "in charge of security" is just an oxymoron at this place because apparently nobody was, they would of course, after terminating someone, you'd have to go around and do the equivalent of changing the locks on all the doors.  You'd need to change the passwords and the one-time password authentication secret and so forth.  But it seems very unlikely that anyone did.



So again, yes, none of this in this instance is rocket science.  This bar was so low that anybody could have jumped over it in order to unfortunately start poking around with the SCADA system at the plant.  Again, the best possible outcome is that, because this got so much attention in the press, all the other admins or people in charge have to have thought, ooh, crap, we don't even have passwords.  So let's hope this was a wakeup call and that a lot of attention got paid.



My great concern, and I don't want to be right on this, is that we keep seeing that anything that hasn't received serious attention is seriously lacking in security.  And there have been lots of people worrying about lack of SCADA security.  The fact that these things just aren't being attacked, as far as we know, means that they're not getting lots of attention.  Well, let's hope that the concern is great enough that security really is an issue, and that we're not going to have to get a rude wakeup call when we have a nationwide power outage, and like the equivalent of what we did, apparently we did, we and the Israeli cyber folks, with Stuxnet, when the Iranian nuclear centrifuges got blasted by Stuxnet.  That was a SCADA attack, very clever and high end because, as we know, they were not on the Internet.  All these systems are because everyone wants the convenience that that affords.  But if you're going to do that, you really need to take responsibility.



So speaking of taking responsibility, a lot happened with last Tuesday's patch batch.  Overall, Microsoft addressed 56 security vulnerabilities, including 11 rated critical and six that were already publicly known.  So, yes, let's get those patched.  And as expected, they did finally lower the boom on the use of unencrypted remote procedure calls to prevent the protocol fiddling that was what led to and enabled last year's Zerologon mess.  So they gave everybody lots of time to get that resolved and fixed.  They don't want to break anything, but they do want to get this, what was basically a serious protocol mistake, locked down.  They can't really change it without breaking things, but they can at least wrap it in a secure authenticated tunnel in order to keep it from being abused.  The 56 CVEs span the .NET framework, Azure IoT, Azure Kubernetes Service, Microsoft Edge for Android, Exchange Server, Office and Office Services and Web Apps, Skype for Business and Lync, as well as Windows Defender.



The biggie that was found being exploited in the wild carries a surprisingly low severity rating of just 7.8, which puts it in the "important" range.  But researchers noted that it deserves attention above some of the critical bugs in terms of its patching priority.  This problem exists in Windows' Win32k operating system kernel module.  We've talked about that often.  It is an elevation-of-privilege vulnerability.  It would allow a logged-on user to execute code of their choosing with admin root system level privileges, so in the context of the kernel.  And again, it is being used maliciously in the wild.



So it's good that last week's updates eliminated it.  I guess it probably got a 7.8 because you had to already be a local logged-on user.  You had to be on the system with access to the API.  However, if you had that, that allowed you to bypass all of the system's deliberate security provisions against allowing such a user to have root privileges.  And so this cut right through that.  It's fixed.  And again, it was found being used.  So it certainly was useful.



There's also a publicly known critical flaw in the .NET Core and Visual Studio, but details are being closely held.  Dustin Childs, who's Trend Micro's Zero Day Initiative guy, said:  "Without more information from Microsoft, that's about all we know about it.  Based on the CVSS severity scale, this could allow remote, unauthenticated attackers to execute arbitrary code on an affected system."  He says:  "Regardless, if you rely on the .NET Framework or .NET Core [and pretty much everything does now]," he said, "make sure you test and deploy this one quickly."  Believe it or not, there are also two critical-rated remote code execution flaws in Windows Fax Service.



LEO:  Well, they've got to fix that.



STEVE:  Fax Service?



LEO:  Yeah.



STEVE:  Really?  Does anyone fax anything anymore?



LEO:  Oh, believe me.  There are a lot of people who still use that.  Hard to believe.



STEVE:  Wow.



LEO:  I know.



STEVE:  In any event, Microsoft said that an attacker who successfully exploited either of these two critical vulnerabilities could take control of an affected system, yes, by fax. 



LEO:  Wait a minute.  You could send a fax to it, and it would hack it?



STEVE:  Yeah.  Yeah.



LEO:  Oh, that's a good one.  



STEVE:  Yeah.  Yeah.



LEO:  Wow.



STEVE:  Then, from receiving a fax, the bad guy could install programs; view, change or delete data; or create new accounts with full user rights.



LEO:  You know there are tons of businesses, medical offices, and more that use this for inbound faxes.  This is actually probably more serious than we're thinking.



STEVE:  Well, so to me this sounds like, for most of us, one of those services you want to uncheck and remove from most, if not all, Windows systems.  Again, we always want to be minimizing our attack surfaces.  We recently talked about turning off unneeded application layer gateways in our routers.  Unneeded and unused features are inherently dangerous.  If a system that has never needed to send or receive a fax doesn't have its fax service running or installed, even if the fax code is vulnerable, it's not there to be attacked.



So in Windows Control Panel, on the Add or Remove Apps page, there's a link for adding or removing Windows features.  You can browse that list and remove the crap that Microsoft installed in order to minimize their tech support calls.  They'd rather have the fax service running, taking up RAM and making everyone vulnerable to the exploitation of its flaws, in the off chance that someone, somewhere, might someday need it, than to require the person who needs it to install it if they know they need it.  So hopefully those law firms and doctors' offices, okay, good, cool.  Faxing in Windows?  We got that.  But it would sure be nice if it was just not on by default.



The principle here is clear.  Whether it's an unneeded gateway in your router, or a Windows fax service you will never use, services that are not running cannot hurt you.  And without question, shutting them down or uninstalling them will reduce your attack profile.  When you hear about systems being security hardened, it's because all of this stuff has been turned off.  That's what you do to harden a system; right?  You turn that all off, and you turn on the firewall.



So anyway, now we're going to talk about a service that no one can turn off or remove.  Believe it or not, Windows is still experiencing remote code execution vulnerabilities in its TCP/IP stack.  What year is this, Leo?



LEO:  Right.



STEVE:  As we know, that's the last place you want to have such vulnerabilities because it is by definition exposed to the world.



LEO:  And nothing you can do about it.  That's what it does.  



STEVE:  One flaw.  Yeah.  And you're glad that you can talk to other people.  One flaw that Microsoft fixed last week was found in the way Windows handles IPv4 source routing.  And the other was in the way Windows handles IPv6 packet reassembly.  Okay.  So what was I just saying about the abuse of unused and unneeded code and services?  Here's what Rapid7 has to say about IP source routing.  They said:  "The host is configured to honor IP source routing options.  Source routing is a feature of the IP protocol that allows the sender of a packet to specify which route the packet should take on the way to its destination, and on the way back.  Source routing," they write, "was originally designed to be used when a host did not have proper default routes in its routing table.  However," they said, "source routing is rarely used for legitimate purposes nowadays.  Attackers can abuse source routing to bypass firewalls or to map your network."  Oh, yeah.  Turn that one on, definitely.  Ugh.



Quoting Dustin Childs again, from Trend Micro's ZDI, who was short and to the point about this one.  He said: "IPv4 source routing should be disabled by default."  He said:  "You can also block source routing at firewalls or other perimeter devices."  In other words, not today, nor for the past couple of decades, if ever, has anyone had problems with their routing tables.  They work just fine, thank you very much.  Notice that also in the 15-plus years of this podcast, where we have gone many times deep into the bit levels of the Internet, IP packets, and routing, never have we even touched on IP source routing because it is never used.



LEO:  Why would you need it?



STEVE:  You don't, in the real world.



LEO:  It feels like a vestigial feature that was left in almost by accident, like nobody even - is that still in there?  Do we still have that in our TCP stack?



STEVE:  Yet Microsoft just patched a critical flaw...



LEO:  I shouldn't laugh.



STEVE:  ...with a CVSS score of 9.8.  So here, before last Tuesday - and hopefully no longer since everybody installed their updates; right?  Were someone to send your system a deliberately malformed IP packet containing source routing information, although the feature has never been used and has never been needed, they could nevertheless take over your system remotely.



LEO:  Holy McGillicuddy. 



STEVE:  Yeah.  You know, there really ought to be an install time option in Windows.  You know how you get that screen of little slider switches?



LEO:  Yeah, do you want that?  Do you want that?



STEVE:  How much spying do you want and so forth?



LEO:  Yeah.



STEVE:  There ought to be a big slider switch where you get to choose, and on one side...



LEO:  How much legacy code, yeah.



STEVE:  Yeah.  On one side it's labeled "security," and on the other side it's labeled "install a bunch of unneeded and never-used extra features."



LEO:  Unbelievable.



STEVE:  It is.  It's just like, again, 2021.  So unfortunately it really is a switch.  You can either have security, and not have a bunch of unneeded and never used extra features installed.  But you can't have both because code is buggy.  And I know I sound like I'm harping on Microsoft.  But I'm very clear always that anyone can make a mistake.  You've never heard me jump on anyone for making a mistake.  My entire problem surrounds policies.  Organizations should be held to account for their policies.  And Microsoft has clearly demonstrated the policy of installing unneeded services by default and supporting long obsolete and unneeded protocols.  They don't want someone saying, hey, why aren't you supporting IP source routing?  They ought to just say, go get Linux.  Really.  It's just nuts.  I mean, I don't even know if Linux has it turned on by default.  



LEO:  You know, it might.  You know, it really might.



STEVE:  Yeah, actually, yeah.  That's why it came to mind.



LEO:  Yeah.



STEVE:  And that brings us to the other TCP/IP bug, IPv6 packet reassembly.  Now, we've talked about this.  Packets are never supposed to become fragmented in transit from their sender to their receiver.  It's inefficient, and it's assiduously avoided by all inter-networking equipment.  It can occur when a router receives a large packet on one of its interfaces which needs to be sent out, thus routed, out of another interface that has a lower MTU.  MTU is Maximum Transmission Unit.



But much as with IP source routing, what made sense at the dawn of inter-networking has since largely become obsolete.  Ethernet rules the world.  And the Ethernet MTU of 1500 bytes is the standard.  There are so-called "Jumbo Frames" for Ethernet of 9000 bytes, with the idea of making Ethernet frames, individual Ethernet frames larger, in order to allow them to carry more payload per frame, thus reduce the per frame, and in this case per packet, addressing overhead.  But such Jumbo Frames are only useful within carefully controlled environments, and they generally cause more trouble than they're worth because you just sort of get inexplicable, can't reach this destination errors.  And then it's like, ooh, that's right, this is a Jumbo Frame connection.



So packet fragmentation has turned out to be a longstanding annoyance within the Internet protocol.  I mean, it's been a source of continuous problems.  Once a packet becomes fragmented, it remains fragmented throughout the rest of its or their journey to their destination.  And the packet reassembly problem turns out to be a particularly tricky wicket to code reliably.  As a result, as I said, it has historically been a source of some significant networking vulnerabilities, which we would hope by the year 2021 have finally been resolved.  Not so.  Windows TCP/IP still, until last Tuesday, was not managing to get it right, thus creating a newly discovered critical vulnerability with a CVSS score of 9.8, enabling a full unauthenticated remote code execution vulnerability in Windows.



Because fragmentation is no longer supposed to occur, some high-security firewalls simply drop all incoming fragmented packets.  It's considered a good practice.  Or a router, which is faced with a need to fragment a packet for some reason, may choose not to fragment and forward lots of smaller packets, but rather to return an ICMP - that's Internet Control Message Protocol - message explaining to the sender that the packet it's just received is too large for it to forward, in which case the sender should reduced its transmitted packet size and try again.  So in other words, robust mechanisms exist for handling this without the need to ask the receiver of the final collection of fragments to ever reassemble them.  Despite the fact that you're never going to actually get fragments, before last Tuesday, if Windows 10 did, whammo, takeover.



LEO:  I like the whammo.



STEVE:  Yes.



LEO:  A big thought bubble comes out of your machine, "Whammo."



STEVE:  Last Tuesday also fixed a critical bug in the Windows Camera Codec Pack, and another in the Windows DNS server.  Thankfully, that is one service that Microsoft does not install by default because they understand most people, while they still think most people need to receive a fax, they realize most people don't need to be a DNS server.



LEO:  Yes.



STEVE:  So the good news is that one is turned off.  The bad news is it is highly critical remote code execution.  If the service is running, if someone does have Windows 10, before last Tuesday, configured to serve DNS queries, and it receives a maliciously formed DNS query, what is it we say, Leo?



LEO:  Whammo.



STEVE:  Whammo.  That's right.  A critical flaw was...



LEO:  Pow.  Zoom.  Bang.



STEVE:  Biff.  Biff, pow.



LEO:  Biff.



STEVE:  Also fixed in Windows print spooler, in the .NET Core for Linux, and in Windows Codecs Library.  So pretty much just your typical month in the life of Windows 10.  They are never going to get it right because their economic model which they have adopted now requires that they keep fussing with it forever.  And all experience tells us that, every time you touch it, you risk breaking something that used to work.  It doesn't matter how good you are.  It doesn't matter how careful you are.  Especially with an edifice, I mean, basically that Picture of the Week that we showed at the top is Windows.



LEO:  It's Windows.



STEVE:  You know?  That's what it looks like inside.  And it's like, ooh, I'm just going to change this one block here, and I'm sure it will be fine, because we need to support, I don't know what, Rocky Road Protocol.  So what could possibly go wrong?  Well, anyway, this podcast will run out of digits before Microsoft gets Windows 10 working right.



I did mention that, if you are using Adobe's Acrobat or Reader, either 2017, 2020, or the DC versions of either, there is a targeted attack on those occurring in the wild.  So that needs to be fixed.  If you're using any of those, if you know you're using them, then you do need to get yourself updated.  That's important.  Adobe has released fixes.  You can probably just ask any of those to check themselves for updates.  They'll go ask Adobe, and they'll find, oh, yes, there's something new that we need to take care of.



Okay, now, I mentioned that I don't normally talk about Android app security flaws and problems.  They have their own podcast here on the TWiT network.  And I also suppose it's because it seems like such low-hanging fruit.  I mean, our time here is limited every week.  But when vulnerabilities have been found and responsibly disclosed in an Android app that has 1.8 billion users worldwide, and when after 90 days of no response from that app's publisher the responsible and well-known disclosing party decides to finally go public with their vulnerability information, then the situation rises to the level that we need to touch on it here.



The Android app in question, as I mentioned, is SHAREit.  And I don't follow this stuff that closely, but I recognize that one.  And I'd venture that many of our Android-equipped listeners may have a copy.  The Google Play Store lists it as SHAREit - Transfer & Share.  It is obviously a super popular file exchange app.  It was Trend Micro who examined, discovered, and reported the problem to SHAREit's publisher and received no feedback.



Trend Micro wrote:  "We discovered several vulnerabilities in the application named SHAREit.  The vulnerabilities can be abused to leak a user's sensitive data and execute arbitrary code with SHAREit permissions by using a malicious code or app.  They can also potentially lead to Remote Code Execution (RCE).  In the past, vulnerabilities that can be used to download and steal files from users' devices have also been associated with the app."  Meaning it has a history of problems.  They said:  "While the app allows file transfer and download of various file types, such as Android Package (APK) files, the vulnerabilities related to these features are most likely unintended flaws."



So SHAREit has over one billion downloads in Google Play and has been named one of the most downloaded applications - it was in the top ten - most downloaded applications in 2019.  Google has been informed of these vulnerabilities.  So we'll see what action, if any, they take.  Trend Micro's posting then delves into the details of the app's API registrations, that is, the things it's doing that are causing these problems, and in detail into its operation, which allow arbitrary files to be downloaded and executed, including downloading and installing any APK.



And just to be clear, it's not the SHAREit app itself that's malicious, but its presence in all 1.8 billion Android devices which are creating security holes large enough to drive Google through.  So this creates a huge opportunity for abuse by any other app that wants to get up to some mischief.  And now, after Trend Micro's full disclosure, everyone who might want to do that knows about it.



They concluded their detailed write-up by saying:  "We reported these vulnerabilities to the vendor, who has not responded yet.  We decided to disclose our research three months after reporting this, since many users might be affected by this attack because the attacker can steal sensitive data and do anything with the apps' permissions."  They said:  "It is also not easily detectable."



So mostly a heads-up to any of our listeners who have downloaded SHAREit.  It might be one of those free Android apps that you once upon a time downloaded, used it for a while, and then forgot about it, but it's still installed.  If it's still installed, it's a problem.  Now would be a good time to say goodbye.  Or maybe you use it regularly and cannot live without it.  In that case, perhaps be on the lookout for its publisher to finally take the security of their app seriously by producing an update.  Maybe this will bring them under some pressure to do that.  Or maybe find a hopefully more responsibly written alternative.



Anyway, mostly I just wanted to give everyone a heads-up about SHAREit because yikes.  It does sound like it's massively installed, and its presence is creating a set of vulnerabilities for anyone who has it installed that could create problems.  Certainly you can imagine it being used in a targeted fashion.  If somebody knows that you're using SHAREit and can get you to download something which is not itself malicious, but that abuses the permissions that SHAREit has asked for itself, you could be in trouble.



LEO:  Yeah.  It's still on the Google Play Store with no notice of anything.  And as you said, one billion-plus downloads.  That's got to be the majority of Android phones in the world; right?  I mean...



STEVE:  I think so, yeah.  



LEO:  Yeah.  I don't think I've ever installed it.  It doesn't look like I ever have, thank goodness.



STEVE:  Good.  You don't want it.  And neither do our listeners unless you really need it.  And again, it's one of those things.  We'll be talking about this theme a little bit, this notion of removing things you are no longer using because, even if they're not still there, they can still represent a problem.



So Microsoft last Thursday - they've got a team they call Detection and Response Team, DART.  They post an interesting update about a rapidly growing security threat which we've not yet ever discussed directly.  And that's known, these things are known as web shells.



So first we need to define a web shell.  It's a fancy name for some malicious code that, well, you definitely don't want running on your server.  Or rather, actually, present in your server.  A web shell is typically a small bit of malicious code written in whatever typical server-side web development programming language your server supports.  So that would be something like ASP, Active Server Pages; PHP, Personal Home Page; JSP, Java Server Pages; or similar.  Attackers somehow arrange to implant their script onto a victim's web server to then provide them with long-term persistent remote access and code execution of server functions.



These web shells allow attackers to run commands on servers to steal data or use the server as a launch pad for other activities like credential theft, lateral movement within the infected network, deployment of additional payloads, or hands-on keyboard activity.  And most significantly they allow attackers to rather trivially maintain a persistence within an affected organization which is surprising hard to detect.  And this gets picked up by our radar because Microsoft has been monitoring this as a rapidly growing trend.  They wrote, in their posting Thursday:  "One year ago we reported the steady increase in the use of web shells in attacks worldwide."



They said:  "The latest Microsoft 365 Defender data, which is their online real-time instrumentation system, shows that this trend not only continued, it accelerated.  Every month from August 2020 through January 2021, we registered an average of 140,000 encounters of these threats on servers, almost double the 77,000 monthly average we saw over the same period year over year compared to the previous year.  The escalating prevalence of web shells may be attributed to how simple and effective they could be for attackers.  As web shells are increasingly more common in attacks, both commodity and targeted," they said, "we continue to monitor and investigate this trend to ensure consumers are protected."



Microsoft blog posting continues with a little bit of riveting case history.  They said:  "Attackers install web shells on servers by taking advantage of security gaps, typically vulnerabilities in web applications" - and we'll be talking about one next in WordPress - "in Internet-facing servers.  These attackers scan the Internet, often using public scanning interfaces like Shodan.io, to locate servers to target.  They may use previously fixed vulnerabilities that unfortunately remain unpatched in many servers, but they are also known to quickly take advantage of newly disclosed vulnerabilities.



"For example, last June 30th, F5 Networks released a patch for CVE-2020-5902, a remote code execution vulnerability in Traffic Management User Interface (TMUI).  The vulnerability is a directory traversal bug with a CVSS score of [our favorite] 9.8."  We talked about it at the time.  Microsoft says:  "Just four days later, on the Fourth of July, exploit code was added to a Metasploit module.  The following day, Microsoft researchers started seeing the exploit being used by attackers to upload a web shell to vulnerable servers.  The web shell was used to run common cryptocurrency miners."



Now of course, those were the quaint days, right, when cryptocurrency was being mined.  Now we're going to encrypt all your data.  We're going to exfiltrate, as you said, Leo, the embarrassing bits.  And then we're going to hold you hostage and make you pay us some bitcoin.



LEO:  Yeah.  They're so smart, these ransomware folks.



STEVE:  Although, boy, did you see what's happened to bitcoin, Leo?



LEO:  No, don't.  Zip.  Zip it.



STEVE:  Yeah.  Ouch.



LEO:  Actually, it's far worse for you than it is for me.  I gave my son my wallet and said, "You can hack it.  If you can crack it, it's yours."  And then I told him, the good news is by not being able to unlock it, we've watched bitcoin go through the roof.  You know?



STEVE:  And you're right because we would have all sold our coins.



LEO:  Oh, yeah.



STEVE:  Back, like, so long ago.  That is the way I feel better about this is that...



LEO:  You wouldn't have the 50 now.  You wouldn't.  You would have sold it when they were a thousand bucks each, and you would have said, "I'm happy."



STEVE:  I would have thought, woohoo!



LEO:  Woohoo, I'm rich.  I told Henry, by the time those 7.85 bitcoin are worth more than a million dollars, we'll have quantum computers, and we can just crack the thing.  Right?



STEVE:  So you actually do have your wallet.



LEO:  Oh, I have the wallet.  I forgot the password.  Which is really stupid.  But we'll be able to crack it.  Not maybe with current computing technology.  But by then it'll be really worth something.  It'll be worth cracking it.  That's my attitude.



STEVE:  Good.  I like that attitude.  And it gives Henry something to look forward to.



LEO:  Oh, it drives him nuts.  It drives him crazy.  Weekly he'll email me, say, "Did you think of anymore passwords you might have used?"  I actually have it running on my system at home.  So if I ever think of a password I can try it.  But so far no luck.  You know when I'm going to feel bad?  When it goes down to a buck a bitcoin.



STEVE:  Right.



LEO:  Right?  Opportunity missed.



STEVE:  Like when it collapses again.



LEO:  Right, right.  If it does.  Who knows what's going on with that.



STEVE:  If it does.  You know, I think it was you who said that some financial group was saying they see this thing going to 150,000.



LEO:  Oh, yeah.  And with companies like Tesla buying 1.5 billion of bitcoin, that just props it up further, you know.  As long as that continues to happen.  Would you like me to take a break?



STEVE:  That's a great idea.  Let me just finish this one piece...



LEO:  Oh, sorry, go ahead.



STEVE:  ...about web shells, and then we'll do that.  So once these web shells have been installed on a server, writes Microsoft, "web shells serve as one of the most effective means of persistence in an enterprise."  Listen to that again.  Once installed on a server, web shells serve as one of the most effective means of persistence in an enterprise.  And we'll talk about why in a second.  They said:  "We frequently see cases where web shells are used solely as a persistence mechanism.  Web shells guarantee that a backdoor exists in a compromised network because an attacker leaves a malicious implant after establishing an initial foothold on a server, that implant being the web shell.  If left undetected, web shells provide a way for attackers to continue to gather data from and monetize the networks" - I love that - "monetize the networks they have access to."  Yes, we're into a little malicious network monetization now.



Okay.  So just to make the mechanism clear, a web shell script is just a static text file with an extension like .asp, .php, .jsp, and so on.  The typical web server will have a bazillion such files.  They're little fragments of the whole web system package which are invoked on demand.  And if one additional .asp or .php file were to be added to the hundreds of others that are already there, who would ever know?  It's like some file appearing in your Windows System32 directory.  Remember the quaint old days when there were four files that ran our operating system?  Now no one knows what they all are.  So the point is that if one additional PHP file somehow gets added to a contemporary web-based system, it's impossible, virtually, to detect.  And it would tend to go completely unnoticed.



Okay.  Then at any time or times later, a remote attacker simply queries a specific URL on that company's web server which references the web script that was deposited into a script executable directory, which is to say along with all the other .PHPs or .ASPs, and the attacker's code comes to life.  It's really kind of diabolical.  It's trivial on the one hand and doesn't take a rocket scientist.  After all, PHP was designed to be dead simple to use as a page scripting authoring language.  So you just always hope that it's only your code that your server is running.



What Microsoft points out is that the instant a new vulnerability surfaces, attackers are now scanning the Internet and using the new vulnerability to quickly get a foothold, to quickly drop a web shell onto what might be briefly vulnerable targets before they're patched.  And once there, the script can then sit unseen, not, I mean, it's not running, nothing is going to detect it, it's like just some text code sitting in an executable script directory.  But it will come to life when invoked.



So as I said, if minutes later the vulnerability that allowed it in is patched to foreclose any future use of that vulnerability, it's too late.  Now that server is carrying a malicious script that will jump into service whenever it's invoked through simply receiving a querying URL.  Microsoft notes that the challenge of discovery of such implants is hampered by the sheer volume of network traffic, plus the usual noise of constant Internet attacks.  This means that targeted Internet traffic aimed at a web server will blend right in, making detection of web shells a lot harder and requiring advanced behavior-based detection that can somehow identify and stop malicious activities that are essentially hiding in plain sight.



So anyway, I just sort of wanted to put that on everyone's radar.  It is a growing trend.  It has doubled in a year.  The concept of empowering web servers to interpret textual scripts as code is incredibly empowering.  This method of running server-side code has pretty much taken over the world.  It's the way it's being done now.  And the downside is that, well, text files on the server are being interpreted as code.  In other words, it's both what we want and what we don't want.



LEO:  Right.



STEVE:  And it really is a growing problem.



LEO:  I mean, somebody put a PHP script ages ago on one of my servers.



STEVE:  Yup.



LEO:  And because I had that folder open for FTP, people could execute it.  And that's a real flaw.  You really shouldn't have folders that just anything in there can be executed.  That's just - but that's one of the biggest flaws with PHP, in my opinion.



STEVE:  And in fact we've talked about several of the recent problems with WordPress, and we're about to talk about another one, is that you can do that .png.php, or the other way around, you know, double extensions, and it'll be seen by the system as an image file.  But when the PHP interpreter is invoked with it, it'll go, oh, look, I've got something to do.  It's a script, and it'll run it.  So wow.



LEO:  Wow is wow.



STEVE:  Or whammo.



LEO:  Whammo.  Pow.  Zoom.



STEVE:  So I mentioned we have once again yet another WordPress mess.  And I hope that, if nothing else, mentioning these every week, I mean, they are of great concern to the security community.  I hope that mentioning them every week is having the effect of increasing our listeners' security by virtue of doing something to keep themselves from being vulnerable.



I mentioned WordFence last week.  It sounded like a useful service.  They have both a free and not.  And so that's something to think about.  Or just really resisting the installation of plugins.  I don't know whether we've seen an instance where WordPress itself has problems any longer.  I'll knock on wood here somewhere.  But in this case, this week's problem is known as the Responsive Menu WordPress plugin, which is exposing more than 100,000 WordPress sites to multiple critical and some high-severity vulnerabilities.  This Responsive Menu is a WordPress plugin designed to help admins create W3C, World Wide Web Consortium, compliant and mobile-ready site menus.



The group I mentioned, WordFence, the threat intelligence folks, found three vulnerabilities that can be exploited by attackers with only basic user permissions to upload arbitrary files and remotely execute arbitrary code.  And what was I saying about the rise of web shells.  This is exactly kind of thing you would install would be a web shell.  And a WordPress site would automatically be having a PHP interpreter running, so off you go.



The first of the three flaws enables authenticated attackers to upload arbitrary files which eventually allows them to achieve remote code execution.  So there you need some authentication.  That was one problem.  But the other two vulnerabilities allow an attacker to forge requests to modify plugin settings of the plugin, which in turn allows them to upload arbitrary files, allowing for remote code execution.



So to leverage these vulnerabilities, the attackers logged in as subscribers, or another low-level user, upload menu themes archived as zip files and containing malicious PHP files.  Once the archive is extracted for installation, the attacker could then access the files via the site frontend to remotely execute their malicious code, which ultimately can lead to a full site takeover.  So it sounds like a more involved kind of complex dance to go through to get remote code execution.  But if the target has sufficient value, and if for example a persistent web shell can then be dropped into a briefly vulnerable server, it might well be worth the effort.



So once again, unfortunately, a WordPress plugin is presenting an opportunity.  The problem is, we've talked about this, these are written in PHP.  We know absolutely, I'm sure, that all the plugin authors had the best of intentions.  But they're not professional security people.  So unless you have been exposed to directory traversal, the consequences of directory traversal attacks, or double file extension compromises, I mean, again, we keep seeing the same things happening over and over because people who aren't security professionals are writing code that has to be secure against threats that have become well known.  And so the same mistakes keep being made over and over and over.



So I don't know how we get ourselves out of this.  The only solution with WordPress is, if you've got to run your own, give it its own sandbox.  Give it its own virtual machine.  Restrict what it can do.  While I was running one, I gave it its own physical server and established a hardware firewall between it and the rest of GRC because I could not risk something getting loose in there.  And of course I was very careful about which plugins I installed.  I added a couple, but minimal, which is...



LEO:  I think plugins are really, I mean, at least historically it's all been plugins; right?  The core code I think is pretty good.



STEVE:  I think that's exactly right, yeah.  So a brief update on SpinRite.  Last week I talked about, and I made you chuckle, Leo, the anxiety-provoking Discovering System's Mass Storage Devices screen, where historically, if SpinRite was going to get tripped up, if it was going to have a problem, that was where it would happen, while it was scanning the system's drives.  What was often happening was that since SpinRite was having to always use the BIOS, which is what I'm working hard to get completely away from, it would make a BIOS call innocently, asking something about the drive, and the drive would have a problem, and the BIOS would just hang.  And so it's like, hello, okay.



Anyway, so I decided, as I mentioned last week, to show SpinRite's work in progress as it's doing the work.  And so I decided to post SpinRite's process and progress as it went along onto a screen.  And you've got it up on the show notes.  That's cool.  At this time last week, that was just a concept.  Today it exists.  I finished...



LEO:  I'm impressed.  Holy cow.  That's fast.  Wow.



STEVE:  I finished that work and posted a sample image, which you've got onscreen, of the new SpinRite screen to my work progress tracking thread of my blog on the GRC forums.  And also to GRC's spinrite.dev newsgroup.  But then, because actually seeing it work is really fun, I made a video.



LEO:  Oh, fun.



STEVE:  The link is there below the screen.  It is GRC's shortcut of the week, so grc.sc/806.  That will take you to a 25-second video of this process which is running on my mega-death development machine which, you know...



LEO:  Has a few drives.



STEVE:  ...has a bunch of controllers.  Yes, a bunch of drives, a bunch of controllers, all kinds of craziness.



LEO:  That is so cool, Steve.  That is really cool that you did that.  Can I ask you a couple questions about your development?



STEVE:  Yeah.  Yeah, yeah.



LEO:  So as we all know, Steve is - this is a DOS program because you can't run it while Windows is running, for obvious reasons.  So it's a, what do you call it, TUI; right?  It's a text-based user interface.  Do you by hand do the ASCII code for line, bar, cross, all of that?  Or do you have some sort of generator that you use to create that?  You must have a macro or something; right?



STEVE:  Sort of both.  There was a really neat text, kind of like text editor, written a long time ago, called Dan Bricklin's Demo.



LEO:  Oh, yeah.  Oh, yeah.  We know Dan, sure. 



STEVE:  Of course we all know Dan Bricklin.  He was the originator of one of the two, along with Bob Franklin of VisiCalc. 



LEO:  Frankston, yeah.



STEVE:  Yeah.  And so DBD, Dan Bricklin Demo, it was a DOS program that allowed you to sort of easily, like, edit screens, type text into windows and things.



LEO:  Right, right.



STEVE:  So I prototyped SpinRite's user interface in that.  But it was its own world.  So then I took from the prototype, what I did build was a full text windowing system.  So SpinRite is built on top of a textual windowing system where I'm able to, for example, push the screen, pop a window on top, and then point it to a description of what's in the window, and then for example things like the menu bar will automatically move up and down as the user presses up and down arrow.  So I'm coding a lot by hand, but I did sort of build sort of a windowing OS, a little windowing OS, and then I describe all of the different windows in a data structure that is efficient for that.  And it compresses down to just nothing because it's all text.



LEO:  So clever.  So that speeds all of this stuff up, all of these things that you have to do.



STEVE:  Yes.



LEO:  Yeah.



STEVE:  Yeah.  It means that I'm not having to write everything by hand.  I've got a bunch of tools.  And actually I'm so rusty with it that it's been good for me to build a new screen in this system because it's like, oh, that's right, I can do da da da da da.  So I have, I'm like rediscovering all the subroutines that I wrote two decades ago in order to bring this screen to life.  But anyway, grc.sc/806, you know, today's podcast number.



LEO:  Nice.  It's a cute little interface.  You can see the difference, though.  If you had to sit for 25 seconds even, looking at a blank screen, it gets a little nerve-wracking.  But if you see it doing stuff, it's like, oh, yeah, yeah, it's enumerating devices.  Go ahead, yeah.



STEVE:  Yeah, yeah.  And it's cool to actually get to see it, yeah.



LEO:  It's very cool, yeah. 



STEVE:  So the other thing that happened is - oh.  So I forgot to mention that I got that done at the end of last week, like I think it was Friday or maybe like - I think Friday night I released that, that is, the first piece of the new SpinRite code to the spinrite.dev newsgroup, and they all began pounding on it.  That is, they ran that all on their own systems, and on maybe a hundred different systems.  Maybe 75.  I didn't count them.



I ran across one problem that came back from a guy.  Chris in Germany has an AMD gigabyte motherboard with a Phenom processor.  Everything's great if he boots from floppy.  But if he boots from a USB, we have a hang problem.  It was happening with ReadSpeed, the predecessor code.  I finally - just the problem kind of went away.  And I was like, okay, well, I'm glad it's not happening any longer.  Anyway, it's back.  So yesterday or the day before I purchased - I found that motherboard on eBay.  And so I've got one of them coming.  Because really the only - this is just some obscure, I don't even know what the problem is.  But there's that.



Then a couple people had a problem with that last phase you can see in the video where all the hardware is first enumerated, and all of the drives are found, the controllers and their drives.  And then it goes back in and patches in the BIOS numbers.  Well, that's important because drives that SpinRite doesn't recognize through hardware, it will still allow to be accessed the way it always has been through the BIOS.  It's not ideal, but at least you can still run it.  And that's what SpinRite has always allowed you to do.



But now the problem is, if it doesn't - if it finds the hardware, but isn't able to associate it with its BIOS number, then you'll get two listings for one drive.  SpinRite won't know that there are actually two references to the same drive.  And so I call that BIOS association.  And it's tricky because...



LEO:  So that's what's happening with this NVME here.  It's identifying both as NVME and SCSI.



STEVE:  Exactly.



LEO:  Yeah.



STEVE:  Exactly.  So it's probably the NVME that is actually appearing as that last BIOS drive.  



LEO:  Right.  Oh, I see, 88, yeah, yeah, yeah.



STEVE:  And so that's the way you will access it.  But imagine if any of those lit up in white drives if they didn't have their BIOS numbers next to them.  Then it would show the BIOS item because it would think that it's going to have to access it that way.  But also it would show the physical drive.  Well, so one of the ways I got around that was by hashing the boot sector of every physical drive and then accessing the boot sector through the BIOS, hashing that and looking for a match.  It works unless two drives have identical boot sectors.  And in one case, one of the systems had two 1TB drives and two 500GB drives.  Since they were identical size, and they were set up by the same guy at the same time, they had identical boot sectors.  So they had the same hash, and SpinRite was unable to disambiguate them.  I have a solution for that also that involves deliberately leaving the drives in an error condition and then reading from the BIOS, which will clear the error condition in the hardware.  And that mostly works.  But in this case it isn't.



So anyway, that's where I am this evening.  I have an idea now about how to make that fallback process more robust.  And the moment I get that done, then - and of course I'll get this USB boot gigabyte AMD Phenom processor-based motherboard in, and I'll stick it in a chassis and see if I can recreate Chris's problem.  Hopefully I'll be able to make it happen here, in which case I'll just figure out what's wrong, and I will dance for a while because when Chris posted a couple days ago that he was having this problem, it's like, oh, I thought that one was gone.



LEO:  Damn.



STEVE:  I didn't really earn it.  It just kind of disappeared.  And so it was like, okay, well, I guess I'm going to have to really figure out what's wrong.



Okay.  So on the screen, in the show notes, is what happened when I put one of my email addresses into this test site:  "Oh no!  Your email address has been leaked."  Now, the good news is I ran through first all of the email addresses I think I have ever used at GRC.  None of them were there.  Then I put my Gmail address in, and that's the one that came up.



Okay.  So I'm getting ahead of myself a little bit.  But I did want to refer our listeners to this leak tester.  I gave it its own GRC shortcut, grc.sc/comb.  That will bounce you to the personal data leak check at CyberNews.com, who are the folks that wrote about this monster database leak and immediately brought up a site check that allowed people to perform a database query against their email address.



So the CyberNews guys wrote:  "It's being called the biggest breach of all time and the mother of all breaches."  Of course, the mother of all breaches would be MOAB, which in my opinion that would be a far cooler name, although technically MOAB has already been taken by the Mother Of All Bombs, which is you may remember that low air dispersion, just this insanely powerful - or maybe it was a bunker buster that was a MOAB.  I don't remember.



But anyway, we haven't checked in on the status, as I mentioned, of the underground dark web's aggregation and maintenance of massive login credential lists in quite some time.  So I thought that this recent appearance of the latest and by any measure greatest such compilation would be a good opportunity to see where all of that currently stands.  COMB stands for Compilation of Many Breaches.  It contains more than 3.2 billion, with a "b," unique pairs - unique pairs, so no reps - cleartext emails with their matching passwords.



I've embedded a screenshot of the hacker's announcement from exactly two weeks ago, February 2nd, in the show notes.  And the fine print, he has four bullet points which I had to squint to read, so I've also reproduced them in the show notes.  Four bullet points.  He wrote:  "Most of the contents are almost all publicly available."  He said:  "Compilation of many breaches is built on the breach compilation which was 1.4 billion entries."  And he says:  "And more new leaks added, for example, Collection #1-#5, and many more."  So these are things, you know, we're beginning to see a little bit of the parlance of the dark web because, like, the people who are typically reading this are like, oh, yeah, yeah, of course, the Collection 1-5.  But it's not something we talk about.



He said, second bullet point:  "All data is in an alphabetical order in a tree-like structure."  He says:  "As with the Breach Compilation, a query script is included."  And he says:  "All data is archived and added to an encrypted and password-protected container.  Password is below."  Although you can see in the screenshot it says "Hidden content for authorized users."  And whoever was viewing this was apparently not authorized.  Or maybe they didn't take a screenshot of that.



In any event, CyberNews, the people who posted about this, claim that they were the first leak test database to include the COMB data.  And since COMB was first released, they said that nearly one million users had used their personal data leak checker to see if their data was included within this biggest breach compilation of all time.  And as I said, I checked all of my various GRC email addresses that I've had through the years, and they all were clean.  But when I checked my Gmail account, which I sort of use as just a generic spam filtering bit bucket - like if I don't really want to give someone my GRC email, I'll give them my Gmail - I received the screen above, which informed me that my email address had appeared in a breach.



Fortunately, I do change that, my main Google password, from time to time.  It is a long, high-entropy, total gibberish password.  And I have one-time password multifactor authentication enabled, less for Gmail, which I don't really care about, than for my Google account itself, which I do.  But I never use that Gmail account for anything that, for example, might need password recovery.  So nothing sensitive is even passing through that account.  And although it's unusual behavior with Gmail, where they encourage you to leave everything there, I routinely delete everything from my inbox and trash.



LEO:  Do they have the passwords for this account, or just the  email address?



STEVE:  Well, I don't know.  They say they have an email address and some password.  So I don't know what it is that they have.  You can't see that.  I don't know, I mean, so...



LEO:  I mean, email addresses are not hard to come by.



STEVE:  No, they're not.



LEO:  And by themselves it's meaningless that somebody has it except you might get more spam.



STEVE:  Correct.  And I may have used - and I do, as I was just saying - I use that for, like, throwaway accounts.  So, for example, I might have used my Gmail account on some other site when I was creating an identity there.  So I used that and some password.  That site leaked its information.  So it's not my Gmail account password that was associated with the Gmail email, it was some random password at the site.  So what we hope, however, is that even back then, and I don't know when "then" was, but there was a day, Leo, when you were known by your monkey password.



LEO:  It could have been that.  It could be that.



STEVE:  So we've all gotten better since those early innocent days where we use - although a lot of people still use "password123" as their password, unfortunately.



LEO:  How is this different from HaveIBeenPwned?  Is this a bigger database?



STEVE:  Yes.  It is a bigger database.  I went over to see whether HaveIBeenPwned had updated yet to include this.  It doesn't look like they have.  They did mention the Collection 1.



LEO:  They have the Anti Public Combo List.



STEVE:  Yes.  Yes.  And actually that's here somewhere.  I did run across Anti Public and Exploit.in.  Those are also both incorporated here.



LEO:  And they have Collection 1, yeah, yeah.



STEVE:  Yeah.  So it looks like, in general, these guys are trying to be the one-stop shop for everything.



LEO:  I'd say that's the big difference between this and HaveIBeenPwned because, in the case of HaveIBeenPwned, they tried to tie it to the breach that is associated with that email address.



STEVE:  Right.  Right, right, right.



LEO:  So you maybe can get some guess as to what password has been breached.



STEVE:  Yeah.  So they're seeing things in this COMB database - Netflix, Gmail, Hotmail, and Yahoo.  You know, email address domains.  They did some counting, and they found approximately 200 million unique Gmail addresses and 450 million Yahoo email addresses.  And again, those are not necessarily the login for those services.  They could just be other sites that were breached, and people used those addresses at those sites.  Microsoft confirmed Outlook had been breached back in 2019, or I guess between January and March of 2019, so hackers were able to access some of the Outlook.com, Hotmail, and MSN email accounts.  We know that Yahoo suffered what was probably the biggest breach of ever.  The breach occurred in 2014, but remember they didn't tell anybody about it for two years, until 2016.  In that case, bad guys apparently had access to all three billion of Yahoo's user accounts which were impacted.



So, and of course we know that these days many exfiltrated passwords are now hashed.  Older ones weren't, back in the really early days.  And then even in the early days of password hashing, those that were, were not well hashed - few if any iterations, maybe no salt added, or maybe a static salt for the site.  It wasn't until later that we understood, okay, you've got to do per-account salt, and you've got to iterate the hash a whole bunch to make it really difficult to reverse.  So consequently some of these raw databases contain email in plaintext and passwords as hashes.  However, when the data from the previous breach compilation was analyzed, it was found that 14% of exposed username/password pairs had not previously been decrypted by the community and were now available in cleartext.  So it looks like the project of reversing these password hashes is an ongoing campaign, and there is progress being made on that front.



And then, anytime you have a database like this, there's the question of age; right?  Because these things do tend to just continue to grow.  Hackers always want to say, oh, yeah, mine is bigger than yours.  So to say 3.2 billion email addresses and passwords, the question is, yeah, but how many of them are still good for anything?  As we know, the older the lists are, the less useful they're going to be.  However, when the identity intelligence company 4iQ discovered that breach compilation database in 2017 - so, what, four years ago - they tested a small subset of the passwords for verification, and most of the tested passwords worked, they said.  So the threat analyst stated at 4iQ that they found this 41GB dump on December 5th of 2017, with the latest data updated on November 29th of that same year of 2017.  And we talked about this at the time, if anybody says, oh, yeah, that kind of sounds familiar.  It did for me, too.



The 4iQ researchers note that the leak was not just a list, but rather an interactive database that allowed for fast one-second response searches and new breach imports.  Given the fact that people reuse passwords across their email, social media, ecommerce, banking, and work accounts, hackers of course can automate account hijacking and account takeover, or at least try.



Okay.  So what are our takeaways from the news of there is now a 3.2 billion item list?  For one thing, old, forgotten, and unused accounts often remain active; right?  I mean, unless you go and kill it, it's probably still there somewhere.  Something somewhere that you might not have used for years could still be active, probably is.  And it could allow a bad guy to gain a foothold, if you've just sort of abandoned it, but it's still there, if it's still possible to access it using old credentials.  So one thing we could all do is ask ourselves about any accounts that we haven't used for a long time, perhaps since before we began using a password manager, and so were much less cautious about our choice of password.  And monkey.



LEO:  123.  123.  Don't forget the 123, yeah.



STEVE:  Exactly.  And then of course shutting down any long-unused accounts will meaningfully reduce our online target profile.  It's worth considering.  And assuming that our password manager allows us to see a list of everything it's holding for us, we might take a moment to scan through it, just to see whether we really still need all of that.  We tend to accumulate a growing collection of one-off sites, where keeping an account might really no longer serve any useful purpose.



So again, reducing our profile just makes sense.  It's not always easy to delete our account, but increasingly it is possible.  So looking through your password manager and thinking, okay, I am just - there's no way.  Or maybe you create an account for something you thought you were going to be using that didn't happen, like how many apps have we downloaded over the years that qualify that way.  So again, reducing your target profile makes sense.  And if nothing else, you could have your password manager flip those passwords into the clear and just make sure that they have been turned into a long string of gibberish.  That is certainly worth doing.



And lastly, as these massive lists age, they automatically lose their value as people change their email and hopefully their passwords.  But we can all help those lists age out even faster by deliberately obsoleting the data that they contain about who we were, which is us.  We can't change what the lists say about our past.  That's in the lists.  But we can arrange to have them say nothing about who we are today.  And just sort of some measures to stay safe on the Internet.



LEO:  A little hygiene.



STEVE:  Yup.



LEO:  Yeah.  And a good password manager, LastPass, for instance, has a security challenge you can go through that I think, I'm pretty sure they also have access to a database, maybe HaveIBeenPwned.  And your browsers now do that, too.  There's a Chrome extension will say, we've seen this login somewhere else.  Watch out.



STEVE:  And in fact I think it's built into Chrome itself because...



LEO:  Might be now, yeah, yeah.



STEVE:  Yeah, because there was something I was using, I think I mentioned it the other day, where it came up and said, oh, look, this password has been used in a breach.  And I went to look, and I go, oh, yeah, that was on purpose, actually.  So, yeah.



LEO:  I breached myself.



STEVE:  I knew what that was.



LEO:  Steve Gibson.  He's the only guy who breaches himself.  There he is, right there.  He is the...



STEVE:  I'll have to be careful about that.



LEO:  ...man in charge at GRC.com.



STEVE:  I'm probably not the only guy.



LEO:  No, no, no, no.  He's a self-breacher.



STEVE:  So next week.  I did want to tease next week.  Unless something even more tantalizing comes up, we're going to examine - oh, my goodness - a brilliantly clever new concept supply chain attack that was fortunately pulled off by a good guy security researcher because, if it hadn't been, all hell would have broken loose.  Thirty-five major companies were breached in this experiment.  So we've got a really fun topic for next week.



LEO:  Yeah, and the Supermicro hack is back in the news.  Bloomberg is putting more information out.  Supply chain, thanks to SolarWinds, what you're about to talk about, and quite rightly so.  Supply chain attacks are very much in people's minds these days.  That's a real hazard.



STEVE:  And remember that we never got definitive proof about Bloomberg; but at the time I said, okay, maybe it didn't happen.  But, boy, could it have.



LEO:  Yeah.  And, you know, we've done, the NSA has done this with Cisco routers and stuff.  So it happens.  We know it happens.  And so it's something to be very much aware of.  Good, I look forward to that.  That's next week.



You can get today's episode and all 806 Security Now! episodes at Steve's site.  He's got some unusual versions.  He specializes in collecting the weird versions, like the 16Kb audio versions for those who don't have a lot of bandwidth.  He has 64Kb audio, as well.  And he has transcripts.  Elaine Farris actually writes down these immortal words so that you can read along as you listen, or search - I think that's the most useful reason to have those transcripts - for the thing you're looking for and jump right to that part of the episode.  All of that's at GRC.com.



While you're there, do pick up a copy of SpinRite, SpinRite 6, the world's finest hard drive maintenance and recovery utility now getting more useful, more interesting all the time as we head towards 6.1.  You'll get a free copy of 6.1 if you buy 6 today.  You'll also be able to participate in the development of 6.1.  These little side alleys that you're going down are fascinating, and I think I'm really looking forward to seeing 6.1.  It's going to be a lot of fun.  Coming soon.  Steve has lots of free stuff, as well, including ShieldsUP!, which is a great way to test your router.  I don't install a new router without running ShieldsUP!.  And periodically I'll check it, as well.  Lots of other fun stuff.  GRC.com.



STEVE:  You know, Leo, that DNS Benchmark?



LEO:  That's a really good one.



STEVE:  It's 3,000 downloads a day.



LEO:  Yeah.  No, I'm not surprised.  It's a really good way to find a better DNS server than your ISP's.  But also if you're considering something like Cloudflare's Quad1 or Quad9's or NextDNS or some of these other DNS servers, it's really a good idea to test it first with the DNS Benchmark to see what your local results will be.  You don't want to choose a slow DNS server.  That's not a good thing.



We also have copies of the show at our website, TWiT.tv/sn.  We pretty much stick with 64Kb audio, and we do do a video version, if you want to watch, see the blinking lights here, the blinking lights there, all the blinking lights everywhere.  That's all at TWiT.tv/sn for Security Now!.  There's a YouTube channel for Security Now!, dedicated just to that show.  You can share that with your friends.  It's a good way to share the show with your friends, just a link to the YouTube video, because you can even pick the part of the video, the time code and everything, and jump right to that.



We also of course are on every podcast program and directory.  If you use a podcast program, probably that's the easiest thing to do is subscribe in that, either to the audio or the video, to get it automatically.  Steve is on Twitter.  @SGgrc is his handle.  You can DM him there.  His DMs are open, @SGgrc, if you've got a tip or a question or a comment.  You can also do it on his website, GRC.com/feedback.  Next week, Supply Chain Attacks.



STEVE:  Ooh, a good one.  Very, very clever new way.



LEO:  Thank you, Steve.  Have a great week.  We'll see you next week on Security Now!.



STEVE:  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#807

DATE:		February 23, 2021

TITLE:		Dependency Confusion:  The Build Chain Hack

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-807.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we'll follow up on the Android SHAREit app sale.  We look at a clever new means of web browser identification and tracking, and at a little mistake the Brave browser made that had big effect.  I want to remind our listeners about the ubiquitous presence of tracking and viewing beacons in virtually all commercial email today.  We'll look at Microsoft's final SolarWinds Solorigate report, and at another example of the growing trend of mobile apps being sold and then having their trust abused.  I'll share a post from the weekend about a dramatic improvement in SSD performance after running SpinRite, but also why you may wish to hold off on doing so yourself.  And then we're going to look at what everyone will agree was  and perhaps still is  a breathtaking oversight in the way today's complex software products are assembled, which creates an inherent massive vulnerability across the entire software industry.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and lots to talk about.  We'll have more on that SHAREit vulnerability.  Apparently it's been fixed now, but we'll tell you how it happened.  We also have a lot more from Microsoft on the Solorigate story.  And we'll talk about Dependency Confusion, a real security vulnerability that is causing a lot of consternation in businesses all over.  So we'll talk about that and a lot more, coming up next on Security Now!.  Stay tuned.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 807, recorded Tuesday, February 23rd, 2021:  Dependency Confusion.



It's time for Security Now!, the show where we protect your security, privacy, safety, knowledge base with Mr. Steve Gibson from GRC.com.  You are knowledge base protection.



STEVE GIBSON:  Just when you thought it was safe to leave the house.



LEO:  No, no.	



STEVE:  No, actually, the house is where a lot of these problems are happening.



LEO:  No leaving the house.  Yeah, it's true, isn't it, yeah.  Hi, Steve.



STEVE:  Hello, my friend.  This is 807, Security Now! 807.  



LEO:  Yes, yes.



STEVE:  Titled "Dependency Confusion."  And I mentioned last week that if nothing earthshaking happened in the intervening week, this is what we would be talking about.  And it's hard to imagine that anything could be earthshaking enough to push this one further away.  I also mentioned that our Picture of the Week last week sort of was meant to tie in with this.  But when I looked more closely at this, I thought, okay, this needs its own show.  And no one is going to think this was the wrong decision.  Just wait till everyone gets a load of the, I mean, the breathtaking mistake that the entire industry has been making and was caught out about.  And arguably, it is so pervasive that only the major players have probably noticed this and fixed it.  There will no doubt be lots of little backwaters that are going to be bitten.  So this is huge.  The subtitle is "The Build Chain Hack," and it's our main topic.



But there's a lot to talk about.  We're going to follow up on the Android SHAREit app sale that we talked about last week.  We're going to look at a clever new means of web browser identification and tracking, like yet another new way of doing this, which all the browsers at the time of this research are vulnerable to.  Actually, the Brave browser got a little advance heads-up from these guys, and so they've already fixed it.  But none of the other browsers have yet, so they will be.  And also a little mistake, speaking of the Brave browser, that had a big effect.



I also want to remind our listeners about the ubiquitous presence and tracking of viewing beacons, which are now present in virtually all commercial email, just for those who might not be thinking about that.  We'll also take a look at Microsoft's final SolarWinds Solorigate, as they named this thing, report, and another example of the growing trend of mobile apps being sold and then having their trust abused.  This appears to be like a thing now.



I'm going to share a post from the weekend over in the GRC forums about a dramatic improvement in SSD performance that one of our testers found after running SpinRite, but also why you may wish to hold off on doing so yourself.  And then we're going to look at what everyone I am sure will agree was and perhaps still is just a breathtaking oversight in the way today's complex software products are assembled which creates an inherent massive vulnerability across the entire software industry.  I mean, this is not one vendor's widget that had a glaring mistake for a long time.  This is, like, stunning.  And Leo, because you understand how this stuff is assembled, assembling much of it yourself, I'm just glad you're seated for the podcast.



LEO:  I'm ready.  I am sitting on a ball, so I could fall off, if it's too shocking.



STEVE:  Oh, okay.  Well, yes.  Widen your stance, my friend.



LEO:  I think I know where you're going with this, not having read the show notes yet.  But I certainly know where there would be a supply chain issue with dependencies.  So I can't wait to hear about this.  Is it time for our Picture of the Week, Steve?



STEVE:  It is.  And this one is a little, I mean, I guess our pictures are always a little geeky.



LEO:  A little.  A little.



STEVE:  That's the nature of this podcast.  But this one is a little over - this is maybe over the top.  So it shows this guy looking at a screen, and it says "This website doesn't [in red] use cookies."  And then there's a button, "Got it, don't show again," which he clicks.  And then he sits there for a minute, and he thinks, wait a minute, if it doesn't use cookies...



LEO:  Don't do it, no.



STEVE:  Yes.  So he clicks Refresh, and up comes the same screen:  "This website doesn't use cookies.  Got it, don't show again."



LEO:  Proof.  Proof.



STEVE:  Yes.  Which of course is a problem because, as we know, something like cookies, some sort of tracking mechanism, is the only way of maintaining state from one browser request to another.



LEO:  There you go.



STEVE:  So it kind of needs to have cookies or something if it's going to be able to remember that you clicked on, okay, yeah, fine, don't show it again.  Which means - anyway, it's sort of self-contradictory.  As I said, a little bit on the over-the-top geeky side.



LEO:  Oh, but I love it because our audience gets it; right?  Yup.



STEVE:  Yup, exactly.  So last week we covered the disclosures from Trend Micro about the quite buggy SHAREit Android app, not because it was a quite buggy Android app, but because this particular quite buggy Android app happened to have an active user base somewhere north of one billion, with a "b," users.  We explained how Trend Micro...



LEO:  Steve, it wasn't buggy.  It did exactly what its creators wanted it to do.



STEVE:  Yes.  Unfortunately.  And so we explained how Trend Micro's ZDI, their Zero Day Initiative folks, had tried to contact SHAREit's publisher 90 days earlier with a disclosure of the very many worrisome problems they had found, and how after 90 days of no response they decided they'd done their due diligence and that at this point the many problems were so bad that now the responsible thing to do was to inform the public of the danger that those more than one billion users with a "b" remained in.  So I commented last week that perhaps after the public embarrassment of a widely respected security research firm disclosing the many design mistakes made by the app, maybe then its publisher would react.  And we wondered also what Google would be thinking about this, still having that app on their Google Play Store.



And indeed last Friday the Singapore-based SHAREit company issued a press release containing two bullet points.  First one says:  "SHAREit app is a leading file sharing, content streaming, and gaming platform.  Since its inception, billions of users have entrusted SHAREit to quickly and securely share their files.  The security of our app and our users' data is of utmost importance to us.  We are fully committed to protecting user privacy and security and adapting our app to meet security threats."  Okay.



Second bullet point:  "On February 15th, 2021" - which was last Monday - "we became aware of a report by Trend Micro about potential security vulnerabilities in our app.  We worked quickly to investigate this report; and on February 19th, 2021, we released a patch to address the alleged vulnerabilities."  So looks like it took a public exposure and embarrassment.  No doubt they heard from people, maybe Google, to get these guys to actually move because nothing, you know, three months of waiting  and Trend Micro trying to say, hey, take a look at this, they were just blown off.  Until, okay, now it's time.



I went looking for any update from Trend Micro, but so far there's nothing.  If they do decide to verify the fixes, it might take a while.  And this was only just last Friday that these SHAREit folks finally decided, ooh, okay, we'd better address this.  But also Trend Micro's original disclosure from the Monday before was comprehensive enough to allow anyone who wished to, to verify these things independently; and, unfortunately, any bad guys who wished to, to take advantage of the more than one billion-plus downloads and installs of this SHAREit app.



So I also went over to the Google Play Store to see whether there might be an update history of any kind.  I didn't find one.  But I did notice that the app showed as being updated yesterday, meaning Monday, February 22nd, and they had in their press release said they had updated it on February 19th.  So looks like it's now getting suddenly a flurry of updates.  So maybe they're still fixing things that are being - maybe there's some dialog with the security community with Trend Micro that we're not aware of.



Again, as I said, Trend Micro as of yesterday didn't have anything.  But it looks like this thing is finally going to get itself fixed, and hopefully Trend will stay on them to push this thing to a point where they now believe that it's safe.  So we can hope.  Anyway, an example of a security research firm being ignored, doing the right thing, being responsible, giving its publisher plenty of time, 90 days, and then saying, okay, we're lowering the boom.  And only then did they fix it.  And of course the downside with this is that it's going to probably take some length of time for some billion-plus users to update this.  And until that happens, there are a billion-plus vulnerabilities.



And remember that this is not the app itself which is vulnerable, but the design of the app has permissions which allow its presence in the Android device to be abused by anything that the user installs that is aware of SHAREit's problem and the fact that it's probably - there stands a good chance of it being installed in the phone.  So basically it's like the Android OS itself has been made far less secure by having SHAREit present.  And so hopefully Google's aware of this.  We'll see what happens.



This week in web browser tracking, or maybe where there's a will, dot dot dot.  And there sure does appear to be a large amount of will behind browser tracking.  I mean, it just must be that there's - it's just so valuable to know where we go on the Internet and to be able to track us.  And we've been talking about this from the beginning of the podcast.  From the day this podcast was born 15 years ago, tracking was an issue.  And of course it's enabled by the pervasiveness of, well, entities like Google that have their hooks into us no matter where we go, and also large advertising networks that similarly are pushing their own content onto websites everywhere.



And it's the pervasiveness of one entity that arranges to get our browsers to make a query back to them, no matter where we go, that then wants to know, oh, who is that who has made that query?  What do we know about them?  And of course I invested a lot of my time in the early days where third-party cookies, third-party tracking, as they were called, cookies, and the forensics of those I investigated back with some code on GRC.  Now the idea of using third-party cookies seems almost as quaint as floppy disk viruses.



But browser tracking is back in the news because a group of researchers from the University of Illinois at Chicago will be presenting this week their paper on the use of favicons for tracking during this weeks' virtual Network and Distributed System Security symposium, which is NDSS 2021.  Their 19-page paper is titled "Tales of Favicons and Caches:  Persistent Tracking in Modern Browsers."  For anyone who wants more detail, although you're really not going to need it because I'm going to explain this all, I do have a link to their 19-page PDF in the show notes.



So for those who are not aware, the favicon is the tiny little icon that appears typically at the left of browser tabs and also, as its name suggests, when we save a website link as a favorite.  So, for example, GRC has what I call the "Ruby G."  TWiT has that cute little TWiT AND-gate icon with an eyeball, standing on its two feet.  GRC's SQRL forums present the SQRL logo.  And pretty much every site you go to will have its own favicon.  And yes, I've heard it pronounced fav-i-con.  But just as a lib is a library...



LEO:  We know where you stand.  We know where you stand.



STEVE:  Yes.



LEO:  Yes.



STEVE:  A favicon is a contraction of favorite icon.  So no, I am not of the fav-i-con crowd.



LEO:  I am.  I say fav-i-con and lib.



STEVE:  No kidding.



LEO:  Oh, yeah.



STEVE:  All right.



LEO:  I guess, you know, really the two positions are the pronunciation is determined by what it's an abbreviation for, your position.  Mine is the pronunciation is determined by how it is used in its orthography, once the contraction is made.  So if it weren't for that you know that it was a favorite, if you looked at favicon, you would say fav-i-con.  But because you know it's a favorite, you say it's...



STEVE:  You're saying orthography versus morphography.



LEO:  Perfect.  Semantics versus syntax.  Perfect.



STEVE:  Okay.  And of course we have "jif" versus "gif," but let's not go there now.



LEO:  Unh-unh.  Unh-unh.



STEVE:  In any event, it turns out that, get this, all browser makers have assumed that since a whatever you want to call it, a fav-i-con or a fave-icon - actually, fav-i-con does kind of roll off the - anyway.



LEO:  Uh-oh.  Stick with morphology.



STEVE:  All browser makers have assumed that a favicon is sent from a site that makes its flow unidirectional.  So unlike cookies or web beacons or signals used for fingerprinting, the favicon didn't need anti-tracking protection.  And as a result of that, all browser makers cache their favicons in a separate cache which is never cleared when cookies are cleared or even when the browser's other caches are cleared.  And to add insult to injury, what's more, both the standard and the incognito mode interfaces of a browser share that single favicon cache.



So needless to say, if it turned out that there was some means of tracking users through favicons, not only would it be immune from the user's deliberate anti-tracking measures of flushing this or that browser cache, but it could also be used to breach the security boundary between the explicitly no-history-being-retained private browsing modes and the standard browsing mode.  Since there's only a single favicon cache, it would be possible to determine, for example, whether a browser had ever visited a site when it's in private browsing mode by seeing whether it requests a favicon from the site in question when not in private browsing mode.



And of course we know where this is going.  I was quite curious to learn how these guys had pulled this off, since a browser's retrieval of a favicon is a binary event.  Either it doesn't have one yet, so it'll ask for it, or it always has one, and thus doesn't need to ask again.  The hack is rather brute force, but I'll give them a "C" for clever.  So here's how they describe their work in the abstract of their paper.



They said:  "The privacy threats of online tracking have garnered considerable attention in recent years from researchers and practitioners.  This has resulted in users becoming more privacy-cautious and browsers gradually adopting countermeasures to mitigate certain forms of cookie-based and cookie-less tracking.  Nonetheless, the complexity and feature-rich nature of modern browsers often lead to the deployment of seemingly innocuous functionality that can be readily abused by adversaries."  And of course we've talked about all manner of those sorts of things in the past.



They said:  "In this paper we introduce a novel tracking mechanism that misuses a simple yet ubiquitous browser feature:  favicons."  Or fav-i-cons.  They said:  "In more detail, a website can track users across browsing sessions by storing a tracking identifier as a set of entries in the browser's dedicated favicon cache, where each entry corresponds to a specific subdomain.  In subsequent user visits, the website can reconstruct the identifier by observing which favicons are requested by the browser while the user is automatically and rapidly redirected through a series of subdomains.  More importantly" - and we'll talk about the details of that in a second.



"More importantly, the caching of favicons in modern browsers exhibits several unique characteristics that render this tracking vector particularly powerful, as it is persistent, not affected by users clearing their browser's data; non-destructive (reconstructing the identifier in subsequent visits does not alter the existing combination of cached entries); and even crosses the isolation of the incognito mode."  They said:  "We experimentally evaluate several aspects of our attack and present a series of optimization techniques that render our attack practical.  We find that combining our favicon-based tracking technique with immutable browser-fingerprinting attributes that do not change over time allows a website to reconstruct a 32-bit tracking identifier" - so that's unique 4.3 billion different browsers - "in two seconds.



"Furthermore, our attack works in all major browsers that use a favicon cache" - in other words, all major browsers - "including Chrome and Safari.  Due to the severity of our attack we propose changes to browsers' favicon caching behavior that can prevent this form of tracking, and have disclosed our findings to browser vendors who are currently exploring appropriate mitigation strategies."



Okay.  So this works since subdomains also each get their own favicons.  So these guys set up an HTTP 302 redirection chain to take the user's browser on a 32-subdomain walk, where the primary domain indicates whether this browser has ever visited this site before.  So if the browser doesn't need that main site's favicon, that's because this is not the browser's first visit.  So the site sends the browser off across a chain of 32 subdomains of that main site domain, noting which of the subdomains the browser asks for favicons from, and which it does not.  But it never gives the browser any new favicons to store.  That pattern of requests will be unique for that browser because, if the browser does ask for the favicon from the primary site, then the site knows that the browser has not yet been unique favicon tagged.



So now the site chooses a new 32-bit identifier, increments a master counter somewhere to get a unique identifier which it will assign to this browser.  And it uses that identifier to judiciously and selectively dole out, or not, subdomain favicons as it takes the browser on its 32-subdomain walk to match the 32-bit identifier that it has chosen for the browser.  So, yeah, it's kind of brute force.  I think it's kind of clunky.  But it's diabolical when you consider how none of our browsers have been treating their favicon cashes with the respect it is due.



The attack is currently effective a against Chrome, Safari, Edge - because of course it's Chromium.  And it was effective against Brave also since Brave is Chromium, until the researchers gave the Brave developers an early heads-up, which allowed Brave to beat the rest of the pack to the deployment of an effective countermeasure.



And interestingly, Firefox, which I haven't yet mentioned, would also have been vulnerable to the technique, and in a sense they very much wanted to be.  But it turns out that a bug in Firefox prevents the attack from working.  The researchers explain this.  They said:  "As part of our experiments, we also tested Firefox.  Interestingly, while the developer documentation and source code include functionality intended for favicon caching similar to other browsers," they said, "we identify inconsistencies in its actual usage.  In fact, while monitoring the browser [meaning Firefox] during the attack's execution, we observe that it has a valid favicon cache which creates appropriate entries for every visited page with the corresponding favicons.  However, it never actually uses the cache to fetch the entries.



"As a result, Firefox actually issues requests to re-fetch favicons that are already present in the cache.  We've reported this bug to the Mozilla team, who verified and acknowledged it.  At the time of submission, this remains an open issue.  Nonetheless," they said, "we believe that, once this bug is fixed, our attack will work in Firefox, unless they also deploy countermeasures to mitigate the attack."  Which of course they would when they fix it.



So anyway, it's kind of cool for Firefox.  They had the cache.  Turns out, due to a bug, they were never using it.  So Firefox was always issuing requests for favicons for all the sites we've been visiting and so was never susceptible to this particular attack.  On the other hand, when they fix this, they will speed up Firefox.  That's good.  And presumably they'll also deploy a fix for this, however they decide to arrange to do that.



So anyway, everybody's going to fix this.  They're all on it.  If anybody is really worried in the meantime, it turns out that all the various browsers provide some means for disabling their fetching of favicons.  I don't know why anyone would.  But maybe just to reduce your fingerprint.  I can't imagine not having those cute little icons on all my browser tabs.  I mean, they're really handy.  But I do have three DuckDuckGo search links for Chrome disable Favicon, Safari disable Favicon, and Edge disable Favicon, if anyone just wants to click the links as opposed to putting it into their DuckDuckGo search engine.



So it can be done.  It's going to get fixed.  It was sort of a clever hack.  And so props to those guys.  Again, sort of brute force-y, you know, to store some combination of favicons in 32 subdomains off of the main domain.  But it could get a unique ID in two seconds.  Maybe you could do it in the background.  While the main site was showing you its page, it would be sending some other resource off on that 32-website redirection chain.  Basically the browser pulls up a subdomain.  It receives a 302 redirect.  And meanwhile, the browser has asked for the favicon for that subdomain.  The browser then goes to the next domain in this chain, and that repeats 31 times.  So kind of clever.



But I mentioned that the Brave browser has just fixed a privacy mistake.  It was kind of bad.  And I'm a little annoyed with them.  So the privacy mistake was that the Brave browser was sending DNS lookup queries for .onion domains - in other words, domains that are supposed to be hidden, right, by Tor - out onto the public Internet, rather than routing them through Tor nodes.  This, of course, exposes users' visits to dark websites.  The mistake was fixed in a hot fix release of Brave 1.20.108 which was made available last Friday.  So anyone who is depending upon Brave's otherwise nifty built-in what they call the "private window with Tor" feature for safer TOR-based anonymity will want to be sure to be running the 1.20.108 or later release.



And the source of the bug is interesting.  The trouble arose from Brave's internal ad blocking component.  It uses DNS queries to discover sites that are attempting to bypass its ad blocking capabilities.  But the developers had forgotten to exclude .onion domains from these DNS checks.  Whoops.  So the thing I mentioned that's a bit disturbing is that the Brave folks have known about this for some time.  It was first reported to the HackerOne bug bounty site by the person who discovered it and thought it was bounty worthy back in the middle of January, on the 13th, after which the bug was fixed in a Brave nightly release in early February.



Apparently the fix was planned for a rollout in a larger point release, which would have been 1.21.something.  But the flaw was publicly disclosed on Ramble, which pushed the Brave folks to advance their timetable and release the interim 1.20.108.  So I'm a bit uncomfortable with the idea that something that's as significant, privacy critical as publicly resolving .onion domains without Tor's privacy protection wouldn't be regarded as an emergency with a patch pushed immediately by the Brave folks.  I mean, it's one thing not to offer privacy.  But to say that you're offering it and not deliver it, and know you're not delivering it, but still saying you're offering it, when you could fix it, that seems a little wrong to me.  But, and I put this in the show notes, I suppose it's a brave new world.  Yes.



And I will, before our next break, I will mention, just to sort of put this back on our listeners' radar, while we're on the subject of tracking, I'll note that today a huge percentage of email spam, like virtually all of it, contains embedded tracking beacons.  And I know this is not news, but I just kind of wanted to remind everybody about it.  These days the transition from text-only to HTML email is pretty much complete.  Most people want to see pretty colors and fonts and logos in their email.  And while it's possible for email to embed those graphics, it's also possible for an email to contain a serial number-encoded URL back to the mothership.  This essentially turns your email client into a web browser so that the act of opening and viewing that lovely colorful email causes your email client to obtain an image from a remote server which, because the URL is encoded with your identity, confirms your receipt and viewing of the note.



And again, I'm not saying that any of this is news.  But I just kind of wanted to refresh everyone's awareness of it.  There was a recent report in the BBC news titled "Spy pixels in emails have become endemic."  And the report told the story of the fact that today, virtually all commercial email embeds these callbacks to confirm the viewer's reception and display of the email.  Many email clients offer add-ons for blocking these little spying beacons.  Of course it's also possible to configure most clients not to display any images at all, or even go further and display the email as old-school plaintext.  So there's no big takeaway for our listeners, but I just wanted to remind our security and privacy anti-tracking friends that there is another vector of monitoring that is going on, often unobserved and underreported.  So just a heads up and reminder about that.



LEO:  Yeah, that's why I use text-only email.



STEVE:  Yes.



LEO:  HTML email is a bad idea.  But people persist.  



STEVE:  Yup.



LEO:  It's actually worse than tracking pixels.  You could embed malware in it, if it's a web page, and you don't have all the patches.  Could be just as bad as that.  All right.



STEVE:  And during the transition, remember that you used to be able to configure, what was it, Eudora and then Outlook, you could say "Use HTML," or "Only render as text."  And that was our advice back then was oh, my god, you do not want IE having a presence in your email because...



LEO:  I will only use email clients, MUAs, Mail User Agents that support text only.  And I do, on the Mac, it's called MailMate, and it supports only text.  There's TXT.  RTF is probably more safe, I would bet.



STEVE:  Yes.



LEO:  And then there's HTML, which is not.  Now back to Steve.



STEVE:  So Microsoft's final, hopefully, report on what they named Solorigate.  Last Thursday Microsoft posted the results of their research into the details of their own SolarWinds breach.  And I will, I have for the show notes, paraphrased from their larger posting, which is a little self-serving and so forth.



They said:  "We have now completed our internal investigation into the activity of the actor and want to share our findings, which confirm that we have found no evidence of access to production services or customer data.  The investigation also found no indications that our systems at Microsoft were used to attack others."  Okay, which that really wasn't a deal, but okay.  "Because of our defense-in-depth protections, the actor was also not able to gain access to privileged credentials or leverage the SAML techniques against our corporate domains."



They said:  "We detected unusual activity in December and took action to secure our systems.  Our analysis shows the first viewing of a file in a source repository was in late November and ended when we secured the affected accounts.  We continued to see unsuccessful attempts at access by the actor into early January of 2021, when the attempts stopped.  There was no case where" - and this is interesting phraseology.  I had to read this one a couple times.  What?  "There was no case where all repositories related to any single product or service was accessed."  Which sounds like, how can we put the best possible spin on this?  "There was no access where all repositories related to any single product or service were accessed."  Okay.



LEO:  Yeah.  Parse that, yeah.



STEVE:  Yeah.  They said:  "There was no access to the vast majority of source code."  Okay.



LEO:  Vast majority.  Vast majority.



STEVE:  That's right, uh-huh.



LEO:  No access.



STEVE:  "For nearly all of code repositories accessed, only a few individual files" - you know, the juicy ones - "were viewed."



LEO:  Just the good stuff, yeah.



STEVE:  Yeah.  As a result of a repository search.  In other words, the bad guys searched the repository and only viewed a few things.  



LEO:  Oh, good.



STEVE:  Yeah, gee.  You think maybe they were the dumb files?  Or maybe they were the good files because, you know, we know that they have a repository search.  Okay, anyway.  They said:  "For a small number of repositories" - again, the ones the attackers wanted; right? - "there was additional access, including in some cases downloading component source code.  These repositories contained code for:  a small subset of Azure components (subsets of service, security, and identity); a small subset of Intune components; and a small subset of Exchange components."  Again, we know how good these guys are.  They were probably worried about being, like any of this being caught.  So they only got the things they wanted.  Anyway, thank you, Microsoft.



"The search terms used by the actor indicate the expected focus on attempting to find secrets."  Okay, now, this is interesting, and props to Microsoft.  They said:  "Our development policy prohibits secrets in code, and we run automated tools to verify compliance."



LEO:  Hmm.



STEVE:  Yes.  "Because of the detected activity, we immediately initiated a verification process for current and historical branches of the repositories.  We have confirmed that the repositories complied and did not contain any live production credentials."  And so I'll take note of this sentence.  "Our development policy prohibits secrets in code, and we run automated tools to verify compliance."  Yay.



Now, how many times have we talked about vendors, both small and large - can you say Cisco? - introducing horrific remote vulnerabilities into their production products when "secret," and I have that in quotes, accounts and passwords are embedded?  We should all have learned long ago that secrets can never be kept, least of all embedded in firmware.  That's bad.  And so, again, yay to Microsoft for recognizing code should never have secrets.



Anyway, they finish:  "The cybersecurity industry has long been aware that sophisticated and well-funded actors were theoretically capable of advanced techniques, patience, and operating below the radar; but this incident has proven that it isn't just theoretical.  For us, the attacks have reinforced two key" - unfortunately they said "learnings that we want to emphasize."



LEO:  That's a Microsoft logism.



STEVE:  Oh, Leo.



LEO:  Mary Jo Foley has mentioned it in the past, yeah.  I don't like it.



STEVE:  Yes, we have some learnings to share.



LEO:  Learnings.



STEVE:  Stand by.  Anyway, and those learnings in this case are embracing a Zero Trust mindset and protecting privileged credentials.  And then they expand on these two learnings:  "A Zero Trust 'assume breach' philosophy is a critical part of defense.  Zero Trust is a transition from implicit trust, which is assuming that everything inside a corporate network is safe, to a model that assumes breach and explicitly verifies the security status of identity, endpoint, network, and other resources based on all available signals and data."



And you know, Leo, if they can't get the bugs out of Windows, I'm kind of glad they're at least spending all the money they have on their own internal security because that's better.  I mean, at least, as far as we know, Windows doesn't have deliberate bugs that have been installed by bad guys.  They're just bugs that Microsoft has made mistakes on.  So that's better.



And they said:  "We've recently shared guidance for using Zero Trust principles to protect against sophisticated attacks like Solorigate."  And then they finish:  "Protecting credentials is essential.  In deployments that connect on-premises infrastructure to the cloud, organizations tend to delegate trust to on-premises components.  This creates an additional seam that organizations need to secure.  A consequence of this decision is that, if the on-premises environment is compromised, this creates opportunities for attackers to target cloud services."



So in other words, you don't want to automatically give your local network credentialed access to the cloud because, if bad guys get into your LAN, then they will leverage that automatic access to the cloud to move themselves into the cloud.  And so don't do that.  That's one of those "learnings" which Microsoft has had.



LEO:  Learnings.



STEVE:  So anyway, a very good point about not having any embedded secrets in code.  And it's sort of interesting that they were able to profile the repository queries that the bad guys were making to posit what it was they were probably hoping to find.  And of course we also know that getting source code allows you to go over it from the standpoint of a bad guy perspective, finding things that the authors haven't found.  And I would argue maybe they weren't so much looking for secrets as looking at, oh, look, here's a type confusion problem that we can leverage into a buffer overflow in Exchange Server.  So buckle up.  We'll see.



LEO:  Wow.  Wow.



STEVE:  We have a second instance of a highly popular Android app being sold for the express purpose of exploiting the app's well-earned existing install base for adware profit.  And one instance is an event.  Two, I would say we're beginning to see a trend.  And yes, perfectly placed sigh there, Leo.



LEO:  Mm-hmm.



STEVE:  For some time, Malwarebytes has been exploring how a previously trusted, useful barcode and QR code scanner app on Google Play that accounted for over 10 million installs had suddenly become malware overnight.  After gaining a following and acting as just what it was, innocent software for years, more recently Android users began to complain that their mobile devices were suddenly full of unwanted ads.  This suddenly troublesome app was just called Barcode Scanner.  Kind of generic.  It was finally identified as the source of this nuisance and is now tracked as Android/Trojan.HiddenAds.AdQR.



Malwarebytes determined that recent malicious updates of that app had resulted in aggressive advertisement pushing which had been added to the app's code.  The app's analytics code was also modified, and the updates to it were heavily obfuscated.  Malwarebytes concluded that the App's owner, Lavabird Ltd., was likely to blame since that was the ownership registration at the time of the update.  And once reported, the software was pulled from the Google Play Store.  So there was a window of time during which the new owner had basically made the good app go bad, was generating revenue from this torrent of ads they were pushing, presumably realizing that their time in the sun was limited before Google would yank it.  But they were going to make as much money during this window as they could.



So what was equally suspicious was that, at the time, Lavabird did not respond to requests for comment from Malwarebytes.  However, the vendor has since reached out to Malwarebytes with an explanation of the situation.  So that is to say, Lavabird said, okay, look, here's what's going on.  So on the 12th of February, 12th of this month, which was, what, Friday, couple Fridays ago, Malwarebytes said that Lavabird blamed an account named the "space team" for the changes, following a purchase agreement in which the app's ownership would change hands.



LEO:  Ah.



STEVE:  Yup.  Apparently, Lavabird was an escrow-like intermediary between the original author and seller and its eventual purchaser.  Lavabird purchased the Barcode Scanner on November 23rd.  And the subsequent "space team" deal was agreed to two days later, on November 25th.  Lavabird told Malwarebytes that they develop, sell, and buy mobile applications.  So they're sounding a little bit fishy.  But the monetary transactions for mobile applications, it turns out, has become a thing.



Lavabird explained that the "space team" purchaser of Barcode Scanner was granted access to the app's Google Play console for the purpose of verifying the software's key and password prior to confirming the purchase.  And it was that provisional buyer who first pushed the malicious update out to Barcode Scanner users.  And this made sense to Malwarebytes, who wrote:  "Transferring of the app's signing key when transferring ownership of the app is a legitimate part of the process.  Therefore, the request by the 'space team' to verify that the private key works by uploading an update to Google Play seems plausible."



After the update was performed, the app was transferred to the buyer's Google Play account on December 7th.  However, Malwarebytes said that at the time of the malware update, ownership was still tied to Lavabird.  The first malicious update took place well before that, back on November 27th, which was two days after the original November 25th purchase.  And subsequent updates obfuscated the malware's code.  Until January 5th, when the app was yanked from Google Play.



So this tactic was apparently more surprising to Malwarebytes than it would be to our listeners.  Their researcher, Nathan Collier, wrote:  "From our analysis, what appears to have happened is a clever social engineering feat in which malware developers purchased an already popular app and exploited it.  In doing so, they were able to take an app with 10 million installs and turn it into malware.  Even if only a fraction of those installs updated the app, that's a lot of infections.  And by being able to modify the app's code before full purchase and transfer, they were also able to test whether their malware would go undetected by Google Play on another company's account."  That is, while it was still under another company's account.



So it seems we need a new flag added to Android apps in the Google Play Store.  Or maybe like a flag added to the update process.  An app's change of ownership need not be a malicious event, but it certainly can be.  And as I said, we're now seeing instances where good Android apps are being purchased by somebody who wants to exploit them.  And you could hardly blame the original author, who created an app.  Maybe it wasn't generating any revenue.  It was clean.  It was therefore very popular.  So he cashes out, you know, this 10-plus million user base for some money.  That app is turned into malware.  There's now a window of opportunity before Google gets wise to its misbehavior and removes it.  But if during that length of time it can participate in bitcoin mining, or it can be showing ads that generate revenue, then unfortunately this is a viable profit model for taking free Android apps and despoiling them for some period of time before they go bad.



So the point is, though, the original app wasn't bad.  It's an update which is bad.  So it would seem useful when an update is presented to also note to the updating end user, oh, by the way, ownership of this has changed hands.  And in fact maybe it's because of that, even what I'm suggesting, that the purchaser said, look, we're going to push an update before we confirm the purchase just so we can make sure we can.  Of course that update could always be reverted if the purchase didn't go through.  But still, it would avoid this approach.



But it seems to me with there being the gazillion free Android apps that there are, super popular because they're free, and also because they're behaving themselves, we're going to see this attempt to exploit the trust and credibility which has been built up for exactly that reason.  And I don't know how we solve that problem. But we are now beginning to see the emergence of this as a new profit model.



What hasn't been a big profit model for the last, what is it, 17 years?  I can never be accused of dinging people for constant update fees.  



LEO:  Grasping Steve, yeah.



STEVE:  So I do try to keep an eye on postings in the GRC forums.  And I saw a recent posting titled "RS shows VERY [in all caps] obvious improvement after one pass of SR 6."  And this was posted by the TheDukeofURL on this past Saturday at 4:14, or 4:16, rather.  I've got a link in the show notes for anyone who's interested in seeing the whole thread.  But TheDukeofURL posted last Saturday:  "Been trying out SR 6 / RS scanning" - meaning ReadSpeed scanning, our benchmark - "and testing on a bunch of drives I have."  He said:  "Spinning, SSD, laptop, SATA, and PATA," you know, Parallel ATA.  He says:  "What follows is a really good indication of what SpinRite can do with SSDs that are a bit on the old side and need a little TLC.  Today's selection is a Crucial M4 2.5" 128GB SATA III MLC, Multi-Level Cell, which has been in service for close to five years."



So he shows two ReadSpeed outputs, a before where he shows the 128GB M4 Crucial, and you know how ReadSpeed does benchmarks at 0, 25, 50, 75, and 100% points in the drive.  So we have 258 mbps, 283, 309, 296, and 296.  Then after running SpinRite on Level 3, same drive, 533.5, 533.5, 533.5, 533.5, and 533.6.  So that's using a Level 3.  Level 3 is the minimal writing, the "Refresh the Surfaces."  So it basically just reads everything and writes everything back.



So what the benchmark clearly demonstrates is that the act of reading and rewriting the entire storage surface of the SSD has essentially doubled its subsequent read performance as measured in ReadSpeed's 1GB reads from five locations across the SSD.  And I'll note that many users have reported that this does in fact result in a subsequent noticeable improvement in the actual perceived performance of the media.  So it's not just some benchmarking attribute.



There's been a lot of discussion in the GRC newsgroups about the source of this SSD slowdown over time.  There are those who hold that the slowdown is caused by long-term fragmentation of the mapping between logical sector addresses and their physical location.  The idea is that SSDs achieve their peak performance through parallelism, through the parallel reading across many, we could think of it as cores, which are independent channels in the SSD.  And that a brand new SSD will have a uniform "map" that maximizes the read performance of that device.



So the theory goes that, over time, the relocation of regions introduces an unavoidable fragmentation of this map which causes clumping up of the reads, thus reducing the channel parallelism.  And as we know, wear leveling is the idea that, as you're using this, if you're writing to what looks like the same logical location, you're actually writing to different physical locations, which the SSD is managing.  And so the need to level out the wear so that your writing is not spotty, and so you're not burning out one spot on an SSD, that's causing this mapping fragmentation which reduces the ability of the drive to pull from its surface in parallel.



And it's been noted that performing the SSD's Secure Erase operation immediately restores the drive's maximum performance as seen under ReadSpeed.  One assumption is that this has effectively defragmented the SSD's logical-to-physical mapping table, thus restoring its full performance.  But I believe that's not what has happened.  SSDs know when and exactly where data has previously been stored.  So a Secure Erase function unmaps the logical-to-physical association so that after the Secure Erase, a read instantly returns zeroes for any read because the drive knows that nothing has been stored there yet since the Secure Erase.



And in fact you can see the same thing if you issue trims to the entire drive.  If you issue trims, you're not securely erasing, but you are telling the drive there's nothing in these locations.  You don't need to worry about them.  That has the same effect of unmapping that logical-to-physical association.  And suddenly the drive reads at full performance because it's lying.  It knows nothing's been stored there, so it just sends back zeroes instantly.



Okay.  So what does running SpinRite do?  We know that SSDs store data as electrostatic charges in a vast array of very slowly leaking capacitors.  It's unnerving, but it's the truth.  And this is why we reported many years ago that storing SSDs offline in a hot environment would cause their data to be lost much more quickly than if offline SSDs were stored in a cold environment.  It's well known that heating a semiconductor results in increased electron migration due to thermal agitation.  An SSD's capacitor array wants to discharge.  It's always trying to turn to a state of maximum entropy.  And heating helps that to happen more quickly.



As we know, SSDs rely upon surprisingly advanced built-in data recovery on the fly, it's happening all the time, to deal with the reality of what Allyn Malventano, who's Intel's storage guy, referred to as "charge drift."  They will read and reread, applying differing thresholds to an SSD's bit value determinations in an attempt to obtain a read that can be read either with or without error correction, upon which we know SSDs are relying heavily.  So the only way to make sense of what TheDukeofURL's results show us is that in a way that exactly matches the idea of refreshing a spinning drive's magnetic surfaces to find and fix any bad spots before they become too bad to read and/or correct fully.



Rewriting that SSD could not have defragmented its logical-to-physical mapping.  As far as we know, only a full drive erase or trimming will do that.  So what had to have happened is that many regions that were being slowed down by their need for extensive on-the-fly error recovery and correction are now once again reading at full speed because their capacitors that store the SSD's data have been fully recharged.  And not only did this double the read speed of the drive, it also had to have a dramatically improved effect on the drive's long-term reliability, at least for reading.



And I'm not suggesting that everyone should run out and run SpinRite 6 on their SSDs today.  Not yet.  SpinRite needs to be optimized for this application.  For one thing, not all regions are slow.  As we've seen, ReadSpeed's detailed output showed wide variations in read performance.  And SpinRite is not yet smart enough to selectively rewrite only an SSD's slow spots, which is what we want in order to reduce SSD media wear.  Another issue is the whole issue of page alignment of SpinRite's writes.  SSDs erase and rewrite their data only in large page-size chunks.  SpinRite 6.1 will work in large chunks that are inherently page aligned.  SpinRite 6.0 and earlier versions have had a track alignment which was oriented to 63 sectors, which, I mean, that's a horrible number, 63.  It's just like almost designed not to line up evenly with any binary sizes.



LEO:  That's a prime number; isn't it?



STEVE:  It's horrible.  It can't be prime because six plus three is nine.  But it's definitely going to be bad.  And then there's trimming; right?  We touched on this before.  Rewriting the entire drive detrims the whole physical surface, telling it that the entire drive is in use and contains valid data.  But the drive's file system knows better.  But SpinRite is not only rewriting valid files, it's rewriting the entire surface.  Windows, when we talked about this before, can be instructed to retrim a drive.



That's what optimizing a drive now on SSDs does.  And you can actually see it says there, if you run optimize, it says retrimming.  And Linux we know will periodically run a retrim over its drives.  But a future SpinRite will also be natively trim aware.  So anyway, TheDukeofURL's posting Saturday was a clear demonstration that SpinRite has, I would argue, at least as much to do in the future as it has in the past.  So I am very excited to get us there.  And that's what's got all my focus right now.



LEO:  Can you trim too often?  Can you wear a drive out by trimming too much?



STEVE:  No.  Trimming doesn't write anything to the surface.



LEO:  Okay.



STEVE:  It only talks to the management layer in the controller, basically telling it that these regions have nothing of interest.



LEO:  It's zero here, yeah.



STEVE:  It sort of puts it back to its original state. 



LEO:  Yeah, yeah.



STEVE:  Yeah, because the problem is, because of the fact that the SSD can only erase, and in order to write to an SSD, you have to write all zeroes to it, and then you selectively write ones where there were zeroes.



LEO:  Oh, I didn't know that.  Really.



STEVE:  Yeah.



LEO:  That's interesting.



STEVE:  Yeah.  You have to push the whole thing down.  And these pages are huge.  They might be like 4 or 8K in size, where a sector is still 512 bytes.  So if you were to just rewrite one sector, and if the SSD thought that all of the regions around it were in use, it would have to read that whole thing, erase the whole large block, and then rewrite the whole block with that one sector changed.  But if instead, if it had been trimmed to know that none of that was in use, then it wouldn't have to bother with that read/modify/write cycle.  And if it knew that it had been previously erased, it could then push all of the bits.  I think maybe erase writes ones, and then it just pushes zeroes where it needs them.  But anyway, it's like surprising how much technology is in these things.



LEO:  Yeah, yeah.



STEVE:  And it just, you know, we're just unaware of it.



LEO:  Yeah.  It's very cool, actually.



STEVE:  Very, very cool.



LEO:  Nice.  All right.



STEVE:  Our last break, and then oh my god, Leo.  Just oh.  Fasten, you know, buckle up.



LEO:  I can't wait.  We'll get to Dependencies in just a bit.  All right.  I am all ears.  I want to hear about this dependency issue that you're covering here.



STEVE:  Oh, boy.  This will not disappoint.  Two weeks ago Alex Birsan put up a posting on Medium that drew a great deal of well-deserved attention.  Unfortunately, it's not possible for it to have drawn enough attention.  I mean, and we'll see why.  And as I said, it was so cool that I punted on talking about it last week so I could make it our topic this week.  And as I also mentioned, it relates to our Picture of the Week last week because that was a - in order to explain it to our listeners, we described it as a house of cards, although it was sort of a building of rickety blocks that had inherent dependencies upon the blocks below.



So Alex wrote:  "Ever since I started learning how to code, I've been fascinated by the level of trust we put in a simple command like this one."  And then he shows "pip install package_name."  And for those who don't know, this is a simple means of asking your OS to go out and find from a repository some package and download it and install it into your system.



He says:  "Some programming languages, like Python, come with an easy, more or less official method of installing dependencies for your projects.  These installers are usually tied to public code repositories where anyone can freely upload code packages for others to use.  You've probably heard of these tools already.  Node has npm and the npm registry.  Python's pip uses PyPI, Python Package Index.  And Ruby's gems can be found on, not surprisingly, RubyGems.  When downloading and using a package from any of these sources, you are essentially trusting its publisher to run code on your machine.  So," he asks, "can this blind trust be exploited by malicious actors?  Of course it can."



He says:  "None of the package hosting services can ever guarantee that all the code its users upload is malware-free. Past research has shown that typosquatting  an attack leveraging typoed versions of popular package names  can be incredibly effective in gaining access to random PCs across the world."  And I'll note that we've talked about exactly this problem here on the podcast in the past.



And he said:  "Other well-known dependency chain attack paths include using various methods to compromise existing packages, or uploading malicious code under the names of dependencies that no longer exist."  But that's not what he did.  He said:  "While attempting to hack PayPal with me during the summer of 2020" - and this guy's an ethical hacker.  He says:  "Justin Gardner shared an interesting bit of Node.js source code found on GitHub."  He said:  "The code was meant for internal PayPal use, and in its package.json file appeared to contain a mix of public and private dependencies [which are to say] public packages from npm, as well as non-public package names, most likely hosted internally by PayPal.  These names did not exist on the public npm registry at the time."



And Leo's got the picture of this on the screen.  This is just some JSON showing a block named "dependencies."  And inside we have one item, "express," showing a version 4.3.0.  One is a "dustjs-helpers," v1.6.3.  There's one "continuation-local-storage" with a version of 3.1.  Then there's "pp" - probably PayPal - "logger" at 0.2 version.  "Auth-paypal," 2.0.0.  A "wurfl-paypal" with a version 1.0.0.  And an "analytics-paypal," 1.0.0.  So again, some public things and clearly some private things.  But these are all dependencies for something that something is using.



So he says:  "With the logic dictating which package would be sourced from where being unclear here, a few questions arose:  What happens if malicious code is uploaded to npm under these names?  Is it possible that some of PayPal's internal projects will start defaulting to the new public packages instead of the private ones?  Will developers, or even automated systems, start running the code inside those libraries?  If this works, can we get a bug bounty out of it?"  In other words, can I make some money?  "Would this attack work against other companies [meaning besides PayPal], too?"



He said:  "So I started working on a plan to answer these questions.  The idea was to upload my own" - and he has in quotes "malicious" because of course, again, they wouldn't hurt anybody, but thus quotes - "Node packages to the npm registry under all the unclaimed names, which would 'phone home' from each computer they were installed on.  If any of the packages ended up being installed on PayPal-owned servers, or anywhere else for that matter  the code inside them would immediately notify me.  At this point," he said, "I feel it's important to make it clear that every single organization targeted" - now, I'll explain also that limited targeting was possible.



But, he says:  "Every single organization targeted during this research has provided permission to have its security tested, either through public bug bounty programs or through private agreements."  And he says:  "Please do not attempt this kind of test without authorization."  And of course we know why.  We've seen unwitting hackers having agents knocking at their doors, and those agents tend to be very humorless.



So he says:  "Thankfully, npm allows arbitrary code to be executed automatically upon package installation, allowing me to easily create a Node package that collects some basic information about each machine it is installed on through its preinstall script."  He said:  "To strike a balance between the ability to identify an organization based on the data, and the need to avoid collecting too much sensitive information," he said, "I settled on only logging the username, hostname, and current path of each unique installation.  Along with the external IPs, this was just enough data to help security teams identify possibly vulnerable systems based on my reports, while avoiding having my testing be mistaken for an actual attack."



And he says:  "One thing left now.  How do I get that data back to me?  Knowing that most of the possible targets would be deep inside well-protected corporate networks, I considered that DNS exfiltration was the way to go.  Sending the information to my server through the DNS protocol was not essential for the test itself to work, but it did ensure that the traffic would be less likely to be blocked or detected on the way out."  He says:  "The data was hex-encoded and used as part of a DNS query, which reached my custom authoritative name server, either directly or through intermediate resolvers."  He says:  "The server was configured to log each received query, essentially keeping a record of every machine where the packages were loaded."



And I'll pause here just to note that this approach does in fact work beautifully.  I use it for GRC's DNS spoofability test, and also as an ultra lightweight means of allowing GRC's more recent apps to check for updates without making explicit TCP connections.  If, for example, you were to use NSLOOKUP to look up sqrl.ver.grc.com, you'll receive a virtual IPv4 address containing the current release number of GRC's SQRL client.  So it's a beautiful way of not raising any false alarms or upsetting anybody, yet still being able to make a lightweight query.  And if I were logging, although I'm not, incoming queries, then essentially it is a way of identifying where SQRL clients are.  This guy was explicitly logging all of the incoming DNS queries, which allowed him to tie those back to the networks and domains of machines that were inadvertently executing his code.



So he says:  "With the basic plan of attack in place, it was now time to uncover more possible targets.  The first strategy was looking into alternate ecosystems to attack.  So I ported the code to both Python and Ruby, in order to be able to upload similar packages to PyPI" - that's the Python Package Index - "and RubyGems.  But arguably the most important part of this test was finding as many relevant dependency names as possible."  That is to say, he wants to figure out what to name his, I don't want to call them trojan, but they kind of are, but his benign trojan packages, what to name them so that they will get pulled by mistake if they're going to be from public repositories.



So he says:  "A few full days of searching for private package names belonging to some of the targeted companies revealed that many other names could be found on GitHub, as well as on the major package hosting services, inside internal packages which had been accidentally published, and even within posts on various Internet forums."  He said:  "However, by far the best place to find private package names turned out to be inside JavaScript files.  Apparently it is quite common for internal package.json files, which contain the names of a JavaScript project's dependencies, to become embedded in public script files during their build process, thus exposing internal package names.  Similarly, leaked internal paths or 'require' calls within these files may also contain dependency names.  Apple, Yelp, and Tesla are just a few examples of companies who had internal names exposed in this way.



"During the second half of 2020, thanks to @streaak's help and his remarkable recon skills, we were able to automatically scan millions of domains belonging to the targeted companies and extract hundreds of additional JavaScript package names which had not yet been claimed on the npm registry."  He says:  "I then uploaded my code to package hosting services under all of the found names and waited for callbacks."



Okay.  So just to be clear, what Alex was exploring was the idea that there might be a fundamental flaw in the way package dependencies are currently being resolved within our industry such that the building process for packages may first look to public repositories for needed software libraries before attempting to find and resolve dependencies which require and use nonpublic internal libraries.



Alex wrote:  "The success rate was simply astonishing."  And I would add horrifying.  He said:  "They range from one-off mistakes made by developers on their own machines, to misconfigured internal or cloud-based build servers, to systemically vulnerable development pipelines.  One thing was clear.  Squatting valid internal package names was a nearly surefire method to get into the networks of some of the biggest tech companies out there, gaining remote code execution and possibly allowing attackers to add backdoors during builds.



"This type of vulnerability," he wrote, "which I have started calling 'dependency confusion,' was detected inside more than 35 organizations to date, across all three tested programming languages.  The vast majority of the affected companies fall into the greater than a thousand employees category, which most likely reflects the higher percentage of internal library usage within larger organizations.  Due to JavaScript dependency names being easier to find, almost 75% of all the logged callbacks came from npm packages.  But this does not necessarily mean that Python and Ruby are less susceptible to the attack.  In fact, despite only being able to identify internal Ruby gem names belonging to eight organizations during my searches, four of these companies turned out to be vulnerable to dependency confusion through Ruby gems.



"One such company is the Canadian ecommerce giant Shopify, whose build system automatically installed a Ruby gem named shopify-cloud only a few hours after I had uploaded it, and then tried to run the code inside it.  The Shopify team had a fix ready within a day, and awarded a $30,000 bug bounty for finding the issue.  Another $30,000 reward came from Apple after the code in a Node package which I uploaded to npm in August of 2020 was executed on multiple machines inside Apple's network.  The affected projects appeared to be related to Apple's authentication system, externally known as Apple ID.



"When I brought up the idea that this bug may have allowed a threat actor to inject backdoors into Apple ID, Apple did not consider that this level of impact accurately represented the issue" - you bet they didn't want to - "and they said 'Achieving a backdoor in an operational service requires a more complex sequence of events and is a very specific term that carries additional connotations.'"  Whatever the hell that means.  Anyway:  "Apple however did confirm that remote code execution on Apple servers would have been achievable by using this npm package technique.  Based on the flow of package installs, the issue was fixed within two weeks of my report, but the bug bounty was only awarded less than a day prior to publishing this report."  Yet he got $20,000.



"The same theme from npm packages being installed on both internal servers and individual developer PCs could be observed across several other successful attacks against other companies, with some of the installs often taking place within hours or even minutes after the packages had been uploaded.  Oh," he says, "and the PayPal names that started it all?  Those worked, too, resulting in yet another $30,000 bounty."  He said:  "Actually, the majority of awarded bug bounties were set at the maximum amount allowed by each program's policy, and sometimes even higher, confirming the generally high severity of dependency confusion bugs.  Other affected companies include Netflix, Yelp, and Uber.



"Despite the large number of dependency confusion findings, one detail was, and still is to a certain extent, unclear.  Why is this happening?  What are the main root causes behind this type of vulnerability?  Most of the affected organizations were understandably reluctant to share further technical details about exactly how their root causes and mitigation strategies worked.  But a few interesting details did emerge during my research and from my communication with security teams."



He said:  "For instance, the main culprit of Python dependency confusion appears to be the incorrect usage of an 'insecure by design' command line argument called --extra-index-url.  When using this argument with pip install library to specify your own package index, you may find that it works as expected, but what pip is actually doing behind the scenes goes something like this."  Okay.  Get a load of this.



"First, checks whether library exists on the specified probably internal package index.  Two, checks whether library exists on the public package index.  In other words, PyPI.  Three, installs whichever version is found.  If the package exists on both, it defaults to installing from the source declaring the higher version number.  Therefore, uploading a package named Library 9000.0.0 to PyPI would result in the dependency being hijacked in the example above.  Any library that doesn't have a version higher than 9000 will be superseded by its presence, the spoofed presence on the public repository."



He says:  "Although this behavior was already commonly known, simply searching GitHub for --extra-index-URL was enough to find a few vulnerable scripts belonging to large organizations, including a bug affecting a component of Microsoft's .NET Core.  The vulnerability, which may have allowed adding backdoors to .NET Core, was unfortunately found to be out of scope in the .NET bug bounty program."  So he didn't make any money on that one.  "Ruby's gem install source also works in a similar way," he says, "but I was unable to confirm whether its usage was the root cause of any of my findings."  He said:  "Sure, changing extra-index-url to index-url is a quick and straightforward fix, but some other variants of dependency confusion were proven much harder to mitigate.



"JFrog Artifactory, a piece of software widely used for hosting internal packages of all types, offers the possibility to mix internal and public libraries into the same virtual repository, greatly simplifying dependency management.  However, multiple customers have stated that Artifactory uses the exact same vulnerable algorithm described above to decide between serving an internal and an external package with the same name.  At the time of this writing, there is no way to change this default behavior."  He says:  "JFrog is reportedly aware of the issue, but has been treating this possible fix as a feature request with no ETA in sight, while some of its customers have resorted to applying systemic policy changes to dependency management in order to mitigate dependency confusion in the meantime.



"Microsoft also offers a similar package hosting service named Azure Artifacts.  As a result of one of my reports, some minor improvements have been made to this service to ensure that it can provide a reliable workaround for dependency confusion vulnerabilities."  He says:  "Funnily enough, this issue was not discovered by testing Azure Artifacts itself, but rather by successfully attacking Microsoft's own cloud-based Office 365, with the report resulting in Azure's highest possible reward of $40,000" this guy made.  He says:  "For more in-depth information about root causes and prevention advice, you can check out Microsoft's white paper 'Three Ways to Mitigate Risk When Using Private Package Feeds.'"



He said finally, as he's finishing:  "While many of the large tech companies have already been made aware of this type of vulnerability, and have either fixed it across their infrastructure or are working to implement mitigations," he says, "I still get the feeling that there is more to discover.  Specifically, I believe that finding new and clever ways to leak internal names will expose even more vulnerable systems, and looking into alternate programming languages and repositories to target will reveal some additional attack surfaces for dependency confusion bugs."  And for what it's worth, he suggests to people who are reading that, and of course people listening to this podcast, that there may be more money to be made because these things are horrific, and they are generating maximum bounty payouts every single time they are found to infect or affect a major organization.



So hopefully the power of this is breathtakingly obvious.  And you have to ask, I mean, think about this.  What if Alex was not a good guy?  What if he was not the first ever to have had this thought?  What if a transient incursion was made into a massive corporate network simply by having the corporate build system or its servers pull malicious code from a public repository?  Such  code could be posted, exploited, then removed to eliminate the chance of discovery.  I mean, it is horrifying.



LEO:  Yeah.



STEVE:  So props to Alex for thinking of this.  And, boy, what a glaring oversight on the part of the way these systems are being built.



LEO:  I mean, any time you build software, you often will pull dependencies from sources like, if you're doing it in Linux, from the Linux repositories.  These are public repositories.



STEVE:  Yup.



LEO:  Is the problem here that these are private repositories?



STEVE:  It's that there's a hybrid.  So they declare the dependencies.  They were making the assumption that their private repositories would never exist on public repositories.



LEO:  Got it, yeah.



STEVE:  And so the only match would be a local match.  So it turns out...



LEO:  So anything that's in public, they will check signatures and things like that.  But they presume that anything on a private repository is safe.



STEVE:  Well, yes.  And that only their private repository would have a name match.



LEO:  Could be the source, right, yeah, yeah.



STEVE:  What this guy was assuming was what happens if we deliberately create a name collision, would the repository get pulled publicly first?



LEO:  Right.



STEVE:  And in fact in one case the build system compares the version numbers and deliberately chooses...



LEO:  The higher number, yeah.



STEVE:  ...what it thinks is the newer one.



LEO:  Yeah, yeah, yeah.



STEVE:  In which case you could override with a bogus public posting on a repository.  You override it just by declaring it a newer version than the public, like version 9000.



LEO:  Right.  Yeah, that's what these manifests often say is this version or better.



STEVE:  Yup.  



LEO:  And I guess the caret, that's what the caret signified in the repository you show.



STEVE:  Right.



LEO:  Yeah.  But, I mean, everything that builds software uses repositories.  And most package managers on most systems will pull in code from a variety of public repositories.



STEVE:  Yeah.



LEO:  And it's kind of on the user to validate those, really.



STEVE:  That's what makes this so breathtaking, Leo, is it's like, wait a minute.  I mean, the system has been that fragile.  In fact, it's so fragile it's hard to believe it's that fragile.



LEO:  Yeah.  Well, we all kind of pretend we...



STEVE:  Yeah, I know.



LEO:  Yeah, just it'll work out.  Just hope for the best.



STEVE:  We just go tiptoe through the tulips and hold our breath.



LEO:  Yeah, just hope for the best.  Wow, yeah.  There's always that risk, you know, when you're pulling dependencies that you could be pulling a malicious dependency.  There's a certain amount of trust that the repositories are maintained, and somebody's paying attention.  I don't know if that's the case in a lot of situations, honestly.



STEVE:  Unfortunately, as we showed in our Picture of the Week last week, Wilbur in Nebraska...



LEO:  That one guy, yeah.



STEVE:  ...is maintaining, you know, exactly.  And in fact somebody tweeted me that there's one guy in Sweden maintaining cURL. 



LEO: Yes, that's right. 



STEVE:  That's the maintainer.  And we are so dependent upon cURL working correctly.  And it's like, let's hope it stays good.



LEO:  Yeah.  It's been a big deal for some time, actually.  There's been a lot of talk about that.  Daniel Stenberg's the benevolent dictator for life is what they call these guys.



Wow, what a story.  Mr. Gibson, you've done it again, as always.  This is a fascinating listen.  I know everybody who listens or has heard this show knows that's the case.  Let me tell you where you can get this show and previous shows and all future shows.  Start at Steve's site, GRC.com.  He has 16Kb audio, 64Kb audio, nice transcriptions written by a human being so you can read along or use them to search for anything in all 807 episodes.  GRC.com.



While you're there, pick up a copy of SpinRite, currently 6.0.  As you know, 6.1 is in process.  That's going to be an amazing choice, not just for spinning drives, but for solid-state drives.  And if you buy it now, you'll automatically get upgraded to 6.1.  Plus you can participate in the development of 6.1.  That's at GRC.com.  Lots of free stuff there, too, including his feedback form.  If you want to ask a question or leave a suggestion, GRC.com/feedback.  Steve also takes suggestions on his Twitter handle, @SGgrc.  His DMs are open, as the kids say.  @SGgrc.



We have copies of the show at our website, TWiT.tv/sn for Security Now!.  You can download audio or video there.  You can also watch us do it live.  We do the show live every Tuesday around about 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  The live stream's at TWiT.tv/live.  People who are watching live, I encourage you to chat because the chatroom is also watching live at irc.twit.tv.  The on-demand versions, as I mentioned, are at the website.  You can also watch the YouTube channel.  You can get them from Steve.  But maybe the easiest thing to do is find a podcast client and subscribe.  That way you can get it the minute it's available of a Tuesday afternoon so you can listen to it instantly.  Steve, we have concluded the project for today.  Thank you.



STEVE:  We'll be back next week with 808.



LEO:  808.  See you then.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#808

DATE:		March 2, 2021

TITLE:		CNAME Collusion

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-808.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we discuss a welcome change coming soon to the Chrome browser, and a welcome evolution in last week's just released Firefox 86.  We're going to look at questions surrounding the source of the original intrusion into SolarWinds servers, and at a new severity-10 vulnerability affecting Rockwell Automation PLC controllers.  We'll touch on VMware's current trouble with exploitation of their vCenter management system, and I want to share a recent code debugging experience I think our listeners will enjoy and find interesting.  Then we're going to conclude with some information about something that's been going on quietly out of sight and under the covers which must be made as widely public among web technologists as possible.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, including breaking news.  Seven, count them, seven zero-days in Microsoft Exchange Server.  And we'll talk about a sneaky new thing that some websites are using to track you, even if you have tracking protection turned on.  We'll tell you how to avoid it, CNAME collusion, coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 808, recorded Tuesday, March 2nd, 2021:  CNAME Collusion.



It's time for Security Now!, the show where we cover your security and privacy and well-being online with this cat right here, Mr. James - James?  Started calling you James Tiberius Gibson.  But no.



STEVE GIBSON:  I knew where you were going with that, yeah.



LEO:  Steve Gibson of the GRC Corp.  He has danced...



STEVE:  It was the Vulcan wave.



LEO:  That's what did it.



STEVE:  The Vulcan hand sign.  That's what got you tripped up.



LEO:  That's what did it, yup.  I don't know what Mr. Spock's middle name is.  I don't even know what his first name is.  But I do know James Tiberius Kirk.



STEVE:  Actually we're having fun.  We are rewatching "Fringe," which Lorrie never saw.  



LEO:  Oh, yeah, yeah.



STEVE:  And of course he is Bell.  And at the end of the first season he comes out of the shadows.  And of course I recognized his voice.



LEO:  Shatner.  You knew immediately, yeah.



STEVE:  Yeah.  And then she's like [gasps].  So anyway, we're having fun with that.



LEO:  Nice.



STEVE:  This is going to be one of those episodes, Leo.  This is important.  No fooling around this time.  There's something which has come to light which is a form of escalation of the browser tracking fight which is very disturbing because of what the tracking companies are asking websites to do, thus the "collusion" part of this.  There is collusion involved.  And the consequences of what's been done in order to avoid those who wish not to be tracked, to circumvent anti-tracking, is deeply disturbing.



So there was more news, but I wanted to be able to spend enough time on this because, I mean, we do have news.  But as I looked into this, I just thought, okay.  And I say this in the show notes later because I just wrote this about 10 minutes ago.  We can't fault people when cookies began being abused by third parties, even though that was never their design, because people didn't know.  I mean, random users, they didn't see the tracking going on.  The technologists knew, and we did nothing.  And we're here again.  We're at something that is going on that no one is seeing, that by the end of this podcast every one of the podcast listeners is going to understand.  And something - we just can't do nothing again.



Anyway, the topic, the name of the podcast is CNAME Collusion.  I was going to go with the CNAME Conspiracy, but that word's been a little overused lately.  And so I thought collusion sounds better, and it's actually more accurate.  But first we're going to discuss a welcome change coming soon to a Chrome browser, probably near you.  And a welcome evolution in last week's just-released Firefox 86, which actually 86's something.  We're going to look at questions surrounding the source of the original intrusion into SolarWinds servers, which there's some controversy about.  The old CFO and the new CFO have differing opinions about how this thing crawled in in the first place.



Also we're going to look at a new severity-10 vulnerability affecting Rockwell Automation PLC controllers.  CISA is warning the world about this.  We'll touch on VMware's current dilemma with the exploitation of their vCenter management system as a consequence of a patch they just released which was instantly reversed and for which there are, last time I checked, six public exploits which immediately started getting used.  I also want to share, because I think our listeners will find it really interesting, I certainly did, a recent code debugging experience I had with that system that I mentioned last week, that it was the only system that I had that was still causing me trouble.  And I now know why.  And, oh, is it weird.



And then, as I said, we're going to conclude with some information about something that's been going on quietly out of site and under the covers, which must be made as widely public among web technologists as possible.  And so we're going to do our part on this podcast.



LEO:  As always.  That sounds interesting.  I will be staying tuned.  Not like I can go anywhere, but I'll be listening with interest.



STEVE:  Just don't fall off your ball, Leo.



LEO:  I might.  Depends on how shocking the CNAME Collusion is.  All right, Steve.



STEVE:  So our Picture of the Week is just sort of a fun one.  I titled it "Not exactly confidence inspiring."  And this is showing an ATM, a contemporary-looking ATM.  And on the screen it shows - apparently the processor has crashed and rebooted, and it shows Microsoft Windows NT Workstation.  And I went down, I squinted at the screen, and I thought, oh, well, at least it's Workstation 4.0.  So that's good.  It's not 3.51 or whatever it used to be.



But anyway, yes, if your ATM is running on Windows NT, I mean, that doesn't mean that it's insecure because of course new viruses won't infect Windows NT.  But it does sort of suggest that it isn't receiving any regular maintenance and love and care, that maybe the 300 baud modem which it's using to connect to the rest of the world is the reason why your transactions are running a little slowly.



LEO:  Used to be you'd hear that.  You'd hear the [mimicking modem noise].



STEVE:  Oh, yeah.



LEO:  It's also a little concerning that we're seeing the boot screen on the ATM.  I don't think that's a good sign, either.



STEVE:  That's true.  Yeah.  That probably means that the 10MB hard drive...



LEO:  It's full.



STEVE:  ...is retrying or was unable to get off the ground or lord knows.  Maybe the floppy that it's running inside is having read errors.  So I am delighted to announced that the forthcoming Chrome v90, which is slated for release around mid-April, will finally assume that any non-specific, or as Google terms it, "schemeless" URL which is entered into its omnibox, which is what they call the URL field, will be assumed HTTPS before falling back to HTTP.  As our listeners know, I've mentioned often that it seems well past time for our browsers to assume HTTPS rather than HTTP.  They don't do that yet.  But it appears that's finally going to happen.  This will likely influence certainly all other Chromium-based browsers, and we can expect that probably Firefox and Safari will follow suit.  I think it's 80 - I saw the figure recently, actually when I was researching this.  Eighty-some, oh, maybe it's in here.



So last Wednesday Google's Emily Stark tweeted, if you're running Chrome Canary, dev or beta, so that's not the one we get yet, or that the rest of us have yet, and you want some more HTTPS in your life, which, okay, you can't avoid having it in your life.  Anyway, she said:  "Go to chrome://flags and search for 'omnibox-default-typed-'" - actually all you have to do is "omnibox-," and you could type a "d" for default.  I did it.  There aren't any other collisions in the search.  So anyway, it's omnibox-default-typed-navigations-to-https, which allows you to enable Chrome first trying HTTPS rather than HTTP by default.



Anyway, and then the next day she followed up, tweeting:  "Currently, the plan is to run as an experiment for a small percentage of users in Chrome 89" - okay, so that will be the next one we get, which probably is sometime soon, later this month, and then will launch fully.  Assuming presumably that nothing blows up from their small percentage of user tests in 89, it'll be on in Chrome 90.  So, yeah, the current public release is 88.  And I checked.  88 doesn't yet have anything like that option.  89 will.  So a test percentage of 89 users will get that.  The rest of us, if we're curious, and I will when 89 comes out, will turn it on because it's clear that when you just type GRC.com, you should go to https://GRC.com.



I have long had code that redirects any HTTP person coming in immediately to HTTPS.  Well-behaved sites do that.  But again, HTTP should die eventually.  Certainly the browsers are doing everything they can to kill it off.  So, yeah, this is just, you know, makes sense that this would eventually happen.  Chrome is leading the way.  Edge and Brave and everybody else, Vivaldi, all the other Chromium-based browsers will probably do the same thing.  And I imagine then Firefox and Safari will follow.



LEO:  So Brave does HTTPS Everywhere.  I think it has it built in.  Is that the same thing?



STEVE:  Okay, yeah, kind of.  So that says it's typically an add-on on current browsers. 



LEO:  Yeah, it's a Chrome extension, I think, yeah.



STEVE:  Yes.  Which does transmute the non-specific URL into HTTPS.  So yes.  Basically that HTTPS Everywhere, our listeners know, has been around for a couple years now.  It's finally getting built in.  But so if you don't specify, Chrome will go HTTPS first.  If that doesn't answer, there's nobody home there, then they'll go, huh, and try HTTP.  And of course then all kinds of other alarms and bells are going to go off because Chrome doesn't want to talk to anybody over HTTP.  It's like you get all kinds of scary, like oh, wait a minute.  And like, yeah, yeah, yeah.  But I think it was 83% of all websites are now HTTPS, which is really great.



LEO:  That's great.  And that's - you can thank Chrome for that because Google really pushed this; right?



STEVE:  Yes.



LEO:  They said you'll rank higher in the search.



STEVE:  Chrome and Let's Encrypt.  Let's Encrypt was arguably...



LEO:  They made it easy, yeah.



STEVE:  Well, they made it free.  That was the big deal.



LEO:  Right.



STEVE:  All the old grumbly Linux farts [cross grumbling].  That's not the way the Internet was meant to be.  It's supposed to be free.



LEO:  Well, it is pricey, I have to - or was pricey.



STEVE:  As in beer or something.  What is it, beer free?  I don't know if beer is free.



LEO:  No, it's not.  It's liberated.



STEVE:  Liberated, yes.  Anyway.



LEO:  So, yeah, because Brave does have that.  So Brave has done that for a while, for as long as I can remember, this HTTPS.



STEVE:  They may have been, you know, maybe Chrome was looking at that going, huh, that works better than we thought.  So, yeah.  So, okay.  So that's the first bit of good news on the browser front.  The second is that apparently my wish list is getting some long overdue attention this week.  Mozilla just announced that with their recently released Firefox 86, the long-running abuse of third-party cookies would finally be 86'd.



Of course as I've long lamented, and we'll be talking about this toward the end, the use of third-party offsite cookies for tracking was never part of the plan.  Netscape invented first-party cookies in order to implement a simple session maintenance mechanism which for the first time back then, and still today, enables the concept of a user logging into a website and then being known as they moved about.  Essentially it amounted to them being tracked as they moved about that one site.  But being a first-party cookie, it only worked for that one site.



What was never intended was that third-party advertisers, or dark and unseen analytics providers, or Google Analytics, would insinuate themselves pervasively throughout the web and employ their own cookies for tagging and tracking the activities of individual users.  But as we know, what can be done will be done.  And tracking is what resulted.



So here's what they've done.  With the release of Firefox 86, that just ended.  I mean, like really.  At the top of their posting titled "Total Cookie Protection," Mozilla wrote:  "Today we are pleased to announce Total Cookie Protection, a major privacy advance in Firefox built into ETP Strict Mode.  Total Cookie Protection confines cookies to the site where they were created, which prevents tracking companies from using these cookies to track your browsing from site to site."



Okay.  So in other words, third-party cookies are not blocked, but they are stovepiped.  So assuming, for example, that third-party cookies were enabled at all in your browser, which is the case typically, any third-party entity may still give the user's browser its cookie, like an advertiser or like Google Analytics or like anyone providing content to your page when you visit a specific site.  They're welcome to give your browser its cookie.  But now, I mean, like Firefox right now, I have 86, and you get it.  If you go to About Firefox you'll probably see that you have 85, and then it'll offer - although I did get an update yesterday without asking.



But now Firefox will associate the third-party cookie it received with the website where the user was when that cookie was received.  The two will be paired.  So if the user returns to the same site, that third-party cookie will be returned to the third-party site.  So it's not breaking third-party cookies.  But if the user visits a different site with content, an advertisement or tracking code from that same third-party site, because the user is visiting a different website, there will be no third-party cookie associated with the visited site.  So cross-site tracking is defeated.



Now, if we wanted to use some modern high-falutin' language to describe this, we would say that Mozilla has segmented their browser cookie name space, creating individual cookie name spaces for each website.  So I think this is it.  I mean, this is a wonderful compromise between allowing and refusing all third-party cookies just as a binary choice.  With this solution, third-party cookies are still allowed.  Nobody can say, oh, you turned off third-party cookies.  You're bad.  No.  They're on.  But you don't get that same third-party cookie when you go somewhere else that has that same third-party site.  You're at a different location.  So it's treated as a new third-party cookie, not cross-associated among websites.



So this is just great.  We know that the pressure to track is significant.  Even though, when it really does work, it's frequently reported as being a bit unnerving, like when some recent activity that you have had somewhere, like you're in Amazon searching for something, that turns up in an ad somewhere else a few minutes later.  That freaks people out.  It's like, wait a minute.  I mean, notice that when people actually experience being tracked, they're not happy.  They're like, wait.  But most of the time you don't experience it.  And I'm not convinced it even actually provides any substantial, like, worthwhile revenue.  But it sure is a big business.  So anyway, big props to Mozilla for adding this welcome and long-overdue feature to Firefox.



Okay.  SolarWinds.  It's going to be a while before we really get through with this topic.



LEO:  The gift that keeps on giving, yeah.



STEVE:  Yeah.  As we know, post-intrusion forensics is always difficult.  Like the famous Hacking 101 is, well, once you break in, you delete the log files of your break-in, and thus you eliminate some of the tracks.  So that's sort of a classic example.  But, yeah, you can kind of do that.  And we've talked about how much the designers of the intrusion, how much effort they went to to deliberately thwart post-intrusion forensics from figuring out where they came from.  Like to decouple the intrusion from SolarWinds into other systems, to prevent it being tracked back to SolarWinds.



So the previous SolarWinds CEO, Kevin Thompson, says that it may - this was in front of the Senate or the House, I guess it was, a representative - oh, yeah, the U.S. House of Representatives Oversight & Homeland Security Committee.  He said:  "It may have all started when an intern" - right, blame it on an intern, they're gone - "when an intern set an important password to solarwinds123."  Fortunately, not monkey.  But still it was SolarWinds password set to solarwinds123.  And then, adding insult to injury, the intern posted it on GitHub.



LEO:  Love it.



STEVE:  Oh.  Kevin Thompson, he told a, as I said, a joint U.S.  House of Representatives Oversight & Homeland Security Committee hearing that the password was "a mistake that an intern made.  They violated our password policies, and they posted that password on their own private GitHub account.  As soon as it was identified and brought to the attention of my security team, they took that down." 



Okay, now, as soon as, you know, when you learn to speak that way, you get the C of the CEO in front of your designation.  Kevin's responsible-as-possible-sounding testimony was contradicted by SolarWinds' current CEO, Sudhakar Ramakrishna, who confessed that the password solarwinds123 was in use by 2017.  The researcher Vinoth Kumar, who discovered the leaked password to one of SolarWinds' file servers had earlier stated that SolarWinds did not change the password until November of 2019, after he had discovered it on the Internet and reported it.  So about two years that password solarwinds123 was in use.  Now, the insecure password - yeah.



LEO:  You have to wonder at all the employees who use it who didn't think twice.



STEVE:  Yes, exactly.  Exactly.  In two years that's how they logged onto that server.  Oh, thank goodness this is easy to remember.



LEO:  So easy to remember.



STEVE:  Don't have to look it up.  It's not a bunch of gibberish.  I can just say it over the phone.  How nice.  The insecure password is one of three possible avenues of attack, which SolarWinds has been investigating as it tries to determine how it was first compromised by the hackers.  The two other theories are brute-force guessing of company passwords, so-called "credential stuffing," as we call it now, as well as the possibility the hackers could have entered via compromised third-party software.  That's right.  Let's blame it on somebody else, if not this intern that we had a couple years ago whose password was allowed to sit there for several years.



Then some other third-party software, and of course they're the third-party software that really did the damage.  In other words, they don't know for sure.  And since post-intrusion forensics is difficult, we might never be certain.  But publicly posting a private password on GitHub is certainly not the way to keep it a secret. 



Okay.  Speaking of things that you really wish you could keep secret, but you can't, Rockwell Automation has a CVE-2021-22681.  It is a 10 out of 10 Critical, assigned by CISA.  The security of nearly all of Rockwell Automation's PLCs, which are Programmable Logic Controllers, are affected by the use of a single globally shared static encryption key.  Oh, yes.  Every one of the, now, I wrote "hundreds of thousands."  It's probably millions.  I mean, these things are everywhere.  I'll explain what PLCs are.  But they're all "protected," in air quotes, by the same single key.  So of course there just might as well not be one.



The Programmable Logic Controller fills an important gap within any process control system, or an important need.  For example, you might be on an oil rig, where the pressure of a feeder line, and I don't even know what that is, but it sounds good, a feeder line must be maintained within a range.  But the pressure might need to be taken at several different places and averaged.  And there might be multiple upstream sources of pressure controlled by valves with actuators.  So in a sense it's a small closed system having a handful of inputs and outputs.  And once its function is defined, it can and should just be left alone to work.  You just want that feeder line pressure maintained.  And if you've got to open some valves using actuators to maintain the pressure, then that's good.  And you want to average the pressure in a few locations.  So not a big complex job, but it's a job that needs to get done.



So how do you build the control system for that?  Once upon a time, before computers, a custom circuit would have been created, and some tech would have built it from scratch.  Today, you go over to Rockwell Automation's website and pick the PLC, the Programmable Logic Controller, that's just big enough to - because there's a whole bunch of them of different sizes.  You want the one that's just big enough to handle the number and types of inputs and outputs that you need.  Then an engineer who's been trained up uses Rockwell software, which is called Studio 5000 Logix Designer, to program the little computer that resides inside that industrial oil rig-tough little box.  And you hook it up.  And that little world will now take care of itself.



So a PLC does a limited set of very specific things.  Once upon a time, as I said, it might have been done with discrete circuitry, like a bunch of clacking relays, all wired together to implement the sequencing logic required to route vials of newly synthesized vaccine around their carousel, counting them as they pass, and then to flip routing gates open and closed at the exact time needed to fill the waiting containers.  Another typical job for a PLC.  But today all of that is handled, not with a bunch of clacking relays, but by an unseen Rockwell Automation PLC.  It's programmed once, and it effectively becomes part of the overall machine.



In any industrial setting, where things are moving, spinning, whirring, valves are opening and closing and stuff's happening, there are tasks that don't require a general purpose computer.  And god knows you sure don't want Windows anywhere near the control loop of systems like that.  It'll decide it's time to update, and your vaccine vials will go flying all over the place.  So yes, Windows hosts Rockwell's Studio 5000 Logix Designer app, which is used in a cool way to interactively design the logic that will be programmed into this.  But once that PLC device is programmed, it's blessedly off on its own.  Leave it alone, it'll just get the job done.



So everything would be great with these workaday PLCs.  But apparently some bozo somewhere decided that needing to go down to the shop floor to tweak the controller of the machine that's squeezing bottle caps onto Coke bottles was too much to ask.  So let's put it on the network.  Believe it or not, these perfect little happy worker controllers have received IP addresses.  Stop me if you've heard this one before.  What could possibly go wrong?  And yes, as I mentioned above, not only do they have IP addresses, often with public presences on the Internet, again, things that are just supposed to get their job done, just leave them alone.  They're working.  But they are all being protected by the same, now well known, cryptographic key.



Last Thursday, the U.S. CISA warned of a critical vulnerability, giving it a 10 out of 10, which is a hard score to earn, that 10.  You can get to 9.8 without trying that hard.  But getting a 10, it's like the Olympics.  So that allows hackers to remotely connect to Logix controllers and from there alter their configuration or applicable code.



CISA stated that the vulnerability requires a low skill level for exploitation.  Quoting them, they said:  "The vulnerability tracked as CVE-2021-22681 is the result of the Studio 5000 Logix Designer software making it possible for hackers to extract a secret encryption key."  And they didn't put "secret" in quotes, but, you know.



LEO:  Semi-secret.



STEVE:  Yeah.  We wanted it to be secret.  So could you please, let's keep it a secret, everybody.  Let's agree.  "This key is hard-coded into both Logix PLC controllers and engineering stations, and verifies communication between the two devices.  A hacker," they're writing, "who obtained the key could then mimic an engineering workstation and manipulate PLC code or configurations that directly impact a manufacturing process."  It's just why must we put everything on the Internet, Leo.  We just, you know...  



LEO:  Because it's there, Steve.  Because it's there.



STEVE:  But people's garage doors are on the Internet.  And, I mean, if it moves, hook it up.  Give it an IP address.



LEO:  That's it.



STEVE:  Oh, my lord.



LEO:  My garage door is on the Internet.  Is that a bad thing?



STEVE:  I really didn't mean to pick on you, Leo.



LEO:  It makes it easy to open it from anywhere.



STEVE:  On the other hand, I should have said, of course your garage door is on the Internet.



LEO:  Of course it is.



STEVE:  We know your front door is on the Internet.



LEO:  No, no, no.  Well, it is.  The camera.  Yeah, yeah, yeah.



STEVE:  I know.  I know.



LEO:  You're right.  You're right.



STEVE:  Okay.  So VMware's got some problems.



LEO:  Uh-oh.



STEVE:  I mean, it's not their fault.  They did things responsibly.  As we know, there are companies that get notified of a problem, and they don't fix it for a long time, and they force the people who notify them to release the information for the benefit of the world since the company refuses to do anything until apparently made to do so.  That didn't happen here.  What happened was a very bad flaw was found in the entire population of VMware's vCenter servers.  VMware could do nothing but patch it; right?  Like here, everybody update your VMware vCenter systems.  Unfortunately, they're a big target.



And the bad guys got right on this.  As a consequence, hackers are currently mass scanning the Internet in search of VMware servers that have not yet patched this newly disclosed code execution, remote code execution vulnerability which carries a severity rating of 9.8 out of 10.  As I said, 9.8 you can get.  To hit 10, you've got to really be doing something.



LEO:  You've got to be good.  You've got to be really good.



STEVE:  Yeah.  So the VMware problem is CVE-2021-21972.  It's a, as I said, remote code execution vulnerability.  vCenter is an application for Windows or Linux used by admins to enable and manage virtualization of large networks.  Within a day of VMware issuing a patch for this very bad problem, proof-of-concept exploits appeared from at least six different sources.  The severity of the vulnerability, combined with the availability of working exploits for both Windows and Linux machines, immediately motivated hackers to scramble to find vulnerable servers.



Troy Mursch, a researcher with Bad Packets, wrote:  "We've detected mass scanning activity targeting vulnerable VMware vCenter servers."  He said that the BinaryEdge search engine - which we know is sort of another version of Shodan.  The BinaryEdge search engine found almost 15,000 vCenter servers exposed to the Internet, while Shodan searches revealed about 6,700.  The mass scanning is aiming at identifying servers that have not yet installed the patch.



So the flaw is just about as bad as it gets.  It allows a hacker with no authorization to upload files to vulnerable vCenter servers that are publicly accessible over port 443, which as we know is TLS, HTTPS.  Successful exploits will result in hackers gaining unfettered remote code execution privileges in the underlying operating system.  The vulnerability stems from a lack of authentication in the vRealize Operations plugin, which unfortunately is installed by default.  So they're all going to have it.



In their blog posting, Positive Technologies, who discovered and responsibly privately reported the flaw to VMware, wrote:  "In our opinion, the RCE (Remote Code Execution) vulnerability in the vCenter Server can pose no less a threat than the infamous vulnerability in Citrix."  And here they're referring to CVE-2019-19781, which was widely implicated in the mass of ransomware attacks on hospitals, those early ones, back in 2019.



They said:  "The error allows an unauthorized user to send a specially crafted request, which will later give them the opportunity to execute arbitrary commands on the server."  So they're being a little bit cagey because they don't want to give away everything.  They're being responsible still.  They said:  "After receiving such an opportunity" - you know, on the other hand, right, six public exploits with full source are available.  So the cat's out of the bag.



"After receiving such an opportunity," they wrote, "the attacker can develop this attack, successfully move through the corporate network, and gain access to the data stored in the attacked system, such as information about virtual machines and system users.  If the vulnerable software can be accessed from the Internet" - which of course is the case in vCenter systems, those 15,000-plus of them - "this will allow an external attacker to penetrate the company's external perimeter and also gain access to sensitive data.  Once again," they write, "I would like to note that this vulnerability is dangerous, as it can be used by any unauthorized user."



So, yeah, we got the message.  Again, it's one of those races against time, essentially.  One day after this patch was released, six proofs of concept existed, and mass scanning began.  So my mantra has been make sure you are maintaining an open line of communication with the vendors of all the front line equipment that you're maintaining and make sure this doesn't go into a, yeah, we do these on Friday sort of mailbox, but really comes to the attention of somebody who it may be necessary to get out of bed or, yes, reboot a server that you'd rather not reboot because you're going to have to kick everybody off that's currently using it.  But boo-hoo.  This thing needs to get fixed now.  So this is one of those.



And there's just, you know, there isn't any way around this.  They had to release the patch.  The only thing they could do was to hope that the news got out, that the people who are in responsible positions would respond to it instantly, inside of the timeframe required to reverse-engineer it and for the bad guys to start scanning.  Who knows how, I mean, and this is going to typically be a larger company running a VMware vCenter.  They have a huge percentage of install base.  I saw that it was like 80% market share at the high end of this kind of virtualization up in the high fortune companies.



So those are the targets that the ransomware guys want.  So no surprise that this was, you know, not only was it simple to execute once you had the proof of concept code, obviously it's simple to reverse engineer because it only took a day.  But the target was juicy.  The target set would also be juicy, targets of opportunity.  So this thing just had everything.



Last week - I want to share with our listeners, and I think everyone will get a kick out of it - I mentioned that one troublesome machine owned by a tester in Germany was again causing my new code some trouble.  Back in the earlier ReadSpeed Benchmark development days, I was worried about wearing out my welcome with him because, like, he had a problem.  And the only thing I could do was to produce a series of test releases in what was ultimately a futile attempt to zero in on the trouble and fix it.  I mean, I added auditing code that was spitting out like leaving breadcrumbs as it went.  And then they just disappeared.  And it's like, okay.  And then I would try something else, and I would zero in on where the breadcrumbs disappeared, you know, did everything I could remotely by just giving him test after test after test to try and run and then report on what happened.



Then, miraculously, his system started working.  And of course that always makes me nervous because if you don't really do something to fix a problem, then that miracle might choose to reverse itself at any point.  And sure enough, when I moved the new code over into SpinRite and released the first test releases of it there, it no longer worked on his system.  So I had purchased one of the very same old Gigabyte motherboards from eBay.  And it came last week.  So, and I may have had it, in fact, but hadn't - what?



LEO:  You got it.



STEVE:  Oh, yeah, yeah.  In fact, I have...



LEO:  Such dedication.  I can't believe it.



STEVE:  This is, oh, that's standard operating procedure for me.  I've got controllers and drives and motherboards.  And a lot, almost everything I can do just by sort of looking at the symptoms, looking at an audit, and then making a good guess.  And then the guy will say, yay, it works now.  It's like, congratulations.  Like, okay, good.  Whew.  But sometimes it's just nothing I can do.  So I put the motherboard in an ATX case that I had.



Anyway, I thought I'd give our listeners a sneak peek into this microdrama because it demonstrates a bit about the process of debugging code and serves as a beautiful example of the weird sorts of things that we face in the real world where code which is born in the lab actually needs to function in the real world eventually.  And as it turns out I now know I could never have figured this out remotely.  I mean, I would have thought he was nuts.  I mean, I just wouldn't have known what to think because, even with the machine sitting in front of me, what I saw made absolutely no sense.



The problem was occurring in a simple routine which copied the contents of a disk sector buffer from high XMS memory above 1MB down into traditional x86 segmented memory below 1MB.  Should be a piece of cake.  But the machine went into that subroutine, and it never came back, never came out.  So, okay.  At least now I had apparently located the location of the problem that Chris and his machine in Germany was having.  So I fired up my debugger.  And I followed the processor into that simple subroutine.



As we've talked about a lot, one of the reasons I find the Intel chips enjoyable to program, and also why I never want to program a RISC chip, an ARM-based architecture, for example, is that the Intel chips have a CISC architecture, Complex Instruction Set Computer, CISC, C-I-S-C.  The ultimate example of a CISC ISA, an ISA, Instruction Set Architecture, was probably the DEC PDP-11 and the VAX machines.  They were designed back at a time when a lot of code was still being written in their assembly language.  And when compiler design was still sort of a nascent art, I mean, those were the early days.  So the chips themselves presented a sort of high-ish level language at the assembly language, at the machine language, to the people who were going to program them.  They wanted to make it pleasant.



Okay.  So for example, the Intel x86 architecture includes an instruction that I used in that subroutine.  It's a byte-range copy instruction that no self-respecting RISC chip would ever abide.  They'd be like, what?  We're not copying a range of bytes.  We do one thing really well.  And if you want more of that, you've got to ask for it.  But not Intel.  So the starting address of the source range is placed into the chip's SI register, SI standing for Source Index.  I'm not kidding.  And the starting address of the destination range to copy to is placed into the chip's DI register, DI standing for Destination Index.  And the number of bytes to be copied is placed into the CX register, C as in Count.



Then a single instruction, like one byte opcode instruction is executed, which causes the heavily microcoded Intel chip, or actually in this specific case an AMD processor, which is a Phenom II that was on this Gigabyte motherboard, to fetch a byte from where the SI register points, store it to where the DI register points, increment both the SI and DI registers so that they will now each be pointing to the next byte in their ranges, then decrement the CX register.  If the CX register has not just been decremented to zero, then repeat.  Copy the next byte and so on.



So essentially, by executing a one-byte instruction, after setting things up by putting specific pointers into specific registers, the Intel will copy a block of data from one place to another.  So I'm explaining all this because as I single-stepped the processor, instruction by instruction, watching it like put the data for S into the SI register, no problem.  Put the data into the DI register.  That worked.  Store the 512-byte count into CX.  Yup. I then stepped into that byte range copy instruction, and nothing happened.  It was as if the instruction was taking forever to execute.  It just went into the debugger.  The debugger didn't come back to me.  So one of the tricks we all learned, and Leo, I know you know, back in the early days of the PC, and a system appeared to lock up, was to hit the Num Lock on our keyboards a few times.  



LEO:  Forgot about that.



STEVE:  And, oh, yeah, I still do it.  Of course I'm still living back in this world.



LEO:  It doesn't do anything; does it?



STEVE:  Well, it turns the light on and off.  And so if the Num Lock key on your keyboard works, that means that keyboard interrupts are being serviced.



LEO:  Oh, okay, good.



STEVE:  That the BIOS has seen that you hit Num Lock, and it sends a message to the keyboard to turn that light on or off.  So it sort of says, oh, look.



LEO:  I'm not dead yet.



STEVE:  Yeah.  It's just a flesh wound.



LEO:  Yes.



STEVE:  So essentially back then it meant that there was still some hope.  But if you hit Num Lock a few times, and the light didn't change, then probably not even the famous three-finger salute of CTRL+ALT+DELETE would bring the system back.  It was time to reach over for the Reset button in order to get things restarted.  But in this case Num Lock was still toggling.  So the debugger showed that it executed this instruction, and nothing happened.  Yet Num Lock was toggling.



And Chris had originally also noted that the little ASCII character spinners, if you may remember, when the ReadSpeed Benchmark is running, I cycle the characters at the ends of the title banner, which are vertical bars.  I switch them to left-leaning slashes, then minus signs, then right-leaning slashes, then back to vertical bars.  So it makes little spinners.  He commented that they were still spinning.  His system stopped working right in the middle, but they were still spinning.



LEO:  Interesting.



STEVE:  Which told me again that meant that the timer interrupt was being serviced because the timer interrupts at 18.2 Hz, and so I count several of those, and then I advance the ASCII character to the next position.  So things were still working.  The processor was still running.  But it was also apparently...



LEO:  [Crosstalk] loop, apparently; right?  Just stuck in a loop.



STEVE:  Well, yeah.  It was apparently just sitting at that single instruction, doing nothing.  Now, Intel chips have some built-in debugging support.  And this debugger works using that.  It sets a hardware breakpoint on the instruction after the one that's about to be stepped through.  That way, when the processor comes out on the other side of the instruction, the debugger retains control.  It updates the screen to show the current processor state, and you can see where you are.  But that breakpoint was never being tripped because the AMD Phenom II processor was apparently never stepping out of that instruction to the next one.



So I stared at that for a while, thinking, what?  It made no sense.  It had to work.  And I think I mentioned last week that Chris had observed that everything worked just dandy if he booted from a diskette.  But not when he booted from a USB thumb drive.  And in my subsequent experimentation before rolling up my sleeves, I learned that all was okay when I booted from any mass storage device.  And in subsequent testing, I determined that it wasn't actually what booted the machine, but from where the program was run.



In other words, this instruction, this one instruction would hang if I booted from hard drive, but then ran the code from a USB thumb drive.  Yet everyone else who has been testing this code all along is also typically booting and running from the code from their USB thumb drives.  Yet no one else was seeing this problem.  Which was really not surprising since this problem could not possibly be happening in the first place.  Yet it was.



Okay.  So because what I was seeing was impossible, I decided to decompose that fancy single-instruction Intel block copy into a series of individual instructions that would accomplish the same thing.  You know, do my own loop, rather than use this built-in looping behavior of the Intel chip.  And again, I single-stepped.  And again, the system hung at one indivisibly simple instruction, when the processor attempted to load the accumulator register with the contents of the location in upper memory.



So now we're just at a move instruction.  There's nothing more basic, more simple than a move instruction; right?  You've got to move data from one place to another.  It never completed.  But also it never completed only when the code was run from USB.  And DOS doesn't load anything on the fly.  It's not doing anything fancy.  It's old school.  It loads everything first into RAM before it starts to run the program.  So how could there be any memory of where the byte came from, the evil byte, the move instruction that it just wasn't going to run.



So anyway, I have no idea why running from USB could possibly matter.  The only thing I can conclude is that there's some bizarre subtle bug in that old AMD Phenom II processor.  The Intel x86 architecture provides us with six segmentation registers.  I was using the default, which is DS, which stands for Data Segment.  So what I was seeing was impossible.  In a Hail Mary, I changed the code to use the FS segment register, and everything worked perfectly every time.  So henceforth, none of SpinRite's code will ever set the data segment to zero and attempt to use it to access 32-bit flat memory storage.  Doing that should work.  And notice that it works for everybody else.  And as far as we know, everywhere except on a Gigabyte motherboard with an AMD Phenom II processor, when the code is loaded from USB.  Welcome to my world.



When I published a test release for Chris to try, and also to check my own sanity, it did indeed fix his trouble, too.  And someone else who had never reported in, but who had been watching, wrote to say that his similar AMD Phenom II-based Gigabyte system had also never worked before, but now it does.  So anyway, I thought our listeners might get a kick out of a peek inside a bit of last week's work.  Most problems that I track down and resolve teach me something that I don't know.  That's what makes this journey so interesting.  I can't say that I learned anything from this problem except what not to do for magical mysterious reasons, which I will never do in the name of achieving total compatibility.  Once upon a time, back in '04...



LEO:  Way back.



STEVE:  Yeah, when SpinRite 6.0 was released, one of the reasons it developed such a strong following was that it just always worked.  I am now in the process of wrestling this new and soon-to-emerge SpinRite 6.1 back into that state, where it just always works.  And when I'm finished, it will.



LEO:  I'm surprised, given that bug, that you still prefer segmented memory architectures and x86 to the flat memory model of ARM processors.  I mean, why do you prefer x86?



STEVE:  I wouldn't say that I prefer it.



LEO:  Okay.



STEVE:  And in fact I'm having so much...



LEO:  I mean, this bug comes from a segmented memory flaw of some kind.



STEVE:  Yes, yes, yes.  What I appreciate is that it is often the case that you don't always need access to 32 bits of stuff.  That is, you know, that's 4.3GB.  Most things fit within 64K, which means you could access them with 16 bits.  But if you were going to access them with 16 bits, then you need to choose which 16 bits in the system.  And that's what segmentation does is it gives you an offset to the beginning of a 64K range of bytes.  And it's efficient, you know, in terms of back once upon a time, when efficiency actually mattered, you know, people say, Gibson, I can't believe your Benchmark is 13K.  It's like, yeah, 13,000 bytes.  And a lot of that is text because I wanted to say something on the screen.



The point is we've completely lost touch with how efficient code can be.  And I understand I'm the weirdo here.  But these are the problems that I like to solve.  But at the same time, Leo, I am so anxious to move to this new 32-bit platform for SpinRite 7.  I'm just - I cannot wait to get there because it will be nice.  I've been in programming Windows, as we know, since I stopped programming SpinRite.  And I've really gotten spoiled by just being able to point to something, go, yeah, I want that.  Even though it's a long way away, I still want it.



LEO:  And we should point out Steve is one of the handful of people that addresses his own registers and pays attention to this stuff.  Almost everybody else is using a higher level language that you can completely ignore what's going on at the processor level.  It's just you, Steve, let's face it.



STEVE:  Yes.  I know.  I know.



LEO:  But as a connoisseur of assembly language, I respect your opinion on this because you're the last man standing.  Congratulations.  No, I'm sure there are plenty of people, especially in the gaming industry, who are writing the most time kind of code.



STEVE:  Oh, and Leo, the guys who do those demos, the demos that fit within a certain size and do this amazing stuff with graphics, holy crap are - well, and hackers.  Hackers are all living here because this is where they are.



LEO:  Right.



STEVE:  Is down in buffer overruns and register contents and  things.  So, yeah, at the application programmer level, nobody needs to worry about this.  But anything you do where it actually is necessary to know exactly what's going on, well, exactly what's going on is in the registers.  That's where the action is.



LEO:  This man lives in the registers.  That's the truth of it.  Yeah.



STEVE:  Okay.



LEO:  And actually it's really valuable to understand that, by the way, because there are subtle bugs that happen in higher level languages that it's helpful to understand why, especially like numeric overruns and things, where you understand that's a 32-bit integer or a float.  And you can't get that precision or that kind of thing.



STEVE:  Well, and what would you do?  If you had a higher level language, and you executed an instruction that was supposed to copy something, and it just went in and never came back.



LEO:  Happens all the time.  I sent you a wonderful article, I don't know if you read it, about debugging the loading code in Grand Theft Auto IV, which is notoriously horrific, like...



STEVE:  Oh, yeah.  You sent that to me for reading while I was recovering from my second vaccine shot, yeah.



LEO:  Yeah.  So this guy, it's famous, GTA IV takes sometimes 20 minutes before you can play the game.  I mean, it's insane.  And it turns out it's because they're parsing a big JSON file using sscanf(), and it's got a subtle bug in it.  And it's actually not a bug, but it's something that causes - it's an inefficiency.



STEVE:  Right.



LEO:  You probably, at the level you're coding, pay no attention to efficiency, the Big O notation or anything like that.  That doesn't come up; does it?



STEVE:  Oh, yeah.  Remember when I was doing the LRS, the Longest Repeated Strings?



LEO:  Oh, that's right.



STEVE:  I was working on that.  That was a serious...



LEO:  Linear versus geometric expansion of the time, yeah.



STEVE:  P vs. NP sort of problem.



LEO:  Right, right, right.  Okay.  So you do pay attention to that stuff.  Usually in assembly it's probably not - doesn't come up that much.  All the loops are unrolled and everything, you know.  You're not recursing or anything.



STEVE:  Yeah.  I dropped, in fact, I used our own podcast, something I learned from the podcast.  I had in the original ReadSpeed code, I was hashing the boot sectors of drives with SHA - I don't remember now.  Maybe SHA-1 because I really didn't need that much.  But it was still a rather large algorithm.  



LEO:  Right.



STEVE:  And when I moved into SpinRite, I was upset that just a hash function was taking up so much space.



LEO:  I love it.



STEVE:  So I switched to the FNV function, FNV-1, which we talked about on the podcast, which simply multiplies a byte by a specific prime, and it's what the hackers were using in the ransomware to create a high-speed, very small, lightweight hash function.  SpinRite now has that.



LEO:  Interesting.  Yeah, I remember that, yeah.



STEVE:  And I saved myself several K worth of hash lookup tables by switching to a very economical, basically FNV.  It doesn't have to be cryptographically strong.  I just needed a good hash.  And now I've got one that takes up no space.



LEO:  Well, that was kind of the bottom line in this fix.  This guy, by the way, didn't have access to the source code.  He disassembled - that was the other thing.  I thought about you.



STEVE:  Good for him.



LEO:  He disassembled it and did it all by hand.  He didn't have a symbol table or anything, was able to figure it out, modify the DLL.  And it really came down to the fact that these folks at Rockstar had written their own JSON parser, which is horrifically inefficient.  And bottom line is use libraries.  Don't try to - you're nuts to write your own JSON parser.  That's just nuts.  Why do that?  He fixed it.  He got about 70% improvement in loading time.



STEVE:  Nice.



LEO:  Yeah.  We'll see if Rockstar pays any attention.  Anyway, that's why I sent it to you.  I thought while you're curled up on the couch you'd enjoy this tale of disassembly.



STEVE:  Perfect story.



LEO:  All right, Steve.  On we go.



STEVE:  One little bit of news.  Paul, @whatsupdoc114, shot me a note that Exchange Servers all over the world were currently under attack.  I did a little quick checking, and sure enough, today on March 2nd, Microsoft just released seven remote code execution vulnerability patches for Exchange Server, the most three recent, I think 2019, 2016, and 2013 or 12.  Anyway, I did a little digging, and I found a note.  The risk is still extremely high.



The exploit allows an attacker to perform a Pre-Auth RCE and essentially end up with the ability to run commands with system privileges since most customers don't use split permissions or have not performed the steps required to remove excessive permissions from Exchange Servers and Active Directory, it's likely that the attacker may be able to gain highly privileged rights in your on-premises domain.  So it must be, I don't know where the - oh, yeah, you found it.  Emergency patches for four - and actually there are seven that I saw.



LEO:  Yeah, so this is out of date.  This is Dan Gooden writing at Ars Technica.  He's always very good.  He pushed this about an hour ago.  It was four, and it's now up to seven zero-days in Exchange Servers.



STEVE:  Wow.



LEO:  That's not good.  And by the way, Microsoft says hackers have been using it on behalf of the Chinese government.  So that's not good.  That's not good.  Well, thanks for the update. That's why people listen.  We don't normally do breaking zero-days.



STEVE:  No.



LEO:  But when they happen, we've got to; right?



STEVE:  Yup.  And so here is some news that is just - it's beyond distressing.  Okay.  So Criteo, I guess that's how you pronounce it, C-R-I-T-E-O, is a leading tracking company.  They send website administrators with whom they already have a tracking and analytics relationship an email.  It asks them to make a quick change which will "only take two minutes," and it will "adapt their website to the evolution of browsers."  Which is to say that it will work around their own website's visitors' attempts to block tracking and to reenable tracking to their site's visitors in a "more optimal way."



Then in this email, after presenting instructions for the site's webmaster about how to make the required change, which will indeed only require a couple of minutes, in the particular instance of email that I saw, they conclude with, if this is not done, you may lose 11.64% of your sales, 11.53% of your gross turnover, and 20.82% of your audience.  And this brings us...



LEO:  Geez.



STEVE:  ...to some recently published research, which explores just how prevalent and pervasive this new technique has grown over the past few years.  The group of five researchers will be presenting their work at the 21st Privacy Enhancing Technologies Symposium (PETS) 2021 this July.  But we have the research now.  I'm going to quickly read the abstract of their paper and then explain in detail because this is really important and horrifying what this means.



Their abstract says:  "Online tracking is a whack-a-mole game between trackers who build and monetize behavioral user profiles through intrusive data collection, and anti-tracking mechanisms, deployed as a browser extension, built into the browser, or as a DNS resolver.  As a response to pervasive and opaque online tracking, more and more users adopt anti-tracking tools to preserve their privacy.  Consequently, as the information that trackers can gather on users is being curbed, some trackers are looking for ways to evade these tracking countermeasures.



"In this paper we report on a large-scale longitudinal evaluation of an anti-tracking evasion scheme that leverages CNAME records to include tracker resources in a same-site context, effectively bypassing anti-tracking measures that use fixed hostname-based block lists.  Using historical HTTP Archive data we find that this tracking scheme is rapidly gaining traction, especially among high-traffic websites.



"Furthermore, we report on several privacy and security issues inherent to the technical setup of CNAME-based tracking that we detected through a combination of automated and manual analysis.  We find that some trackers are using the technique against the Safari browser, which is known to include strict anti-tracking configurations.  Our findings show that websites using CNAME trackers must take extra precautions to avoid leaking sensitive information to third parties."



Okay.  So here's the story.  So first of all, what are CNAME records?  They're not something we've had much occasion to talk about in the past.  I have a feeling that's going to change.  But on the other hand, DNS is something we're pretty much always talking about.  A CNAME record is simply another type of DNS record.  As we know, a DNS "A" (standing for Address) record resolves a specific domain name to a dotted quad IPv4 address.  Similarly, a DNS "AAAA" record resolves a specific domain name into an IPv6 address.



An SMTP email server might query a domain, like for example GRC, for any MX records which will point to one or more IP addresses, which are used for email servers for that domain.  And for various reasons, a domain's text records might be queried for information, like to provide the public key used to check a domain's anti-spam signatures.  So although DNS's primary purpose is to look up and return IP addresses, it's also a nifty general purpose distributed Internet directory, capable of containing and returning all sorts of other information.  And another of those types of queries is the CNAME.



CNAME (C-N-A-M-E) stands for Canonical Name.  Whereas an "A" query returns an IPv4 address, a CNAME query returns another domain name.  The domain name being queried is considered to be an alias, and what's returned is the canonical name for that alias.  And CNAME records are handled specially by DNS.  As Wikipedia explains, CNAME records are handled specially in the domain name system and have several restrictions on their use.  When a DNS resolver encounters a CNAME record while looking for  a regular resource record, it will restart the query using the canonical name instead of the original name.  The canonical name that a CNAME record points to can be anywhere in the DNS, whether local or on a remote server in a different DNS zone.  So you can think of it as a pointer.  It is a pointer to a different DNS name.



So here's what's evil, and what that email above was asking website admins to do, and which many - these guys counted more than 10,000, I'll get to that in a minute - websites have done.  They were asked to say, okay, say at example.com, to place a CNAME record into their site's DNS such that some arbitrary but specified subdomain of example.com, like say dyzxrdb.example.com, would be an alias for the canonical name web-trackers-R-us.com.  So what that does exactly is anytime someone wants to look up the IP address for dyzxrdb.example.com, their assigned DNS resolver, which is performing the DNS resolution for them, will query the example.com domain's name servers for that subdomain.  But because that subdomain record is a CNAME record, that's what will be returned, not an IPv4 IP address, but what will be returned to the querying DNS resolver is a CNAME result with that web-trackers-R-us.com as its answer.



The resolving DNS server that understands that is the canonical name for which dyzxrdb.example.com was an alias will then ask web-trackers-R-us.com silently, like on its own, because this is all built into DNS, for its IP.  Whereupon the user's DNS resolver will return that IP as the IP of dyzxrdb.example.com to the person, the browser, the web browser that asked for it.  From the user's perspective, they asked for the IP of a subdomain of example.com, and they received an IP.  But due to prior collusion between the website they're visiting and web-trackers-R-us.com, the IP they received was for web-trackers-R-us.com.  From the standpoint of the user's browser, this is an in-domain, same-domain query.  So third-party cookie restrictions do not apply.  And the user's web browser will treat this query as a subdomain of the website being visited.



Okay.  So what we have so far is a horrifically sneaky means of deliberately overriding a user's wishes for anti-tracking by websites that feel that they have a superior right to track and obtain leverage from their visitors.  But believe it or not, it's much worse.  Cookies set on specific domains are accessible to, and sent to, anyone who queries their subdomains.  This means that by colluding in this way to allow an untrustworthy third-party tracking entity to pretend to be within a website's domain...



LEO:  Ooh.



STEVE:  Yes, Leo.



LEO:  That's sneaky as hell.



STEVE:  Well, the cookies being held...



LEO:  So it's not a third party, doesn't appear to be a third-party cookie, even though it is.



STEVE:  Correct.  It doesn't appear to be a third-party query, a third-party request.  It actually is.  But this means the cookies being held by the browser of visitors to that site will be sent to that third-party entity because the browser won't know any better.  The website's visitors' logon session authentication cookies will be sent outside of that domain...



LEO:  Oh, that's not good.



STEVE:  No, to untrusted and, I would argue, untrustworthy third-party tracking and analytics companies.



LEO:  Wow, that's really not good.  You're sending your Facebook login cookie to them, in effect.



STEVE:  Exactly.



LEO:  They can post as you.  Geez.



STEVE:  Yes.  The fact that it's done over HTTPS provides no security.  Anyone at any of those tracking, advertising, analytics firms  of which 13 have now been identified by the researchers  could trivially impersonate any user of any website who didn't explicitly log off, and who therefore still have a valid authentication cookie.  It is an unbelievable breach of trust and abuse of web technology.



I ran across a wonderful website that allows us to play with and explore our own browsers' cookie and subdomain handling to understand exactly this issue.  And I made it this week's Security Now! podcast shortcut of the week, so it's https://grc.sc/808 because this is podcast number 808.  That will bounce you over to scripts.cmbuckley.co.uk/cookies.php.



And I played with it this morning because I was wondering whether my Firefox 86 with its new full "Total Cookie Protection" that I opened with fully enabled would help.  No.  It is not blocking any of this leakage because these are not third-party cookies.  These are subdomain cookies.  What this cool site, again, grc.sc/808, it allows you to set cookies in different domains and subdomains of that site and see which ones are returned.  It's a very cool little page.  So I'm sure that our listeners will get a kick out of it.



Okay.  So how widespread is this behavior?  Thankfully, these researchers have gone to some effort to unearth the extent of this currently spreading industry-wide website collusion with the tracking industry.  It's not difficult.  You just, for example, resolve any subdomains of the primary domain that you receive from a website.  You do that DNS lookup for yourself as if you were a recursive DNS resolver, and you see whether you receive a CNAME record that points to any one of the 13 current providers of this form of CNAME tracking.  And you've got something up on the screen, I see, Leo, from that page.



LEO:  So this site, basically what I've done is I've told cmbuckley.co.uk to set my cookie.  And it returns my cookie, even though it says it looks like a first-party cookie, but it's really my third-party cookie.  Is that what's happening here?



STEVE:  Well, so and then, if you click down below in that text in the lines below, see that they have an a.something.



LEO:  Yeah, a script.  Yeah, oops.



STEVE:  So that's a subdomain of the root domain, and you can see it receive your cookie.



LEO:  Right, same thing, there's a cookie, yeah.  And then let's zoom in on this.



STEVE:  Yes.  And so that's the point is that because it's a subdomain, you set the cookie on the root domain, subdomains all get the same cookies.



LEO:  I see.



STEVE:  So with the collusion enabled by the CNAME, some random gibberish dot, like .amazon.com, it would get Amazon.com's cookies.  All the amazon.com cookies you have would go to the third party.  It's that bad, Leo.  It's unbelievable that this has been happening.  Who would know?



LEO:  And of course they're saying, oh, well, we'll never do that.  We just want to know who's visiting your site.  This is not - this is for you.  We would never steal your authentication cookies.



STEVE:  Right.  This is for your benefit.  We're making more relevant ads.  And it keeps the Internet free, and it wouldn't be free otherwise.



LEO:  This is one way people are getting around ad blockers and trackers is looking - if everything looks first party, they don't block it.  None of these block if it's first party; right?



STEVE:  Right.



LEO:  So if you can make a third-party ad or a third-party cookie look...



STEVE:  Be a subdomain, yup, yup.  Okay.  So the researchers found this technique currently in use on a total of 10,474 websites.  And of the top 10,000 websites overall, 9.98%, one in 10 of the top 10,000 are currently employing this form of CNAME tracking, cloaking, subdomain collusion.



LEO:  Are they sending the cookies to themselves or to this third party?



STEVE:  That's the problem.  There's no distinction, Leo.



LEO:  We don't know.  We don't know.



STEVE:  No, no, no.  I mean, we do know.  There's no distinction.  Our browsers, what that page you were playing with demonstrates is our browsers send cookies set on the root domain to their subdomains.



LEO:  Right.



STEVE:  That's the way browsers are designed.  They're supposed to do that.  Once upon a time you could start the root domain with a dot.  It'd be like .amazon.com.  And that would say don't share these root cookies with my children, with our subdomains.  That behavior went away years ago.  It's now ignored by browsers, even if they still see it.



Okay.  So their research furthermore observed what they termed "targeted treatment of Apple's Safari web browser" where the advertising technology company I mentioned before, Criteo, who mailed the letter I opened with, switched specifically to CNAME cloaking to bypass Safari's otherwise strong privacy protections.



And it's worse.  Data leaks.  Significant cookie data leaks were found on 95% of the sites that use that CNAME tracking, so 95% of the 10,474 sites, all of which sent cookies containing private information such as full names, locations, email addresses, and even session authentication cookies to trackers of other domains without the user having any knowledge or control.  Again, remember that the entire presumption of cookies is that bad and abuse-prone as they may be, at least they stay within the domain that set them.  At least their content, whatever it might be, even if it's a user's actual name and real world identity, bad practice as that would be, at least it remains between those two parties.



So while cookies can be used for tracking, the only data that's ever returned to a domain is something that that domain had previously sent.  Thus by definition it's not secret to that domain.  But now, thanks to the horrendous abuse of CNAMEs being used to deliberately confuse cookie domains, data is being sent with queries by the user's browser to entities who never set that data in the first place.  That tracker never set the authentication cookie, which is how the user is staying logged in.  They never put the user's name and location and email address in the cookie.  The domain did, figuring, okay, yeah, it's bad practice, but what the hell.  It's going to stay here.  It's only between the users' browser and us.  And, oh, look, we're HTTPS now, so no one can spy on it.



CNAMEs break that so that all the information which was private between the users' browser and the domain is now being sent to any subdomains, and this subdomain is now a tracker, an analytics company.  As the researchers noted, that data which should never be exposed to any third party often contains information that tracking firms would die to have and leverage.  And now they don't have to.  They just need to get websites to  collude with them by adding a CNAME record to that domain's DNS.



There is a bit of good news.  The only good news here is that good old Gorhill's uBlock Origin add-on is at least partially effective at spotting and blocking accesses to these despicable subdomains.  I have in the show notes a table from the research, Table 1, titled "Overview of the analyzed CNAME-based trackers," based on the HTTP Archive dataset from October 2020.



The number one tracker is a company called Pardot, P-A-R-D-O-T.  Unfortunately, it's owned by Salesforce.  That had the highest number, just shy of 6,000 detected websites.  5,993 detected websites were using Pardot, a Salesforce company which, I mean, we all know Salesforce, they say "powerful business-to-business marketing automation," stating that "Pardot offers powerful marketing automation to help marketing and sales teams find and nurture the best leads, close more deals, and maximize ROI."  And they are the number one user and abuser of this technology.



Number two position is Adobe Experience Cloud that is also doing this.  And then there's a list of all 13 of these companies.  But in a note on this table, the researchers did observe that Pardot is being blocked because the third-party script being sourced from Pardot.com is being blocked, that is, by uBlock Origin; and that, if that script was not blocked, then CNAME abuse would succeed.  The researchers had the following to say about countermeasures against CNAME.



They said:  "In response to a report that a tracker was using CNAMEs to circumvent privacy block lists, uBlock Origin released an update for its Firefox version that thwarts CNAME cloaking.  The extension blocks requests to CNAME trackers by resolving the domain names using the browser's own browser.dns.resolve API to obtain the last CNAME record, if any, before each request is sent."  And by that they mean CNAME records can actually chain; right?  Because it's a pointer that causes the DNS to go to another domain, that one could have a CNAME that could point it somewhere else.  So it wants to follow the chain to the last CNAME record.  Then it checks whether the domain name matches any of the rules that it is blocking.  So it's got a robust CNAME chain following a technology in uBlock Origin.



He says:  "Subsequently, the extension checks whether the domain name matches any of its rules in its block lists, and blocks requests with matching domains while adding the outcome to a local cache."  And then they said:  "Although uBlock Origin also has a version for Chromium-based browsers, the same defense cannot be applied because Chromium-based browser extensions do not have access to an API to perform DNS queries.  As such, at the time of this writing, it is technically impossible for these extensions to block requests to trackers that leverage CNAME records to avoid detection.



"uBlock Origin for Chrome, which does not have an explicit defense for CNAME-based tracking, still manages to block several trackers.  This is because the requests to the trackers matched an entry in the block list with a URL pattern that did not consider the hostname.  Unfortunately, it is fairly straightforward for the tracker to circumvent such a fixed rule-based measure by randomizing the path of the tracking script and analytics endpoint, as is evidenced by the various trackers that could only be blocked by the uBlock Origin version on Firefox."



And you see that in this table.  They have a column for uBlock Origin where Firefox was successful, and uBlock origin where Chrome was successful.  uBlock Origin on Firefox, because it actually is doing CNAME block lists, is able to be more effective.



LEO:  So it's interesting because I use Firefox and NextDNS.  So it looks like I have pretty full coverage if I do both of those.



STEVE:  Yup.  NextDNS is also a good CNAME blocker, yes.



LEO:  They're kind of like a piehole in the sky.



STEVE:  Right.



LEO:  Yeah, I love that.



STEVE:  So the researchers wrap up their research with the following conclusion.  They said:  "Our research sheds light on the emerging ecosystem of CNAME-based tracking, a tracking scheme that takes advantage of a DNS-based cloaking technique to evade tracking countermeasures.  Using HTTP Archive data and a novel method, we performed a longitudinal analysis of the CNAME-based tracking ecosystem using crawl data of 5.6 million web pages.  Our findings show that unlike other trackers with similar scale, CNAME-based trackers are becoming increasingly popular, and are mostly used to supplement 'typical' third-party tracking services. 



"We evaluated the privacy and security threats that are caused by including CNAME trackers in a same-site context.  Through manual analysis we found that sensitive information such as email addresses and authentication cookies leak to CNAME trackers on sites where users can create accounts."  In fact, I didn't mention this, but in their report they took a handful of these sites where you can create an account.  They created accounts.  They tracked and verified the leakage.  They used the leaked authentication tokens to impersonate themselves, and it all worked.  So this is not a theoretical problem.  And this is, remember, 10% of the top 10,000 websites are doing this now.  It's just...



LEO:  It's so amazing.



STEVE:  It's just horrible.



LEO:  Yeah, horrible.



STEVE:  So what we have is a real mess.  No form of explicit tracking was ever designed into our use of the web.  It happened as an unintended consequence of single advertising services having appearances on multiple hosting websites.  And those providers were allowed to set cookies in our browsers just like their originally intended first-party cousins.  I would argue we should have stopped it then.  We should have just said no.  But the trouble was this tracking was effectively invisible.  Users didn't see it.  It went completely unseen by the public.  And it wasn't the public's responsibility to stop it.  I would argue it was technologists' job to say no because it was the technologists who were abusing this technology.  But of course  those wearing white hats didn't say anything.  No one said no.



Then, when an awareness began to emerge, and third-party cookies were being threatened and sometimes disabled or deleted, browser fingerprinting emerged as a means for allowing what had grown into a tracking industry to retain its grip on our browsers and on us.  Since fingerprinting was more difficult to defend than cookies, it received a stronger pushback from browser vendors who didn't like the idea that cookies were being bypassed as a means of tracking their users and that this kind of slimy fingerprinting was going on behind the scenes.



And now we have what is perhaps the ultimate abuse in tracking technology.  Thanks to explicit collusion among a growing number of websites, third parties, those same tracking third parties and analytics firms, are being allowed to receive a website's cookies, apparently without the website knowing or caring.  Our logged-in session authentication cookies are being received by third-party tracking entities with whom users have no relationship; and with whom they would surely refuse to share their logon session and various other possibly personal details if they were made aware of what the technology they are using was doing behind their backs.



But once again, end users have no idea.  They just use this, and they assume that people who do know are going to do something, that they're being protected by people who are going to be responsible.  This has been going on for years and has been growing slowly, and it needs to be fixed.  As with the original abuse of third party cookies, where all this began, it cannot be the responsibility of those who do not understand this to say no.  It's got to be those of us who do understand this to push back in every way possible.  So I am so glad that this research has shined a bright light on this next generation of tracking.  It needs to be shut down immediately.  But as I said, it takes those who are technologically savvy in the web industry to make it happen.  The sooner the better.



LEO:  Yeah.  It's amazing.  But I think that this is the cat-and-mouse battle between tracking companies and advertising companies and ad tech companies and users who just reasonably say "Don't track me, bro."  And they're going to pull out all the stops, including posing as a first-party site.



STEVE:  Yeah.  It's going to take legislation.  That's the only thing that can happen is that we just have to say, sorry, you just can't track people.  I mean, imagine right now...



LEO:  Well, awareness is good because the market can respond.  The market can, I mean, I want to know what these top 10 sites are so we can say something.



STEVE:  Yeah, 10%.



LEO:  Yeah.



STEVE:  Yeah.  So 1,000 of the top 10,000 sites are doing this.



LEO:  So if those are well-known sites, and I think they probably are, those names need to be revealed so that we can say something.  Because that's how you, you know, that's not okay.  They think they're getting away with it because nobody will ever notice.



STEVE:  Right.  Exactly. 



LEO:  Well, now we know, yeah.  Wow.  I'm glad I use NextDNS.  That's all I can say.  And uBlock Origin.



STEVE:  That would have been a good name for this podcast, Leo.  "Well, now we know."



LEO:  So now you know the rest of the story.



STEVE:  Now we know.



LEO:  That's pretty much every podcast with Steve Gibson.  It's a great informative thing, and I'm glad you're here to hear it.  And tell your friends; you know?  If they're smart enough to understand what we just said, anyway.  Some people maybe this would go [sound effect], but - most people.  That's the problem is this stuff is [crosstalk].



STEVE:  Yeah, we should mention NextDNS, I mean, because if your DNS, if the people you are sending those queries to are on the ball, then they're the ones that will be asking example.com for the value of this CNAME.  They will see that it is a domain that is a tracking domain, and they'll just say, oops, sorry.



LEO:  And it's my guess that if Quad9 and Cloudflare and the others don't already protect against this, they could, and I imagine they'd be implementing that pretty quickly.  I'm just pleased that this NextDNS.io, it's free for the first 300,000 queries.  But what happens is you get to that number pretty quickly because you put it on everything.  I have it - it's running on my network.



STEVE:  And god, in this day and age, 300,000 queries is like lunch.



LEO:  Goes like that.  So I buy it, but it's not, it's like two bucks a month or something.  It's fairly inexpensive.  And boy, is it well worth it.  It really - it does a whole lot more than that.  Lot of security stuff.  NextDNS.io.



Steve Gibson is at GRC.com, and that's where you'll find so many great things like this show:  16Kb audio versions for the bandwidth impaired; full human-written transcripts that are great to read along while you listen.  You can also use them for searching.  And of course 64Kb audio, all at GRC.com.  While you're there, pick up SpinRite.  Release 6 is current.  But as you can see, Steve's working pretty darn hard to get 6.1 out the door.  So buy v6 now, you'll get 6.1 free when it's available.  You'll also get to participate in the early testing and so forth.  So it's a good thing.  Everybody needs SpinRite.  ShieldsUP! there, lots of other stuff for free.  He's a very generous soul.  I have copies of the show, as well, or we do.  There is no "I" in TWiT.  Actually, there is.



STEVE:  But it's a lowercase "i."



LEO:  It's a lowercase "i."  It's just a humble "i," a little "i."  It's at TWiT.tv/sn.  That's where you'll find audio and video, too, actually.  There's also a YouTube channel you can watch dedicated to Security Now!.  What else?  You can subscribe in your favorite podcast application.  Simple enough.  And that way you'll get it the minute it's available of a Tuesday afternoon.



We do the show around 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  You can watch us stream it live, if you like to watch the behind-the-scenes chitchat at TWiT.tv/live.  Watching live, chat live at irc.twit.tv.  After the fact, our forums are at www.twit.community, no third-party tracking cookies involved, as far as I know.  I guess it's possible that - I'll check the CNAME real quick, just to make sure.  No, of course not.



And same thing with our Mastodon instance.  Everybody's saying, "Where's Steve?"  I said, "It took me years to get Steve to use Twitter.  Just relax, okay?  We'll move him over to Mastodon in time."  It's the federated open source version of Twitter.  Our Mastodon server that's a federated server is at TWiT.social and gives you access to all the other Mastodon servers, as well.  TWiT.social.  I'll see you in there.



Thank you, Steve.  Have a wonderful week.  I'm glad you got your second Fauci Ouchy.  We wouldn't want to lose you.



STEVE:  No, ready to go.  Bring it on.



LEO:  Good.  We'll see you next week on Security Now!.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#809

DATE:		March 9, 2021

TITLE:		Hafnium

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-809.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look into last week's critical Chrome update and also cover the wackiest-but-true Chrome extension of all time.  We look at Google's new funding of Linux security development; a surprisingly undead, long-unheard-from media player that just received a massive collection of updates; and, yes, still another way of abusing Intel's latest processor microarchitecture.  We need to update everyone on our Dependency Confusion topic from two weeks back because there's big news there.  We have several bits of identical listener feedback all wanting to be sure that I knew something had happened.  Then we're going to cover the world's latest global crisis which we first mentioned as breaking news in the middle of last week's podcast.  It was breaking then.  It's badly broken now. 



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  There's some fun stuff and some serious stuff.  We'll talk about a Chrome plugin that detects when you're eating chips, the return of one of the great Windows media players, and also a look at Microsoft's Hafnium exploit.  This is the one that's causing havoc in more than 60,000 Exchange users, and why you may not be as safe as you think.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 809, recorded Tuesday, March 9th, 2021:  Hafnium.



It's time for Security Now!, yes, time to protect you and your loved ones online, your privacy, your security, with this guy right here, the security commander-in-chief, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Good afternoon, my friend.



LEO:  Good to see you.



STEVE:  Today's podcast has a lot of stuff.



LEO:  Oh, no.



STEVE:  Actually, something that's kind of wonderful and wacky.  But also essentially what was breaking news last week, we interrupted the podcast to mention it, has become this week's global security crisis.



LEO:  Well, that's about par for the course, isn't it, yeah.



STEVE:  Yeah, it's about right.  So we're going to look into last week's critical Chrome update and also cover the wackiest but true - I had to do a double-take to make sure this was not April Fool's Day - Chrome extension of all time.  You're going to love it, Leo.  We're also going to take a look at  Google's new funding of a Linux security development and a surprisingly undead, long unheard-from media player.  When I saw this getting a bunch of updates, I thought, what?  That's still around?



LEO:  Does it really kick the llama's butt?  Or is it another one?  We'll find out.



STEVE:  We have yet another way of abusing Intel's latest processor microarchitectures.  We need to come back to our topic from two weeks ago, Dependency Confusion, because there's big news there.  And we have, interestingly, several bits of identical, virtually identical listener feedback which was all wanting to be sure that I knew of something that had happened.  Then we're going to cover, as I mentioned, the world's latest global crisis, following up on what was last week its breaking news.  So, yeah, Security Now!, 809 and counting.



LEO:  Oh, man.  I love this show, though.  I look forward to it every week because often I'll look at a story and go, I can't wait to hear what Steve has to say about that.  And that's what this show has become, really.  I think that's the motto.  Wait'll you hear what Steve has to say about that.  All right, Steve.  On we go.  Picture of the Week, I think; yes?



STEVE:  Yes, this is another one of those not exactly confidence-inspiring photos.  This one shows an NCR-brand ATM that the foreground dialog says "Welcome to Internet Explorer 8."



LEO:  Oh, no.  Oh, no.



STEVE:  And then, if you look real closely in the background, that's on top of something that says "To help protect your security, Internet Explorer has restricted this web page from running scripts or ActiveX objects," blah blah blah.



LEO:  Oh, oh.



STEVE:  So it's like, you know, folks, I get it that it's easy to develop things.



LEO:  A web interface, wow.



STEVE:  Oh, god.  Well, and that's not so bad.  But on, what is that, probably XP that IE8 is running on.



LEO:  Right, yeah.



STEVE:  And then of course it's online.  So apparently Microsoft said, oh, I think it's time to update your ATMs, wherever they are.  Oh, goodness.  It's just not the way to do this, no.



Okay.  As of last Tuesday, March 2nd, we're now at Chrome 89.0.4389.72.  This release included 47 security fixes, and a bunch of bug hunters earned themselves some nice income.  One researcher, I just sort of looked over the list of 47 different fixes.  And there was maybe half of them were to be determined, you know, $TBD.  But I saw one guy who was paid $10,000 for one, and $7,500 for another by Google.  And his third was listed as TBD.  But overall there were a collection of $10,000 awards, $7,500, a bunch of 5Ks and some 3Ks.



And it just seems to me that it's very clear, well, especially as today's podcast's topic will highlight, the computer industry is experiencing a growing, not a shrinking, problem, the problem of software that can be attacked.  So it's not like we're solving this problem and careers in bug hunting are going to be short-lived.  I think it's a growth industry.  So of course, and what's happened is, companies in the industry are realizing that by offering bounties to legitimate hackers who are able to find problems in their software, they're coming out ahead.  So of course it's not all happening in the light.  As we know, there are the likes of Zerodium, who are offering big money also to purchase other people's vulnerabilities, which they then turn around and resell to their shady clientele.



So I just want to say, again, that we're often touching now on issues where discoverers of problems are making a lot of money.  Some guy got paid $50,000 the other day for something.  It didn't quite make the cut for this week's news.  But I thought, wow, you know, I mean, to play, if you really enjoy computers, if you want to understand what's going on underneath, you do need some education in order to understand and to look at code in a way you haven't before.  But as I've often also lamented, it's not like bugs in products are being found and killed forever.  Microsoft is a constant churn of new stuff.  New means buggy, unfortunately.  Nothing is happening to reduce that.  So it's not like all the bugs have been found or are being found.  They're being created at a pace which is greater than that at which they're being found.



LEO:  Yeah, that's the metric I always kind of consider is I'm happy to see them fix old bugs.  So I'm always curious - we've got a Patch Tuesday today.  I'm always curious how many of those bugs are you're fixing old code?  How many of them were introduced in new code?  Because that's the stuff that you really - I don't want to see that.  That's not good.



STEVE:  Yeah, yeah.



LEO:  I'm glad they're fixing it, but...



STEVE:  Yes.  And actually it was Brian Krebs' research into the topic of today's podcast revealed something interesting about the Microsoft Exchange Server issue that we will be getting to that is chilling in a different way.  But all indication is that programmers are still in a hurry, still racing against deadlines, still shipping code before it's ready because we're still seeing patches in recently updated code.



So anyway, among those 47 vulnerabilities which were fixed last Tuesday was a zero-day that was being exploited the wild.  Google was informed of the issue last month on February 11th by Alison Huffman of Microsoft's Browser Vulnerability Research.  And of course since Microsoft is now also on the Chromium bandwagon, it makes sense that Microsoft would be finding a problem in the browser that they most care about and then let Google know.  And they fixed it with last week's Chrome update.  So it took a couple of weeks to go from being informed to being fixed.



And that also connects back into today's main topic.  I don't think I mentioned that the title of today's podcast is Hafnium, H-A-F-N-I-U-M, which is an element on the periodic table.  I don't know why Microsoft chose to name the attackers, the original attackers of Exchange Server the "Hafnium" group, but they did.  But one of the things we're going to talk about is some very disturbing news which has come to light about that.  Anyway, we'll get there.  First, Leo, this you're just not going to believe.  And before adding this to today's show, I had to really drill down and verify that it was true, and not an April Fool's posting.



LEO:  Oh, dear.



STEVE:  But it appears to be 100% legitimate.  And I learned this from BleepingComputer, who's very good about vetting their stories.  It is a Chrome browser web extension called Crispy Subtitles from Lay's.



LEO:  What?



STEVE:  Yes.



LEO:  Lay's Potato Chips?



STEVE:  Yeah, Lay's Potato Chips.  After this browser extension has been installed, anytime you are watching a YouTube video, and the system's AI-trained microphone detects the sound of crispy chips being eaten, YouTube captions will be automatically enabled to allow anyone, including yourself, to be able to obtain the video's dialog information over the sound of...



LEO:  Of the crunch?



STEVE:  ...those noisy chips being crunched.



LEO:  That's hysterical.



STEVE:  Yes.



LEO:  That's hysterical.



STEVE:  Lawrence Abrams at BleepingComputer explained that to make it easier to watch YouTube videos, the creative agency Happiness Saigon partnered with Frito Lay to create the Lay's Crispy Subtitles browser extension that automatically enables YouTube captions when it detects you are eating chips.  Lawrence says that to achieve this, Happiness Saigon trained an AI algorithm using 178 hours of recordings of people eating chips from all over the world.



Furthermore, he said that BleepingComputer used the extension and was pleasantly surprised by how the extension immediately enabled YouTube captions when their microphone picked up the noisy sound of chips being eaten.  He added that they had performed some tests with other food groups, including peanuts, carrots, and cereal.  While peanuts and carrots were not noisy enough or crunchy enough, eating cereal also enabled captions in their tests to see what would trigger the extension.  He concluded:  "Your results may vary, depending upon how noisy you eat your food."



LEO:  That's hysterical.  That is hysterical.



STEVE:  So, yeah, just, like, really, is this true?  If it were at the end of March...



LEO:  It's just good marketing.  It's marketing.  You know.



STEVE:  Yeah.



LEO:  I don't think many people will install it.  It's not malicious; right?  I mean, it's just - no.  Works as advertised.



STEVE:  No, no.  As far as we know, it's a legitimate app from Frito Lay to advertise, like now you can munch and crunch and not worry about having to turn the volume up or bothering anybody else.  You'll just get captions.



LEO:  That's very funny.



STEVE:  I mean, really.  This, Leo, this is why we have computer technology.



LEO:  Yes.



STEVE:  This was what it was all meant to do.  And speaking of Google doing good things for security, as they do, they also recently announced that they would be funding two Linux kernel developers' full-time efforts as maintainers exclusively focused on improving Linux security.



LEO:  Wow. That's awesome.  That's great.



STEVE:  It really is.  I just, you know, this is just a feel-good story.  But I thought, let's give them props for this because, yes, of course they're a heavy Linux user; right?  Because that's Android.  But still, everybody gains.  And when you stop to think about it, Linux, I mean, I'm still a FreeBSD Unix person.  But Linux is the open source alternative OS that has won that battle.  And we need it.  So the Linux Foundation said at this announcement:  "While there are thousands of Linux kernel developers, all of whom take security into consideration as the due course of their work, this contribution from Google to underwrite two full-time Linux security maintainers signals the important of security in the ongoing sustainability of open source software."  And of course we've often talked about...



LEO:  One of these guys is a mainstream kernel contributor anyway.



STEVE:  Yes. 



LEO:  Gustavo Silva has been doing this all along.



STEVE:  Yes.



LEO:  So really in effect what they're doing is saying, look, we're going to make these guys paid, instead of volunteers, paid.  And they can continue to do their work.  And they do really good work.  It's really fantastic.  Thank you, Google.



STEVE:  I completely agree.  So it's Gustavo Silva and Nathan Chancellor, the two kernel developers funded through this initiative.  They will now be able to exclusively focus on Linux kernel security development.  Chancellor will triage and fix bugs in the Clang/LLVM compilers.  Silva will turn to the elimination of several classes of buffer overflows and focus that as his full-time development work.  The Foundation noted that additionally, Gustavo Silva, as you said, Leo, is actively focusing on fixing bugs before they hit the mainline, while also proactively developing defense mechanisms that cut off whole classes of vulnerabilities.  He's constantly one of the top five most active kernel developers since 2017, and he has impacted 27 different stable trees going all the way back to Linux v3.16.



LEO:  That's great.  That's so great.



STEVE:  Yeah.  I just wanted to say yay for Google. Chancellor tweeted, he said:  "I'm very, very thankful that I can get paid to do something that I love.  Thank you to everyone at Google and the Linux Foundation who was able to make this happen, and I look forward to what this journey has in store for me."  So David Wheeler, the Linux Foundation's Director of Open Source Supply Chain Security - and lord knows the supply chain security, we're going to be coming back to that here in a minute, is so crucial.



He said:  "Ensuring the security of the Linux kernel is extremely important as it's a critical part of modern computing and infrastructure.  It requires us all to assist in any way we can to ensure that it is sustainably secure.  We extend a special thanks to Google for underwriting Gustavo and Nathan's Linux kernel security development work, along with a thank you to all the maintainers, developers, and organizations who have made the Linux kernel a collaborative global success."  So yay.



Okay, now, Leo.  I know this one is going to be, like, what?  Winamp.  



LEO:  Yes.



STEVE:  What?  It's still around?



LEO:  Yes.  It really kicks the llama's butt, yes.



STEVE:  Oh, my god.  Okay.



LEO:  It's been through a bunch of different owners.  I mean, I don't even know who owns it now.



STEVE:  I just - when I saw that, I thought, when was the last time anyone uttered the phrase "Winamp"?  So WACUP stands for the Winamp Community Update Project.



LEO:  Oh, there you go.  So it's a community thing now.  Good.



STEVE:  Yes.  Well, community, but that's sort of - meaning that it's not explicitly closed.  It seems to be one guy.  But they, it, recently released preview version 1.0.20.7170 to provide what I have to term, and there's a link here in the show notes, Leo, if you want to look at the list, an ungodly number of fixes and improvements to the venerable Winamp media player.  There is a page of just like oh, my goodness.  So this WACUP is a project by the ex-Winamp developer Darren Owen, which is aimed at fixing bugs and extending the Winamp version 5.66 media player functionality through the program's plugin feature.  Interestingly, for those who may not have been born when some of us were using Winamp...



LEO:  It came out in 1997, just to give you some idea.



STEVE:  Oh, Leo.  One of the player's strongest features was that it includes a plugin system which allowed, and you're still scrolling, third-party developers to extend...



LEO:  I'm going to be for a while.



STEVE:  Yeah, and modify the program's operation.  The plugins range from new visualization tools to equalizers and ways to change the media's playback.  I mean, I looked through, and they're talking about updating the security certificates and Wget and, like, all kinds of Internet connectivity stuff.  So I guess this thing will wash your car and polish your doughnuts at the same time. I mean, it just looks like...



LEO:  The guy, Justin Frankel, the guy who did it, who's kind of legendary, sold it to AOL, like 2005 or something.  So, and then Radionomy bought it.  I think what's happened is it's been kind of taken over by the community, I think.  I hope.



STEVE:  As you said, it used to be commercial software.  But apparently at some point it got leaked online.



LEO:  Ah, yeah, because this is a new version numbering.  It's starting over again at 1.0.  They were up to Winamp 6.



STEVE:  Right.  So for anyone who's interested, getwacup, G-E-T-W-A-C-U-P dot com.  That will get you this thing, and it brings along Winamp as part of its install.



LEO:  Interesting.



STEVE:  It is now freeware.  So if you're curious about the way your elders once listened to music, you can grab it at https://getwacup.com.



LEO:  It is definitely a trip down memory lane.  I hope it still has the visualizers and all of that.  They had some great visualizers.



STEVE:  Oh, actually I saw two screenshots.  It's beautiful looking, Leo.



LEO:  Yeah, yeah.



STEVE:  I mean, it's got like a multi-pane sort of integrated, I mean, yeah.



LEO:  I used Winamp to program the music for our New Year's Eve Party 1999 to 2000.  And I had a big screen projecting the visualizations because they were so gorgeous.



STEVE:  Yeah.  They had all kinds of 3D stuff.  And I guess one of the problems was that it would no longer run on contemporary OSes.



LEO: Oh, yeah, no.  That thing was... 



STEVE:  Because it was using APIs that, not quite Flash, but you get the idea.  And so this guy, apparently the plugin architecture is so strong that you can reach into the Winamp, the existing Winamp code and fix things, like it won't run on a 586 processor.



LEO:  Wow.  Using a plugin.  Wow.



STEVE:  Yeah, using a plugin.



LEO:  That's amazing.



STEVE:  So this brings it back to life.  So anyway, I know that among our listeners there will be some people who are like, Winamp, god.  I haven't thought about that for three decades.  So, yeah, that's about right.  And you can get it and play with it.



Okay.  We have yet another research paper, academic, describing a functional and, they claim, practical side-channel attack on the latest Intel processor microarchitectures.  And I will say it is brilliant work.  But then all of this fringe-y, like, Meltdown and Spectre stuff, it's all brilliant.  Right?  And it's worth noting, I think, if only to place it on the record so that it's like, if anything should happen we can say, yeah, we talked about it.  And also into its proper context, so that if someone tells you over drinks that, oh, the Intel chip has just collapsed again, you'll be able to say, uh, no.  Have another.  We're all fine.



So the work is by a trio of intrepid researchers from the University of Illinois at Urbana-Champaign, who will present their paper during the USENIX Security 2021 conference coming up later this year.  The paper is titled - and they couldn't resist because there actually is a thing called a Ring that we'll be talking about here in a minute.  So of course the paper is "Lord of the Rings."



LEO:  Don't get your hopes up.  It's not that "Lord of the Rings."



STEVE:  Yeah, yeah, right.  "Side-Channel Attacks on the CPU On-Chip Ring Interconnect Are Practical," the headline claims.  And so I'll just start by sharing their paper's short abstract.  They said:  "We introduce the first microarchitectural side-channel attacks that leverage contention on the CPU ring interconnect."  And I'll explain what that is in a second.



They said:  "There are two challenges that make it uniquely difficult to exploit this channel.  First, little is known about the ring interconnect's functioning and architecture."  Right, because it's an Intel proprietary secret.  They said:  "Second, information that can be learned by an attacker through ring contention is noisy by nature and has coarse spatial granularity."  Wouldn't you know.  "To address the first challenge, we perform a thorough reverse engineering of the sophisticated protocols that handle communication on the ring interconnect."



And I'll just pause to say this just boggles my mind, the idea that there are communication protocols on some sort of ring which is like IBM's Token Ring back in the day, which is a round robin communication bus which ties all of the little sub, you can't even see them they're so small, itty-bitty subsystems together on this piece of silicon.  I mean, the engineering of this is just so far beyond belief.  It's just amazing.



Anyway, they said:  "With this knowledge" - which they gained through reverse engineering of something nobody even knew was there - "we build a cross-core covert channel over the ring interconnect with a capacity of over 4 Mbps from a single thread, the largest to date for cross-core channel not relying on shared memory.  To address the second challenge" - that is, the noisiness and so forth, the lack of fine granularity - "we leverage the fine-grained temporal patterns of ring contention to infer a victim program's secrets.  We demonstrate our attack by extracting key bits from vulnerable EdDSA and RSA implementations" - in other words, they're extracting the jewels from another process, they said - "as well as inferring the precise timing of keystrokes typed by a victim user."



Okay.  So what is all this ring business that they're referring to?  It's not something that we've ever talked about before because who knew it was there?  Okay.  There is so much going on on today's microprocessors, more than we are typically aware of.  Research into side-channel information leakage due to the fundamental architecture of modern processor design has been, as we know, a big deal for the past few years, with a whole host of various attacks having at least theoretically been shown to create exploitable vulnerabilities.  And the result has been a bunch of Intel and AMD firmware updates.



So these were not nothing, although as far as we know, nobody actually was attacked using any of them.  But as Bruce Schneier famously said, attacks only get better, they never get worse.  This new attack leverages the bandwidth limitations and thus the access contention for a limited bandwidth commodity on Intel chips which results from individual modules vying for access to the so-called "interconnect ring."  The system on a chip ring interconnect is an on-die bus arranged in a ring topology which enables inter-component communication among the chip's various subsystems.  And here again, I'm standing back amazed that this crap even works.  It's like this is the extent that the engineers have had to go to to continue to squeeze the kind of performance that we need and expect these days out of silicon.  It is just nuts.



So in this context these things that are on the ring are known as agents generically, and include things like the chip's various processor cores; the last level cache, or LLC, as it's called; any graphics cores; and other chip-level subsystems.  Each of these ring agents communicates with the others through the ring, through what's called a "ring stop."  So the researchers reverse engineered Intel's proprietary and deliberately secret ring interconnect protocols to reveal the conditions under which two or more of these agents might be able to force a ring contention.  And that in turn allowed them to create a covert channel having a leakage capacity of 4.18 Mbps.  That is, they were able to leak information at that rate.



The researchers noted that this is the largest to date covert channel rate for cross-core channels not relying on shared memory.  One of the researchers said:  "Unlike prior attacks, our attacks do not rely on sharing memory, cache sets, core-private resources" - and a core-private resource, for example, would be branch history, which other attacks have leveraged in the past.  They said:  "As a consequence, they are hard to mitigate using existing 'domain isolation' techniques."



To implement an attack, an attacker would measure the delay in memory access associated with a malicious process due to a saturation of bandwidth capacity caused by a victim process's memory accesses.  So again, another sort of at-arm's-length inference attack, but this one across the chip rather than within a processor.  This is interprocessor and so-called LLC, this last layer cache.  They said the repeated latency in memory loads from LLC due to ring contention allows an attacker to use the measurements as a side-channel to leak cryptographic key bits from vulnerable EdDSA and RSA implementations, as well as reconstruct passwords by extracting the precise timing of keystrokes typed by a victim user.  To which I would argue, well, there are lots of easier ways to get keystroke timing than doing this.  But okay.



Now, the good news is Intel was not unduly upset or impressed by this.  I read their response, which was, yeah, okay.  So they built the ring and designed-in the handling for contention.  So Intel fully realized that this could be done.  And the weaponization of contention-based on-chip ring latencies is not something that is keeping Intel's microarchitectural engineers up at night.  Nor should it keep us up at night.  And as usual, the threat only presents in environments where malicious processes are arranging to share some silicon with naive processes containing secrets where those naive processes have poorly implemented cryptographic code, for example, doing non-constant time processes, where secrets are altering execution path in a way that changes timing.



So this is a case where, as the term is, defense-in-depth would help because, if you had constant in-time cryptographic protocols, then there isn't anything to get leaked.  And if any of our personal workstations have a malicious process loose that has an interest in doing this, then we already have bigger problems than some theoretical, extremely difficult to leverage cross-core leakage.  But it's a paper.  It exists.  It demonstrates, first of all, it highlights an aspect of processor microarchitecture I had no idea was even there, which just blows my mind.  But again, it's not the end of the world.  It turns out the end of the world keeps coming to us way up at the actual software mistake problem.  And that's where we're going to go looking at what I called "Dependency Contusion."



LEO:  All yours.



STEVE:  Okay.  So our podcast two weeks ago was titled "Dependency Confusion."  Yeah.  And we need to spend some more time on this issue because this is really bad.  And after explaining what dependency confusion was all about, and noting that this is currently a fundamental design weakness and readily exploitable flaw within the industry's package managers and project build logic used pervasively throughout the industry, it was clear that this was going to be a large problem for quite some time.  And that unfortunate expectation is being realized quickly.



So stated as briefly as possible, dependency confusion amounts to a by-design backdoor into the internal build servers and private code repositories of a vast number of software publishers large and small.  The U.K. firm Sonatype first blogged about their findings from their security instrumentation last Monday.  So that was like the 1st of March.  Their post was titled "Newly Identified Dependency Confusion Packages Target Amazon, Zillow, and Slack;" and they said, "Go Beyond Just Bug Bounties."



They wrote:  "Sonatype has identified new 'dependency confusion' packages published to the npm ecosystem that are malicious in nature.  These squatted packages are named after repositories, namespaces, or components used by popular companies such as Amazon, Zillow, Lyft, and Slack.  As previously reported by Sonatype, Alex Birsan's dependency confusion research" - and that's what we talked about two weeks ago - "disclosure led to copycat researchers publishing 275-plus identical packages to the npm repo within 48 hours, in hopes of scoring bug bounties.  The number then jumped to over 550 within the next few days.



"As of today, Sonatype's automated malware detection systems, part of Nexus Intelligence" - which is their proprietary technology - "has since identified well over 700 npm copycat packages based on Birsan's proof of concept.  Although ethical hacking for bug bounties and spreading security awareness has its place and is even welcomed by the community as it keeps us all more secure, the copycat packages recently identified by Sonatype unfortunately crosses the line of what is deemed ethical."



So that was Monday.  Two days later, their follow-up posting was titled "PyPI and npm Flooded With Over 5,000 Dependency Confusion Copycats."  So this has predictably morphed almost overnight into an industry-wide siege on the software industry's use of third-party packaged libraries.  And Sonatype notes that these are not all just white hats hoping to score a bounty.



They wrote:  "As soon as these packages are installed automatically, because they share a name with an internal dependency, therefore exploiting dependency confusion, they exfiltrate the user's .bash_history file and etc/shadow directory, and in some cases spawn a reverse shell.  The etc/shadow file," they note, "is a successor to the etc/passwd Linux file that maintains hash-based password data of user accounts on a system."  So these are no longer benign.



The exfiltration goes well beyond bug bounties at this point.  The original discoverer and publisher of this disaster, of course, Alex Birsan, whose work we described two weeks ago, was extremely careful not to do anything that could be construed as malicious.  He understood that if he posted confusing dependencies that would confuse the dependency managers, he would be executing code on somebody else's systems.  And so he deliberately used simple DNS queries as a means of indicating the success of that probe.  The fact that it's extremely difficult NOT to use this for malicious purposes demonstrates just how easy it is TO use it for malicious purposes.



And despite being warned about this by Alex's original work, remember that Microsoft was one of the companies he said, "Microsoft, you want to go look over here because unfortunately your servers are sending DNS queries to mine, meaning that you have picked up external code and are running it."  In a follow-up experiment, Microsoft Teams was deeply penetrated.  Last Thursday, Matt Austin, the Director of Security Research at Contrast Security, described his successful use of dependency confusion against Microsoft.  This is enough of a problem that I think it's worth sharing a bit of Matt's description just to drive his point home. 



So here's part of what he wrote.  He said:  "Dependency confusion involves the creation of packages on third-party libraries that have identical names to packages stored in a company's internal repository.  The goal is to trick developers and automated systems into using the wrong library because of defaults configured into package managers that show a preference for external libraries over internal ones."



He says:  "So while it should be difficult for external users, whether bad actors, legitimate developers, or security researchers, to even find the names of packages stored in internal repositories, Birsan was able to find the names of these packages in the applications themselves, and was able to replicate that accomplishment over at least 35 applications.  Since Birsan's research was published, multiple reports of bad actors using the technique have started to appear.  In addition, other security researchers," he said, "including myself, began exploring various software-as-a-service-based applications to see whether we could find dependency confusion vulnerabilities that could be exploited by attackers.



"A member of the Contrast Labs team," he said, and he meant as a member of the Contrast Labs team, "I specialize in security research on applications created with the Electron framework, including Microsoft Teams.  Previously, I've discovered and reported several remote code execution vulnerabilities in that application.  Given my background, I decided to contribute to the effort by examining Teams to see if I could identify a dependency confusion vulnerability."



He wrote:  "I began by looking at the dependencies used by the Teams desktop application.  In one section of the application, I saw a Node.js package called 'Optional Dependencies.'"  He said:  "Typically, the intent of optional dependencies is to provide a place to store binary files that are a part of the testing suite, but not the production application.  The interesting thing about optional dependencies is that, if they do not exist in the repository from which a developer is trying to pull them, the build will fail silently.  Thus developers must write code that is relatively defensive when optional dependencies exist.  Specifically, one cannot 'depend' upon a dependency that is optional."



He says:  "Inside the Teams desktop application is a package file that lists the dependencies that the application needed in order to be built" - again, inside the Teams desktop application, meaning what the world has installed on their desktops, I think it's 150 million instances - "is a package file that lists the dependencies that the application needed in order to be built.  When one downloads and installs the application, it does not reach out to the dependency managers.  This is because every part of the application is built on a Microsoft server somewhere, after which it is shipped to customers."



But the point is this still was a massive important information leakage.  I have in the show notes a picture from his posting which shows the package.json and the "optionalDependencies" JSON information with the names of the dependencies and their version numbers, just right out there.  That was in the desktop application.



So he says:  "Now back to what I discovered.  When analyzing the package, I noted a number of modules in both public and private repositories.  I also saw that some of the private packages were not taking advantage of the scoping capability provided by npm."  In other words, making sure they were scoped locally so that they would not be scoped globally.  He said:  "I noted that some of the optional dependencies did not exist on disk inside the package itself.  This means that during the build process those dependencies would not be found in any repository, public or private.  By design, these optional dependencies failed silently whenever the application attempted to pull them from both public and private repositories.



"I then selected one of the modules that was listed as an 'optional dependency' and registered it on npm, setting the version to 0.0.1.  I added a simple line of code in the install script of the package to alert me when it was installed.  Once I was ready to deploy, I set the version of the module to match the version number from the application.  At this point, I had two choices:  bump the version number up by one and wait for Microsoft to update and pull in the new version, or keep it at the current version and hope that a build server would pull in a fresh copy of it," and he says, "(not using packagelock.json)."



He says:  "There are risks either way, but I decided to do what would be the least impactful, keeping the version number the same.  As soon as I set one of the dependencies to a high enough version, I started getting requests from the module being installed from a number of internal Microsoft IP addresses.  The name of the module was relatively generic, but it was Microsoft-specific and not an overly common word."



He says:  "I happened to be doing this research late at night.  Based on that and other factors, I deduced that the responses were most likely from internal, automated resources within Microsoft that were pulling the dependencies and installing them, perhaps an automated continuous integration/continuous deployment server.  But it could also have been a live developer working a late shift in the U.S. or a daytime shift somewhere overseas.



"Whether the responses I saw were automated or manual, the fact that I was able to generate this reaction poses significant risk.  By taking advantage of the post-install script, I was able to execute code in whatever environment this was being installed on.  If attackers were to execute code the way I did on a build server for a desktop application update that was about to be distributed, they could insert anything they wanted into that update, and that code would go out to every desktop using Teams, more than 115 million machines.  Such an attack could have monumental repercussions, potentially affecting as many organizations as the massive attack on the SolarWinds software factory that was revealed in December."  And I would argue significantly bigger than that.



So I wanted to drive home the point that this will not be easy to fix, and that it is going to be a source of immense long-running pain for the entire industry.  This is similar to the first time someone observed that a deliberate buffer overflow could be abused to execute attacker-supplied code on the stack.  Today, everyone knows it.  But there was a time when that had never occurred to anyone.  And this is like that.  Look at what an enduring problem buffer overflows have been.  I would argue this is no less significant.  A lazy and thoughtless approach to package dependency management has pervaded the entire software industry.  It is already everywhere.  And it's going to take a lot of work to pull all of it out by the roots.



So the abuse of this has exploded since we talked about it for the first time two weeks ago.  Basically, anything a developer tries who's wearing a white hat succeeds because these insecurities have been built into the architecture without giving thought to how they could be abused.  It has to be the case that right now there are dependency problems of this kind, these sorts of confusions, which are installing malicious code in packages.  And we don't know it yet.



So anyway, I mean, whereas what we're going to be talking about is our main topic in a minute is a huge, obvious, in your face crisis, this one is far more insidious.  And I don't know how it will be that we'll tie back future exploits to this having been the way.  But if any of them are sufficiently big, then enough people apply forensics, we're going to end up figuring out that, yup, this came from a dependency confusion, where some bad guy simply registered a funky-named package on npm or PyPI or any of the other public repositories.  It got sucked into some random but important company's build, and then they shipped this thing out to everybody.  It's breathtaking essentially in the leverage that this creates, which is why this is such a problem.



And here's Microsoft.  This is months downstream of when they were first informed of this.  And, whoops, you know, caught them again, even though they well knew.  That's my point is that this thing, it's hiding, unless you look.  And how many companies out there aren't following the latest security news?  They're just busy getting their work done and, oh, you know, what was that?  Well, we'll think about that later.  Meanwhile, their build system is pulling malicious code in and replacing their internal package with something, and out it goes to their customers.  It can't be overstated.



Okay.  In happy news, Aaron Wood tweeted from @The_Real_Abear.  He said:  "@SGgrc Microsoft Edge has native vertical tabs now, and they're awesome."  Chris Ryan:  "I don't know if you saw this @SGgrc, but MS Edge has vertical tabs native."  Robert Osorio said:  "@SGgrc Side tabs a la Tree Style in Edge coming this month."  And indeed, yes.  Even my Edge that I fired up last night finally has that little widget that we've seen screen shots of in the upper left-hand corner.  And when you click it, it instantly toggles between vertical and horizontal-oriented tabs.  And I checked.  It remembers the last setting it was in.  So once properly set to the way man clearly intended all tabs to be arranged, it happily remains correct from then on.



So a shout-out and thanks to all our listeners who made sure that I knew.  Really, it's beautiful.  And so we have a Chromium-based browser which has been pushed onto us by Microsoft, so it's there, for which the tabs can now be made correct.  So yay.  Be interesting to see whether Google realizes that, oh, maybe we should do that, too.  That would be great, if Chrome ended up doing the same thing.



LEO:  All right.  Hafnium.  Let's talk about it.



STEVE:  So, yeah.  Our picture at the top of this is "Emergency Directive 21-02:  Mitigate Microsoft Exchange On-Premises Product Vulnerabilities," which was from CISA, our Cybersecurity and Infrastructure Security Agency.  One week ago, during last week's podcast, we interrupted the podcast to share the breaking news at the time of Microsoft's emergency release of updates to patch four separate pre-authentication remote code execution, that is to say, pre-auth RCE exploits, affecting their widely popular Exchange Server 2013, 2016, and 2019.  It also turns out that 2010 was similarly affected, although it's out of patch cycle.  However, this is bad enough, they ended up giving anyone who's still using Exchange Server 2010 a freebie in order to fix this because this is so crucial.



Since last week this has exploded into another, as if we needed another, truly global crisis of epic proportion.  Today, we know that as many as hundreds of thousands of individual Exchange Servers have been under quiet attack since, get this, the beginning of January.  So not just for a week, but for two months before any alarm was raised.  To give a sense for the impact of this, this past Saturday Bloomberg News posted their coverage of this beginning with the headline:  "Microsoft Attack Blamed on China Morphs Into Global Crisis."  And then they had two subheads:  "Number of victims of Chinese attack continues to grow rapidly," and "White House warns companies to take threat very seriously."



Bloomberg's coverage begins:  "A sophisticated attack on Microsoft Corp.'s widely used business email software is morphing into a global cybersecurity crisis, as hackers race to infect as many victims as possible before companies can secure their computer systems.  The attack, which Microsoft has said started with a Chinese government-backed hacking group, has so far claimed at least 60,000 known victims globally, according to a former senior U.S. official with knowledge of the investigation.  Many of them appear to be small or medium-sized businesses caught in a wide net the attackers cast as Microsoft worked to shut down the hack."



Later in their article, Bloomberg wrote:  "The Chinese hacking group, which Microsoft calls Hafnium, appears to have been breaking into private and government computer networks through the company's popular Exchange email software for a number of months, initially targeting only a small number of victims, according to Steven Adair, head of the northern Virginia-based Volexity.  The cybersecurity company helped Microsoft identify the flaws being used by the hackers for which the software giant issued a fix on Tuesday."



Okay, now, the truth is Volexity was the discoverer - well, a discoverer, I'll explain how this is a little more complicated than we thought - a discoverer of this whole mess, so we'll switch over to Volexity in a moment.  But Bloomberg quoted Charles Carmakal, a senior VP at FireEye, as saying:  "The good guys are getting tired."  Which I thought was such a sad statement of today's state of affairs.  We're still dealing with the aftermath of the SolarWinds breach, and now we have this.



And what's interesting is that the attack rate followed that discovery-and-patch model we've often talked about here.  Bloomberg wrote:  "Initially, the Chinese hackers appeared to be targeting high-value intelligence targets in the U.S.," meaning surreptitiously, specifically, not blasting, not mass.  This was a secret, and they were using their secret for targeted penetration.  Bloomberg says:  "Then, about a week ago, everything changed.  Other unidentified hacking groups began hitting thousands of victims over a short period, inserting hidden software to give them access later."



And that's one of the keys here is it turns out this thing has just been a web shell-o-rama.  Volexity's Steve Adair said:  "They went to town and started doing mass exploitation - indiscriminate attacks compromising Exchange Servers, literally around the world, with no regard to purpose or size or industry.  They were hitting any and every server they could."  And of course this is the attacker rationale that we've noted in the past.  So long as exploits remain unknown, the attackers' optimal strategy is quiet, stealthful, surgical abuse, surgical strikes.  Since discovery will happen sooner or later, there will always be time to switch to mass exploitation mode.  So set up for mass exploitation so that you are ready when that time comes.  But until then, carefully target the highest value victims that will remain unaware of what you're doing.



So it turns out that stealth mode had been underway for two months.  And at this point, lord only knows how many high-value victims were compromised.  Remember, we're talking about Exchange Server from 2010, so the last 11 years of Exchange Server.  Anybody with Exchange Server will have 2010, 2013, 2016, or 2019.  So damage has been done.  Then the instant Microsoft went public with patches, the secret was out.  The jig was up.  So now the optimal strategy became to exploit as many systems as fast as possible, including implanting persistent backdoors, before those systems could have the newly available patches applied.  And that's what happened.



Last Saturday the 6th, Kevin Beaumont, who is now with Microsoft, tweeted from his @GossieTheDog account.  He said:  "A single server in the MailPot honeypot has been exploited with these vulnerabilities five times today, as a data point."  He said:  "So far nobody has actually done anything with those web shells, just planted them."  So there is a honeypot system called MailPot which is sitting there, five exploits in one day, installing web shells into the honeypot.  So the primary takeaway is that patching after the announcement was almost certainly closing the barn door after the horses had left.  The mass automated exploitation that exploded early last week was a race to install web shell backdoors into every available still-vulnerable server before those patches could be applied.



So any admins who think, whew, glad we're okay now, everything looks fine, are probably fooling themselves.  Everything will look fine, but might not be.  And coincidentally, we were just talking in detail about web shells, about how they leverage a website's scripting engines against themselves, how trivial they are to design and implant, yet how diabolical they can be once they're in place.  They turn any web server into a slave by equipping it with a new set of command-following capabilities of the attacker's design.  And they hide among any website's gazillion other mystery files.  Nobody knows what all that crap is in today's high-end web server system.  There's just tons of stuff there.  And that's exactly what the mass exploitation effort was rapidly implanting into every available Exchange Server were web shells.



And so what does one of the early discoverers of this latest nightmare explain?  Steve Adair, Volexity's President, said:  "We've worked on dozens of cases so far where web shells were put on the victim system back at the end of February, on February 28th, before Microsoft announced its patches, all the way up to today."  He said:  "Even if you patched the same day Microsoft published its patches, there's still a high chance there is a web shell on your server.  If you're running Exchange and you haven't patched this yet, there's a very high chance that your organization is already compromised."



I just identified Volexity and Steven Adair as "one of" the early discoverers.  Here, amid what is now being called a "global crisis," we learn that, believe it or not, Microsoft was credibly informed of these threats by three independent researchers as far back as early January, Leo.



LEO:  And they just ignored it?



STEVE:  Yes.  The second and third reports being of detected use of these vulnerabilities in the wild.  Yet Microsoft apparently felt no great urgency to act on the world's behalf.  On January 5th, a researcher tweeting as Orange Tsai posted:  "Just report a pre-auth RCE chain to the vendor.  This might be the most serious RCE I have ever reported!  Hope there is no bug collision or duplicate."  Meaning he hoped for a reward.



After everything went public, and the you-know-what has hit the fan, Orange Tsai, who is a member of DEVCORE, has taken their ProxyLogon disclosure site public.  It's https://proxylogon.com.  And even Microsoft named the script for detecting the vulnerability ProxyLogon.  Microsoft has adopted that name because these were the first people who told them.  I have in the show notes the timeline, and I'll give you a sense for this.  October 1st of 2020, they said  DEVCORE started reviewing the security on Microsoft Exchange Server.  On December 10th of last year DEVCORE discovered the first pre-auth proxy bug, which now has a CVE.



On the 27th of December, so two days after last Christmas, DEVCORE escalated the first bug to an authentication bypass to become admin.  In other words, they're now building a chain.  On the 30th of December, DEVCORE discovered the second post-auth arbitrary file write bug, another CVE.  On the 31st, New Year's Eve, last New Year's Eve, DEVCORE chained all bugs together to a workable pre-auth RCE exploit.  On January 5th, 2021, DEVCORE sent at 18:41 GMT+8 the advisory and exploit to Microsoft through the MSRC portal directly.  The next day, on January 6th, MSRC acknowledged the pre-auth proxy bug, MSRC case 62899.  Same day MSRC acknowledged the post-auth arbitrary write bug, MSRC case 63835.



Two days later, on January 8th, MSRC confirmed the reported behavior.  On January 11th, DEVCORE attached a 120-day public disclosure deadline to MSRC and checked for bug collision.  Again, they're looking for bounties; and, lord, do they deserve some.  January 12th, MSRC flagged the intended deadline and confirmed no collision at the time.  In other words, these guys were the first people to report this.  Microsoft had no awareness of it before.  Now, on January 5th, acknowledged the day after, on the 6th, and confirmed the behavior on January 8th that this thing was real.



Now we lose a month.  It's February 2nd.  DEVCORE checked for an update.  On the February 2nd, Microsoft replied:  "They are splitting up different aspects for review individually and got at least one fix which should meet our deadline."  Of 120 days.  Four months for this?  Okay.  February 12th, MSRC asked the title for acknowledgements and whether we will publish a blog.  On February 13th, DEVCORE confirmed to publish a blog and said will postpone the technique details for two weeks, and will publish an easy-to-understand advisory, without technical details, instead.  Anyway, it goes on like that.



So what is difficult is that this - I don't know, I guess Microsoft just assumed, okay, not good, but these guys are going to keep it a secret, so we'll just move this through our regular process.  I mentioned three independent researchers.  DEVCORE began their analysis of Exchange Server on October 1st, and as I said, found the first of several remotely exploitable problems on December 10th.  Independently, in Reston, Virginia, Volexity discovered attacks using these flaws on January 6th, also the beginning of January.  They watched and characterized it, and officially informed Microsoft about it on February 2nd.



Again, on the 6th they discovered attacks using the flaws.  Meaning that this was already, at the beginning of January, in parallel with DEVCORE finding it from a static analysis of Exchange Server, Volexity found this in the wild at the beginning of January.  Microsoft knew about it at the beginning of February, that this was not - didn't matter that this was being kept secret by DEVCORE under their agreement.  It was in the wild at the beginning of February.  And then a third research group, the Danish security firm Dubex, says it first saw their clients being hit on January 18th, and they reported their incident response findings to Microsoft on January 27th, before Volexity did.



So Microsoft had multiple confirmations of in-the-wild zero-day attack of these exploits on Exchange Server by the end of January and knew about it with a full disclosure and reproducibility from DEVCORE at the beginning of January.  This was arguably a five-alarm, easy-to-exploit.  Microsoft's own disclosure says these are easy to do.  These are not like hard to get out of the lab and actually leverage.  They said these are easy pre-authentication attacks, remote code execution attacks against Exchange Server.  And they did not act.



The only way I can explain it is that perhaps they were hoping to bury these, what clearly were critical, zero-day, in the wild, being exploited against targets' vulnerabilities of Exchange Server that everybody uses.  Maybe they hoped to bury them in a Patch Tuesday.  They didn't make it into February's Patch Tuesday.  There was a comment they made saying, I saw, that they were hoping to get them into March's Patch Tuesday.  Which, by the way, is today.  And maybe they hoped nobody would notice.  I don't know.  Anyway...  



LEO:  Is it possible that the fix was difficult, like they started in early January, and it just took them that long?  Maybe they didn't, you know, they were doing their best, maybe.



STEVE:  Maybe.  And recall which servers were patched.  Brian Krebs, in his post-mortem construction of a timeline, made an interesting and chilling observation.  Brian wrote:  "On March 2nd, Microsoft patched four flaws in Exchange Server 2013 through 2019.  Exchange Server 2010 is no longer supported, but the software giant made a 'defense in depth' exception and gave Server 2010 users a freebie patch, too."  He wrote:  "That means the vulnerabilities the attackers exploited have been in Microsoft Exchange Server's code base for more than 10 years."  



LEO:  God.



STEVE:  Yeah.  Volexity has a fully detailed write-up with indicators of compromise, the IP addresses to which data was being exfiltrated and so on.  But they begin with a short narrative that I think our listeners will find interesting.  This is like, from the field, this is how it happened.  They wrote:  "In January 2021, through its Network Security Monitoring service, Volexity detected anomalous activity from two of its customers' Microsoft Exchange servers.  Volexity identified a large amount of data being sent to IP addresses it believed were not tied to legitimate users.  A closer inspection of the IIS logs from the Exchange servers revealed rather alarming results.



"The logs showed inbound POST requests to valid files associated with images, JavaScript, cascading style sheets, and fonts used by Outlook Web Access.  It was initially suspected the servers might be backdoored, and that web shells were being executed through a malicious HTTP module or ISAPI filter.  As a result, Volexity started its incident response efforts and acquired system memory (RAM) and other disk artifacts to initiate a forensics investigation.  This investigation revealed that the servers were not backdoored and uncovered a zero-day exploit being used in the wild.



"Through its analysis of system memory, Volexity determined the attacker was exploiting a zero-day server-side request forgery (SSRF) vulnerability in Microsoft Exchange.  The attacker was using the vulnerability to steal the full contents of several user mailboxes.  This vulnerability is remotely exploitable and does not require authentication of any kind, nor does it require any special knowledge or access to a target environment.  The attacker only needs to know the server running Exchange and the account from which they wish to extract email."  And in fact some of the early reporting said that this was being used against government and major industry players to suck the private email out of many sensitive accounts.



They go on:  "Additionally, Volexity is providing alternate mitigations that may be used by defenders to assist in securing their Microsoft Exchange instances.  This vulnerability has been confirmed to exist within the latest version of Exchange 2016 on a fully patched Windows Server 2016 server.  Volexity also confirmed the vulnerability exists in Exchange 2019, but has not tested against a fully patched version, although it believes they are vulnerable.  It should also be noted that this vulnerability does not appear to impact Office 365."



Then they end, saying:  "Following the discovery of the CVE that was assigned, Volexity continued to monitor the threat actor and work with additional impacted organizations.  During the course of multiple incident response efforts, Volexity identified that the attacker had managed to chain the SSRF vulnerability with another that allows remote code execution on the targeted Exchange servers.  In all cases of remote code execution, Volexity has observed the attacker writing web shells (ASPX files) to disk and conducting further operations to dump credentials, add user accounts, steal copies of Active Directory database, and move laterally to other systems environments."  In other words, again, as I said, a five-alarm catastrophe.



Now, I don't know, it's difficult not to hold Microsoft responsible for what appears to be a sluggish response to a very clear and present, massively widespread, critical danger to every one of their users of Exchange Server.  Again, you scan the Internet, and you find something listening on port 445 and check to see if it's Exchange.  If so, welcome.  So yeah, you know, Microsoft is big.  But we often see other big companies like Apple and Google responding in days, and even sometimes in hours.  This took Microsoft months, with the foreseeable result that a phenomenal number of organizations are now likely compromised, and with no idea that they have been.



LEO:  Yeah, that's the problem.



STEVE:  Yes.  Even if they've patched, their Exchange Servers are now likely to be hosting a dormant backdoor web shell.  BleepingComputer also has coverage as of last Sunday of Microsoft's just-updated-for-this-nightmare, standalone MSERT server scanner.  Oh, and I should mention - I skipped over it, I think, or maybe it didn't make it into my notes.  Brian Krebs did elicit from Microsoft an acknowledgment that they knew of this in early January.  So that's there.



Anyway, GRC's shortcut of the week is a link to Microsoft's MSERT server scanner, which has been updated to detect any of seven web shells that might now be present on a compromised Exchange Server.  You can download it either for 32- or 64-bit machines.  So the link to its home page is here in the show notes.  And it's also, as I said, our shortcut, grc.sc/809, which of course is this episode number.  That will bounce you to this scanner, which you can run, and definitely want to, on anything hosting what was a previously publicly exposed instance of Exchange Server.



And note that the scanner will only run for 10 days after it's been downloaded, to assure that older releases don't stay trusted.  You can always grab an update, either by using this week's short cut, 809, grc.sc/809, or by bookmarking the redirected page once you follow this week's shortcut.  And then you'll want to get the latest whenever you're going to want to run a scan.



And Leo, as if all of this wasn't bad enough, I have a very important note about the likely failure of manually installed Exchange Server patches.



LEO:  Oh.  Oh.  Oh.



STEVE:  If the updates are not run as an administrator, and it's very easy to download them and double-click them and just run them, believe it or not the patching will fail silently, providing no warning feedback and leaving the system unpatched and unprotected, even though you think you just installed the patches.  Microsoft said that the installer will not display any errors or messages to let you know that the Exchange security updates have not been installed correctly.



They wrote:  "This issue occurs on servers that are using User Account Control.  The issue occurs because the security update doesn't correctly stop certain Exchange-related services."  And as we know, if you don't stop the service, you can't replace it because it's in use.  To work around this known issue, Microsoft recommends installing the security updates as an administrator.  So if anyone here might not have done that last week, you'll want to double check.  Right-click on the update, and then choose Run as Administrator.  You'll then get the dark screen, UAC intercept, say yes, and then these updates will properly install.



I also have a link down near at the end of the show notes to Microsoft's page titled "Repair failed installations of Exchange Cumulative and Security Updates," which was updated yesterday.  They write:  "This article describes the methods to verify the installation of Microsoft Exchange Server Cumulative Updates (CUs) and Security Updates (SUs) on your servers, lists known issues that you might encounter when installing CUs and SUs, and provides resolutions to fix the issues."  So the page provides links to scripts that can be used to check for indicators of compromise and also instructions for verifying the installation of these CUs and SUs.



So they said:  "Use the following script which automates testing for all four vulnerabilities described in the Microsoft Threat Intelligence Center (MSTIC) blog post.  The script provides a progress bar and performance tweaks to make the test for CVE-2021-26855 test run fast.  Download the latest version of the script from the Exchange Support GitHub repository."  And I have the link, as I said, at the bottom of the show notes.



So anyone involved with Exchange Server, absolutely make sure that the fixes were installed correctly.  Don't assume that because you responded quickly, something may not have had a chance to get in there and get up to some mischief on your server beforehand, and definitely check to make sure that the backdoor - I am tempted to call it a front door - has been closed.  And also, if you can, that you didn't pick up an unwanted passenger on your server.  What a mess, Leo.



LEO:  Yeah.



STEVE:  And again, at least 60,000, probably more.  Thousands of Exchange Servers.



LEO:  Compromised.  Compromised.



STEVE:  Compromised.  Yes, compromised.



LEO:  Yeah, that's amazing.  A lot of people use Outlook Web Access.  It's very popular.  Oh, well.  What can you say?  And I hope Microsoft has a good reason for not fixing it faster.  I'm sure we'll talk about this tomorrow.



STEVE:  Had they gotten it out a month before, far, far less damage would have been done.



LEO:  Next week, FLoC.



STEVE:  Yes, we're going to talk about FLoC next week, unless something even more insane happens.  FLoC is the worst abbreviation, and in fact the worst abbreviation for the worst name:  Federated Learning of Cohorts.



LEO:  It sounds like Borat.



STEVE:  It's awful.



LEO:  It's terrible.  And it may be a terrible technology.  The EFF is very negative about it.



STEVE:  Oh, boy, are they not happy about this.  Anyway, this is Google's plan to replace third-party tracking cookies with something else.  So we'll do a full dive on that.



LEO:  Good, good.



STEVE:  Next week.



LEO:  I need to understand it better to understand if it's an issue or not.  Steve, thank you, as always.  Steve Gibson is at GRC.com.  That's his website.  You'll find this show there, 16Kb versions for the bandwidth impaired, 64Kb for those who like full-fledged audio.  There's also transcripts.  You know, the other day I was searching for something, and the transcript popped right up, which was great because I could go right into it, see what I was looking for, and jump to that part of the podcast.  Really saves a lot of time.  Thank you, Steve, for doing that.  That's all at GRC.com.



While you're there, pick up SpinRite, the world's best hard drive maintenance and recovery utility.  It's Steve's bread and butter.  You can get v6 now and be in line for 6.1, a free upgrade, the minute it comes out.  You can also participate in the beta testing.  You can also leave messages for Steve at GRC.com/feedback.  There's also other free stuff there, too.  It's a lot of fun.  Save an afternoon to go visit.



You can get the show at our site, too, TWiT.tv/sn for Security Now!.  There's audio here, and video, as well.  Download the format you like.  If you want to watch us do it live, it's every  Tuesday, right after MacBreak Weekly.  That should be, usually is, 1:30 Pacific, 4:30 Eastern.  And because we're going to Daylight Savings Time on Sunday, next week's show, we're springing forward, so it'll be an hour earlier if you don't move.  I guess the easiest thing to say is it's 20:30 UTC, and you can just figure out what that'll be based on your time zone.  So just a note, we will apparently move next week.  Although from our point of view we're exactly where we started.  And that's the magic of setting the clocks forward.



Watch it live at TWiT.tv/live, or listen live.  Chat live at irc.twit.tv.  After the fact, you can chat with us at TWiT.community.  That's our forum.  We have a TWiT.social as our Mastodon instance.  It's kind of like Twitter only open source and federated.  And of course the best way to get the show would be subscribe in your favorite podcast player.  That way you can get it the minute it's available, after we finish up on Tuesday afternoon.  Steve, have a great week.



STEVE:  Thank you, buddy.



LEO:  Go enjoy your first meal out in a year.



STEVE:  Oh.  



LEO:  He's very excited about that.  And we'll see you all next time on Windows Weekly.  Bye-bye.  Windows Weekly?  Security Now!.  Security Now!.



STEVE:  Angel hair capellini in an extra garlic white clam sauce.  It's like, oh.



LEO:  Oh, man.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#810

DATE:		March 16, 2021

TITLE:		ProxyLogon

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-810.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we start off with a bunch of interesting browser-related news, zero-days, updates, a browser-based PoC for Spectre, a zero-script tracking kludge, and a look at last Tuesday's Patch Tuesday, what it fixed and what it broke.  Some wonderful news for the Open Source community, a bit of miscellany, some listener feedback, and a screenshot of the final replacement for SpinRite's "Discovering System's Mass Storage Devices..." screen.  Then we revisit the Microsoft Exchange disaster, another week downstream and still drowning.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Lots to talk about.  Another zero-day in Chrome.  Google's patching it, of course.  Another browser side-channel tracking attack that uses no JavaScript.  Steve explains how you can do it in CSS.  We'll also talk about ProxyLogon.  That's the Exchange server hack.  You won't believe how many computers have been compromised.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 810, recorded Tuesday, March 16th, 2021:  ProxyLogon.



It's time for Security Now!, the show where we cover the latest on security and privacy and how things work with this guy right here, Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hello, Leo.  And sometimes it is impossible for us to get off of a major topic, which happened again this week.



LEO:  Oh, no.



STEVE:  Yeah.  Last week was Hafnium, which was the name that Microsoft gave to the Chinese APT, the Advanced Persistent Threat group who they believe were the first people to be leveraging this horrific Exchange server breach.  So much has happened since last week that we're going to talk about it some more.  Lots of more news.  We're getting more numbers in.  There's been - and actually I didn't write this down for the notes, but Microsoft has - there was an article in The Wall Street Journal that I meant to follow up on but didn't, where Microsoft is a little wondering about whether one of their partners to whom they provided early access may have been the source of the leak.



LEO:  Oh.



STEVE:  Apparently there's like 40, I think maybe it's 400, I don't remember now, there's a bunch, I think it was 400, they call it the MAPP, as in MAPP group, like some sort of, you know, security partners that they provide access to for whatever reason.  And the point is that the exploits that did get used  bore a worrisome resemblance to the proof of concepts that they were working with and provided to these partners, under the presumption that they would never let it get out.  And my gripe, and we'll be hearing a lot more about that this hour, is that Microsoft apparently sat on their butt for two months after having been informed about this, and with devastating consequences.  Anyway, we're going to end up talking about that.  We've got a bunch of interesting browser-related news, a zero-day in Chrome, some updates.  Believe it or not, Leo, Spectre - as in Meltdown and Spectre - Google's produced a proof of concept that works in Chrome for Spectre.



LEO:  Oh, no.  Oh, no.



STEVE:  We've also got the kludgiest kludge you will ever, I mean, I love the word, as we know.  This is a  kludge's kludge from our guys at the University of the Negev in Israel, a zero-script technology for tracking that is so bad, but we have to talk about it.  We're going to take a look at last Tuesday's Patch Tuesday, what it fixed and, yes, what it broke.



We have some wonderful news, wonderful news for the open source community, a little bit of miscellany, some listener feedback, and I do have a screenshot of the final replacement for SpinRite's, as I first described it to you, the anxiety-provoking Discovering System's Mass Storage Devices screen, which was sometimes, that's all it said in a little window in the center, and it would just sit there.  And it was like, okay, is it going to go away?  Is it going to go away?  Is it going to ever finish?  Oh, my god.  Anyway, what I've replaced it with is so much better.



And then we're going to revisit the Microsoft Exchange disaster, another week downstream and still drowning.  And as you commented before we began recording, we have a really fun Picture of the Week from an old industry player, Rob Rosenberger, ex of Vmyths.com, where he specialized in debunking the virus hype, as he called it.  So, yeah, interesting stuff.  



LEO:  Oh, nice, Rob Rosenberger.  Time for the Picture of the Week.



STEVE:  So this wasn't really tweeted to me.  But Rob referred to me as @SGgrc.  And so this is from Rob Rosenberger, who ran for many, many years a site called Vmyths.com.  If you're curious, you can find his site having been archived by the web archive.  Anyway, he tweeted:  "Right here, right now, at Florida's oldest diner, this man holding the ketchup is talking about @SGgrc's CNAME 'information aggressors' tirade, and I can barely contain myself," he says.



LEO:  All right.



STEVE:  So anyway, I just got a kick out of that.  Yes, we have some reach, as we know.



LEO:  You get the word out.  You get the word out.  That's important.



STEVE:  And I did notice that, although nobody is masked, there's like a series of - they look like black frames along the diner's bar, the food bar, that are probably like plexiglass containers.  So maybe there's a little less transmission from server to customer across the bar.  But over here on the doesn't look very socially distanced pink tables, nobody's wearing a mask.



LEO:  It's Florida, baby.  Everything's wide open. C'mon in.



STEVE:  That's right.  That's right.  You've got a lot of sun, got a lot of Vitamin D, you're probably okay.



LEO:  There you go, yeah.



STEVE:  So last Friday Google, that is to say four days ago, Google updated Chrome to v89.  And then it's got the regular decimals after it - .0.4389.90.  And in doing so, they closed the second zero-day for Chrome this month, which makes it the third zero-day of the year because there was also one last month.



So what makes this different from Microsoft's response to learning of in-the-wild exploits against vulnerabilities present in their past 11 years of Exchange server, is that Google first learned of this most recent zero-day - wait for it - last Tuesday, and was pushing out updates three days later, on Friday.  So, yeah, slightly different rate of response.



One of the clear trends we've been witnessing, and all of our listeners will have seen this, if we move through the past few years, is an acceleration in the speed, to the point of frenzy, with which newly discovered vulnerabilities are attacked.  And of course this also means that there has to be a matching pushback frenzy on the part of IT guys, who are acting with full responsibility, when they learn of something like this.  I mean, they've got to just be every bit as frenzied.



So the world is still learning what happens when Microsoft waits 60 days rather than three days before patching what they must have absolutely recognized to be a bone-chillingly horrific vulnerability.  Whatever their internal problems may be, that needs to be fixed.  But anyway, we were talking about Chrome.  We'll get back to Microsoft later.



As I've noted before, I wonder when we learn of a remotely exploitable exploit against something that has no business being online, like we talked about this once, a graphics editor that had an RCE.  It's like, what?  An image editor has a remote, like an Internet remote code execution vulnerability.  Or a mouse driver, something that just should not be on the 'Net.  But I'm not surprised when we see that something like a browser or a media rendering codec whose job it is to make sense of whatever's thrown at it while also successfully ducking any curveballs that are deliberately thrown to hurt it, when that sometimes runs afoul of something.



So today, with 70% of the world using Chrome, and an even higher percentage using it on Windows, where Safari has little share because that 70% of the world accounts for also - I think Safari has about a 20% share.  So Chrome is a lot stronger than 70%, if you only look at the Windows side.  Any bad guy wishing to gain a foothold on any user's machine, at home or at office, who is using Windows, has by far the best chance of doing so by finding a way in through Chrome.  And I believe we're seeing more zero-days on Chrome because it has become the firewall that is taking all of the incoming.



So this update of Chrome fixed a total of five security problems.  There was a use-after-free in WebRTC which earned its discoverer a $500 reward for reporting it responsibly.  There was a heap buffer overflow in Chrome's tab group management which was reported and found by a Microsoftie in their browser vulnerability research group.  And there were various other fixes from internal audits that Google did, their own fuzzing and other sources.  The biggie, of course, is the zero-day that I mentioned, this third of the year, which was found in Chrome's Blink, which is the rendering engine, I would guess sort of an optimistically named rendering engine that takes a blank page and paints it with text, graphics, and images.



The vulnerability was anonymously reported to Google, which is interesting.  It would have probably been worth some money.  But who knows why that didn't happen.  IBM's X-Force vulnerability report about this zero-day, they said:  "Google Chrome could allow a remote attacker to execute arbitrary code on the system, caused by a use-after-free in Blink.  By persuading a victim to visit a specially crafted website, a remote attacker could exploit this vulnerability to execute arbitrary code or cause a denial of service condition on the system."



Now, again, curious to know why it was anonymously reported because that would have been worth some serious coin.  Google is known to be good about paying bug bounties.  And, wow, a targetable watering hole-style targeting zero-day that can perform an arbitrary code execution on a user's system?  That would have earned somebody some money.  But for whatever reason they just decided they were going to help Google to remove it.  So yay for them.



Oh, and in their disclosure Google also said, and I thought this was nice, they offered their sincere thanks to all the other security researchers who worked more or less namelessly with them during the development cycle to prevent security bugs from ever reaching the stable channel, which of course is always the better outcome.  You'd rather catch it before you ship it.



And this version of Chrome, 89, has also lost a bit of weight.  Google says that Chrome 89 brings some significant memory consumption savings to Windows.  And in the process of that, it also reduces its energy consumption and improves the browser's responsiveness.  Of course, if you actually remove code, then there's less code for the processor to go through, to slog its way through.  So yeah, it's going to get quicker.  They estimate that Chrome will now consume as little as 78% of its previous version's RAM.



Mark Chang, who's Chrome's product manager, noted that the new version also trims about 8% memory from the browser's renderer - that is to say, Blink - and roughly 3% from the GPU.  He explained that they achieved this by using PartitionAlloc, which is their own advanced memory allocator.  It's optimized for low allocation latency, being very space efficient, and also for having good, strong security.  Typically memory and memory allocation is a well-known service of any operating system.  I mean, it's like, if you were to - even if you were to think in terms of a microkernel, where the goal is what are the - the definition of a microkernel is what are the fewest number of things that the microkernel must supply to its client programs to be useful.



And so one is execution; right?  It's got to give it a thread in order to do something.  But right up there is memory management.  Any microkernel will allow its client program to say, hey, I need 8K of memory.  Give me a pointer to it.  And the microkernel keeps track of this and hands out a pointer to the beginning of an 8K region of memory or whatever the program asked for.  But it turns out the challenge of that escalates as there's a lot more competition for memory because memory is asked for by multiple processes in no particular order, and well behaving processes release the memory back to the operating system after they're done with whatever the process needed its 8K for.  It says, here, you can have that back.  I don't need it any longer.



And the process presumes that, first of all, that's part of being a good citizen on the OS; and that if it needs some more memory later, it'll ask for it and receive it.  So anyway, rather than relying on the underlying operating system's allocator, what Chrome is now doing is probably asking for big contiguous blocks all at once.  And then it's doing what's known as suballocation within that large block.  It can play by different rules when it knows that all of the allocations are going to be belonging to it and not a completely heterogeneous collection of processes that may be behaving in ways that are completely nondeterministic.



So anyway, they're switching Chrome over to this.  They've used PartitionAlloc previously in their Blink engine; and so now it's proven itself there, they're making it more universal.  They claim that similar memory savings have also been achieved on the browser tab memory management with 80% less RAM needed.  Mark Chang said Chrome now reclaims up to 100MB per tab, which he says is more than 20% on some popular sites, by discarding memory that the foreground tab is not actively using, like big images that you've scrolled offscreen.  So again, they're getting better about managing memory because they realized, whoa, this thing's getting kind of big.  And think about it.  If 20% is 100MB, well, that means that it's 500MB; right?  It's half a gig for a tab on a page.  So yikes.  Yeah, getting big.



I also did notice that the two zero-days which were - or no, it was the other secure - not zero-days.  The other security problems that were fixed in 89 happened to be in tab memory management and Blink, which were these things they were just boasting about getting performance improvements from PartitionAlloc.  So maybe there were a few little conversion problems which have been ironed out.



Anyway, Mark said that Chrome is also shrinking its memory footprint in background tabs on macOS, something that they've been doing on other platforms for a while, and that Google improved Chrome's overall responsiveness by up to 9% and achieved a 65% Apple Energy Impact score improvement for background tabs.  So they're doing better about not wasting cycles.  The Android version of Chrome was also repackaged, leading to faster page loads and startup times, and reducing its memory usage by 5%.  So they've been busy.



In the middle of last year, Chrome 85, when it debuted, gave us 10% faster page loads due to, and we talked about it at the time, a new compiler optimization technique, Profile Guided Optimization (PGO).  Then in November of 2020, with the release of 87, they optimized the browser's performance, resulting in 25% faster startups and 7% faster page loads while using less memory.  And he says to stay tuned.  There's more to come.  So Google is, or Chrome rather, is making some nice moves.



I have been experimenting with Edge as a consequence of last week's podcast when I was informed by our listeners that Edge finally had the tabs down the left-hand side option, with a simple click.  I said, okay, let's try this out.  And so I really had never spent any time in Edge.  But I fired it up and logged in and installed LastPass and uBlock Origin and a couple other things that I use and began to get it set up.  I had said no to, what is their horrible search engine?  I can't remember.



LEO:  Bing.



STEVE:  Bing.  Oh, my god, yes.  No thank you to Bing.  And brought my...



LEO:  You love DuckDuckGo; right?



STEVE:  That's the one.  Actually, I was impressed by the list of search engines.



LEO:  Oh, yeah.  Nowadays everything, yeah.



STEVE:  Oh, yeah.  So anyway, this is what's interesting is on Friday of last week, Google's security blog post was titled "A Spectre Proof of Concept for a Spectre-Proof Web."  Google's created and is sharing a working Spectre exploit written in JavaScript that's able to obtain data from the browser's internal memory.  So the way we sort of left Spectre was Intel, as we know, said oh, crap, let's make this better.  And so they updated a bunch of microcode to perform mitigations.  But then there was some pushback by the researchers who were able to demonstrate that you were still having speculative execution problems.



And remember also that enabling these features noticeably reduced processor performance because the reason they were put in in the first place was to gain significant enough processor performance that it was worth dramatically increasing the processor complexity in order to provide all this crazy branch prediction logic down at the silicon level.  But the way things kind of got left was that there would still be some obligation on the part of the application, at the application layer, to take a little bit of responsibility for this.  Not everything could be done down in the silicon.



So in Google's introduction, in their security blog posting of this, they wrote, they kind of remind us briefly:  "Three years ago, Spectre changed the way we think about security boundaries on the web.  It quickly became clear that flaws in modern processors undermined the guarantees that web browsers could make about preventing data leaks between applications.  As a result, web browser vendors have been continuously collaborating on approaches intended to harden the platform at scale.  Nevertheless, this class of attacks still remains a concern and requires web developers to deploy application-level mitigations."



And we're going to come back to this because this is the, well, the good news is that there's something that can be done.  The bad news is that this needs to be done.  And it's entirely optional, which makes me think you can hope, but we'll see.



So they said:  "In this post, we will share the results of Google Security Team's research on the exploitability of Spectre against web users, and present a fast, versatile proof of concept written in JavaScript which can leak information from the browser's memory."  That's not good.



They said:  "We've confirmed that this proof of concept, or its variants, function across a variety of operating systems, processor architectures, and hardware generations.  By sharing our findings with the security community, we aim to give web application owners a better understanding" - okay, web application owners; right?  The guys who, as I mentioned, will need to add some headers to their servers, headers to the queries and responses that their web application servers generate, if they are going to be proactive in taking responsibility for mitigating these problems.



So what's cool about this is that Google is saying, look, here it is.  If you don't fix this, this is what can happen to your application, folks.  So they said:  "Finally, this post describes the protections available to web authors and best practices for enabling them in web applications," which is where we're going to spend a little bit of time.



So the link to their posting is in the show notes for anyone who's curious.  So I'm going to only share the important bits from what is a lengthy post.  And everybody knows what Spectre is, so I'm going to skip that.  So here's some interesting and underappreciated facts affecting browsers.



They wrote:  "In 2019, the team responsible for V8, Chrome's JavaScript engine, published a blog post and whitepaper concluding that such attacks cannot be reliably mitigated at the software level.  Instead, robust solutions to these issues require security boundaries in applications" - meaning at the higher level - "such as web browsers to be aligned with the low-level primitives, for example process-based isolation."  And of course we've been talking about process-based tab level isolation because tabs are sharing process memory unless they are put in their own processes.



They said:  "In parallel, browser vendors and standards bodies developed security mechanisms to protect web users from these classes of attacks.  This included both architectural changes which offer default protections enabled in some browser configurations - such as Site Isolation, out-of-process iframes, and Cross-Origin Read Blocking - as well as broadly applicable opt-in security features that web developers can deploy in their applications."  And those are things like Cross-Origin Resource Policy, Cross-Origin Opener Policy, Cross-Origin Embedder Policy, and others.  And we'll explain what some of those things are here in a minute.



They wrote:  "These mechanisms, while crucially important, don't prevent the exploitation of Spectre; rather, they protect sensitive data from being present in parts of the memory from which they can be read by the attacker."  In other words, Google is acknowledging that Spectre really is going to be an ongoing problem.  So the best we can do is to understand the nature of what the Spectre problem presents and then give web app developers the tools they need should they choose to understand the problem and restrict the way their web apps operate to make them safe against, proof against Spectre.



But my reading of reality says this is going to be a big lift.  The tyranny of the default is going to come back.  And if since these additional things, these clear mitigations are not required, and if they are applied inartfully, they can break things that work without them.  I'll be surprised to see, it'll be interesting to see what degree of deployment they get over time.



So they said:  "The low-level nature of speculative execution vulnerabilities makes them difficult to fix comprehensively, as a proper patch can require changes to the firmware or hardware on the user's device.  While operating system and web developers have implemented important built-in protections where possible" - again, site isolation with out-of-process iframes and so forth - "the design of existing web APIs still makes it possible for data to inadvertently flow into an attacker's process."



And I've cut out a whole bunch of detail.  But they say:  "With this in mind, web developers should consider more robustly isolating their sites by using new security mechanisms that actively deny attackers access to cross-origin resources."  In other words, you really, really, really want to only, as a web app developer, only have your user's browser working with your site; or where you design other sites to participate in your solution, sharing the page with the user's browser.  You want to  explicitly allow that cross-origin presence, not allow any cross-origin presence.



And we are getting the tools in our browsers to make that possible.  For example, Google is leading this, essentially.  These are all standards-based.  But there's a long list of things that are not yet in browsers.  Firefox, for example, doesn't yet have these.  So its lack of them means that if they're present, they'll be ignored.  And when Firefox acquires them, then it will start honoring them.



So there were three that I'll just touch on briefly.  And I've got links in the show notes which explain these in more detail.  And I'm going to then sort of borrow some language from one of these pages which sort of helps to sort of characterize the nature of this.  So there's something known as Cross-Origin Resource Policy (CORP), and Fetch Metadata Request Headers.  These are all sort of extended headers which allow developers to control in this case which sites can embed their resources, such as images or scripts, which prevent data from being delivered to an attacker-controlled browser renderer process.  And in a minute I'll explain how that could happen by mistake.  But there is a page, resourcepolicy.fyi, and that's the first time I'd seen the TLD of FYI.  That's cool.  So resourcepolicy.fyi.  And then the other one is web.dev/fetch-metadata.



Anyway, so this CORP, C-O-R-P, Cross-Origin Resource Policy.  Then there's Cross-Origin Opener Policy, COOP, C-O-O-P, which lets developers ensure that their application window will not receive unexpected interactions from other websites, allowing the browser to isolate it in its own process.  This adds, they write, an important process-level protection, particularly in browsers which don't enable full site isolation.  So again, if you had this turned on, like globally, and your web app did need  some other origin's involvement, this would break that.  On the other hand, you can explicitly allow that.  So you can sort of think of these things like firewall rules for a browser.  It's very much like that.



Unfortunately, as we'll see in a minute, the web started without any of this, much as the Internet's first firewalls, right, were allow any, and then deny bad ports.  Well, we learned how that worked out.  And so today's firewalls are all deny all, and then allow specific things that you want through.  The problem is we're not going to be able to flip that logic around as we did with firewalls in our browser ecosystem, or the web ecosystem.  There's just no way to get to there from where we are now.  But the third one is COEP, Cross-Origin Embedder Policy, which ensures that any authenticated resources requested by the application have explicitly opted into being loaded.



They said:  "Today, to guarantee process-level isolation for highly sensitive applications in Chrome or Firefox, applications must enable both COEP and COOP."  That is to say, to guarantee process-level isolation.  And that's the point.  If you don't have those, if you don't provide those to the browser, if the web server doesn't ask for that, the browser is not able to provide process-level isolation because other stuff from other origins has to come in.  So it's only by adding those headers that you're telling the browser, lock this down.  Either no other origins or only these specifically applied other origins are allowed to put stuff and to interact with this page.



So they finish:  "In addition to enabling these isolation mechanisms, ensure your application also enables standard protections, such as the X-Frame-Options" - which I have on my site, it's a bunch of things that you can tell the browser that frames should not be able to do on your site.  And there's also X-Content-Type-Options, which content types are allowed.  Again, the problem is none of this is the default.



And so we've been incrementally over time looking at how the abuses occur, and we are responding to them.  Unfortunately, much like when firewalls were all open and looking at what ports were hurting us and going, ooh, let's block that.  Ooh, let's block this one.  And just it's not a good way to go.  But again, it's the only thing we have at this point.  There's no way to flip the definitions over without breaking everything.  So clearly, if anyone played with web browsers, if you're not doing it now, browsers and servers and headers, it used to be so simple.  Used to be GET and POST, and you would send a host header and maybe a cookie or two.  I mean, boy, you know, this is not our father's Internet any longer.



So at that web.dev site on the fetch-metadata page, the site attempts to explain the generic problem, pretty much as I have. This guy wrote:  "Many cross-site attacks are possible because the web is open by default" - which I think is the best way I've seen of saying it - "the web is open by default, and your application" - talking to web application developers - "your application server cannot easily protect itself from communication originating from external applications."  And I'm going to give an example of that in a minute.



But he said:  "A typical cross-origin attack is a cross-site request forgery (CSRF) where an attacker lures a user onto a site they control" - which is the fancy way of saying a user went to a site that was bad, malicious - "and then submits a form to the server the user is logged into.  Since the server cannot tell if the request originated from another domain (cross-site) and the browser automatically attaches cookies to cross-site requests, the server will execute the action requested by the attacker on behalf of the user."



So let me explain that a little more carefully.  In other words, an innocent user visits some site.  That site displays a page with JavaScript which, as we know, you pretty much can't live without anymore.  Even I gave up having NoScript enabled where by default scripts - remember those sweet days when you could actually still use a site without scripting?  It's gone.



So that site, this site that a user visits, displays a page with JavaScript, which it uses to submit a form with a POST query to some other vulnerable site, presumably that the user has a relationship with.  The user's browser is performing the form submission POST query, so it adds the session cookies which it has for that site to which the query is being sent because that's where cookies go with queries.  The targeted site sees this as a valid query from a known and logged-in user and thus honors the request, whatever it is.  So in essence, the malicious site is acting on behalf of the user without their knowledge.  That is a classic cross-site request forgery.



And remember that the way web apps work now, back in, again, the quaint old days, you actually had a form that you would fill out fields, and then you would press the Submit button, and it would send a POST.  Well, now everything is web APIs.  Well, web APIs are just POST queries.  Maybe GETs sometime.  Mostly POSTs.  So what this generalizes to is you can visit a malicious site which, without you knowing it, will be able to send web API queries as if you were visiting another site with your browser, and JavaScript from that site was issuing these web APIs, doing all kinds of fancy web app stuff on your behalf that you don't see behind the page.  Well, now bad guys can do that, acting as you, impersonating you.



So anyway, when the author of that page said that by default the web is open, essentially that's exactly what he was talking about, that if we're going to fix this, we need to proactively take action to lock things down.  So again, I like the firewall analogy I think is the best example.  The fact is right now you need to very carefully, that is, web developers, consider adding rules just in the form of headers to web applications, which explicitly permit content and interaction only with the specific origins, that is, the other domains, and it may be none, that your app must interact with.  If that's none, then that's wonderful because it means that you are enabling the browser to decline any sort of this abuse, and also to know that it can put your entire site's interactions in its own isolated process using the operating system's process isolation features, which are pretty mature, in order to provide protection.



So anyway, it'll be interesting to see how this goes.  My feeling is the responsible web developers listening to this podcast may already know about this.  Or if they didn't, I'll bet they're going to go find out because it's certainly a useful way of enhancing the security of their applications and preventing them from being hacked.  The problem is there are many more web developers who may not be clued into this.  There's nothing that the browsers can do to enforce this that wouldn't risk breaking apps, and we know that's the last thing they want to do.



So those clever and resourceful guys at the Ben-Gurion University of the Negev, the University of Michigan, and the University of Adelaide will be presenting their research - and I'm not sure why they're going to bother, but that's just my opinion - during the upcoming USENIX Security Symposium 2021 this August.  I've been a big fan of their work.  Not sure about this one.  Their paper is titled "Prime+Probe 1, JavaScript 0."  They said:  "Overcoming Browser-based Side-Channel Defenses."



Okay.  So first of all, here's how they explain this.  They said:  "The 'eternal war in cache' has reached browsers, with multiple cache-based side-channel attacks and countermeasures being suggested."  Oh, and I should explain, this is a JavaScript-free tracking technology.  So it's a new way of tracking, even if there's no script running in the browser.  So they say:  "A common approach for countermeasures is to disable or restrict JavaScript features deemed essential for carrying out attacks."  And for example we've talked about reducing the number of bits of resolution in available time measurements and/or deliberately adding some timing jitter to the timing that JavaScript was able to read.



So anyway, they said:  "To assess the effectiveness of this approach, in this work we seek to identify those JavaScript features which are essential for carrying out a cache-based attack.  We develop a sequence of attacks with progressively decreasing dependency on JavaScript features."  So they iterated on this problem, doing it, and then saying, okay, how can we eliminate this?  How can we eliminate that?  And they whittled this thing down to no JavaScript at all.



They said:  "...culminating in the first browser-based side-channel attack which is constructed entirely from Cascading Style Sheets and HTML, and works even when script execution is completely blocked.  We then show that avoiding JavaScript features makes our techniques architecturally agnostic, resulting in microarchitectural website fingerprinting attacks that work across hardware platforms including Intel Core, AMD Ryzen, Samsung Exynos, and Apple M1 architectures."



They said:  "As a final contribution, we evaluate our techniques in hardened browser environments including the Tor browser, DeterFox and Chrome Zero.  We confirm that none of these approaches completely defends against our attacks.  We further argue that the protections of Chrome Zero need to be more comprehensively applied, and that the performance and user experience of Chrome Zero will be severely degraded if this approach is taken."



Okay.  So they have engineered a cross-browser, cross-platform, cross-architecture, script-free, side-channel browser fingerprinting hack.  So I was curious to learn what they had done.  And having done so, I would characterize it as one of the most godawful hacks I have ever seen.  Here's how they describe what they designed.



They said:  "The attacker first includes" - so this is, you know, you go to a site, and this thing is going to be used against you to fingerprint you.  "The attacker first includes in the CSS [Cascading Style Sheet definition] an element from an attacker-controlled domain, forcing DNS resolution.  The malicious DNS server logs the time of the incoming DNS request.  The attacker then designs an HTML page that evokes a string search from CSS, effectively probing the cache.  This string search is followed by a request for a CSS element that requires DNS resolution from the malicious server.  Finally, the time difference between consecutive DNS requests corresponds to the time it takes to perform the string search, which serves as a proxy for cache contention."



Now, that was as clear as mud to me.  But unfortunately they also provided an annotated snippet of HTML.  Thank you, Leo.  It's on the screen.  So the HTML above, on the screen for those who are looking at it, or in the show notes, shows a code snippet, just a standard HTML, which implements this CSS - they call it the Prime+Probe hack.  Well, they didn't say "hack," I did - using CSS attribute selectors to perform the attack.  So in this onscreen code, line 9 defines a div with, from their text, a very long class name, on the order of - is everybody sitting down? - two million characters.



LEO:  So the ellipsis in there is just to represent the fact that there would be two million characters here.



STEVE:  Yes.  That is a, shall we say, a heavily loaded or overloaded ellipsis, yes.



LEO:  How would you even get two million characters in a file?



STEVE:  Who even knew that was legal?  That's insane.



LEO:  I mean, yeah.



STEVE:  A class name.  And what's - so here's the hack, Leo, is it's possible to use CSS selectors to do searches within class names.  And that's what they've done.  So if you look above, you'll see those two style entries at line 3 and line 5.  So those are selectors which select some subtext out of the class name.  And when the selector succeeds, then you can see it's loading a background image from a URL of some random domain name at attack.com.  So anyway, so essentially what they've done is...



LEO:  It's a buffer overflow, I would guess; right?



STEVE:  Well, it is a cache content-based delay.



LEO:  Oh.



STEVE:  Which is why I said it is the mother of all kludges.



LEO:  Clever.



STEVE:  So, yeah, well, it is clever, I'll give them that.  So after this, what they call the "external div," this monster div with a class name of two mega characters, then they have some interior divs with IDs referring back up to the selectors.  So in order to display the interior div, the ID references the selector, which then uses this weird, I mean, I'd never even looked enough into CSS to know that you could have a selector which has a wildcard which matches some piece of text in the parent div.  But yes, you can.  Anyway, I just...



LEO:  It's powerful.  That's pretty amazing, yeah.



STEVE:  It really is powerful.  And I can't, I mean, it makes your head spin to think about how you would actually use this when you weren't trying to create this ridiculous cache-content-based DNS lookup timing hack.  Anyway, these are the guys who transmitted crypto keys from the caps on the keyboard or people sneezing in the next room.  I mean, they've done all this crazy stuff.  So I guess we shouldn't put this one past them.  So props to them.  But there was a little more breathless coverage in the tech press than I think this deserves.  I can understand how they got there.  They said, okay, we have JavaScript.  Now, let's remove this.  Let's remove that.  I mean, basically they took everything out of it until there was nothing left but HTML and CSS and said, oh, look, it still works.  We don't need JavaScript.  Okay.



This is the third Tuesday of March, which is always our opportunity to look back on the second Tuesday of March and find out what happened.  Of course that was Patch Tuesday, which saw the release of Microsoft's monthly patches.  This one, no records were broken.  Some hearts, yes; records, no.  They repaired 89 security flaws, including an actively exploited-in-the-wild zero-day in IE, of all things.



Now, that happens to be one of the flaws that those North Korean hackers were using.  We talked about them a few weeks ago.  They were, remember, they created a fake security firm.  So they were impersonating a legitimate security firm that had like a security portal and website, and they were out soliciting other reputable, well-known firms, asking if they'd like to make an entry in their blog and collaborate with them on some projects.  And, oh, they offered some Visual Studio projects, demonstrating some of their exploits.



Of course, we found out that those were booby-trapped with malicious DLLs that Visual Studio would happily load into the system when you opened the project.  And they were using this zero-day IE vulnerability, that is, an IE vulnerability that was unknown to anyone when it was discovered actually by South Korea.  And as we've mentioned before, even though IE has long now been deprecated, and in fact even Edge Classic has now been deprecated.  Now that Microsoft is sure that Edge Chromium is a good thing, Classic is being shut down.



But even though IE's been deprecated and will no longer respond to a URL scheme that's been given to it, it's still deeply embedded into Windows.  And in fact there've been some instances where, for example, Media Player, right, where if you were to  do something that disabled IE, weird parts of your system would break because they depend upon that embeddedness which Microsoft originally created so that they could claim that their browser was part of the operating system, and that it couldn't be removed for some third-party browser.  It's like, okay, well, so now they're having the consequences of that.  Anyway, IE can still be invoked. 



Overall, of those 89 flaws, 14 are critical, 75 are important, two are listed as being publicly known, and five others are under active attack.  And among those five are the four that immediately and deservedly became infamous, that now they're sort of generically called the ProxyLogon vulnerabilities.  And of course we're going to end the podcast by updating everybody about where that all stands at the moment.  March's update packs fix two additional very serious remote code execution flaws in Windows DNS server, and those have the difficult-to-achieve VSS score of 9.8.  You've got to work really hard to get up to 9.8 in severity, but these two do.



And our astute listeners may remember that there was just another DNS RCE flaw fixed last month.  So I guess it's good that Microsoft is looking closely at their DNS server.  These were in the Dynamic Update feature of DNS server, which is a means for automatically updating the so-called "DNS zone files" that allow clients to make these changes.  So a feature of DNS which has been standardized.  And those two 9.8 flaws are exceeded only by the RCE in Hyper-V which has a CVSS of 9.9.



SharePoint Server and Azure Server also receive fixes for their each of their own remote code execution vulnerabilities.  And Microsoft noted that the pair of problems fixed in Windows DNS server are tagged as "exploitation likely" because they are low-complexity, zero-click attacks requiring no user interaction.  I immediately wonder why these would ever - why this Dynamic Update would ever be facing outward to the Internet.  But again, things tend to be insecure by default.  So there's another example.



So patching immediately, as we know, has become an imperative for the survival of anyone using Windows with any online presence.  And I know that all of us who watch this drama unfold weekly have come to understand this.  But I really do wonder, and we actually have some stats on this at the end, how well understood this is within small enterprises, who hired a computer guy, like one of those who we saw at the diner, probably, to install...



LEO:  I'm a computer guy.



STEVE:  That's right.  I'm the computer guy for four different companies.  And it's like, okay.  Good luck to them.  Are you on the beach at the moment, or are you patching their Exchange server?  They want email and web and WiFi, please.  And he says,  yup, I can do that.



LEO:  I can do it, yeah, uh-huh.



STEVE:  Yup.  So according to McAfee, those two DNS vulnerabilities arise from an out-of-bounds read and out-of-bounds write, respectively, to the heap, when that DNS server processes Dynamic Update packets, which result in a potential arbitrary read and remote code execution.



And speaking of McAfee, I recently let pass the observation that  the company's namesake, original founder and longstanding entertaining embarrassment John McAfee, had finally been arrested in Spain last October and is currently there awaiting extradition, which John for some reason claims will never happen.  And actually that was back in early October, and so far it hasn't.  He was brought to mind because he hit the news a few weeks ago over a recently unsealed U.S. Department of Justice indictment alleging that he and his business associate, Jimmy Watson, used John's Twitter account to tout various cryptocurrencies to hundreds of thousands of followers - and by the way, he has one million followers.



LEO:  Wow.



STEVE:  Yeah.  And apparently this concealed how they stood to gain from a run-up in prices, you know, your standard pump and dump scheme; right?  Anyway, that's what the DOJ thinks.  Prosecutors allege that McAfee, Watson, and other members of McAfee's cryptocurrency team took in more than $13 million by victimized investors who had bought into this fraudulent scheme.  I don't know any more details.  And also, meanwhile, John has often explained that he doesn't believe in taxation.  Nope, I don't believe in that, he says.  And thus shouldn't be forced to pay any.



So I suppose, unsurprisingly, his arrest and detention in Spain was over earlier separate criminal tax evasion charges which were filed by the tax division of the U.S. Department of Justice.  And I read a bit of his recent Twitter feed.  It's sort of sad having him locked up because he really is, like, almost probably the definition of a free spirit.  But on the other hand I was thinking that perhaps it'll give him the chance to finally settle down and, as he has said he plans to, and as only John could, write his own unauthorized autobiography.



LEO:  Wait a minute.  You can't write your own unauthorized - he said "unauthorized," huh?



STEVE:  Yes, he did.  He's going to write his own unauthorized biography.



LEO:  I do not approve this biography that I am writing.



STEVE:  It might be worth a read.



LEO:  I think it might.



STEVE:  And I think, Leo, if you were to read his recent tweets, it's a little sad.



LEO:  That's why he has a million followers.  People are fascinated, probably; right?



STEVE:  Yeah, yeah.  Boy, and I'll tell you, it's not for children, either.  Ooh.  He's rather blue in his writing.  Okay.  So if anyone experienced Blue Screens of Death after Windows 10, when attempting to print after installing the March updates, you were not alone.  It was a widespread problem that may have been related to two of the March updates that were intended to eliminate printing-related elevation-of-privilege vulnerabilities.  So those were two things Microsoft was touting as having fixed.  And apparently they needed some additional fixing.  Kyocera, Ricoh, and Dymo printing are among those known to be affected.



In response to this, Microsoft has since released optional cumulative updates containing the fix.  Since they are published as optional, they will not be automatically installed via Windows Update for everyone.  So if by any chance you haven't already fixed these blue screens, if you got them after last Tuesday's Patch Tuesday, then you can go to Windows Updates.  You may need to do a check for updates, see if it offers them to you.  If not, you can find them under "optional" and then install them.



Okay.  The good news to follow all of that, free code signing is coming to open source.  In response to the clearly recognized problems with the security of the open source software supply chain, as so clearly demonstrated in the recent dependency confusion trouble and the earlier malicious RubyGems NPM exploits, the Linux Foundation, Red Hat, Google, and Purdue have designed and are working to deploy a new, free, complete, state-of-the-art code-signing facility to be called Sigstore.  I'm certain that we'll have an episode of this podcast bearing that name before long.  Once implemented, it will provide fully auditable, verifiable, and transparent code signing for the open source community.  



The tech press covering the news, and even Google themselves, are referring to it as "Let's Encrypt for open source code signing."  Google's blog post about this from last week was titled "Introducing Sigstore:  Easy Code-Signing & Verification for Supply Chain Integrity."  I've got the link to their whole announcement.  I'll just summarize it.  They said - or the beginning.  They said:  "One of the fundamental security issues with open source is that it's difficult to know where the software comes from or how it was built, making it susceptible to supply chain attacks.  A few recent examples of this include dependency confusion attack and malicious RubyGems package to steal cryptocurrency.



"Today we welcome the announcement of Sigstore, a new project in the Linux Foundation that aims to solve this issue by improving software supply chain integrity and verification.  Installing" - and I love how people talk about how bad the past has been, but not until they have a solution.  So of course, oh, it's wonderful.  Don't worry.  Okay.  But now they're saying:  "Installing most open source software today is equivalent to picking up a random thumb drive off the sidewalk and plugging it into your machine."  What could possibly go wrong?



They said:  "To address this, we need to make it possible to verify the provenance of all software, including open source packages.  The mission of Sigstore is to make it easy for developers to sign their releases and for users to verify them."  They said:  "You can think of it like Let's Encrypt for Code Signing.  Just like how Let's Encrypt provides free certificates and automation tooling for HTTPS, Sigstore provides free certificates and tooling to automate and verify signatures of source code.  Sigstore also has the added benefit of being backed by transparency logs, which means that all the certificates and attestations are globally visible, discoverable, and auditable.  Sigstore," they said, "is designed with open source maintainers, for open source maintainers."



They finished:  "We understand long-term key management is hard, so we've taken a unique approach of issuing short-lived certificates based on OpenID Connect grants.  Sigstore also stores all activity in Transparency Logs, backed by Trillian, so that we can more easily detect compromises and recover from them when they do occur.  Key distribution is notoriously difficult, so we've designed away the need for them by building a special Root CA just for code signing, which will be made available for free.  We have a working prototype and proof of concepts that we're excited to share for feedback.  Our goal is to make it seamless and easy to sign and verify code."  So that is all at Sigstore.dev, S-I-G-S-T-O-R-E dot dev.



So anyway, this is a wonderful and much-needed solution and service for the open source community.  What this means is that, once it's up and running, a developer's software build chain and a source repository publication will acquire the ability to periodically obtain, as needed, a relatively short-lived code-signing certificate which it will use to sign whatever it packages.  Anything that then obtains that signed object from a repository, downloaded from a website or whatever, will be able to verify the signer's signature, perform a real-time check over the 'Net to confirm that nothing is known to be wrong with that signature, that its trust has not since been rescinded after signing, and that it's okay to proceed.



So this represents a fabulous step forward for the open source community and industry.  As with any change, it'll take a while to happen.  But it will wind up being built into our systems and will then become transparent.  So unlike things like I was saying, like the need for web developers to be unfortunately painfully proactive if they know and then choose to lock down their applications, that's not necessary here.  We're going to get, you know, doing this will end up being built into the next generation of repository publication and repository pulling tools, and signing will happen.



And once that's in place, once we're to the point where it is possible to refuse to use anything that's not signed, then the bad guys are in trouble.  Take a while to get there, but this is the only solution I can see to this problem of inadvertent mistakes allowing bad guys in.  This dependency confusion, as we know, and as I've been saying, is a huge problem.  This is a beautiful piece of fix for it.



JPL's Persistence Rover, Leo.



LEO:  Perseverance.



STEVE:  Perseverance.  I'm sorry.  I've got it right in front of me.  I said it wrong.



LEO:  It's persistent.  But it's perseverant, as well.  It's both.



STEVE:  It is, exactly.  National Geographic produced a fabulous one-hour documentary about JPL's construction.  Did you see it, or do you know of it?



LEO:  No, I just heard about it, and I know I need to watch it, yeah.



STEVE:  You have to.  The documentary is titled:  "Built for Mars:  The Perseverance Rover."  And it goes behind the scenes at NASA's JPL, the famous Jet Propulsion Laboratory, to document the birth of NASA's latest technological marvel.  Now, I didn't know what I was in for.  You might tend to think that this wouldn't be as interesting as the news that it made it safely to Mars and is working.  But if you take an hour to watch this, you'll know why it landed on Mars and is working.  And you'll learn why that almost didn't happen.  There were some glitches.  And, oh, the nature of the glitch, the nature of the problem was so cool and so unexpected.  I mean, it just - it is really neat.  It almost blew their schedule for another, what is it, two and a half years when we will be back into a position where we can do an Earth-Mars transfer.  So anyway, so much more went into, or I should say goes into the construction of these remote machines than anyone would ever imagine.  So I wanted to tell you, Leo, and to commend to all of our listeners...



LEO:  I can't wait, yeah.



STEVE:  ...that they really need to see if you can find the program.  It was recommended to me by a friend in GRC's newsgroups, and I am so glad that Lorrie and I watched it.  She was every bit as riveted and fascinated by this because, I mean, it's not deeply technical.  But first of all, it is all footage that was filmed, like, you know, they documented the entire process.  And so you get to see inside all of the various stages of construction.  But you really understand that the term "no room for error" comes to play.  Anyway, I cut my cable, only using Cox now for data.  I'm streaming with Roku.  I subscribe to YouTube TV, and the National Geographic Channel is available through YouTube TV, so I just put into the search there "Perseverance," and it came right up.



LEO:  Oh, good.



STEVE:  And so you can watch it on demand any time.  It does go away, I think in May.



LEO:  Uh-oh.



STEVE:  So don't wait too long.  But it is, oh, my god, it is so worthwhile.  And just, wow, I mean, it will change anybody who watches it.



Three pieces of feedback from our listeners.  We got a note from a listener in France who said:  "Catching up on my Security Now! episodes, and I finished the 808 CNAME Collusion this week."  He says:  "I feel, just like you, it is a bad thing that tracking services can access website cookies and authentication tokens by the CNAME trick.  However, assuming you are on a browser using same-site cookie policy, my understanding is the tracking website cannot track you across different website anyway," he says, "aside from using fingerprinting."



And he says:  "Using your example in SN-808, if the tracking website sets a cookie in the browser, it would be associated with dyzxrdb.example.com; thus, web-trackers-R-us.com has no right to ask for it after, when you're visiting other websites.  So from a tracking standpoint it seems as good as third-party cookies, plus the ability to catch the main website cookie."  He says:  "Am I missing the point?"  And he says:  "Thanks for the show, your work on SpinRite," et cetera.



So he's absolutely right.  This does not allow for cross-site tracking.  But that's no longer an impediment.  The impetus to track is so strong that a tracker, a third-party tracker would be happy to have you carrying their cookie under that subdomain name for them and receive it next time you go back.  So it was also explained as an adjunct to traditional cookie tracking.  So it's like other forms of fingerprinting or other transient tracking mechanisms, the idea being that, if you did something that caused them to lose track of you, then this would allow them to reestablish it.  So essentially any information they can get is bad, and this is a substantial additional piece of information.  But at the same time, absolutely right, this is not cross-domain by its nature.



Someone tweeting as Ruddog said:  "Hi, Steve.  I'm a long-time viewer of Security Now! and a proud owner of SpinRite.  If I remember correctly, your and Leo's stance on virus checkers is 'not needed.'  Is this still the stance you take on virus protection?  If not, what would you recommend for protection, not only for your computer, but emails and attachments?  Thank you for your time."



And so I'll just - we've mentioned this a few times in various contexts.  But officially I am still using, I'm sitting right now in front of Windows 7.  Microsoft refused to continue sending updates to me...



LEO:  You're crazy, man.



STEVE:  ...a year ago.  But my Defender is still a green little house or a little...



LEO:  It's because they keep that up to date, yeah.



STEVE:  Yes, a little fort with a flag on it.  And I'm glad for that.  So as I mentioned, mostly it's an annoyance for me because as a software developer I am creating executable content all the time.  And it doesn't know what it is.  It doesn't have a reputation.  Apparently my code for some reason matches, just statistically matches some random virus somewhere, and so it's telling me that the thing I just built is endangered.  So I'm having to whitelist my development region of my machines in order to keep from having constant false positive annoyance.  I mean, it's really annoying when you go to run it, and you're told that it's gone.  It's like, wait, what?  First I think that my build failed.  Then I realize, oh, no.  I've been overprotected by Defender.



But anyway, my feeling is what Microsoft has built in is good enough for anybody.  And it's deeply embedded in the operating system.  We've seen lots of examples where third-party AV is now causing trouble because Microsoft can't check all of the various AV scanners.  And many of them, in order to work, they go in and hook the guts of the operating system, which is really bad practice.  It's just bad form.  But it's what they have to do if they want to stay relevant and, for example, scan all email and attachments of everything coming in.  So I'm happy with what Windows provides at this point.  I would recommend everybody use that.



LEO:  I should add, because I just did an ad thing, we use ESET.  It might be a little different in business, and that's why we use a business product, ESET for business.



STEVE:  Right, I agree.



LEO:  Because you have a heterogeneous system.  You have users who are not sophisticated.  And also the way we are able to run it, it doesn't impinge in any way on their systems.  Plus none of us are writing our own assembly language code, so that's a good thing.



STEVE:  Yeah.



LEO:  So I agree with you, and I've always said the same thing.  And I've often been berated by IT guys who say, well, yeah, Leo, because you're safe and Steve's safe.  But don't forget, in business we've got to take a little extra precautions.  And so we use...



STEVE:  They have a lot more incoming, too; right.



LEO:  Yeah.  And we use a variety of tools to protect our users on their machines.  Most of the machines don't actually have ESET running on the machine.  The editors we do because they're using Windows 7.  And unlike you, we're a little nervous about using Windows 7.  But I trust Russell.  He knows what he's doing, and he's kept us safe all this time.  So I'm not going to - the last thing I would ever say is, oh, what are you doing, Russell?  Just take all that stuff off.  It will be fine.  Because I don't know if we would, to be honest.



STEVE:  No, I would agree.  As long as it's not causing any trouble.



LEO:  It doesn't, yeah.



STEVE:  Belt and suspenders.



LEO:  But it's, again, it's a business class product.  I've always said that.  Geez, the last thing I'd ever use is, for instance, Norton or McAfee on an end-user's computer.  That's just a nightmare.  But businesses have a different need, and often they have different ways of doing it.  You know, the antivirus doesn't necessarily run on the machine.  I don't want to talk too much about our topology, but it's usually running at the front end, so to speak.



STEVE:  Where it needs to, yup.  And lastly, Alim S., who might be a Dutch physicist because that's what his handle looks like.  He said:  "Hi, Steve.  I am a five-years-long follower of Security Now!.  Thanks for your great work.  I highly appreciate it.  Last week, you mentioned why Microsoft named the group Hafnium.  Coincidently, just a few days before listening to your last podcast, I had listened to a podcast from Microsoft, named Security Unlocked.  They had an interview with one of their employees who has a job title of Threat Intelligence Librarian."



LEO:  Oh, interesting, wow.



STEVE:  "She gave a little explanation why the periodic table is used for naming.  In essence, it's to have some abstraction and keep it neutral."



LEO:  Because we don't really want to call it the Exchange Server Virus.



STEVE:  That's correct.



LEO:  Keep it neutral.



STEVE:  We'll just call it Hafnium.  And I have to say that my thought when learning that was, you know, there just aren't that many elements.



LEO:  Oh, yeah.  You're going to run out fast.



STEVE:  Microsoft, well, remember, this is Microsoft.  So, yeah.  And anyway, I just have in the show notes a nice picture that I took yesterday of SpinRite's final evolution of its Discovering System's Mass Storage Devices screen, which is actually a screenshot from my development machine showing a whole bunch of...



LEO:  Which gets me every time.  You've got so many things hanging off your machine.



STEVE:  Well, and my actual machine has two.  But this is meant to really give the software a workout.  I mean, it's specifically for SpinRite development, so it shows AHCI controllers, what ports they're hooked to.  I'm also pulling from the SMART data the total running time of each drive so far since it was first plugged in for you, and it was zero when it began, because I think that's just cool to know.  Also the size of the drive, the drive's identity, and then its up-to-20-digit serial number, so you can keep track of them and know what they're doing and so forth.  So anyway, we're now moving forward past that onto the drive selection screen, which I will be updating and improving with new information, and then working to get SpinRite running.  So we're getting close.



Okay.  So I can't promise we're never going to talk about this again because our talking about it will probably be dwindling in the same way unfortunately that the number of servers being patched is dwindling.  We have some stats about that.  It's been a week since we first talked about this.  It was two weeks ago that during the podcast the news of this broke on March 2nd.  Check Point Research has widespread Internet instrumentation that allows them to observe a lot about what's going on, actually a bunch of the various security companies have really some really interesting instrumentation.  So one of the tidbits that caught my eye since we talked about this last week was even in the popular press I saw some scroll going along the bottom of the screen on CNN, I think it was on Sunday, saying that attacks were doubling every hour.



LEO:  Holy cow.



STEVE:  And, you know, that'll get your attention, yeah.



LEO:  Holy cow.



STEVE:  Check Point said that they had observed that the number of attempted attacks had increased tenfold just between March 11th and March 15th, so tenfold over the course of, what, four days.  The country most attacked is us, the United States, receiving 17% of all exploit attempts, followed by Germany at 6%, the U.K. at 5, the Netherlands at 5, and Russia at 4.  And we do believe that this is China behind this.  The most targeted industry sector has been the government and military receiving 23% of all exploit attempts, followed by manufacturing sector at 15%, banking and financial at 14%, software vendors at 7, and healthcare at 6.



Threatpost's updated coverage last Thursday opened with the headline "Microsoft Exchange Servers Face APT Attack Tsunami."  They wrote that:  "At least 10 nation-state-backed groups are using the ProxyLogon exploit chain to compromise email servers."  And of course email is just the way in, as we know.  Nobody really cares that much about an email server.  They want to get in and take over the enterprise.  "According to researchers, overall exploitation activity is snowballing," they said.



As we already know, some of the attacks are being carried out by a China-linked APT group which Microsoft has named Hafnium, but multiple other security firms have observed attacks from other groups and against a widespread swathe of targets.  Researchers at Huntress Labs said that they had discovered more than 200 web shells, that's like 200 different hashes of web shells, completely distinct web shells deployed across thousands of vulnerable servers, even though these systems are equipped with antivirus and endpoint detection and recovery.  And Huntress said that they expect this number to keep rising.



They said:  "The team is seeing organizations of all shapes and sizes affected, including electricity companies [gulp], local city governments, healthcare providers, banks and other financial institutions, as well as small hotels, multiple senior citizen communities, and other mid-market businesses."  So Leo, it's like the model that we were talking about before.  There are so many tens of thousands of small installations where there's a Windows server running Exchange server, and it's providing them with a web presence and email.  And of course Exchange server's got to be on the Internet in order to do email.  Those systems are probably not being maintained in near real-time, the way they essentially have to.



In fact, researchers at ESET tweeted that CVE-2021-26855 was being actively exploited in the wild by at least three APTS besides Hafnium.  They said:  "Among them we identified #LuckyMouse, #Tick, #Calypso, and a few additional as yet unclassified clusters."  They also noted that while most attacks are against targets in the U.S., they said that:  "We've seen attacks against servers in Europe, Asia and the Middle East."  So, yeah, it's a global mess.



And, you know, with all this happening, with all the attention that this has been getting, not only in the tech press but also in the popular press, wouldn't you think that everyone with an Exchange server would have quickly patched?  Who could not know about this who might be responsible for an Exchange server?  We keep hearing about mounting attacks and tens of thousands of victims.  Well, Microsoft is now working with RiskIQ to track the number of servers that are online-facing, unpatched, and still vulnerable to attack.  As of last Friday, March 12th, approximately 82,000 - okay, Leo - 82,000 Exchange servers are still not patched.



LEO:  Unpatched?  Unpatched?



STEVE:  Yes.



LEO:  Oh, lord.



STEVE:  Last Friday the 12th.  So this is 10 days from the time this began, with all the attention this has been getting, 82,000 servers are being monitored.  They have not yet been patched.  Palo Alto Networks' number is higher than that.  They're counting at least 125,000 unpatched servers worldwide as of last week.  But it might have been earlier last week.  So from our position, as people who live security, it's so obviously necessary to update instantly, if not sooner.  But the reality is, amazingly enough, it's still not happening.



Microsoft themselves commented, and I love this:  "Microsoft is deeply committed to supporting our customers against these attacks, to innovating on our security approach, and to partnering closely with governments and the security industry to help keep our customers and communities secure."  Right.  Except someone needs to explain why they sat on this for two months.  I'm sure they understand now that this was a huge mistake.  But that mistake cannot be made.  I mean, this isn't the last of these.  They've really got to fix their game.



And starting last Tuesday, a brand new strain of ransomware known as "DearCry," D-E-A-R-C-R-Y, has appeared.  Michael Gillespie, we've spoken of him before, he's the creator of that ransomware identification site ID-Ransomware and the guy we've mentioned who curates the free decryptors for those improperly designed ransomware attacks that can be decrypted without needing a unique per-instance key.  He said that, beginning last Tuesday, users began submitting a new ransom note and encrypted files to his system.  After reviewing the submissions, he discovered that users submitted almost all of them from Microsoft Exchange servers.



And on the same day, a victim also created a forum topic in the BleepingComputer forums where they state their Microsoft Exchange server was compromised using ProxyLogon vulnerabilities, with the DearCry ransomware being the payload.  Now, that person posted that last Tuesday the 9th, a week after this was known and emergency patches were available.  Again, the communication lines are down, apparently.



Okay.  So now we're likely talking about tens of thousands of new ransomware infections.  Ransomware, on top of the underlying Exchange server problem.  And since then, multiple other security firms, including Microsoft, have confirmed the appearance of this new ransomware strain.  Our friend Marcus Hutchins of Kryptos Logic tweeted on Friday.  He said:  "We've just discovered 6,970 publicly exposed web shells placed by actors exploiting the Exchange vulnerability.  These shells are being used to deploy ransomware."



Marcus explained that anyone who knows the URL to one of these public web shells can gain complete control over the compromised server.  The DearCry hackers are using these shells to deploy their ransomware.  The web shells were initially installed by Hafnium, the state-sponsored threat actor operating out of China.  Marcus said that the newer attacks are "human operated," meaning attackers are manually installing ransomware onto one Exchange server at a time.  He said: "Basically, we're starting to see criminal actors using shells left behind by Hafnium to get a foothold into networks."



And this of course underscores a key aspect of the ongoing response to securing the Exchange servers that were previously exploited by ProxyLogon.  It's not enough to simply install the patches.  Without removing the web shells which were certainly left behind, servers remain open to intrusion after they've been patched, either by the hackers who originally installed the backdoors, or by other hackers who figure out how to gain access to them.



So at this point little is known about DearCry.  Security firm Sophos said that it's based on a public key crypto system with the public key embedded in the file that installs the ransomware.  And what's interesting is that allows files to be encrypted without the need to first connect to a command-and-control server.  In other words, traditional ransomware has been generic, the same ransomware installed to different victims.  Then the ransomware calls out to a command-and-control server to receive the key which it will be using to perform the encryption.



This is different.  DearCry is being created per attack, and the public key is built into it.  So it doesn't need any net communication in order to begin encrypting things.  And it's using state-of-the-art 256-bit AES as its bulk cipher and a 2048-bit public key.  So it appears to have been well designed.  And it was clearly ready.  Someone, I mean, maybe they were going to deploy this elsewhere.  Maybe they were thinking, well, how are we going to find firms to infect?  Then this gift comes along of Exchange server and web shells that allow someone just as fast as they can to go and install this and encrypt the machines of companies all over the world. 



And there's more.  Last Thursday, March 11th, Dave Kennedy, who's the founder of the security firm TrustedSec, tweeted:  "Wow.  I'm completely speechless here.  Microsoft really did remove the Proof of Concept code from GitHub.  This is huge, removing a security researcher's code from GitHub against their own product and which has already been patched."  TrustedSec is one of countless security firms that has been overwhelmed by desperate calls from organizations hit by ProxyLogon.  And many of Dave Kennedy's peers agreed with his sentiments.  But interestingly, not all.



Anyway, so let's back up a bit.  Ars Technica's Dan Goodin writes:  "GitHub has ignited a firestorm after the Microsoft-owned code-sharing repository removed a proof-of-concept exploit for critical vulnerabilities in Microsoft Exchange."  Anyway, paraphrasing from Dan's reporting, on Wednesday, a researcher published what's believed to be the first largely working proof-of-concept exploit for the vulnerabilities.  Based in Vietnam, the researcher also published a post on Medium describing how the exploit works.  The exploit as published had been deliberately neutered and inactivated.  But with a few tweaks, hackers would have had most of what they needed to launch their own in-the-wild RCEs.



Publishing proof-of-concept exploits for patched vulnerabilities is a standard practice among security researchers.  It helps them understand how the attacks work so that they can build better defenses.  The open source Metasploit hacking framework provides all the tools needed to exploit tens of thousands of patched exploits and is used by black hats and white hats alike.  Within hours of the proof of concept going live, however, GitHub removed it.  By Thursday, some researchers were fuming about the takedown.  Critics accused Microsoft of censoring content of vital interest to the security community because it harmed Microsoft's interests.  Some critics pledged to remove large bodies of their work on GitHub in response.



And I'll just note that it was exactly these fears of this sort of behavior on Microsoft's part that so much worried the open source community when Microsoft purchased the world's largest software repository.  Google's Tavis Ormandy tweeted the question, is there a benefit to Metasploit?  Or is it literally everyone who uses it is a script kiddie?  And of course, as we know, Tavis is a member of Google's Project Zero, who regularly publishes proof of concepts almost immediately after their patches become available.  Tavis's tweet continued:  "It's unfortunate that there's no way to share research and tools with professionals without also sharing them with attackers, but many people like me believe the benefits outweigh the risks."



Some researchers claimed that GitHub was following a double standard that allowed proof-of-concept code for patched vulnerabilities affecting other organizations' software, but removed them for Microsoft products.  But Marcus Hutchins disagreed.  He told Dan Goodin in a private PM, he said:  "I've seen GitHub remove malicious code before, and it's not just code targeted at Microsoft products.  I highly doubt MS played any role in the removal, and it just simply fell afoul of GitHub's 'active malware or exploits' policy in the terms of service, due to the exploit being extremely recent, and the large number of servers at imminent risk of ransomware."



And in response to Dave Kennedy on Twitter, who was the person originally saying "Wow, I'm shocked," Marcus tweeted, he quoted "Has already been patched."  And he said, like as if to say what:  "Dude, there's more than 50,000" - actually more like 86,000 - "more than 50,000" - so yeah, that's accurate - "more than 50,000 unpatched Exchange servers out there.  Releasing a full, ready-to-go RCE chain is not security research, it's reckless and stupid."



And a post published by Motherboard contained GitHub's official statement, which read - this is from Microsoft:  "We understand that the publication and distribution" - well, I'm sorry, it's not from, well, it's from Microsoft's GitHub, GitHub's official statement:  "We understand that the publication and distribution of proof-of-concept exploit code has educational and research value to the security community, and our goal is to balance that benefit with keeping the broader ecosystem safe.  In accordance with our Acceptable Use Policies, we disabled the gist following reports that it contains proof-of-concept code for a recently disclosed vulnerability that is being actively exploited."



And I have to say I come down on Microsoft's side and GitHub's side.  I'm sure the Vietnamese researcher was excited that he had reverse-engineered this, and he wanted to share it and crow about it a little bit.  It was the first one to be published publicly.  You could argue that the cat's already out of the bag.  I mean, look at all the attacks that are already actively exploiting this.  But there wasn't one that was publicly shared.



LEO:  Code that any idiot could use.



STEVE:  Yes.  And when you get down to the "any idiot" level, at that point, I mean, it's not like it could be much worse.  So here's the interesting thing, the shape of the patch curve.  We have a couple data points.  RiskIQ's telemetry shows that the numbers are dropping, but that the rate of drop is slowing.  Microsoft stated in a blog post:  "Based on telemetry from RiskIQ, we saw" - oh, boy, and they acknowledged this - "a total universe of nearly 400,000 vulnerable Exchange servers on March 1st."  400,000.  "By March 9th there were a bit more than 100,000 servers still vulnerable."



Then they said:  "That number has been dropping steadily, with only about 82,000 left to be updated."  And to which I said, only 82,000?  Oh, is that all?  Okay.  So 400,000 on the 1st.  Eight days later, on the 9th, 100,000.  Now 82,000.  In other words, it hasn't dropped much since the 9th, which was, what, last, oh, a week ago, last Tuesday.  So the rate of patching is exponentially slowing.  And as with so many of these servers on the Internet, I mean, there's still things out there that are scanning with Code Red and Nimda after all these years.  So there's a bunch of Exchange servers, I mean, tens of thousands, that will never be patched.  They will also be totally owned and just be used for mining cryptocurrency and lord knows what.



LEO:  Is that mostly what they're doing?  Or is it espionage?  They're reading the contents?  I mean, what is the point of this exploit?



STEVE:  What I'm wondering is, since the very first bit of this was...



LEO:  Espionage.



STEVE:  ...was access to email, yes, the very first bit was only access to email, maybe that's what gave Microsoft a sense of, well, not good, but house not on fire.



LEO:  Right.



STEVE:  On the other hand, those...



LEO:  I might disagree with that, if it's my email being read by the Chinese, by the way, but okay.



STEVE:  Yeah.  Yeah, exactly.  Well, and it's government and military email being read.  That might be a problem.  Yeah.  So but of course within a few days that was escalated to a full chain that allowed remote code execution, which is where we are today.  So it was initially exfiltrating email.  That was cute, you know, in December that that's where we were.  But by beginning of January, this thing was remote code execution.



And anyway, it is a huge mess.  I would argue that it's a mess that could and should have been avoided, and that the takeaway has to be, I mean, Microsoft doesn't suffer from being undersized and under-resourced.  So anyway, Leo, it is a mess, and it's a mess that could and should have been avoided.  If any lesson comes from this, it's got to be that Microsoft needs to get their act together.  They are certainly not a resource-constrained organization.  They can throw as much money at this as they need to.  Certainly this will have been hugely expensive in terms of reputation damage.  So they just need to be able to respond in a timely fashion.  Five years ago, this would have been fine.  They could have done it for the next month's patch.  But now everything is moving way faster, and this is the consequence of a not-difficult-to-exploit widespread remote code execution.  It is a catastrophe for the world at this point.



LEO:  Yeah, yeah.



STEVE:  And I don't think we've begun yet to account for the second order damage that has been done to the companies that have been affected.



LEO:  Oh, gosh, no.  And, you know, if you have 80,000 Exchange servers still unpatched, you would also realize that there's going to be tens of thousands of Exchange servers that are compromised that will always be compromised. 



STEVE:  Right.



LEO:  And I'm sure the Chinese are counting on that.  That's like, great, you know, we can see everything going on in the U.S. for the rest of time, rest of eternity.  



STEVE:  Yeah.



LEO:  What was the stat?  How much of this was U.S.?  Most of it; right?



STEVE:  Yeah.  The majority is U.S.



LEO:  Yeah.  We do this show every week.  And good news, there's always something to talk about.  Maybe next week we'll do FLOC.



STEVE:  Hope so.  We'll try.



LEO:  If something else doesn't break.  You probably didn't notice this, but yesterday Azure authentication was offline for most of the day.



STEVE:  Ooh.



LEO:  So some of our Azure stuff stopped working.  A lot of people who use Azure authentication for Office or whatever couldn't get on.  It's happened before.  Took them till 7:00 o'clock last night to fix it.  So they've got other things, other things to work on.



Steve Gibson, he's at GRC.com.  That is a good place to go.  There's lots of good stuff there.  Of course lots of good free stuff.  This podcast, for one.  He's got 16Kb audio, 64Kb audio.  He's even got a human-written transcript.  Elaine Farris does a great job writing this all down so you can read along as you listen.  I find it useful for searches because if I search Security Now! and a topic, I go right to it because those transcripts make it so easy to find.  That's at GRC.com.  When you're there, you might want to pick up a copy of SpinRite, the world's finest hard drive maintenance and recovery utility.  Not just hard drives, SSDs now.  Does a great job.  And 6.1 is on its way.  So if you buy 6.0 now, you'll get 6.1 free.  And you'll also get to participate in its development cycle.  ShieldsUP! is there, lots of other free stuff.  GRC.com.



You can even send Steve some feedback, GRC.com/feedback for the form.  Although most people I think use Steve's Twitter handle, @SGgrc - here, I'll put it up on the screen here.  His DMs are open so you can DM him.  You can slide into his DMs, if there's something you want to say.  You should also follow @SGgrc on Twitter.  We have 64Kb audio and video on our site, TWiT.tv/sn.  You can also - there's a YouTube channel.  You can also get it on your favorite podcast client, audio or video.  Pick the one you want, subscribe, you'll get it the minute it's available.  We do Security Now! every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC now because we jumped ahead a little ahead of you guys, 20:30 UTC.  I guess that's everything I need to say.  Steve, have a wonderful week.



STEVE:  Thanks, my friend.



LEO:  And thanks for being here.  We'll see you next week on Security Now!.



STEVE:  Right-o.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.














GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#811

DATE:		March 23, 2021

TITLE:		What the FLoC?

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-811.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we briefly, I promise, catch up with ProxyLogon news regarding Windows Defender and the Black Kingdom.  We look at Firefox's next release which will be changing its Referer header policy for the better.  We look at this week's most recent RCE disaster, a critical vulnerability in the open source MyBB forum software, and China's new CAID (China Anonymization ID).  We then conclude by taking a good look at Google's plan to replace tracking with explicit recent browsing history profiling, which is probably the best way to understand FLoC (Federated Learning of Cohorts).  And as a special bonus we almost certainly figure out why they named it something so awful.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a new fix for the Microsoft Exchange Server flaw.  This one's automatic, thanks to Microsoft.  We'll also take a look at some nice new features in Firefox 87.  You can get it right now.  And then, what the FLoC?  We'll take a look at Google's proposal for replacing third-party cookies.  Is it better?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 811, recorded Tuesday, March 23rd, 2021:  What the FLoC?



It's time for Security Now!, the show where we cover your privacy, your security, your safety online with this guy right here, Steve Gibson from GRC.com.  Hi, Steve.



STEVE GIBSON:  Coming to you via Zoom for the first time ever.



LEO:  Yeah.



STEVE:  I know that Alex has been doing this on MacBreak, and everyone's been saying, wow, look how good he looks.  Now, okay, I don't look as good as Alex, but the picture is sharp.



LEO:  Yeah.  Skype has been going downhill, to be frank.  And we tried some other alternatives, including an open source WebRTC solution called OBS.Ninja.  And then Alex said, "Why are you trying everything else?  I've been using Zoom all year," for all his stuff.  You know, he does a daily eight-hour thing called Office Hours and stuff.  And he says it's the best.  So I trust Alex.  If anybody knows streaming, it's Alex.  So we're giving it a shot.



STEVE:  Well, John sent me a link a couple hours ago.



LEO:  Latency's low; right?



STEVE:  Yeah, yeah.  And it just, you know, connected right up.  And I had it - I think you and I, I guess did we use Zoom when we did that last TWiT special?  We did the...



LEO:  Oh, for the other, the panel?



STEVE:  Yeah, the panel.  I think...



LEO:  Did we?  Maybe we did.



STEVE:  Because I had - I don't know why I would have Zoom on this little machine that I use only for our podcasts.  It's like my TWiT box.  So anyway...



LEO:  Must have used it sometime, yeah.



STEVE:  We are at Security Now! Episode 811 for March 23rd.  Oh, three days before I turn 66.



LEO:  Happy birthday.



STEVE:  Thank you.  And we're finally going to get to talk about the topic I've had on our radar for a couple weeks, except that ProxyLogon bumped it off for the last two weeks because we had  to talk about that.  And that's this so-called, god, the worst-named abbreviation ever.  Actually, in discussing this we're going to figure out why it's called FLoC.



LEO:  Birds of a feather FLoC together.



STEVE:  I realized why it happened.  And it's like, oh, my god.  Then they had to reverse engineer what this horrible abbreviation stands for.  So we got Federated Learning of Cohorts, of all things.



LEO:  Of course.



STEVE:  Anyway, we're going to briefly first - I promise briefly - catch up with ProxyLogon news regarding something Microsoft has done that's good with Windows Defender, and also something not so good involving the Black Kingdom.  Then we look at Firefox's next release, which will be changing its Referer Header policy for the better.  We look at this week's most recent RCE, you know, remote code execution disasters; a critical vulnerability in the open source MyBB Forum software; and China's new CAID, C-A-I-D, which is their - it stands for China Anonymization ID.  Uh-huh.  Good luck with that.



Then we're going to conclude by taking a long look and a deep dive into Google's plan to replace tracking with explicit recent browsing history profiling, which is probably the best way to understand FLoC, Federated Learning of Cohorts.  Oh, and, yeah, as I said, we're going to figure out why they named it that.  We've got a surprising Picture of the Week which I experienced, and so I took pictures of it.  And I got like a surprise shout-out from an ex-longtime Microsoftie by the name of Dave Plummer, who is most notable for having written Task Manager.



LEO:  Wow.



STEVE:  So some fun things to talk about on this podcast.



LEO:  That'll be fun.  Oh, all right.  Picture of the Week time with Mr. G.



STEVE:  Java has been a mixed blessing.  There was a time when the advice was you really didn't want your browser to be running Java apps behind your back, you know, Java being different and completely unrelated.  Unfortunately there's a name collision between it and JavaScript.  The two have nothing to do with each other from a technology standpoint.



Anyway, like for whatever reason, I saw the little orange coffee brewing icon on my tray a few days ago.  And I thought, what?  I've not used Java like forever.  I don't even know why I have it on my machine.  Actually, I think it was because of a utility that I used to use to extract from my TiVo when I was using TiVo, KTTMG or KMTTG or something like that.  It was like TiVo to Go something.  But it was a desktop app.  I think that's what it was that used Java.



Anyway, so I click on the little orange icon, and up comes this dialog:  "Please remove unused versions of Java."  And it says:  "It appears that you have not used Java on your system in over six months."  That's right, I switched to Roku.  No more TiVo.  And it says:  "We recommend that you uninstall it by clicking the remove button below."



LEO:  Wow.  That's unheard of.



STEVE:  I know.  I thought, really?  I'm very impressed.  And they said:  "If you later decide you need Java, you can reinstall it from Java.com."  It says:  "If you wish to keep Java on your system, please update it by clicking this update button."  So the point is there was an update, but it looked and saw, well, okay, we've got something new, but this guy's not using it.  So it'd be better if he just took it out.



So when I clicked on "Remove" because I wasn't using it, up comes the next one, with a yellow caution triangle:  "Out-of-date Java versions detected."  And then it said:  "Keeping out-of-date Java versions installed on your system may present a security risk."  And so then it listed the one I had, Java 8 Update 271.  And it says:  "Click Uninstall to uninstall the selected Java versions."  And I just thought, wow, you know, got to give them some credit, where I've given them enough heat over the years.  So when something like this happens where they're just being proactively security-conscious, I thought, okay, props.  So very cool, Oracle.  Good move.



Okay.  Before I get into this, because I'm afraid I'm going to forget, Dave Plummer is, like, an original Microsoft, now retired, developer who was there for MS-DOS and Windows 98.  He has launched a YouTube channel, Dave's Garage.  And so like the first three episodes:  "The Secret History of Windows Task Manager Origins," "The Secret History of Windows Task Manager Technology," "The Secret History of Task Manager Source."  And actually the fourth one, I'm curious.  I haven't watched it:  "The Secret History of Microsoft Bob."



LEO:  Wow.  I knew he had secrets.



STEVE:  I don't know where that came from.



LEO:  Wow.



STEVE:  Then "The Secret History of Windows Format FAT-32 Limits," which would kind of be interesting.  But then we've got Hello, well, actually there was "Hello Windows!  Retrocoding 'Hello World' for Windows with Dave," which apparently he did in C.  And then I guess before that, or no, even more recently, I'll be interested again to see what he says:  "Linux Versus Windows, Round 1, Open Source versus Proprietary, from a Retired Microsoft Dev."  Again, interesting to know what he has to say.



Well, the one that happened yesterday was "Hello Assembly!  Retrocoding the World's Smallest Windows App in x86 ASM."  You know, assembler.  And I learned about it because apparently a lot of our listeners have already figured out about Dave Plummer and are watching it.  And they're going along, watching it, and if you were to jump forward, Leo, and turn audio on, to 28 minutes, go to 28 minutes, you'll catch the shout-out.



LEO:  Right at the end.  It's a 29-minute thing here.



STEVE:  Yup.



DAVE PLUMMER CLIP:  3,072 bytes.  I'm pretty satisfied with 3K, but can anyone go smaller while still preserving all the functionality?  There were a number of optimizations that I didn't take, such as tail call elimination, smaller strings, eliminating some air checks and so on.  To me, anything under 4K smells like victory, but I'd be curious to see if anyone can go smaller than that 3,072.



LEO:  I know someone who can.



DAVE PLUMMER CLIP:  If we run the app, we find that it indeed works perfectly.  It paints our greeting dead center in the main client area.  It does it transparently over the gray background...



LEO:  Wow, he uses the Windows UI.



DAVE PLUMMER CLIP:  ...properly when we resize the window in either dimension.  If we click on the Close widget or select Close from the system menu, the application shuts down, just as it was designed to do.  And that is that, a complete working Windows application in 3K.  Is it the world's smallest Windows app?  I believe it is.  And unless and until someone shows me a working demo that is less than 3,072 bytes, I stand by it.  Notify Steve Gibson that there's a new king in town and bring me his crown and scepter.  I hope you've enjoyed this episode of...



LEO:  No, there's not.  I thought of you.  I was watching - so Harvard has an Introduction to Computer Science CS50, very well known.  I'm using it to mentor a high school senior in programming.



STEVE:  Oh, cool.



LEO:  Yeah, it's a really great class.  It's actually the number one most attended class at Harvard, 800 students every year.  Very famous.  And at one point they talk about assembly language, which they say, "People used to write code in assembly language.  Not anymore."  And I thought, maybe not.  Maybe there's at least two now I know, yeah.  I'm going to watch that.  It looks fun, yeah.



STEVE:  It really was.  And there's an entire, you know, he shows you an entire Windows app in assembler.  And so I thought, okay.  So having thrown down the gauntlet, I went over, and I replied.  I said: "Well, Dave did a terrific job with his smallest possible Windows app, except it isn't."  I said: "It's small, yes.  And he clearly made his point.  As he was coding, and I was noting things that could be done better, meaning smaller, I was planning to just let them pass.  Again, Dave did a great job.  But then I got name-checked.  Hold on a second."



LEO:  Yeah, big mistake.



STEVE:  "Now, here's the problem.  I know that Dave could make his smaller if he really needed to, if he thought about it.  For example, I never compare a register to zero.  That's wasteful.  But Dave did it several times in his code.  When checking a function return for zeroness, Dave compared EAX to zero.  That generates the bytes 83F800.  And it will set the zero flag if EAX equals zero.  So it definitely works.  But there's a smaller way to do the same thing.  The more efficient way to check a register for zeroness is to OR that register with itself."



LEO:  Right.



STEVE:  "That generates the bytes 0BC0.  Yeah, it's only one byte smaller.  But it's also 66.6% the size.  And it's all about pride in one's code."  And I finished:  "As many of you know, I'm deep into updating SpinRite at the moment, still going strong on 16-bit DOS.  So I'm going to let Dave's challenge stand and keep my focus.  And again, we know that Dave could have also made it smaller if he really wanted to.  All the best, everyone."



LEO:  Is it OR or XOR?



STEVE:  XOR is the right way to zero a register.



LEO:  Oh, okay, right.



STEVE:  That's better than moving zero into it.  And really you could AND or you could OR the register with itself.  Either has the same effect of just setting the status and not changing the register.



LEO:  Yeah, that's awesome.



STEVE:  But anyway, I made it this week's shortcut.  So for anyone who wants to jump to it, grc.sc/811, since this is Episode 811, grc.sc/811.  And he's a neat guy, I mean, he's put in his time.  He's worked for Microsoft forever, wrote Task Manager, and has lots of experience and opinions.  So anyway, just a counter shout-out to Dave.



Okay.  So the latest update on the ProxyLogon fiasco is from Microsoft last Thursday.  They wrote:  "As cybercriminals continue to exploit unpatched on-premises versions of Exchange Server 2013, 2016, and 2019" - and also apparently 2010, if anyone has something that's 11 years old.  They said:  "...we continue to actively work with customers and partners to help them secure their environments and respond to associated threats.  To date, we have released a comprehensive Security Update, a one-click interim Exchange On-Premises Mitigation Tool for both current and out-of-support versions of on-premises Exchange Servers, and step-by-step guidance to help address these attacks.



"Today" - and this is the reason for their posting - "we have taken an additional step to further support our customers who are still vulnerable and have not yet implemented the complete security update.  With the latest security intelligence update, Microsoft Defender Antivirus and System Center Endpoint Protection" - which is part of the enterprise version of that - "will automatically mitigate" - and they have a CVE number, the main entry point - "any vulnerable Exchange Server on which it is deployed."



LEO:  Oh, that's a good idea.  That's a very good idea, yeah.



STEVE:  Yes.  "Customers do not need to take any action beyond ensuring they have installed the latest security intelligence update, if they do not already have automatic updates turned on."  So again, this is a win.  I was like, for a moment I was puzzled about this.  If a system hasn't had its special early release emergency updates applied, nor the monthly March patches, then how does this help?  But their little advertisement graphic in their posting makes their intent more clear.



They said:  "Automatic mitigation with Microsoft Defender.  Immediate mitigation for threats taking advantage of Exchange Server vulnerabilities."  Then they said:  "The latest version of Microsoft Defender Antivirus helps mitigate Exchange Server attacks by performing these two actions:  Automatically mitigate that CVE via a URL Rewrite configuration" - which I'll explain in a second - and "Scan the server and reverse changes made by known threats."



Okay.  So that's really good.  Clearly, the point here is, A, that it's one more thing they can do, sort of by way of apology to the world, so that no one can say they didn't do something that they could have done; and, B, unlike the monthly patch updates, which require an administrator's intervention and permission for a full server reboot, the use of Windows Defender, as we know, will eventually be automatic.  I mean, I'm sure it's on everywhere.  It's unclear to me how often Microsoft OSes check for Defender updates by default.  I spent some time trying to get something definitive, and I couldn't find anything.  But when I looked on my own system's security widget last night, Defender had just run 90 minutes before I had checked.



LEO:  Yeah.  It's pretty regular, yeah.



STEVE:  So it's presumably updating itself all the time.



LEO:  Yeah.  It's pretty regular.



STEVE:  And so what this means is on systems that have, like, the administrators wandered off and like are on vacation or something...



LEO:  Mm-hmm, exactly.



STEVE:  ...then this will come along.  It will close the entry and scrub what it can.



LEO:  Yeah, my last Defender scan was nine minutes ago.  So, exactly.



STEVE:  Right, right.



LEO:  They do it all the time.



STEVE:  Right.  And so I mentioned that the vulnerability would be neutered, but not removed.  As we know, removal requires the replacement of DLLs that are resident in RAM and have been invoked by low-level services.  They cannot be replaced without a full system reboot and reload.



But Microsoft's announcement mentioning the use of a URL Rewrite configuration is interesting.  URL Rewriting is an in-line, pre-server, pattern-matching filter that's able to transmute any matching URL into another.  So they're really using Defender to do much more in this instance than its normal scan and sequester.  It's tweaking the configuration of Exchange's IIS web server, and maybe it looks first to see if the patches have been installed and, like, leaves it - presumably, if there's no vulnerability, it doesn't.  But I would bet that it's like, when it's vulnerable, it will add preemptively, proactively add a new URL Rewrite rule to IIS, their web server, to prevent the still-exploitable underlying IIS server from being exploited.  And then it goes beyond even that by seeking and reversing known malicious changes that have been made.



So they're essentially using Windows Defender, which as we know checks for updates frequently, as a no-boot mitigation for Exchange Server systems that are critically and chronically unadministered.  So this is clearly, as we've said, a good move on their part.  It will allow Exchange Server to at least partially be brought back from oblivion without any administration.  And unfortunately this arrived on the 18th of March, which was 16 days after the emergency patches went public, which triggered the explosion in scanning and attacks.  And it's a full week after the mass scanning was seen that we talked about last week.  So, but still, like, we know, what was it, 86,000 still unpatched servers last week, and an exponential drop-off in the rate of patching occurring.



So again, good move on their part.  It's a little bit actually building new barn doors that are much stronger after the horses have escaped.  But at least they're there now.  And again, I really hope, truly hope that Microsoft is taking a serious inward look at what internal systems failed in order for this to have happened.  As we've been saying, and as all recent experience shows, it's no longer sufficient to wait a few months, as it once was, two years ago, after being notified of a serious vulnerability.  The instant the knowledge exists in the world, the race is on.  And we're now seeing that more and more.



Also on the ProxyLogon front, we have Black Kingdom.  The other interesting bit of news is that the original DearCry ransomware campaign, which was the first to impact vulnerable ProxyLogon servers, has now been joined by the so-called Black Kingdom ransomware.  And we're not going to go into any profound detail about it.  As we know, they're all pretty much the same.  They're just scanned differently.  They have different patterns.  And so the various security firms who see them go, oh, look, we haven't seen this one before.



Over the weekend, just two days ago, our friend Marcus Hutchins of MalwareTech blog tweeted that another threat actor was now compromising Microsoft Exchange Servers via the ProxyLogon vulnerabilities.  Notice that means that last weekend there were still plenty available to be compromised.  He said, based on logs which his honeypots were producing, he said that the threat actor was employing the chained Exchange Server vulnerabilities  to execute a PowerShell script that downloads this Black Kingdom ransomware from yuuuuu44[.]com - that's five U's - then pushes it out to other computers across the network.



And this was confirmed by submissions to the ransomware identification site ID Ransomware that we mentioned last week.  That's Michael Gillespie's site.  He told BleepingComputer that his system has seen over 30 unique submissions of this new Black Kingdom ransomware campaign, with many submitted directly from mail servers.  So this is the tendency he's now seen for the last several weeks.  When encrypting devices, the ransomware encrypts files using random extensions and leaves a ransom note named "decrypt_file.txt," although Hutchins states that he saw a different ransom note named ReadMe.txt which also had slightly different content.  So it looks like they've been tweaking their ransomware a little bit as they've been going on.



In browser news, Firefox will be adopting a new privacy-enhancing Referrer Policy, which I'm glad to see.  We're all currently on Firefox 86; 87 will bring this update.  We've talked about the misspelled web browser "referer" - R-E-F-E-R-E-R - header often.  It's of course supposed to be R-E-F-E-R-R-E-R, but it's not.  It was misspelled in the original specification and implementations, so that's what we have today.  It's long been controversial because it contains by design, you know, the original architects of the web thought, hey, when a query is sent for some other asset from a web page, it would be really handy for that asset being queried to know who's asking.



So the referer header in a web browser's query contains the URL of the page that referred its visitor to the resource being requested.  That could be another web page, a tracking beacon, or anything that the browser fetches from the referring page.  And, you know, once upon a time that would be a useful thing to know.  But not surprisingly, the referer header has become a source of significant tracking information.  Mozilla aims to trim its feathers back a bit.



And if you think about it, remember, like in the really bad old days, you could put a username and password in the URL.  There was a syntax for that.  And there was something I did for SQRL where one of the things that has always been adhered to is nothing after a pound sign had ever been in a referer.  So you can put things that you absolutely don't want leaked behind a pound sign; but of course lots of other information like the query tail, all that stuff after the question mark.



So, for example, search engines often use the whole long search phrase following a question mark in the URL.  Well, what that means is that everything that the browser on that page goes out to request - ads, beacons, everything - gets the referer header that until this change would contain that query tail, meaning they know what you searched for in order to get to the page which has then requested all this other stuff.  So obviously this is a huge privacy mess.



Mozilla has announced that the next release of Firefox will introduce a more privacy-focused default Referrer Policy to protect Firefox users' privacy.  And it's about time.  The web browser will, from 87 on, automatically trim user-sensitive information like the path, which is great because it's no one's business, and the query string information, which is accessible otherwise and has been historically from the Referrer URL.



Mozilla's spokesperson said:  "Unfortunately, the HTTP referer header often contains private user data.  It can reveal which articles a user is reading on the referring website, or even include information on a user's website account."  And of course it's actually somewhat surprising and disturbing to see just how much potentially useful to bad guys information is inadvertently leaked by browser referer headers.  An examination of web server logs shows referer headers often containing, among other tidbits, internal host names of government and enterprise entities that most likely should never be public.  Yet this mechanism publishes them, just sort of blindly, without thinking.  And of course bad guys could easily use such information to their advantage.



The first appearance of an explicit Referrer Policy appeared in our web browsers, it varied by browser, but it was around 2016 to 2018, depending upon which browser implemented and which browsers followed.  And back then, the web was still largely a hybrid of HTTP and HTTPS.  So there was a concern that resources being accessed over the less secure, certainly it was unencrypted and unauthenticated HTTP, should have a restricted view of what was going on on any HTTPS page.  So the Referrer Policy then was known as "no-referrer-when-downgrade."  That was enacted.  So any query to an HTTP page or asset would not have any referer header.  It was just eliminated.



So the idea then was that less secure resources would receive much less information about the page requesting whatever their asset was, if that page was protected by HTTPS.  So anyway, today Mozilla considers the no-referrer-when-downgrade policy just to be a relic of the past because, as we know, today's web looks much different.  We're finally on a path to becoming HTTPS-only.  And browsers are taking steps to curtail information leakage across websites.



So Mozilla has decided that it's time for Firefox's default Referrer Policy to be updated.  Starting with 87, it will be using what's known as "strict-origin-when-cross-origin," which will trim sensitive information accessible in the referrer's URL.  So, for example, where previously Firefox's referer header might be HTTPS, the referer header value would be https://www.example.com/, and then the full path, and the question mark, and then the query.  Now, under Firefox 87, when the request is being made to any other domain, the referer header's value in that query from the browser will stop after example.com.  That's it.  Period.  No path, no query.  So significantly more privacy.



And really, when you think about it, it's a little jarring that this is only happening now.  It's one of those things that, wow, you'd have thought this would have been done 10 years ago.  But the problem is these sorts of things tend to break stuff.  So pulling back to make privacy-centric changes is something that arguably needs to be done carefully so that things are not broken.  So anyway, this new policy will affect everything - all navigational requests, redirection requests, all of a page's subresources, images, styles, scripts, everything, to provide a significantly more private browsing experience.  And the best news is we don't have to do anything.  This just gets changed in Firefox for us with the next release.  So yay.



LEO:  Which is out now.



STEVE:  Is 87?



LEO:  Yeah.



STEVE:  It wasn't last night.  Oh, cool.  I did a check and an update, and I was at 86.  



LEO:  You made me check.  And I said, oh.



STEVE:  New, cool.  So this week in RCE disasters, remote code execution.  The week before last, in the long shadow cast by the ProxyLogon vulnerabilities, the Seattle-based firm F5 Networks, quietly but necessarily, disclosed patches for critical 9.8-scale vulnerabilities, five in all, in their so-called Big-IP and Big-IQ devices.  March 10th, F5 released an advisory stating that the REST interface of the iControl management interface is vulnerable to an authentication bypass, which is not something you ever want to hear in anything that is publicly exposed on the Internet, as these are, which includes remote code execution.



No detection rules or artifact information was initially provided by F5, and no public exploit was known at the time of F5's advisory publication.  This potentially gave sysadmins time to patch, and blue teams the space to research and implement detection capabilities so that they could get ahead of the bad guys.  But in the week that followed, several researchers posted proof-of-concept code after reverse engineering the Java software patch in BIG-IP.  And that's all it took.  The proof-of-concept code turned the exploitation of the vulnerability from something requiring some real skill into low-hanging fruit.  And sure enough, last week the scans and exploitation began.



Last Friday, on the 19th, Bad Packets tweeted that "Opportunistic mass scanning activity detected from the following hosts checking for F5 iControl REST endpoints vulnerable to remote command execution."  There was one IP at 112.97.56.78, located in China.  There's one, 13.70.46.69 in Hong Kong.  And the third, 115.236.5.58, also in China.



So it seems to me what we're seeing is that it may be necessary for the industry's security researchers to reconsider the timing of their release of proof-of-concept code, and to withhold their disclosures, not until the patch has been released, but at least until non-script kiddies have themselves demonstrated that the vulnerabilities have been successfully reverse engineered.  That is, hold the proof of concepts until the cat's already out of the bag, until we see exploits in the wild so that it's no longer the case that, as a security researcher, you have actually enabled that to happen.  I would argue that no ethical researcher wants to have their proof-of-concept code used as-is, in the wild, wide-scale, devastating and damaging attacks.  Yet that's what we're now seeing.



So I think maybe it's going to be necessary, just as a consequence of the dynamics of today's world, to hold onto these things longer.  I know that the security researchers are excited to share, like hey, we reverse engineered this from the compiled Java.  We know what it was.  But yeah, but script kiddies can't do that.  So why help them?  That just, you know, that doesn't make any sense.  And the other thing we know is that just having a patch released is way different than having a patch applied.  It's the application of the patch that then makes a proof-of-concept release okay.  But release and patch, or release and application, are unfortunately widely spaced events.



Speaking of which, MyBB, the free and open source forum software  MyBB, was originally MyBulletinBoard.  Then it was shorted to MyBBoard, and now finally to MyBB.



LEO:  Probably because no one knows what a bulletin board is anymore.



STEVE:  Exactly.



LEO:  Kids, these used to be called "forums."  Before there were forums, there were blackboards.



STEVE:  That's right.  That's right.  They're not going to be able to make it any shorter than MyBB.



LEO:  MyBB, yeah.



STEVE:  Yeah.  So of course it's written in PHP with a...



LEO:  I used to use MyPhpBB.  Is that the same?



STEVE:  Oh.  No, I don't think it is.



LEO:  Okay.  There's another one.



STEVE:  There's that, too.  That's another one.  



LEO:  Okay.  All right. 



STEVE:  This one is written in PHP with a MySQL database backend.  The good news is it's not massively popular.  It's got around 2,100 potentially vulnerable domains showing MyBB present.  Until patches were released on March 19th, it had a pair of critical vulnerabilities that could be chained to achieve remote code execution without the need for prior access to a privileged account.  The flaws were discovered by two independent security researchers, Simon Scannell and Carl Smith, and they were reported to the MyBB team on February 22nd.  And as I said, on March 10th, an update was released to close the holes.  So that's a nice, you know, February 22nd, so what, 18 days?  No, February only has 28 days.  So like a little over two weeks; and, bang, we now have a hole closed.



So according to the researchers, the first issue, a nested auto URL persistent cross-site scripting vulnerability, stems from how MyBB parses messages containing URLs during the rendering process, thus enabling any unprivileged forum user to embed stored cross-site scripting payloads into threads, posts, and even private messages.  That's not good.  MyBB's advisory said:  "The vulnerability can be exploited with minimal user interaction by saving a maliciously crafted MyCode message on the server," they said, "for example as a post or private message, and pointing a victim to a page where the content is parsed," which is trivial to do.



The second vulnerability is an SQL injection in a forum's theme manager that could result in an authenticated remote code execution.  A successful exploitation occurs when a forum admin with the "Can manage themes" permission imports a maliciously crafted theme, or a user for whom the theme has been set visits a forum page.  So by chaining these, it's pretty simple to do.  As a result, the researchers' write-up, they said that:  "A sophisticated attacker could develop an exploit for the stored cross-site scripting vulnerability and then send a private message to a targeted admin of a MyBB board.  As soon as the admin opens the private message on his own trusted forum, the exploit triggers.  An RCE vulnerability is automatically exploited in the background and leads to a full takeover of the targeted MyBB forum."



The researchers waited eight days after the patches were made available to publish their work, which included, unfortunately, a complete soup-to-nuts description and discussion, with examples, of the exploit.  So while previously an attacker may have needed to be sophisticated, as they said in their write-up, when armed with their complete and detailed how-to, not so much.  Was eight days long enough for them to wait?  Did every instance of MyBB get patched and updated during the interim?  Well, we can certainly hope so.  But we pretty much know that that won't have happened.  So maybe MyBB is not big enough a target to cause much pain.



On the other hand, if any high-value sites are running MyBB, I'll bet you that state actors have built themselves a database that cross-references all of the valuable targets with all of the publicly exposed technologies they have.  For example, there's just no way that China and Russia, they seem to be where these attacks are coming from.  I mean, and not just at the U.S., but globally.  I'll bet you that their teams have a database such that when a problem is announced by F5, they type F5 into their database, and it tells them every valuable high-profile target using F5 hardware.  And they immediately launch attacks based on the reverse engineering of that vulnerability.  That's the world we're in today.



So if there were any high-profile users of MyBB, and this release came out, I'll bet you that it didn't take long for an attack to get launched.  That's, again, isn't that what any serious attacker would do?  They would build a reverse index of all the technologies used by all the targets they care about.  And if we learned anything from the last few months of attacks, certainly from the SolarWinds, where we saw a seriously committed threat actor who we believe to have been state-sponsored, we saw them do absolutely everything right.  Well, part of doing it right is building an index of who's using which technologies on the Internet.  That has to exist.



So I couldn't resist, Leo, calling this one "CAID is able."



LEO:  As in Cain and Abel, all right, I got it, I got it.



STEVE:  Of course.  I know you would.  CAID, C-A-I-D, is the China Anonymization ID, which is an indirectly Apple-inspired, well, because it's a workaround, to Apple's forthcoming plans to dramatically tighten up the tracking allowed by Apple Store apps.  And this refers to what you were just talking about, about the recent change in Apple policy that forced Google to disclose what their stuff was doing.  And oh, boy...



LEO:  What a list.



STEVE:  ...is it a laundry list of, like, in fact, I was thinking of putting a picture in the show notes.  But in order to show it all...



LEO:  More than one page.



STEVE:  ...the print has to be so tiny that you can't read it.  So I thought, uh, no.  Okay.  But I thought this would be the perfect segue for this week's discussion, which we will conclude with, of Google's FloC initiative.  Okay.  So we'll be coming back around to that in a few minutes.  But eight days ago, on the 15th, the privacy-focused DuckDuckGo search engine tweeted.  Their tweet reads:  "After months of stalling, Google finally revealed how much personal data they collect in Chrome and the Google app."  And DuckDuckGo says, "No wonder they wanted to hide it."



So they said, and of course we know where DuckDuckGo is coming from; right?  They actually showed this as a side-by-side, and I do have the image from their tweet.  The very left-hand little thing shows DuckDuckGo.com, and there's like, nothing there.  They're proudly collecting nothing.  And then they have Google Chrome, and then next to it Google apps in general, with the laundry list of all the stuff, all the categories that they're collecting.



And on the 'Net, I heard this, or I saw this referred to as the "nutrition label," meaning it's sort of like the standardized list of ingredients which all entities are now required to put on a can of something, where all the ingredients they contain listed in the order of how much of that they have, from most to least.  And in many cases, of course, how much percentages of this and so forth.  Anyway, that's what Apple has created, you know, a standardized means of sharing with users what the apps in the App Store are collecting, what information, what privacy and tracking-related stuff they're collecting.



So anyway, I thought this would be a useful preamble for our discussion of Google's planned FLoC, their Federated Learning of Cohorts.  And we should note that DuckDuckGo's comparison is unfair.  They are not offering 15GB of free, fast, and hyper-robust cloud storage.  Nor do they provide the number one by far most popular free email service in the world.  Gmail has 1.5 billion with a "b" users; whereas Outlook is in the number two spot with 400 million, and Yahoo! Mail, of all things, somehow holds onto the number three position with 200 million.



And when I look at the amount of spam Gmail detects and eliminates for me hourly, even though it serves as my catchall throwaway email account, they're doing a phenomenal job for me.  Not to mention that I still prefer Google's search, and that I get Google docs and spreadsheets and so much more for free.  Or if not exactly technically free, at least without me needing to transfer any of my cash, which I'd much prefer to give to Starbucks.  And this is obviously a bargain that I'm not alone in being quite happy with.  I really don't give it a second thought, nor does most of the world.



But as we also know, there is also a creepy side to this.  For many of us, just the idea that we're being tracked and profiled  even if it's against our will and wishes, against all of our efforts to say no  is enough to give us pause.  So first of all, what is Google's big reveal that the DuckDuckGo people got themselves all lathered up over?



This transparency is all being driven by Apple.  And what recently happened is that, after months, I guess DuckDuckGo was saying three months, following Apple's December 2020 announcement of its App Store policy changes, Google's finally updated its App Store apps to bring them into compliance.  I'll fill in some background about this in a minute.  But the most interesting data point to me was that the forthcoming iOS v14.5, with iOS 14.5, all apps will be required to explicitly request and receive their users' informed consent before they will be allowed to use the device's Apple-provided advertising identifier, known as the IDFA, the ID for Advertisers, which is part of a new framework which Apple calls ATT, which stands for App Tracking Transparency.



So here's the data point:  An analysis by the mobile advertising firm AppsFlyer found that, once several third-party developers had integrated Apple's ATT system into their apps, thus making clear to those apps' users what was going on and requesting permission to share their anonymous identity with other Internet services  in other words "tracking," while steering well clear of that term, they didn't call it that, but everyone knows  fully 99% of users chose not to give those apps that permission which the apps were requesting.



In his speech, which was delivered on January 28th during the Computers, Privacy and Data Protection conference, Tim Cook, who as we know of course is Apple's CEO, said:  "Technology does not need vast troves of personal data, stitched together across dozens of websites and apps, in order to succeed.  Advertising existed and thrived for decades without it.  If a business is built on misleading users, on data exploitation, on choices that are no choices at all, then it does not deserve our praise.  It deserves reform."



Okay.  So Apple, who sells hardware and privacy, is tightening the screws on those who adamantly insist that tracking and profiling are worth it; that it needs to be allowed to happen; that it's unfortunate, when users are informed and given a choice, they decline to be profiled and tracked, but that needs to be done anyway.



So clearly this is going to become a fraught issue.  Just last Wednesday, France's competition regulator rejected calls from advertising companies and publishers who wanted them to block Apple's ATT on grounds of antitrust, stating that Apple's ATT privacy initiative "does not appear to reflect an abuse of a dominant position on the part of Apple," though the regulator did say that it would continue to investigate the changes to ensure that Apple does not apply less restrictive rules for its own apps.  In other words, if Apple's going to do this, then it needs to play by its own rules.  And of course that's, okay, Apple, because Apple is selling privacy as one of their products, or a clear feature of their products and platform, we don't expect that to be a problem for them.



So where there's a will to track, and there's no lack of enabling technology and innovation, there will always be a way.  The Financial Times recently reported that the Chinese Advertising Association (CAA) has developed an identifier it calls the China Anonymization ID (CAID) that's aimed at bypassing Apple's new privacy rules, and that is to bypass the need for or use of the IDFA, this ID for Advertisers.  The use of China's nascent CAID would enable companies to continue tracking users without having to rely on Apple.



LEO:  So wait a minute.  It's not a China Anonymizing ID.  It's a China Deanonymizing ID.



STEVE:  This is China tracking.  The China tracker.



LEO:  That's hysterical.



STEVE:  I know.  And of course it's not going to ask for users' permission.



LEO:  No.



STEVE:  Because users say no. 



LEO:  Yeah.



STEVE:  If you ask people, do you want to be tracked, uh, gee, hmm, let me think.  So get this, Leo.  The Chinese advertising technology firm with the not-so-subtle name TrackingIO said that CAID, this C-A-I-D, "has the characteristics of anonymity and decentralization, does not collect private data, only transmits the encrypted result, and the encrypted result is irreversible" - maybe that means hashed.  Anyway, "...which can effectively protect the privacy and data security of the end user."  They said:  "The decentralized design allows developers to be more flexible to meet business needs."  Okay.  Whatever that means.  You know, it's Chinese translated into English.  Actually it's a pretty good translation.



They added: "Because CAID does not depend on Apple IDFA and can generate device identification independently of IDFA, it can be used as an alternative to device identification in iOS 14 and form a supplementary solution when IDFA is not available."  Right.  So although CAID is not yet formally implemented, it's believed to be under testing by some of China's largest tech companies who think it's a pretty good idea.  And that includes ByteDance and Tencent and several foreign advertising companies that have already applied on behalf of their Chinese divisions.



And following these reports that companies are readying workarounds in an effort to bypass Apple's forthcoming notification and consent requirements on tracking, Apple has sent cease-and-desist letters to two Chinese app developers known to be testing CAID.  The email from Apple includes the language:  "We found that your app collects user and device information to create a unique identifier for the user's device."  And it went on to warn the developer to update the app to comply with App Store rules within 14 days or risk its removal from the App Store.



So does a solution exist, or can a solution be created, to provide advertisers with the information they crave about the apparent interests of web and app users under a model that learns of those interests without, in any way, tracking them? Google says yes.  The EFF, they're not sure that even that is okay.  So What the FLoC?



LEO:  And now Steve will explain FLoC.  I'm dying to hear it.



STEVE:  So on Wednesday at the beginning of the month, on the third, Dave Temkin, who's Google's Director of Product Management, Ads Privacy, and Trust, posted a statement about Google's post-third-party cookie tracking plans titled "Charting a course toward a more privacy-first web."



Now, perhaps David is a bit biased because his posting begins right off the bat with an assertion that I'm not certain holds up.  He starts:  "It's difficult to conceive of the Internet we know today - with information on every topic, in every language, at the fingertips of billions of people - without advertising as its economic foundation."  And I would certainly agree that advertising has fueled a lot.  And in fact advertising does fuel a lot.  You know, Leo, it fuels this podcast network.



LEO:  Yeah, yeah.



STEVE:  It's arguably the reason that TWiT is still here and going strong.



LEO:  Exactly, yeah.



STEVE:  After 15-plus years.  And we know that it certainly fuels Google.  As I stated earlier, I'm a happy recipient of a ton of free Google stuff that I make great use of, apparently in return for allowing Google to track and profile me.  But is there a better way to accomplish the same task?



Well, let's ask David.  He continues.  He says:  "As our industry has strived to deliver relevant ads to consumers across the web, it has created a proliferation of individual user data across thousands of companies, typically gathered through third-party cookies.  This has led to an erosion of trust.  In fact, 72% of people feel that almost all of what they do online is being tracked by advertisers, technology firms, or other companies; and 81% say that the potential risks they face because of data collection outweigh the benefits, according to a study by Pew Research Center.  If digital advertising doesn't evolve," he writes, "to address the growing concerns people have about their privacy and how their personal identity is being used, we risk the future of the free and open web."



And I'll just interject here that once again we see the all-too-human characteristic that it's often not until someone has a solution to a perceived problem that they are fully willing to acknowledge that the problem exists in the first place.  So now that Google has FLoC, oh, look, third-party cookie tracking bad.  



Okay.  Anyway, he says:  "That's why last year Google announced its intent to remove support for third-party cookies, and why we've been working with the broader industry on the Privacy Sandbox to build innovations that protect anonymity while still delivering results for advertisers and publishers.  Even so," he says, "we continue to get questions" - questions and questions - "about whether Google will join others in the ad tech industry who plan to replace third-party cookies with alternative user-level identifiers.  Today, we're making explicit that once third-party cookies are phased out, we will not build alternative identifiers to track individuals as they browse across the web, nor will we use them in our products."  What?  What will Google do?



LEO:  I'm sure they'll find a way.



STEVE:  I think they're not going to lose track of us, yes.  And notice that, coincidentally, we've recently been talking about third-party cookie phase-out.  Those Firefox cookie same-site sequestration changes are all about phasing out the trackability of third-party cookies.  So that handwriting really does seem to be on the wall.



So David continues:  "We realize this means other providers may offer a level of user identity for ad tracking across the web that we will not, like PII (Personally Identifiable Information) graphs based on people's email addresses.  We don't believe these solutions will meet rising consumer expectations for privacy, nor will they stand up to rapidly evolving regulatory restrictions, and therefore aren't a sustainable long-term investment.  Instead" - and here it comes - "our web products will be powered by privacy-preserving APIs which prevent individual tracking while still delivering results for advertisers and publishers."  How are they going to do that?



Well, he says:  "People shouldn't have to accept being tracked across the web in order to get the benefits of relevant advertising.  And advertisers don't need to track individual consumers across the web to get the performance benefits of digital advertising.  Advances in aggregation, anonymization, on-device processing, and other privacy-preserving technologies offer a clear path" - well, it's clear now, apparently - "to replacing individual identifiers.  In fact, our latest tests of FLoC show one way to effectively take third-party cookies out of the advertising equation and instead hide individuals within large crowds of people sharing common interests.



"Chrome intends to make FLoC-based cohorts available for public testing through origin trials with its next release this month" - and this was written this month - "and we expect to begin" - so they'd better get on it, we're at the 23rd here - "and we expect to begin testing FLoC-based cohorts with advertisers in Google Ads in the second calendar quarter this year.  Chrome also will offer the first iteration of new user controls in April and will expand on these controls in future releases, as more proposals reach the origin trial stage, and they receive more feedback from end users and the industry."



He finishes:  "This points to a future where there is no need to sacrifice relevant advertising and monetization in order to deliver a private and secure experience."  And finally:  "Keeping the Internet open and accessible for everyone requires all of us to do more to protect privacy; and that means an end to not only third-party cookies, but also any technology used for tracking individual people as they browse the web.  We remain committed," they say, "to preserving a vibrant and open ecosystem where people can access a broad range of ad-supported content, with confidence that their privacy choices are respected.  We look forward to working with others in the industry on the path forward."



Okay.  So before we go any further, this raises an interesting philosophical question.  How do we feel about non-tracking-based aggregation of our interests?  As individuals interacting with the Internet, do we actually demand full and absolute privacy, meaning that we are a completely opaque entity to every site we visit?  Or is it all right for who we are to be known as an anonymous cloud of likes, desires, and interests?  And as I thought about that, it seems to me that I have no problem with people who I know and implicitly trust knowing a lot about who I am.  But I feel much less sanguine about having totally unknown and unknowable strangers knowing much about me without my giving explicit permission.



Okay.  So given the title of the EFF's reaction to Google's FLoC, they apparently feel even more strongly.  And I should note that the EFF does not like anything ever.  The only thing I can recall them ever liking was Let's Encrypt.  Oh, they loved Let's Encrypt.  Everything else, no.  The EFF titled their reaction to Google's FLoC, they said:  "Google's FLoC Is a Terrible Idea."  And they apparently wanted to be certain that no one came away from their posting feeling in any way unsure of any of the details.  So their posting is endless.  When I went to it, the scroll thumb shrunk down to like a little itty-bitty square.  So I'm going to share some of what they posted with liberal interjections.



They said:  "The third-party cookie" - this is the EFF, you know, the Electronic Freedom Foundation.  "The third-party cookie is dying, and Google is trying to create its replacement."  Okay.  Eh.  But we understand where they're coming from.  They said:  "No one should mourn the death of the cookie as we know it.  For more than two decades, the third-party cookie has been the linchpin in a shadowy, seedy, multi-billion-dollar, advertising surveillance industry on the web.  Phasing out tracking cookies and other persistent third-party identifiers is long overdue," writes the EFF.  "However, as the foundations shift beneath the advertising industry, its biggest players are determined to land on their feet.



"Google is leading the charge to replace third-party cookies with a new suite of technologies to target ads on the web.  And some of its proposals show that it hasn't learned the right lessons from the ongoing backlash to the surveillance business model.  This post will focus on one of those proposals, Federated Learning of Cohorts, which is perhaps the most ambitious," they said, "and potentially the most harmful.  FLoC is meant to be a new way to make your browser do the profiling that third-party trackers used to do themselves, in this case boiling down your recent browsing activity into a behavioral label and then sharing it with websites and advertisers.  The technology will avoid the privacy risks of third-party cookies, but it will create new ones in the process.  It may also exacerbate many of the worst non-privacy problems with behavioral ads, including discrimination and predatory targeting."  And we're going to talk about that.  We'll get there.



They said:  "Google's pitch to privacy advocates is that a world with FLoC and other elements of the Privacy Sandbox will be better than the world we have today, where data brokers and ad tech giants track and profile with impunity.  But that framing is based on a false premise that we have to choose between 'old tracking' and 'new tracking.'  It's not either/or," they allege.  "Instead of reinventing the tracking wheel, we should imagine a better world without the myriad problems of targeted ads."



Ah.  So there's a clear data point.  The EFF takes the position that any and all targeting will inherently be fraught with targeting-related problems independent of tracking.  So this attitude unfortunately strongly biases their language since non-tracking is not "new tracking."  It really is non-tracking.  Anyway, we'll understand this.



They said:  "We stand at a fork in the road.  Behind us is the era of the third-party cookie, perhaps the web's biggest mistake."  And of course we all know my often lamented feelings about third-party cookie tracking.  It was never meant to be.  But as technologists we allowed it to happen.  So maybe we are finally going to get rid of it.



They said:  "Ahead of us are two possible futures.  In one, users get to decide what information to share with each site they choose to interact with."  They said:  "No one needs to worry that their past browsing will be held against them, or leveraged to manipulate them, when they open a tab."  Okay, now, wait a minute.  Users get to decide what information to share with each site they choose to interact with?  How's that going to work?  Like it's been such a wonderful improvement to our lives that we now need to give every site we visit explicit permission about whether or not to use cookies.  What a nightmare.  But anyway.



The EFF continues:  "In the other case, each user's behavior follows them from site to site as a label, inscrutable at a glance, but rich with meaning to those in the know."  They said:  "Their recent history" - meaning users' recent history - "distilled into a few bits, is 'democratized' and shared with dozens of nameless actors that take part in the service of each web page.  Users begin every interaction with a confession:  'Here's what I've been up to this week.  Please treat me accordingly.'  Users and advocates," they say, "must reject FLoC and other misguided attempts to reinvent behavioral targeting.  We implore Google to abandon FLoC and redirect its efforts towards building a truly user-friendly web."



Okay.  So with that introduction, to offer a bit of background, which is interesting for reasons we'll see, they continue:  "In 2019," they say, "Google presented the Privacy Sandbox, its vision for the future of privacy on the web.  At the center of the project is a suite of cookieless protocols designed to satisfy the myriad use cases that third-party cookies currently provide to advertisers.  Google took its proposals to the W3C, the standards-making body for the web, where they have primarily been discussed in the Web Advertising Business Group, a body made up mostly of ad tech vendors.  In the intervening months, Google and other advertisers have proposed dozens of bird-themed technical standards:  PIGIN, TURTLEDOVE, SPARROW, SWAN, SPURFOWL, PELICAN, PARROT.  The list goes on."



LEO:  Okay.



STEVE:  "Seriously.  Seriously," they said.  "Each of the 'bird' proposals is designed to perform one of the functions in the targeted advertising ecosystem that is currently performed by cookies."  And then it hit me.  Birds.



LEO:  Birds.



STEVE:  That's why, Leo, and you already knew, that's why this abbreviation is so godawful.  They had to...



LEO:  It's a retronym.



STEVE:  Oh, they had to reverse engineer something for flock, which it's a flock of birds.  So we get the painfully horrible Federated Learning of Cohorts.  At least we now know where it came from.  Let's hope it's a working title.  On the other hand, that's what McIntosh was, and that wasn't so bad.  But FLoC, ugh.  Anyway, maybe we'll get used to it.



They said:  "FLoC is designed to help advertisers perform behavioral targeting without third-party cookies."  And I would strengthen also, without tracking.  It actually is non-tracking.  They said:  "A browser with FLoC enabled would collect information about its user's browsing habits, then use that information to assign its user to a 'cohort' or group.  Users with similar browsing habits, for some definition of 'similar,' would be grouped into the same cohort.  Each user's browser will share a cohort ID, indicating which group they belong to, with websites and advertisers.  According to the proposal, at least a few thousand users" - and actually it's thousands is what Google says because I read the spec - "should belong to each cohort," although they say, though, that's not a guarantee.



Okay.  So first of all, the small size of that group that they're alleging surprises and concerns me.  I assumed that cohorts should be much larger groupings.  But the motivation is clearly to keep them both highly targeted, yet you don't want them to be too small because you still want anonymity.  Anyway, they said:  "If that sounds dense, think of it this way:  Your FLoC ID will be like a succinct summary of your recent activity on the web.  Google's proof of concept used the domains of the sites that each user visited as the basis for grouping people together.  It then used an algorithm called SimHash to create groups."



And I'll interject.  SimHash is short for Similarity Hash.  It's an algorithm that Google has deep experience with, since it's used by the Google web spider to estimate the similarity of non-identical web pages, which it encounters as it's spidering the web.



They said:  "SimHash can be computed locally on each user's machine, so there's no need for a central server to collect behavioral data," which I think is cool.  "However," they said, "a central administrator could have a role in enforcing privacy guarantees.  In order to prevent any cohort from being too small - in other words, too identifying - Google proposes that a central actor could count the number of users assigned each cohort.  If any are too small, they would be combined with other, similar cohorts until enough users were represented in each one."



Then the EFF provides some useful and interesting detail.  According to the proposal, which by the way is public on GitHub, most of the specifics are still up in the air.  The draft specification states that a user's cohort ID will be available via JavaScript.  But it's unclear whether there will be any restrictions on who can access it.  And I would presume there will be none.  Or whether the ID will be shared in any other ways, like in a header, for example.  FLoC could perform clustering based on URLs or page content instead of domains.  It could also use a federated learning-based system, as the name FLoC implies, to generate the groups instead of SimHash.



It's also unclear exactly how many possible cohorts there will be.  Google's experiment used 8-bit - and I almost fell off my chair, 8-bit, because it's so small - cohort identifiers, meaning that there were only 256 possible cohorts.  That would be wonderful, but that's never going to happen.  In practice that number could be, they said, much larger.  The documentation suggests a 16-bit cohort ID comprising four hexadecimal characters.  Of course the more cohorts there are, the more specific they will be.  Longer cohort IDs mean that advertisers learn more about each user's interests and have an easier time, the EFF says, fingerprinting them.



LEO:  I disagree.  That's completely illogical.  But okay. 



STEVE:  Right.  One thing that is specified is duration.  FLoC cohorts will be recalculated on a weekly basis, each time using data from the previous week's browsing.  So that's another nice thing is that this creates a rolling identifier as the things you do differ, and your browser notices that.  It updates weekly and moves you into a new cohort ID.  They said:  "This makes FLoC cohorts less useful as long-term identifiers."  Right.  "But it also makes them more potent measures of how users behave over time."  Well, okay.  On the other hand, who cares, maybe?



So anyway, so far, despite EFF's valiant efforts, I'm not convinced that this is a bad thing.  It's bad, of course, if you're absolutely unwilling to be targeted in any way.  But for anyone who's willing to make a tradeoff, this seems like the one to make.



LEO:  I'd agree with you. 



STEVE:  Yeah.



LEO:  I'm not going to assume that any tracking is bad.  I mean, if all it is is so that you have ads that are suiting your interests, and if you've been anonymized sufficiently.  That's why a higher number would be...



STEVE:  A larger number.



LEO:  Larger number of buckets would be bad.



STEVE:  If I were one in 64K of all users in the world, bring it on.



LEO:  Who cares?  And the thing is there's a disincentive for them to make it too granular because you don't want groups to be too small, either.  I would submit that if there's an 8-bit, 16-bit, 32-bit, 24-bit, would really be a function of how big advertisers want those groups to be.  Do they want 100 people in the cohort?  A thousand?  Ten thousand?  And I think the demands of advertisers probably vary.  But Google will optimize that for the right-size bucket.  Not for the granularity, but for the size of the bucket, if you make it too granular.  But it sounds like what they're going to do is like a red, green, blue thing.  So they're going to have, you know, there'll be several axes.  So on the income axis, on the age axis, maybe the interest axis.



STEVE:  Well, I don't think so.



LEO:  No?



STEVE:  From what they're saying, it is based on interests reflected by the history of the domains you visit.



LEO:  I see.  So they're not going to collect demographic information at all.



STEVE:  Yeah, they're not going to collect demographics.



LEO:  That's interesting, yeah.



STEVE:  Yeah.



LEO:  Advertisers want demographics.



STEVE:  I know.



LEO:  But more than that, they want - they certainly want interest.  I mean, look.  If you could tell an advertiser this guy's going to buy a car in the next three weeks, for a certain group of advertisers, that's all they care about.  Maybe they care about your budget.



STEVE:  Well, but you might be able - I don't know, who knows if you're able to infer that from places you visit.



LEO:  Other information, yeah.



STEVE:  So now they present some negatives which are interesting.  They said:  "The first issue is fingerprinting.  Browser fingerprinting," they said - we all know this, but it's brief - "is the practice of gathering many discrete pieces of information from a user's browser to create a unique, stable identifier for that browser.  EFF's Cover Your Tracks project demonstrates how the process works.  In a nutshell, the more ways your browser looks or acts different from others', the easier it is to fingerprint.



"Google has promised that the vast majority of FLoC cohorts will comprise thousands of users each, so a cohort ID should not alone distinguish you from a few thousand other people.  However, it still gives fingerprinters a massive head start."



LEO:  Right.



STEVE:  "If a tracker starts with your FLoC cohort, it only has to distinguish your browser from a few thousand others, rather than a few hundred million others."  And I would counter that by observing that it changes weekly.  And who knows?  I would imagine that the changes are asynchronous globally so that my cohort is going to suddenly be different by some measure at some point and not notify anybody when that happens.



LEO:  Your real concern is deanonymization; right?  Is that the real concern?  I mean, that's what fingerprinting might do is identify you as Steve Gibson.



STEVE:  Kind of.  So here's more.  They note:  "Fingerprinting is notoriously difficult to stop.  Browsers like Safari and Tor have engaged in years-long wars of attrition against trackers, sacrificing large swaths of their own feature sets" - and we've documented that on this podcast - "in order to reduce fingerprinting attack surfaces.  Fingerprinting mitigation generally involves trimming away or restricting unnecessary sources of entropy, which is what FLoC is.  Google," they're saying, "should not create new fingerprinting risks until it's figured out how to deal with the existing ones."



And then they highlight a new problem created by this technology which they call "cross-context exposure."  They said:  "The second problem is less easily explained away.  The technology will share new personal data with trackers who can already identify users.  For FLoC to be useful to advertisers, a user's cohort will necessarily reveal information about their behavior."  Right?  That's what it is.



The project's GitHub page addresses this upfront.  GitHub page says:  "This API democratizes access to some information about an individual's general browsing history, and thus general interests, to any site that opts into it.  Sites that know a person's PII" - their Personally Identifiable Information - "for example, when people sign in using their email address, could record and reveal their cohort.  This means that information about an individual's interests may eventually become public."  Which is interesting.  



The EFF noted:  "As described above, FLoC cohorts should not work as identifiers by themselves.  However, any company able to identify a user in other ways, say by offering 'log in with Google' services to sites around the Internet, will be able to tie the information it learns from FLoC to the user's profile."  And they said:  "Two categories of information may be exposed this way.  First, specific information about browsing history.  Trackers may be able to reverse engineer the cohort-assigned algorithm to determine that any user who belongs to a specific cohort probably or definitely visited specific sites.  And second, general information about demographics or interests."  Well, duh.  That's what the cohort ID is; right?



But they said:  "Observers may learn that, in general, members of a specific cohort are substantially likely to be a specific type of person.  For example, a particular cohort may over-represent users who are young, female, and black; another cohort, middle-aged Republican voters; a third, LGBTQ youth.  This means every site you visit will have a good idea about what kind of person you are on first contact, without having to do the work of tracking you across the web, or buying that service from an aggregator.  Moreover, as your FLoC cohort will update over time, sites that can identify you in other ways" - like because you log into them explicitly - "will also be able to track how your browsing changes.  Remember," they wrote, "a FLoC cohort is nothing more and nothing less than a summary of your recent browsing activity."



And here's their key point:  "You should have a right to present different aspects of your identity in different contexts.  If you visit a site for medical information, you might trust it with your information about your health, but there's no reason for it to know what your politics are.  Likewise, if you visit a retail website, it shouldn't need to know whether you've recently read up on the treatment for depression.  FLoC erodes this separation of contexts, and instead represents the same behavioral summary to everyone you interact with."  Now, I would argue that they're reversing disadvantages of it, you know, picking it apart.  But they make a valid point.



And then, tying back to the beginning about the inherent problems associated with any type of targeted advertising, they wrap up, or I'll wrap up what they're sharing by saying the EFF makes some additional disturbing observations.  They said:  "FLoC is designed to prevent a very specific threat, the kind of individualized profiling that is enabled by cross-context identifiers today.  The goal of FLoC and other proposals is to avoid letting trackers access specific pieces of information that they can tie to specific people.  As we've shown, FLoC may actually help trackers in many contexts.  But even if Google is able to iterate on its design and prevent these risks, the harms of targeted advertising are not limited to violations of privacy.  FLoC's core objective is at odds with civil liberties."



They say:  "The power to target is the power to discriminate."  And this sounds like something you'll want to talk with Jeff about tomorrow, Leo.  They said:  "By definition, targeted ads allow advertisers to reach some kinds of people while excluding others.  A targeting system may be used to decide who gets to see job postings or loan offers just as easily as to advertise shoes.  Over the years, the machinery of targeted advertising has frequently been used for exploitation, discrimination, and harm."  And actually in their posting they have links for examples of all this.



They said:  "The ability to target people based on ethnicity, religion, gender, age, or ability shows discriminatory ads for jobs, housing, and credit.  Targeting based on credit history, or characteristics systematically associated with it, enables predatory ads for high-interest loans.  Targeting based on demographics, location, and political affiliation helps purveyors of politically motivated disinformation and voter suppression.  All kinds of behavioral targeting increase the risk of convincing scams."



So I'm reminded of this when we've talked about it before.  We talked about how billboards along the highway don't know, at least yet, who's driving by.  Nor do placards posted in store windows.  We're all treated uniformly.  Television advertisers have always been able to select the TV programs on which they will appear.  The advertisers can presume the demographic of any program's audience, but they have no feedback beyond that.  And it makes one wonder whether web and web advertisers wouldn't be satisfied with choosing which websites to have hosting their ads, based on the demographics of the visitors to those sites, rather than having ads able to chase their targets across the web.



LEO:  Well, they're only willing to take it if that's all they can get.



STEVE:  Right, right.



LEO:  You know, and it's been our experience, that's how podcast ads worked.  But more and more, advertisers are demanding more information about listeners.  And as they start to get it from platforms like Apple and Spotify, it makes it difficult for people who don't want to somehow track listeners.  You just don't get ads.



STEVE:  Well, and you know, I had a creepy thought, Leo, when I was thinking about this.  It just occurred to me, I wonder whether the inserts that are now sometimes being placed into podcasts, if everyone gets the same one.



LEO:  Oh, no, no, no.  Because they're by IP address.  So it's geographic.  It's not - I don't think they have any demographic information, but they have rough geography from the IP addresses.



STEVE:  Interesting.



LEO:  But that's not at all unusual.  An advertiser who sells cars in Northern California doesn't want to buy a podcast that's international.  They want to buy Northern California listeners.  And I don't think that's unreasonable, to be honest with you.



STEVE:  You know that I'm a big user of YouTube TV.  And they sometimes have these weird blank times where they just talk, and it's like nothing is showing.  And I said to Lorrie, I said, "I wonder if they know it's us, and the ad that they might have inserted there like, you know, is not meant for me."



LEO:  No.  They know it's web.  So the television ad buyer buys MSNBC, says specifically "not for streaming."  So when that ad comes up, and you're watching YouTube TV, you won't get it.



STEVE:  Okay.



LEO:  And that's very common because they don't want to buy those numbers.



STEVE:  Why not?  I mean, it's like TV watchers are - is there any other way to watch MSNBC other than streaming?



LEO:  I can't speak for advertisers' logic.  Sometimes it does seem illogical.  But they're well within their rights to say that.  And by the way, billboards are targeted demographically.  For a long time there's a lot of evidence that menthol cigarettes billboards only showed up in black neighborhoods.



STEVE:  And so like in large syndicated radio shows - well, in fact I know that because I see ads for some car dealer around the corner.



LEO:  Local.



STEVE:  Obviously they're not giving that to people in New York.



LEO:  Right.  So your cable company is selling those, Comcast and Cox and the others.  When you're watching a channel on cable, there are local avails that the cable company can sell.  And that's why you see local ads there.  You know immediately when we switch to the local ads, the crappy ads.



STEVE:  And they're really cheesy, yeah.  Oh, my goodness.



LEO:  You know immediately.



STEVE:  Where did they get this guy?



LEO:  This has gone on forever.  I mean, the inserts in your newspaper, those vary depending on neighborhood.  This has always happened.  The problem is that as soon as digital technology came along, better and better ways of doing this appear.



STEVE:  A much sharper knife. 



LEO:  A sharper knife, thanks to Google and Facebook.  The thing that puzzles me about FLoC, you know, Facebook knows a lot about you, more than anybody else.  That's why their ads are so efficient.  But they don't give that information to anybody.  That's their secret sauce.  If you're an advertiser, you can't go to Facebook and say, well, you know, tell me who's looking at this page.  You buy a demographic.  Facebook keeps that closely held.  That information...



STEVE:  And have you been seeing their ads?  They're, like, advertising advertising.



LEO:  Yeah, well, we'll be doing that too, soon, because advertising has slowed down a little bit in COVID.  So I'm surprised Google - I think I have to read this more carefully.  I don't know if EFF has misunderstood FLoC.  Why would Google give this information to a website?  I don't think they would.  Google would sell that website based on that information to an advertiser.  But they don't want anyone to know what group you're in.



STEVE:  Ah.  So maybe the encoding is proprietary.



LEO:  Absolutely.  Unless I'm misunderstanding it.



STEVE:  So you get the code from the person visiting, and then you've got to pay Google to find out what that means.



LEO:  Not even that.  Look, when you're buying a Google ad, you're buying it from Google.  They know.  So you tell Google, look, I want to advertise only on sites for males 25-54.  And Google knows who that is.  You're in that FLoC.  So when they see you show up, not the website, Google knows.  The website doesn't get that information.  That's proprietary.  Google spends a lot of money to get that information.  They're not going to give it away.



STEVE:  Well, in that case, then, that's a big question because these guys are clearly saying, and the GitHub page makes it, I mean, they even show some sample JavaScript where any site could put some JavaScript in the browser and acquire the FLoC cohort ID.



LEO:  That's interesting.  I don't know why Google would allow that.  Because that's like Facebook saying, yeah, I mean, that's what they're selling.  That information is the gold.  So maybe this is because it's an open standard?



STEVE:  Google is selling the appearance of the ads on the page; right? 



LEO:  Yeah, and they sell it based on the advertiser saying I want this particular cohort.



STEVE:  Well, you're right.  So Google does its own tracking and builds its own profile.



LEO:  Yes.



STEVE:  Which is how, through DoubleClick, which is how they perform their...



LEO:  Precisely.  That's how they do it now.  Now, the third-party tracking cookies is interesting because when you have a "like" button from Facebook on every page, Facebook is gathering information about every page you go to.  And in fact you're visiting Facebook all the time because that's, you know.  So I understand the concern about that.  Although, again, mostly this is used just to target advertising.  And I agree what the EFF says about how that could be misused.  But it's still only advertising.



STEVE:  How about any advertising targeting is misused, yeah.



LEO:  Yeah.  But, I mean...



STEVE:  That's the nature of it.



LEO:  It's an ad.  It's crap.  It doesn't mean you have to pay attention to it.  In fact, the larger story is people are just blocking ads in general.  And that's, see, I think sometimes that gets conflated with tracking.  They're two separate things.  You and I block ads because they can carry malware, because they kill bandwidth, because they're annoying.  There's too many of them.  There's all sorts of good reasons to say I don't want to see ads.



STEVE:  And, oh, gee, they're not relevant to me.  What do you know?



LEO:  That's part of the problem; right?  I don't want to see those ads.  They're not for me. 



STEVE:  It doesn't appear to actually work.



LEO:  Yeah.  Yeah.  Well, that's true.



STEVE:  It's like all this machination, and it's like, wait, you know, I'm not buying baby diapers.



LEO:  But put yourself in the position of the person buying an ad.



STEVE:  Or adult diapers yet.



LEO:  Yes.  I mean, we buy ads.  We buy Google ads.  TWiT does.  If you put yourself in the position of an advertiser, they don't want an ad to show to anyone who's not interested in their product.  They're trying to find people who are...



STEVE:  Because it's expensive for them.



LEO:  It's a waste of money.



STEVE:  They have to pay for that, yes.



LEO:  So efficient ads are targeted ads.  That's what advertisers want, quite reasonably.  I think end users, if they were properly targeted, would prefer ads for - you don't want to see an ad for diapers if you don't wear them.  You don't want, I mean, that's almost insulting.



STEVE:  Actually, there are a lot of ads, come to think of it, these days that I'm seeing that I'm thinking, oh, no.



LEO:  We're insulted by every ad we see.  If you watch cable news, it's nothing but drugs you don't need.



STEVE:  Exactly.



LEO:  Nonstop.  But those advertisers...



STEVE:  Let's try some Vyvanse.  Ask your doctor if that's right for you.  And then...



LEO:  Most advertisers would far prefer to advertise to people...



STEVE:  And then there's the stuff that falls off if you take it.  It's like, oh.



LEO:  I know.  It's kind of the opposite of an ad, isn't it.  It's like, I'm not taking that.  I don't know what's wrong with that person.  Why are they taking that?  But honestly, the makers of Vyvanse would far prefer to sell it to people who are buyers of Vyvanse, or potential buyers.  Not us.  So I have very mixed feelings about all of this.  It is, frankly, just speaking from my position as somebody who sells ads, that's all - advertisers push for that very hard.  And it's really a hard thing to say.  You know, you'll lose ads, we lose ads all the time.



STEVE:  We'll have to figure out who has access to the information.



LEO:  That's interesting.



STEVE:  But it sure does sound like it's better than tracking.



LEO:  Yeah.  I think it's at least somewhat anonymous.



STEVE:  Yeah, and the idea that Chrome would just shut down third-party cookies.  Of course then we have the whole CNAME problem again.  It doesn't remove that, which is now we know 10% of the top 10,000.



LEO:  Here's my complaint, really, is Google saying, okay, no third-party cookies.  We'll do something only we can do, and good luck to the rest of you.  To me, what really this is is saying, yeah, well, we can...



STEVE:  And so maybe that argues for them making it public, for them allowing the cohort to be public.



LEO:  I really have to read more about this.



STEVE:  And that means you have to publish what the ID means.  Otherwise nobody can make any sense of it.



LEO:  Right.  But why would they do that?



STEVE:  Well, and it also means that there will be sites that show you the meaning of your own browser's cohort.



LEO:  Right, right.



STEVE:  I mean, you know...



LEO:  Who are you?  Here's what I know about you.



STEVE:  I won't have to do it.  Troy Hunt will do it for us.



LEO:  Yeah.



STEVE:  But, you know, you'll be able to go there and see, oh, look at the Venn diagram that I'm in.



LEO:  You see, that's why I don't think this is going to work that way.  I read this EFF article when it came out, and I was puzzled by some of it.  So I don't know.



STEVE:  Well, I have a feeling this will not be the last "What the FLoC" we end up discussing.



LEO:  Right.



STEVE:  And maybe we'll know more about...



LEO:  What the FLoC.



STEVE:  What the FLoC.



LEO:  Aptly named.  Thanks, Steve Gibson.  His home on the web is GRC.com.  That's where of course you'll find SpinRite, the world's best hard drive maintenance and recovery utility.  It's a good time to get SpinRite, if you don't already have it, because 6.1 is coming.  And if you buy 6.0 now, you'll have a free upgrade, plus you can participate in the development of 6.1.  And I think the best news of all that I've heard is that SpinRite is no longer just for spinning drives.  It works very well in interesting ways on SSDs.  So it's really of great use for anybody with storage.  How about that?  StorageRite.  That's GRC.com.



While you're there, of course, you can get a copy of this show.  Steve has a couple of unique versions of this show, a 16Kb version, little lower audio quality, but it's a much smaller file for the bandwidth-impaired.  Well, you can tell how much lower.  What is that, one-sixth the size.  No, it's one-fifth the size, something like that.  One-fourth the size, there we go.  You can also get transcripts, which are probably a tenth the size because it's text, by Elaine Farris.  She writes this all up.  That's nice to have, if you read along while you listen or just read.  I use it for searching because, if you search, you can find any part of the show, any show, all 811, all at GRC.com, along with 64Kb audio.



We have audio and video at our site, TWiT.tv/sn.  You can also - that means you can download any episode from there.  You can also get it on YouTube.  There's a YouTube channel.  All the episodes are up there, video.  And of course subscribe in your favorite podcast application.  That way you'll get it automatically, the minute it's available.  We do the show on a Tuesday afternoon about 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  So if you want to watch us do it live, the unedited, unexpurgated version, you can get that at TWiT.tv/live, watching live, chat live at irc.twit.tv after the fact.  Steve takes DMs at his Twitter site.  You can slide into his DMs at @SGgrc, or leave feedback at GRC.com/feedback.



We have our own forums.  Steve has his SpinRite forums.  We have our TWiT community forums at www.twit.community.  We also have a Mastodon instance.  That's the federated Twitter-like Fediverse, and it's really a lot of fun in there.  We just passed 1,000 users at TWiT.social.  I'm @Leo at TWiT.social.  People ask, how can we get Steve in here?  I say, "Give me a break, it took me years to get him on Twitter."  Slow down.  Just wait a little bit.  Maybe in a while.  Steve has a lot of other things he's working on right now.



That's it for the show.  Thank you for being here.  We'll see you next week, Steve, on Security Now!.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#812

DATE:		March 30, 2021

TITLE:		GIT Me Some PHP

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-812.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we begin by checking in on the patching progress, or lack therefore, of the ProxyLogon Exchange Server mess.  We examine a new Spectre vulnerability in Linux, a handful of high-severity flaws affecting OpenSSL, still more problems surfacing with SolarWinds code, an intriguing new offering from our friends at Cloudflare, and the encouraging recognition of the need for increasing vigilance of the security of increasingly prevalent networked APIs.  I'll check in about my work on SpinRite.  Then we're going to take a look at the often breathlessly reported hack of the PHP project's private Git server, and why I think that all the tech press got it all wrong.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  There is a lot to talk about.  Steve's got a unique take on the PHP Git repository hack.  He thinks it's actually a good thing.  We'll find out more about that.  A virtual browser solution from our friends at Cloudflare that looks pretty useful.  And a little plug for our friend Rasmus Vind and his Warcraft site.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 812, recorded Tuesday, March 30th, 2021:  GIT Me Some PHP.



It's time for Security Now!, the show where we cover the latest news about the world of security.  And, boy, is there some news this week.  But I guess you could say that about every week.  Steve Gibson's here from the GRC company.  When we first started doing this 812 episodes ago we thought, how will we ever fill half an hour?  And now we fill four half hours, and there's still more to do.



STEVE GIBSON:  Oh, my goodness, yes.



LEO:  Hi, Steve.  Did you have a good week?



STEVE:  Had a good week, yes.  Got some work done, lots of work actually, on SpinRite.



LEO:  Yay.



STEVE:  I'll mention it briefly toward the end.



LEO:  People are happy to hear that.



STEVE:  This 812th episode I titled GIT Me Some PHP.



LEO:  And I know why.



STEVE:  Yeah.  And my reading is that all of the tech press got it wrong.



LEO:  Oh.  Good, that's why we count on you.  Good.



STEVE:  Yeah.  As I was reading all the huffing and puffing, I thought, you know, it's not clear to me that this was anything more than what will end up being a big benefit.  But we'll get to that.  We're going to begin by checking in on the patching progress, or lack of course thereof at this point, of the ProxyLogon Exchange Server mess.  We examine a new Spectre vulnerability to hit Linux, believe it or not.  So Spectre's not over.  We have also a handful of high-severity flaws affecting OpenSSL, probably one of the other things you were thinking of, Leo.



Still more problems surfacing with SolarWinds code.  An intriguing new offer from our friends at Cloudflare, who just, you know, innovation seems to be their middle name.  They keep adding stuff.  They're not sitting on their laurels, that's for sure.  And we've got some encouraging recognition of the need for increasing vigilance of the security of increasingly prevalent networked APIs.  Then, as I said, I want to briefly just touch on my ongoing work with SpinRite.  And then we're going to take a look at what was a breathlessly reported hack of the PHP Project's, like, main central Git repository server, and why I think all the tech press got it very wrong.



LEO:  Interesting.



STEVE:  And we do, of course, have kind of a fun Picture of the Week.  So I think another great podcast for our listeners.  And, yeah, no sign of security problems letting up.



LEO:  We should do a traffic report.  And it's all jammed up along the information superhighway.



STEVE:  On the 405, yeah.



LEO:  Okay, Steve.  I'm ready with the Picture of the Week.  This one speaks to me.  It does.



STEVE:  I had a feeling it would.



LEO:  Yeah, it really does.



STEVE:  So what we have is two service windows.  One, there's a big signage over the one on the left says "More Gear."  Get your more gear here.  And then the other window next to it says "Learning to Use Existing Gear."



LEO:  Guess which one has the longer line?



STEVE:  Yeah, the guy behind the Learning to Use Existing Gear, well, he's not asleep because he's reading a book with his head propped up on his hand.  There's nobody who has any interest in learning to use their existing gear, apparently.  There's nobody at his window.  The entire line, and it goes right off the screen, is just I need some more gear.  Give me some more gear.



LEO:  Don't learn to use what you've got.  Get something new.  It'll be more easier.  It's not signed, but it really looks like a Rich Tennant cartoon.  You know, he did "The 5th Wave," it was in the "For Dummies" books, it was in magazines like - I can't remember, it was PC - no, it was Computerworld, that's what it was.  Rich Tennant.  Really looks like might be one of his.



STEVE:  You know, and I have to say I often harken back to when I was five because I knew what every button on every piece of equipment that my family owned did.  I mean, I just - that was my thing.  It made sense to me.  



LEO:  Yeah, that's how you got to be a geek.



STEVE:  I was going to know what it is.  But I look at the remote control on the whatever it is I've got, and there's buttons there.  You've got your top menu, your side menu, your backwards menu, the this and the that, I mean, it's just like, what is all this?  Do I really - all I want to do is go to the next episode of "Fringe."



LEO:  It's a lot harder than it used to be.  I agree with you.



STEVE:  Oh, Leo.



LEO:  I don't know if that's us.  I don't think it is.



STEVE:  I don't know.



LEO:  I just think everything has proliferated to such a degree.  And user interface design seems not to have improved enough to accommodate all the new features.



STEVE:  Yeah.  I mean, even, you know, one of the most elegant things about the iPhone was that there was four buttons.  You clicked a picture, and you got a phone.  Or you clicked when you got notes.  You know, they did have a little wood grain problem there back in the beginning.  But still.



LEO:  That was to make you feel at home.



STEVE:  There just was, like - now it's like, oh, you've got to push the screen harder and hop on one foot and then do a little twist with your finger in order - and then you get some secret menu that you never knew was there.  And oftentimes, I mean, and I'm certainly no guru, but I'll do something, like I'll swipe along the bottom and go back to an app because I saw that on one of your shows once, Leo.  And Lorrie goes, how did you do that?  What's that?  What?  What?



LEO:  Yeah, there used to be a home button.  They took it out.  How do I get out of here?



STEVE:  The other day I was helping her with something in Chrome, and she was at some link somewhere, and I grabbed to the left of the URL and dragged it off and dropped it on the desktop.  And she's like, "What?  That's a thing?"  It's like, "Yes, honey.  Now you have an icon that will get you back there in time."  She says, "Oh," she says, "I just need to watch you work more often."  But again, so yeah, I have like four things...



LEO:  It's just as baffling for us, though.  That's the thing.



STEVE:  Yes.  I have four things that she hasn't figured out.  But I look at this stuff, and I think, what is hidden behind all these user interfaces?



LEO:  I feel bad, I mean, if you and I have trouble, what's a normal person to do, really?  And I think that that's why this cartoon is so great, because I think really normal people just - they don't try.  I don't know how to get better using this, so I'm just going to get another one, which I'll be just as lost in.  Oh, gosh.  I really feel bad for people.



STEVE:  Okay.  So our weekly ProxyLogon update.  I looked for any update from Microsoft, from RiskIQ, which is the people that they keep citing, or any other source to get some sense for how the patching was going.  I did discover that RiskIQ is now estimating that "only" - and I put that in quotes.  "Only" needs to be in quotes because the only sense in which it's "only" is in comparison to the original several hundred thousand vulnerable and unpatched Exchange servers that we started out with.  So today we're down to "only" 29,966 instances of Exchange Server still vulnerable and thus still wide open to attack.  But that's down from the last number we reported, which was 92,072, back around March 10th.  And that nearly 30,000 number appears to be holding.



And of course unfortunately our experience suggests that, especially at this point, right, like anyone who was going to get the news, got the news in the last three weeks since this happened.  So four weeks, actually, yeah, one, two, yeah, four weeks now exactly since March 2nd.  So we know that any further improvement will be incremental, slow, attritional, and perhaps the result of Microsoft's slipping that useful ProxyLogon remediation into their Windows Defender solution, since it's able to filter the primary exploit vector from the IIS web server before that attack reaches the server's tender underbelly.



It's not clear whether RiskIQ is actually testing for the vulnerability, which I don't suspect, or obtaining Exchange Server's version information from some logon hello handshake, which is probably what they're doing.  So if it's the case, then RiskIQ's number would be high because it would not be crediting all of those instances of Exchange Server which had not been actually updated, but which did have the Windows Defender remediation slid in and is protecting it sort of without getting any credit for doing so.  So it's probably the case that the number's coming down.  But tens of thousands.  And as we know, it's like there's a battle for who can take control of these servers and what mischief they can get themselves up to.



LEO:  Well, and remediation doesn't kick them out.  It just prevents new ingress.  But if somebody's already in there, they're in there; right?



STEVE:  Yeah.  Now, what they did say, without any specifics, is that it will also go and try to find the things that it knows of that they may have done.



LEO:  Oh, good.  Okay.  So you could see traces of them, crumbs left behind.



STEVE:  Exactly.  So it may have been able to remove them, which would also be a good thing.



LEO:  Yes.



STEVE:  And I need to turn my - pardon me.  I'm trying to get our balances correct now, having turned up my microphone, now I'm blasting myself.



LEO:  I should explain we've used Skype since Episode 1, but we started using Zoom because we're concerned, well, first of all, you never liked, from the day Microsoft acquired them, the things they did to change how Skype worked.  It used to be peer-to-peer.  Now all of a sudden it's going through Microsoft servers, blah blah blah.



STEVE:  Yeah.



LEO:  So after looking for many alternative solutions, Alex Lindsay suggested moving to Zoom.  He's doing a lot of streaming, obviously, and he knows more probably than anybody about which works best.  And we're very happy with Zoom.  But it's a whole new set of interfaces and a whole new set of buttons that have to be tweaked.



STEVE:  Now it's all wonderful.



LEO:  Yes.



STEVE:  You sound great.



LEO:  Good.



STEVE:  And I'm just a sultry whisper in my own ears.



LEO:  A whisper in your own ears.  Good.



STEVE:  Yeah, and "sultry" is not a word that's ever been used to describe myself.



LEO:  Actually, the chat room said you have a rich, velvety sound now.  So, hmm.



STEVE:  Ah, well.  Just be chatting.  So Spectre is remaining with us.  It's clear.  Two weeks ago we noted that Google's security blog was titled "A Spectre Proof of Concept for a Spectre-Proof Web."  And they demonstrated two weeks ago and shared their creation of a working Spectre exploit in JavaScript that's able to obtain data from the browser's internal memory.  And yesterday researchers with Symantec's Threat Hunter Team disclosed two ways in which Spectre's processor mitigations could be circumvented in Linux-based OSes to launch successful speculative attacks to obtain sensitive information, like crypto keys, from the system's kernel memory.



And what's interesting about these attacks is that on the one hand, in the very beginning, the first time there was any notion of, like, oh, we could leak a bit every minute, people were like, who cares?  A bit a minute?  But crypto keys are notoriously dense; right?  You need to get all the bits right, or you don't have anything.  So that's, you know, every single bit is crucial.  But they're not very long overall.  And you really want to hide their bits well.  Well, the one thing that this kind of low bandwidth leakage does is it does get things that you thought were well hidden exposed.



So the Symantec group found two related but different ways to pull off something like crypto key in the kernel memory leakage.  Two CVEs have been assigned.  And interestingly, they're 2020:  2020-27170 and 27171.  Because these should be fixed, but they do not spell the end of the world or of Linux, they carry relatively mild CVSS scores of 5.5.  And they impact all Linux kernels prior to v5.11.8.  So the trouble was first identified last year, thus the 2020 CVE years.  And the Linux teams were notified.  Patches for Ubuntu, Debian, and Red Hat were just published on March 17th, and then they were released for deployment the Saturday before last, on March 20th.



So as I said, there are two.  The first one is able to reveal the contents from the entire memory of an affected computer; and the second one, 171, can reveal the contents from the 4GB range of kernel memory.  So remember that, because Spectre and Meltdown are chip-level vulnerabilities, operating system patches can only be mitigations, which are designed to make it hopefully impossible for an attacker to exploit the vulnerabilities.



My point is that the operating system has no ability to address the underlying issue which exists in the processor beneath it, that it can't get there.  It is able to load microcode at boot time.  And Intel has updated the microcode, and the Linuxes are carrying that, and they are indeed doing as much as Intel has been able to do.  But it's these mitigations for Spectre which were also incorporated into Linux, which the Symantec group found a way to get around, to essentially bypass the mitigations.  So by using these mitigation bypasses on any unpatched Linux before - and I wrote before 5.11.7, but it must be before or including 5.11.7, since the update brought us to 5.11.8 - so then malicious code can read memory that its process, that is, the process the malicious code is running in, should have no permission to inspect.



And what's more, the attacks could also be launched remotely through malicious websites running exploit JavaScript.  So when you hear that, that's the concern; right?  Because we've often talked about how, yeah, Spectre and Meltdown, they're not good.  We don't want to have our processor leaking between processes.  But still, it's more of a theoretical than a practical issue, we have been led to believe for the last couple years.  And the point has been that, if you've got a process sharing your personal system, that using Spectre or Meltdown, you've already got bigger problems than its ability to perform some difficult-to-execute memory leakage.  But if it's possible for JavaScript running in your browser to do this when it's on a Linux machine, then that's something to worry about.



So the Symantec team worked out a way to take advantage of the kernel's support for the Extended Berkeley Packet Filters known as EBPF, to extract the contents of the kernel memory.  The Berkeley Packet Filter, BPF, has been around forever.  It started out to be a general purpose, lightweight virtual machine that was used to inspect the contents of network packets, the idea being that, if you wanted to make a fancy packet inspector, you need a little bit of code to do that, to perform some pattern matching.  If this is that, then check if this is that and, you know.  It's a little more difficult than you could do with a set of fixed rules.



So they implemented a simple virtual machine, the Berkeley Packet Filter, in order to perform those sorts of simple things and to make them very fast because you don't want something slowing down your packets.  So anyone who's ever had occasion to use Linux's TCP dump facility has likely encountered the BPF system.  Since then, the Extended BPF variant has become a universal in-kernel virtual machine which has hooks throughout the kernel in order to do what it needs to get done.



So Symantec explained, they said:  "Unprivileged BPF programs running on affected systems could bypass the Spectre mitigations and execute speculatively out-of-bounds loads with no restrictions."  And that's the no-no which Linux was trying to prevent.  They said:  "This could then be abused to reveal the contents of the memory through Spectre-created side-channels."  And specifically it's in kernel/bpf/verifier.c.  They said:  "The kernel [that file] was found to perform undesirable out-of-bounds speculation on pointer math, thus defeating fixes for Spectre and opening the door for side-channel attacks."



So the point is that Linux has been hardened against Spectre.  But there was a little piece that didn't get hardened, that Symantec realized, oops, you could still do this.  So in a real-world scenario until recently, as we know, Spectre has been a bit light on unprivileged users' ability to leverage these weaknesses to gain access to secrets.  But this allows a way for that to happen.



Symantec explained that:  "The bugs could also potentially be exploited if a malicious actor was able to gain access to an exploitable machine through some previous step, downloading malware onto the machine to achieve remote access.  This would allow them to further exploit these vulnerabilities to gain access, for example, to all user profiles on the machine."



And again, patches are out.  So individuals should have no problem updating themselves, which you'll want to have done since the 20th.  But, you know, here we were just talking about the difficulty of getting the world's systems updated, the world's Windows systems updated.  Just imagine how many Linux systems have not been updated in the past two weeks.  Many haven't been updated in years, and won't be, never will be.  So Symantec tells us that these unpatched gremlins that they have found can be exploited remotely, unfortunately.



LEO:  Is it a firmware update?  Or is it an operating system update?



STEVE:  It's an OS.  It's an OS update. 



LEO:  Okay.



STEVE:  So the problem actually existed in some lack of remediation against the remaining ways that even after the firmware was updated, that it was still possible to do this.  So it's in that C file.



LEO:  Okay.  All right.  Well, yeah, I'll do the update.  The problem with Linux, well, you know, as you point out, that a lot of these boxes are designed just to run forever and not be updated.  I have a server in the other studio that, you know, it's a server.  I don't want to update it more than necessary, and it doesn't update automatically.  A lot of people who have desktop Linuxes, in fact I've seen people complain about this, are obsessively updating, like every day they update.  But that still doesn't guarantee you're going to get the update because the way Linux distributions work, the updates happen upstream, and then they have to be incorporated into the distribution so that your distribution, whatever it is, will see it.  Some distributions are slower about that than others.  It's not a uniform process.  So, interesting.



STEVE:  Well, and how many appliances, how many turnkey boxes of one sort or another.



LEO:  Yeah.  Oh, gosh, yes.



STEVE:  I mean, all of the routers, they're all Linux-based.



LEO:  Right, right.  As are, I mean, anything Android-based is Linux-based.  So there's a lot of Linux out there, yeah.



STEVE:  Yeah. 



LEO:  By the way, I don't know if you noticed, but I'm glad you didn't come to me earlier because I put in new rubber bands in my - Burke said, oh, I got some.  Look at that.



STEVE:  Oh, perfect. 



LEO:  It's bouncing right in there.  Look at that.



STEVE:  Oh, nice.



LEO:  It's only been that way for, like, four years.  Yours too, probably.  On with the show.



STEVE:  I've not touched it in 15 years of the podcast.



LEO:  Yeah, exactly.  They go in about three, so that'll give you some idea.  On we go.



STEVE:  So the OpenSSL project has fixed several high-severity flaws.  Alarm bells were also ringing over at the OpenSSL project as a result of a server crash Denial of Service and a certificate verification bypass.  So as we know, for many years, OpenSSL contained the main repository of open source crypto magic, so the OpenSSL library was incorporated everywhere that secure communications and certificate management was needed.  Again, don't reinvent the wheel.  Security, especially security code is hard to get right, so just drop in the library.  And the library that was dropped in was OpenSSL.



Now, these days crypto's gone much more mainstream, and OpenSSL now has many viable newer and quite a bit sleeker competitors.  We've talked about Bouncy Castle, Cryptlib, GnuTLS, Libgcrypt we were just talking about recently, Libsodium, NaCl, NSS, I mean, there are many alternatives now.  And even Amazon created a super svelte TLS implementation for their own AWS stuff.



LEO:  You have one you prefer.  I think you used NaCl for SQRL; right?  Or was it Libsodium?



STEVE:  Libsodium, actually.  But the two are almost - Libsodium and NaCl are...



LEO:  NaCl is salt; right?  



STEVE:  Right, right.  So inertia being what it is, OpenSSL remains dominant.  So it's under most of the rocks that you will turn over.  It is big.  It's bloated.  It's creaky.  But it remains the reference standard against which the performance of everything else is compared.  If you're creating a clone function, you see what OpenSSL does, and then you make sure that yours does the same thing.  So although it has by any measure through the years been quite robust and secure, its popularity means that, when something goes wrong, it's generally a pretty big deal.



The biggest previous mess brought to us by OpenSSL was a worrisome little flaw that became known as Heartbleed.  Ouch.  And any of our listeners from seven years ago will appreciate what a ruckus Heartbleed created back in 2014.  What the two recent discoveries lack, probably, is marketing.  Somehow naming this CVE-2021-3449 just isn't nearly as catchy as Heartbleed.  And there's no wonderful dripping blood logo.  But it is still quite worrisome.  And I think we've probably not heard the end of it.



Last Thursday morning cryptographic engineer Filippo Valsorda tweeted:  "CVE-2021-3449 looks like it could have been found easily if anyone figured out how to fuzz renegotiation."  But, he said:  "Renegotiation is sadness."  He says:  "Anyway, sounds like you can crash most OpenSSL servers on the Internet today."  And that is true.  Bottom line, this lets you crash most OpenSSL servers, which is to say most Linux-based and Unix-based servers.



Okay.  So that brings us to last Thursday's OpenSSL Security Advisory from the 25th of March.  It had two pieces.  The first was NULL pointer deref in signature_algorithms processing.  And it's describing this first of the two problems, 3449.  They rated its severity as high.  And they said:  "An OpenSSL TLS server may crash if sent a maliciously crafted renegotiation ClientHello message from a client.  If a TLS v1.2 renegotiation ClientHello omits the signature_algorithms extension where it was present in the initial ClientHello, but includes a signature_algorithms_cert extension, then a NULL pointer dereference will result, leading to a crash and a denial of service attack."



They said:  "A server is only vulnerable if it has TLS v1.2 and renegotiation is enabled, which is the default configuration.  OpenSSL TLS clients are not impacted by the issue, only servers."  And they said:  "All OpenSSL 1.1.1 versions are affected by this issue.  Users of these versions should upgrade to OpenSSL 1.1.1k."  They said:  "This issue was reported to OpenSSL on the 17th of March 2021 by Nokia.  The fix was developed by Peter Kaestle and Samuel Sapalski from Nokia."



Okay.  So note that the advisory just told any malicious prankster how to down most of the Internet's servers that use OpenSSL to provide TLS v1.2 support, which is pretty much everything today.



LEO:  Crikey.



STEVE:  So that's why I said I don't think that we have heard the last of it.



LEO:  That's not good.



STEVE:  No.  The good news is taking servers down hopefully is less gratifying today than it would have been 15 years ago.  Today they want to crawl in there.  They want to set up their cryptocurrency miners.  They want to...



LEO:  Yeah, it's just malicious malarkey versus actual valuable stuff.



STEVE:  Right.  Still...  



LEO:  There's still malicious malarkey out there.



STEVE:  It is.  And having servers down can be pesky.  So if anyone notices that their servers are crashing suddenly for no obvious reason, well, you want to update your OpenSSL.



LEO:  I'm logging in right now.



STEVE:  Okay.  Now, that seemed a little tricky; right?  The other OpenSSL problem that was also fixed last Thursday could best be described as a weirdo edge/corner case that you'd really need to try hard to create.  But if you did, the result would be a true bypass of certificate verification in OpenSSL.  And that would obviously be very bad since, if you cannot authenticate the identity of the party you're having a private conversation with, it doesn't really matter if it's a private conversation.  It could be a man in the middle or anyone that you're actually talking to.



So as I was writing this, I thought, I'm tempted to share the advisory's description just so you'd have a clear example of exactly what a "weirdo edge/corner case" exactly sounds like.  And then I thought, oh, what the hell.  Here's how.  The advisory describes the problem that they also fixed.  This is CA (Certificate Authority) certificate check bypass with X509_V_FLAG_X509_STRICT.  Also severity high.  Again, this is an authentication bypass for the certificate chain in OpenSSL and anything you use it for.  So not good.



So here it is.  They write:  "The X509_V_FLAG_X509_STRICT flag enables additional security checks of the certificates present in a certificate chain.  It is not set by default.  Starting from OpenSSL version 1.1.1h, a check to disallow certificates in the chain that have explicitly encoded elliptic curve parameters was added as an additional strict check.  An error in the implementation of this check meant that the result of a previous check to confirm that certificates in the chain are valid CA certificates was overwritten.  This effectively bypasses the check that non-CA certificates must not be able to issue other certificates."  Whoops.



"If a purpose" - as in one of the declared purposes for the certificate.  "If a purpose has been configured, then there is a subsequent opportunity for checks that the certificate is a valid CA.  All of the named purpose values implemented in libcrypto perform this check.  Therefore, where a purpose is set, the certificate chain will still be rejected, even when the strict flag has been used.  A purpose is set by default in libssl client and server certificate verification routines, but it can be overridden or removed by an application.



"In order to be affected, an application must explicitly set the X509_V_FLAG_X509_STRICT verification flag and either not set a purpose for the certificate verification or, in the case of TLS client or server applications, override the default purpose.  OpenSSL versions 1.1.1h and newer are affected by this issue.  Users of these versions should upgrade to OpenSSL 1.1.1k," the one that just came out.  And this issue was reported to OpenSSL on the 18th of March by Benjamin Kaduk from Akamai and was discovered by others at Akamai.  The fix was developed by Tomas Mraz.



So we're not going to lose any sleep over that one.  It must have been, you know, this is not something you would discover like in the wild or in the field or anywhere.  It must have been that the guys at Akamai were perusing the OpenSSL source because, again, this was only introduced in .1h, and we're on "k."  So they must have been looking at the source and spotted the logic flaw that way.  It's never good, as I said, to have any way around authentication in a system whose entire purpose is authentication.  So it'll be good to have this one resolved.  But there are a bunch of servers out there.



It's unlikely that the situation exists that actually allows this to be triggered in the wild.  And that "h" subversion came out last September.  So the window of opportunity, like from September till now, "h" through "k," is just not that wide.  It's nothing like the 11-plus years during which Exchange Server has had these flaws, thus all Exchange servers, even ones out of currency, are vulnerable to the Exchange Server problems.  But still it's good to get these things patched.  I'm sure that when we issue our command to check for libraries in Linux or Unix that need to be updated, OpenSSL will now pop up.  And it's like, yep, let's get that code updated.



SolarWinds keeps finding new critical problems within its own code.  Last Thursday was a busy day.  SolarWinds released a new update to its Orion networking monitoring tool to fix four security vulnerabilities, including two that could be exploited by an authenticated attacker to achieve remote code execution.  So that's better than unauthenticated, but perhaps not enough better.  We've talked about JSON deserialization flaws, about how deserialization inherently requires interpretation, and how difficult it is to create perfectly robust interpreters.  The programmers who write these serializers, and that's something that turns a dense data structure into some sort of a series of bytes which you can then store, and then later you deserialize in order to restore the original data structure.



Invariably the guys who wrote the deserializers are the same ones who wrote the serializers, or at least the spec, the serialization spec.  And the assumption is too great that the data that the deserializer will be receiving came from the serializer that the same guys wrote.  So the point is you just make the assumption that valid data is what you're being asked to deserialize.  And we have seen time and time again that that results in vulnerabilities which create buffer overruns which end up being critical, must-fix-now problems.  And the Orion Web Console has one of those.  



The second issue concerns a high-risk vulnerability that could also be leveraged by an adversary to achieve remote code execution in the Orion Job Scheduler.  The release from SolarWinds notes:  "In order to exploit this, an attacker first needs to know the credentials of an unprivileged local account on the Orion Server."  So not privileged, but at least some credentials required.  And both of these came from Trend Micro.  There are also two others, a high-severity stored cross-site scripting vulnerability in the "add custom tab" within the customized view page and a reverse tabnabbing - we've talked about that in the past - and open redirect vulnerability in the custom menu options page, both of which require an Orion administrator account for successful exploitation.



So it does sound like the really bad egregious problems are - they are no longer finding those.  So it brings a number of other improvements and fixes along the way.  But, you know, as I'm thinking about SolarWinds and how bad a problem they've had,  how many problems have been fixed, it sort of begs the question, I think, that certainly many people in government and industry must be asking themselves:  Should SolarWinds now be abandoned for a hopefully more secure alternative?  The key of course is whether an alternative would truly be more secure.  It could be that with all the hot water that SolarWinds has recently been in, their code finally got the deep cleansing security scrutiny that it had always needed, so that now it's actually the better solution compared with the others that perhaps haven't had the scrutiny that SolarWinds' time in the spotlight has given it.



It's somewhat like the dilemma that an employer faces after discovering some errant action of an employee who sincerely apologizes after being called onto the carpet for it.  Is it better to then sever the transgressor's employment over that mistake, or are they now a better employee for having learned a valuable lesson?  Again, the age-old dilemma.  In the case of SolarWinds, my feeling is that bad code somehow got in there in the first place, and it wasn't found.



So to keep me as a customer in the long term - and I'm not a customer of SolarWinds, but if I were - to keep me I would need to be convinced that not only were all of this handful of flaws patched up and fixed, and that's good, but that the flawed system that created them in the first place had also received what was apparently some much-needed attention and patching.  So tough to decide whether you leave something that's been fixed because it was once broken, or think, well, now it's fixed, so the devil you know.



Cloudflare is continuing their move toward offering more and more security-related services.  Last week they announced and debuted a web browser virtualization service as part of their Cloudflare for Teams offering.  They call it "Zero Trust Browsing."  I just really like the things that these guys are doing.  Their description explains the motivation behind it.  They said:  "Cloudflare's Browser Isolation service makes web browsing safer and faster for your business, and it works with native browsers.  Web browsers," they said, "are more complex and sophisticated than ever before."  And, boy, is that a theme of the podcast.  They said:  "They're also one of your biggest attack surfaces."  Again, hello, yes.  "Cloudflare Browser Isolation is a Zero Trust browsing service.  It runs in the cloud away from your networks and endpoints, insulating devices from attacks."



They said:  "Secure Web Gateway policies are too restrictive, or too relaxed.  No secure web gateway can possibly block every threat on the Internet.  In an attempt to limit risks, IT teams block too many websites, and employees feel overly restricted.  Then there's malicious content, which is difficult to spot and costly to remediate.  Innocuous webmail attachments, plugins, and software extensions can disguise harmful code.  Once that code travels from a user's browser to their device, it can compromise sensitive data and infect other network devices."  And they wrap up, saying:  "IT teams have limited power to manage browser activity.  Organizations often do not have full visibility into or control over the browsers their teams use, keeping them from meeting compliance standards and securing the users, devices, and data over their network."



So we might think of it like Remote Desktop for browsers.  But the desktop is not being remoted.  Only the browser's fetch and render engine is remote.  The browser's network communications, all the stuff it fetches, all the interpretation it does, the scripting it runs, the rendering it does, all live at Cloudflare.  And Cloudflare sends the rendered visual result, and only the visual result, to the user's browser.  And apparently they're able to pull this off so that the lag is negligible, unnoticeable.



And I was thinking about this.  You know, given how insanely complex today's web pages have become, reaching out to so many differing third-party servers to pull page sub-assets, it does make a certain sort of sense to outsource that entire process, that entire machine, to a capable and well-connected cloud provider like Cloudflare.  Their DNS servers can have massive caches to minimize the need for lookups.  And we know that, when you share a big cache, a big DNS cache, with a lot of people, the IPs you're looking for are already going to be in the cache.  So that's a win.  And in fact they can also have massive caching proxies for the Internet.  Which means that everything can be network-local to that browser cloud engine.  So you could theoretically render pages at lightning speed by dramatically reducing all lookups and network transit delays, blast the page together, then intelligently send the post-rendered page result to the user, thus completely offloading all of that work and protecting the user.



And of course the whole point of this is that anything that attacks the browser is then also remote, since there's not any system to attack at the remote end, just this browser, this virtual browser.  And the only thing the user receives are post-digested page image results.  And it's interesting also because, by the end of today's podcast, where we'll be talking about the hack of the PHP project's private Git server, we wind up looking at the growing trend toward outsourcing of services for which little local value can be added.  If we cannot add any value to a service, why do it ourselves, especially if there's a downside.



And when you think about it, why are we all pulling all of these disparate web browser assets redundantly from all over the Internet to each of our own individual web browsers?  It really does make a sort of sense to imagine having a "browser service" that does all of that non-value-addable redundant work for us, then sends us only a safe, attack-free, already digested final result.  It's going to be interesting to see how this evolves.  If anyone's curious to learn more, I have a link to the Cloudflare page describing their new browser isolation feature in today's show notes.  It's Cloudflare.com/teams/browser-isolation.  Really sort of an interesting idea, I think.



And I just wanted to sort of plant a flag on the issue of API security, a report that was recently out from, not surprisingly, a company that is selling API security.  So there's that.  But it had some interesting stats, and it is a thing.  So the original concept of an API didn't need any security.  There was no such thing as API security.  It was entirely local.  Operating systems offered their underlying services through calls to operating system functions, like asking the OS to launch a process to allocate some memory, to open a file and read its contents.  And because there were operating system applications, and programmers used these service calls, over time they became known as application programming interfaces, APIs.  And the operating system was then sent to be the publisher of these interfaces.



So generically what evolved was the idea of carefully and clearly defining a set of function calls that one entity would publish, meaning to offer, which would then be consumed or used by one or more API users or consumers.  The big change then happened with networking, the introduction of networking.  It occurred to developers of increasingly sprawling systems and solutions that whereas web browsers had traditionally been using HTTP queries and responses to obtain things to show on the page, there was no reason why the parameters used by traditional local operating systems and other application APIs, which were typically binary parameters, could not be turned into well-formed text and sent over the wire in exactly the same fashion as HTTP web traffic.  So network APIs were born.



The problem is that insufficient attention has been given to the security of publicly exposed APIs.  And consequently, attacks against APIs are another area of growing malicious interest.  So this is forcing enterprises to start taking the security aspects of API adoption more seriously.  So the good news is the need for security is on people's radar.  And according to this report, 91% of the IT professionals they surveyed claim that API security should be considered a priority over the next couple years, especially since more than 70% of enterprises are estimated to be using more than 50 different sets of APIs.



The main aspects of API security which respondents considered to be a priority is access control, which was cited by 63% of those, and I'm surprised that number's so low, I mean, like access control is everything; regular testing, 53%; and anomaly detection and prevention, 43%.  Again, I'm not sure why all that's not 100, but okay.  So maybe someday.  In total, eight out of 10 IT admins want more control over their organization's APIs, like sophisticated API-aware firewalling.  Yet tools for that are currently kind of lacking.  And then a couple other stats jumped out at me:  19% of enterprises test their APIs for signs of abuse.  Okay.  Meaning that 81% don't?  Four out of five organizations enable their partners or users to access data using external APIs; right?  That's not surprising, 80%.  That's often what these APIs are doing.  They're information-sharing APIs.



The current focus of network API strategies are centered around application performance and development and integration.  And, finally, 64% of survey respondents said their current solution is to not provide robust API protection.  So anyway, there's no takeaway for us at this point.  But I just wanted to put it on everyone's radar, as I said.  We're seeing an ever-increasing amount of automation.  IoT is all about, I mean, like IoT is networked APIs.  When I've got an IoT thermostat, and I've got a humidity reader, and I've got a few of those AC plugs on timers, that's all network API.  And so it's going to explode with the continuing explosion in IoT.  So I have a feeling that we'll be talking about exploits explicitly against networked APIs in the future.



So SpinRite.  The work on 6.1 is moving nicely forward.  And although in one sense - and now I'm gaining like experience with this conversion; right?  In one sense it's the same SpinRite, but with direct maximum performance hardware support for IDE and SATA drives through ATA and AHCI interfaces.  Doesn't sound like a big deal.  The implication, though, is that sector addressing is expanded from 32 to 64 bits.  Since it was the 32-bit sector addressing that clamped all previous SpinRite at 4.3 billion sectors.  Right?  4.3 billion.  We're running across that number all the time.  That's the number of 32-bit IP addresses on the Internet.



Well, that's also the number of sectors you can address with 32 bits, 4.3 billion.  And back in '04, when I finished with SpinRite 6, that was all we were ever going to need; right?  Uh-huh.  Well, that's only 2.2TB.  So for SpinRite to be able to run on today's drives, meaning all of today's drives, I am needing to support 64-bit sector addressing.  And since sector addressing is SpinRite, I am needing to update everything.



But I'm very happy with the way it's coming along.  Before I began, I worried that it wasn't going to be any different, and that SpinRite 6.0's users, upon getting 6.1, might think, what did I wait all this time for?  But in the process of moving through the code, I am making many improvements.  So SpinRite 6.1's users will definitely notice a different-looking SpinRite.  Many places where, I mean, I've had to rework things because the underlying plumbing had to be reworked.  And while I'm at it, I'm making it better.  So anyway, we're getting there.  And I'm very pleased with the way it's coming.



LEO:  Yay.



STEVE:  And Leo, I am very pleased with the way this podcast is coming.



LEO:  It's rolling right along now that the microphone solutions have all been applied and all that stuff.  Hey, I was going to mention, we interviewed on Triangulation about a year, two years ago a guy named Scott Petry.  In fact, I remember Scott because he was a former Newton engineer, and I have all this Newton stuff that he sent along.  But he had a company called Authentic8, with the number 8, that did virtual browsing.  It was the same idea as Cloudflare's doing, where you would use their browser in the cloud and render it locally.  So I wonder if Cloudflare acquired them, or maybe they just didn't - it wasn't unique enough.  They call it Silo.  I remember playing with it at the time and thinking, that's a pretty cool idea.



STEVE:  Well, and of course one of the offshoots of Chromium, right, is that rendering is now open source.  So, you know...



LEO:  Right, right, right.  You could render, yeah.  I think eventually a lot of what we do in computing, including running Windows, is going to be done that way, just run on servers.



STEVE:  Microsoft is talking about it.



LEO:  Yeah, they already have it, virtual desktop.



STEVE:  I mean, they're like, yeah.



LEO:  I think it's where they're headed.



STEVE:  Don't you worry about those pesky bugs.  Just, you know...



LEO:  Well, that's a good candidate for it.  Let them update it.  Let them deal with the flaws and all that stuff.  It's on their servers; right?



STEVE:  Yeah.  And if you can't run Windows for an afternoon because of a widespread outage, that's really okay; you know?



LEO:  Take the day off.



STEVE:  We should walk more.



LEO:  Well, there's already - you probably aren't too aware of it, but there's already several gaming services that do this.  They have GPUs in the cloud.  Google has one called Stadia.  Microsoft has xCloud.  Gaikai was bought by PlayStation Sony, and they do that.  There's GeForce now.  And all of them they rent - they have powerful machines in the cloud.  And you can use an iPhone or an Android phone to get Triple A gaming because all the work's done remotely.  So we've...



STEVE:  Ah, nice.



LEO:  Yeah.  We've seen this now, and I think this is kind of going to be the, like, big trend in computing.  You're right.  When Azure goes down, not so good.  And not that that ever happens.  Okay, Steve.  I'm ready to learn all about PHP.



STEVE:  So I read all the coverage of this in the tech press.  And I've looked at the source materials.  And no one appears to understand that this had to primarily be a joke hack.



LEO:  Oh.  Not malicious, but a joke.



STEVE:  See if you don't think so by the time I give you my perspective.  I think it was perpetrated by someone who arranged to compromise either the PHP Project's private Git server, as they believe, or the account of someone.  Perhaps I'm missing something.  But everyone appears to be taking this like a super serious attempt to actually sneak a backdoor into PHP.  I don't think that's...



LEO:  They committed updates that had backdoors in them, basically; right?  No?



STEVE:  Yeah.  Okay.  So the code is a backdoor.



LEO:  Okay.



STEVE:  Sort of.  I'll explain that in a minute.  But to the degree that it's a backdoor, it's not some sneaky, stealthy backdoor hiding in the shadows.



LEO:  Yeah, in fact, PHP says, well, we noticed and fixed it within minutes; right?



STEVE:  Well, it's a backdoor embellished with big neon signs reading, "Hey, check out this wide-open backdoor I just created here."



LEO:  Oh, oh, okay.



STEVE:  So, yeah, it's a backdoor, but it's screaming to be found.



LEO:  Yeah, yeah.



STEVE:  Okay.  So here's the code that was submitted.  I've got the code in the show notes, and I know our listeners can't hear it, but I'll explain what the code does.  So as we know, every browser query to a server identifies the browser, and typically a collection of its add-ons which may have been added to the browser, by sending a user-agent header, U-S-E-R hyphen A-G-E-N-T colon space and then the value of the header.  The PHP code  that was inserted into the repository, which you've got onscreen now in the show notes, it extracts the value of the HTTP user-agent header from the http_globals array that was built by PHP to describe the query.  It holds that string, or it holds that value, the value of that header in a string named "enc" which it had declared up at the top.



It then checks to see whether the first eight characters of the user-agent header value are zerodium, Z-E-R-O-D-I-U-M.  If it finds that the user-agent header does indeed begin with the eight characters zerodium, it then feeds the rest of the string, skipping those first eight characters, as one would, into PHP's insanely dangerous eval function, which interpretively executes whatever PHP code is passed to it, which is whatever is contained in the balance of the string.  And driving the joke home, as if the presence of the trigger string test for zerodium were not glaring enough, our hacker then tosses in a quoted string reading in all caps:  REMOVETHIS colon space, and then it says "sold to zerodium, mid-2017."  It's like, what?



LEO:  It's an old exploit.  Is that what he's trying to say?



STEVE:  Well, yeah, exactly.  This person who put it in two days ago was trying to say somehow you've missed this for the last four years.  Okay.  The official PHP documentation for the eval function reads:  "Caution."  Caution, bold larger type.  Then it says:  "The eval language construct is [in italics] very dangerous..."



LEO:  Flawed.



STEVE:  Exactly.



LEO:  That's why we put it in.



STEVE:  Oh, exactly, "...because it allows execution of arbitrary PHP code."  Then again, italics, all italics this sentence, "Its use thus is discouraged."  But of course, but it's there; right?  And they say:  "If you have carefully verified that there is no other option than to use this construct, pay special attention," and now we're going to switch into italics again, "not to pass any user-provided data," now back to non-italics, "into it without properly validating it beforehand."



Okay.  So of course feeding user-provided data into the eval function is precisely what this little glaringly obvious snippet of code does.  But it's that it's so glaringly obvious, deliberately calling attention to itself with the all caps "REMOVETHIS" as in, what?  Remove this before use?  Or don't leave any of this in here since it's a hack that was sold to Zerodium many years ago?  It makes no sense.



LEO:  It doesn't execute.  And by the way, evaluating it doesn't make sense, either.  It doesn't do anything; right?



STEVE:  Well, okay.  So first of all, Zerodium's CEO was not impressed by this.  He tweeted that the culprit was a "troll."  That's his word.



LEO:  Yeah, yeah.  That's accurate, yeah.



STEVE:  Commenting that - this is the guy, the CEO:  "Likely, the researcher(s) who found this bug/exploit tried to sell it to many entities, but none wanted to buy this crap, so they burned it for fun."  Okay, now, wait.  What?  Maybe he also misunderstood this.  It was a commit to the PHP Git server two days ago.  It's not like it's been hiding in PHP since 1950 and no one noticed it until now.  I mean, that entire block was added, not, like, a few characters changed to make this happen.  And also interestingly, I thought this was interesting, the name of the actual header being checked is HTTP_USER_AGENTT.  It's got two T's on the end.



I checked in with Rasmus, Rasmus Vind, who is, as we know, my go-to guy for all things PHP, to verify that PHP would, in fact, populate the http_globals array with any and all client headers it found in the query.  He wrote some code to demonstrate that it does.  So we'd have to presume that using the deliberately misspelled twice, it's not just misspelled once because he's using it, and then he's also taking the size of it elsewhere, that using HTTP_USER_AGENTT with the extra "T" was the hacker's way of hiding the use of what is actually a custom header in a lookalike header that might go unnoticed maybe.  I mean, I saw it right away.  But on the other hand, I program in assembler so I look for details.  But maybe you would miss it in a cursory scan.



It might also be that commandeering the actual HTTP_USER_AGENT header for this purpose, that is, Zerodium and then some code, could have unforeseen side effects like causing the query to be blocked elsewhere.  And finally, in an exercise, I don't know, dry wit or maybe a twisted sense of humor, the hacker gave their commit the title "Typo Fixed" and in the detail just says "Fixes minor typo."  But it's a block of code.  I mean, anyone who looks at it sees a block of code that's been added.



So on the serious side, what we definitely had here was a true, completely unauthorized incursion into the PHP private Git server.  Had it gone unnoticed, if a tiny tweak had been dropped in, for example, the damage throughout the industry could have been substantial.  But it was designed to be seen.  Like, first of all, "Typo Fixed," and it's a block of new code?  So again, you can't possibly.  And then this Zerodium with the all caps REMOVETHIS.  Your eye goes immediately to that.



So yesterday Nikita Popov, a well-known software developer at JetBrains and an active open source contributor - he works with PHP, the LLVM project and Rust efforts - he posted under the subject "Changes to Git commit workflow."  And he wrote:  "Hi, everyone.  Yesterday 2021-03-28" - so two days ago for us.  He said:  "Two malicious commits" - only because it was like that block was created in two pieces - "were pushed to the php-src repo from the names of Rasmus Lerdorf, the creator of PHP..."



LEO:  The creator of PHP.



STEVE:  "...and myself."



LEO:  Oh, wow.



STEVE:  He said:  "We don't yet know how exactly this happened."



LEO:  It sounds like the credentials were compromised.



STEVE:  I think it's a credential hack.  But he says, for whatever reason, he says no.  He says:  "But everything points towards a compromise of the git.php.net server," he says, "(rather than a compromise of an individual git account)."



LEO:  Oh.  That's much worse, actually.



STEVE:  Yeah, exactly.  He said:  "While investigation is still underway" - and Leo, that is the point, what you just said.  "While investigation is still underway, we have decided that maintaining our own git infrastructure is an unnecessary security risk."



LEO:  Yes.  No one else does, yeah, yeah.



STEVE:  "And that we will discontinue the git.php.net server.  Instead, the repositories on GitHub, which were previously only mirrors, will become canonical.  This means..."



LEO:  Good.  That's sensible.



STEVE:  Yes, "...that changes should now be pushed directly to GitHub rather than to git.php.net.  While previously write access to repositories was handled through our homegrown karma system, you will now need to be part of the PHP organization on GitHub.  If you are not part of the organization yet, or don't have access to a repository you should have access to, contact me at" - and he has his email address - "with your php.net and GitHub account names, as well as the permissions you're currently missing.  Membership in the organization requires two-factor authentication to be enabled.  This change also means that it is now possible to merge pull requests directly from the GitHub web interface.  We're reviewing the repositories for any corruption beyond the two referenced commits.  Please contact security@php.net if you notice anything.  Regards, Nikita."



So this is all good.  The PHP guys are taking the opportunity of this hack to move their work from their private server, where they have been responsible for much more than just the code it contains.  They're moving to GitHub, where they only need to be responsible for the code it contains, and the GitHub folks get to worry about the security of all the rest of the infrastructure, the bandwidth, the capacity, the storage, authentication, attacks, and so on.



LEO:  Focus on your strengths, in other words.



STEVE:  Yes.  And it's worth noting that, as trends go, this is definitely a trend.  I'll remind everyone that about three and a half years ago, when I was participating in that DigiCert customer advisory board meeting in Utah, and I casually referred to my server rack at Level 3, everyone looked at me like I had just dropped an F-bomb on the Disney Channel.  And I said, "What?"  And one of the guys said, "Steve, no one does their own hardware anymore."  And at that point I thought it best not to mention that I also code in assembly language.



LEO:  It's actually an interesting thing.  I've been thinking about this because a lot of people, well, a good example is in the password management sphere.  There are a certain number of more sophisticated users, probably listeners to this show, who say, oh, no, no, no, I don't want to trust my password vault to LastPass or 1Password or any centralized thing.  I'm going to have my own password vault.  And while on the one hand I understand, I mean, you're certainly eliminating a target because everybody knows there's a bunch of vaults at LastPass's storage, wherever that is.  But on the other hand, you now have to attain the level of professional security that LastPass or 1Password presumably has protecting the vaults.  You're assuming the security risk.  Just sticking it on Dropbox, I don't know if that's more secure.



So it's an interesting question and tradeoff.  And I often tell people, I trust LastPass, or Bitwarden because you can do that yourself, you can self-host Bitwarden.  But I trust them to do a better job than I'm going to do.  It's their full-time job.  Same thing with GitHub.  It's their full-time job; right?



STEVE:  Yes.  And, you know, I think certainly in the case of these guys it makes sense.  But one thing we have to remember or recognize is that inherently this approach, this consolidation, which is sort of what we're talking about, puts a lot of eggs into many fewer baskets.  This makes the care and handling of those baskets far more important than ever.



LEO:  Critical, yeah.



STEVE:  We do see reports, and you were talking about it, and I hear about it on the other podcasts, of spotty outages of major services that transiently bring down all users of the affected service at once.  And although I haven't mentioned it before, one of the more notable recent victims of a ransomware attack was one of the largest managed service providers who's been hit with a $20 million ransom demand.



So this sort of consolidation is more cost effective overall.  But I think we need to appreciate that it also creates an inherently more fragile solution.  This consolidation and refactoring of function and responsibility is clearly going to happen.  And a school district can give its students a day or two or a week off if their informatics systems go down.  But mission-critical environments like a hospital might not be able to withstand transient outages.  So it needs to be, just as you said, Leo, it's a tradeoff.



LEO:  Yeah, you need to understand the tradeoff.  It's just not inherently better.



STEVE:  Right, right.



LEO:  And maybe it is.  But the burden now is on you.  If you're going to host your own Git repository, then the burden is on you to keep it secure.  And apparently they weren't able to.



STEVE:  Well, and I think on balance the industry owes this jokester its thanks.



LEO:  Good point.



STEVE:  He or she made PHP more secure and more securable as a consequence.



LEO:  And didn't actually do anything malicious.



STEVE:  Nope.



LEO:  Just called attention to the fact that he could have.



STEVE:  Yes, exactly.



LEO:  Yeah.  So he in a way did us all a favor, yeah.  Because PHP is just everywhere.



STEVE:  Yeah, he dropped a big blurb, something you could not fail to notice, that didn't pass any smell test.  And everyone's like, whoa.  So what the GitHub guys were upset about, I'm sorry, what the PHP guys were upset about was that this happened to them.  What the tech press thought was important was, oh, my god, a backdoor was inserted.



LEO:  Right.



STEVE:  And it's like, no.  This was a good thing, folks, not a bad thing.



LEO:  Yeah.  I understand the reaction, though.  Randal Schwartz got arrested because he was working at, I won't name the name of the company, working at a company and found a flaw.  And he didn't exploit it.  He told them about it.  And they fired him and got him arrested because they said, "You're hacking our system."  And I think this is not that unusual, where there's a gray line.  You're not supposed to be nosing around in there.  But if you find a security flaw, I think you're duty-bound to tell the company you found it.  This is a good way to do it anonymously without getting in trouble.  Who knows.  For all we know it could have been Rasmus's son or somebody like that that did it.  It's a good thing.  There's somebody saying he's not a white hat, not a gray hat, not a black hat.  He's a clown hat hacker.  Okay.



STEVE:  Okay.  And speaking of Rasmus, who that Rasmus is the father of PHP...



LEO:  Lerdorf, yeah.



STEVE:  My Rasmus is a PHP guru.  Leo, you've got a browser in front of you.



LEO:  Yes.



STEVE:  You need to go to www.hiveworkshop.com.



LEO:  Ooh.



STEVE:  That is Rasmus's work.



LEO:  This is the guy who does XenForo.



STEVE:  Well, no.  So this is the guy who is a listener of ours.



LEO:  Oh, he's our listener.



STEVE:  Who when I was saying that I was scratching my head about how am I going to integrate SQRL with XenForo, which is written in PHP...



LEO:  Right, right.



STEVE:  He said, "I use XenForo.  I'd be happy to help."



LEO:  Nice.  So this is a XenForo forum, but...



STEVE:  Believe it or not, that is the most crazy, heavily reskinned, I mean, it's unrecognizable.



LEO:  For fans of World of Warcraft.  That's cool.



STEVE:  Yes.  It bills itself, HiveWorkshop.com, the No. 1  Largest Warcraft 3, whatever this is, Reforged Modding Community.  And I have no idea what that means.  But it is a tour de force in PHP-based CSS and HTML reskinning.  So, I mean, I can barely see XenForo as I know it under there.



LEO:  Yeah, yeah.



STEVE:  But, wow.



LEO:  That's good.  That's funny.



STEVE:  Yeah, great graphics and performance.  He moved to the latest XenForo and is apparently cleaning up some little debris.  But anyway, I just wanted to give him a shout-out because he's been a big help to us and to the podcast.



LEO:  Thank you, Rasmus.  HiveWorkshop.com.  You get a little plug.  How about that?  And you get a little respite for a week.  That concludes this thrilling, gripping edition of Security Now!:  GIT Me Some PHP.  Our own personal joker titled this one.  You'll find Steve at his website, GRC.com.  That's where of course SpinRite lives, the world's best hard drive recovery and maintenance utility.  6.1's coming.  Steve's getting there, making some real good progress.



STEVE:  I'm on it.



LEO:  If you buy 6.0 now, you'll get a free upgrade to 6.1.  More importantly, you'll get to participate in the development of it.  Everybody, if you have a - and I keep saying if you have a hard drive you should have SpinRite.  But because now it works so well and does so much on SSDs, if you have any drive, you need SpinRite.  I'm getting a new system.  I'm going to be getting my SpinRite out to work on the M.2 SSD in it, and it has a spinning drive in it, too.



STEVE:  It will drive you happy.



LEO:  So SpinRite before you - that should be your motto.  SpinRite before you go.  You'll also find 16Kb versions of this show for the bandwidth-impaired, handwritten human-written transcriptions of every word.  Thank you, Elaine.  You'll also find 64Kb audio there.  There's a feedback form on the website at GRC.com/feedback.  There's also a lot of free stuff, including ShieldsUP!, which is really the premier router testing platform.  Any time you install a new router, you should go to ShieldsUP!.  He's also got a lot of other interesting stuff.  It's a rabbit hole you can go down and spend some time.  GRC.com.  He also is on the Twitter at @SGgrc.  You can leave him a DM there.  His DMs are open.  Slide into Steve's DMs.



We have copies of the show at our website, of course, as with all our shows, 64Kb audio plus video.  For some reason we shoot video of it.  That's all at TWiT.tv/sn.  If you're watching us do it live, we do it live right after MacBreak Weekly of a Tuesday.  Usually it's around 1:30 to 2:00 p.m. Pacific.  That'd be 4:30 or 5:00 p.m. Eastern, 20:30 to 21:00 UTC.  Just, you know what, we're on all day.  Go to TWiT.tv/live.  There's a live video stream and live audio stream.  You can check that out.



While you're doing that, chat with our chatroom.  They're watching live, too:  irc.twit.tv.  You can also comment asynchronously, if you listen to the podcast, at Steve's forums at GRC.com.  We also have forums at twit.community, and we have a Mastodon instance.  That's the Twitter clone that's federated.  It's really cool.  We now have enough, I think, critical mass, more than a thousand users, so it's fun.  It's perking up.  That's twit.social.  You're more than welcome to join.



I think, though, if I might, I'd like to encourage you, there's lots of ways to watch the show.  There's even a YouTube channel.  Get a podcast program and subscribe.  That way you'll get it automatically.  You won't have to worry about missing an episode.  And if you would, if they allow reviews in that podcast player, please give us a nice review.  Five stars would be more than welcome.  Steve, thank you very much.  Have a great evening.  Is there an Italian dinner in your forecast for this week?



STEVE:  Oh, yeah.  Steak tonight, Italian on Sunday.



LEO:  Steve's fully vaccinated, and he's living it up.



STEVE:  Ah, yeah.



LEO:  I'm right after you, Steve.  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#813

DATE:		April 6, 2021

TITLE:		A Spy in Our Pocket

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-813.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week, by popular demand, we examine the big cover-up at Ubiquiti.  We look at the consequences of the personal data of 533-plus million Facebook users appearing on the 'Net and how to tell if you're represented there.  We look at another water treatment plant break-in with a very different outcome.  We look at a new move by Google to further lock down Android against abuses of its permissive-by-design API services.  We look at the new threat to Call Of Duty cheaters, and yet another set of serious vulnerabilities in QNAP NAS devices.  Then, after sharing a catchy tweet, we look into some new research from researchers in Ireland into the unwarranted chattiness of iOS and Android mobile phones.



SHOW TEASE:  Coming up next on Security Now!, it's me, Jason Howell, filling in for Leo Laporte this week.  But you've come for Steve Gibson, and he is here to deliver.  He talks all about Facebook's major data leak and what's going on there.  It happened a couple of years ago, but now all that data is out.  You were warned.  Also a threat to Call of Duty cheaters, the cover-up at Ubiquiti, and just how much do these devices that we have in our pockets, how much are they sharing our data?  Well, Steve has all the numbers to share with you next on Security Now!.



JASON HOWELL:  This is Security Now! with Steve Gibson, Episode 813, recorded Tuesday, April 6th, 2021:  A Spy in Our Pocket.



It's time for Security Now!, the show where we talk about the week's biggest security news.  And we have just the guy to do it.  I'm Jason Howell.  I'm not the guy.  I'm filling in for Leo Laporte, who is out enjoying time away from TWiT for a change because he's been here like the last year solid because of the pandemic and everything.  So I'm super happy to sit in for Leo.  But the guy I'm talking about is Steve Gibson.  He's the guy you really tune in for.  How are you doing, Steve?



STEVE GIBSON:  Hey, Jason.  Great to be with you again for your fill-in week.  And yes, we know from the things that Leo has shared publicly that he lives to travel.  He's found a travel mate that he really enjoys, and he's been stuck in COVID land, like, going stir-crazy.



JASON:  As we all have.



STEVE:  And he was saying, I heard him say the other day that he's off to Mexico or something in October.  I don't remember where it was he was going.



JASON:  Yeah, he's got a bigger plan, a bigger trip planned later.



STEVE:  A little brief one, and we'll have him back.  But anyway, this is Episode 813 for the 6th of April.  I titled it "A Spy in Our Pocket."  There's some new research out of some security guys in Dublin, Ireland, who went to the trouble of - they've done some research that was sort of like this previously, but they expanded their look.  They've got the technology to watch the cellular communications of both - in their case they looked at the top two mobile phone families, iOS and Android - and looked at just how chatty they were.  And it's a good thing that hard drives are as cheap as they are because, given the install base of these drives, I've got the numbers in the notes, but they're spooling terabytes of data an hour across their entire install base of devices.  But we'll end up talking about that.



We've got a bunch of interesting stuff.  By popular demand, I can't tell you how many of our listeners wanted to make sure I had heard about this.  We've got the big cover-up at Ubiquiti.  I'll be talking about that a little bit later and why all of our listeners were saying, hey, Steve, did you know about this?  We're also going to look at the consequences of the personal data of 533-plus million Facebook users just a few days ago appearing on the 'Net for free.  And also, happily, how to tell if you might be represented there.



We're going to look at another water treatment plant break-in that had a very different outcome than the one in early February in Florida.  Also we look at new moves by Google to further lock down Android against abuses of its original permissive-by-design API services.  You know, they wanted to be the alternative.  It's going to be open.  Everybody's on the same side.  Like, well, not so much.  So we've seen a succession of tightenings that they've had to do, and we're going to talk about another one today.  We also are going to look at, because all of the tech press was just all over this story, the new threat to Call of Duty cheaters; and also another set of serious vulnerabilities in QNAP NAS devices, which I try not to talk about because there are so many of them, sort of like ransomware.  But anyway, we have to because QNAP is just bad.



Then, after sharing one catchy tweet that as a coder I really appreciated, we'll wrap up by talking about the research from Ireland into the fact that we really do have spies that we carry around in our pockets, and just what's being spied on.  Oh, and we have a terrific Picture of the Week.  So I think another great podcast for our listeners.  



JASON:  Absolutely.  And let's just get this out on the record right now.  You didn't fill this rundown with Android stories because I'm on today.



STEVE:  That is true.  It's the powers, they're inscrutable.  Somehow Mr. Android is here on an Android-heavy episode of Security Now!.



JASON:  I lucked out.  Right on.  Well, we've got a whole lot of great stuff to talk about.  Thank you, Steve, for that.  All right, Steve.  Let's get to this pic right here.  I know I've seen this at the playground, but it takes on new meaning here.



STEVE:  Well, I just got a kick out of it.  Somewhere on Twitter, I think someone sent it to me.  For those who are not looking at video, it shows a park with some kid-friendly, jungle gym-y sort of things in the background, and one of those tube slides, like made of real industrial tubing, that a kid would get in, like climb up the ladder at the high end, get in, and then slide down the inside and come shooting out of the end, down like to hit nicely sawdusted covered ground.  Anyway, this shows that the end, the output end is covered over.  There's a bolted piece of plywood completely closing the exit.  And someone has written "Slide Closed" on there.



And this was titled "A Backend Fix for Frontend Issues," which I got a kick out of, of course, from a computer science standpoint.  We're hoping that the top of the slide, which is out of the picture, we can't see it, similarly has a big piece of closed plywood bolted across it because otherwise you'd be in trouble; you know?  Kid would get in the front end, slide down, hit the back and be like - and then, you know, Mommy would be hearing some screaming about, you know, "Agh," because you have to try to climb back up the tube, I guess.  And worse if you have a pileup down there at the bottom.



JASON:  Yes.



STEVE:  So anyway, we're assuming that the slide people were conscientious and have blocked both openings, the front end and the back end.



JASON:  I certainly hope so.  Although looking closely at this side...



STEVE:  It does beg the question. 



JASON:  Yeah, it really does.  We don't know for sure based on the picture.  But looking closely at this slide, I see down at the bottom there's a little notch.  So at least if you get locked in there, you're not going to run out of air.



STEVE:  And really, if you wanted to close the slide, it occurs to me that just closing the top would do the job; right?  Because if you can't get in at the top, there's no slide to be had.  So kids are mischievous.



JASON:  Although I will say I've seen my kids many times climb up through the bottom.  So you've probably got to close it on both if you really want to keep them out.



STEVE:  I had a childhood we will not go into in any detail.  Okay.  The big Ubiquiti cover-up, the most tweeted-to-me issue in quite a while.  Our long-time listeners know that I've been a fan of the Ubiquiti EdgeRouter X, which is an amazingly affordable five-port Ethernet router.  I think it was like $49, max $49 at the time on Amazon.  And the thing that drew me to it was that its five interface ports were actually individual NICs, actually Network Interface Controllers.  It wasn't a router hooked like a one-port WAN and then four ports of LAN, where they were actually just a digital switch so that, for example, they were all related to each other.  These were individual NICs, which meant they could each have their own subnet to create a truly segmented network on the LAN side.  And as I've often preached, this is the only way, that is, network segmentation.  And yeah, you can potentially use a VLAN, but it's, I mean, it's a little more tricky to do that.  So this is the way to create a secure environment on today's LAN.



With many of our IoT devices, immediately upon hooking them up, phoning home to Chinese cloud services, there can be no true security if those devices are allowed to sit on the same network as the family's or small business's LAN.  You're just, sooner or later, we're going to be talking about this on the podcast.  So IoT devices must be given their own isolated network.  And at the time the Ubiquiti was the only cost-effective solution for doing that.



Today, a feature of more modern consumer WiFi routers is to have one or sometimes two guest channels which support explicit inter-network isolation.  Sometimes when I'm unable to reach my Sonos speakers from my iPad, it's because they're on the IoT WiFi, and my iPad is on the real WiFi, the inter-secure device WiFi.  And they can't see each other.  Which is what you want.  So since we so often talked about Ubiquiti, it should be no surprise that many of our listeners have made sure that I knew of the mess that has recently erupted over there.  It was fresh last week.  I got some early indications on Tuesday morning.  But there was still some, I mean, I quickly took a look at it.  Some things were still unknown.  Brian Krebs, who was much involved with this, was still sort of working out the details.  So I decided just to hold off.



Now we know much more.  It appears clear that Ubiquiti has been proactively covering up the extreme customer-affecting severity of a data breach that put probably all, many of their customers' networks at significant risk of unauthorized access.  Brian Krebs has cited an internal and unnamed whistleblower from within Ubiquiti.  And Brian is very careful.  If Brian says this, he has vetted the crap out of it.  I mean, I would absolutely believe what Brian is posting on his site, KrebsOnSecurity.com.  So in January Ubiquiti seriously downplayed what it said was "unauthorized access to certain of our information technology systems hosted by a third-party cloud provider."



Okay.  So while that was literally correct, it was also quite vague.  The notice said that, while there was no evidence the intruders accessed user data, the company couldn't rule out the possibility that they obtained users' names, email addresses, cryptographically hashed passwords, addresses, and phone numbers.  Ubiquiti recommended at the time that users should change their passwords and enable two-factor authentication.  So at this point that's standard generic post-breach boilerplate.  But last Tuesday's report from Brian was able to flesh this out by citing that security professional within Ubiquiti who helped the company respond to the two-month-long breach, which it turns out began in December of 2020.  Brian's inside source reported that the breach was much worse than Ubiquiti had disclosed publicly, thus my term "cover-up," and that executives were minimizing the severity to protect the company's stock price.  So, you know, no surprise there.



And to make matters worse, the breach follows Ubiquiti's push, if not, well, it is now, it's become an outright requirement for cloud-based accounts for users to set up and administer the devices running their newer firmware versions.  An article on Ubiquiti's site says that during the initial setup of, for example, a UniFi Dream Machine, which is a popular router and home gateway appliance, users will be prompted to log into their cloud-based account; or, if they don't already have one, to create an account.  And I'll just note this is similar to my annoyance with some versions, apparently not all, though, because I've managed to bypass it, but Windows 10 is now like there had been a way to just say no, I do not want to log into Microsoft in order to create an account on my Windows 10 machine.  I want to just do it offline.  And you have to now jump through hoops, last time I did that anyway.



So Ubiquiti's page states:  "You'll use this username and password to log in" - get this - "log in locally to the UniFi Network Controller hosted on the UDM, the UDM's Management Settings UI, or via the UniFi Network Portal for Remote Access."  So, I mean, somewhere, misguided though this was, they thought, oh, everything is cloud.  We want cloud.  Our users want cloud.  They were wrong there.  But so even to talk to the thing sitting next to you, the blinking lights that you can see, you log into the cloud, and then they reach back to it.  It's like, oh, this is a recipe for disaster.



So these changes had not gone unremarked upon.  Ubiquiti's customers are decidedly unhappy, complaining about the cloud login requirement and the risk it inherently poses to the security of their devices.  Any of our listeners would understand that this is not a good idea.  I mean, okay, in some use cases yes, but not as a blanket requirement where you can't configure the device whose cord you keep tripping over without logging into some cloud in China.  Thank you.



So as I noted previously, according to Brian's inside contact - and he calls this guy "Adam" just for convenience.  So we don't know his name, so we'll call him Adam.  After all, Adam was the start of all this.  The data that was accessed, Adam alleges, was much more extensive and sensitive than Ubiquiti portrayed.  So I'll paraphrase a bit for brevity, from what Brian wrote.



He said:  "In reality, Adam said, the attackers had gained admin access to Ubiquiti's servers within Amazon's cloud service."  Okay, so that's that third-party cloud provider that they alluded to back in January.  Turns out it's Amazon AWS "which secures the underlying server hardware and software, but still requires the cloud tenant" - meaning Ubiquiti, the user of AWS services, the cloud tenant - "to secure access to any data stored there."  Which apparently they were a little lacking in.  "They were able" - "they" the attackers - "were able to get cryptographic secrets for single sign-on cookies and remote access, full source code control content, and signing keys exfiltration."  In other words, yeah.  Full admin access rights.



Adam says the attackers had access to privileged credentials that were previously stored in the LastPass account of a Ubiquiti IT employee.  So, okay.  It was secure there.  Oh, let's put it in the cloud.  Anyway, and gained as a consequence root admin access to all Ubiquiti AWS accounts, including all S3 data buckets, all application logs, all databases, all user database credentials, and secrets required to forge single sign-on cookies.  In other words, this entire Ubiquiti cloud infrastructure was compromised, and Ubiquiti had previously forced all of at least their newer users who were upgrading firmware even of older devices to switch to the new and better cloud solution.



So this would allow, Adam was explaining, the intruders to remotely authenticate to countless Ubiquiti cloud-based devices around the world, all those owned by Ubiquiti's customers.  According to its website, Ubiquiti has shipped more than 85 million devices to play a key role in networking infrastructure in over 200 countries and territories worldwide, all of which, or many of which at least, are now vulnerable.  Any that have been updated to use Ubiquiti's now mandatory cloud facility were vulnerable to remote takeover.



And even after all this, Ubiquiti continues spewing the corporate line.  They said:  "As we informed on January 11, we were the victim of a cybersecurity incident that involved unauthorized access to our IT systems.  Given the reporting by Brian Krebs, there is newfound interest and attention in this matter, and we would like to provide our community with more information."  You know, by not doing so.



They said:  "At the outset, please note that nothing has changed with respect to our analysis of customer data and the security of our products since our notification on January 11th.  In response to this incident, we leveraged external incident response experts to conduct a thorough investigation to ensure the attacker was locked out of our systems."  Yes, the barn door has been securely closed and locked.  There's nothing in the barn; but, boy, is our barn secure.  After they were rummaging around and took everything for two months.  



"These experts," they continue, "identified no evidence that customer information was accessed, or even targeted."  Okay.  "The attacker, who unsuccessfully attempted to extort the company by threatening to release" - right, that information that apparently wasn't stolen in the first place.  Okay, I'm sorry - "by threatening to release stolen source code and specific IT credentials, never claimed to have accessed any customer information."  Though having it all.



"This, along with other evidence, is why we believe that customer data was not the target of, or otherwise accessed in connection with, the incident.  At this point, we have well-developed evidence that the perpetrator is an individual with intricate knowledge of our cloud infrastructure.  As we are cooperating with law enforcement in an ongoing investigation, we cannot comment further.  All this said, as a precaution, we still encourage you to change your password if you have not already done so, including on any website where you use the same userID or password.  We also encourage you to enable two-factor authentication" - maybe you should use three - "on your Ubiquiti accounts if you have not already done so."



So okay.  Our takeaway for the podcast is that Ubiquiti's skeptical customers were 100% correct to object to upgrades of their systems' firmware which offered them no alternative other than to manage their own local devices through an online cloud service.  That's insane.  And this meant that all of these devices were now vulnerable to remote access compromise, though they had never been before this cloud centralization.  It was clearly wrongheaded from the start.  Anyone using these cloud-attached Ubiquiti devices should obviously have changed their passwords at the first inkling of this.



And certainly I agree with the advice.  Use two-factor authentication if you can't get three, if you haven't already done so.  And given that intruders into Ubiquiti's network had access to single sign-on cookies and secrets enabling remote access, including signing keys, it would also be a good idea, annoying though it is, to delete any access profiles associated with any of those devices.  Make sure the device is using the latest firmware, and then recreate profiles under brand new credentials.  And of course, as always, remote access should always be disabled unless it's truly needed.  We're going to be running across many things during this podcast where stuff is being done just because it can be.  And that's not security.  That's not secure.



So anyway, that's the story on Ubiquiti.  And yes, I'm up to speed, and I'm certainly disappointed in them.  The good news is there are now better, more modern, much more consumer-friendly alternatives for doing things like setting up sequestered and segmented IoT networks.  Most IoT things are WiFi anyway.  So what we talked about back then was getting an old pokey 10BASE-T or 100 router set up as an access point and plugging it into one of the Ubiquiti router's ports so you could create a sequestered and segmented WiFi that you could, you know, all your plugs and your light bulbs and your thermostats and things could be connected to just because you really just don't want those things on the same LAN as stuff you really care about.  Which is everything not IoT.



So we have Facebook's, and we have a count, 533,313,128 user whoopsie.  We talked a lot about this Facebook breach back when it happened.  It was two years ago, in 2019.  And now the data that was taken during that intrusion has all just been released onto the dark web for free.  You don't have to pay anything.  This includes the full names, real-world names, Facebook IDs, mobile phone numbers, physical locations, email addresses, genders, occupations, city, country, marital status, account creation date, and other profile details which in this massive database are broken down by country, with over at least 32 million records belonging to users in the U.S. alone, 11 million in the U.K., 6 million users in India, and so forth.



So when I saw this I thought, you know, you've got to love it that Facebook has a position there titled "Director of Strategic Response Communications."  You can imagine the conversation.  "Hi.  What do you do?"  "Well, my name is Liz Bourgeois."  It actually is.  "And I'm the Director of Strategic Response Communications for Facebook."  And the person says, "Wow.  So when the you-know-what hits the fan, you're the person who gets quoted in the media while managing to never say anything meaningful."  And Liz responds, "Yes, that's a perfect job description."



In this case Liz said:  "This is old data that was previously reported on in 2019.  We found and fixed this issue in August of 2019."  So, okay.  Well, so the data is old.  Then what?  That creaky old data must no longer apply; right?  People have all changed their names and phone numbers and Facebook IDs.  They all moved and changed their genders and so forth.  So we really don't need to worry that the data of 533,313,128 Facebook users from only two years ago, not so old really, is now being offered for free in bulk on the dark web.  Thanks, Liz.  Whew.  For a while there, this seemed like it might be a big deal.  And that was, by the way, a beautifully executed strategic response.  Very strategic.



JASON:  That's why she is the Director of Strategic Response Communications.



STEVE:  Yes.



JASON:  Put that at the top of your rsum for your next position of that same title.



STEVE:  Someone named Liz Bourgeois to be in charge of your strategic response.  Okay.  So just to remind our listeners, the data is known to have been obtained, we talked about this two years ago, apparently in August, by exploiting a vulnerability in Facebook's Add Friend feature, which enabled automated scripts to scrape with abandon Facebook users' public profiles and associated private phone numbers in bulk.  It's true that the leak was fixed.  And at the time, I remember being somewhat sympathetic to the complexity of doing what Facebook was doing.  We got into the deep details of the API, and it was like, oh, okay, this, you know, you could kind of understand how this happened.



But at the same time, I remember expressing our worry that Facebook's controls allowed it happen in the first place.  We need them to do better.  We need better from them.  And I suspect that for Liz, well, she's likely a lost cause.  If you're wondering whether you might be affected by this massive Facebook data dump, Troy Hunt's Have I Been Pwned site has your answer.  And it just got upgraded since I wrote this last evening, and I have the update.



Troy Hunt - and thanks to Simon Zerafa, whose tweet I saw just before the podcast - Troy Hunt has a long tweet thread on Twitter about his recent addition of the leaked Facebook data appearing on the web.  I've got a link to the tweet if you're curious, and it's on the screen.  Thank you, Jason, or producer, whoever's doing this.  The upshot is that the data appears to be not only incomplete, but sparse when it comes to Facebook user email addresses, which is what Troy's Have I Been Pwned site is currently set up to cross-reference.  Of the 533-plus million Facebook member records, only 2.5 million include an email address.



What we really want in this case is a phone number, which is far more highly represented in the data.  Troy yesterday indicated that he's exploring the possibility of allowing users to search on their phone numbers.  Okay.  Since then, it happened.  He says in his most recent posting over on TroyHunt.com, he said:  "The Facebook phone numbers are now searchable in Have I Been Pwned."  He said:  "The headline is pretty self-explanatory.  So in the interest of time, let me just jump directly into the details of how all this works.  There's been huge," he has in italics, "interest in this incident.  And," he said, "I've seen near unprecedented traffic to Have I Been Pwned over the last couple of days.  Let me do my best to explain how I've approached the phone number search feature.  Or if you're impatient" - and then he has a link.  He says:  "What's changed?"  And I'll just share the top of this.



He said: "I'd never planned to make phone numbers searchable.  And indeed, this user voice idea sat there for over five and a half years without action.  My position on this was that it didn't make much sense for a bunch of reasons.  First, phone numbers appear far less frequently than email addresses.  Second, they're much harder to parse out of most datasets."  He says:  "I.e., I can't just regex them out like email addresses can be.  And, three, they very often don't adhere to a consistent format across breaches and countries of origin."  Right.  It's famously hard to even use a foreign phone number because how many digits?  How is it grouped?  Blah blah blah.



So he says:  "Plus, when the whole modus operandi of Have I Been Pwned is to literally answer the question Have I Been Pwned, so long as there are email addresses that can be searched, phone numbers don't add a whole lot of additional value."  And then I'll conclude with this.  He said:  "The Facebook data changed all that.  There's over 500 million phone numbers, but only a few million email addresses.  So greater than 99% of people were getting a miss when they should have gotten a hit.  The phone numbers were easy to parse out from mostly well-formatted files.  They were also all normalized into a nice consistent format with a country code.  In short, this dataset, it was preprocessed by Facebook, after all, all cleaned up and made searchable.  This dataset completely turned," he said, "all of my reasons for not doing this on their head."



So anyway, HaveIBeenPwned.com.  You can now put your phone number, what you had then, what you have now, various phone numbers, and see if you get any hits on that data.  So once again, thanks to Troy for this.



JASON:  Yeah, that's good.  I haven't been on Facebook in a while, and nothing comes up as being pwned.  I did it in no time.



STEVE:  That's what you want.



JASON:  All right.  So I must have missed that there is another water security incident that suddenly happened.  But that appears to be what you're going to tell me all about.



STEVE:  Yeah.  So we never really got any closure on that hack to the water treatment plant in Oldsmar, Florida.  That was the one that, whoa, got everybody's attention.  And that one was in early February.  But it may have put other similar facilities on alert.  Certainly being second with something very much the same gets a lot more egg on your face because it's like, wait a minute, after February, you're saying you guys didn't change your security protocols?  You didn't make sure nothing like this could happen again?  Well, we were going to.



Anyway, Saturday before last, on March 27th, a young 22 year old named Wyatt Travnichek, living in Ellsworth County, Kansas, is believed to have, well, pretty well confirmed, but we'll call it "belief" at this point, to have broken into a protected computer system belonging to the county's Post-Rock Rural Water District.  For some reason, he used his illegal access to shut down the cleaning and disinfecting processes at the facility.  You know, you want your water cleaned and disinfected whenever you can get it that way.  So turning that off is not good.  The public reports don't specify whether any contamination may have resulted to the water supply, but authorities are not taking this lightly at all.



Wyatt was quickly identified and indicted on the serious charges that he had accessed a public water facility's computer system, jeopardizing the safety and health of the residents of the local community.  So Wyatt has been charged with one count of tampering with a public water system, which is I guess a thing you can be charged with, and one count of reckless damage to a protected computer during unauthorized access, according to the Department of Justice.



So Lance Ehrig, the Special Agent in Charge of the Environmental Protection Agency (EPA) Criminal Investigation Division located in Kansas, said:  "By illegally tampering with a public drinking water system, the defendant threatened the safety and health of an entire community.  EPA and its law enforcement partners are committed to upholding the laws designed to protect our drinking water systems from harm or threat of harm."  And we're all glad for that.  He said:  "Today's indictment sends a clear message that individuals who intentionally violate these laws will be vigorously prosecuted."



So Lance's comments suggest that there might be some embarrassment factor and reaction over no one having been identified and held accountable for the previous very high-profile headline-making event in Oldsmar, Florida.  Wyatt's indictment does not specify whether his attack was successful, nor how it was detected.  But if Wyatt should be found guilty, he faces up to 25 years in federal prison and a total fine of half a million dollars.



The other salient fact here is it turns out Wyatt was not some naive opportunistic post-teenage hacker.  The indictment tells that he was previously employed by the water district, and his employment capacity required him to remotely log into the water district's computer system on a regular basis.  So he knew what he was doing and how to do it.  He quite deliberately shut down the water cleaning and disinfecting process at the facility.  Which at least in my mind seems extra creepy and far less prone for sympathy.



At the same time, this also suggests that the water officials at that facility also failed to properly secure credentials by not proactively removing Wyatt's remote access account after he left.  They said on whatever terms he was no longer an employee there, and he was still able to access the computer remotely.  Duh.  So they may have not been able to do so conveniently if, for example, maybe everyone was sharing the same credentials.  So that was harder than just changing Wyatt's, if everybody's had to change.  But that's no excuse, of course.  In any event, let's hope that word of this spreads and that at least our own domestic hackers learn the lesson that messing around with public utilities is not something that the U.S. Justice Department is going to ever take lightly.  I think that seems clear.



JASON:  And reasonable.  



STEVE:  Yeah, absolutely, yeah.  You're an ex-water works employee who logs in and shuts down cleaning and disinfecting?  Okay.



JASON:  I mean, come on.  Why are you doing this?



STEVE:  Enjoy the water in prison, Wyatt.



JASON:  Oh, yeah.



STEVE:  So now here we are, Jason.  Android.  Jason knows a little something about Android.



JASON:  Little something about Android.  Yes, what you got, Steve?



STEVE:  So on the Android platform, apps have always been able to detect the presence of specific apps, even collecting a full list of installed apps through the QUERY_ALL_PACKAGES  privilege.  And what's more, apps can be set to receive OS notifications when a new app is installed.  That feature, I have to say, really has the smell of, hey, wouldn't it be neat if we let apps be informed when other apps are installed?  Just think of all the cool things you could do with that.  Unfortunately, as we frequently see, cool things you could do is often quickly turned to the dark side.  It doesn't take a rocket scientist, or even a computer scientist, to observe that this wide open facility would provide yet another means for fingerprinting devices and profiling their users.



And it's not just theoretical.  Seven years ago, back in 2014, Twitter - Twitter! - began tracking the list of apps installed on users' devices as part of its "app graph" initiative with an aim to deliver tailored content.  And the digital wallet company MobiKwik was also caught collecting the information about installed apps in the wake of a data breach that just recently came to light earlier this week.  And a study published by a team of Swiss researchers two years ago in 2019 concluded that "free apps are more likely to query for such information, and that third-party libraries are the main requesters of the list of installed apps."  The Swiss researchers said that:  "As users have on average 80 apps installed on their phones, most of them being free, there is a high chance of untrusted third parties obtaining the list of installed apps."



And a year ago, in March of 2020, another academic study found that 4,214 Google Play apps stealthily collected a list of all other installed apps to allow developers and advertisers to build detailed profiles of users.  And you can imagine it's like, hey, Google lets us do it, so it must be okay.  Android makes this convenient with two OS function calls, getInstalledPackages() and getInstalledApplications(), which return the list.  So it's like, hey, look, they're right there. I'm going to impress my boss by using them and saying, hey, look what we can do now.



JASON:  Yeah.  If we can, why not?



STEVE:  Exactly.



JASON:  If the system makes it possible, why not?  Nothing to stop us.



STEVE:  Exactly.  So the reason we're highlighting this long-running behavior today is because Google is about to clamp down on this cool but overly permissive and abuse-begging, I mean, this begs to be abused.  We don't need to know what else the user has.  But if we ask, Android will tell.  So why not?  As they say, you can ask.



So Google's Developer Program Policy March 31 announcement reads:  "We're updating the following policies.  All new and existing apps will receive a grace period of at least 30 days from March 31st, 2021, unless otherwise stated, to comply with the following changes.  Package Visibility, effective Summer 2021.  The inventory of installed apps queried from a device are regarded as personal and sensitive user data subject to the Personal and Sensitive Information policy, and the following requirements.



"Apps that have a core purpose to launch, search, or interoperate with other apps on the device may obtain scope-appropriate visibility to other installed apps on the device as outlined below.  First what they describe as broad app visibility.  Broad visibility is the capability of an app to have extensive, or 'broad,' visibility of the installed apps, the packages on a device."



And they said:  "For apps targeting API level 30 or later, broad visibility to installed apps via the QUERY_ALL_PACKAGES permission is restricted to specific use cases where awareness of and/or interoperability with any and all apps on the device are required for the app to function."  And you can imagine, you know, things like launcher apps that inherently need access to see all the apps that it would be available to launch would be an example.  But not some puzzle game that is free.  It's got no need to see anything else.



They said:  "You may not use the QUERY_ALL_PACKAGES permission if your app can operate with a more targeted scoped package visibility declaration, for example, querying and interacting with specific packages instead of requesting broad visibility.   Also, use of alternative methods to approximate the broad visibility level associated with the QUERY_ALL_PACKAGES permission are also restricted to user-facing core app functionality and interoperability with any apps discovered via this method."  They finally said:  "Please see this Help Center article for allowable use cases for the QUERY_ALL_PACKAGES permission."  Basically, they're really going to lock down on this.



And what they're doing with developers is, and I didn't have this in the show notes, but it was in the broader content that I read, indicating that the developers would have some grace period to remove their request for that privilege unless they could demonstrate they truly needed it.  But if it is left in there, and they don't pull it out, those apps are going to get pulled from the Google Play Store.  Then they also said at the same level is limited app visibility, where they said:  "Limited visibility is when an app minimizes access to data by querying for specific apps using more targeted instead of broad methods, for example, querying for specific apps that satisfy your app's manifest declaration.  You may use this method to query for apps in cases where your app has policy compliant interoperability, or management of these apps."



And finally:  "Visibility to the inventory of installed apps on a device must be directly related to the core purpose or core functionality that users access within your app."  Meaning the whole app visibility can't be some other thing that the app wants to do that isn't about solving the maze puzzle.  Maze puzzles don't need to know what other apps you have on the machine.  So again, it really needs to be focused.  So what we're really seeing is a decision being made, this is not okay.  It's truly unfortunate, in my opinion, that we cannot have nice things, or at least that a massively widely used and deliberately permissive system, with all the original features and benefits of Android, is inevitably being slowly whittled down, locked down, and tightened up.



I recall many times hearing Leo so often proclaim that he was using Android explicitly for its deliberately non-Apple freedom, and its openness.  He loved all the extra stuff he was able to do.  And it's clear that Google and their Android engineering designers had their hearts in the right place.  They wanted to create, they set out to create a free and open platform for the world to use.  But naive users need to be protected from all the things that their open pocket computer might do that's against their interest and their expectations.



This podcast is titled "A Spy in Our Pocket" due to some new and worrisome research, as I mentioned, from Dublin, Ireland.  But there's a much broader sense in which we're all carrying around little spies in our pockets, and this is one of them, the idea that apps were saying, yeah, I'd like to have the QUERY_ALL_PACKAGES permission because I'd like to query all packages.  After all, you didn't say I couldn't.  So even though I don't need the information, I'd like to have it.  Who knows?  



JASON:  Feels to me like when we look at kind of the way the technology world has kind of continued to expand and grow in the past 10 years that what once was a very noble kind of goal for Google to keep Android this very open platform and to do all of these open things, "open" in air quotes, when compared to a more closed platform like iOS, we're just in a different technology world now.  We're at a point now where there's a lot more awareness, even among general users and general consumers, about what it means to have privacy on our data and to protect our data and to protect our security.  And I think that our awareness has shifted to the point to where Google needs to make these changes now.  Whatever their intentions were for a feature like this before, as noble as they may be, you're right, now there are actors out there that are happy to take advantage of that.  And maybe they were there before, and we just weren't as aware about it.  But now so many more people are aware of this that it puts pressure on Google to make changes like this.  And that's why we're here.  That's my thoughts.



STEVE:  And, you know, just look at all the brouhaha that was stirred up in the early days of COVID by the initiative to do recent proximity via Bluetooth.  We did a podcast on it.  We looked at the technology.  It was beautifully co-developed by Apple and Google, and it didn't matter.  Everyone said no, you know.  But the fact is, and we'll see this at the end of the podcast, that's nothing, nothing compared to what is actually  happening on all of our phone platforms today.  The idea that you were near some other phone for a while, well, they know that now without any Bluetooth, without any proximity tracking, without any permissions.  All of that is being sucked up.



If they made a mistake, and I'm not saying it was a mistake because of course they had to tell us, but it was just saying we're going to add this feature to our phones for the benefit of the world.  No, no.  Well, yeah.  So we do need, yeah, exactly as you said, Jason, this is not the world that Android was developed in or first conceived in.  Things have changed a lot.



JASON:  Right.  Things have changed a lot, yeah.



STEVE:  So I'm sure that none of our listeners are cheating with Call of Duty.



JASON:  Yeah.



STEVE:  Nobody listening to this podcast, I know nobody would do that.  



JASON:  They don't do that. 



STEVE:  No.  Now, maybe Paul - no, no.  Not even Paul.  Everywhere I looked in the tech press this past week I saw mentions of the new malicious game cheats for Activision's Call of Duty:  Warzone.  The idea of infecting gamers through malicious cheats, it's not new.  It's become a longtime persistent and popular means for bad guys sneaking their malicious code into the machines of unsuspecting, though also somewhat less than completely virtuous, game players who are willing to cheat to get ahead in the game.



Still, malware is malware.  And the need to obtain an edge, even if not ethically, is inducing gamers to drop their systems' built-in protections.  The cheats, that is, the so-called cheats, the cheating software systems instruct gamers to run the installation, the cheat install, as an admin, and of course disable their antivirus.  And that's interesting because the gamer knows they're downloading and attempting to run something that's shady in the first place.  So to them it might make sense that they would need to give the installer admin rights and of course disable their antivirus system upon which they would otherwise be depending.  But in this one case, you know, I need that cheat-y stuff, so let's just let it in.



And as we know, while these voluntary circumventions are often needed for a cheat to work, they also then make it easier for malware to survive reboots and go undetected.  And what's actually being installed often is remote access trojans, so-called RAT malware, that opens up a connection off to Russia or wherever and gives the people who perpetrated all this access to those machines.  So with all of their guard being down, users won't get warnings of the infection or that software is seeking heightened privileges because they gave the privileges to them to start with.



So Activision noted in their report by writing:  "While this method is rather simplistic" - that is, you know, asking for what you want - "it is ultimately a social engineering technique that leverages the willingness of its target, players who wish to cheat, to voluntarily lower their security protections and ignore warnings about running potentially malicious software."  Activision also provided a long list of Warzone Cheat Engine variants that installed malware of all descriptions.



And why are there so many?  It's being distributed using the increasingly popular affiliate model.  Activision's analysis indicated that multiple malware forums are regularly advertising a kit that customizes the fake cheat.  The kit makes it easy to create versions of Warzone Cheat Engines that deliver malicious payloads chosen by the soon-to-be attacker who plans to offer it.  The people selling the kit advertise it as an effective way to spread malware and "some nice bait for your first malware project."  So that's right, script kiddies, you can now - you don't have to understand this.  You just set this up and turn it loose.



The sellers have even posted YouTube videos that promote the kit and explain how to use it.  So turnkey cheat-ware for a super popular game, packaged for repackaging by affiliates.  It might not be worth that endless ammo or speed or invincibility.  In any event, while I'm sure that none of our, as I said, our listeners would stoop so low as to something like this, if anyone knows a hot gamer who might, it could be worth dropping them a word of caution in this case.  It may not be a free cheat that you're downloading after all.



QNAP.  For this podcast I've been trying, successfully, to avoid talking about QNAP, sort like I now try to avoid talking endlessly about ransomware.  You notice that I didn't so far, and there was a bunch of stuff that happened.  Some crazy ransomware people set the ransom at $40 million for a school district, like a school district has $40 million.  They can't even afford pencils these days.  So anyway, I don't talk about that because it's just too much of a target-rich environment.



So is QNAP, it turns out.  Everybody at this point knows ransomware is bad.  It exists.  What are you going to do?  But every indication is that QNAP, the company, is also bad, and they produce things that are bad, meaning insecure and in many cases insecurable.  Yet they are the number one Chinese supplier of Network Attached Storage devices.  And they hold, by some accounts, about a 69% market share of the network attached storage NAS market globally.  So when something really bad happens and continues to happen, we have to talk about it.



Few things are more important than the security of network attached storage.  After all, it's network, and it's attached, and it's storage.  Presumably it's storing things that its users might like to keep secure, and perhaps even confidential.  And given that the new attacks that we're seeing on networks and corporations are "pivot style," where an attacker first gets into a device on a private network LAN boundary which forms a bridge between the private LAN and the public Internet, and then pivots to use that as the launching pad for attacks into the LAN network to which they now have access, it's not so much that someone's laundry list might become public as that an intruder can now leverage their position on these appliances to launch much more devastating and serious intrusions.



So what happened this time?  Security researchers at SAM Seamless Network published their report last Wednesday containing news that they had been sitting on for months, as in four months, in an attempt to be responsible.  But QNAP was not.  SAM's report is titled "New Vulnerabilities Allow Complete Device Takeover."  I've edited and shortened it a bit for the podcast, but basically it reads:  "SAM's security research team is actively looking for vulnerabilities in IoT devices that have yet to be discovered in order to ensure our network security coverage is as accurate and up to date as possible.  SAM's engine subsequently blocks such vulnerabilities from the first day of their discovery, often prior to the vendor resolving it."  And I would say, yeah, if they're blocking on the first day of discovery, they're oftentimes way ahead of any vendors resolving it.



They said:  "Below is a summary of two recent vulnerabilities and their potential impacts that our research team discovered in a specific kind of NAS device made by QNAP.  It's standard practice to report the discovered vulnerabilities to the vendor and allow for a 90 to 120-day grace period for them to resolve it prior to notifying the public.  As seen in the timeline below, we followed the responsible disclosure procedure and immediately reported it to the vendor, especially as the impacts of their exploitation are significant.  These vulnerabilities are severe in nature as they allow for full takeover of devices from the network" - meaning public Internet - "including access to the user's stored data, without any prior knowledge."



They say:  "We discovered two critical vulnerabilities in QNAP TS-231's latest firmware version 4.3.6.1446, which was 9/29 of 2020.  So last year, September.  The two vulnerabilities:  First, web server allows a remote attacker with access to the web server running on default port 8080 to execute arbitrary shell commands without prior knowledge of the web credentials.  Whoops.  And their DLNA server allows a remote attacker with access to the DLNA server running on default port 8200 to create arbitrary file data on any non-existing location, without any prior knowledge or credentials.  It can also be elevated to execute arbitrary commands on the remote NAS, as well."



So, yeah, their "complete device takeover" titling is no exaggeration.  They said:  "These may affect other models and firmware versions, as well."  And we know how likely that is because most of these use a common base of firmware that they then spread across devices with different port configurations and capacities and so forth.  And here it comes.  They wrote:  "We reported both vulnerabilities to QNAP with a four-month grace period to fix them.  Unfortunately, as of the publishing of this article, the vulnerabilities have not yet been fixed."  So after 120 days, nothing.



They said:  "Due to the seriousness of the vulnerabilities" - and here I salute these guys.  This has got to be the new protocol.  They said:  "We decided not to disclose, even after four months, the full details yet, as we believe this could cause major harm to tens of thousands of QNAP devices exposed to the Internet."



So then under their technical details, which are brief because, as I said, they're not disclosing, they lay out the scenario and note that, even now, they are continuing to be super responsible.  Vulnerability number one, RCE (remote code execution) vulnerability, affects any QNAP device exposed to the Internet.  They wrote:  "This vulnerability resides in the NAS web server running on port 8080.  Previous RCE attacks" - remote code execution attacks - "on QNAP NAS models relied on web pages which do not require prior authentication, and run/trigger code on the server side.  We've therefore inspected some CGI files which implement such pages and fuzzed a few of the more relevant ones.  Most of the CGI files that are available through the web server reside at" - and they give the path name.



"During the inspection, we fuzzed the web server with customized HTTP requests to different CGI pages, with focus on those that do not require prior authentication.  We've been able to generate an interesting scenario, which triggers remote code execution indirectly, in other words, triggers some behavior in other processes."  And that's all they're saying about it in the hopes that QNAP will awaken from their long QNAP and get this fixed.



They said, under Process for Solving Vulnerability, they said:  "The vendor can fix the vulnerability by adding input sanitizations to some core processes and library APIs, but it has not been fixed as of this writing."  And they of course disclosed it all, said here's what it is.  Here's how you do it.  This is horrible.  Fix it.  So October 12, 2020, full disclosure reported to QNAP security team.  Eleven days later, October 23rd, sent another email to QNAP security team.  Now we're at October 31st, Halloween.  Automatic reply from QNAP Support with a ticket number.  So that took, what, 19 days just to get an automatic reply with a ticket number.



January 26th, sent a notification to QNAP about end of grace period, which is planned to end on February 12th.  On the 26th, reply from QNAP.  Oh, my god, same day.  QNAP Helpdesk.  The problem is confirmed, but still in progress.  Okay, now we're up to February 12th.  Grace period has elapsed.  They still wait.  March 31st, so they gave them from February 12th another six weeks, initial blog post published.  That's this.  Still not disclosing details.  Just like, please fix this, you idiots.



Vulnerability number two, arbitrary file write vulnerability.  And as we know, this is in the DLNA server listening on public port 8200.  They said the DLNA server is implemented as the process "myupnpmediasvr," and handles UPNP requests on port 8200.  What could possibly go wrong with that?  Let's put UPNP on the public Internet.  They said:  "We discovered the vulnerability during investigation of the process's behavior" - I bet they did - "and communication both externally and internally."



They wrote:  "We've been able to elevate that vulnerability to remote code execution on the remote NAS, as well."  So across the public Internet.  Same, they have a shorter disclosure timeline, but same basic idea.  So hopefully this public embarrassment may finally work to get QNAP's long-overdue attention.  We could hope.  No good would come from SAM's more full disclosure.  Given the nature of attacks, I'd argue that there would never be any reason for them to disclose.  But if they don't convincingly threaten to do so, it's quite clear that these problems are just going to sit there, and QNAP's irresponsible behavior will continue.  So the only way to motivate them is to give them time, then to embarrass them.  It's hard to imagine any good coming from going further.



As I started out saying, I've been avoiding talking about QNAP.  Things keep going by, and I just think, okay, but what are you going to do?  But I've already let many similar stories go uncovered.  And so please, everyone, take this to heart for your own benefit.  When you're choosing a NAS supplier, let's reduce the market share of these people.  And if you already have QNAP devices, find some use for it inside your network.  Remove it from the public Internet.  I don't think there's a safe way to have these things exposed on the Internet.



And before we take our final break, one piece of listener feedback that I really got a kick out of.  This is from - his name is The Realest M.F., and he's tweeting from @MaxFeinleib.  He said:  "Great remark from my college CS professor," so of course Computer Science professor.  "There are two hard problems in computer science:  cache coherence, naming things, and off-by-one errors."



JASON:  Ba dum tss.



STEVE:  Very clever, because of course that was three things.  And it's funny, I mean, I'm a coder.  That's what I do.  And I completely agree.  I've talked about the problem with naming things.  Names tend to drift over time.  You name something for what you think it is.  And later, if you don't remember - a perfect example.  I'm deep into SpinRite 6.1 right now.  And I saw that decades ago I was calling something a "size," like "drive size."  Well, in what?  In bytes?  In sectors?  It's unclear.  And I guess my habits have evolved as a coder.  I just don't do that anymore.  I'm very conscious, drive bytes or drive sector size.  Make it clear.



But the other thing you have to be very sure about when you're naming things is that your own use of that thing, once it's named, doesn't expand.  So the name, the original name no longer applies.  That's another thing that I've noticed can happen over time, where it's like, wait a minute, that's not what that's doing.  Maybe once, but not now.  I changed it.  But I didn't change the name.  So that.



And then of course, famously, off-by-one errors.  Oh, my god.  I mean, what I do is I, like, resort to paper and pencil when I'm needing to make sure that I'm copying a range of bytes from here to there, especially if the range is overlapping.  I put my pointer here.  Okay, now is it that many things, like the number of things between the start and the end index is not the difference between them, it's the difference plus one, if you're counting the items inclusively.  So inclusive versus exclusive and so on.  Anyway, anyone who's done any serious coding understands that, oops, that's where a lot of the bugs are.  So anyway, got a big kick out of that bit of Twitter feedback, thank you very much.



JASON:  All right.  The main event where Steve tells us why carrying around a phone in our pocket might not always be the best thing in the world, although it's kind of hard to put that genie back in the bottle.  It's kind of what we do now.  And for so long.  It's our habit.



STEVE:  And that is what I conclude.  But the journey is interesting.



JASON:  Yes.



STEVE:  This week's podcast owes its title to the title of the research paper recently published by Douglas Leith's group at  Trinity College in Dublin, Ireland.  He's in the School of Computer Science & Statistics there.  And I've mentioned before, I have a fond memory, sort of a fleeting memory of Trinity College from my visit to the Dublin chapter of OWASP in September of 2019 to demonstrate SQRL to them.  Lorrie and I watched the beautiful Trinity campus pass by while we were attempting to figure out how to open the doors of the metropolitan transit.  We never did, so we missed our opportunity to walk around.  Maybe someday.



But in any event, Douglas titled his team's research paper "Mobile Handset Privacy:  Measuring the Data iOS and Android Send to Apple and Google."  Now, needless to say, neither Apple nor Google are pleased about having a third party poking around into their device's communications.  They'd rather that no one did.  But we're all familiar with the phrase "keeping them honest," which I think applies here.  It's not at all that either of these behemoths are attempting to do anything explicitly nefarious.



I would argue that it's more likely the case, and recent history with all forms of computing teaches us, that without adequate supervision, and especially when an entity imagines that no one will ever look, the strong tendency is to collect data less because it's truly needed than because it's there.  And today bandwidth, storage, and computation might as well be free, so slurp it all up just in case, and we'll see whether we might actually have any need for any of it later.



We were just talking about the case of the Android app packages installed.  It's like, well, Android offers an API that lets me get a list of all the apps that are installed on the phone along with me.  Why not use it?  Right, except Google says no, no more.  You need to prove you need it.  In this case, they're not taking their own advice, but we'll get there.  So I'll also note that one thing these researchers do is notice how this information could be used and potentially abused.  Not accusing anybody of that, no.  But they're seeing what is being collected.



So, okay.  Against that backdrop their paper's abstract summarizes what their independent analysis found.  They said:  "We investigate what data iOS on an iPhone shares with Apple and what data Google Android on a Pixel phone shares with Google.  We find that, even when minimally configured and the handset is idle, both iOS and Android share data with Apple and Google on average every 4.5 minutes.  The phone IMEI, the hardware serial number, the SIM card serial number and IMSI, handset phone number, et cetera, are shared with Apple and Google.



"Both iOS and Android transmit telemetry, despite the user explicitly opting out of this.  When a SIM is inserted, both iOS and Android send details to Apple and Google.  iOS sends the MAC addresses of all nearby devices, other handsets and the network gateway to Apple, together with their GPS location.  Users have to opt out of this, and currently there are few, if any, realistic options for preventing this data sharing."



Again, okay, they're not saying that there's anything inherently wrong with doing this.  But someone needs to ask why.  Why are they collecting this data?  What's being done with it?  Certainly as technologists we can readily envision many things that we would not like to have done with all this information.  So if Apple and Google are not doing any of those worrisome things, what are they doing?  And if they're doing nothing with any of that information, then why is it being collected?



Certainly some of that is truly essential to, as we know, the baseband operation of any cellular radio system.  We know that the nature of cellular service requires an ongoing back-and-forth dialogue with nearby cell towers.  Even when you're not using your phone, you can see how many bars of reception you have; right?  That's all going on in the background.  But none of that should involve any data above the level of cellular connection maintenance.  Or if it does, documentation and disclosure should be available.  Yet none is.  Thus research is required.



The researchers organized their presentation very nicely in layers of successive detail, with each layer going down to provide more specifics.  So I want to share just their top level of detail, which is all we need to fill in the relevant facts for our purposes.  And for what it's worth, I've got a link to the PDF here in the show notes.  And, I mean, it shows you the detailed protocol back and forth handshaking nitty-gritty.  So it's all there.  I've lightly edited the presentation for better delivery through this podcast, and I've included a link to their full research paper.  So again, anybody who wants to know everything, can.



At their top level they wrote:  "In this paper we investigate the data that mobile handset operating systems share with the mobile OS developer, in particular what data iOS on an iPhone shares with Apple and what data Google's Android on a Pixel phone shares with Google.  While the privacy of mobile handsets has been much studied, most of this work has been focused on measurement of the app tracking and advertising ecosystem, and much less attention has been paid to the data sharing by the handset OS with the mobile OS developer.



"Handset operating systems do not operate in a standalone fashion, but rather operate in conjunction with backend infrastructure," meaning maintaining a constant link to the mothership.  They said:  "So, for example, handset operating systems check for updates to protect users from exploits and malware, to facilitate running of field trials, for example, to test new features before being rolled out, to provide telemetry and so forth.  Hence, while people are using an iPhone, the iOS operating system shares data with Apple; and when using a Pixel, the operating system shares data with Google.  And this is part of each device's normal operation.



"To allow direct comparisons, we define experiments that can be applied uniformly to the handsets studied that generate reproducible behavior.  Both Apple and Google provide services that can be, and almost always are, used in conjunction with their handsets, for example, search (Siri and OK Google); cloud storage (iCloud and Google Drive); maps and location services (Apple Maps and Google Maps), photo storage and analytics (Apple Photo, Google Photos)."  They said:  "We endeavor to keep these two aspects separate, to focus on the handset operating system in itself, separate from optional services like those.



"We assume a privacy-conscious but busy non-technical user who, when asked, does not select options that share data with Apple and Google, but otherwise leaves handset settings at their default value."  In other words, given a choice, no.  But they're not going to go dig in and try to turn everything off. "In these tests we evaluate the data shared, one, on first startup following a factory reset."  So first startup, absolutely clean phone.  "Two, when a SIM is inserted or removed.  Three, when a handset lies idle.  Four, when the settings screen is viewed.  Five, when location is enabled and disabled.  And, six, when the user logs in to the pre-installed app store.  



"We note that these tests can be partly automated and used for handset operating system privacy benchmarking that tracks changes in behavior over time as new software versions are released."  They said:  "The following table summarizes the main data that the handsets send to Apple and Google."  And there's then a multicolumn chart with two lines, Apple iOS on the top line, Google Android on the second line.



And pretty much everything is the same, although Google does not have location checked where Apple does, nor local IP address, which is interesting, not being collected, whereas it is on iOS.  And then device WiFi MAC address not sent by Apple, apparently is by Google.  And nearby WiFi MAC addresses not being sent by Android is being sent by the iPhone.  So otherwise, IMEI, hardware serial number, both of them.  SIMs, both of them.  Phone numbers, any of that kind of stuff, basic underlying cellular technology you can imagine needing to be sent.



And they said:  "This data is sent even when a user is not logged in," and they said, "indeed, even if they have never logged in.  In addition to the data listed in this table, iOS shares with Apple the handset's Bluetooth Unique Chip ID, the Secure Element ID" - which is associated with the Secure Element used for Apple Pay and contactless payment and, as we know, the Secure Enclave is like everything - "and the WiFi MAC addresses of nearby devices, in other words, of other devices in a household of the home gateway."  And of course we know that WiFi is Ethernet, and Ethernet uses IP packets contained in Ethernet packets, and that the Ethernet system uses MAC addresses in order to address the packets on the Ethernet.  So you're getting a huge amount of information.



They said:  "When a handset's location setting is enabled, these MAC addresses are also tagged with their GPS location.  And it takes only one device to tag the home gateway MAC address with its GPS location, and thereafter the location of any other devices reporting that MAC address to Apple is thus revealed," right, by social graphing, connectivity graphing.  "Also note that sharing of these WiFi MAC addresses allows linking of devices using the same network, in the same household, same office, same shop, cafe," whatever, "and so the construction of a social graph over time and place.



"Both iOS and Google Android transmit telemetry, despite the user explicitly opting out of this.  However, Google collects a notably larger volume of handset data than Apple.  During the first 10 minutes of startup, the Pixel handset sends around a megabyte of data to Google, compared with the iPhone sending around 42K of data to Apple.  When the handsets are sitting idle, the Pixel sends roughly a megabyte of data to Google every 12 hours, compared to the iPhone sending 52K to Apple.  Google collects, they conclude, around 20 times more handset data than Apple.  Not clear how relevant that is.  You'd have to look at the data in detail to see whether you care.



And you just had on the screen and also in the notes are two charts showing at startup for Android a very steep upward climb, and then it levels out.  That's at startup.  Whereas Apple pretty much stays at a low purr.  And then idle, similarly, Android is just sending data out, I mean, like lots of data, more or less continuously over the course of idle time; whereas Apple continues at a lower purr.  At the same time, I'm unhappy with what we know of some of what Apple is sending.  That just seems really unnecessary.



So they said:  "In 2020 it is estimated that in the U.S. there are 113 million" - so that's last year - "113 million iPhone users and 129 million Android users.  Assuming all of the Android users have Google Play Services enabled, then scaling up our measurements suggests that in the U.S. alone, Apple collects around 5.8 gigabytes of handset data every 12 hours, while Google collects around 1.3 terabytes of handset data in the same period of time.  When the handset is idle, the average time between iOS connections to Apple is 264 seconds, while Android connects to Google on average every 255 seconds," so that's about comparable.  In other words, both operating systems connect to their back end servers on average every 4.5 minutes, even when the handset is not being used.



So yes, Jason, that handset that may or may not be in your pocket, mine which is sitting over on a charger, that is otherwise in my pocket or on a charger, we're not doing anything.  And every 4.5 minutes it's connecting back to the mothership and sending a bunch of stuff that is clearly not necessary for them to send.  And I guess the point of showing us how this accumulates, 1.3 terabytes of handset data for Android in aggregate every 12 hours, 5.8 gigabyte for iOS, why?  Are they keeping it?  Are they storing it?  Are they processing it?  Are they parsing it?  What are they doing?  And again, this is not cellular layer tower connections.  This is connections back to Apple and Google.



They said:  "With both iOS and Android, inserting a SIM into the handset generates connections that share the SIM details with Apple or Google."  Okay, fine.  "Similarly, browsing the handset settings screen generates multiple network connections to Apple or Google," which is interesting.  I guess that's telemetry; right?  Like oh, we want to collect all this data on what the user's looking at.  Okay.  "A number of the pre-installed apps and services are also observed to make network connections, despite never having been opened or used.  In particular," they wrote, "on iOS these include Siri, Safari and iCloud; and on Android these include the YouTube app, Chrome, Google Docs, Safetyhub, Google Messaging, the Clock, and the Google Search bar."  Maybe the clock they want to make sure it's set correctly.



"The collection of so much data, they write, by Apple and Google raises at least two major concerns.  First, this device data can be fairly readily linked to other data sources.  For example, once a user logs in, as they must to use the pre-installed app store, then this device data gets linked to their personal details - name, email, credit card, et cetera."  Okay, that's obvious - "and so potentially to other devices owned by the user" - oh, that's true, that's not so obvious - "shopping purchases, web browsing history and so on.  This is not merely a hypothetical concern since both Apple and Google operate payment services, supply popular web browsers, and benefit commercially from advertising.



"Second, every time a handset connects with a back-end server, it necessarily reveals the handset's IP address, which is a rough proxy for location.  The high frequency of network connections made by both iOS and Android on average every 4.5 minutes therefore potentially allow tracking by Apple and Google of device location over time.  With regard to mitigations, of course users also have the option of choosing to use handsets running mobile OSes other than iOS and Android."  What, Blackberry?  They said:  "For example, e/OS Android."  I'm sure you know what that is, Jason.  I've no idea.



They said:  "But if they choose to use an iPhone, then they appear to have no options to prevent the data sharing that we observe."  Of course a firewall if you were to configure it correctly.  But if you're cellular, then no.  "But if they choose to use an iPhone, then they appear to have no options to prevent the data sharing that we observe.  They are unable to opt out.  If they choose to use a Pixel phone, then it is possible to start up the handset with the network connection disabled to prevent data sharing, then to disable the various Google components, especially Google Play Services, Google Play Store and the YouTube app, before enabling connection to the Internet.



"In our tests, this prevented the vast majority of the data sharing with Google, although of course it means that any subsequent phone apps must be installed via an alternative store and cannot depend upon Google Play Services."  They said:  "We note that many popular apps are observed to complain if Google Play Services is disabled.  However, further testing across a wider range of handsets and configurations is needed to confirm the viability of this potential mitigation.  When Google Play Services and/or Google Play Store are used, this mitigation is not feasible and the data sharing with Google that we observe appears to be unavoidable."



So they conclude this top layer with:  "Ethical disclosure:  The mobile OSes studied here are deployed and in active use.  Measurements of Google Play Services backend traffic were previously disclosed by our group, but the present study is broader in scope.  We informed Apple and Google of our findings and delayed publication to allow them time to respond.  To date, Apple have responded only with silence."  He said:  "We sent three emails to Apple's Director of User Privacy, who declined even to acknowledge receipt of an email."  I guess Apple doesn't have one of those emergency response coordinator people that Facebook has.  Anyway.  "And," they said, "we also posted an information request at the Apple Privacy Enquiries contact page [apple.com/privacy/contact], but we have had no response.



"Google responded with a number" - I mean, these are not bozo security researchers.  I mean, this is true, honest research being conducted by a useful group who've done things before.  Anyway:  "Google responded with a number of comments and clarifications, which we have incorporated into this report.  They also say that they intend to publish public documentation on the telemetry data that they collect."  And I'll mention, it's not in here, but there is also Google disputing the 20-factor greater than iOS claim that these guys found.  Google didn't like that.



JASON:  I'm sure.



STEVE:  And they finished with:  "A key consideration is what mitigations are possible, and on what time scale can they be deployed.  It seems likely that any changes to Apple iOS or Google's Android, even if they were agreed upon, will take a considerable time to deploy while keeping handset users in the dark for a long open-ended period, which seems wrong."



So my take on this is that, as we said at the top, Jason, the mitigation of this data collection, as they described, is largely impractical.  No one's going to go through all those hoops and jumps and so forth.  And the only way to truly avoid it is to choose not to use a mobile handset.  And who's going to do that in this day and age?  These devices have become our science fiction, globally connected, super powerful pocket computers.  I mean, they're amazing.  But they're also inextricably tethered to their mothers, and there's no breaking that bond.  We know that all of the privacy downside the researchers painted for us is completely feasible.  We don't know what's being done with the data.  Why is Apple sending back all the MAC addresses of the other devices that it sniffs in our environment?  That just seems gratuitously unnecessary.



Are Apple and Google actually performing all of that linking to build sophisticated social graphs or device proximity connection histories, at a low level that's inaccessible to us?  They certainly could be.  Sharing our phone's IMEI and SIM serial number seems benign and likely necessary to provide the services we need.  But there's really no way to characterize the aggregation and forwarding of every MAC address within the phone's reach, on an ongoing active basis, as anything less than surveillance.



Apple may boast  and they certainly do, and use it as a selling factor  that they are unable to see inside a locked phone.  But they certainly have the ability to tell law enforcement everything that iPhone has seen, everyone it's been near to, what the proximity patterns are, its location history through time.  And that's a pretty serious encroachment into every iPhone user's privacy.  I won't be giving up my phone, and I'm sure that very few will.  No one, probably.  But it might behoove us to keep in mind that we are each carrying a little spy in our pocket.



JASON:  Indeed.  And you mentioned earlier, or rather the report mentioned e/OS.  That's more like an open source - there's open source versions of Android that are de-Googled entirely, and that's one of them, basically removes Google entirely - and my Google just started up - entirely from the phone so you don't have any of the services; you don't have any of those interlocking pieces.  You also don't have the Play Store.



There are ways with Android to basically remove Google from the equation for the most part.  But, I mean, only certain people are going to even be aware to do that.  Or certain people are even going to care enough to do that.  A lot of people I think nowadays have just kind of resigned themselves to the fact that, yeah, you know what, this is just the cost of doing business.  The cost of having a smartphone that does all the things I want it to do is that it collects this data.  And I'm not even so sure that that data collection is nefarious.  But whatever.  It's already done, and it's too late to put it back; you know?  I don't know.  I think there's a lot of stuff that happens.



STEVE:  One of the things that we've been talking about recently is the tech-savvy social responsibility to protect those who cannot protect themselves.  And so, for example, web tracking.  We talk about web browser tracking.  Well, all the techies know about web browser tracking.  Most users don't.  So as techies, don't we have an obligation to make the world safer for everybody, even if they don't have all the details about how this happens?  And I think there's a useful case to be made for the fact that, yeah, this should be fixed.  And if nothing else, Apple should tell us.  Tell us why you're collecting all this.  You're doing it behind our backs.  There's no disclosure of this.  What are you doing with it?  And  I would argue, if we knew, then that would be fine.



JASON:  Yeah, well, it would certainly be fine for some people.  That would be enough.



STEVE:  Oh, better, it would be better.



JASON:  Apple's got a tight collaboration of all of their devices working together.  This is just a component.  This is what enables it.  Great.  That's one of the benefits that I see in the Apple ecosystem, and I'm okay with it.  But, yeah, other people, it's like, any of that collection whatsoever, it's not okay.  And that's part of the big challenge, too; right?  There's just so many varying degrees of comfort level with people and their data right now.  The big companies have to kind of guess what is the sweet spot, and they have to keep themselves in business, too.  So I don't know what the right answer is.



STEVE:  I'm glad for the research and the disclosure because, as I said, there's a tendency, for engineers especially, well, no one will know what we're doing, so why not?  We've got lots of bandwidth.  We've got lots of storage.  Maybe we'll be able to use this someday.  Maybe we'll do something.  So why not?  Well, okay.  Being called on the carpet for the data collection you're doing is a why not.  Because here's Apple, all jumping around, selling privacy; right?  I mean, Tim Cook makes a huge deal of it.  Well, okay.  Except what about this?  Oh, well.  You know?  So if they're not using it, they should shut it off.  And if they are using it, then what for?



JASON:  Yeah, and what you just said there, for whatever reason, I hate that thought of, like, we're collecting the data because we can, not because we have any use for it now, but we might have use for it later.  I feel like that's a Pandora's Box that you open up, and that leads to potentially very bad things down the line.  So absolutely right.



STEVE:  Right.



JASON:  Indeed.  Good stuff, Steve.  Appreciate all that you do in keeping us all informed on all of this.  Everybody who wants to follow what Steve is doing even closer can go to GRC.com.  Everything that Steve's up to can be found over there.  Of course SpinRite, which we didn't talk about today, but it's an awesome hard drive recovery and maintenance tool.  You can get your copy there.  Information about SQRL, audio and video of this show found at GRC.com.  Also transcripts of this show can be found over there.  You've got a lot going on at GRC.com, and everybody should check it out, so please do.



If you want to hit our site for this show, pretty easy to find, TWiT.tv/sn for Security Now!.  We host audio and video versions of this show, ways to subscribe to the podcast, about the YouTube, if you like.  It's all there.  We do record this show, well, normally Leo records it.  Today I am with Steve.  But we record every Tuesday starting at 1:30 p.m. Pacific, 4:30 p.m. Eastern, 21:30 UTC.  And you can check it live, if you like, TWiT.tv/live.  We've got an active chat audience who has been participating throughout this entire show behind the scenes, as well.  But we've reached the end of this episode, Steve.  Thank you so much for letting me join you on today's episode.  Appreciate it, man.



STEVE:  Great to have you, Jason.  And we'll see you next time Leo wanders off somewhere.



JASON:  That's right, that's right.  I will happily fill in for Leo next time.  And Leo and Steve will see you next time, next week on Security Now!.  Bye-bye, everybody.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#814

DATE:		April 13, 2021

TITLE:		PwnIt and OwnIt

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-814.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we start with some needed revisiting of previous major topics.  We look at an additional remote port that Chrome will soon be blocking, and the need to change server ports if you're using it.  We look again at Google's forthcoming FLoC non-tracking technology and a new test page put up by the EFF.  We revisit the PHP GIT server hack now that it's been fully understood.  We look at Cisco's eyebrow-raising decision not to update some end-of-life routers having newly revealed critical vulnerabilities, and we also examine another instance of the industry's failure to patch  for years.  Then, we conclude with a blow-by-blow, or hack-by-hack, walkthrough of last week's quite revealing and somewhat chilling Pwn2Own competition.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with the answer to some critical questions.  Why are Firefox and Chrome blocking port 10080, hmm?  We'll also talk about FLoC, Google's Federated Learning of Cohorts technology.  It's starting to roll out now, and he has a good way of figuring out if you're in the FLoC.  And then it's a look at Pwn2Own, some fun exploits, some not-so-fun problems.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 814, recorded Tuesday, April 13th, 2021:  PwnIt and OwnIt.



It's time for Security Now!, the show where we get together with this guy right here, Steve Gibson, every week and talk about your security and privacy online.  Okay.  I'm looking at the salute, the Vulcan salute.  There's something different.  I'm trying to figure out what it is about that ring finger of yours.  What's going on, Steve?



STEVE GIBSON:  Looks a little bit like yours, actually, Leo.



LEO:  It does.



STEVE:  Yeah.



LEO:  There's a band of gold on it.



STEVE:  Yeah.  After three and a half years of Lorrie being very patient, I decided that she had been patient enough.  Actually, about a month ago we decided that we were going to make it official.  And she's so much more than a girlfriend.  At one point she said, "So, what am I, your girlfriend?"  And I thought, that's not right.  So...



LEO:  Yeah.  At our age, "girlfriend" doesn't really say it, does it.



STEVE:  Yeah, yeah.  And if you say, oh, my "partner," then they're like, well, [crosstalk] this partnership and so forth.



LEO:  Are you gay?  Yeah, exactly, yeah.  "Wife" has a certain - everybody understands what a wife is.  It's a certain ring to it.



STEVE:  It's a done deal, yeah.  It is a four-letter word, but it's also a good one.



LEO:  Good, good, good.  Congratulations.



STEVE:  So anyway, we made it official last Wednesday afternoon, just a very quiet little ceremony.  We actually ordained her son with the Universal Life Church.



LEO:  Oh, that's perfect.



STEVE:  Where you click "Ordain Me" on the website.



LEO:  Yeah, I have that, I have that, yeah.  And you're legal.



STEVE:  Yeah.  And she wrote our vows...



LEO:  Oh, nice.



STEVE:  ...which her son read, and we did our best to repeat.



LEO:  Oh, that's great.



STEVE:  And it was really - and just kept it quiet to ourselves.  And so it feels really good.  And here I am, what, five days in.



LEO:  Congratulations, yeah.



STEVE:  And not a regret, no doubt or anything.



LEO:  Married man.  That's very nice.  That's really great, yeah.  Congratulations.  She's great, too, by the way.  We've met, and I gave her my seal of approval some time ago.



STEVE:  Yeah, she is.  Well, and I told a story, I posted the news over on the newsgroups, and I said that at this time of your life, by this point, you've probably pretty much figured out who you are.  And so on our first date she asked me one of her, like, test questions.  And she said, "What are your plans for retirement?"  And I thought, you know, let's just, you know, no reason to soft pedal this.  Let's just rip the bandage right off.  If this is going to be the first and last date, then better to know now.  So I said, "Oh, I'm never going to retire."  Which turned out to be the right answer.  



LEO:  The right answer, good.  It's a good answer for me, too, by the way, Steve.  I just want to - glad to hear it.



STEVE:  Yeah.  And I explained that every relationship the friction had been that I just love what I'm doing so much.  And that had always been a problem.  And so I think basically I waited for three and a half years because I couldn't believe it, that it was really possible to have someone who let me work.



LEO:  That's wonderful.  That's great.



STEVE:  And yeah, so, anyway.  Very happy.



LEO:  Congratulations.  And she's great, and you two make a wonderful couple.  So I'm very happy for you both.



STEVE:  Thank you.  So PwnIt and OwnIt for Episode 814, here in mid-April.  This is when the annual Pwn2Own competition occurs.  And ever since they began we've had a lot of fun.  In years past you sort of gave us the, what was his name, Howard Cosell, the Howard Cosell read.



LEO:  Howard Cosell play-by-play of Pwn2Own.  It's an amazing battle.



STEVE:  And I made it the topic because it's a little bracing just to watch these guys cut through what we think of as and hope are secure systems, just like, eh, figured I'd make an extra 40 grand, so here's your escalation of vulnerability, or your escalation of privilege.  Or, I mean, and oh, Leo, you would think by now that maybe like Exchange Server was safe? Unh-unh.  No, no, no.  



LEO:  What?  There's more?



STEVE:  Oh.



LEO:  Oh, my god.



STEVE:  So we're going to start the week with some topics that we need to revisit because we've been picking good things recently where they keep generating more interesting news.  So we're going to look at an additional remote port that Chrome will soon be blocking, and perhaps the need to change some server ports if any of our listeners happen to be using the one that Chrome has decided it now needs to block.



We're going to look again at Google's forthcoming FLoC, their non-tracking technology, and at the new test page that has been put up by the EFF, who doesn't like it.  Of course, they don't like anything.  Then we're going to revisit the PHP GIT server hack, now that we understand fully how it happened.  And we're going to look at Cisco's eyebrow-raising decision not to update some end-of-life routers that have newly revealed critical as in remote access, vulnerabilities.  But they've said they're old, so no.



And we're also going to examine another instance of the industry's failure to patch for years, and the consequences.  And then I think a fun blow-by-blow or hack-by-hack walkthrough of last week's quite revealing and a little bit chilling Pwn2Own competition.  



LEO:  And I promise not to do my Howard Cosell for it.  All right.  Good show.



STEVE:  And we do have - this Picture of the Week I've been sort of sitting on for a while.  But I just, for our audience, in context, it's like, really?  Like, no.



LEO:  I've been laughing at that one for a while.  To the Picture of the Week, Mr. Steverino.



STEVE:  So when I was putting this - I grabbed it from my stock of pictures for the podcast.  Sometimes I run out; sometimes I have a little excess.  I've been waiting because we've had more relevant pictures recently.  And I put this on the show notes, and Lorrie walked by.  And I said, "Look at this.  This is like - what does this say?"  And she said, "That's not real."  I said, "Oh, yeah.  They actually said that."  Anyway, this is the big blue, I don't know what color it is, aqua-colored screen that we all see now who use Windows 10.



LEO:  It's Windows Blue.  We all know.



STEVE:  Windows Blue.  That's right.  And anyway, it just - this is purely rhetorical, of course.  But this is a screen that comes up, I don't remember when, like maybe when it's doing a feature update or something.



LEO:  Yeah, so annoying.  This goes along with "All your files are right where you left them."



STEVE:  Yeah.



LEO:  It's just - but it tells you a little.  It is actually a little bit of - I think it tells you a little bit about Microsoft's mindset, frankly; right?  Leave everything to us.



STEVE:  Leave everything to us.  Just stand back from your computer.



LEO:  Just let us do it.



STEVE:  And down below it says, "Don't turn off your PC."



LEO:  Oh, yeah, don't do that.



STEVE:  We're busy.  So, but leave everything to us.  And of course which begs the question that we often ask on this podcast:  What could possibly go wrong?



LEO:  I love it.



STEVE:  Anyway.  And, you know, Lorrie's been abused by Windows 10.  It does the same things to her that it does to everybody else.  She's like, "Really?  They're actually saying that?"  Uh-huh, yeah.



So as we know, the practice known as NAT Slipstreaming, which we've talked about twice recently, uses or rather abuses the user's local router's Application Layer Gateway features.  Through NAT Slipstreaming, code running on a browser inside the LAN is able to arrange for unsolicited traffic from outside to get into the LAN and to go to specific devices, thus effectively bypassing the natural firewall features that we love so much and depend upon our NAT routers for.  For this form of abuse to work, the browser needs to be able to emit traffic bound for specific remote ports.



So browsers have been fighting back, thus our two previous mentions of this, by preventing outbound connections to specific abuse-prone ports which NAT routers may be monitoring for application layer traffic.  Of course famously FTP was a big one, where because of the trickiness of the FTP protocol, active FTP, a packet outbound would itself in the packet carry information for the remote server, telling it which port to return its traffic to.



So the NAT router, for NAT to work with active FTP, it had to be inspecting the packet's contents, realize that this is FTP, look inside it to see if it's got that port that the remote server is being told to connect back on because then it needs to proactively open that so that when the remote server does respond on that port, it'll be able to come through the NAT and get back to the proper computer inside the LAN.  So there's a sort of a simple example.  But many of the more fancy, more modern, if you will, protocols have things in their actual protocol that affect the traffic.  So NAT routers need to be able to listen to that.



At the moment, Chrome is blocking ports 69, 137, 161, 554, 1719 and 1720, 1723, 5060, 5061, and 6566.  We're talking about this because last Thursday Google stated that they intend to add TCP port 10080, so 10080, to their growing list.  And as it turns out, it's been on Firefox's block list since late last year, November of 2020, when it got added for Firefox.  That 10080 port is known to be used by the Amanda backup software and also by VMware's vCenter.  But in neither of those two cases is there any need for a web browser to be initiating traffic to it, to those ports.  So no reason not to block it at the browser.  Well, almost none.



The biggest concern is that very much like port 8080, which is a popular port of choice for so-called userland web browsers, you know, back in the dawn of the podcast we talked about how in the original Unix implementation of IP networking, ports 1 or 0, depending upon how far down - there technically is a zero because you could have all the bits, all 10 bits of the port number could be zero.  Oh, wait, all 16 bits, sorry.  I was thinking of 10 bits because that's where the kernel access ends.



Ports 1 through 1023 are reserved so that only processes running with root privilege are able to open ports, those low-numbered ports.  As a consequence, it's not possible for a user to run their own web browser on port 80.  Being a user, they don't have access to anything below 1024.  So but port 8080 is often used for that.  Well, so is 10080, just because it has, you know, it's a nice high number that ends in 80, which of course is historically HTTP.



And when I was researching this issue last night, I encountered some instances of problems.  There was a posting on Reddit that was titled, "Why Firefox Developer Edition blocks HTTP on port 10080 after update."  And this guy wrote:  "My current school project uses port 10080 to run the web application.  After the update to Firefox 85b2 Dev channel," he said, "I need to set network.security.ports.banned.override in order to access my web.  What's the reason behind the ban of this port?  I'm curious because it's not a standard port.  Firefox allowed it before, and it's not used by any widely known applications."  He's right on all counts.



So of course we've talked before about how dicey it can be to ever take back anything once it's been given. The Internet, the web, and many of its descendent technologies were originally designed by technologists who placed very few  and in retrospect, too few  limitations on the use of the new toys that they were creating.  And look at how cautious, for example, Google was with Chrome's careful gradual tiptoeing removal of FTP.  I mean, they very much wanted to remove it and just not have an FTP client in their browser.  But they were also very worried about taking anything away that users might be using and depending upon.



So over in the Bugzilla forum, Mozilla's forum, someone posted:  "I have a similar problem with this change.  I have thousands of CPE" - and I'm sure he was referring to Customer Premise Equipment with the standard abbreviation - "with their management port on 10080."  He says:  "Of course not accessible from the Internet.  But I need to manage them.  Is there any option in about:config that will allow me to use port 10080 again?"  And of course he was referring to this change which hit him also in Firefox last November.  And somebody at Mozilla replied, saying:  "Sorry for the inconvenience this is causing."  And they had a three bullet point instruction:  "Go to about:config.  Create a new pref of type String with the name network.security.ports.banned.override."



And first of all, I didn't even know you could do that.  I thought, like, all of the preferences were built in, and you search for a piece of one in the search bar, and then you get them.  But when I went and looked, it's like, oh, sure enough, there's a plus sign over on the right.  You can create your own.  So cool.  Anyway, and the third instruction is add the required ports as the preference value.  He says:  "You can also add multiple as a comma-separated list or as ranges."  And he says:  "The change does not require a restart."



LEO:  We should point out you can create your own, but it might not do anything.



STEVE:  Exactly.  If you say, you know, wave.hi.to.mom, then...



LEO:  It's not going to do anything.  Clearly Mozilla's code does check to see if such a preference exists.  



STEVE:  Yeah, you could, like, maybe discover a cookie that nobody knew was in there; right?



LEO:  Yeah, I bet there's a lot of stuff in there, yeah.  Yeah, who knows?



STEVE:  Don't spend your time.



LEO:  No.



STEVE:  So as far as Chrome's decision goes, their developer, Adam Rice, noted of port 10080, he said:  "It is an attractive port for HTTP because it ends in '80' and does not require root privileges to bind on Unix systems."  To allow developers to continue using the port, he said that they'll be adding an enterprise policy that developers can use to override the block.  "Once Chrome's change is in place" - that will happen at some point.  I didn't see any version number, but imminently - "users will receive an 'ERR_UNSAFE_PORT' message whenever Chrome attempts to access remote port 10080."  So the takeaway for our listeners is that it would probably be a good idea to migrate any services you might be hosting on port 10080, which need to be accessed from web browsers, move them to, you know, what, 9080 or something.



LEO:  Or 10081, you know, I'm sure there's plenty of places.  And there's 65,000 places you can go.



STEVE:  Exactly.



LEO:  But my question is, and I don't think anybody's answered this, why 10080?  Is there something going on in 10080 that they're trying to prevent?



STEVE:  The reason I ran across those other references was I was asking the same question of the great Internet, and I was unable to find an answer.  So it is not a widely used port.  The only reason, you know, it fell under the category of NAT Slipstreaming, so it must be that there somewhere is a router  that matters, that Google became aware of, that is abusable if it sees traffic passing by it to 10080.  Not any of our consumer routers because, as we said, those are generally low-numbered ports that are bound to services that need some special treatment.  So perfect question, Leo.  



LEO:  I think I found it.  You're the one who should know.  You've got ShieldsUP!.  I'm sure you test that port; right?



STEVE:  Right.



LEO:  It actually shows up as a really good resource for looking at what different ports, especially the canonical ports, are being used for.  Apparently 10080 is used by Amanda.



STEVE:  Yes, there is an Amanda backup software that uses it.



LEO:  Which is broken now.  Sorry, Amanda.  



STEVE:  No, because it's not...



LEO:  Is it inbound or...



STEVE:  That's a very good question.  And when I was digging around, I came away thinking that browsers didn't need to access that.  But maybe that is Amanda's web interface, and Google just said, well, sorry, as you said, sorry, Amanda, but this is more important.  So and it must be because even Adam recognizes that there may be some breakage. 



LEO:  There is a command injection privilege escalation exploit, CVE-132794, for Amanda.  So I wonder if this was to mitigate that.



STEVE:  Interesting.  Maybe they are preventing that abuse of that through Chrome. 



LEO:  You could use Shodan; right?  You could scan for that port on Shodan and see what happens.



STEVE:  Oh, yeah.  And you would find everybody who had it open.  And we ought to also note that for some reason Firefox added that.  Oh, in fact, it does say Amanda on the Firefox list.  



LEO:  Yeah.  This is an old - it's a 2019 CVE.  I'm sorry, 2016 CVE.  A user with backup privileges could trivially compromise a client installation, and that might be why.  But you would think they would want Amanda to fix the exploit as opposed to blocking the port for everybody.



STEVE:  Yeah, exactly, like block it for everybody.  And Leo, in the show notes I do have that searchfox.org/mozilla-central.  If you click that, because I saw that there is a #98, that'll jump you right to the top of Mozilla's huge list of blocked ports.  It's like way more even than Chrome is blocking.



LEO:  Wow.  Interesting.



STEVE:  So, yeah, they're really shutting down a bunch of ports on the outbound side.  And you'll notice at the bottom there...



LEO:  There's Amanda.



STEVE:  There it is, and it's labeled Amanda.



LEO:  Yeah, huh.  Interesting.  So all of these other ports are used for exploits, too; right?  Why else would you block them?



STEVE:  Yes.  Well, but the other thing is that, as we know, when a client, any client of any of our operating systems says give me an outbound port, they start being allocated on local ports from 1024 and up.  So all of those services are going to be down low.  And it would, of course, as we know, web browsers by default aim their traffic at 443 for HTTPS.  If you can force them over HTTP anymore, that'll be port 80.  But you can put colon and then the port number in some script, JavaScript or on your page, to go pull a resource from any port you want to remotely.  So anyway, it does look like they've locked down one more problem.



LEO:  And Mozilla points to spec.whatwg.org for a port-blocking spec that has all these ports on it.  So there's some Internet group - it does not have, I noticed, 10080 on it yet.  But there's some group on the Internet that's saying these ports should be blocked due to a bad port.  And I don't know what that all means.



STEVE:  Wow.



LEO:  So these are the bad ports.  Don't use those.  Bad port.



STEVE:  So believe it or not, this abbreviation of Google's is just - it's not going down easily.  I mean, we figured out, we kind of reverse engineered it.  Well, you jumped on it because you realized that they had all these bird-themed things over at Google Projects.  And so of course they had to use FLoC for their tracking or their anti-tracking abbreviation.  And so then if you have FLoC of birds, then you're going to have to reverse engineer, which is why we get the really awful Federated Learning of Cohorts, which, wow, you know.



So we ask rhetorically, are you FLoCed?  Or rather, actually, the EFF actually did ask that.  Our podcast three weeks ago bore the title "What the FLoC?" because we had to explain what it was about.  And now the EFF has put up a test site which can be used to determine one's FLoC-age, I suppose, with the title - this is literally the title - "Am I FLoCed?" 



LEO:  F-L-O-C.



STEVE:  F-L-O-C, yes, children, A-M-I-F-L-O-C-E-D dot org, amifloced.org.



LEO:  And I'm on Firefox, so I presume I am not FLoCed.



STEVE:  You could not be, yes.



LEO:  Right.  And Brave has decided not to - they're a Chromium port, but they've decided not to include FLoC.



STEVE:  Interesting.  Well, at this juncture.  But of course they're also Brave, so their whole deal is privacy.



LEO:  Right, they don't want it, yeah.



STEVE:  But if you click that little red button there, Leo, that you had on the page a second ago - I tried to click it for you through the camera, but it didn't work.



LEO:  Yeah, no FLoC.  I am not FLoCed.  You have to have Chrome 89 or up.



STEVE:  Ah, okay.  So we already know from our coverage three weeks ago that the best way to characterize the EFF's position is that any form of bias in the treatment of users of the Internet, no matter the means, is a fundamentally bad idea, says the EFF, because it discriminates among Internet users who, in their view, should all be treated identically.  And of course, as we know, Google's FLoC creates a temporary and transient tag formed from hashing the websites Chrome has visited during the previous week, the immediately previous week.  So even though it is expressly not tracking, and even though Google plans to terminate all third-party cookie support in Chrome, which yay, we should herald that, in their transition to FLoC the EFF will be satisfied with nothing less than an entirely non-customized experience on the Internet.



So they've created Am I FLoCed to test and display whether you and your instance of Chrome may have been randomly chosen to participate in Google's initial FLoC research, which Google refers to as an "origin trial."  Odd phraseology, but that's what they call it.  The EFF's page opens with the headline:  "Google is testing FLoC on Chrome users worldwide.  Find out if you're one of them."  Chances are not, but I can't wait to get some feedback from our listeners because, based on the probabilities, we'll certainly have some who are.



The EFF said:  "Google is running a Chrome 'origin trial' to test out an experimental new tracking feature" - which it isn't, but okay, EFF - "called Federated Learning of Cohorts, a.k.a. 'FLoC.'  According to Google, the trial currently affects 0.5% of users in selected regions, including Australia, Brazil, Canada, India, Indonesia, Japan, Mexico, New Zealand, the Philippines, and the U.S.  This page will try to detect whether you've been made a guinea pig in Google's ad-tech experiment."



Okay.  So 0.5% is one in every 200 Chrome users.  And assuming a statistically neutral assignment, we will surely have many listeners among us.  I checked two of my Chrome instances at my two locations, and I came up negative at each.  So it'll be interesting.  What's also interesting is the EFF's take.  I'm going to share a little more of what they wrote.



They said:  "What Is FLoC?  Third-party cookies are the technology," they wrote, "that powers much of the surveillance-advertising," as they refer to it, "business today.  But cookies are on their way out."  And I would argue, yes, thanks to Google.  But they said:  "Cookies on their way out, and Google is trying to design a way for advertisers to keep targeting users based on their web browsing once cookies are gone.  It's come up with" - "it's" meaning Google - "has come up with FLoC.



"FLoC runs in your browser.  It uses your browsing history from the past week to assign you to a group of other 'similar' people around the world.  Each group receives a label called a FLoC ID, which is supposed to capture meaningful information about your habits and interests.  FLoC then displays this label to everyone you interact with on the web."  And remember from our first discussion of this, that's one of the points EFF makes is that it's a beacon saying this is me.



LEO:  Yeah, that's the big problem, I think; right?  Because anybody can see it.  That's, when I found that out, I thought, wow, that's bad.



STEVE:  That is true.  And so they say:  "This makes it easier to identify you with browser fingerprinting." So that's one of the other reasons EFF doesn't like it is that, as we know, fingerprinting takes advantage of as many different signals as your browser is making available.  And, wow, if it's a FLoC ID it's going to be a big signal with many bits of non-entropy to help track you.  So they said:  "This makes it easier to identify you with browser fingerprinting and gives trackers a head start on profiling you.  You can read EFF's analysis and criticisms of FLoC here."  And they have a link to, yeah, the rant which we looked at a couple weeks ago.



So they said:  "The Chrome origin trial for FLoC has been deployed to millions of random Chrome users without warning, much less consent.  While FLoC is eventually intended to replace tracking cookies, during the trial it will give trackers access to even more information about subjects."  Okay, that's true.  But then cookies are going to go away, assuming this happens.  They said:  "The origin trial is likely to continue into July of 2021, and may eventually affect as many as 5% of Chrome users worldwide," so one in 20.  And they said:  "See our blog post."



So under "How can I opt out," they said:  "For now, the only way for users to opt out of the FLoC trial in Chrome is by disabling third-party cookies."  Which is news to me.  That's interesting.  They said:  "This may reset your preferences on some sites and break features like single sign-on. You can also use a different browser.  Other browsers, including independent platforms like Firefox, as well as Chromium-based browsers like Edge and Brave, do not currently have FLoC enabled.



"If you are a website owner" - and this is interesting.  "If you are a website owner, your site will automatically be included in FLoC calculations if it accesses the FLoC API or if Chrome detects that it serves ads."  Probably their ads.  "You can opt out of this calculation by sending the following HTTP response header."  So the header is Permissions-Policy: and then interest-cohort= and then a null set, so just open and closed parens [Permissions-Policy: interest-cohort=()].  Which is interesting.



So if you were - of course, that's on the server side.  But if for some reason you didn't want visitors coming to your site, to have your site's FLoC identity, whatever that is, we'll talk about the SimHash in just a second, added into or to affect your visitors' FLoC ID, then you could arrange, you could easily add that response header to your server, your site's server responses, which would instruct the FLoC accumulating, you know, the FLoC ID accumulating browser, at this point only some instances of Chrome, to not consider that you had visited that site.



So finally, what does my FLoC ID mean?  "If you have been assigned a FLoC ID, it means that your browser" - that is, if you clicked this test, right, and it says, oh, here's your ID.  And I'd love to know if it changes, like every week.  Anyway...



LEO:  So it does tell you your cohort, so you know who you are.  Yeah, they're supposed to change regularly.



STEVE:  Yeah, that would be interesting.



LEO:  Yeah.  Now I want it.  I'm going to get Chrome.  What cohort am I in?



STEVE:  Exactly.  And is it right?  Is it wrong?



LEO:  I can't touch this.  I literally don't run Chrome anywhere.  Which is good.



STEVE:  Yeah, it is.



LEO:  I'm starting to be glad.



STEVE:  So it means that your browser has processed your browsing history and assigned you to a group of - and they have in quotes "a few thousand," which I'm skeptical about, too.  I mean, they're saying on the order of 33,000 groups.  But if you multiply 33,000 by a few thousand, you get like 33 million.  Well, there are a lot more than 33 million Chrome users in the world.  So either it needs to be a larger FLoC ID, meaning more granular tagging, or the groups have to be larger than few thousand.  Anyway, we'll see how this evolves.  But something's not quite right about this.



So they said:  "The numeric label is not meaningful on its own. However, large advertisers like Google and websites like Google will be able to analyze traffic from millions of users to figure out what the members of a particular FLoC have in common."  So that's sort of interesting.  That says that there isn't, like, bits are not assigned in the ID, meaning, oh, that bit's for commerce sites.  This bit's for outdoor camping.  This bit's for autos.  It's not like that.



So apparently - and we'll talk about the SimHash, as I said, in a second.  So it's very fuzzy.  And so you need to be somebody like a Google who has its fingers out everywhere, like Analytics, right, they've got Analytics probes everywhere.  Their Analytics probe will receive the FLoC ID.  They will know what site their Analytics probe is on.  So they'll be able to aggregate these FLoC IDs over the whole Internet, effectively, and reverse engineer that these IDs are have been seen on all of these websites where we have Google Analytics probes.  And of course Facebook is the same way with their Like buttons everywhere, and advertisers serving ads across the Internet.



So you can sort of see how this closes the loop.  It isn't tracking.  It is profiling, which is the word I'm going to recommend in a minute that they switched to using for accuracy's sake.  And it does require a lot of backend work to be constantly associating these tags, which are changing weekly.  And I guess maybe the FLoC IDs themselves would settle down after a while, and then who was carrying them would change from week to week.  Anyway, really interesting technology.



And so I'm going to stop sharing what they wrote.  We have enough of that.  So you and I, Leo, indicated three weeks ago that it seemed like an improvement over explicit tracking by third-party cookies, although when we dug into it a little bit further and realized, okay, you know, one of the EFF's points is that it does present a tag, a who-I-am-ish tag, to sites who have a way of understanding it.  It may, though, be that, due to the nature, I mean, it's not going to be a tag with an obvious public meaning.



So if I saw tags coming to me from visitors at GRC, I don't have probes all over the Internet like Google and advertisers do.  So it's just nonsense for me.  What I did want to say is that I wish EFF would drop their insistence on calling it "tracking."  It is not tracking.  And I think it weakens them, their position, which has some merit, if they call it "profiling."  Which, you know, is equally derogatory in this connotation.



LEO:  Yeah, and maybe worse.



STEVE:  Yeah, people don't want to be profiled, but that's really what it's doing.  It's says "profiling distillation," essentially.  So what's different about this?  I promised to talk about the SimHash.  I was looking into it a little bit more.  A highly desirable and in fact a required feature of any  traditional cryptographic hash is that a tiny difference, even a difference of one bit, in what we call the digest, right, the hash's input, a one-bit change yields dramatically different hashed results.  And in fact when we talked about the actual technology of cryptographic hashes in the past, we noted that, if you change one bit in a big digest that you feed to a cryptographically strong hash, on average a random set of half of the resulting bits will change.  Which is mind-boggling.  That's just so cool.  You change one bit in what you feed into the hash, and on average a random set of half of the hash's output bits change.



But the SimHash algorithm that Google plans to use deliberately produces similar hash results - thus the name SimHash - when given similar inputs.  So in other words, if you hash the big digest that we were just talking about, but didn't change much of it, the output won't change much either.  That is, similar input results in a similar hash value.  It's still a hash, but two inputs that may have similarities will result in a similar result, which is interesting.



So there's a sense of like a computation, a mathematical concept of distance, you know, how far away from each other are two similar things that you run through the SimHash.  And it approximates that.  So that's like the secret behind Chrome's ability to pour all the places you go to on the 'Net over the course of a week into this SimHash and distill it down to something which is in some way representative of the nature of the places you went without explicitly revealing where you went.  And that's, from the user's standpoint, that's kind of cool because, in the same way that a password hash, where it's exacting, right, if you put the same password in, you get the same hash, which is how we use password hashes.  Yet the hash itself tells you nothing about the password.  Similarly, presumably the SimHash won't reveal which similar sites you went to, but that apparently you went to some.



So anyway, I guess as a tech junkie I think it's kind of cool.  It'll be interesting to see how it all evolves.  But in any event, I would love to have our Chrome-using listeners go to  amifloced.org and see where this thing says, yeah, at the moment you are.  Tweet me at @SGgrc on Twitter, if you go there and you get some positive results.  I think it'd just be kind of cool.



While we're doing follow-ups on past topics, the week after our "What the FLoC" episode was "GIT Me Some PHP."  And as our listeners know, that was about what I felt had to be the oh so deliberately obvious hack of the PHP project's private GIT server.  The press all saw only the fact that the GIT server had been hacked and a backdoor had been installed, or code for a backdoor was there.  But the way it was done, you know, the guy was sending up fireworks.



So the middle of last week we received an update on the PHP project's ongoing investigation of exactly what happened.  Now we know.  Nikita Popov, who is one of the two people, he was the main guy involved in tracking this down, and it was his identity along with Rasmus's, the original PHP inventor/designer, whose name was used in the two commits which created this hack.  So he posted:  "Update on git.php.net incident."  His posting is long and detailed, and its link is here in the show notes for anyone who's curious.  But the short version is that some legacy stuff bit them in the butt.  They had a seldom-used secondary and less secure means for pushing commits into their private GIT repository.



Nikita, who is very much on top of this, wasn't even aware of this secondary back-channel at the time.  He wrote:  "When the first malicious commit was made under Rasmus's name, my initial reaction was to revert the change and revoke commit access for Rasmus's account, on the assumption that this was an individual account compromise.  In hindsight," he said, "this action didn't really make sense because there was at the time no reason to believe that the push occurred through Rasmus's account in particular.  Any account with access to the php-src repository could have performed the push under a false name."



Then he said:  "When the second malicious commit was made under my own name, I reviewed the logs of our gitolite installation in order to determine which account was actually used to perform the push.  However, while all adjacent commits were accounted for, no git-receive-pack entries for the two malicious commits were present, which means that these two commits bypassed the gitolite infrastructure entirely.  This was interpreted as likely evidence of a server compromise.



"Something I was not aware of at the time is that git.php.net intentionally supported using changes not only via SSH," and he says, parens, "(using the gitolite infrastructure and public key crypto), but also via HTTPS.  The latter did not use gitolite, and instead used git-http-backend behind Apache2 Digest authentication against the master.php.net user database."  He says:  "I'm not sure why password-based authentication was supported in the first place, as it is much less secure than public key authentication."



Anyway, he then shows us a chunk of the Apache HTTP server log showing the two commits, and he notes:  "It is notable that the attacker only makes a few guesses at usernames, and successfully authenticates" - meaning has the password - "once the correct username has been found.  While we don't have any specific evidence for this, a possible explanation is that the user database of master.php.net has been leaked, although it's unclear why the attacker would need to guess usernames in that case.



"The master.php.net system, which is used for authentication and various management tasks, was running" - and here it is - "very old code on a very old operating system/PHP version, so some kind of vulnerability would not be terribly surprising.  We've made a number of changes to increase the security of this system."  Good.  So four bullet points:  "Master.php.net was migrated to a new system running PHP 8 and renamed to main.php.net at the same time.  Among other things, the new system supports TLS 1.2, which means you should no longer see TLS version warnings when accessing this site."  So, yeah, it had been a little creaky.  "The implementation has been moved towards using parameterized queries, to be more confident that SQL injections cannot occur.  Passwords are now stored using bcrypt."  Elsewhere he had mentioned that they were using MD5, which has long been deprecated everywhere.



And, finally, "Existing passwords were reset."  So then he says where to go if you need to generate yourself a new one because your old ones won't work.  So it's a little distressing that right in the middle of the home of PHP we find a very old server with, like, sending warning messages because it doesn't support any of the new TLS protocols that our browsers are using, on a very old platform, running a very old PHP that no one has looked at or is really even aware of for quite a long while.  And you know me.  Old doesn't automatically mean bad.  Plenty of old things were written well and have stood the test of time.  But big complex operating systems, feature-laden web servers, and PHP do not generally number among those things.  So now we have the point of entry.



I still think of the attacker as more of a prankster due to the crying-out-loud code he placed onto the server which demanded to be noticed.  He somehow arranged to authenticate as two very high-profile developers, again making sure his changes would be caught.  And they never really did determine exactly how, and they really didn't care.  They just got rid of it all, replacing it with up-to-date solutions to do the same thing.



And yes, they did also move the entire working PHP repository - which up to that point had just been a backup repository, now it's the main working repository - over to GitHub so they can focus upon PHP development and not worry about the security of the access controls of the repository.  So all a good move.  A little embarrassing.  But it's nice, I mean, it's good for them to say, you know, yeah, this thing was so dusty that we're not surprised that somebody was able to crawl in.  We don't really care how.  We just got rid of it all.



A constant in our industry is the dilemma of deliberately terminating important critical patch support for previously supported systems that have reached the end of their support lifecycle.  We often talk about this with Microsoft and Windows.  It's especially irksome when some people are receiving paid-for  updates while others are not.  So it's not as if those updates don't exist.  But even mighty Microsoft occasionally, we might even say often, bends to the severity of their own mistakes to offer out-of-lifecycle patches when the cost to them of doing so, if only I guess in reputation damage, would be prohibitive.



They just did this at the start of March by reaching way back to patch Exchange Server 2010 for the ProxyLogon flaws, even though that version was well past its kill-by date.  But we've also, we've seen similar situations where Cisco, for example, and in this case, makes a different call.  And it's not as if Cisco's commercial products are not similarly littered with patchable vulnerabilities.  They are.  Not to mention that spate of secret accounts and passwords that's appeared throughout their high-end products as people started poking around in their networking firmware and found that they'd hard-coded all those backdoors.  We were covering that for a while a couple years ago.



Today, Cisco has informed the world that it has no plans to fix critical security vulnerabilities affecting some of its smaller SOHO, the small business routers.  What does it tell its past customers to do?  Replace them with new Cisco devices.  Or perhaps it's time to consider changing brands.  The bug they all share is tracked as CVE-2021-1459.  And it carries the difficult-to-achieve CVSS score of 9.8 out of 10.  It's hard to get up there.  Just about the only way to get a higher score is if it's able to attack you after it's been unplugged.  In this case, it's a bad vulnerability.  Four routers are affected:  the RV110W, which is a VPN firewall; and three small business routers, the RV130, RV130W, and the RV215W routers.



In each of the four cases, the known flaws allow an unauthenticated, remote attacker to execute arbitrary code on the affected device.  In other words, 9.8.  The flaw, which stems from improper validation of user-supplied input in the, wait for it, web-based management interface - when have we ever heard of that being a problem? - could be exploited to send specially crafted HTTP requests to the device to achieve remote code execution.



Cisco's advisory said:  "A successful exploit could allow the attacker to execute arbitrary code as the root user on the underlying operating system of the affected device."  They also said:  "The Cisco small business RV110W, RV130, RV130W, and RV215W routers have entered the end-of-life process."  Painful as it is in this case.  "Customers," they said "are encouraged to migrate to the Cisco small business RV132W, RV160, and RV160W routers."



So I looked them up.  The routers are their lowest end little plastic box consumer box routers.  The "W" suffix in each case means "Wireless," so that's the wireless flavor.  The new replacements, for example the RV160 and RV160W are $114 and $145 respectively at the moment on Amazon.  So, you know, in any event, not a huge investment.  It's not as if they're leaving their major enterprise customers out to dry.  No self-respecting enterprise would have one of those, hopefully.



And sadly, even if they were to update the firmware, that is, if they were to offer updates of the firmware of those old and no longer being made or supported routers, how many of them would even ever get the updated code?  Right?  I mean, these things are forgotten in a back room.  We know that there will be tons of those older routers out on the 'Net, thanklessly doing their job, day in and day out.



And presumably, people chose the Cisco brand because they'd heard of Cisco and wanted the assurance of a superior product.  So let's hope that the default configuration was to disable remote web access and that no one ever had it turned on.  This is another of those, we see them too often, web management interface issues.  Hopefully no one is exposing their router's web management interface to the Internet.  And I'm sure that all of our listeners know that unless remote management is really needed and is being actively used, web management, all remote management, should always be kept off of the public Internet.



One thing to note is that all of the tech press which covered Cisco's announcement of this trouble led their stories saying,  "Cisco says," and I'm quoting one of them, "Cisco says it will not patch three small business router models and one VPN firewall device with critical vulnerabilities."  That was repeated over and over in similar words.  So it appears to matter to the tech press.  At the same time, how long are they supposed to be responsible for routers that they are no longer selling?



I just thought I would say, so that we can sort of take this as a learning moment, the one right way to handle the need for remote access is to turn off remote access everywhere, then use one high-quality SSH server that requires a password and a certificate and a time-based additional factor for authentication.  And while you're at it, run that server on some random port.  There's no reason not to.  Don't leave it on the default SSH port.  If you use SSH to securely - oh, I'm sorry.  So then you use SSH to securely first gain access to the internal network, then perform any required administrative work from the inside over LAN-bound interfaces.  And it's even possible to run a standard Windows Remote Desktop connection over SSH.  It works great.



So to me that's the way to do this is, you know, I've often talked about this.  If your remote ends have fixed IPs and fixed IP ranges, absolutely use IP address filtering so that nobody can even see those ports when they're scanning from Shodan or any of the growing number of commercial or private scanners.  Only people like at a sister IP network by IP address are able to even have any access.  But if for some reason you need roaming access, where you're able to connect from any IP, the only thing, the only presence ought to be an SSH server somewhere that is high quality, that you're paying attention to.  You've got three different ways to authenticate - something you know, something you have, and something that's changing all the time.  You need to use those that get you in.  And then from the inside you can do all kinds of things.  Today that's the way to set this up.



Okay.  Our final, before we get to our big conversation about Pwn2Own.  I titled this "Failure to Patch."  And it'll lead us to talk a little bit more about the nature of this kind of problem.  Way back in early 2019, Fortinet, major Internet supplier of Internet-connected appliances, they produce among other things the FortiGate SSL VPN.  Early in 2019 they received notification through responsible disclosure for a critical remotely exploitable vulnerability in several current releases of their FortiOS, as they call it, which forms the basis of several products.  The security researchers in question were Meh Chang and Orange Tsai from the DEVCORE Security Research Team.  We'll be hearing their name again later in this podcast.



And we've talked about Orange Tsai and DEVCORE recently.  That's the guy who, or maybe it's a real name, I don't know, but in any event they're the people who informed Microsoft in 2020 that they had a problem with Exchange Server.  And we're going to be talking about them in Pwn2Own.  So you pay attention when these guys say, hey, we found a critical remotely exploitable vulnerability in your SSL VPN.  So Fortinet shortly found and immediately fixed the trouble.  They were told in early 2019.  It afflicted three branches of their FortiOS, the 5.4, 5.6, and 6.0 branches.



And in May of 2019 they produced update patches, and their FortiGuard Labs, which is the security research side, published a clear vulnerability disclosure explaining that:  "A path traversal vulnerability in the FortiOS SSL VPN web portal" - web portal - "may allow an unauthenticated attacker to download FortiOS system files through specially crafted HTTP resource requests."  Okay, now, once again, a path traversal; right?  We keep having those problems occurring also as a consequence of the fact that we have hierarchical directory structures, and ../ moves you up a level.  Anyway, that was May 2019.



Three months later - so they announced it.  They contacted their customers, sent out email, made the official declaration, had the patches out.  The DEVCORE guys, responsible disclosure; right?  They let them know.  And it turns out the DEVCORE guys were going to make a presentation in the upcoming Black Hat conference.  So three months later, on August 28th, Fortinet posted a blog titled "FortiOS and SSL Vulnerabilities."  That was the title.  And they explained that:  "At the recent Black Hat 2019 conference held in Las Vegas this past August 3rd through 8th, security researchers discussed their discovery of security vulnerabilities that impacted several security vendors, including Fortinet.  All of the vulnerabilities impacting Fortinet were fixed in April and May of 2019."



But in their disclosure, this disclosure in August, we get another little interesting tidbit.  They said:  "In addition, it was also disclosed and fixed in May that FortiOS included a 'magic'" - and they had that in quotes - "a 'magic' string value that had been previously created at the request of a customer to enable users to" - oh, this is always so bad - but "at the request of a customer to enable users to implement a password change process when said password was expiring.  That function had been inadvertently bundled into the general FortiOS release, and an Improper Authorization vulnerability resulted in that value being usable on its own to remotely change the password."



LEO:  Oh, god.



STEVE:  So basically they left a magic string...



LEO:  A backdoor, basically.



STEVE:  Backdoor, yes, that allowed an unauthenticated - because after all, if you forgot the password, you couldn't log in to authenticate yourself, so let's just have a magic password bypass.



LEO:  And it was discovered, apparently.



STEVE:  Yeah, exactly, yeah.  Well, because it was revealed at Black Hat, which their previous disclosure did not say because it was too embarrassing.  Right?  It's like, okay, we'll just - we fixed it.  Don't worry.  Just please...



LEO:  Yeah, yeah.  We fixed it.  Don't worry your little head about it.



STEVE:  Yeah, get yourself patched quickly.  Oh, lord.  So a few days before that, this had hit the tech press because it was, you know, Black Hat.  So for example, Dan Goodin, writing for Ars Technica, titled his story "Hackers are actively trying to steal passwords from two widely used VPNs."  And Dan opened with:  "Hackers are actively unleashing attacks that attempt to steal encryption keys, passwords, and other sensitive data from servers that have failed to apply critical fixes for two widely used virtual private network (VPN) products, researchers said."



He said:  "The vulnerabilities can be exploited by sending unpatched servers web requests that contain a special sequence of characters, researchers at the Black Hat security conference in Las Vegas said earlier this month.  The pre-authorization file-reading vulnerabilities resided in the FortiGate SSL VPN installed on" - wait for it - "about 480,000 servers."  So, yeah, this is a popular solution, nearly half a million servers.  "And the competing Pulse Secure SSL VPN, installed on about 50,000 machines."  And that's researchers from DEVCORE Security Consulting reported.  So, yeah, 480,000 FortiGate SSL VPN instances.  Yikes.  At the time, the Internet was being sprayed - that's the term that was used in several of the other reports - sprayed with probes seeking to find and exploit these now well-known weaknesses.



Okay.  So then nearly a year passes.  On July 16th of 2020, Fortinet blogs with the title:  "APT29 [Advanced Persistent Threat] Targeting SSL VPN Flaws."  So in July last summer, 2020, they're blogging that the well-known APT29 group are targeting their devices.  They wrote:  "United Kingdom's National Cyber Security Centre (NCSC) and Canada's Communications Security Establishment (CSE) have published research into the activity of APT29, also known as the Dukes" - or of course we know them as Cozy Bear, they're Russians - "who have been targeting various organizations involved in COVID-19 vaccine development in Canada, the United States, and the U.K., highly likely with the intention of stealing information and intellectual property relating to the development and testing of COVID-19 vaccines."  And, you know, there was reporting, right, about espionage last summer relating to COVID-19 and attempts to get in.  Now we understand one of the ways in.



They wrote, Fortinet wrote:  "The initial attack vectors for this group have been unpatched vulnerabilities in SSL VPN solutions from Fortinet.  One of the vectors included a vulnerability resolved by Fortinet in May of 2019" - so more than a year before this - "allowed an unauthenticated attacker to download FortiOS system files through specially crafted HTTP resource requests as disclosed in" - and then they linked to their original disclosure.  "At the time of the disclosure, Fortinet made available patches for all supported releases (5.4, 5.6, 6.0, 6.2).



"Customers were notified at the time via the public PSIRT advisory system of the need to upgrade immediately, and highlighted the same in the release notes.  For those unable to upgrade, mitigations were provided.  For additional transparency, this was again highlighted in a blog in August 2019 after the vulnerabilities were disclosed by the researchers at Black Hat 2019."



So here we are.  And today, this nearly now two-year-old issue is back in the news because Kaspersky Labs has just released their report analyzing a few high-profile ransomware attacks, employing a relatively new strain of ransomware called "Cring," C-R-I-N-G, and it's well designed.  It uses AES 256-bit keyed encryption.  And just for the heck of it, an 8092-bit public key.  So public key crypto with overkill bit length because why not.  These attacks and Cring have been used to shut down some major European industrial enterprises.



Kaspersky said:  "The attackers exploited the CVE-2018" - so 2018, right? - "13379 vulnerability to gain access to the enterprise's network.  The vulnerability was used to extract the session file of the VPN Gateway.  The session file contains valuable information, such as the username and the plaintext password."  Because absolutely, let's log the plaintext password.  What could be wrong with that?  Unpatched FortiGate devices - on the other hand, you know, maybe they know the magic key that lets you log in without having the password, so there's that.



They said:  "Unpatched FortiGate devices are vulnerable to a directory traversal attack, which allows an attacker to access system files on the FortiGate SSL VPN appliance.  Specifically, an unauthenticated attacker can connect to the appliance through the Internet and remotely access the file 'sslvpn_websession,' which contains the username and password stored in cleartext.  The vulnerability affects devices that run FortiOS versions 6 to 6.0.4, 5.6.3 to 5.6.7, and 5.4.6 to 5.4.12."



Several days - and this gets back to our point, Leo, about surveillance first.  They said, Kaspersky said:  "Several days before the start of the main attack phase, the attackers performed test connections to the VPN Gateway, apparently in order to check that the vulnerable version of the software was in use on the device.  The attackers may have identified the vulnerable device themselves by scanning IP addresses.  Alternatively, they may have bought" - as in purchased - "a ready-made list containing IP addresses of vulnerable FortiGate VPN Gateway devices."  Because why not?  They said:  "In autumn 2020, an offer to buy a database of such devices appeared on a dark web forum.



"After gaining access to the first system on the enterprise network, the attackers downloaded the Mimikatz utility to that system.  The utility was used to steal the account credentials of Windows users who had previously logged in to the compromised system.  With the help of Mimikatz, the attackers were able to compromise the domain administrator account, after which they started distributing malware to other systems on the organization's network.  They used the Cobalt Strike framework for that purpose.  The Cobalt Strike module was loaded on attacked systems using PowerShell."



So they have a much greater in-depth report for anyone who's interested.  I have the link in the show notes.  And, you know, once upon a time, and we've talked about this before, Leo, as we old timers vividly recall, our systems, whether they were Windows, Mac, Unix, or Linux, crashed with some regularity.  They don't any longer.  And I'm really curious to see whether our use of networking and networking technologies will follow the same path.  Are we ever going to get it right?  Can we?  One of the advantages our operating systems have is that everything is concentrated in one place.  You know, they're self-contained monoliths of technology.  And even so, at the margins, our operating systems are still far from perfect.



But on the Internet, everyone rolls their own, and everyone wants to.  So as a consequence, we keep seeing the same mistakes being made over and over again.  And we even see regressions where problems, once fixed, later reappear.  And lessons once learned, like "don't use secret strings in firmware," are forgotten or unlearned. You know, someone new comes along and thinks, "I'm going to solve that problem this way," even when many others before have learned the hard way not to.



On the Internet there's no central control, which is often touted as being a good thing.  It spurs and spawns innovation.  And I'm sure that's true.  But innovation brings mistakes.  The old adage, "If you're not making mistakes, you're not trying hard enough," is unfortunately all too true on the Internet.  But collectively we really cannot afford to keep making the same mistakes over and over.  They're becoming more and more expensive as the Internet is becoming more and more core and critical.  And as our look at Pwn2Own is going to show, there are undoubtedly many that have not yet been found.



In this instance it's certainly the case that many of the FortiGate SSL VPN gateways, I'm sure, 480,000 of them initially, I'm sure a bunch were quickly patched by IT professionals who were on top of their game.  They received and read the news of an update, understood its significance, and quickly patched their enterprise's servers, even if they may have briefly inconvenienced some of their users in order to keep them safe.  But we know that not everyone received the news; or, if they did, they received so much of it on a daily basis that they put it into the "I'll deal with this later" pile and never got back to it.



One thing we've seen is that there are technologies that seem to be particularly troublesome.  Aside from embedding secret strings in firmware, there are web interfaces.  They're attractive because they're so user-friendly.  But they're also inherently attacker-friendly because their user-friendliness comes by way of complexity.  And complexity is at an eternal war with security.  So it appears that the best we can do is design our solutions to minimize our attack surfaces, like by using, as I said, one high-security SSL server to provide all remote access by moving all other remote access to the inside.



And of course, as we've often mentioned, being careful to keep all lines of communication open to all the vendors of our products and to carefully consider the implications of every security update notice we receive.  Lord knows how many of those out-of-cycle, out-of-life, all-but-dead Cisco plastic box low-end routers, I mean, they're out there.  They're on the 'Net.  Let's hope they don't have the web interface exposed.  They are discoverable.  They will be discovered.  And now that bad guys know there's a way in, they'll take a look at, I mean, you could buy one off eBay because, right, they're not going to have their firmware fixed.  So buy one.  Everyone knows there's lots of documentation on reverse-engineering SOHO router firmware.  And find the problem, and wow.  So the world we live in today, Leo.



LEO:  All right.  Let's PwnIt and OwnIt.



STEVE:  So last week - of course it was a virtual event, right, because we're still in COVID land.



LEO:  Right, right.  In a way that's better because bad guys operate virtually; right?



STEVE:  That's a very good point.  You're right.  So last week, Tuesday through Thursday, $1,210,000 flowed from some generous, deep-pocketed sponsors to some very clever security researchers during what was the Spring 2021 Pwn2Own contest.  And the blow-by-blow details are as interesting as ever, and we'll get to those in a second.  But overall, 23 teams of researchers targeted web browsers, virtualization offerings, servers, and what was grouped as "enterprise communications," Zoom among them.



The total prize pool, most of which was distributed, was $1.5 million, so as I said, 1.21 million went out in awards.  And there was a Tesla Model 3, but none of the teams chose to tackle the Tesla this year.  But as we'll see in a minute, they pretty well minced up Windows 10, Microsoft Teams, Exchange Server, Ubuntu Desktop, Chrome, Edge, Safari, and the Parallels VM Desktop.  And in addition to cash, which remains kings, point scores, the Masters of Pwn point scores were also awarded for successful hacks.  And the top three teams all tied at 20 points each.



Okay.  So here's what happened.  Starting Tuesday morning, April 6th, at 1000 hours, Jack Dates from RET2 Systems targeted Apple Safari in the Web Browser category, obviously.  Jack used an integer overflow in Safari and an out-of-bands write to get kernel-level code execution.  In doing so, he won $100,000 and 10 Master of Pwn points.  An hour and a half later, here comes DEVCORE for the first of several.  DEVCORE targets Microsoft Exchange, of course in the Server category.



Now, recall, as I reminded us already, that it was DEVCORE who originally discovered and reported the authentication bypass bugs in Exchange Server that led to this year's devastating ProxyLogon attacks, while Microsoft appears to have badly underestimated their impact, and took their time releasing patches.  Well, lest we think that all of the problems with Exchange Server have been resolved, we should think again.  The DEVCORE team combined an authentication bypass - yes, another one - and a local privilege escalation to completely take over Exchange Server, pocketing $200,000, and 20 Master of Pwn points.



And you know, this time it's not difficult to imagine that Microsoft will be patching Exchange Server with some alacrity.  But since today, here on April 13th, is April's Patch Tuesday, those fixes may not have been ready in time.  I haven't even looked yet at what is happening today underneath us.  We'll check into that next week.  So maybe we'll see an out-of-cycle update.  Who knows?  Certainly they don't want to let an authentication bypass and complete remote code execution vulnerability languish in Exchange Server because they're still being patched.



At 1300 hours the researcher who goes by "OV" targeted Microsoft Teams in the Enterprise Communications category.  He combined a pair of bugs to demonstrate code execution on Microsoft Teams and, in doing so, earned himself $200,000 and 20 points towards Master of Pwn.  At 1430, Team Viettel took aim at Win10, going for a Local Escalation of Privilege, and they, too, succeeded with an integer overflow in Windows 10 to escalate their privilege from regular user to system privileges, earning them $40,000 and four points towards the Master of Pwn.



At 1530 hours, the STAR Labs team consisting of Billy, Calvin, and Ramdhan targeted Parallels Desktop in Virtualization, and this brought us the first failure of the first day.  They were unable to get their exploit to work within the time allotted.  At 1630 hours, Ryota Shiga of Flatt Security, Inc. targeted a fully patched and up-to-date Ubuntu Desktop, hoping to achieve an escalation of local privilege.  Ryota used an out-of-bands - I'm sorry, out-of-bounds, I just have OOB here - out-of-bounds access bug to elevate himself from a standard user to root on Ubuntu Desktop, earning himself a tidy 30,000 and three Master of Pwn points in his own Pwn2Own debut.  He had never done this before.



At 1730, undaunted by their inability to penetrate the Parallels Desktop previously, that STAR Labs team of Billy, Calvin, and Ramdhan went after Oracle's VirtualBox.  Unfortunately, they were unable to accomplish their penetration within the allotted time, and that ended Day One.



Starting at 9:00 in the morning on Wednesday, April 7th, Jack Dates again, he returned from RET2 Systems.  He kicked off the day, much as he did on the day before on Tuesday, this time targeting Parallels Desktop.  Jack nailed it by combining three bugs:  an uninitialized memory leak, a stack overflow, and an integer overflow to escape from the Parallels Desktop and execute code directly on the underlying OS.  Jack added $40,000 to the $100,000 from the first day, racking up an additional four Master of Pwn points.  So he's now at 140,000 so far.



At 1000 hours, Bruno Keith and Niklas Baumstark of Dataflow  Security targeted Chrome and Edge - of course Edge uses the Chromium engine now - in the Web Browser category.  They successfully employed a type mismatch bug to exploit the rendering engines in both Chrome and Edge, of course same engine, because of course we're headed toward a web browser monoculture, for better or for worse.  They earned $100,000 in total and 10 Master of Pwn points.



At 1130, Team Viettel, they were back targeting Microsoft Exchange Server also, and scored a partial success, partial only due to a previous disclosure.  They did successfully demonstrate their code execution on Exchange Server, but some of the bugs they used in their exploit chain had been previously reported in this contest.  So probably a coincidental collision.  This counts therefore as a partial win, but did award them 7.5 Master of Pwn points.



At 1300 hours, Daan Keuper and Thijs Alkemade from Computest targeted Zoom Messenger, which we'll have a little more to say about later because it was significant.  This was also in the Enterprise Communications category, like Microsoft Teams.  And this one made some news.  They successfully used a three-bug chain to exploit Zoom Messenger and get code execution on the target system.  Whoopsie.  And this was without the target clicking anything.  It's a zero-day, zero-click exploit which earned them $200,000, 20 Master of Pwn points, and I'm sure a follow-up conversation with Zoom.



At 1430, Tao Yan of Palo Alto Networks went after Windows 10.  By using a race condition bug, Tao was able to successfully escalate his access to full system privilege on a fully patched Windows 10 machine.  That earned him $40,000 and four points toward the Master of Pwn.  At 1530, Sunjoo Park, who's apparently also known as Grigoritchy, was targeting Parallels Desktop.  And sure enough, by using a logic bug in Parallels, he was able to execute code on the underlying OS, basically breaking out of the VM container and earning himself $40,000 and four points.



At 1630, Manfred Paul also targeted the Ubuntu Desktop and achieved or hoped to achieve local escalation of privilege by using an out-of-bounds access bug.  He succeeded in escalating to root on Ubuntu Desktop.  So he's now $30,000 richer and scored himself three points.  At 1730, the researcher known as "z3r09" targeted Windows 10 with a local escalation of privilege attack.  He successfully used an integer overflow, escalating his permissions to NT AUTHORITY\SYSTEM account, which simultaneously escalated his bank account by $40,000 and his Master of Pwnage by four.



Which brings us to the final day.  Also at 900 hours, Benjamin McBride from L3Harris Trenchant also targeted Parallels.  Boy, that Parallels was a popular target this year.  And Ben employed a memory corruption bug to successfully execute code on the host OS from within Parallels Desktop, earning himself $40,000 and four Master of Pwn points.  At 1000 hours, Steven Seeley of Source Incite thought that Microsoft Exchange probably still presented some low-hanging fruit.  Although Steven did successfully use two unique bugs in his demonstration, he was only credited with a partial win because his attack required a man-in-the-middle aspect, so it wasn't solely one-sided.  But it was great research, and the judge awarded him 7.5 Master of Pwn points.



At 1130, Billy, operating solely from the STAR Labs team, targeted Ubuntu Desktop.  Although he was able to successfully escalate his privileges to root, the bug he used was already known to - he was targeting, oh, yeah, Ubuntu.  It was already known to Ubuntu and was on their patch list.  So Billy's demo of this earned him two additional Master of Pwn points, but that was it.  At 1230, Fabien Perigaud of Synacktiv targeted Win10.  And despite Fabien's reported excellent use of ASCII art during his demonstration - I didn't see it...



LEO:  That's critical, though.



STEVE:  Oh, you've got to have good ASCII art, absolutely.  And it turns out Microsoft was aware of the bug he used.  So he did earn two Master of Pwn points for the partial win.  And, yes, for the ASCII art.



LEO:  It doesn't seem fair that because the company's aware of it, even if they haven't published it, that you should lose points.



STEVE:  I agree with you.  And Leo, it also doesn't seem fair to me, if there was a way to capture the exploits, like to capture them and escrow them, it doesn't seem fair if earlier in the same competition someone uses the one that you had.  You ought to share the prize money.  Right?



LEO:  Yeah, there you go.  That would be fair, yeah.



STEVE:  Because the sequence is just arbitrary.  Because they're sequential, and in this case on the next day, you might argue, oh, the guy gleaned something from the demo.  But anyway.  We have the first woman ever, Leo.



LEO:  Ever?  That's surprising.



STEVE:  Yes, at 1330 Alisa Esage went after a Parallels Desktop penetration.  Despite her great demonstration and, yes, replete with ASCII art, the bug used by Alisa had been reported to ZDI prior to the contest, which as you said, Leo, I agree, shouldn't have counted against her.



LEO:  I mean, if it's public, yeah.  But if it's never been made public, hey, she found it on her own, independently.



STEVE:  Right.  In this case it reduced it to a partial win.  The judges commented that it was great work and were thrilled that she broke ground as the first woman to participate as an independent researcher in Pwn2Own history.  She took home a pair of Master of Pwn points, and let's hope we see her again.



At 1430, Vincent Dehors of Synacktiv targeted Ubuntu Desktop.  And despite Vincent's admission that this was his first exploit ever written for Linux, he had no issues escalating to root through a double-free bug, thus earning himself $30,000 and three Master of Pwn points.  And Ubuntu is the wiser for it.  At 1530, Da Lao took aim at Parallels Desktop and, using an out-of-bands write, he, too, successfully completed a guest-to-host escape in Parallels, earning himself $40,000 and four points toward the Master of Pwn.  And at 1630, last but not least, Marcin Wiazowski targeted Windows 10 for a local escalation.  He nailed it using a use-after-free flaw to escalate his Windows 10 privilege to system, taking home $40,000 and four Master of Pwn points.



So a bunch of high-profile companies have some high-profile patching to do.  And every Pwn2Own, where we watch talented researchers, research hackers essentially, appear to so easily find and exploit previously unknown flaws - these are all true zero-day exploits when they're demonstrated - it always gives me a bit of a chill.  And it really begs the question, just how much other unknown stuff lies out there, either undiscovered or, worse, previously discovered and being put to quiet use?  We don't know what Zerodium's portfolio looks like today, and I'm not sure I want to know.



And I said I would mention a little more about these newly revealed Zoom vulnerabilities, which were demonstrated by the team from Computest Security.  Theirs is particularly noteworthy because they require no interaction of the victim, or from the victim, other than being a participant on a Zoom call.  What's more, it affects both Windows and Mac versions of the app, though it's not clear whether Android and iOS may also be vulnerable.



LEO:  And it doesn't affect the web version of the app, either.



STEVE:  Oh, okay, right.  Fortunately, details of the flaws have not been disclosed.  But in a statement sharing the findings, Computest said that they were able to almost completely take over the system and perform actions such as turning on the camera, turning on the microphone, reading emails, checking the screen, and downloading the browser history.  So it sounds more like an escape to browser sort of thing based on what they're doing, like reading emails, well, maybe Yahoo and Gmail, you know, but maybe not emails outside.



LEO:  Yeah.  If the browser's sandboxed, they can't get outside of that.  Although it does beg, okay, now let's find a sandbox escape.  We're on our way.



STEVE:  Right.  For its part, Zoom has said that it already pushed a server-side change to patch the bugs, and noted that it's also working on incorporating extra protections to resolve some security shortcomings.  A Zoom spokesperson said:  "On April 9th we released a server-side update that defends against the attack demonstrated at Pwn2Own against Zoom Chat.  This update does not require any action by our users."  Again, that suggests, yes, it's the web only.  That way, like when you bring up a new web instance, because they said it was a server-side update, right, so it's going to push out the new client-side stuff to that web chat instance.



And they said:  "This update does not require any action by our users.  We are continuing to work on additional mitigations to fully address the underlying issues."  So that sounds like they pushed an immediate short-term, but incomplete, fix to block the explicit attack or the explicit vulnerability that had been found and demonstrated, and that it revealed some need for some deeper re-engineering, which they're going to follow up and do.  Zoom said it's not aware of any evidence of active exploitation by these issues, while pointing out the flaws don't impact in-session chat in Zoom Meetings.  So it's only just Zoom Chat.  And they did say the attack can only be executed by an external contact that the target has previously accepted or that's part of the target's same organizational account.



So in any event, Pwn2Own is clearly providing a valuable service.  And I hope that, for what it's worth, those in charge of security everywhere, you know, get the same feeling of chill that I do when they watch what talented researchers are able to do with some of the industry's presumably most secure offerings.  It's like, you know, pay us enough money, and we'll take a hard look at your product and find a way in.  And so you have to imagine that there are people elsewhere being motivated either by money or prestige or their government.  Who knows?  Anyway, we're not going to run out of content anytime soon on this podcast, Leo.  



LEO:  And the point of Pwn2Own, as you said, is to get these exploits into the hands of the people who can fix them, and that's where the money comes from, which is probably why something they already know about isn't worth very much because, well, we already know that.  We're not going to pay you for it.



STEVE:  They don't want to pay for that one, yeah.



LEO:  But I think it's really an important thing.  And it's great that people can make a living, and some of them a very good living, if you're really skilled at it, finding these exploits.  We need that.  That's one of the solutions to what you were talking about, you know, can we ever live in an exploit-free world?  Which is, as you say, highly unlikely, thank goodness.  At least get us to Episode 999.  That's all we're asking.



STEVE:  The world is going to keep screwing around with this stuff.  And, oh.



LEO:  Steve Gibson, always a pleasure.  You'll find Steve's life work, SpinRite, the world's best hard drive - actually shouldn't say hard drive, any disk, SSD, too - maintenance and recovery utility.  Really works with SSDs, which is such good news.  That's the new SpinRite 6.1, that's going to be great.  You can get SpinRite 6 right now at GRC.com.  And you'll get a free upgrade to 6.1 when it's out, plus you get to participate in the development of 6.1, which is ongoing and active.  Right?  No honeymoon; right?



STEVE:  No.  No, we didn't.  I think we actually went back to work that evening.



LEO:  Oh, my god.  I'm not surprised.  You've got to do what you love, man.  So get that SpinRite, GRC.com.  While you're there, of course, you can get a copy of this show, 16Kb.  Steve has two unique versions of it, a 16Kb version for people with not a lot of bandwidth.  He also has very nicely written, because it's written by a human being, Elaine Farris, transcripts, so you can read along as you listen.  That's all at GRC.com.  He also has a 64Kb audio version.



We have audio and video at our website, TWiT.tv/sn for Security Now!.  While you're there you'll see there's a bunch of buttons at the top of the page, including the YouTube page, so you can click there and subscribe there if you want, or find a podcast application.  Click one of those buttons, Apple Podcasts, Google Podcasts, et cetera, et cetera, podcasts, subscribe there.  Do us a favor, leave a review if you're subscribing.  Let everybody else know what a great show, a must listen, Security Now! is.



We do the show every Tuesday around about, it's roughly 1:30 Pacific, 4:30 Eastern, 20:30 UTC if you want to watch us live.  There's a live audio and video stream at TWiT.tv/live.  If you're watching live, chat live at irc.twit.tv.  There's also asynchronous communications available.  Steve has a great forum at his website, GRC.com.  Is it GRC.com/forums?



STEVE:  Yeah, forums.grc.



LEO:  Forums.  Oh, the old school.  That's the best way to do it, subdomain, forums.grc.com.  We have our own forums at www.twit.community.  We also have a Mastodon instance.  It's kind of an open source federated Twitter clone at twit.social.  More than a thousand TWiT listeners in there now, which is really great.  We love having you on both those platforms.  And if you want to follow Steve on Twitter, he's @SGgrc.  His DMs are open, so you can leave questions there or at the website, GRC.com/feedback.



Might be a little late next week.  I don't think so.  Apple's got its event at 10:00 a.m. Pacific.  MacBreak Weekly will follow immediately after.  I suspect we'll be, you know,  they're going to do an hour.  They're very disciplined now that they prerecord these.  So I think we'll not be late.  But just a word of warning.  Thank you, Steve.  Have a wonderful evening with your honey. 



STEVE:  Thank you, buddy.



LEO:  We'll see you next week on Security Now!.



STEVE:  I'll be doing exactly that.  Bye.



LEO:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#815

DATE:		April 20, 2021

TITLE:		Homogeneity Attacks

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-815.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we touch on the Vivaldi browser project's take on Google's FLoC.  We look at Chrome's vulnerability-driven update to v89, and then its feature-embellished move to Chrome 90.  We consider the surprising move by the FBI to remove web shells from U.S. Exchange Servers without their owners' knowledge or permission, and WordPress's consideration of FLoC Blocking.  We also have an interesting-looking programmer's Humble Bundle, some interesting closing-the-loop feedback from our listeners, and a brief progress report on SpinRite.  We finish by examining an important privacy guarantee provided by Google's FLoC implementation which prevents homogeneity attacks, where users presenting a common cohort ID also share a sensitive attribute.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  Version 90 of Google's Chrome is out.  He'll talk about some new features.  He'll also talk about Google's Federated Learning of Cohorts, or FLoC.  There's a heck of a drumbeat against FLoC, but is it all that bad?  Steve examines the privacy implications from a very deep level.  Always something of value from Steve Gibson on that.  And then we'll talk a little bit about the Humble Bundle for Programmers.  Steve's found some books he really likes.  And he asks a question:  What the heck is Scrum?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 815, recorded Tuesday, April 20th, 2021:  Homogeneity Attacks.



It's time for Security Now!, the show where we cover the security and privacy of you and your loved ones online with the man in charge of Security Now!, Steve "Live Long and Prosper" Gibson.  Hello, Steve.



STEVE GIBSON:  It was really interesting for me to see, you know, because that picture I shared around with Lorrie and me with our wedding rings, where we were both doing the Vulcan hand sign, I didn't know how obscure that was.



LEO:  People got it.



STEVE:  Yeah, everybody got it.



LEO:  The caption was "We plan to live long and prosper," so that might have helped.



STEVE:  Oh, yeah, that's a good point.



LEO:  All right.  What's on the agenda today, Steve?



STEVE:  We are Security Now! 815 for, what is this, the second to the last podcast of April.  Leo,  April is almost gone already. 



LEO:  I know.  Amazing.



STEVE:  I don't know what's happening.  This one, this was originally not titled "Homogeneity Attacks," until I got dug into the topic that I wanted to talk about, which is more an I think really interesting detail about the work Google has put into the privacy-preserving aspects of their FLoC proposal.  And there's something known as a "homogeneity attack" which they are preventing, which is the true story behind a lot of the misinformation that's now on the 'Net, because of course this Google FLoC proposal is very controversial, and we'll be talking about some of that this week.  Yeah, this week.  Right now.  In the next couple hours.



But we've got a lot to talk about.  We're going to touch on the Vivaldi browser project's take, as I mentioned, on FLoC.  We look at Chrome's vulnerability-driven update mid-version 89, and then its feature-embellished move to 90, that has some interesting new stuff, one that really puzzled me for a while.  But then I drilled down, and I'll explain it to our listeners.  We consider the surprising move by the FBI to removing web shells from U.S.-based Exchange servers without their owners' knowledge or permission, in what I think is pretty much a first for that kind of move.



We've also got WordPress's announced position on maybe adding FLoC-blocking to the WordPress core.  We have an interesting look at a programmer's Humble Bundle that I think there's enough there to catch our listeners' attention.  We've got some interesting closing-the-loop feedback from our listeners.  I'll have a brief progress report on SpinRite to share.  And then we're going to finish by examining this important privacy guarantee which is provided by Google's implementation of their FLoC, what they call their "FLoC API," which prevents homogeneity attacks, thus the title of the podcast, where users presenting a common cohort ID also share a sensitive attribute.



One of the critiques has been, and it's a misinformed critique, that sensitive information would be disclosed by the cohort that an individual is in.  It turns out Google really wants this to work.  And so it'll be clear, I think, by the end of the podcast, the efforts that they've gone to to preserve the privacy of the users, of anyone using FLoC who for now is going to be just Chrome.  So I think a useful podcast.  And again, I've got lots more to say, so we'll get to that in time.



LEO:  Save it.  And a Picture of the Week.



STEVE:  Yes.  Okay, so this is a three-frame cartoon, and the first two frames show Mom and Dad clearly very upset at their kids, apparently, we're sort of led to believe.  Dad is "We are so disappointed with you."  And Mom, "How could you betray our trust like this?"  And then the second frame, Dad, "You're living under my roof.  You should be following my rules."  And Mom, "We expected better of you."



And then in the third frame, finally, "How dare you sell off maps of our home to the highest bidder?"  And we see at their feet a robot vacuum cleaner that they've been talking to.  And it's got thought bubbles.  It's thinking, "Crybabies!  They're the ones who signed off on my user agreement!"



LEO:  Ah.  Roomba.  Roomba.



STEVE:  Yeah.



LEO:  Got some 'splaining to do.



STEVE:  It's nice when we have long ago covered these topics on the podcast, and then they come out into the popular media.  And it's like, oh, yeah, we talked about that.



LEO:  Well, these guys, this is JoyofTech.com.  This is Nitrozac and Snaggy.  They're the ones who did the great moustache painting of you that's on the mugs.



STEVE:  Oh.



LEO:  Yeah, yeah, yeah.  They're friends of the network.  Yeah, absolutely.  They do a lot of our...



STEVE:  Yeah, that's a really snooty-looking picture.  I've got to talk to them about that.



LEO:  We can get a new one if you want.  We need to gray the moustache a little anyway.



STEVE:  Kind of like looking down my nose, like okay.



LEO:  I know.  That's why I like it.



STEVE:  Okay.  Speaking of looking down one's nose, we have the Vivaldi Project's take on the FLoC, uh, I guess maybe you could call it a controversy.  It certainly has been picked up in the news a lot.  And predictably.  The Chromium-based privacy-oriented web browser forks are all up in arms over this proposal.  And even the DuckDuckGo search site says they'll be adding FLoC blocker headers to prevent visits to their search engine from registering in Chrome's FLoC aggregation.  So it's like, yeah, okay.  But in the case of the Vivaldi browser project, their posting last Tuesday was titled "No, Google!  Vivaldi users will not get FLoCed."  And of course again another reason why this is just the worst acronym or abbreviation.



LEO:  Oh, it just begs for that; doesn't it?



STEVE:  It does.  It's just like, you know, don't FloC me and oh, my god.



LEO:  Didn't they think about that?



STEVE:  FLoC no, or, oh.



LEO:  Yeah, gosh.



STEVE:  Yeah.  So we can all guess how Vivaldi would be feeling about this.  And I want to share the intro of their posting now.  But one of the points it makes later we need to address because it's - and this was my original title for the podcast.  Google calls this "Sensitivity of Cohorts," which is like the technical term.  But I thought homogeneity was more fun.



So here's Vivaldi.  They said:  "Old habits die hard.  Google's new data harvesting feature is nasty.  Called FLoC (The Federated Learning of Cohorts), this new advertising technology intends to replace third-party cookies and related technologies like third-party local storage.  This clearly is a dangerous step that harms user privacy.  Currently, it's being trialed in Google Chrome and is a part of the Chromium browser engine.



"Now the real question:  What is Vivaldi's position on this new technology by Google?"  And I think I must have skipped the title of theirs.  Oh, yeah.  I have it in a link above.  Oh, yeah, right.  "No, Google!  Vivaldi users will not get FLoCed."  So we can imagine what Vivaldi's position is.



They said:  "This is a valid question as we are based on Chromium.  But the truth is that while we rely on the Chromium engine to render pages correctly, this is where Vivaldi's similarities with Chrome, and other Chromium-based browsers, end."  Although I did see a heading, a headline, and I did not get a chance to pursue it.  And it just came out, I think, that apparently Microsoft has also said we may not be enabling FLoC, at least initially.



LEO:  No, they're not going to put it in Edge.  It's not in Opera, Vivaldi, or Edge.  None of the Chromium users.



STEVE:  Offshoots, right.  So they said:  "FLoC off," of course.  "Vivaldi does not support FLoC."  They said:  "At Vivaldi, we stand up for the privacy rights of our users.  We do not approve tracking and profiling in any disguise.  We certainly would not allow our products to build up local tracking profiles.  To us, the word 'privacy' means actual privacy.  We do not twist it into being the opposite.  We do not even observe how you use our products.  Our privacy policy is simple and clear:  We do not want to track you."



FLoC - and they call it a "privacy-invasive tracking technology."  They said:  "Google will continue to build profiles and track users in the absence of third-party cookies and local storage.  It presents FLoC as a part of a set of so-called 'privacy technologies,' but let's remove the pretense here.  FLoC is a privacy-invasive tracking technology."  So they said:  "Does FLoC work in Vivaldi?  The FLoC experiment does not work in Vivaldi.  It relies on some hidden settings that are not enabled in Vivaldi.  The FLoC component in Chrome needs to call Google's servers to check if it can function since Google is only enabling it in parts of the world that are not covered by Europe's GDPR. It seems there is still some discussion as to whether FLoC could even be legal under the GDPR regulations.  We will continue to follow this closely."



And, okay, now that's really not fair.  In the trial, Google does have a bunch of Google Chrome syncing stuff that is going on, which is part of the trial mechanism.  But that's really separate from FLoC.  So it's like, okay, fine.  Anyway, they finish the part that I'm going to quote at the beginning, saying:  "Although Vivaldi uses the Chromium engine, we modify the engine in many ways to keep the good parts, but make it safe for users.  We do not allow Vivaldi to make that sort of call to Google.  We will not support the FLoC API and plan to disable it, no matter how it is implemented.  It does not protect privacy, and it certainly is not beneficial to users to unwittingly give away their privacy for the financial gain of Google."



Okay.  So message received.  The Vivaldi folks are not fans of FLoC.  Just one more piece of the Internet checking in on how they feel about this.  And I don't have a sense for how committed to this Google is.  But as we'll see, because I'm going to quote them, a little bit of their background philosophy and sentiment, they really do get it that cookies are on the way out, and that traditional tracking is endangered.  And we know that we have Google, they would argue, because of the revenue generated by advertising.  And I actually do have some stats that they also quote about the amplification factor of revenue as a consequence of personalization, which is always - I've always been a little bit fuzzy about.  But anyway, we'll get to that in a minute.



Talking about browser stuff, Chrome, of course, continues to be the high-value target on the 'Net.  Last Tuesday, Google released - they initially released Chrome 89, which patched two newly discovered security vulnerabilities, both which it said exploits for existed in the wild, which allowed attackers to engage in active exploitation.  They didn't quite call them zero-days.  It wasn't clear whether they had seen them being leveraged, or whether they had seen that the exploits had been published.  But still, in any event, nothing that we want.



So one of the two flaws leverages an insufficient validation of untrusted input in Chrome's V8 JavaScript rendering engine.  This was the flaw that we actually talked about the week before, or last week's podcast.  It was demonstrated by researchers from Dataflow Security during that Pwn2Own 2021 hacking contest.  So that was immediately fixed.  The other flaw resolved with this v89 blah blah blah dot 128.  It was reported by an anonymous researcher on April 7th.  So in this case the Chromium team went from report to patch in under one week.



And I can't pass up the opportunity to give Microsoft a little jab in the side and say, "Are you hearing this, Microsoft?"  Less than a week from report to patch, and the whole Exchange Server mess would have never happened had they jumped on the early reports of it.  But since then, and actually when I went to look at Chrome last night, talking about these vulnerabilities, it started to spin and update itself.  And it moved me to 90.  So, and it's 90 point whatever.  So we have a major new version of Chrome with a bunch of interesting new stuff.



Finally, the long-awaited feature which has appeared for the first time in this v90 of Chrome, which everyone is now getting, at long last defaults to using the HTTPS protocol scheme, or implying it, when none is explicitly specified by the user.  So, for example, when just GRC.com or TWiT.tv is entered into the URL bar, that is not specifying the whole https://, Chrome will now first try to initiate a TLS connection to port 443 at that domain, rather than first trying to initiate, as it always has until now, beyond reason, except just the only explanation would be inertia, until now it's gone to port 80 with a plaintext query.  And at least in GRC's case, and in the case of many sites, anything coming into port 80 immediately gets turned around with a 302 Moved reply, telling it no, go to https://, and then the same place over on the TLS secure port for the site.



And so the good news is that Chrome's move finally with this v90 to assume HTTPS means that all sites which have been having to perform a similar redirect, bouncing their incoming port 80 queries over to 443, are now going to see a modest performance boost.  The page won't have to go to the wrong place and then get rerouted to the right place before it shows.  So, yeah, that's good for everybody.



Another change is that another port, I was going to say has been removed, but actually it's been re-removed for reason of NAT slipstreaming, and this is port 554.  Google had previously been blocking port 554, but later removed the block after receiving complaints from some enterprise users that they were having a problem because they needed - something that they were doing needed Chrome to be able to initiate connections to port 554.  However, after performing some analysis of the use of this port, they determined that it was used for only approximately, get this, 0.00003% of all requests in Chrome.



So they said, you know, given that it is subject to abuse through NAT slipstreaming, and they've got to prioritize security, that low level of incidence said to them there's got to be some other way to do whatever the enterprise users are doing over port 554.  It is now blocked with v90, and hopefully the enterprise users will have figured out this was coming.



Also v90 brings us for the first time the newer AV1 AV codec, which increases performance for use in any videoconferencing over the WebRTC protocol.  Google has indicated that AV1 basically brings more of all the good things that we want:  better compression efficiency than other types of video encoding, reduced bandwidth consumption, and improved visual quality.  They said enabling video for users on very low bandwidth networks, offering video as low as at 30 kilobits per second and lower.  So more efficient codec means yes, you can deliver better quality at a lower bit rate.  And also apparently significant screen sharing efficiency improvements compared to VP9, which had been the codec of choice until now, and other codecs.



Okay.  And here's the one that was really puzzling to me.  It's apparently rolling out in v90, but it's coming soon because it's not actually working yet for me and for others who were puzzled by this because they've announced it, they've talked about it, and actually it's existed over on the receiving side, but not on the sending side.  I'll explain what I mean.  This is a new feature which they call Link to a Highlight.  Rather than just linking to an entire web page, when you right-click on a highlighted region of a page, the contextual pop-up from some coming version of 90 will have a new item in its context menu, copy the link to the highlight.  And what that places on your clipboard is a URL with a pound sign.



And supposedly, if you share this pound sign-embellished URL with others - and this would of course be with Chrome-using others because as far as I know Chrome is the only browser to do this yet, or I should say Chromium, so all of the Chromium browsers probably will because there's no privacy downside.  Their use of that link will jump them not only to the page, but to that highlight on the page, with it highlighted.  And I actually have a sample of this in the show notes because later on, when I was putting the show notes together, I clicked on a link that came up in Chrome, in Google Search, to Wikipedia, that took me to exactly the phrase I'd been searching for on the Wikipedia page lit up in yellow.  And maybe some Chrome users had been seeing that recently, thinking, oh, look at that.



LEO:  I can't show it because I use Firefox.



STEVE:  I know you do, Leo.



LEO:  But I'll take your word for it.



STEVE:  I understand.  Okay.  So of course this is not the way that pound signs have traditionally worked.  Anyone who has coded much HTML will know that it's possible to drop explicit anchors into HTML to which the text following the pound sign in a URL can refer.  And all browsers like from the dawn of time will jump to the page and then scroll to that previously placed anchor.  For example, GRC's Security Now! pages have always contained an ID tag, which is the anchor, with the episode number in it, so that someone could jump directly to that episode description on the page.  You know, it's just sort of proper HTML etiquette to offer that.  And it's been there forever.



Well, that's now changing.  Certainly that functionality will stay there.  I did some digging, and I discovered a very new, as in a W3C working draft dated last month, which proposes a rather dramatic extension to the syntax of what can follow a hashtag in a URL.  It's supported, as I said, in Chromium and all the Chromium browsers.  And so that's everything except Firefox and Safari.  But as I said, since there's no privacy downside - although this draft proposal is really complicated, so I guess they could just like take the source from the Chromium browser and move it over into their implementation because it maybe, you know, there's no reason it wouldn't become a standard.  So for what it's worth, that will be coming in 90.



Chrome has for some time been able to scroll to and highlight a link which the Google search engine adds to the tags in order to support that.  But users were not able to easily generate their own.  Now, you'll be able to just, like if you want to send something to somebody who is a Chrome user, you can highlight a block on a page, right click, copy that special URL which adds that hashtag embellishment, and when they click on it, they'll be taken not only to that random place on the page independent of whatever ID tagging may be there, but also have that highlighted.  So, you know, just kind of a cool feature as we move through the evolution of the Internet.



In the surprising news of the week - and this was happening as we were doing last week's podcast, the news was breaking, so we didn't cover it then.  The official release, like the news release was dated last Tuesday, April 13th, titled like a press release, for immediate release, from the United States Attorney's Office for the Southern District of Texas.  And the release begins, its title is:  "Justice Department announces court-authorized effort to disrupt exploitation of Microsoft Exchange Server vulnerabilities."



And in their little brief summary they said:  "Action" - that is, the action that was taken.  They said:  "Action copied and removed web shells that provided backdoor access to servers, but additional steps may be required to patch Exchange Server software and expel hackers from victim networks."



So there's some interesting stuff here that I want to share.  They said:  "Houston," as in like where this is being sent from.  "Authorities have executed a court-authorized operation to copy and remove malicious web shells from hundreds of vulnerable computers in the United States.  They were running on-premises versions of Microsoft Exchange Server software used to provide enterprise-level email service.  Through January and February 2021, certain hacking groups exploited zero-day vulnerabilities in Microsoft Exchange Server software to access email accounts and place web shells for continued access."  And I'll just, you know, to pick a nit, I'll just note that they were not zero-day vulnerabilities because Microsoft was told about them in December.  So just said.



They said:  "Web shells are pieces of code or scripts that enable remote administration.  Other hacking groups followed suit starting in early March after the vulnerability and patch were publicized.  Many infected system owners successfully removed the web shells from thousands of computers.  Others appeared unable to do so, and hundreds of such web shells persisted unmitigated.  This operation" - meaning the one that's being disclosed in this disclosure - "removed one early hacking group's remaining web shells which could have been used to maintain and escalate persistent, unauthorized access to U.S. networks.  The FBI conducted the removal by issuing a command through the web shell to the server, which was designed to cause the server to delete only the web shell identified by its unique file path."



Okay.  So then the Assistant Attorney General John C. Demers for the Justice Department's National Security Division is quoted in this, saying:  "Today's court-authorized removal of the malicious web shells demonstrates the Department's commitment to disrupt hacking activity using all of our legal tools, not just prosecutions.  Combined with the private sector's and other government agencies' efforts to date, including the release of detection tools and patches, we are together showing the strength that public-private partnerships bring to our country's cybersecurity.  There's no doubt that more work remains to be done, but let there also be no doubt that the Department is committed to playing its integral and necessary role in such efforts."



And one last quote.  T, the Acting U.S. Attorney Jennifer B. Lowery of the Southern District of Texas was also quoted, saying:  "Combating cyber threats requires partnerships with private sector and government colleagues.  This court-authorized operation to copy and remove malicious web shells from hundreds of vulnerable computers shows our commitment to use any viable resource to fight cyber criminals.  We will continue to do so in coordination with our partners and with the court to combat the threat until it is alleviated, and we can further protect our citizens from these malicious cyber breaches."  And so, okay, I'm skipping a bit of historical background that all of us have memorized by now.  But then it finishes with an interesting conclusion.



It says:  "This operation was successful in copying and removing those web shells.  However, it did not patch any Microsoft Exchange Server zero-day vulnerabilities or search for or remove any additional malware or hacking tools that hacking groups may have placed on victim networks by exploiting the web shells.  The Department strongly encourages network defenders to review Microsoft's remediation guidance and the March 10th Joint Advisory for further guidance on detection and patching."



And, finally:  "The FBI is attempting to provide notice of the court-authorized operation to all owners or operators of the computers from which it removed the hacking group's web shells. For those victims with publicly available contact information, the FBI will send an email message from an official FBI email account (@fbi.gov) notifying the victim of the search," what  they're calling a search.



"For those victims whose contact information is not publicly available, the FBI will send an email message from the same FBI email account to providers such as a victim's ISP, who are believed to have that contact information, and ask them to provide notice to the victim.  If you believe you have a compromised computer running Microsoft Exchange Server, please contact your local FBI Field Office for assistance.  The FBI continues to conduct a thorough and methodical investigation into this cyber incident."



So, okay, wow.  This is the first such known effort to ever have been carried out under the auspices of the U.S. federal government and action on this scale of the FBI.  And it's not entirely without some controversy since the federal government technically intruded, uninvited, into the Exchange servers owned by American citizens and altered them.  I'm sure they were very careful to keep this on U.S. soil so that our FBI was not reaching out into the Exchange servers belonging to citizens of other countries.



But this is - it must be due to the case that was made to the court that authorized this about the ongoing threat leaving these backdoors in place represented.  They referred to it as a "search"; right?  So this, maybe they couched this as a search warrant, and the FBI entered the backdoor, found the web shell which they had shown the court was only there, not because the individual had deliberately put it there, but they were able to closely link it to the efforts of a hostile foreign power.



And then notice that they said they "copied and removed."  So it must also have been that they said, if we remove this in error, we will have made a copy of it and notified the individuals owning that server that we did this and that we have a copy of it in case we removed it erroneously and so that they would be able to put it back, copy it back to their server.  And then, okay, if you want this, it's yours to want it.



For example, you can imagine some security researchers.  Who knows how much vetting the FBI did of the hundreds, they said, of instances of this.  You can imagine that there may well have been some security researchers who were deliberately running these known compromised Exchange servers for the purpose of gathering data on the use of these backdoors.  We don't know.



And in the case of good security researchers, they would not be associated with IPs of their security research firms; right?  So the FBI might not have been able to figure out who they belonged to, just because they would want the bad guys to be able to figure out who they belonged to if they were running a honeypot operation.  So you can imagine that this is dicey.



And I've told the story on this podcast before of how I was involved in a multiparty conference call, many moons ago, involving officials from the DoJ, some of the politically connected people from the SANS Security Institute, and a number of other security researchers.  We'd all got together on a big conference to discuss what to do about some of these Internet worms that were really wreaking havoc back then - Code Red, Nimda, MSBlast.  They were scouring the Internet seeking new targets.  And at one point there were so many of them that their seeking other victim traffic was choking the Internet at some choke points that were creating spotty DoS for some sections of the 'Net.  So, I mean, it was really a problem.



So I remember that we posed the question to the government whether we could use those same well-known by then vulnerabilities, they weren't secrets any longer, ourselves to  go into these known-infected systems and remove the worms from them.  We believed we could do it safely and in an entirely targeted version.  And I well remember the unequivocal response from the DoJ was "Don't even think about doing that."  Really.  Period.  Not even wink-wink.  I mean, you will be breaking the law.  And of course, yes, without a search warrant court order, that would have been the case.  That would have been a cyber intrusion, even if it was people wearing hats that were scrubbed bright white.  No, you can't do it.



But in this case the actions that the FBI took were of course legal under U.S. law where our courts have the power to selectively legalize activities within clear boundaries and constraints which would otherwise be illegal.  Courts have the power to authorize disconnection, to authorize the FBI to go in and seize equipment that, again, if you convince a court that this is in the public interest to do so, courts can say, yes, you can go in and take all of their computer systems.  We've talked about instances where that's happened in the past on this podcast.  So I guess it's not surprising that in this instance the courts authorized the FBI to perform as responsible a surgical excision of those backdoors as was possible, and that happened.  So, interesting, Leo.  Wow.  And, you know, probably overall a good thing.



So again, on this FLoC controversy, from a different angle, on Sunday morning, couple days ago, a blog post titled "Proposal:  Treat FLoC like a security concern," and this was from WordPress.  WordPress suggests four lines of code to block FLoC.  They said, after quoting some of the EFF's "Google's FLoC is a terrible idea" blog post, their post begins:  "WordPress powers approximately 41% of the web; and this community can help combat racism, sexism, anti-LGBTQ+ discrimination and discrimination against those with mental illness with four lines of code."



Okay, so certainly that would be worth doing if that were the case.  The four lines of code relate to what we talked about last week.  It's the PHP code which could be added to the WordPress core, which is what they're proposing, to cause the WordPress website to add that FLoC-blocking reply header or response header to everything going out from the WordPress site to the browser.  And so this WordPress post proposes that this bit of code should be added to the so-called WordPress Core.  So this 41% of the web would be saying we don't want the fact that we went to this WordPress site to be entered into the Chrome browser's aggregation of browser use history which is used to form this FLoC ID. 



And I was trying to think, because, I mean, because I've looked at, you know, the 'Net is full of reactions to this.  So if nothing else, I'm wanting to understand what the technology is, make sure our listeners understand what it is, that we're just informed.  And then it's going to be interesting to see how this shakes out.  I have no idea.  You know, Chrome by far the majority browser on the 'Net.  Probably not within the cohort of our listeners.  I don't know.  But the facts are what matters.  I was trying to think of what the reactions that I've been seeing on the 'Net have put me in mind of.  And the first thing that occurred to me was the Apple-Google contact tracing proposal, back when COVID was a new term for us.



And as we'll recall, none of the popular press or even the tech press took the time to understand how the system was designed.  We did hear, and it was clear, if nothing else, that it was well-designed with privacy protection as one of its central tenets.  But the media just latched onto some of the scary words uttered by others who hadn't bothered to understand the system.  And yes, it was complicated.  It was not simple to understand, but it was understandable.  And as I've educated myself more about FLoC, I'm seeing that the same is true of it, and we'll get to that in a minute.



But I'll share something that just happened to me yesterday.  I had a conversation with someone who had so far chosen not to get vaccinated against COVID-19 because he explained to me that the mRNA vaccines contained pig DNA, and that he didn't want pig DNA mixed in with his human DNA.  Okay.  This person's been a friend for about 40 years, so I didn't want to be rude, and I was caught a bit off guard.  I was pretty sure that there was no pig DNA or any other DNA in those vaccines.



So I explained the mechanism by which a deliberately engineered fragment of mRNA is injected, and how it briefly commandeers our own cellular genetics to cause our bodies to synthesize the characteristic COVID-19 spike protein, which our immune systems then see and recognize as a foreign invader and consequently build antibody defenses for any future reappearances or appearances, actually, of the actual spike protein which embellishes the actual COVID-19 virus.  And I also explained that the injected mRNA fragments, which are not DNA, are rather quickly degraded and taken apart.  They're disassembled by the natural actions of the enzymes that operate our metabolism.



Well, he didn't seem convinced.  Until I explained where that weird rumor must have originated.  Because one of the components of the vaccine is polyethylene glycol, which for convenience is often abbreviated PEG.  So, yeah, the vaccines do contain a small amount of PEG, but no PIG.  And when I actually gave him that piece of information, he's like, oh, and he realized where this mistake had come from.  He had some information now, and he seemed much more open to the idea.



So we're always going to look at the technology, which is what I want to do here again.  At this moment, always subject to change if more is learned, it's clear that FLoC is different from tracking.  The mechanism, for one thing, is all on the browser side, as opposed to being spread and distributed all across the Internet.  And I would argue that in many ways it is vastly more privacy protecting than the cookies and the fingerprinting that we have today.  Assuming that we can - and again, subject to any additional information that we receive, which is how we form our opinions.  But assuming that we can truly kill all long-term, all other long-term tracking, to me it seems like an improvement.



Today, using the existing true tracking technologies, not only exactly who you are by web browser, that is, which web browser, and exactly everywhere you go, including how long you stay and what you do while you're there, is all being explicitly tracked and logged, you know, like not just where you went, but all the pages there that you visited.  And the trackers are able to infer how long you remained by how long until another beacon from your browser pings somewhere else.



So by comparison, Google's proposal deliberately and significantly fuzzes up only a little bit of that information by reducing that explicit identification and explicit website visiting.  And activities, like while you're there, disappear entirely.  All of that is reduced to a short hash token that indicates nothing exact about who you are, where you've been, or how long you stayed, and what you were up to while you were there.  I mean, it's a real improvement in privacy.  But that said, it is a profile tag.  No argument there.



And I understand that people don't want to be profiled.  I don't want to be.  But we keep being told that profiling is the price we pay for an otherwise free Internet.  We're told that it supports the commercialization of the Internet and the content that we all take for granted.  I've always been skeptical of that, but I have no way of gauging it.  Perhaps it's just that it's something like those who already have enough still want more.  We know that back in the '50s soap commercials were run during those daytime dramas because housewives in the '50s were watching those, and so products of interest to them were what was shown.  Thus soap operas.



So it would be nice if this tracking, this profiling were to end.  To me that's sort of a separate issue.  It hasn't ended yet.  And I have, as I said earlier, I've no sense for how committed Google is to this.  Only time will tell.  But for me, it's an intriguing technology.  And mostly I just want us to understand what it is so, if nothing else, we have a true way of gauging it rather than saying, period, all profiling is bad, no thank you.  If we are to believe what the research is said to show, adding profiling doubles the revenue that websites with ads receive.  And so that's a big gain.



And for what it's worth, and we'll have a better sense for this as soon as you understand what I have learned about the efforts that Google has gone into protecting our privacy, which is how we're going to finish this podcast, I'd much rather have that, if all traditional tracking can really be killed, if we can kill cookie tracking and fingerprinting and local storage tracking.  And the browsers know how we're being tracked.  Certainly Google knows.



So anyway, I just - I'm looking at the reaction that is occurring and thinking, you know, folks, okay.  We saw this back when we were talking about a very well-designed "who you had been in proximity to" system that Apple and Google together designed.  I wish they hadn't called it a FLoC ID.  I would argue no one likes being ID'd, especially when that's not what it is.  A better name would have been a FLoC CIC, meaning Common Interests Cohort.  But that's not what we got from Google.  So anyway, we will wrap up by talking about one of the interesting things that they have done to further protect privacy.  But I want to share a few other things first.



It is Humble Bundle book time.  And I should mention that our listeners must be keeping track of the HumbleBundle.com site because I get references from them to this or that bundle from time to time.  Most of them seem maybe of interest, but they don't grab me.  We're talking about one this time because it did.  This is O'Reilly's Head First series of predominantly programming eBooks that looks pretty much worthwhile.  So if you were to buy all these, you would be laying out $772 worth of O'Reilly's books.  They are all DRM-free, and they're available in multiple formats.  So as we know, it's a tiered system; right?  So just $1, pay $1 and you get Head First Ruby, Head  First C, Head First PMP.  I thought, what, is that a language I haven't heard of?  No.  That's project management.  And also Head First SQL and Head First Statistics.  So Ruby, C, and SQL.



And these Head First books are visual, heavy diagrammatic, sort of they're easy to wrap yourself around.  So a dollar.  If you go to $10, you get those and Head First JavaScript Programming, Head First Learn to Code, Head First HTML & CSS, Head First C#, and Head First Agile.  And then again I thought, okay, Agile?  Is that a programming language I've never heard of?  No.  I read the description, and I still have no idea what it is.



They said:  "In Head First Agile, you'll learn all about the ideas behind Agile and the straightforward practices that drive it.  You'll take deep dives into Scrum, XP, Lean, and Kanban, the most common real-world Agile approaches today."  This makes me feel old, Leo.  "You'll learn how to use Agile to help your teams plan better, work better, write better code, and improve as a team because Agile not only leads to great results, but Agile teams say they also have a much better time at work."  Okay.  That all sounds good.  "Head First Agile will help you get Agile into your brain" - not into mine - "and onto your team."  So anyway, like I said, I still have no idea what it is, but at least for $10 you get all the other ones and JavaScript, Learn to Code, HTML/CSS, and C#, which are all cool.



And wait.  There's one more tier.  Should you choose to shoot the moon for $18, in addition to all of those, and apparently dramatically improving your agility, whatever that is, you'll also receive Head First Go, of course Go is a cool language; Head First Java, the most popular language; Head First Python; Head First Kotlin; which actually is a language that's like a derivative of Java and actually runs on the Java VM; and also Head First Android Development.  All for 18 bucks.  So anyway, for coders who might want to stretch themselves out a bit, or for curious non-coders.  I get a lot of people who say, like, hey, how do I start programming?  I want to code.  How do I start?  $18, you know, you'll have all these eBooks to kick around and look at.  And these are O'Reilly texts.



So anyway, if you just go to HumbleBundle (H-U-M-B-L-E-B-U-N-D-L-E) dotcom.  And then you'll scroll down a bit, you'll find the Head First Programming by O'Reilly item.  And that's your entry into all of this.  So this one I really felt was worth sharing with our listeners.



Three interesting bits of closing-the-loop feedback.  I love this one.  @dpmanthei tweeted:  "Could setting TTL" - that's the field in IP packets which, TTL, Time To Live, and we talked about this back in the How the Internet Works series ages ago.  It's a packet which every router, I mean, every router, this is one thing, nobody skimped on this one.  Every router decrements the value in that field.  It's an 8-bit value.  It decrements it by one as it accepts a packet and is getting ready to forward it.  If in decrementing it to one, the value goes to zero, the router won't forward it.  It just says no.  And well-behaved routers will send back an ICMP packet saying "Expired," meaning that the time to live, this packet's life on the Internet expired right here at that router.



So that functionality has enabled some cool things; right?  Like that's how trace route works.  The way you can figure out the route your packets take on the Internet is by deliberately setting them to expire early and having the routers where they expire send back the equivalent of a ping, but it's a different type of ICMP packet, saying hey, this packet you sent me died here.  And then you decrement the TTL one further so it expires on the previous router hop, and that one sends back an ICMP.  And then you decrement it again and so forth, all the way back down to one, so you're able to map the route the packets take.  So really cool from an engineering standpoint.



Anyway, he says:  "Could setting TTL to some low number help, but not solve, some security issues with web interfaces?"  He says:  "Force admins to be within X hops to login to the web interface?"  He says:  "Not a solution, but could reduce attack surface."  And Leo, this is something you and I talked about, again, so long ago.  And, yes, it would be a great solution.  I've long thought that, again, it's one of those don't let good be the enemy of perfect.  It's like, yes, it's not a perfect solution; but, boy, would it be great.  If you knew that you were not ever more than a few hops away, like if you were going to try to access your system through the same ISP as many people do, or that you were no more than four or five hops away, if you were to turn down the TTL on the packets that were leaving your system, your protected system, on a specific port, where you don't want to allow access from a greater distance, it's as good as blocking the port from all but a known IP.



In this case it's blocking the port, think of it as within a known radius, like a known Internet radius of that server.  So that nobody further away is able to get to it.  So it's, again, not a perfect solution.  But I just thought, yeah, that's nice to see somebody else having the same sort of thought because it is another tool that could be deployed.



Someone tweeting, well, he has the name duckDecoy, but he's andrewCoyleNZ, so maybe New Zealand.  He said:  "I'd be interested to hear your thoughts on how to make a 'vaccination passport' that could not be faked.  Any ideas?"  Of course this has been in the news because of this idea that maybe at some point, I mean, there's lots of people who are up in arms at the idea that you would have to prove vaccination before doing something, traveling in an area where you would be exposing people to yourself, who knows what.  But independent of that, again, don't care about the politics, let's talk about the technology.



Yes, thanks to crypto today and the concept of signatures, it would be absolutely possible to create, for example, a QR Code which contains the identity of an individual, their legal identity through some means, you know, name, birthday, whatever they want, whatever you want to use to anchor the person's real-world identity.  And again, that could be whatever it should be.  And that information is signed by an authority.  And so in the same way that server certificates are signed by a Certificate Authority, and we trust the Certificate Authority, and we're able to verify their signature with their public key, it would be entirely possible to create a system of signed QR Codes or other form of signed digital information, like there are other types of barcodes which are not square, where the digital information contains a signature which cannot be faked.  I mean, we know certificates can't be faked.  There is no feasible means to fake a cryptographic signature.



So all of the technology exists.  If we have vaccination passports, if that comes to pass, I hope they do it right.  And it's hard to imagine that they wouldn't at this point because it's so easy to create a digitally verifiable spoof-proof passport or assertion of any kind.  We are now able to assert things.  That's what SQRL was; right?  It was a signed assertion of a domain name that made that whole system work.  So these problems are solved.



Oh, and lastly StarKiss tweeted @SGgrc, he says:  "I know QNAP deserved the beating you gave them last episode; but looking at system defaults, DLNA is turned off by default, so most systems won't be vulnerable.  Same with the Plex bug a month ago.  It's not even installed by default, let alone set for external access."  So I appreciated the feedback.  I should have put that in errata.  Not necessarily that it was wrong, but it's worth mentioning, as we know, the tyranny of the defaults.



And a quick progress report.  Actually that's what I titled my posting yesterday, yesterday morning, to GRC's SpinRite development newsgroup.  And so I'll just share the first portion of it, which will be of interest to our listeners.  I wrote:  "Work is proceeding quite nicely.  I'm finally feeling as though I'm completely back in the groove with SpinRite's old code and its segmented, 16-bit coding environment."  I said:  "It's taken a while to make the switch cognitively since I code so much by habit, and my habits were all wrong after coding, since 2004, exclusively for the 32-bit unsegmented flat model."



I said:  "After a very good weekend, I have all of the drive discovery and enumeration, listing, selection, feature browsing, and display working.  I need to determine what I did to break the starting and ending percentage editing, since I've updated its display to show massive sector counts.  But something I did back in the beginning broke its UI.  This is not surprising since I ripped out tons of code that was no longer relevant, and I needed to make room within the 16-bit fixed size code segment for all the new code I was adding.  The changeover to an entirely new drive database also impacted everything.



"So a lot of time has gone into finding and fixing everything that became broken.  Once I have the starting and ending percentage screen working, I plan to neuter item #3 from the Main Menu, which is the 'Perform Drive Benchmarks' item.  Then I'll release what I have for testing by everyone here," meaning in the GRC newsgroup.  "And then, finally, while that testing is underway, I'll work to bring the benchmarking back online."  I said:  "That's a perfect read-only solution for the next step, since it means that I need to have all of the various ways SpinRite can now access drives - six now, six at last count - different ways for SpinRite to talk to drives working in order to perform that benchmarking.  Then, we'll test that, which will be a significant milestone toward completion."



So anyway, I have to say I finally felt like I was back in the groove, really making very good progress.  The coding is comfortable again.  I've got this, you know, like I've unlearned the joy of having just a single 32-bit flat coding environment, and so I've got the 16-bit segment coding.  That's now my default.  I'll have to unlearn that again, thankfully, when I move SpinRite over to a 32-bit platform.  But that will be joyful in and of itself.



LEO:  Yeah, I bet.  



STEVE:  Yeah.



LEO:  Let's talk about homogeneity.



STEVE:  Okay.  So again, given the reactions we're seeing to Google's FLoC proposal, I wanted to introduce, again, just like for just the facts, I wanted to introduce their deliberate awareness of its potential for divulging sensitive personal information.  Which is one of the ways that it's being attacked.  And this, too, is something that really got their attention.  So I thought I'd start out by citing a part of, and this is, again, typical of what I'm seeing on the 'Net, part of the not-fully-grounded-in-facts rant from the Vivaldi Project, since it, as I said, it does reflect some widely voiced industry concerns.



So later in that FLoC Off! posting they said:  "FLoC intends to do all of the profiling work within the browser.  The browser sees everything you browse, so it gathers the data about your browsing habits and determines your preferences.  This is not like a browser maintaining your browsing history for you.  It is analyzing your personal behavior for Google.  It decides which aspects of your browsing behavior are important.  And if enough other people share that behavior, it assigns you the same ID as all of them."



They said:  "Advertising companies no longer get to see a unique identifier so they cannot see exactly what you browsed  unless they also happen to be the same company that makes the browser you are using  so they cannot see you specifically."  And even Vivaldi said:  "It does sound great."  Then they said:  "But they can see that every person who buys certain medical products seems to be in the group (FLoC) 1324, or 98744, or 19287."  And they said:  "Now things start getting ugly."  And I'll just mention, I'll thank them for this example because they are completely wrong. 



Then they said:  "So if you have one of those FLoC IDs, they can display ads for that product, even if that particular medical condition is something you'd rather keep to yourself."  They said:  "It's all anonymized.  Sounds like it should be all right, but that is far from the truth.  They can still work out that you have that certain medical issue."  Again, no they can't.  But again, misinformation.  They said:  "That you seem to be in a certain age group."  No.  "That you seem to have certain character traits because you share the same ID as other people who have those traits."  Okay, true.



"Statistical analysis of those IDs is harder for small ad companies.  They don't get quite so much data to work with.  They don't see every website where that FLoC ID appears."  That's not quite the way it works, but okay.  "The company that gets to know the most about that ID is the one that controls the largest amount of the advertising space:  Google."  Okay.  Some good points, but mostly some anxiety.  Right?  And it's misplaced.



Their research paper, I've got a link in the show notes because, boy, the math and the charts and things, I'm not going to - I can't do that.  I can't share that here.  But I'm going to share the essence of what they've done, and the math is there to back it up.  The research paper is titled "Measuring Sensitivity of Cohorts Generated by the FLoC API."  And the abstract of the paper is two sentences:  "We present a discussion of the protections beyond k-anonymity" - I'll explain that in a second - "that the Chrome implementation of the FLoC IC will provide users.  These protections mitigate the risk that a cohort number generated by this API in Chrome leaks sensitive information about the browsing behavior of a user."  In other words, they understood that anxiety long before it had been voiced, and they addressed it.



Okay.  So at first blush that seems to run counter to FLoC's entire goal; right?  I mean, profiling is the point.  But it turns out that Google really wants this to work.  They make this very clear, and that they've given this considerable consideration.  Okay.  So I should mention something about this "k-anonymity" term.  It's an industry-wide, understood within some community term.



Here's what Wikipedia said:  "K-anonymity is a property possessed by certain anonymized data."  Oh, and by the way, "k" is the number of people in the group.  So the concept of k-anonymity was first introduced in a paper published in 1998 as an attempt to solve the problem, and here's the problem:  "Given person-specific, field-structured data, produce a release of that data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful."  So it's a formalized anonymity guarantee system.



They said:  "A release of data is said to have the k-anonymity property if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appear in the release."  Meaning cannot be distinguished from all of their others, where k is the individual count.  And then they explain, and I thought this was interesting, and a number of terms our podcast listeners will ping on:  "K-anonymity received widespread media coverage in 2018 when British computer scientist Junade Ali used the property alongside cryptographic hashing to create a communication protocol to anonymously verify if a password was leaked without disclosing the searched password.  This protocol was implemented as a public API in Troy Hunt's Have I Been Pwned? service and is consumed by multiple services including password managers and browser extensions.  This approach was later replicated by Google's Password Checkup feature."



In other words, it's the underlying technology that allows you to provide your password and know if it's represented in a group without it ever being disclosed.  So cool stuff.  Essentially it's a form of statistically provable fuzzing of information to obscure explicit identification.



Okay, so here's how Google places and frames this entire effort.  They said:  "Today, many publishers are able to leverage interest-based advertising as a source of funding.  This revenue stream" - and remember this is coming from Google, and yes, they get all their revenues from advertising; right?  "This revenue stream allows them to offer content free of charge to their users.  Contrary to contextual ads, interest-based ads leverage information about a user's interests to decide what ads to show them.  Interest-based advertising enables an overall better ad experience for users because the user is presented with more relevant ads than traditional run of network ads; for advertisers, who can better reach their target audience; and for publishers, who are allowed to earn more money, on average, per interest-based ad than a non-relevant ad.  In fact, multiple studies from academia and industry have consistently demonstrated that personalized advertising can account for 50 to 65% of a publisher's revenue."



Okay.  So Google is saying, take it for what it's worth, yes, we clearly realize that no one likes receiving personalized ads, since that means that the advertiser knows something about you in order to deliver something personalized.  But independent studies continue to show that advertising that can arrange to be personalized by one means or another really is far more effective for advertisers, and that means generating at least or more than double the revenue for those sites hosting ads.



Okay.  So in this paper, introducing, before we get into all the math that we're not going to get into, but to explain their intent here, they said:  "In order to accurately serve interest-based ads, ad tech companies use third-party cookies to generate user interest profiles.  Thus, the planned deprecation of third-party cookies in Chrome puts interest-based ads, and the revenue publishers depend upon, at risk.  To ensure publishers continue to have options to fund their services, Chrome has proposed the FLoC API as a way to enable interest-based advertising in a private way.  At a very high level, the FLoC API assigns users to a cohort in such a way that users in the same cohort have similar interests.  An ad tech company can then use the API to advertise to an entire cohort."



They said:  "It has been shown that the FLoC API allows ad tech companies to enable interest-based advertising without generating fine-grained browsing profiles of users."  Okay.  And just to stop for a second and remember that fine-grained browsing is what the tracking companies are collecting today.  FLoC is only an improvement if we're also able to shut down all other forms of tracking, I mean, like truly kill it.



Okay.  So they continue:  "The FLoC API achieves this by generating k-anonymous cohorts.  That is, the API returns a cohort number shared by at least k users.  This ID can be used as an anonymous replacement of a third-party cookie, allowing ad tech companies to build cohort interest profiles without knowing the identity of a user."



They said:  "While k-anonymity, especially for large values of k" - right, meaning a huge number of very different people sharing common interests, but who all have the same cohort ID - "especially for large values of k, protects users from re-identification, it is well known in the privacy community that this privacy notion can be vulnerable to so-called homogeneity attacks."  Thus the title of today's podcast.  "In the context of the FLoC API, a homogeneity attack corresponds to a scenario where all users that share a cohort number also share a sensitive attribute."  And that being the key, "sensitive attribute."  And of course in the example that Vivaldi gave, that being some medical condition.



Oh, and Google says:  "For instance, a cohort that consists only of users who visited a website about a rare medical condition.  By revealing the cohort of a user, the FLoC API may inadvertently also reveal that a user has investigated that rare medical condition.  At a very high level," Google says, "we want to make sure that no company, including Google, can correlate a particular cohort with any sensitive attribute."  Okay.  Again, "At a very high level, we want to make sure that no company, including Google, can correlate a particular cohort with any sensitive attribute."



They said:  "The purpose of this paper is to discuss the privacy protections that are needed in order to prevent this type of privacy leakage and what Chrome is doing to prevent homogeneity attacks from happening in the initial FLoC API origin trial.  As the implementation of the FLoC API is the responsibility of each browser or software that supports the API, the description of the protections here describe only the implementation by Chrome and not necessarily characteristics that are intrinsic to the API itself."  Meaning the API does what it does.  It's an implementation issue.  But if other browsers were interested in doing the same thing, Chromium is open source.  So take it. 



Anyway, they said:  "The sensitive cohort detection described below considers the risk that certain cohorts might imply an elevated likelihood of sensitive browsing behavior.  There is a separate threat, not considered in this analysis, of an attacker attempting to guess browsing history based on the details of how cohorts are created.  That risk should be mitigated by other measures designed to ensure that the map from browsing history to cohorts is sufficiently lossy, even when conditioned on other information" - this is where the SimHash comes in; right? - "a site might have about one of its visitors.  Such measures warrant further investigation, but are out of scope for this document."  Meaning that's not what this effort is talking about.



And before I proceed I want to add one more variable, which, to remind people, which is the short, one-week lifetime of the browsing history that informs this FLoC ID in the first place.  We've talked a lot in the past on the podcast about the privacy implications of the potentially infinite age of personal information that's being captured about us.  Like even mass databases from a decade ago which are then breached on a website.  Well, if the information had never been allowed to age, if it expired, then there would be a far reduced privacy compromise potential.



So of course one of the egregious aspects of the current tracking and profiling paradigm that we've all been under is that we have no control over the length of time that our profiles endure.  But FLoC sets this limit to a hard seven days.  When we're being tracked, actual tracking, where we go is potentially never forgotten.  But with FLoC, all profile aggregation of any previous activity disappears after one week.  Period.  Which to me is a huge difference between the two.  No comparison.  And I don't know whether, for example, it's a rolling seven days where Google removes the oldest day and adds the newest day, and so your ID is actually changing every day, representing the previous week, or if it changes all at once for the previous week.  I haven't got into it.  But we do know nothing lasts more than a week.



Okay.  So they then describe what they mean by "sensitive."  And that's an important thing to understand because they are treating some sites different than others, specifically to protect people from these homogeneity attacks.  They said:  "Before describing the protections Chrome will put in place, we need to define what sensitive categories are.  We will use the same sensitive interest categories defined by Google for its interest-based personalized advertising product."



LEO:  So there's no cost to Google for this because they already block these kinds of ads.



STEVE:  Exactly.



LEO:  So, nice.



STEVE:  Exactly.  They said:  "This list of categories was chosen because Google already forbids showing ads related to them, as well as targeting a user based on them.  Examples of categories in this list are adult and medical websites, as well as sites with political or religious content.  We will use these categories to decide whether or not a web page is sensitive."



LEO:  These categories are determined by Google and no one else, although some of them are in response to regulatory and legal restrictions.



STEVE:  Right.



LEO:  But there's no - it's not like I can say, oh, I don't want you to follow me based on my interest in assembly language.  That's not on the list, yeah.



STEVE:  Correct.  Correct.  And what we do have from the proposal is the ability of websites not to have people's visits there be tracked.  And so, for example, political, religious, adult, other websites as part of this do have the ability to say "Exclude any visitor tracking here."  So that's, you know, very cool.  And so sites could say, like somewhere in the fine print, profiling of you during your visit here does not participate.  Which of course is not something that we have today.  So it's coming from both sides.



So anyway, they said:  "While this list of categories certainly does not capture all the nuances of sensitive content (for instance, websites that are not sensitive but a malicious actor might use, perhaps in combination with other data, as a proxy to infer sensitive attributes), we believe it provides us with a solid foundation that we can build upon."  And again, important that they're thinking about this.



They said:  "Moreover, the methodology presented here can be applied to any other ontology of sensitive categories, as well."  They said:  "Now that we have established what content is sensitive, we define how we decide whether a cohort leaks sensitive information or not."  So they explain:  "At a very high level, we want to ensure that no cohort" - meaning ID tag assignment - "consists of users that have visited web pages related to any particular sensitive category at a much higher rate than the general population."  In other words, there's nothing about any given cohort that makes them stand out.



So they said:  "More formally, we ensure" - and we have another term coming up - "we ensure that a cohort assignment satisfies the strong privacy notion of t-closeness."  They said:  "A cohort assignment is said to satisfy the property of t-closeness if it is k-anonymous; and, for every sensitive category, the distribution of users who visited a web page related to that category has distance at most t from the general distribution.  Intuitively, t-closeness ensures that an adversary that observes a cohort number cannot infer much more about the sensitive browsing behavior of a user than they could before knowing their cohort."



So in other words, this is a formalized and statistically rigorous definition and enforcement of fuzziness with regard to those sites that are deemed to be sensitive.  They said:  "An adversary who observes a cohort number cannot infer much more about the sensitive browsing behavior of a user than they could before knowing their cohort."



So one criticism that immediately occurred to me would be that not everyone's sensitivities are the same.  I might not care much about having my religious affiliation known, whereas I really don't want it known that I spend an inordinate amount of time cruising monster truck websites.



LEO:  That's actually not in the categories.  So if you start seeing ads for monster truck rallies, you'll know why.



STEVE:  That's right.  I know that I've been - I am in a cohort where, you know, well, maybe I'm in good company.



LEO:  Well, but that also points out that one of the problems with this is, if I know anything about you, I might know a lot about you.  For instance, I'm suspecting, if you go to monster truck rallies, I know a few other things about even some of these categories they say we won't sell ads against.



STEVE:  Huh?  No, I mean, Leo...



LEO:  The real argument is that it's just more data about you that can be used in a fingerprinting attack.  Because really that's what people are doing is fingerprinting you more than anything else.



STEVE:  Right.



LEO:  It's good that it changes every week.  So it's probably not that useful, yeah.



STEVE:  It's good it changes every week.  And one wonders if - and Google is saying that to their satisfaction they've demonstrated this provides enough profiling to satisfy advertisers.  So you have to imagine that, if Google really believed that, they really could thwart fingerprinting.  That is, they're saying third-party cookies are going away.  We talked about that CNAME horror which allows cookies to be subdomains with the websites in collusion as a way of avoiding the third-party cookie stovepiping problem, which is what even Firefox has begun to do.



So certainly, if it's additional profiling, then that's a lose-lose.  If it's truly instead of, if they can robustly prevent cookie tracking, and where cookies again only become useful for state management with the first-party site you're visiting, which is how they were designed and originally intended, and if fingerprinting is fixed, if that problem really is fixed, then we've talked before, Leo, about like the ethics of blocking ads; right?  Like if we were to block all ads, we really would be hurting the revenue of the sites we visit.



Well, imagine then if users were given the option of blocking profile-driven ad targeting where the profiling is no longer being tracked and having an endless history of everywhere you go being collected behind your back with no control, to the things you have done in the last week, grouping all of the people who did similar things into a group, and that being presented, and it doubling the revenue, therefore, of the sites that you visit.  So ultimately it seems that we're moving haltingly toward people having more control, which is good.  Do we want to cut the revenue of sites that depend on advertising in half?



LEO:  Yeah, no, that's the problem, absolutely, yeah.  And that's one of the reasons we have Club TWiT, because we can't compete at that level.  I'm not going to track people to that degree.  I just won't do it.



STEVE:  Right.



LEO:  I don't care what advertisers want.  And unfortunately that means a large number of our advertisers have gone elsewhere because they want that tracking information.  It's sad.  You know?  It's worse for blogs.  It's probably not as bad for podcasts, but it's worst for blogs.



STEVE:  It's going to be really interesting to see how this goes.  And, you know, this thing may just never get off the ground because nobody ever takes the time to get underneath the scary stories about, oh, you're going to be tracked if you ever go somewhere and are identified as somebody with a certain medical condition, when in fact that absolutely has never been true about this.



LEO:  Yeah, yeah.  There's also, I mean, I think - I don't know.  I don't want to say Google's disingenuous.  I think they're probably sincere in what they're trying to do.  But, I mean, okay, so I'm looking at the categories.  And it's good.  It's the obvious categories.  We don't want to track you based on your financial worries or your psychological troubles or your sexual history, or there's no birth control, things like that.  But at the same time, it wouldn't take much to figure out, if I go to a site for nose hair clippers, and then I go to a site for diapers, and then I go to a site for, oh, I don't know what, assisted living facilities, those are all legal.  And I think you could make an assumption about people who are in that cohort, that we're probably all a little gray.



STEVE:  Okay, except there aren't that many bits available to represent cohorts.



LEO:  Right, right, right.  They're big, yeah.



STEVE:  They're really big.  And so they really, I mean, probably the monster truck website example is kind of right inasmuch as I like big hats with big wide brims and...



LEO:  Or to sell you belt buckles because we know you like them.



STEVE:  You know I've got these boots that come up nearly to my knees, and they've got, you know, I like spurs and, you know.  Probably it's like a stereotype identifier more than anything else.



LEO: The problem Google has is they don't want to make it too effective because they want to still sell ads.  So if they make it too effective, it's useless to advertisers, and might as well just not track at all.  So they're trying to make something, let's not forget, that is useful to advertisers for tracking.  For selling.



STEVE:  So imagine that you had, what, 65,000 categories.



LEO:  Is it 16-bit?



STEVE:  Yes.  I saw one ID, but it wasn't a real one.  By the way, remember I asked last week, I asked our listeners to go check that amifloced.org that the EFF put up.  Not a single - I didn't get a single reply from anyone saying, yeah.  Because I was interested in how long the ID is.  I saw one that was very scary.  It was like 20 digits or something.  It's like, woo, whoa, wait, wait, wait, wait, wait.  Because, again, I feel very differently about this if there are few people in many cohorts.  That's a whole different pie than if...



LEO:  I don't think it's settled, to be honest.  I think that this is an early testing.  And I don't think it's settled how big the cohorts will be.  They have not specified it; right?  



STEVE:  It certainly does matter.  But, okay.  So the example I was going to draw was imagine that you were to design 65,000 characteristic sets.  And, I mean, that's a lot; right?  There's, like, age, economics, young yuppies buying things for  the kids, I mean, if you had 65,000 categories, and each one of those categories could have any number of properties.  So my point is you could describe a person really well as one of those 65,000, yet still have a huge number of people that fit that description better than any of the other 64,999 categories.  And still, I mean, so yeah, you're learning something about that person.  You definitely are; you know?



LEO:  You have to, or it's useless.



STEVE:  Right.



LEO:  I mean, that's just - we know it.  Whatever Google ends up with, it's going to have to balance the interests of advertisers with our needs for privacy.  And given that Google's business is selling ads, I can think who's going to win that one.



STEVE:  Well, and adoption, too; right?  I mean...



LEO:  Well, that's the big problem right now.  It's already...



STEVE:  Even Edge is saying no.



LEO:  It's already kind of a nonstarter out of the gate.



STEVE:  Yeah.  Unfortunately, I'm reminded of DNT.  I thought that was a great idea, too.



LEO:  Yup, yup, yup.  I think just the fundamental problem is advertisers want to know more.  It's become pretty clear that users, not everybody, but a lot of users of the Internet don't want to be tracked.  And those are fundamentally inconsistent.



STEVE:  Right.



LEO:  And if your business is selling ads, you're going to have to figure out a way to fix that.



STEVE:  So advertisers want to know more.  Because of lax technology, they have been allowed to know more.



LEO:  It's way out of control now, yeah.



STEVE:  Yes, exactly.  So it just kind of - it went wild, and nobody is saying no.



LEO:  Right, yeah.  And I think Google is, as I said, it's hard to tell, but I think they're sincere in trying to solve this.  It's just it's a hard thing to solve, and it's also hard for me to forget that Google's entire revenue comes from selling ads.



STEVE:  Yes.



LEO:  I mean, that's the fundamental bottom line.



STEVE:  Yeah.  On the other hand, how many people use Gmail?  How many people would, like, want to give up Gmail?



LEO:  Right.  Well, I did.



STEVE:  We are, from them, from Google, we're getting a bunch of amazing...



LEO:  Oh, yeah.  And we have to pay for that somehow.



STEVE:  Yeah.



LEO:  And basically the way you pay is giving them information about you so they can advertise.  Maybe advertisers at some point will just give up and say, look, we don't care, we're just - like in the old days.  We're going to buy "I Love Lucy," and whoever watches that's going to see our ad, and we hope that some of them will buy our product.  



STEVE:  And Leo, the advertisers who sponsor the podcasts on TWiT...



LEO:  They know what they're getting.



STEVE:  They're looking at the demographic; right?



LEO:  It's no accident.  You'll hear our advertisers.  They're aimed at tech enthusiasts, yeah.  You don't hear a lot of jewelry and flower ads on here.  Actually, we've had jewelry and flower advertisers, and they've done pretty well.



STEVE:  And some really good bedding, too. 



LEO:  Bedding?  Oh, yes, bedding, yes.  Well, everybody sleeps.  That's an easy one; right?  I'm so glad, you know, this is why we love and trust you, Steve, because you're willing to really look at it with an open mind, and talk about the technology, and explain it.  And that's what we need.  Because almost everything else is hot takes.  I don't like Google.  I want privacy.  Or advertisers got to advertise, or sites got to make money.  So it's nice to hear the actual nitty-gritty details.  Thank you.



STEVE:  Well, exactly.  And you can make up your mind after you know the facts.



LEO:  Right.  You need the facts first.



STEVE:  But you're really not making a decision if it's just, oh, no, that's just more tracking.  It's like, well, okay, it's different.  Let's look at it, and then at least we'll know.  



LEO:  It's a real attempt, and I think a legitimate attempt, based in statistics, to track in a less intrusive manner.



STEVE:  Yeah.



LEO:  Steve Gibson.  He's at GRC.com.  That's his website, the Gibson Research Corporation.  There you will find many things, almost all of them free, including the 16Kb versions of this show in audio, the handwritten human transcription so you can read along as you listen.  He also has a 64Kb audio.  There is one thing you pay for there, though, and that is his bread and butter, SpinRite, the world's best hard drive, any drive, what do we call it, storage maintenance, and recovery utility, I guess; right?



STEVE:  Yeah, mass storage, yeah.



LEO:  Mass storage.  Because it works just as well on SSDs.  Well, it will.  I mean, 6.0 works, but 6.1's really going to work, and he's in the process of developing that.  If you buy now, you'll get 6.1 free, and you'll get to participate in the development.  GRC.com.  You should also check out all the other things he does, including ShieldsUP!  It's just a wonderful little place to browse around.  Plan to spend the afternoon:  GRC.com.  He's on Twitter, @SGgrc, if you want to slide into his DMs because they're open there.  You can also message him at GRC.com/feedback.  And as you can hear, Steve often includes that in the show later.



We have 64Kb audio versions, a little higher quality, and we also have video at our website, TWiT.tv, in this case TWiT.tv/sn.  You can download any of the, what is it, 815 shows.



STEVE:  814, yeah, 15.



LEO:  They're all, well, 15 will be there any minute now.  They're all there.  You can also subscribe in your favorite podcast client, and that way you'll get it automatically.  Steve, we'll see you, let's see, we do the show Tuesdays at 1:30 Pacific, 4:30 Eastern.  We'll see you about 2:00 in the afternoon next week.  Bye-bye.



STEVE:  Okay, buddy.  Thanks.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#816

DATE:		April 27, 2021

TITLE:		The Mystery of AS8003

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-816.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we begin by remembering Dan Kaminsky, who the world lost last Friday at the age of 42.  We finally catch up with this month's Patch Tuesday, and look at a welcome maturation in Google's Project Zero vulnerability disclosure policy.  We shine a light upon a new startup venture which, if successful, promises to dramatically improve the future of IoT security.  We then look at some controversial security research, for which the researchers have apologized, and wonder whether any apology was due.  We shine another light onto a new battle Cloudflare has chosen to wage against an abusive patent troll, to help Cloudflare with additional attention, and to let our listeners know that they can participate in a money-making hunt for prior art.  And after a brief SpinRite progress report, we engage with the Internet mystery of the Autonomous System 8003.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  We remember security researcher Dan Kaminsky.  Steve has some personal memories to share and a little video.  We'll talk about the University of Minnesota researchers who are in big trouble with the Linux kernel project.  And then it's a look at the mysterious case of the AS8003, the Pentagon's massive IP address space.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 816, recorded Tuesday, April 27th, 2021:  The Mystery of AS8003.



It's time for Security Now!, the show where we protect your security and privacy online with our majordomo, Mr. Steve Gibson.  Hello, Steverino of GRC.com.  Good to see you.



STEVE GIBSON:  Mr. Laporte.



LEO:  Yes.



STEVE:  Good to be with you once again for Episode 816, the last one of April.  What happened to April?



LEO:  Boy.



STEVE:  It just kind of shot right by.



LEO:  I'm kind of glad, though, because now I am fully immune.  So I can go out and party with the rest of them, with the kids.



STEVE:  Nice.



LEO:  Yeah, I'm excited.



STEVE:  This is going to be kind of a fun episode.  I have two interesting big topics that will be fun to talk about.  I titled it "The Mystery of AS8003," AS as in Autonomous System, and 8003 as a so-called Autonomous System number, which is something that all of the major players on the Internet are assigned.  And I sort of wish that I had - I could have gotten one back in the early days.  Mark Thompson was saying, oh, you've got to get yourself an AS number.  Then ARIN will allocate a little Class C network, and those will be your IPs, and you'll own them, and you can transport them wherever you go.  And if I were moving around much, that would have been useful.  I think I've moved, what, like maybe twice in the entire life of GRC.  So not so important.  I don't really need 256 IPs.



LEO:  Is that over?  Can you do that still?



STEVE:  You probably can still do it.  But I wouldn't be able to get - I don't know if you can be allocated a block smaller than a Class C.



LEO:  Right, right.



STEVE:  And a Class C at 256 IPs, that's more than I need.  Even as it is, I had - with Verio I had I think 64, and I'm at 16 now.  And there is like a form, an IP justification form.



LEO:  Yeah, I'm looking at it on the RIPE site.  It says you have to have a contractual agreement with the RIPE NCC, which means either become a member or find a sponsoring LIR who will submit the request on your behalf.



STEVE:  Yeah.  So it's involved.



LEO:  Yeah.  RIPE is the network coordination center, so you need their support.



STEVE:  Right.  And so we've long talked about IPv4 address space depletion.  So what happened, and what was really weird, was the timing.  It was minutes before the end of Trump's presidency.  After, well, okay, I'm getting ahead of myself.  But anyway, this is really interesting, and we're going to have fun talking about that.



So but we've got something not fun to talk about.  I want to start by, and we will in a minute, by remembering Dan Kaminsky, who the world lost last Friday at the tender age of 42.



LEO:  So sad.  So sad.



STEVE:  He had been struggling with diabetes his whole life, Type I diabetes, where the pancreas doesn't produce enough insulin.  And a danger of unregulated blood sugar is that your body will go into diabetic ketoacidosis, which is an overproduction of ketones, which are acidic and deadly, and which your body produces when it starts to burn fat sort of out of control.  Anyway, of course we know Dan so well on the podcast.  We'll talk about that in a minute.



We're also going to finally catch up with this month's Patch Tuesday and look at a welcome maturation in Google's Project Zero vulnerability disclosure policy.  I was really happy to see them announce this.  We're also going to shine a light upon a new startup venture which, if successful, and boy, based on the creds of the gal who founded it, it sure ought to be, promises to dramatically improve the future of IoT security, which lord knows we need.  We also then look at some controversial security  research for which the researchers have apologized.  And we'll wonder whether an apology was due.  I'm not sure.  I mean, I get it that the Linux maintainers are all upset.  But maybe it was necessary.



We're also going to shine another light onto a new battle which Cloudflare has chosen to wage against, Leo, an abusive patent troll.  Actually the court we know really well.  We've talked about Judge Albright in the Western District of Texas and the abuse that is...



LEO:  Yee haw.



STEVE:  ...occurring down there.



LEO:  I'm sure it's not the case, but I just imagine him in a 10-gallon hat with six-guns going, "Let's get them patent - let's get them big shots [indiscernible].  Whooee."  Geez, what a jerk.



STEVE:  Yeah, yeah.  The background is really interesting because this guy apparently has just gone so far overboard now that - the problem, of course, is that his judgments, which are strongly pro-patentee, are not being challenged because it costs more money to challenge than it does just to say, okay, fine, we'll settle. 



LEO:  Yeah, yeah.



STEVE:  And of course that's the problem.  Cloudflare says, "Eff no.  We are not going to support this.  We're going to fight it."



LEO:  Good.



STEVE:  And so what they're doing, well, again, I'm getting ahead of myself.  We'll talk about that.  And our listeners get to play a part in this and make some money if they're interested in helping Cloudflare.  And then, after a brief SpinRite progress report, we're going to engage with the Internet Mystery of the Autonomous System 8003.



LEO:  I can't wait.  I was hoping you'd talk about that.



STEVE:  A great podcast for our listeners.



LEO:  Yeah, yeah, yeah.



STEVE:  So Dan Kaminsky cut a wide swath through the computer industry.  He was a prolific tweeter and a real character and personality.  He and I were last together, we followed each other onstage during DigiCert's first security conference.  And Dan peppered me with some questions about SQRL back then, and I was able to satisfy his many salient questions.  He was probably first on the map for this podcast when he realized in doing just some research that he was always up to that the transactions which all of the DNS servers throughout the industry were using had way too little entropy.  Their port numbers for the queries they were generating were often sequential, so they were marching through the port space.



And often the transaction IDs, which is a 16-bit number that is used to associate queries with the replies when they come back, those were also sometimes a fixed, well, they weren't a fixed number.  Ports were sometimes fixed.  But the transaction IDs might just be an incrementing counter.  And what Dan realized was that the lack of query entropy being emitted by DNS servers allowed replies to be spoofed.  You could ask a DNS server yourself something and see where its counters were, and then induce somebody else to ask it a question and provide a spoofed reply before the real reply would get back.  And because you knew where the counters were, you were able to, with high accuracy, get a spoof to be accepted as legitimate.  And that's, you know, because the DNS runs over UDP, there is no TCP handshake to validate IPs, so you're able to completely spoof the replies.



So what this meant was, if the world were to realize that, as Dan had privately, it would be a catastrophe.  So Dan privately got in touch with all the purveyors of the various DNS servers.  They all recognized what he had.  And privately, all of the servers were updated, and an industry-wide reveal was coordinated in order to maximize the probability of getting all this fixed before the bad guys had a chance to abuse it.



And of course because I recognized this was a problem, and we covered it on the podcast, we owe Dan the existence of my DNS Spoofability Service, which I created in honor of his discovery, which allowed individuals to go to GRC's DNS Spoofability.  I arranged to cause, by setting up my own DNS, like pseudo DNS servers, I could cause a visitor to my site's DNS to use me as its resolver, and then I collected all the queries that I was inducing through that web page and analyze the nature of the queries coming from the DNS servers that the user is using.



Anyway, Dan has a large following.  I think, what is it, I had it here in my notes somewhere, 94.3K followers on Twitter.  As I said, he's a prolific tweeter.  He joined Twitter in 2007.  Since then he has posted 130,000 tweets.  Now, if we assume an average tweet rate over 14 years, that's 9285.71 tweets per year.



LEO:  Wow.



STEVE:  Or an average of 25.42 tweets or commented retweets per day.



LEO:  That's amazing.



STEVE:  So if you were following Dan, you knew what he was thinking and doing.  And he was also quite literate.  He pinned a tweet of his from January 16th, 2018 to the top of his feed.  He wrote this:  "I'm increasingly thinking that every functioning system has two forms:  the abstraction that outsiders are led to believe, and the reality that insiders actually and carefully operate.  You don't incrementally learn a system.  You eventually unlearn its necessary lies."



LEO:  That's really good.  And I think it's absolutely right.  Absolutely.



STEVE:  Just really, really good stuff.  He had a site, DanKaminsky.com, which was his personal blog, and he hasn't blogged in about four years.  But his last blog, I'll just share a couple paragraphs from it.  He wrote:  "Cryptographically Secure Pseudorandom Number Generators" - right, we've talked about them a lot, CSPRNGs - he says, "are interesting.  Given a relatively small amount of data, just 128 bits is fine, they generate an effectively unlimited stream of bits completely indistinguishable from the ephemeral quantum noise of the Universe.  The output is as deterministic as the digits of Pi, but no degree of scientific analysis, no amount of sample data will ever allow a model to form for what bits will come next.



"In a way, CSPRNGs represent the most practical demonstration of Godel's First Incompleteness Theorem, which states that for a sufficiently complex system, there can be things that are true about it that can never be proven within the rules of that system.  Science is literally the art of compressing vast amounts of experimentally derived output on the nature of things to a beautiful series of rules that explains it.  But as much as we can model things from their output with math, math can create things we can never model.  There can be a thing that is true  there are hidden variables in every CSPRNG  but we would never know.



"And so an interesting question emerges.  If a CSPRNG is indistinguishable from the quantum noise of the Universe, how would we know if the quantum noise of the Universe was not itself a CSPRNG?"



LEO:  Uh-oh.  Uh-oh.  Uh-oh.  Uh-oh.



STEVE:  "There's an infinite number of ways to construct a random number generator.  What if nature tried its luck and made one more?  Would we know?  Would it be any good?"  So anyway, we have lost...



LEO:  Wow.  That's a beautiful, beautiful thing.



STEVE:  ...a critical thinker among us who made all manner of contributions to security and the Internet.  He was working on some weird JavaScript stuff that I never really tracked.  But we have, and I wanted to play it into the podcast so that it is captured, a minute and 45-second video which he and his young niece produced 13 years ago, niece Sarah, following Black Hat 2008, which was where the DNS problem was first revealed.  So here's - and this is fun because his niece is precocious and following a script that he produced.  But they made a really fun minute and 45 seconds.



[BEGIN CLIP]



DAN KAMINSKY:  I'm security researcher Dan Kaminsky, and I'm here today with my niece Sarah.



SARAH:  Hi, everybody.



DAN:  Hey, Sarah.  So Sarah here has an important message for all of you.



SARAH:  Fixing DNS is so important and so cool.



DAN:  Well, what's DNS, Sarah?



SARAH:  Well, Uncle Daniel, I think you should know.



DAN:  Be that as it may, why don't you tell the people a little bit about it.



SARAH:  Well, DNS is a Domain Name System.  It tells my computer where on the Internet all my favorite websites are.



DAN:  Was there something wrong with DNS?



SARAH:  It'll be okay.  Everyone got together a while back to make sure everything would work out.



DAN:  Oh, everybody?  Even ISC, the makers of BIND, and Microsoft, and Cisco, and Nomi, Nomi...



SARAH:  You mean Nominum?



DAN:  Totally Nominum.  But that's really cool.  So what should everyone do, Sarah?



SARAH:  Well, this is really geeky stuff.  But most people should get automatic updates and be okay.



DAN:  Well, who might not?



SARAH:  Well, there might be some servers that don't get automatic updates because they're really important, and people want to keep an eye on them.



DAN:  Oh, so we should ask those people to take a look?



SARAH:  Totally.



DAN:  Oh, well, when should they look?



SARAH:  Right now.  Duh.



DAN:  Well, when do they have to fix it by?



SARAH:  Well, the attack is pretty weird, but people will probably figure it out after a month.  So I'll give you an exact date:  August 6, 2008.



DAN:  August 6?



SARAH:  August 6.



DAN:  All right, then.  Now, is there any way for the non-geeks to make sure they're safe?



SARAH:  Only if you build them a website.



DAN:  Hmm, I'll get right on that.



SARAH:  You better.



DAN:  Well, thanks, Sarah.  And there you have it.  Kids, talk to your parents about their DNS.  They'll be glad you did.  All right.  That's a wrap.



CAMERA:  All right, that's a wrap.  Okay.  Thanks, Cousin Dan.  And thank you, Mattie.



[END CLIP]



LEO:  That was so sweet.  Oh, my god.  Oh, I'm sure they miss him terribly.  And of course his friend Steve wrote something in assembly to do that, so it was okay.  He didn't have to do that.  Wow, wow, wow.



STEVE:  Yeah, very cool.



LEO:  Oh, he'll be missed.



STEVE:  Also DEF CON has announced on their Twitter feed that they're having an online memorial for Dan on Sunday, May 2nd, on the DEF CON Discord channel, Discord.gg/defcon.



LEO:  Nice.  Nice.



STEVE:  So they tweeted:  "Come share your favorite stories and join us in celebrating the life of a hacker whose life elevated the whole community."



LEO:  Wow.  Good.  Thank you for doing that, Steve.  Yeah.  Of course his name comes up all the time on our shows.



STEVE:  Yeah, yeah.



LEO:  He'll be missed.



STEVE:  Yeah.  Good guy.  And for what it's worth, DanKaminsky.com.  I only shared the top of that really cool posting.  He gets really into it.  So if you're wondering maybe if in fact we are in the Matrix, Dan may give you some pause.  Of course I don't know how long the site will be up.  Hopefully it will stay.



So Patch Tuesday was the week before last, and I missed summarizing it last week just because there was so much else to talk about.  And it would be nice if it was all old news by now.  But believe it or not, the NSA contributed their knowledge of four additional remote code execution flaws in, you guessed it, Microsoft Exchange Server.  Okay, now, I'm not a conspiracy guy.  But you've got to wonder whether these four very valuable RCE flaws in Exchange Server might have been the sort of thing that the NSA had been sitting on quietly as part of its own private stash of remote access tools.



Remember that Exchange Server is used worldwide, not just in the U.S., and it's now become a well-proven means of gaining surreptitious entry into someone else's system.  That's exactly the sort of thing that the NSA or the CIA might find quite handy.  And assuming that we're to believe the various leaks from the past, we know this is exactly the kind of thing that they do in fact hold onto and use, explicitly without telling the world, because they want their access ability to be retained.



But I was thinking that, with all the heat and attention on Exchange Server, they may have correctly decided that it would be far better to help Microsoft more fully clean up this mess with Exchange Server, even at the cost of foreclosing on their future use of some valuable entry points, presuming that, if everyone was starting to look at it so closely now, they would get found anyway, or the bad guys could be using them against us.  So, yeah, let's close the other backdoors that exist.



So, yes, two weeks ago, well after the early March updates, we got another set of these four RCEs closed.  And again, that's all just wild speculation.  It's equally likely that they may have put some of their own hackers onto Exchange Server for the sake of the U.S. and discovered four previously unknown flaws.  That could be true, too.  And in either case, as part of this month's 114 other security flaw repairs, Microsoft fixed these four, which of course affect all versions of Exchange Server - 2013, 2016, and 2019, presumably 2010, too, since all of these flaws seem to have been around forever.  Two of the four of those four that the NSA found are fully juicy, unauthenticated access flaws requiring no user interaction, and thus they rank a CVSS of 9.8, right up there at the top.



Overall, Patch Tuesday fixed a total, as I mentioned, of 114 flaws:  19 were rated critical, 88 important, and one moderate.  One of the most concerning was CVE-2021-28310, which is a privilege escalation vulnerability in Win32k.  We've seen a lot of those over the course of the last year.  This one is a worry because it is under active exploitation, which allows attackers to elevate privileges by running malicious code on the target system.



And at first you say, well, it doesn't get you in, so what?  But Kaspersky Labs found and reported this one to Microsoft.  Their Boris Larin said it's a privilege of elevation exploit that is likely used together with other browser exploits to escape sandboxes to get system privileges for further access.  And just a couple weeks ago we were talking about the Pwn2Own, the most recent 2021 Pwn2Own competition, where there were exactly this sort of chain of exploits used to break out of browsers and get to people's computers.  And we've also talked about how the browser is the main entry point now - okay, Microsoft Exchange Server aside - for intrusions into people's systems.  It is the target of opportunity.  So anyway, good to get those patched.  And it was, yes, another big Patch Tuesday.



Google's Project Zero responded to, in my opinion, today's patch latency reality.  And I was really glad to see that.  As we know, until now, Project Zero set a fixed 90-day timer on the disclosure of vulnerabilities discovered and privately disclosed to vendors.  And we've shown the Project Zero postings where they announce that there's a vulnerability, they say nothing about it, but they say if it's not fixed within in 90 days, we're going to tell the world because, A, the world maybe needs to know so they can fix it themselves.  That's of course dicey because bad guys now jump on that and abuse it before it can be fixed, mostly obviously to put pressure on vendors so they don't  just sit around twiddling their thumbs and don't deal with problems that have been found and could presumably easily be fixed.



Oh, and also remember that when a vulnerability is discovered in the wild, that is, when it is a true zero-day, and by that we mean it's in use, it's completely unknown at the time that it is seen being abused.  As we know, the term "zero-day" has been watered down recently.  Everyone now just uses it because it seems more exciting.  But in real zero-day instances, Project Zero sets the timeout, the disclosure time to seven days, one week.  So that's meant to reflect the extreme danger posed to users of the fact that this thing is happening now, and to really light a fire under the vendor to get them moving on fixing it with some urgency.



What's changed in what I think is a welcome and sane announcement last week is that they're going to add a new 30-day patch latency allowance, which makes so much sense.  If the vendor fixes the problem and publishes a patch before the initially allotted deadline expires - whether it's 90 days for a problem found but not known to be under abuse, or seven days for a true zero-day which is discovered - if it's fixed and patched within that deadline, then Google will add a 30-day grace period onto the end of the original deadline to reflect the reality that we're all observing now that releasing a patch and actually having systems patched against the now-known vulnerability are two very different things.  So this is great.  And clearly some rethinking has been done.



There is some discussion about maybe tightening up on that 90 days, that initial 90-day deadline, saying that's three months.  Come on, folks.  Do you need three months to fix a problem?  Even Microsoft with a 30-day iteration, give them 60.  In case they miss the first one, they ought to be able to catch the second one.  So anyway, we'll see how that goes.  But it really makes sense.  What we keep seeing now is that the moment the details of a flaw emerge publicly, bad guys jump on it and immediately start abusing it because they know not everyone is going to get patched quickly.  So 30 days from the time that the patch is available, no matter when that occurs, that's going to allow a 30-day patching cycle, like many people in the industry now have, to hit its patch event and allow automatic updates to happen, so even users who aren't doing anything.  And this allows the vendors not to have to force an emergency update cycle, which many systems really don't support now.  So bravo to  Google for fixing that.



The other thing I wanted to mention is I'm excited about this.  A newly financed startup named Thistle, T-H-I-S-T-L-E, aims to take aim at IoT security by providing a secure turnkey security foundation to future devices.  For more than 20 years, this new firm's founder, by the name of Window Snyder, S-N-Y-D-E-R, she's been building security into the products of some of the largest companies in the world.  Her startup is creating tools that  will help manufacturers build security into connected devices from day one.



As we know, the manufacturers of, well, everything - printers, ATM machines, consumer electronics, automobiles, light switches and connected plugs, any and all IoT gizmos typically don't have the security expertise that companies like Apple, Microsoft, and Google have developed over the last several decades.  And the result is all too well known to us.  We see billions of devices shipping with vulnerabilities that are preyed upon by profit-driven bad guys and nation-state hackers.  I would argue that the IoTpocalypse hasn't yet been seen.



But when you imagine, and I've talked about this, all the connections which are reaching out from all of our devices in all of our homes over to services in China which anchor these things, wow.  And then you look at things like all of the IP stacks which these things use which are then known to have, be riddled with vulnerabilities, yet they're never able to be updated because it's a wall switch or a plug.  We're just, you know, like I said, you want this on its own network.



So Window, her first name, is a security veteran.  She has previously served as Chief Security Officer at Square, Mozilla, and Fastly, and was Chief Software Security Officer at Intel.  While she was a teenager she was part of a Boston hacker collective before going on to be a consultant at @stake, which is a security company which employed many of the members of L0pht.  Remember we used to talk about L0pht 15 years ago, L-0-P-H-T, that was another Boston hacker collective.  She also spent time at Microsoft working on Windows XP Service Pack 2, which was the update which added a range of really much-needed security improvements to Windows.  She worked on security at Apple.  So she knows what she's talking about.  About the new company she was quoted saying:  "What it takes to build security into products requires a lot of really specialized skills.  You get folks, especially at the device level, building the same security mechanisms over and over again, reinventing the wheel, and doing it to different levels of resilience."



So her firm, Thistle, will develop frameworks that allow device manufacturers to quickly build reliable and resilient security into their products more quickly than they could do on their own.  And believe it or not, be still my heart, the company's initial work will focus on building a platform that delivers security updates to connected devices.



LEO:  Yeah, good.



STEVE:  I mean, has she been listening to this podcast?  Patching devices typically requires reflashing firmware, a process that can be fraught with risk.  And as Window notes, she said:  "It's one of the reasons nobody delivers updates for devices, because the cost of failing an update is so high.  If you've got 100 million devices out there, and you've got a 1% failure rate, which is very low for updates, that's still a million devices that are bricked."  So this is wonderful news.  I hope she succeeds.  I wanted to put her on the map through this podcast.  If any of our listeners are in any position to influence the development of any IoT work, check out Thistle because farming this stuff out to a security specialist who's got this kind of CV behind herself sure seems like exactly the right thing to do, in my opinion.  So bravo.  And in advance, thank you, Window.



Okay.  So the University of Minnesota, I'm inclined to label this "controversial," though many don't believe there's any doubt about this being unequivocally wrong.  Okay.  So the industry's reporting on this stated that three security researchers, an associate professor and two of his grad students, deliberately introduced live use-after-free vulnerabilities into the production Linux kernel in the cause of security research aiming to highlight how potentially malicious code could be deliberately introduced into an open source project and sneaked past the patch approval process.



Their goal was to demonstrate the problem and suggest ways to improve the security of the code approval and patching process.  So they did this in the real world by attempting to sneak their own malicious code patches into the actual production Linux kernel.  So says the press.  A closer reading will show that that's not actually what they did.  But, okay.  So we'll take this one step at a time.  The research was conducted earlier this year, or at least it was published, well, it had to have been last year because it was published late last year.



And when what they had done came to light recently as a result of their own admission, they apologized, saying:  "While our goal was to improve the security of Linux, we now understand that it was hurtful to the community to make it a subject of our research, and to waste its effort reviewing these patches without its knowledge or permission.  We did that because we knew we could not ask the maintainers of Linux for permission, or they would be on the lookout for the [what they called] 'hypocrite patches.'"  And I'll explain that terminology in a second with their paper.



So the researchers claimed:  "We did not introduce or intend to introduce any bug or vulnerability in the OS."  Okay.  But it appeared that evidence emerged to the contrary, suggesting that the research was conducted without adequate oversight and risked the Linux kernel's security.  And this resulted in a unilateral ban of all future code submissions from anyone using the "umn.edu" email address, and also invalidated all past code submitted by the university's previous researchers.  



LEO:  Ouch.  Wow.  I don't blame them.



STEVE:  Oh, Leo.



LEO:  I'd be pissed, too.



STEVE:  So, yeah, the Linux Kernel Project did not take this lightly.



LEO:  No, they're a little irritated, I'm thinking.  I'm guessing.



STEVE:  They were, yes, they were, it would be fair to say, pissed.  They said:  "Our community does not appreciate being experimented on, and being 'tested' by submitting patches that either deliberately do nothing or deliberately introduce bugs."  So responding to the Linux Project's response, another observer thought it was even worse, tweeting:  "This is worse than just being experimented on.  This is like saying you're a 'safety researcher' by going to a grocery store and cutting the brake lines on all the cars to see how many people crash when they leave."



LEO:  Yeah, yeah.



STEVE:  They said:  "Enormously unethical."



LEO:  Yes.



STEVE:  Okay.  And following the incident, the university's Department of Computer Science and Engineering said it was investigating the incident, adding that it was looking into the "research method and process by which this research method was approved, determine appropriate remedial action, and safeguard against future issues."



LEO:  As in, why didn't somebody stop these knuckleheads?



STEVE:  Okay.  So what about this research?  Their paper, which has been accepted for publication and presentation at the IEEE Symposium on Security and Privacy 2021, is titled "On the Feasibility of Stealthily Introducing Vulnerabilities in Open Source Software via Hypocrite Commits."  And the paper explains itself in its abstract, which reads:  "Open source software (OSS) has thrived since the forming of Open Source Initiative in 1998.  A prominent example is the Linux kernel, which has been used by numerous major software vendors and empowering billions of devices.  The higher availability and lower costs of open source software boost its adoption, while its openness and flexibility enable quicker innovation.  More importantly, the open source software development approach is believed to produce more reliable and higher quality software since it typically has thousands of independent programmers testing and fixing bugs of the software collaboratively.



"In this paper, we investigate the insecurity of open source software from a critical perspective:  the feasibility of stealthily introducing vulnerabilities in open source software via hypocrite commits, i.e., seemingly beneficial commits that in fact introduce other critical issues.  The introduced vulnerabilities are critical because they may be stealthily exploited to impact massive numbers of devices.



"We first identify three fundamental reasons that allow hypocrite commits.  One, open source software is open by nature, so anyone from anywhere" - except now the University of Minnesota - "including malicious ones, can submit patches.  Second, due to the overwhelming patches and performance issues, it is impractical for maintainers to accept preventive patches for 'immature vulnerabilities.'"  And they talk about that a little bit later.  "And, three, open source software like the Linux kernel is extremely complex, so the patch review process often misses introduced vulnerabilities that involve complicated semantics and contexts.  We then systematically study hypocrite commits" - and actually they do it in vivo, right, which was the problem - "identifying immature vulnerabilities and potential vulnerability-introducing minor patches.



"We also identify multiple factors that can increase the stealthiness of hypocrite commits and render the patch review process less effective.  As proof of concept, we take the Linux kernel as target open source software and safely demonstrate that it is practical for a malicious committer to introduce use-after-free bugs.  Furthermore, we systematically measure and characterize the capabilities and opportunities of a malicious committer.  At last, to improve the security of OSS, we propose mitigations against hypocrite commits, such as updating the code of conduct for open source software and developing tools for patch testing and verification."



Okay.  Now, I would argue that this is a very valid and very important and very much needed avenue of research.  It should be clear to everyone, and apparently a bit of a sore spot with the Linux kernel maintainers, that surreptitious commits would inherently be a huge problem for any large open source project which is open to many contributors.  The only solution I can see is being extremely, you know, is to have extremely careful multiparty scrutiny of any changes which are made to the kernel.  But that's rather thankless and boring work.  It's much more fun to create new patches and apply them.  But careful scrutiny of changes made to the kernel that are predominantly going to be fine sort of amounts to debugging code that's assumed to be correct and is not known to have anything wrong with it.



So it's very similar to the trouble I've often spoken of, of debugging one's own code, which similarly is believed to be correct.  As I've often observed, it often takes single-stepping through such code which you "know," in quotes, is correct, even though it's misbehaving.  You finally have the debugger just rub your face in the mistake before you see it.  And it inevitably evokes the "aha" reaction that anybody who's written code and has been forced to have a debugger show them where the problem is has experienced.  So auditing every line of code that may have been very, very cleverly designed to misbehave only under a very subtle edge-case condition is probably impossible.  So it represents an ongoing Achilles heel for any large open source projects.  So I would argue that this was important and useful research.



In a follow-up FAQ, these guys attempted, as a consequence of the backlash that their in vivo experimentation with the actual Linux project incurred, they attempted to clarify what they had done.  Their FAQ is titled:  "Clarifications on the hypocrite commit work."  And I've got a link to that also in the show notes.  I'll just share their first introduction of it, which really does put this into context.



They said:  "We recently finished a work that studies the patching process of open source software.  Its goal is to improve the security of the patching process.  The corresponding paper has been accepted by IEEE S&P 2021."  He says:  "I shared the abstract of the paper on Twitter, which then resulted in heated discussion and pushback.  I apologize for the misleading abstract which did not show the details and caused many confusions and misunderstandings."  You know, in other words, yeah.  If you only read the abstract, you don't realize what it is they did.  And so the people who got all upset, and the press, who apparently also just followed the upset, didn't pursue the details.  Which, as you know on this podcast, we find is often valuable.



So he says:  "Therefore, we would like to make a few clarifications.  We would like to first mention that we are a young research group with improving the kernel security as our first priority.  In the past several years, we've devoted most of our time to improving the Linux kernel, and we have found and fixed more than 1,000 kernel bugs."  So, yeah, these guys know what they're doing.



They said:  "The extensive bug finding and fixing experience also allowed us to observe issues with the patching process and motivated us to improve it.  Thus, we consider ourselves security researchers as well as open source software contributors.  We respect open source software volunteers and honor their efforts.  We have never intended to hurt any open source software or users.  We did not introduce or intend to introduce any bug or vulnerability in open source software.  The following are clarifications to the common concerns we received."



So first, the purpose and research value of the work.  They said:  "The project aims to improve the security of the patching process in open source software.  As part of the project, we study potential issues with the patching process, including causes of the issues and suggestions for addressing them.  This study indeed reveals issues, but its goal is to call for efforts to improve the patching process, to motivate more work that develops techniques to test and verify patches, and finally to make open source software safer.



"In this work, we collect 138 previous bug-introducing patches not introduced by us.  Based on these patches, we summarize their patterns; study specific reasons why bug-introducing patches are hard to catch with both a qualitative and quantitative analysis; and, more importantly, provide suggestions for addressing the problem.  In this work we introduce the concept of 'immature vulnerability' where a vulnerability condition of it is missing, but it can be turned into a real one when the condition is implicitly introduced by a patch for another bug.  We also develop tools that help us find code places that may suffer from bug-introducing patches, and suggest what may make these bug-introducing patches hard to catch."



So then they ask themselves the question so they can answer it:  "Did the authors introduce or intend to introduce a bug or vulnerability?"  Answer:  "No.  As part of the work, we had an experiment to demonstrate the practicality of bug-introducing patches.  This is actually the major source of the raised concerns.  In fact, this experiment was done safely.  We did not introduce or intend to introduce any bug or vulnerability in the Linux kernel.  All the bug-introducing patches stayed only in the email exchanges, without being adopted or merged into any Linux branch, which was explicitly confirmed by maintainers.  Therefore, the bug-introducing patches in the email did not even become a Git commit in any Linux branch.  None of the Linux users would be affected.  The following shows the specific procedure for the experiment."



And it continues.  Again, link to the PDF for anyone who's interested.  I don't find any fault with what these guys did.  And I would argue that it's vital research.  What they did was to exercise the Linux Project's patch management infrastructure without the project's knowledge or permission.  So the project's managers are upset over being used in this way.  I may not have all the facts.  I haven't taken the time to study this more deeply, nor look at the maintainers' side of the argument.  But this seems like a critically important piece of work.  And I get it that it was necessary to use the patch management process without its knowledge or permission.



Maybe they could have said, in fact somewhere I read that they were worried that if they asked for permission, they would be told no and foreclose what is arguably a valuable piece of research.  So if they fixed a thousand bugs in the Linux kernel, and the Linux guys are so upset that they're saying they're going to, what, revert a thousand Linux improvements because they all came from these guys when they were doing this research?  Well, I mean, before this research.  And it was the act of fixing the bugs that led them to realize, hey, there's some problems here in this process that we've been participating in that we need to understand better.  And I think it's wrong to slap the university like this.  That was, you know, hopefully this is an overreaction that can be backed out of.



The paper finishes, their conclusion, you know, as all good research papers have, they concluded saying:  "This paper presented hypocrite commits, which can be abused to stealthily introduce vulnerabilities in open source software.  Three fundamental reasons enable hypocrite commits:  the openness of open source software, which allows anyone including malicious committers to submit patches; the limited resources of open source software maintaining; and the complexity of open source software programs, which results in the manual review and existing tools failing to effectively identify newly introduced vulnerabilities.



"We then systematically characterized immature vulnerabilities and studied how a malicious committer can turn immature vulnerabilities into real ones."  And now we understand what that means is an inadvertently introduced vulnerability as part of an intended fix which is sort of latent.  And then another deliberate "improvement" can mature that immature vulnerability into one that can actually be leveraged.  So, I mean, these guys know their stuff.  



And they said:  "We also identified multiple factors that increase the stealthiness of the introduced vulnerabilities, including concurrency, error paths, aliases, indirect calls, and so on.  Furthermore, we provided a proof of concept to safely demonstrate the practicality of hypocrite commits, and measured and quantified the risks.  We finally provided our suggestions on mitigating the risks of hypocrite commits and hope that our findings could motivate future research on improving and patching the process of open source software."  So to these guys I say thank you.  Yeah, I think on balance the reaction has been wrong from the maintainers.  And again, as I said, I hope this gets some potentially well-deserved attention.  



LEO:  I'm looking at the banning notice.  And it says commits from these addresses have been found and submitted in bad faith.  So they say it's just an email, but it sounds like they submitted commits.  Having commit privileges, especially to something as critical as the Linux kernel is, that's a real privilege.  Very few people have it.  Very few people have it for this very reason.  If these guys have commit privileges, and attempted to commit a flawed update, I'd block them, too.  They'd never get to commit again.  That's a privilege.  There's a reason they call it a privilege.  The maintainers say these guys were trying to commit.



Now, it says "Commits from a @unm.edu address have been found to be submitted in bad faith."  So there's a dispute over what the facts of the matter are.  I mean, writing an email, no big deal.  Big deal, you know.  What about this?  What do you think?  Big deal.  But if you have commit privileges, especially the Linux kernel, that's a big deal.  Very, very, very few people have that.  And you in bad faith submit something that's to test the system, I'd revoke your privileges.  I think that's completely appropriate.  You can't be trusted.  I think your ethics are definitely in question.  So I'm looking at the email.  I think that maybe there's other things.  I don't know what's going on because it doesn't match what they said.



STEVE:  So what we have is clearly a collision of facts where these guys are saying, as I read, we absolutely never endangered the kernel.  The kernel guys are saying, well, you could have.



LEO:  Not true.  They submitted it, yeah.



STEVE:  And we no longer trust you.



LEO:  So they're reverting all submissions from that group from the kernel tree, as they should.  The patch set has easy reverts, but there are 68 remaining ones that need to be manually reviewed.  And they must all be reviewed at this point.  Some of them are not able to be reverted as they'd already been reverted or fixed up with follow-on patches as they were determined to be invalid.  Proof that these submissions were almost universally wrong.  So there's a lot of work that has to go on at this point.



STEVE:  Yeah.



LEO:  I'm not - I don't - I wouldn't say nothing from the University of Minnesota will ever be accepted again.  I don't think that's what's happened here.  I think that these people apparently had commit privileges which have been revoked, as they should have been.  And they should have known better.  That's inappropriate.  And by the way, everybody knows these flaws exist, that this is a problem.  That's why it's so hard to get commit privileges.  And there are so many stages to get approval to get to the kernel.  The Linux kernel is not the problem.  It's all those other little things that we've talked about before that have one maintainer out there who's overworked and underappreciated.  Those are the problems.  It's OpenSSH.  It's not the Linux kernel.  That's pretty well protected.  Maybe that's why they attacked it.  But I don't care what your motive for attacking the Linux kernel is.  That's not okay.  I don't think that's okay.  That's my opinion.  So just thought I'd throw that in there.



STEVE:  I'm glad for it, Leo.  We have multiple views.



LEO:  Yeah.  And I think we need to know more about what really happened.  I think that's part of it.  I just don't think that it was that useful, what they've so-called proven.  We know that.



STEVE:  Cloudflare.  Our favorite company.



LEO:  Oh, this is an interesting story, yeah.



STEVE:  Yeah, an interesting favorite company of ours.  On March 15th - I'm reading from Cloudflare's announcement of what went on to set the stage.  "On March 15th," Cloudflare wrote, "Cloudflare was sued by a patent troll called Sable Networks  a company that doesn't appear to have operated a real business in nearly 10 years  relying on patents that don't come close to the nature of our business or the services we provide."



They said:  "This is the second time we've faced a patent troll lawsuit.  As readers of the blog, or followers of the tech press, ZDNet and TechCrunch, will remember" - and I'm sure we talked about it at the time.  They said:  "Back in 2017 Cloudflare responded aggressively to our first encounter with a patent troll, Blackbird Technologies, making clear we would not simply go along and agree to a nuisance settlement as part of what we considered an unfair, unjust, and inefficient system that throttled innovation and threatened emerging companies.  If you don't want to read all of our previous blog posts on the issue, you can watch the scathing criticisms of patent trolling provided by John Oliver or the writers of 'Silicon Valley.'"



They said:  "We committed to fighting back against patent trolls in a way that would turn the normal incentive structure on its head.  In addition to defending the case aggressively in the courts, we also founded Project Jengo (J-E-N-G-O), a crowd-sourced effort to find evidence of prior art to invalidate all of Blackbird's patents, not only the one asserted against Cloudflare.  It was a great success.  We won the lawsuit, invalidated one of the patent troll's other patents, and published prior art on 31 of Blackbird's patents that anyone could then use to challenge those patents or to make it easier to defend against overbroad assertion of those patents.  And most importantly, Blackbird Technologies went from being one of the most prolific patent trolls in the United States to shrinking its staff and filing many fewer cases.  We're going to do it again, and we need your help."



They said:  "Turning the tables, a $100,000 bounty for prior art.  Sable Networks and its lawsuit fit neatly within the same troubling trends we were trying to address the first time we launched Project Jengo.  Sable is taking ancient, 20-year-old patents and trying to stretch those patents light years beyond what they were meant to cover.  It has already sued over a dozen technology companies" - and I don't think I have it here, but like Cisco and Juniper Networks won settlements.  That's what these people do; right?  It's more expensive to fight the lawsuit than it is just to pay these people off.  So that's their profit model.



And Cloudflare says "eff no."  They said:  "It's already sued over a dozen technology companies targeting a wide range of different products and services, and by extending its claims to a company like Cloudflare suggests it may next try to stretch its claims to people that merely use routers - namely, anyone that uses the Internet.  We think Sable's choice to bring these lawsuits on such a tenuous basis should come with some risk related to the underlying merits of its patent and its arguments.  So we are sponsoring another prior-art contest, seeking submissions to identify prior art for all of Sable's active patents.



"We are seeking the help of the Cloudflare community to identify prior art  i.e., evidence that the patented technology was already in use or known before the patent application was filed  that can be used to invalidate Sable's patents.  And we will make it worth your while," they wrote, "by offering $100,000 to be shared among the winners who are successful in finding such prior art."  They said:  "Again this time, we are committing $100,000 to be split among entrants who provide what we determine to be the most useful prior-art references that can be used in challenging the validity of Sable's patents.  You can submit prior-art references as long as Sable's case is pending against us."  And then they cite Sable Networks, Inc. v. Cloudflare, Inc.  And they have the case number.  And then I noted ADA, and then it says in parens (W.D. Tex.).  Well, ADA is Alan D. Albright, a.k.a. the infamous Judge Albright, who is exceedingly patentee friendly.  And his jurisdiction is W.D. Texas, the Western District of Texas.



They said:  "Every three months for two years or until the case ends, whichever comes first, we will select winners from the submissions to date, and give out a portion of the $100,000 as awards.  Once the case ends, we will select final winners from all submissions and award the remaining funds.  We will also make all relevant submissions available to the public."



So anyway, their post goes on at some length.  And it's all really interesting to anyone who has a passion, as I do - and I know, Leo, you do, we've talked about this a number of times on the podcast - for issues surrounding intellectual property rights and the abuse thereof, unfortunately by the U.S. patent system.  And in the posting, I have a link in the show notes, they explain how Sable sues companies, then settles out of court just before the deadline to actually make their case.  It's pure patent trolling harassment.  And it makes our blood boil.  And I have more here.  I don't think there's anything else relevant that I haven't talked about.



LEO:  Yeah, we went through this almost exact situation with the podcast patent troll.



STEVE:  Oh, the podcast troll; right.



LEO:  Yeah.  And, you know, Cloudflare's offering a reward of $100,000 for prior art, which is of course what you want to find.  There are a couple of ways you can fight this stuff.  And it's interesting, you know, we actually hired a law firm to prepare us for this because we got a demand letter from these guys for I can't remember, million dollars or something.  The EFF chose one path, which was you can do an inter partes challenge of the patent itself with the U.S. Patent & Trademark Office.  So you go to them, and you say, here's prior art.  This is evidence that this patent was...



STEVE:  Was not original.



LEO:  Was not original.  Others had done this before.  And you hope that the PTO will overturn the patent, and then the whole thing goes up in smoke.  There's a risk, our attorneys told us, if you lose, that's really going to prejudice the case against you because that loss with the Patent & Trademark Office will be brought up at court.



STEVE:  Oh, further strengthens the patent, yes.



LEO:  So it's a risky process, which we had decided not to pursue.  Our attorney said just ignore it until they sue you.  They did sue a number of people, including Adam Carolla, who raised money and fought it.  He did what Cloudflare's going to do.  He took it to court, and they lost in court.  But actually maybe it was the other way around.  No, I'm sorry, the EFF did  the inter partes and won, the Patent & Trademark Office, as this parallel Adam Carolla court case was going on.



STEVE:  Ah.



LEO:  And the PTO overturned the patent, and then the whole thing was over.  So but Adam Carolla spent a lot of money, I think.  I mean, he raised the money from contributors.  But he was going to fight this.  And that's what you have to do because what happens is the little guys give them money, and then they go to the next big guys, they get more money, and they're building up a war chest to eventually go after Apple and Google and whoever and get the big bucks.  And so at some point somebody has to say, no, we're going to court.  And it's funny because Lisa, I love Lisa for this, she never - she says, "You don't ever settle because once you settle..."



STEVE:  [Crosstalk] flames.



LEO:  We'll go down in flames.  She said, "Once you settle, the word goes out.  Oh, yeah, they'll settle."  So we never settle.  I should just - everybody should know that.  We go to court because that's the only way you can stop this.  You just have to fight it.  And the reason it works is because they usually ask - this patent troll was dumb with us.  They usually ask for an amount that's less than the cost of fighting it.



STEVE:  Right, right.



LEO:  Our attorney said, "It's going to cost you about a quarter of a million to fight it."  He asked for a million dollars.  Stupid.  He should have asked for $240,000, and then the reasonable intelligent business thing to do, we still wouldn't have done it, would have been to say okay.  But we've been sued a couple times since then for amounts just low enough so that you go, oh, here.  And in every case we fight it, even though it costs us more, because it's just not - and we've always won, by the way.  



STEVE:  It's wrong.



LEO:  It's wrong.



STEVE:  Yeah, yeah.  And so it is, you know, a lot of people assume that a patent means something.



LEO:  It means nothing.  It means the right to defend it in court.



STEVE:  Yes.  A patent is literally a license to be sued.  



LEO:  Yeah.



STEVE:  First of all, anybody can patent anything that they want to.  Doesn't even have to - it doesn't have to make sense.  It doesn't have to be reasonable.  And our Patent Office is, I mean, it's a hard job.  And so I have some sympathy for them.  But the presumption is that they are really doing due diligence and making sure that something that someone submits as claiming that, hey, I invented something, more often than not it's just engineering.  I look at these patents, and anybody who came out the other end of a university with a degree in the subject would go, well, that's the way you solve this problem.



LEO:  Right.  It's obvious.  It's an obvious solution, yeah.



STEVE:  Yes.  I mean, Microsoft was, as a technologist, as a coder, I looked at many of Microsoft's patents early on.  And the only thing that happened was that they faced a problem before somebody else.  And anyone trained in the art, and that is actually the language of the patent law, it is supposed to be non-obvious to anyone trained in the art.  Meaning that some other programmer is given this problem, they go, oh, here's how  you solve that.  Well, Microsoft was leading the development of software, so their programmers encountered problems that other programmers hadn't encountered.  Well, they patented everything.  I mean, patent sneezing to the right.  And, oh, because most people don't do - it's like it was insane.



LEO:  And the presumption is, they even say this, the PTO says this, we expect if there's an issue that it'll go to court, and it'll be solved there.  And they just, I think, probably don't have the examiners and the time to do it right.  So they do the best they can, but ultimately all they're saying.



STEVE:  And what mature companies end up doing, and this is what they will say when you challenge them is, well, we're building a patent portfolio so that we can cross-license other large companies' patent portfolios.  And so it's sort of an insider large corporate thing that goes on.  And unfortunately the little guy is the one who ends up being in trouble.



So anyway, bravo to Cloudflare.  I wanted to put this on our listeners' radar.  I've got a link in the show notes.  In fact, even in my show notes I go on at great length about Caspian and this other company, Sable.  For anyone who's interested can just read more than I'm going to put into the podcast because there's no need to go into additional detail.  But Cloudflare is worried that, if this company is allowed to keep going, they're going to start suing people who process packets because there's this notion of tagging packets to be part of a flow, which was a technology that the firm that went out of business, Caspian, tried to market this thing, and they probably went belly up.  Sable probably bought their intellectual property portfolio out of bankruptcy with the intention of pursuing this.



Anyway, so what Cloudflare is worried about is that these guys really do need to be stopped.  Secondarily to the fact that it's wrong, and that also that Cloudflare's been sued.  And of course it's a good idea, it's prudent from Cloudflare's standpoint to send the message out that you sue us, we're going to invalidate your entire patent portfolio, you troll, and put you out of business.  So anyway, cool stuff.  



LEO:  Yeah.  "Non-practicing entity" is the polite name.



STEVE:  Yes, NPE, non-practicing entities.  We even have a phrase and an acronym for these slime balls.



I wanted to note, we got a bit of feedback from a listener, somebody who had been FLoCed.  I put the call out now two weeks in a row.  I went back a little bit into my Twitter feed.  And Krv, wow, I guess he's been in Twitter for a while, literally his Twitter handle is @Krv.



LEO:  Three letters.  That's good.  That's old school.



STEVE:  That's a goodie.  Anyway, he said:  "You asked for someone's FLoC ID.  Here is mine."  And he said:  "You are FLoCed!  Your FLoC ID is 5393."  So that's cool.  That says, I mean, we don't know what the maximum ID is.  But the fact that he got 5393 suggests large pools with a few number of IDs.  But again, Leo, as you've said, all subject to change, and this tells us nothing at this early stage.  So definitely something to keep an eye on.  And did you know, I was following some trails, Microsoft has their own proposal.  And when I saw that it was called Parakeet, and it was based on Turtledove, I said, okay, no, everybody.



LEO:  The birds.  The birds.



STEVE:  Enough with the birds.  Really.  This is for the birds.



In a brief note, as I hoped, the third work-in-progress testing release of SpinRite 6.1 was taken public last Thursday.  I found that bug that I mentioned that I was going to pursue after last week's podcast.  And it fared very well, considering that it incorporated two months' worth of work that hadn't been tortured at that point at all.  The only problem that the testing gang found was with some older machines with floppy disk drives.  Since SpinRite can still boot from a floppy and can log its results to a floppy, that all needs to work correctly.  Floppies are weird, and they've always been weird because remember, Leo, you will, the very first PCs did not have hard drives.  And they often did not have two floppy drives.



LEO:  Oh, yeah.



STEVE:  You could get single-drive PCs.



LEO:  Yeah.



STEVE:  But how could you copy a floppy if it only had one floppy drive?



LEO:  Swapping.  A lot of swapping.



STEVE:  Yes.  The kludge was that the BIOS, actually in the BIOS, it supported a second virtual floppy drive.  And so it always showed two drives.  So DOS always had A and B.  And if you did like a dir of B, which DOS said, well, yeah, okay, he's got two drives...



LEO:  Give us B.  Give us B.  Where's the disk?



STEVE:  Yeah.  So what would happen is the BIOS would prompt you on the screen saying please insert the floppy for Drive B.  And then it would keep track of which floppy was in the one floppy drive you actually had.  Well, believe it or not, I'm still fighting this today.  I mean, because none of that has changed.



LEO:  What?  Why?



STEVE:  Well, because unless I intercept the BIOS's writing to the screen, please insert the floppy drive for B, if SpinRite  touches B, that comes out.



LEO:  Wow.  Oh, wow.



STEVE:  So I had to intercept what's known as the multiplex interrupt, which is INT 2f.  And if AH equals, I think it's 4,000, I have to return with the CX register set to all F's in order to suppress that message being written to the console.  And I needed to touch A and B because I want to build a list of the valid drives to which SpinRite can log its results.  So anyway, turns out there was something I got wrong.  A couple people actually had machines with floppy drives, which is why I so much believe in testing this stuff, and it's all fixed and working now.  So after today's podcast I'll be moving on to the next stage of work.



LEO:  AS8003.  How big - so you said Class C is the smallest.  Is this a Class A?  I mean, this has got to be a lot of addresses.



STEVE:  Bigger than a Class A, actually.



LEO:  Bigger than that.  Wow.



STEVE:  Yeah, now more than.  So since Inauguration Day, January 20th of this year, those who run the Internet have been puzzled by a deep mystery for which no answers were available.  It all began on that Wednesday in January when a surprising BGP message - remember Border Gateway Protocol, I'll refresh our listeners in a second - about that arrived from a previously unknown entity advertising that they would henceforth be receiving traffic - they, the entity - for all 16,777,216 IPv4 addresses beginning with 11.  So today...



LEO:  The number 11?



STEVE:  The number 11.  If it's 11-dot...



LEO:  You never see those.  You never see those 11-dots, do you.



STEVE:  There has never been anywhere for them to go.  11-dot has never been used.



LEO:  Interesting.  Don't forget that the Internet was invented by ARPA.  I mean, it was done for the Pentagon.



STEVE:  Right, right.



LEO:  So of course they're going to get whatever they want.  A giant block.



STEVE:  Right, right.  And once upon a time remember there was no competition.



LEO:  No one else wanted them, yeah.



STEVE:  HP had 14-dot and 15-dot.



LEO:  Amazing.  Amazing.



STEVE:  Yeah.  And in fact also remember that 5-dot had never been allocated, and that's why Hamachi was able to use 5-dot-anything as virtual IPs for all of the people within its peer-to-peer networking system.



LEO:  It could be routed, but it wouldn't conflict with anything.



STEVE:  Right, exactly.



LEO:  Wow.  Wow.



STEVE:  So today, more than three months later, there's still much we don't know.  But this weekend, as you referred to, Leo, we learned a bit more.  So I'm getting a little bit ahead of myself.  Here's how the Washington Post began their coverage of this mystery.  They said:  "While the world was distracted with President Donald Trump leaving office on January 20th, an obscure Florida company discreetly announced to the world's computer networks a startling development.  It was now managing a huge unused swath of the Internet that for several decades had been owned by the U.S. military.  What happened next," they wrote, "was still stranger.



"The company, Global Resource Systems LLC, kept adding to its zone of control.  Soon it had claimed 56 million IP addresses owned by the Pentagon.  Three months later, the total was nearly 175 million.  That's almost 6% of a coveted traditional section of Internet real estate, called IPv4, where such large chunks are worth billions of dollars on the open market.  The entities controlling the largest swaths of the Internet generally are telecommunications giants whose names are familiar:  AT&T, China Telecom, Verizon.  But now at the top of the list was Global Resource Systems  a company founded only in September that has no publicly reported federal contracts and no obvious public-facing website.



"As listed in records, the company's address in Plantation, Florida, outside of Fort Lauderdale, is a shared workspace in an office building that doesn't show Global Resource Systems on its lobby directory.  A receptionist at the shared workspace said Friday that she could provide no information about the company and asked a reporter to leave.  The company did not respond to requests for comment.  The only announcement of Global Resource Systems' management of Pentagon addresses happened in the obscure world of Border Gateway Protocol, the messaging system," they wrote, "that tells Internet companies how to route traffic across the world.  There, messages began to arrive telling network administrators that IP addresses assigned to the Pentagon but long dormant should now accept traffic, but that it should be routed to Global Resource Systems."



Okay.  So the stage is set for the mystery.  Let's step back and examine this from the perspective of someone who runs the Internet at the BGP level.  His name is Doug Madory,  and he's the Director of Internet Analysis for Kentik.  His recent blog posting is titled "The Mystery of AS8003," thus the name of this podcast.  And before I share Doug's description of what happened and what he saw and thinks, I'll remind our listeners about the odd BGP nomenclature.



Within the weird world of Inter-Autonomous System routing, an autonomous system - that's the AS - is said to "advertise" or "announce" that it is the destination for all Internet traffic within one or more ranges of IP space.  The claimed owner of the address space uses their own router to communicate to all the routers it's connected to using the BGP, Border Gateway Protocol.  They update their own routing tables to incorporate this new information into their routing table, and then they in turn forward any changes that they made which resulted, as a consequence of incorporating this information into their tables, to the routers they are connected to.



The upshot of this is that a so-called "advertisement" or "announcement" quickly propagates throughout the Internet, adjusting all other routers as needed, so that any packet that's dropped onto the Internet anywhere will end up being routed to and eventually arrive at the router that maintains, that is responsible for that block of IP addresses which it is now announcing.



So as we've discussed several times before, a simple slip of the finger when updating those crucial tables, or deliberate shenanigans, can raise quite a ruckus across the Internet as large blocks of traffic are rerouted from their intended destination, if in fact those IPs were active already.  And we've also talked about how, because the Internet was sort of assumed to be run by people who were responsible and careful and knew better, and after all it was all just a big experiment anyway that really wasn't known to succeed or not in the beginning, it was fine.  The point is that we still have a lot of that same architecture, and nothing has changed since then.  BGP is notoriously vulnerable and lacking in security.



Okay.  So with all that in mind, here's what Doug Madory experienced and shared this weekend.  He wrote:  "On January 20th, 2021, a great mystery appeared in the Internet's global routing table.  An entity that hadn't been heard from in over a decade began announcing large swaths of formerly unused IPv4 space belonging to the U.S. Department of Defense.  Registered as GRS-DoD, AS8003 began announcing 11.0.0.0/8, among other large DoD IPv4 ranges.  The message bore a timestamp of 16:57 UTC" - which is 11:57 a.m. Eastern - "on January 20, 2021, moments after the swearing in of Joe Biden as the President of the United States, and minutes before the statutory end of the administration of Donald Trump at noon Eastern.



"The questions that started to surface included:  Who is AS8003? Why are they announcing huge amounts of IPv4 space belonging to the U.S. Department of Defense?  And perhaps most interestingly, why did it come alive within the final three minutes of the Trump administration?  By late January, AS8003 was announcing about 56 million IPv4 addresses, making it the sixth largest Autonomous System (AS) number in the IPv4 global routing table.  By mid-April" - meaning this month - "AS8003 dramatically increased the amount of formerly unused DoD address space that it announced to 175 million unique IPs."  Okay.  So 175 million IPs is 1/25th of the Internet's entire 4.3 billion IPv4 space.



Then Doug continues:  "Following the increase, AS8003 became far and away the largest Autonomous System in the history of the Internet.  By comparison, AS8003 now announces 61 million more IP addresses than the now second largest Autonomous System in the world, China Telecom, and over 100 million more addresses than Comcast, the largest residential Internet provider in the U.S."  And I've got a graph of largest ASes by IPv4.  GRS-DoD is in first place, then China Telecom, AT&T, the Department of Defense's active network, then Comcast, China Unicom, and so on down.  So big, big, big.



He says:  "In fact, as of April 20th" - so a week ago today - "AS8003 is announcing so much IPv4 space that 5.7% of the entire IPv4 global routing table is presently originated by AS8003.  In other words, more than one out of every 20 IPv4 addresses is presently originated by an entity that didn't even appear in the routing table at the beginning of this year."  So he says:  "As a valuable asset," he said, "decades ago, the U.S. Department of Defense was allocated numerous massive ranges of IPv4 space.  After all, the Internet was conceived as a Defense Department project.  Over the years, only a portion of that address space was ever utilized," he says, "in other words, announced by the DoD on the Internet.



"As the Internet grew, the pool of available IPv4 dwindled until a private market emerged to facilitate the sale of what was no longer just a simple router setting, but an increasingly precious commodity.  Even as other nations began purchasing IPv4 as a strategic investment, the DoD sat on much of their unused supply of address space.  In 2019, Members of Congress attempted to force the sale of all of the DoD's IPv4 space by proposing the following provision be added to the National Defense Authorization Act for 2020:  'Sale of Internet Protocol Addresses.  Section 1088 would require the Secretary of Defense to sell at fair market value all of the department's Internet Protocol version 4 (IPv4) addresses over the next 10 years.  The proceeds from those sales, after paying for sales transaction costs, would be deposited in the General Fund of the Treasury.'



"The authors of the proposed legislation used a Congressional Budget Office estimate that a /8" - that is to say, that's 16.7 million addresses - "would fetch $100 million after transaction fees.  In the end, it didn't matter because this provision was stripped from the final bill that was signed into law.  The Department of Defense would be funded in 2020 without having to sell this precious Internet resource."



So he poses the question, what is AS8003 doing?  "Last month, astute observers to the NANOG (N-A-N-O-G)" - that's the North American Network Operators' Group listserv, and that's basically sort of the inner sanctum where those who run the Internet talk to each other.  He said:  "Astute observers on the listserv highlighted the oddity of massive amounts of DoD address space being announced by what appeared to be a shell company.  While a BGP hijack was ruled out, the exact purpose was still unclear until yesterday, when the Department of Defense provided an explanation to reporters from the Washington Post about this unusual Internet development."



The DoD's statement said:  "DDS (Defense Digital Services) authorized a pilot effort advertising DoD Internet Protocol space using Border Gateway Protocol.  This pilot will assess, evaluate, and prevent unauthorized use of DoD IP space.  Additionally, this pilot may identify potential vulnerabilities.  This is one of DoD's many efforts focused on continually improving our cyber posture and defense in response to advanced persistent threats.  We are partnering throughout DoD to ensure potential vulnerabilities are mitigated."



So Doug said:  "I interpret this to mean that the objectives of this effort are twofold:  first, to announce this address space to scare off any would-be squatters; and, secondly, to collect a massive amount of background Internet traffic for threat intelligence.  On the second, there is a lot of background noise that can be scooped up when announcing large ranges of IPv4 address space.  A recent example is Cloudflare's announcement of 1.1.1.0/24 and 1.0.0.0/24 back in 2018."



He said:  "For decades, Internet routing operated with a widespread assumption that ASes did not route these prefixes" - that is, the 1-dot prefixes - "on the Internet, perhaps because they were canonical examples from networking textbooks.  According to their blog post soon after the launch, Cloudflare received around 10Gb of unsolicited background traffic on those  interfaces that were announcing those two Class C networks beginning with 1.1.1.* and 1.0.0.*.  And that was just," he writes, "512 IPv4 addresses."  He says:  "Of course those addresses were very special, but it stands to reason that 175 million IPv4 addresses will attract orders of magnitude more traffic, more misconfigured devices and networks that mistakenly assumed that all of this DoD address space would never see the light of day."



So he says, in conclusion:  "While yesterday's statement from the DoD answers some questions, much remains a mystery.  Why did the DoD not just announce this address space themselves, instead of directing an outside entity to use the Autonomous System of a long dormant email marketing firm?  Why did it come to life in the final moments of the previous administration?  We likely won't get all the answers anytime soon, but we can certainly hope that the DoD uses the threat intel gleaned from the large amounts of background traffic for the benefit of everyone.  Maybe they could come to a NANOG conference and present about the troves of enormous traffic being sent their way."



And I also have some reporting from the AP.  It's sort of more gossipy in nature.  Digging down, you can of course uncover all kinds of weird things.  I'll share some of what the AP wrote.  They said:  "What a Pentagon spokesman could not explain Saturday is why the Defense Department chose Global Resource Systems LLC, a company with no record of government contracts, to manage the address space."  The AP wrote:  "The company did not return phone calls or emails from The Associated Press.  It has no web presence, though it has a domain, grscorp.com. Its name doesn't appear on the directory of its Plantation, Florida domicile, and a receptionist drew a blank when an AP reporter asked for a company representative at the office earlier this month.  She found its name on a tenant list and suggested trying email.  Records show the company has not obtained a business license in Plantation.



"Incorporated in Delaware and registered by a Beverly Hills attorney, Global Resource Systems LLC now manages more Internet space than China Telecom, AT&T, or Comcast.  The only name associated with it on the Florida business registry coincides with that of a man listed as recently as 2018 in Nevada corporate records as a managing partner of a cybersecurity Internet surveillance equipment company called Packet Forensics.  The company had nearly $40 million in publicly disclosed federal contracts over the past decade, with the FBI and the Pentagon's Defense Advanced Research Projects Agency (DARPA) among its customers.



"That man, Raymond Saulino, is also listed as a principal in a company called Tidewater Laskin Associates, which was incorporated in 2018 and obtained an FCC license in April of 2020.  It shares the same Virginia Beach, Virginia address  a UPS store  in corporate records as Packet Forensics.  The two have different mailbox numbers at the same location.  Calls to the number listed on the Tidewater Laskin FCC filing are answered by an automated service that offers four different options, but doesn't connect callers with a single one, recycling all calls to the initial voice recording.



"Saulino did not return phone calls seeking comment, and a longtime colleague at Packet Forensics, Rodney Joffe, said he believed Saulino was retired.  Joffe, who is now CTO of Neustar Inc., which provides Internet intelligence and services for major industries, including telecommunications and defense, declined further comment.  In 2011, Packet Forensics and Saulino, its spokesman, were featured in a Wired story because the company was selling an appliance to government agencies and law enforcement that let them spy on people's web browsing using forged security certificates."  And if the name Packet Forensics rings any bells for our listeners, that's why.  We spent a lot of time covering the covert use of these so-called TLS interception middleboxes, and Packet Forensics was among the purveyors of those technologies that we talked about before.  



Anyway, the AP coverage that I was quoting here finishes up, saying:  "The company continues to sell 'lawful intercept' equipment, according to its website.  One of its current contracts with DARPA is for 'harnessing autonomy for countering cyber-adversary systems.'  A contract description says it's investigating 'technologies for conducting safe, nondisruptive, and effective active defense operations in cyberspace.'  Contract language from 2019 says the program would 'investigate the feasibility of creating safe and reliable autonomous software agencies that can effectively counter malicious botnet implants and similar large-scale malware.'"



Anyway, deepening the mystery, they conclude, is Global Resource System's name.  It is identical to that of a firm that independent Internet fraud researcher Ron Guilmette says was sending out email spam using the very same Internet routing identifier.  That's where that reference to AS8003 came down.  It shut down more than a decade ago.  All that differs is the type of company.  This one's a limited liability corporation.  The other was a corporation.  Both used the same street address in Plantation, a suburb of Fort Lauderdale.



So now everyone, for what it's worth, listening to this podcast knows as much as anyone else, aside from those who do know what's going on, and those who do are choosing not to say anything on the record. 



LEO:  It's nothing.



STEVE:  It is interesting that the - what, Leo?



LEO:  It's silly.  Okay, put yourself in - okay.  You're in charge of AS8003.  Some low-level functionary in the IT department, or I don't know who is responsible for those addresses.  But somebody at some point says, you know, we really ought to make sure, you know, remember that 10 years ago somebody misused that 11-dot?  We really want to make sure nobody's got a botnet on there posing as that or using it for DDoS.  How do we do that?  Well, we can do this.  We can do a little quick BGP route and see what traffic we get, maybe run through it and see if we find anything.  Okay.  How would you do that?  Well, I don't know.  Look, we've got this shell company we always use for these kinds of things.  We've got that address down at the UPS Store in Fort Lauderdale.  We don't want to make a big deal about it.



STEVE:  Actually it's even closer to the NSA.  It's the UPS Store in Virginia.



LEO:  I guess it could be the NSA.  But don't you think the DoD has people that do exactly this kind of thing?  It's the Department of Defense.  This is their block.  I don't think it's anything nefarious.  I think they just didn't want to make a big deal about it.  They didn't want anybody to know what they were doing, especially the bad guys.  So they just ran a little operation.  What do you think?



STEVE:  My take is different.



LEO:  Okay.



STEVE:  I think - I don't think it's nefarious.  But I think it was in danger, they were in danger of losing it.



LEO:  Oh.  Because Congress might have made them sell it.



STEVE:  Yes.  They might have thought, whew.  We had a Congress that let us...



LEO:  Keep it, yeah, yeah.



STEVE:  ...get that out of the Appropriations Bill that year.  But a Biden Congress might not be so amenable.



LEO:  Oh, maybe that's why, right, right.



STEVE:  And so if we're not using it, how do we defend our need for it?  But, boy, do we want it.



LEO:  Well, how does this defend their need for it?



STEVE:  They can just say, I mean, somebody said, "Look at all of that IP space that the DoD has, and obviously has no need for."



LEO:  Right.  But this doesn't show a need for it.  This is just a security assay, basically.



STEVE:  Well, exactly.  It is absolutely.  I don't disagree with the brainstorming that has followed its allocation because you are indeed, you know, we've often talked about honeypots.  You can make the honeypot of all time.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  On the other hand, the bad guys know which IP spaces are now being forwarded to AS8003.  And Doug made a good point, too.  You just have to black hole all of that bandwidth because when you announce that much unused space, you're probably going to just be buried with packets, which you really don't want because you actually don't have any use for them right now.



LEO:  You know, Jonathan Bennett in Discord says the sensible thing.  This was signed off by the White House, probably two years before they started this.  And they didn't want to have to go through a whole process again with a new White House.  So they just said, look, if we're going to do it, we've got to do it before there's a new Secretary of Defense and all this.



STEVE:  Makes sense.



LEO:  So let's just get this over with.  It's already been approved.  The actual Secretary of Defense, Mark Esper, left a week or two before this.  He was gone.  So I bet you that it's something that simple.  And the whole thing about the reporter going down to the shared workspace and saying, hey, is this company here, and the woman throwing her out, that's just silly filler from the Washington Post.  It was just a security operation, and somebody got wind of it and made a big story out of it.  I don't - do you see any - what's nefarious about this?  This is what they should be doing.  They probably should be doing it more often.



STEVE:  I think it's just fun.



LEO:  Yeah.  Oh, no, I agree.  It's a great story.



STEVE:  Yeah.  I think it's just fun.  And what we don't know is which came first.  Did the concern about losing it since they weren't using it, did that precede, hey, you know, we could be using this.



LEO:  But they're not using it now, are they?  I mean...



STEVE:  No.



LEO:  No, they just ran a scan, basically, and downloaded terabytes of garbage data, and now they're done.



STEVE:  So what they did was they had unused space.



LEO:  Right.



STEVE:  They have always had it  Blocks of the Internet, the original IP space, were just allocated to DARPA.



LEO:  Right.  Never used it.



STEVE:  And someone said, hey, DARPA, you want 2, 3, 5 - or no, not 5 because we know that was never used.  But what blocks do you want?  And so someone said, well, you know, we'll take 11.



LEO:  We'll take 11.



STEVE:  Yeah.



LEO:  Goes to 11.



STEVE:  And they got a few other ones.



LEO:  Honestly, why are they even...



STEVE:  And they just never got around to using - they just never got around to it.



LEO:  Who cares?  They're never going to use it anyway, now that v6 is here.  They can have a trillion addresses if they want.



STEVE:  Right.  And that's too low a price, by the way.



LEO:  Hundred million?  Yeah.



STEVE:  Oh, yeah.  You could get a lot more money than that.



LEO:  A hundred million to the Pentagon, I might add, is cigarette money.  It's not...



STEVE:  Yes, yes.



LEO:  Even Congress turns its nose up at 100 million.



STEVE:  That is not going to help the budget.  



LEO:  If you have a $92 billion budget...



STEVE:  That's not even a rounding error on the general fund.



LEO:  Yeah, yeah.  That pays for the hot dog stand in the Pentagon's [crosstalk] circle.



STEVE:  Anyway, it was a fun story that lets us talk about the way the world works.



LEO:  I love the story.  Well, I'm not knocking you at all, and I love it, yeah.  I mean, it's fascinating.  But I don't think there's - do you think there's anything nefarious at all about this?  It doesn't sound like it.



STEVE:  No, no.  And I agree with you that they had some random company somewhere, and they said, oh, just hook it up over there.  We need to anchor these addresses somewhere.  Let's send them over there.



LEO:  Exactly.  And the Pentagon said very clearly, no, no, we still own the addresses.  That's not a real company.  That's just a...



STEVE:  Exactly.



LEO:  It's just a shell.



STEVE:  I just think that - I think they needed to light them up because they needed to be able to say, no, we're using those.  Don't go selling out from under us.



LEO:  It might be enough to convince Congress.  You see?  Something happened.  I guess.  Nobody's thinking about the 100 million, I think, at this point.  It'd cost you more to administer an auction.  And besides, who's buying IPv4 addresses these days?  Anybody?  Are they worth anything?



STEVE:  Oh, yeah, yeah, yeah, yeah.



LEO:  They're still precious?



STEVE:  Yeah.



LEO:  Comcast would want them.  Steve, you're always fun.  I love it.  This show is a good conversation starter if you're really a geek, I guess.  We do this show every Tuesday, 1:30 Pacific, thereabouts.  That's 4:30 Eastern time, 20:30 UTC.  If you want to watch live, we stream it live at TWiT.tv/live.  There's live audio and video.  You can chat with us live at irc.twit.tv.  You can also get on-demand copies of every show at our website, TWiT.tv/sn.  Steve's got his own copies.  He's got the unique 16Kb version.  If you don't have an IPv6 address, and you want to save some bandwidth, just get that 16Kb version.  There's also handwritten transcripts, those are probably even smaller, by Elaine Farris.  She does such a good job.  You can get all that.  Have you put up the current show yet?  Because somebody's saying, oh, 2015's still up or something like that.  I don't know.



STEVE:  Oh, did I forget?



LEO:  They said:  "He got busy with his new bride and probably forgot about us."



STEVE:  Whoops.  Yeah, actually I probably was busy with SpinRite.



LEO:  I know, that's exciting.  Getting close.



STEVE:  I'm back in the groove.



LEO:  We're getting close, yeah.  GRC.com's the place to go.  Actually, this is a good time to get SpinRite.  6.0 is the current version, but you'll get a free upgrade to 6.1.  That's what's coming out now.  And you could be an early beta tester.  You could participate in the development of it.  There's a great forum going on at his website, GRC.com.  Lots of free stuff there to highly recommend it.  SpinRite, the world's best hard drive, storage...



STEVE:  Mass storage.



LEO:  Mass storage.  I can't say hard drive anymore.  The world's best mass storage maintenance and recovery utility, works on all kinds of mass storage.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#817

DATE:		May 4, 2021

TITLE:		The Ransomware Task Force

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-817.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we touch on several topics surrounding ransomware.  We look at the REvil attack that affected Apple, and at this past weekend's attack that brought down Southern California's world-renowned Scripps Health system.  We catch up on the multinational takedown of the Emotet botnet and the FBI's contribution of more than four million compromised email addresses to Troy Hunt's Have I Been Pwned.  We also look at the two notification services that Troy now offers.  I take the opportunity to pound another well-deserved nail into QNAP, and take note of an update I just made to my favorite NNTP newsreader, Gravity.  I've also run across a Dan Kaminsky anecdote that I have to share.  Then we have two pieces of closing-the-loop listener feedback before we conclude by taking a look at the just-announced task force to combat ransomware.  Is there any hope that this scourge can be thwarted?



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  And unfortunately there's a lot of ransomware to talk about.  Scripps Health has been brought down by ransomware.  Apple supplier Quanta has also been brought down by the REvil ransomware.  And Steve's going to be talking about the Ransomware Task Force, a governmental effort to stop ransomware in its tracks.  How good can it be?  We'll find out.  That and of course a lot more security news, all coming up next.  A little sci-fi, too, with Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 817, recorded Tuesday, May the 4th, 2021:  The Ransomware Task Force.



It's time for Security Now!, the show where we cover your security and privacy online with this guy right here, Mr. Steve Gibson of GRC.com.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.



LEO:  How are you?



STEVE:  Great to be with you as we begin May.  Down here we have May Gray.  I don't know if you have May Gray in Northern California.  That's followed unfortunately...



LEO:  We do.  They call it the marine layer.



STEVE:  Ah, yes.  And it's followed by June Gloom.



LEO:  Right.  It's all summer long, let's face it.



STEVE:  Well, the summer basically tries not to happen.  So thanks a lot.  I have sort of ambivalent feelings about this, which I will articulate by the end of today's podcast.  But because it's happening, and it's a thing, I thought we had to talk about it.  And that is the recently announced Ransomware Task Force.  I also have mixed feelings about bureaucracies in general.  I'm not a big fan of endless committee meetings.  I've mentioned before that GRC got to a point where I once years later discovered an outline which I had created to prepare for meetings about our meetings.  And I realized, oh, my god, our meetings are having meetings.  So I just, like, yeah, that's not the way I wanted to run my company.  Consequently we no longer have meetings because I have almost no employees.



LEO:  Be a small meeting, yeah.  It would be very small.



STEVE:  Yes.  So, but anyway, there were a couple interesting pieces of information we haven't had before, although most of what's going on with the ransomware world is well covered.  But still worth talking about.  I wanted to sort of plant that flag so that we can then go from there and see if anything develops from it.



We're going to touch on a couple topics surrounding ransomware first.  Of course I know you've been talking about it, this REvil attack that affected Apple through one of their suppliers.  We're also going to look at just this past weekend's attack that brought down Southern California's world-renowned Scripps Health system.  Ouch.  We also are going to catch up on something that had been going on, but I was sort of waiting for the other shoe to drop to see what would happen.  That happened Sunday before last with a really interesting coordinated multinational takedown of the Emotet Botnet, which has been - like it's a huge botnet.  Somehow we just hadn't talked about it, and I'll explain why later.  But since 2014 it had been growing.



And as sort of part of that, the FBI contributed more than four million compromised email addresses to Troy Hunt's Have I Been Pwned.  We're going to follow up talking about that by looking at two notification services that Troy now offers.  And Leo, you're going to want to be poking at one of these because you can now have Have I Been Pwned check for any compromised email addresses by domain, as in *@twit.tv.



LEO:  Yeah, that's good.



STEVE:  And I did that, and I had to get my heart back under control after it returned 155 GRC.com compromised email addresses, which I'll explain.  So anyway, you can cheat and scroll ahead if you want to and be ready with how many TWiT.tv were found.  Anyway, I'm going to take that opportunity to pound - well, so we have that.  Then I'm also going to take the opportunity to pound another well-deserved nail into QNAP, the company that I've come to love to hate because they're just so bad.  Also I'm going to talk about an update I just made to my favorite NNTP newsreader, Gravity, whose source I've taken over because it had been abandoned 10 years ago.



And I ran across an anecdote regarding our ex-friend, unfortunately, Dan Kaminsky, whom we celebrated last week.  But I had to share this one little bit of fun that also arose from people talking about Dan.  We've got two pieces of closing-the-loop feedback from our listeners.  And then, as I said, we're going to talk about this Ransomware Task Force.  I'm glad it exists.  It's good that we're going to, like, an effort is being mounted.  But for reasons that we'll talk about, I'm skeptical about whether it can, whether anything can be done.  And we have a Picture of the Week that literally brought an LOL out of you the moment you saw it.



LEO:  I kind of burst out and said "Oh ho ho ho."  It's fun, totally fun.



STEVE:  Well, and frankly I'm very impressed with how quickly you got it.  I think it was instant recognition.  So no wonder you're a good chess player.



LEO:  Pattern recognition.  It's all about pattern recognition.



STEVE:  Exactly.



LEO:  Now let's see how smart they are.  Let's see how quickly they grok this.



STEVE:  Three, two, one.



LEO:  You want me to show it?  Should I show it?



STEVE:  Oh, yeah.



LEO:  And then this is the Picture of the Week.  See how quickly you get it.  Silence.  So should we describe it, Steve, for people who are listening?



STEVE:  Yeah.  So anyway, this is just fun.  I loved it.  It is a picture of the classic red Volkswagen Bug, or the Beetle, sometimes referred to as the Beetle, you know, the traditional-shaped VW Bug.  And the license plate simply says "FEATURE."



LEO:  It's a bug, not a feature.  I love it.  I wonder, you know, if the guy's driving down the street, how many people see that and go, what?



STEVE:  I was thinking the same thing.  Maybe if you were in Silicon Valley.  I don't know where this picture was taken.  But you could imagine in a sufficiently techie area people would - he'd be getting some horn toots and people appreciating the fact that it's like, it's not a bug, it's a feature, or vice versa.  So, yeah.  Anyway, perfect Picture of the Week.  So thank you, Twitter listener, follower, tweeter.  And all pictures are welcome.



LEO:  I guess you get a lot of them now in your Twitter feed.  @SGgrc is his Twitter handle.



STEVE:  Yeah.  So two weeks ago, shortly before Apple's big "Spring Loaded" product announcement event, the Sodin group, which is behind the REvil ransomware, began publicly leaking Apple's proprietary designs for its forthcoming Mac laptops.  The group's so-called "Happy Blog," as it calls itself, stated:  "In order not to wait for the upcoming Apple presentations, today we, the REvil group, will provide data on the upcoming releases of the company so beloved by many.  Tim Cook can say, 'Thank you, Quanta.'  From our side, a lot of time has been devoted to solving this problem."



Well, okay.  So Quanta, Quanta Computer, is a Taiwanese company that assembles a number of Apple laptops and other consumer devices.  I know they're watched, as well.  And I'm sure you, Leo, are more tuned up on this than I am since you get to talk to your Mac folks.



LEO:  Yeah.  They do the laptops, I think, is their - yeah.



STEVE:  Yeah.  So when Quanta initially refused to negotiate with the REvil group, Quanta Computer is a large supplier, not only for Apple, but for others.  In some of the news coverage I saw that they said "ThinkPad."  But I wasn't sure whether that one might have been a typo, or maybe they actually are doing like construction for Lenovo.



LEO:  Wow.



STEVE:  I don't know.  But anyway, it was Quanta Computer that was actually compromised by the REvil ransomware.



LEO:  It says all 10 top PC companies in the world use Quanta.



STEVE:  Yeah.



LEO:  So that's all of them, including Lenovo, yeah.  Wow.



STEVE:  Exactly.  So, and that's not the, well, it is the company that you would want to get inside if you were a ransomware gang.  And of course Apple would be particularly sensitive to the disclosure.  We know how concerned they are over leaks.  So they would be particularly concerned over this disclosure.  The ransom demand was initially posted just hours before Apple's event.  And the hackers said that they would release more documents every day, adding:  "We recommend that Apple buy back the available data by May 1st."  And a similar extortion attempt from the same group, aimed at Acer, demanded $50 million in exchange for deleting Acer's files.  And I saw the same number, 50 million, was like the opening extortion level also for the Apple stuff.



So groups throughout the Internet began grabbing and analyzing the details from the leaks, and this stuff looked authentic, and there's no reason to believe it wouldn't be.  They noted some differences with the current models on sale.  A new version of the MacBook Pro was shown without the touch bar, and it appeared that maybe HDMI ports might be staging a comeback along with SD card readers.  So, yeah, this early release was providing details that Apple would have rather been releasing themselves.



What we know of REvil from the past is that they are tough negotiators who do not make idle threats.  Of course, they don't want to acquire a reputation for not doing what they say they're going to do, or people will start ignoring them.  So they're also not known for being soft or for backing down.  So something must be going on because last week the REvil gang removed Apple's schematics, drawings, and other data from their data leak site after first warning Quanta that they would leak drawings for the new iPad and the new Apple logos, which I thought was interesting.  It's like, what?  New Apple logos?  So anyway, maybe Apple said, okay, look, Quanta, we need to stop this.



LEO:  It did get quiet.  They only released two schematics that I saw. 



STEVE:  Right.  And so what appears to have happened, for reasons we can only guess, is that Quanta finally responded to REvil and opened a dialogue.  As part of a private chat, and I think it was Bleeping Computer who posted some screenshots of that which they got somehow, REvil told Quanta that they hid the data leak page and will stop talking to reporters to allow negotiations to continue.  And REvil stated that:  "Having started a dialogue with us, you can count on a good discount."  And indeed that does appear to be the case.  Yeah, the extortion.



LEO:  Act today to save 20%.



STEVE:  Oh, no, that's exactly what happens.  So since the demand was updated, it now carries an expiration date of this coming Friday, May 7th.  But it's been reduced from the original request of 50 million down to the now much more seemingly affordable 20 million.



LEO:  See, I can't see Apple paying a penny.  And Quanta shouldn't either.  But at the same time I also could see Apple being very concerned.



STEVE:  Yeah, yeah.



LEO:  I mean, this is stuff they're going to announce in June.



STEVE:  Various researchers have been quoted saying that this appears to be a pattern.  The REvil gang apparently feels that forcing the opening of a dialogue with their victim is a crucial first step in getting paid.  So what appears to be happening is that we're seeing a pattern of them deliberately establishing a reputation for dramatically reducing their initial ransom demand upon the establishment of a dialogue.  So this asking 50 and immediately dropping to 20, that's what people are now coming to expect.



And of course I guess this provides some incentive for a victim to establish contact in order to obtain the more real ransom demand, and also of course in the process serves to break the ice.  And it's like, well, now, I mean, of course we're all put in mind of that old joke about prostitution, like okay, well, we've determined what you are, now we're just negotiating a price.  So this is the world we're in, and of course we'll be talking about this takedown task force here, or, well, the Ransomware Task Force shortly.



I did want to mention, because it's another significant event, that nearly the entire Scripps Health system, which is a world-renowned hospital network based in San Diego, was hit over this past weekend by a cyberattack which forced some critical care patients to be diverted.  And of course it's particularly galling when any healthcare provider is hit, as so many have been, representing I guess sort of a soft target for whatever reason.  Scripps acknowledged the attack in a statement, but did not specify whether it was explicitly a ransomware incident, although in some follow-on reporting everybody seemed to be assuming that, although I wasn't able to track down a specific reference to which ransomware.



It's also unknown whether the adversaries compromised any patient records or other sensitive data, "unknown" meaning just not yet public.  An email notice from the County Emergency Services Coordinator Jaime Pitner said that all four of Scripps' main hospitals in Chula Vista, Encinitas, La Jolla, and San Diego implemented emergency care diversions.  Stroke, trauma, and heart attack patients were all sent to other medical centers because they were just unable to provide for them while they were completely down.



As we know, emergencies being sent elsewhere after a ransomware attack is not unheard of by any means.  Last September employees at Universal Health Services - we talked about this at the time - which is the owner of a nationwide network of hospitals, reported widespread outages that resulted in delayed lab results, a fallback to pen and paper by patient care, as well as patients being diverted to other hospitals.  In that case, the culprit was Ryuk, which locked up hospital systems for days.



And one of the interesting stats that we'll get out of this task force is the average number of days that ransomware brings systems down.  A nurse within the Scripps system wrote that:  "No patients died tonight in our emergency room.  But," she wrote, "I can surely see how this could happen in large centers due to delay in patient care."  And according to reports, outages are widespread across the whole Scripps system.  The San Diego Times-Union newspaper reported that the cyberattack disrupted the organization's backup servers in Arizona; the MyScripps online patient portal was taken offline; and Monday, yesterday, appointments were being postponed.



So the day-to-day activities of staff had also been compromised.  Nurses, doctors, and other personnel have resorted to using manual processes and paper records since the electronic health record system was also disrupted.  And we know that's something that also happened after the UHS attack.  So, oh, also the telemetry being used in real-time at most sites, which is used for electronic monitoring and alarming, heart monitors for instance, had become inaccessible.  Scripps said that regular manual checks would then be required because they could no longer count on their telemetry system, which was down.  A source told the newspaper that medical imaging and other resources had been affected.  So this was a big, comprehensive outage.



The Scripps statement said that, while the systems were offline, "patient care continues to be delivered safely and effectively at our facilities" - not conveniently, but yes, they're managing to work around this - and, they said, "utilizing established  backup processes, including offline documentation methods."  And of course they're attempting to put the best face possible on this nightmare which has been deliberately perpetrated by almost certainly attackers located in - what we're seeing is they're probably in Russia or China.  And we'll be talking about that again at the end of the podcast.  And, you know, there's a sense of you've seen one ransomware attack, you've seen them all.  But I don't think we should allow ourselves to become complacent about these attacks, and numb to them.  The question of course is what, if anything, can be done.  So that doesn't look like there's an answer for that at this point.



But speaking of what can be done, on the topic of massive and pernicious botnets, somehow we've really never stopped to take notice of Emotet.  Perhaps it's because from one standpoint it was just another botnet, and we've certainly spent a lot of time  talking about botnets in general through the years, though Emotet has not remained "just another botnet."  And so I guess while it was on the rise, we were a bit botnet saturated.  But something big has been happening.  At the beginning of this year, in an effort named "Operation Ladybird," a coordinated global operation which included the law enforcement authorities from Canada, France, Germany, Lithuania, the Netherlands, Ukraine, the U.K., and the United States.  All worked together to take control of the hundreds of botnet servers which were supporting the Emotet botnet network.



And they didn't stop there.  Since at one point as many as 1.6 million active bot infections were believed to be active, there was a need to then proactively disinfect those infections.  We're finally talking about Emotet today because Sunday before last, on April 25th at 1:00 p.m., that was the date and time set inside a replacement DLL that had previously been injected network-wide after the takedown, and I'll explain in more detail in a minute.  But at that moment, Sunday before last, more than one million Emotet bots synchronously shut themselves down forever.  Okay, but I'm getting ahead of myself.



LEO:  Wow, that's cool.  I mean interesting, yeah.  Synchronized bots.



STEVE:  Okay.  So let's back up a bit and examine the history of what has been literally a historical and unique network.  Trend Micro was the first group to detect and profile the original Emotet trojan back in 2014, shortly after it appeared.  What they discovered then was at the time a relatively straightforward banking trojan spread by phishing emails.  And banking trojans sit in a user's machine - we've talked about them often - patiently waiting for connections to known banking systems.  When this is seen, they capture and forward the user's banking authentication credentials, sending them to their bot masters, who then typically empty the unwitting user's account.



Or another thing they might do is, while the user believes they're actually performing some generic standard banking transaction, like log into their bank account and then just do something as benign as check their balance, what these trojans are able to do is establish a shadow connection, using their credentials, to their account.  And as soon as they navigate away from the page, that trojan will then transfer, issue on their behalf a transfer of all of their funds to some offshore account somewhere.  And then people report, you know, wait, next time they check or a check bounces or something, where did all my money go?  Well, it went to a banking trojan.



So as we've always seen, cybercrime has evolved from just sort of a "can we make worms propagate" lark into something which started making money for the bad guys.  And of course as soon as the bad guys could start making money, as they said, there's money in them thar hills, and that changed the entire nature of cybercrime.



Okay.  So through the intervening years since 2014, because this thing was succeeding, it also evolved multiple times.  Over time, it grew into a mature and huge Malware as a Service botnet, offering access to its compromised endpoint bots for those wishing to pay.  And unfortunately there were many who wished to pay.  Among them were famous ransomware groups such as Ryuk, and those also pushing their own data-stealing trojans such as Trickbot.  They quickly made the most of the initial access provided to them for pay by the Emotet network, picking and choosing into which victims they would deploy additional payloads.  And Emotet was used by the so-called TA542 threat group, also known as Mummy Spider, to deploy second-stage malware payloads such as Qbot and Trickbot.



It also usually led to full network compromise and often the deployment of ransomware payloads across all infected systems, which a compromised endpoint would allow.  So ransomware like ProLock or Egregor by the Qbot people, or Ryuk and Conti by Trickbot.  So this was a big problem.  And because we were talking about more than a million endpoints, it was actively being tracked.



This growing and enduring success of Emotet demonstrated among other things the potential of success through nothing more than relatively straightforward phishing campaigns that were the main way that this infection was spread; or, that is, you know, injected into people's computers.  It also highlighted the evolution and growing sophistication of the cybercrime economy which was developing its own specialized supply chain.  And once inside a single machine, Emotet evolved the ability to then spread laterally to other devices on a network, which made it among the most resilient pieces of malware which had been seen in recent times.  All instances of Emotet within a network needed to be killed simultaneously because a single surviving instance would quickly reinfect all other reachable machines.  So it was a big nightmare.



Recently, Trend Micro stated that it had grown into one of the largest threats they monitored over the past 10 years, consistently in the top 10 campaigns detected; and with, as I said, according to the U.S. Department of Justice, more than 1.6 million victim machines.



Okay.  So at the beginning of this year, 2021, after a very quiet multinational organization, a law enforcement group that had assembled to deal with this global threat was ready, and they made their move.  In a coordinated takedown strike this past January, control was taken over the IP addresses of the network's command-and-control servers located throughout more than 90, nine zero, different countries.  In coordination with cybersecurity experts, replacement servers were connected to the individual IP addresses of the Emotet's command-and-control machines, hundreds of them, many of them which were themselves hacked PCs which the Emotet gang had been using to manage the botnet and send instructions to its 1.6 million victim endpoint botnet machines.



A security researcher who was involved in the operation said:  "We took over every critical C2 [command and control] top, down, left, right.  From that point on, if a victim machine reaches out to one of my servers or our partners' servers, they're going to get a payload that's inert and prevents further communication with the original botnet."  It's over.  Or was it?



Previous botnet takedown operations have had mixed success, with the cybercriminals often being able to rebuild their networks rather quickly after a takedown attempt, which were enabled, this rebuilding, by built-in fallback communications channels.  So, for example, a prior attempt to neuter the Trickbot botnet is believed to have resulted in only a short-term setback for its operators, who have since developed new versions of their malware and made progress toward rebuilding.  But the good guys had been learning, too, lesson after lesson after lesson.  So again, we're in that Spy vs. Spy mode or, yeah.



In their statement about the Emotet takedown, Dutch police noted that they discovered and disrupted the infrastructure's backups, too, which they hope will make a possible reconstruction of Emotet very difficult, if not impossible.  The security researcher who participated in the takedown confirmed that the operation also monitored the hackers' backup processes to ensure that there were no unknown hidden recovery techniques.  And he believes that all backups were disrupted.  He said:  "We found their backups and how they used them, and we took all of them, too."  So, he said:  "It's going to be very hard, if not impossible, for them to recover.  And even if they do, we have other tools up our sleeve to combat that."



And indeed, since the January takedown, Trend Micro has reported that there has been no Emotet activity.  They said they still observed some detections, since it's nearly impossible to erase all traces of such a massive infection immediately upon takedown.  But as residual infections continue to be cleaned up, they expect to see a gradual elimination of the threat completely.



After the takedown operation, with the redirection of the network's command-and-control server IPs to law enforcement control, authorities then pushed a new configuration to the million-plus active Emotet infections so that the malware would then begin to use permanently command-and-control servers permanently controlled by Germany's federal police agency.  So essentially they did a transient IP redirection that allowed them to then push changes to the infections which then told the infections to change the IPs that they subsequently got instructions from, thus permanently commandeering the dynamic Emotet botnet.



Once that was done, every Emotet infection was updated with a new benign Emotet module, which was a 32-bit EmotetLoader.dll, literally, E-M-O-T-E-T-L-O-A-D-E-R dot D-L-L.  That was inserted into all infected systems.  And that's the thing that had the April 25th time bomb.  This is what caused the entire network of more than one million instances of infected machines to synchronously become inert Sunday before last at 1:00 p.m.  At that moment the Windows server startup and autorun registry keys were deleted network-wide, and the services self-terminated, and it was over.



Now, two security researchers with Malwarebytes examined the uninstaller module, this thing that was delivered by law enforcement to the now-under-their-control Emotet bots.  They did this ahead of time, so they changed the system clock on a test machine to April 25th, 2021, to this trigger moment and confirmed that it only deleted associated Windows service definitions and autorun registry keys, then terminated itself.  It leaves everything else on the compromised devices untouched.  They did this because, as we saw with the FBI's Exchange Server decontamination that we talked about a couple weeks ago, messing with somebody else's computer is a concern.



Marcus Hutchins, whom we know well on this podcast, has tracked Emotet and other botnets for years.  Marcus warned that anyone whose machines were infected should be careful to clean their systems despite the Emotet takedown.  He cautioned that they could still be hit with secondary malware that Emotet's partners may have previously downloaded into their computers like Trickbot or Qakbot.  So anyway, people are still feeling a bit touchy about the idea of law enforcement being this proactive.



So I suppose this is going to be take some getting used to.  As I mentioned, the FBI's subsequent disinfection of U.S.-based Exchange servers was not without controversy.  And in this case, not everyone was completely bullish, even on the Emotet takedown.  Malwarebytes' CEO told BleepingComputer in an interview:  "For this type of approach to be successful over time, it will be important to have as many eyes as possible on these updates; and, if possible, the law enforcement agencies involved should release these updates to the open Internet so analysts can make sure nothing unwanted is being slipped in."



Well, it's nice to wish for that.  On the other hand, it really needs to be done in secret because secrets are very difficult to keep.  One of the stories I had hoped to get into today's podcast, but I'll catch up with it next week, there just wasn't room, is Microsoft's serious concern that it was their sharing with their industry-wide partnerships that may have led to the early leak of the details of the Exchange Server flaws, which is responsible for it getting loose before they had patches ready.  Anyway, we'll talk about that next week.



But that all said, the Malwarebytes CEO said:  "We view this specific instance as a unique situation and encourage our industry partners to view this as an isolated event that required a special solution and not as an opportunity to set policy moving forward."  Again, as I said, the concern when this all surfaced about what the FBI did and even here the concern being voiced is people are not comfortable with law enforcement doing essentially what the bad guys have done.  My take is we're going to have to get comfortable with it because otherwise law enforcement's hands are tied, and of course the bad guys' hands are not tied.



Intervention is never something that the intervened welcomes.  But it's often the only way to solve a problem.  And I suspect we're going to be seeing more of it in the future.  The Emotet botnet established itself through highly effective email phishing campaigns.  Unwitting users clicked on links, which ran macros to infect their machines.  So Emotet was being invited in.  If we deliberately tie the hands of law enforcement to prevent this sort of lawful remediation, a very effective means for kicking it out of, in this case, 1.6 million infected machines will be lost.



And I'm not arguing that the Malwarebytes CEO was wrong in saying it absolutely has to be done very, very carefully and safely.  For example, you would never want to do something that bricked 1.6 million infected machines.  But it's certainly possible to test this, and I'm sure it was tested extensively before it was actually done for real.  So, yeah, it's dicey, but I think it needs to happen.



So, okay.  Among the things that the Emotet botnet was doing was acquiring email addresses.  And in a related public/private partnership, the Dutch authorities and the U.S. FBI have provided, get this, 4,324,770 unique email addresses known to have been compromised and used by the Emotet botnet to Troy Hunt's Have I Been Pwned database service.  Here's what Troy had to say about this last Tuesday.



He said:  "Earlier this year, the FBI, in partnership with the Dutch National High Technical Crimes Unit (NHTCU), the German Federal Crime Police Office (BKA)" - and I can't pronounce that B in German.  I looked it for a while, and I thought, no - "and other international law enforcement agencies brought down what Europol referred to as the world's most dangerous malware:  Emotet.  This strain of malware," writes Troy, "dates back as far as 2014, and it became a gateway into infected machines for other strains of malware ranging from banking trojans to credential stealers to ransomware.  Emotet was extremely destructive and wreaked havoc across the globe before eventually being brought to a halt in February."



He said:  "Following the takedown, the FBI reached out and asked if Have I Been Pwned might be a viable means of alerting impacted individuals and companies that their accounts had been affected by Emotet."  He said:  "This isn't the first time HIBP has been used by law enforcement in the wake of criminal activity, with the Estonian Central Police using it for similar purposes a few years earlier.  In all, 4,324,770 email addresses were provided which span a wide range of countries and domains. The addresses are actually sourced from two separate corpuses" - would that be corpi?  Anyway, "corpuses of data obtained by the agencies during the takedown."



First, email credentials stored by Emotet for sending spam via victims' mail providers.  Okay.  So among other things, Emotet was a spam agent; right?  It sat on victims' computers and used their configured email providers to send out the phishing emails to others.  And of course oftentimes it would also compromise their address book, so the email that was outgoing appeared to be coming from people that its recipients knew, meaning the infected victim.  And the second source was web credentials harvested from browsers that stored them to expedite subsequent logins.  And of course that's something that's always made me a little uncomfortable about storing authentication information in our web browsers is that let's hope that bad guys don't figure out how to get in there.



So Troy wrote:  "We discussed loading these into HIBP" - "we" meaning he and the FBI and Dutch authorities - "as two separate incidents so they could be individually identified.  But given the remediation is very similar, they've been loaded in as a single breach."  One of the cool things about Troy's Have I Been Pwned is it identifies which breach was associated with the various pieces of information.  So, okay, so at this point in Troy's blog I'm skipping the standard "change your password" advice and so forth.  He has all that.  But I wanted to quote one interesting tidbit that he wrote.  He said among his things to do to keep yourself secure was:  "Keep security software such as antivirus up to date with current definitions."  Troy Hunt wrote:  "I personally use Microsoft Defender, which is free, built into Windows 10..."



LEO:  Interesting, oh.



STEVE:  Yes.



LEO:  Yeah, I agree with him, but that's really good to hear him say it.



STEVE:  Yup.  And our listeners know that's what you and I have come down finally, Leo, is that it's just...



LEO:  You don't need anything more.  You just...



STEVE:  And other things cause more trouble than they're worth.



LEO:  Exactly, yeah.



STEVE:  Yeah.  Anyway, he said, so it's free, built into Windows 10, and updates automatically via Windows Update.  So that's an interesting data point from Troy.  He concluded:  "I've flagged this incident as 'sensitive' in HIBP" - again, Have I Been Pwned - "which means it's not publicly searchable.  Rather, individuals will either need to verify control of the address via the notification service or perform a domain search to see if they're impacted."  And I'm going to explain all that.  He said:  "I've taken this approach to avoid anyone being targeted as a result of their inclusion in Emotet.  All impacted HIBP subscribers have been sent notifications already."



Okay.  So the normal thing you do is for non-, what did he call it, sensitive, for non-sensitive issues is you put your email address in, and that's all that you have to do.  You click Have I Been Pwned, and it says no, there's nothing here.  But of course that allows you to put any email address in, and thereby use Have I Been Pwned to probe whether that email address may have been used in previous attacks.  They didn't want to do that here.  So there's two URLs.  Have I Been Pwned, of course, is H-A-V-E-I-B-E-E-N-P-W-N-E-D dot com.  So you do /NotifyMe.  That's the standard single email address signup.  I've signed up using, before I did the next thing, which was even cooler, I put in a couple of my recent email addresses.



LEO:  This isn't the wildcard one.  This is just a regular address.



STEVE:  Correct, yeah.



LEO:  Okay, got it.



STEVE:  This is for people who do not have control of their own domain.  So like if you're a Gmail user, or Yahoo, or your own local ISP, but not this is my domain dot com.  Then you use this.  So you put your email address in, or any that you have been using recently, or back through time, I would say any that still matter, because it needs to be an address on which you still receive email because, when you put it in, you receive at that address a confirmation email which you have to click in order to confirm.  And when you click, it takes you back to Have I Been Pwned with the results of whether or not that email address exists in any of the Have I Been Pwned databases, including this one.  So again, HaveIBeenPwned.com/NotifyMe.



Okay.  One thing Troy did not mention in his blog posting, but I saw it elsewhere, was that 39% of the email addresses provided by law enforcement from the Emotet takedown had already been indexed as part of other data breach incidents.  So nearly 40%, 39% of email addresses weren't being well-managed by their users, and they'd already been participating in breach events.



Okay.  Now, the domain-wide notifications is very cool.  So it's the ability to provide domain-wide notification of any and all past and future breaches.  So, for example, TWiT.tv or GRC.com.  What I did was I created an alias, a notification alias, because I use aliases a lot since I control my own email server.  I created a permanent notification alias where I will receive notices.  And, okay.  So when I registered, I immediately, as I said, received a sobering list of 155 email addresses.



But first I'll explain about registration.  I would strongly recommend that anybody who has control of their own domain should register with this service.  I just can't imagine why you wouldn't.  If you want to, create an email alias for yourself.  So you then need to prove control over your domain with - Troy provides four ways:  email, web, or DNS.  For email, you'll need to be able to respond to an email sent to, and you get to choose, security at your domain, hostmaster at your domain, postmaster at your domain, or webmaster at your domain.



Or you can add a custom meta tag to the root web page at your domain.  And it's, you know, <meta name="have-i-been-pwned-verification" value="long unique token that he provides">.  Or you can place a file named "have-i-been-pwned-verification.txt" onto the root of the domain containing a specific verification text string.  Or you can add a specific text record to your domain's DNS of the form "have-i-been-pwned-verification=blah blah blah," you know, that same unique string.



And then when you've done one of those, you then say "verify me."  And Troy's server will go out, look at your home page, go try to grab that text file from the root of your website, pull a DNS query of your text records and see if the verification string is there, or send you email to one of those four addresses, which you then confirm. 



So I did that.  And as I mentioned, after regaining control of my cardiac sinus rhythm following seeing 155 email addresses within the GRC.com domain - oh, and he provides them as a web page on his site, as a spreadsheet, somehow I got it as a spreadsheet, or as a JSON file.  So you can get it in any of three formats.  I settled down to see what was being seen.  With a domain like GRC.com, which has been around for so long and which has earned a strong reputation for never having been a source of spam, it's desirable for use by people who are trying to spoof email addresses because they just figure they'll be taken more seriously.  So it appears that individuals or bots have used a bunch of always bogus GRC.com "accounts," in quotes, that have never belonged to us, and for which email has never been sent or received.  But at the same time, that list also contains a bit of a walk down memory lane.



LEO:  I don't know if I want to open this.



STEVE:  Uh-huh.



LEO:  Oh, boy.  Do it off camera, yeah.



STEVE:  That's right.



LEO:  Oh, look at that.  No results found.  But not for TWiT.tv.  Not for TWiT.tv.  I was using my own personal domain.



STEVE:  Oh.  Oh, oh, oh, okay.



LEO:  Which that would make sense nobody would be - that's why I'm not showing it on the screen.  Nobody knows what it is.



STEVE:  Right, right, right.  So I found chromazone@grc.com.



LEO:  Love it.



STEVE:  Which, you know, that was an email address I used a long time ago.



LEO:  Oh, it was a real address, though.  Wow.



STEVE:  Oh, yeah, because Chromazone was the way I taught myself Windows.  I wrote that beautiful, if I do say so myself...



LEO:  Oh, I remember that, yeah.



STEVE:  That screen saver.  At the time that flying toaster screen saver, can't remember the name of it...



LEO:  Flying Toaster.



STEVE:  After Dark.



LEO:  After Dark, yeah.



STEVE:  After Dark.  They had, I don't remember now how many, like it was megabytes in size, and you got 11 screen savers.  Mine was, I think it was a few hundred K, and it came with 400 screen savers because it was a screen saver construction set.  I provided you with this editor that allowed you to define and design your own screen savers.  Anyway, I called it, of course, Chromazone because it was very colorful.  And Troy's site showed that River City Media Spam List and Verifications.io were two breaches where that email address was disclosed.



Also cih@grc.com.  That was the virus; remember?  CIH was that virus which wiped out the first megabyte of people's hard drives.  And I didn't want to charge anything to fix it because it wasn't anybody's fault.  So I wrote a custom tool which basically resurrected the entire first megabyte of someone's hard drive in order to reverse the effects of that.  Also cod@grc.com.  That was the way you and I first met, Leo, Click of Death.



LEO:  Oh, yeah.  Yeah, yeah.



STEVE:  Yeah.  And so that one was exposed in the Data Enrichment Exposure From PDL Customer.  Also the River City Media Spam List and Verifications.io.  Not surprisingly, greg@grc.com.  We have not used our first names at GRC.com for years.  Once upon a time I was steve, Greg was greg, and Sue was sue.  But you just can't use a first name at any domain.



LEO:  First name, short first name, bad.



STEVE:  Yes.  So, and Greg was there because he would be responding as a tech support provider.  Therefore his address would be in all of the email boxes of all of our customers.  And so, yeah, it just got loose.  Also s.gibson@grc.com.  I don't remember ever using that, but I guess I must have.  Sgibson@grc.com.  Sales@grc.com.  Steve, as I mentioned, and Sue.  So anyway, so but those, what, one, two, three, four, five, six, seven, eight, nine, there were nine real ones out of 155.



LEO:  So the rest were just like joe@grc.com and stuff.  



STEVE:  Exactly.  And we never had a Joe.  And aaa@grc.com, and just random crap.  So anyway, very interesting.  And again, the beauty of registering domain-wide is now, if any email address I'm using or Sue's using or Greg's using appear newly in Have I Been Pwned, I will receive a proactive notification saying, hey, this email address for your domain just got breached.  So that's super cool.  And I would imagine it would be of use to any of our listeners who are responsible for their own enterprise's email.



We know I don't like QNAP.  I started off being...



LEO:  It's funny because they're really big.  And I think people like them.  But I'm glad I use Synology after hearing all about this.



STEVE:  Boy, are you glad, Leo.



LEO:  Yeah, yeah.



STEVE:  You don't know how glad you are.



LEO:  Yeah.



STEVE:  Yeah.  I've said it before, but sadly it's worth reminding everyone due to recent events.  At this point I'm pretty sure that I will never like nor recommend the use of QNAP's products for any purpose.  Maybe if you needed an anchor for your fishing boat, you know, because if it dragged along the bottom it would be pretty good to hold your boat in place.



LEO:  That and your bitcoin hard drive, you're set.  Sorry.



STEVE:  Ouch.  So time and again the company has demonstrated itself to be just too irresponsible.  They have a well-established track record of ignoring security researchers' reports, despite the researchers' responsible attempts to get them to respond within like 90 days or a reasonable length of time.  They just do nothing until there's like a catastrophic event affecting their users.  Nor do they fess up when they're confronted with reality.  They obliquely referred in this instance to a "improper authorization vulnerability in HBS 3," which is their Hybrid Backup Sync offering.  Well, it certainly is.



But it would be more correctly described as yet another hard-coded firmware backdoor credential that was discovered as they will all inevitably be.  And it's been widely exploited by multiple breeds of ransomware, where there is now a feeding frenzy competition to see which can be the first one to get in and encrypt all of a user's data.  Despite only asking 500 USD equivalent in bitcoin for the decryption key, there's clearly no safe way to have any QNAP device publicly exposed to the Internet.  And now QNAP themselves have begun recommending that their own users should not run on the default port of 8080, but should rather attempt to hide their services elsewhere. 



LEO:  That's no good.  That's terrible.



STEVE:  I know.  Among the 65,000 other ports because, that's right, if you can't make it secure...



LEO:  Just hide it.



STEVE:  ...then at least make it obscure.



LEO:  Yeah.  Oh, god.



STEVE:  No, thank you.  No, thank you.



LEO:  That's not a solution.  The fact that they even suggested that tells you they have no good fix.



STEVE:  Yes.  And they actually do say, you know, put it somewhere else.  Boy.  Yeah.



LEO:  Yikes



STEVE:  So last time we talked about this I said, if you must use it, if you've got the hardware, move it inside.  Don't expose any of it to the public Internet.



LEO:  You'd be safe then; right?  I mean, because it's, you know...



STEVE:  Safer, yeah.  And if there's alternative firmware, I don't know if there's like a different way, if you can run FreeBSD or Linux.  I would say, if you own the QNAP hardware, dig around, see if you can put a real operating system on it and still get the benefit of its mass functions.  That would be a cool solution, if that's possible.



Okay.  I did want to mention to our listeners that since last week I updated the Gravity Windows NNTP Newsgroup Newsreader.  It was at 3.0.10.  It's now 3.0.11.  Somewhere last week somebody posted a screenshot from their, shoot, I want to say Unisys, or Unison, from their Unison newsreader, which crashed Gravity.  A number of us who are Gravity users clicking on the link, it just terminated.  It just disappeared from the screen.  It turns out there was a bug in the multipart MIME decoder.  So I spent an enjoyable couple hours digging into the source, finding the point that was crashing as a consequence, I mean, there was nothing wrong with what the Unison newsreader was posting.  Gravity just had a mistake.



So I fixed it.  Just wanted to let our listeners know.  There's now two entries over in GRC's files page, our freeware page, and also on the discussions page, one for a full new install of Gravity, which now incorporates this new update, and also just Gravity EXE, which is only the updated, because it's only one file that changed.  So if you already have Gravity installed, just grab the EXE and move yourself to 3.0.11.



And as I promised, something fun I had to share about Dan Kaminsky.  I know we spent plenty of time remembering him last week.  But this anecdote from his early life came up that I knew our listeners would appreciate.  As we know, Dan was a respected practitioner of pen testing, right, penetration testing being the art of compromising the security of computer systems at the request of their owners who wisely wish to harden their systems from attack by inviting a skilled hacker like Dan to see whether that skilled hacker is able to get in.



According to Dan's mom, Trudy Maurer, M-A-U-R-E-R, he began developing his knack - now, of course this is coming from a mother's loving eyes - when he was a four year old in San Francisco after his father gave him a computer from Radio Shack.  We don't know that it was a TRS-80, but one imagines.  She said by the age of five he had taught himself to code.  And at one point his childhood paralleled "War Games," which of course we all remember the 1983 movie starring then teenage Matthew Broderick, who unwittingly accesses a U.S. military supercomputer.  Well, it turns out...



LEO:  "Shall we play a game?"



STEVE:  What was the name of it?  It was a...



LEO:  WOPR.



STEVE:  WOPR, yes, WOPR.  When Dan, his mother says, was 11, she received an angry phone call from someone who identified himself as a network administrator for the Western United States.  The administrator said someone at her residence was "monkeying around in territories where he shouldn't be monkeying around."  It seems that Dan had been examining military websites.  The administrator vowed to punish him by cutting off the family's Internet access.  Mrs. Maurer warned the administrator that, if he made good on his threat, she would take out an advertisement in the San Francisco Chronicle denouncing the Pentagon's security.  Mrs. Maurer recalled telling the administrator, "I will take out an ad that says, 'Your security is so crappy, even an 11-year-old can break it.'"  They settled on a compromise punishment:  three days with no Internet.



LEO:  What a good mom.  I love it.  She stood up for her kid.  That's great.



STEVE:  She said, okay, yup.  And actually she's a CEO, so I would imagine that, yeah, it's probably being remembered correctly.  Several decades later, after Dan's comprehensive presentation in August of 2008 at Black Hat of the DNS meltdown that his work and then the industry's work were instrumental in avoiding, he was approached by a stranger from the Black Hat audience.  It was the administrator who had caused him to lose three days of Internet access when he was 11.  He wanted to thank Dan personally, and to ask for an introduction to "the meanest mother he ever knew."



LEO:  For purposes of pen testing?



STEVE:  Anyway, very cool story.



LEO:  Oh, I see what you're saying.  The meanest mother, his mom.



STEVE:  Yes.  His own mom.



LEO:  I know, okay, I was extending the word "mother" beyond the point.



STEVE:  Right.  His actual mom.  



LEO:  His actual mom, yes.  Now I get it.



STEVE:  Yes, yes.  Yeah, he had never forgotten that he got chewed out by the 11-year-old hacker's mother.



LEO:  Yeah, don't mess with mama.  Isn't that great?



STEVE:  And backed down to...



LEO:  Yes, ma'am.  Yes, ma'am.  How about three days, ma'am?



STEVE:  She'll tell him he can't play with his computer over the weekend.



LEO:  Yeah, I think - so many great stories about Dan, of course, upon his death, and that's one of them.  We actually  talked about it on Sunday.  He had a great mom.  She deserves credit.



STEVE:  So two pieces of closing-the-loop feedback.  Makdaddy sent:  "@SGgrc Please don't fancy up SpinRite 6.1 UI.  We love the simplicity of ASCII characters for UI.  It's super retro and uber cool."



LEO:  Super AND uber.  Whoo.



STEVE:  Okay.  And I don't know whether something I said may have given the impression that I might be changing anything.  I guess that I was talking about updating a bunch of SpinRite screens with the additional data that SpinRite now has available, and that I've also added some new stuff.  And I did note that earlier I was worried that those familiar with SpinRite 6 might not notice anything new and different, but that that was no longer any worry.  But for what it's worth, I'll definitely be keeping SpinRite's longstanding textual UI.



It's not that I couldn't do or that it couldn't do with a major rework and a move to a bitmapped interface from this century, but mostly that SpinRite is all about performance rather than appearance.  If I could have both in the same timeframe, sure.  That would be great.  But given a choice, since what we have now for a UI works, what it does is the only thing I'm focused on.  So, yeah, we get to keep our what did he call it, super retro and uber cool user interface.



LEO:  It's actually kind of all the rage in Mac and Linux and Unix communities.  They call it a TUI, a Text User Interface.  And I have a lot of TUI apps instead of GUI.  You don't have all that overhead of a window manager and all that stuff.  And it's perfectly informational.  It works great.  And I agree.  I think you've done a good job, that it's really easy to understand.  You use colors really well.  A lot of the TUIs I use don't use colors nearly as well.



STEVE:  Yeah, it is really colorful, yeah.  Secondly, Henrik Schack said:  "Hey, long time ago you talked about a very, very long sci-fi series, currently," he said, "14 to 15 books, supposed to be 50 plus."



LEO:  Oh, I know what you're talking about.



STEVE:  Yup.  And so does JammerB.  He said:  "I have forgotten the name.  Can you help?"  So we haven't talked about sci-fi much recently, mostly because I've been stuck on my current absolute favorite series, which is what Henrik was asking about.  It is, of course, The Frontiers Saga by Ryk, spelled R-Y-K, Brown.  And I'll just say that it's a straight-up unapologetic space opera.  It's wonderful pulp sci-fi.  But what I think distinguishes it from so many others is that it's written well enough that I never find myself wincing.  A book I was reading years ago kept referring to the "stygian" blackness of space.  And that would have been fine once.  But this author apparently had no other word for black.



LEO:  Yeah, no, sorry, such a clich.



STEVE:  So he kept using "stygian."  And it just - it became tiresome very quickly.  Ryk has a real talent for creating very clear and very well-defined characters.  And once they've been established, he never - and for me this is critical - he never asks them to do something they wouldn't.  Since reading science fiction, or any fiction, is all about building an alternative reality model, the last thing you want is for characters who have been so well and carefully crafted to act out of character.



So anyway, it's just a joy to read this.  The Frontiers Saga is one continuous story, or the planned saga.  I hope he has a chance to finish it.  It's in five broad arcs of 15 books each.  So far, the first two 15-book arcs have been completed and published.  And I've read all 30.  I've re-read the beginning set while waiting for the second set.  And I'll confess that I am currently rereading them all again.  I love to read.  And as I reread them, knowing what's coming and how significant this or that newly introduced character will wind up being is fun.  It's neat watching everyone else getting to know them for the first time.



Ryk was hospitalized due to complications from COVID-19, which I was worried may have thrown off his schedule a bit.  But he's been working all year.  As it happens, he just posted this May 4th morning, stating, he says:  "I guess I'd better say something, lest I find my picture on the side of a milk carton."  So followed by a summary of what's going on, which he posted.  Anyway, he's wrapping up a standalone novel, which will be titled "The Fall of the Core," and then plans to have the third series begin, starting to appear this summer.  He likes to have a few written ahead of time so that he can sort of do an every three to every four month rate.  He started in 2011, so basically 10 years ago.  He's got 30 books out in that period of time.  So, what, he does three a year, so about one every four months.  He was also quite - what?



LEO:  Nothing.  That's just a lot of books.  It's a lot of writing.



STEVE:  It's a lot of writing.  And that's why I hope he does it, like...



LEO:  It's the Augean stables where the, yeah, okay, the labors of Hercules.



STEVE:  I hope he doesn't, like, burn out on this because he's got a bunch of threads which I would love to see him tie up.  He was also quite unhappy with his books being available through Amazon's Kindle Unlimited plan.  So he has stated that only these first two 15-book arcs, meaning a total of 30, will be there.  I'm sure I'll buy them wherever they appear, though I hope Amazon will be able to at least offer them for sale, if not as part of their Kindle Unlimited plan, since Kindle is far and away my preferred reading platform.  For the time being, for those who don't know, all of those first 30 books are free to read as part of the Kindle Unlimited plan, which is $10 per month, and authors are reimbursed...



LEO:  Means he gets nothing.  Right?  How much does he get?  Nothing.



STEVE:  Well, I looked.  And it looks like maybe a 10th of a penny per page read.



LEO:  Oh, geez.  Oh, per page.  Well, he's written many thousands of pages, so that ain't bad.



STEVE:  Yes.



LEO:  That's all right.  Okay.  



STEVE:  Yeah.  So anyway, I will post a note, I mean, I'll just make a note.  I'll let our podcast listeners know so that JammerB doesn't miss it when the third series begins.  But it's not going to be for a few more months.



LEO:  Brett in our chat room is suggesting that he gets paid by the word, and that may be the case.  I don't know.



STEVE:  No.  I did look.  I did look.  And the Kindle Unlimited plan makes the royalty reimbursement system very clear.  What I did find interesting, though, it isn't books you check out.  It's books you actually page through.



LEO:  So you have to - yeah, that's why it's by the page.  Yeah, that makes sense.



STEVE:  By the page read.



LEO:  That makes sense.  So is there a series we should search for?  That'd probably be the fastest way to find it; right?  Search by series?  Because you want to get the first book.



STEVE:  Oh, yeah, yeah.  You have to.  It's called "Aurora" is the very first book.  But if you just google "The Frontiers Saga."



LEO:  Frontiers Saga, Aurora.



STEVE:  Frontiers as plural.  Well, yeah, the Frontiers Saga, Aurora.  And I just, you know, I didn't want to take too much time on this, so I sort of rushed through it, but it is really good.  I mean, it's not Peter Hamilton; right?  That's a caliber all on its own.  On the other hand, Peter's books, I will never reread whatever it was he just last put us through because it was a lot of, like, do I care that the guy's buttons, like the third button down he missed, and he needs to polish it?  No.  I really don't need to know that.  So there's no unnecessary detail.  But really fun characters.



So, you know, top recommendation:  The Frontiers Saga.  And of course we've talked about Hamilton and Michael McCollum and the Honor Harrington series.  And I enjoy, I guess, reading series, and I'm seeing that that's being done a lot more recently.  I think authors like to get you looped in on a series so that you stay with them.  And it's just comfortable being able to continue reading about people you know.  And he doesn't spend any time at all, he assumes you are reading this in sequence.  You don't, you know, there's no time spent bringing you back up to speed over everything you missed before.



LEO:  And you should start at the beginning, obviously.  Yes?



STEVE:  Oh, absolutely.  Yes, yes, yes.



LEO:  So there are sets.  What is the meaning of the sets, then?



STEVE:  So like the first 15-book set, if you - I know.



LEO:  Not a trilogy.  It's a quintilogy.  Okay. 



STEVE:  It's a "You can't even -ilogy this."  When you're done, you're done.  But there's a bit of sadness at like the end, and you think, well, wait a minute.



LEO:  I want more, yeah.



STEVE:  Couldn't there be more?



LEO:  Oh, there is.



STEVE:  And what do you know.



LEO:  Fifteen more, kids.



STEVE:  Yes.  And when the second or third book is titled "Resurrection," it's like, oh, I think I know maybe what is going to happen here.  So, yeah.  Anyway, top recommendation.



Okay.  So the Ransomware Task Force.  The Wall Street Journal and CNN appear to have been the first to obtain and report on a U.S. Justice Department memo which first disclosed the creation of this new task force dedicated to responding to the growing threat of ransomware.  Given the maturity of the task force's first 81-page report, selected parts of which I'll be sharing shortly, this appears to have been in the works for some time.  And needless to say, it's quite needed.  Whether it'll be able to do any good, as I said at the beginning of the show, we'll see, and certainly hope.  The question is, although a task force sounds wonderfully proactive, what can it actually do?



CNN explained that the new initiative follows what the memo describes as the worst year ever for ransomware attacks.  Of course it coincided with COVID-19 that was the worst year ever for health attacks.  It highlights how cybersecurity threats in general have become a major focus of the current administration following other recent high-profile network security incidents such as the now believed to be Russian-backed SolarWinds hacking campaign and of course the Microsoft Exchange Server vulnerabilities that Microsoft has attributed to Chinese hackers.  More recently, it's believed that Chinese hackers exploited vulnerabilities in Pulse Secure's VPN to compromise dozens of agencies and companies in the U.S. and Europe.



In a memo from Acting Deputy Attorney General John Carlin to DoJ department heads, U.S. attorneys, and the FBI last Tuesday, he said:  "Although the Department has taken significant steps to address cybercrime, it is imperative that we bring the full authorities and resources of the Department to bear to confront the many dimensions and root causes of this threat."



So this new task force will pull together and unify efforts across the federal government to pursue and disrupt ransomware attackers.  And to that I say good luck to you.  Actions could include everything from takedowns of servers used to spread ransomware to seizures of these criminal enterprises' ill-gotten gains to the degree that's possible.  We'll be talking about that a little bit more in a second.  In addition, the DoJ plans to devote more resources to training and intelligence sharing, as well as reaching out to the private sector more than they have to gain insight into ransomware and extortion threats.  As we know, during the past few years, ransomware attackers have increasingly targeted schools, hospitals, city governments, and other victims that are perceived to have weaker security or to have an ability to pay.



Brian Krebs covered this news also, and he opened with:  "Some of the world's top tech firms are backing a new industry task force focused on disrupting cybercriminal ransomware gangs by limiting their ability to get paid, and targeting the individuals and finances of the organized thieves behind the crimes."  Brian continued:  "In an 81-page report delivered to the Biden administration this week, top executives from Amazon, Cisco, FireEye, McAfee, Microsoft, and dozens of other firms joined the U.S. Department of Justice, Europol, and the U.K. National Cyber Crime Agency in calling for an international coalition to combat ransomware criminals, and for a global network of ransomware investigation hubs.



"The Ransomware Task Force," he wrote, "urged the White House to make finding, frustrating, and apprehending ransomware crooks a priority within the U.S. intelligence community, and to designate the current scourge of digital extortion a national security threat.  An internal DoJ memo reportedly 'calls for developing a strategy that targets the entire criminal ecosystem around ransomware, including prosecutions, disruptions of ongoing attacks, and curbs on services that support the attacks, such as online forums that advertise the sale of ransomware or hosting services that facilitate ransomware campaigns.'"



So according to security firm Emsisoft, whom we've quoted before, almost 2,400 U.S.-based governments, healthcare facilities, and schools were victims of ransomware in just last year, 2020.  The task force report observes:  "The costs of ransomware go far beyond the ransom payments themselves.  Cybercrime is typically seen as a white-collar crime; but although ransomware is profit-driven and non-violent in the traditional sense, that has not stopped ransomware attackers from routinely imperiling lives."  And of course we were just talking about last weekend's Scripps attack that brought down four hospitals and all of their ancillary satellite-related services.



Okay.  So let's plow into the report to see what this task force is planning.  The 81-page document published by the IST, the Institute for Security and Technology's Ransomware Task Force, is titled "Combating Ransomware:  A Comprehensive Framework for Action:  Key Recommendations from the Ransomware Task Force."  And I have to say that the framework is indeed comprehensive.  Not that it may make any difference, but okay.  We know clearly after looking at this what the problem is.  It does demonstrate a lot of thought and that work has been going on behind the scenes to get the project to this point.  So it is not an empty 81 pages.



It opens with a framing statement that's meant to lay out the problem and the scope of the report's effort.  It's not long.  This is what it has to say.  It says - and there was like, I think it was an eight-member committee of mostly industry who wrote this.  So they're speaking collectively, saying:  "We're honored to present this report from the Ransomware Task Force.  This report details a comprehensive strategic framework for tackling the dramatically increasing and evolving threat of ransomware, a widespread form of cybercrime that in just a few years has become a serious national security threat and a public health and safety concern."



They wrote:  "Ransomware is not just financial extortion.  It is a crime that transcends business, government, academic, and geographic boundaries.  It has disproportionately impacted the healthcare industry during the COVID pandemic and has shut down schools, hospitals, police stations, city governments, and U.S. military facilities.  It is also a crime that funnels both private funds and tax dollars toward global criminal organizations.  The proceeds stolen from victims may be financing illicit activities ranging from human trafficking to the development and proliferation of weapons of mass destruction.



"Tackling ransomware will not be easy.  There is no silver bullet for solving this challenge.  Most ransomware criminals are based in nation-states that are unwilling or unable to prosecute this cybercrime.  And because ransoms are paid through cryptocurrency, they're difficult to trace.  This global challenge demands an 'all hands on deck' approach, with support from the highest levels of government.  Countless people around the world are already working tirelessly to blunt the onslaught of ransomware attacks.  But no single entity alone has the requisite resources, skills, capabilities, or authorities to significantly constrain this global crime enterprise.



"For this reason, we convened the Ransomware Task Force  a team of more than 60 experts from software companies, cybersecurity vendors, government agencies, nonprofits, and academic institutions  to develop a comprehensive framework for tackling the ransomware threat.  Our goal is not only to help the world better understand ransomware, but to proactively and relentlessly disrupt the ransomware business model through a series of coordinated actions, many of which can be immediately implemented by industry, government, and civil society.  Acting upon only a few of these recommendations will not likely shift the trajectory, but the task force is confident that implementing all of them in coordination, with speed and conviction, will make a significant difference.



"While we have strived to be comprehensive, we acknowledge that there will be areas we have not addressed, or on which we could not come to consensus.  Prohibition of payments is the most prominent example.  The task force agreed that paying ransoms is detrimental in a number of ways, but also recognized the challenges inherent in barring payments.  Just as we have been grateful to stand on the shoulders of those that came before us, we hope our efforts and investigations will fuel the thinking and recommendations of those who come after.



"We urge all those with the ability to act to do so immediately.  The ransomware threat continues to worsen by the day, and the consequences of waiting to respond could be disastrous.  More than money is at stake.  Lives, critical infrastructure, public faith in the legitimacy of our institutions, the education system, and in many ways our very way of life depend on taking action.  As a final note, we would like to offer our sincere thanks to the members of the Ransomware Task Force, who responded to our call and generously dedicated their time and energy into developing the recommendations included in this report."



Okay.  So that's nothing we would not expect.  This introduction was followed by an executive summary which I'm going to spare everyone from enduring.  It added very little and was largely repetitive.  The report does contain an interesting and informative infographic.  It pretty much leads with it.  This shows three or four factual bullet points.  The average downtime due to a ransomware attack is 21 days.



LEO:  Yikes.  Yikes.



STEVE:  I know.



LEO:  That's a lot of downtime.



STEVE:  That is, what, three weeks; right?  Which means some people get up quicker.  Some people get up longer.  But three weeks of outage.



LEO:  That's really a long time to be out of business.



STEVE:  Yeah.  The average days it takes for a business to fully recover from an attack, 287 days.  So, what, like two thirds of a year.



LEO:  That's amazing.



STEVE:  To fully recover.



LEO:  Yeah, nine months, yeah.



STEVE:  Victims paid in ransom in 2020, which is a 311% increase over the prior year, the average amount paid - or, no, I'm sorry, the total amount paid in 2020, $350 million.



LEO:  Yeah.  And the bigger that is, the more you're going to get because it's lucrative.



STEVE:  Yes.  Talk about incentive.  Boy.  And here's the average payment in 2020, which represented a 171% increase over 2019, the average ransom, $312,493.  So a little over $300,000 paid in ransom.



LEO:  And of course this task force is not recommending you pay.  This is all about how not to pay.



STEVE:  Correct.



LEO:  How not to get bit.  And then, if you do get bit, how to remediate.  And I think that needs to be done.  I mean, is this for government companies, or is it for everybody?



STEVE:  So it's largely a call to action.  It's sort of like the first steps for beginning to move on this.  This went to the  Biden administration, an 81-page report.  And it has three levels of hierarchy of action items and bullet points that, again, I'm going to spare our listeners because it's what happens when you have a bureaucracy.  But I would argue you can't get started without this.



LEO:  It needs to be done.  It absolutely has to be done.



STEVE:  Yes.  So I scanned the entire report, and I have pulled out some of the most interesting pieces.  When we began this podcast, you and I, Leo, nearly 16 years ago, thanks to your insight that this might be something useful, extracting payment from a victim and receiving it without exposure was an unsolved problem for cybercriminals.  Sending cash to Russia by Western  Union was what we typically saw.  And we talked about it on the podcast.  But as we know, that was then.



And it occurred to me some time ago, we talked about it, we've noted it a couple times on the podcast, that the rise of cryptocurrency exchanges, which support both submitting and extracting payments in local non-cyber currencies, or so-called "fiat" currencies, coupled with the inherent anonymity of the blockchain's wallet designations, has been an enabling factor in the growth of ransomware.  And they touch on that in the report, that the task force agrees.



But it turns out there's much more to it than I knew or than we've ever discussed.  Here's what the report explains about the role of cryptocurrency and the complexities its use introduces.  They said:  "The explosion of ransomware as a lucrative criminal enterprise has been closely tied to the rise of Bitcoin and other cryptocurrencies, which use distributed ledgers, such as blockchain, to track transactions.  The use of cryptocurrency adds to the challenge of identifying ransomware criminals, as payments with these currencies are difficult to attribute to any individual.  Often the money does not flow straight from ransomware victim to criminal.  It travels through a multistep process involving different financial entities, many of which are novel and are not yet part of standardized, regulated financial payments markets.



"Ransomware criminals typically demand that victims send their ransom payments via Bitcoin; but after receiving the payment in a designated digital 'wallet,' the criminals typically obfuscate these funds as quickly as possible to avoid detection and tracking.  Their methods include 'chain hopping,' which involves exchanging funds in one cryptocurrency for another using any of a variety of cryptocurrency exchanges.  The funds can be extremely difficult to trace after they have been exchanged.  And to further shield themselves, ransomware actors may use 'money mule' service providers to set up accounts, or use accounts with false or stolen credentials.



"Ransomware criminals can also obscure their transactions through cryptocurrency 'mixing services,' which muddy the public ledger by mixing in legitimate traffic with illicit ransomware funds.  Some groups will also demand payments in currencies known as 'privacy coins,' such as Monero, that are designed for privacy and make payments untraceable.  However, privacy coins have not been adopted as widely as might be expected because they are not as liquid as Bitcoin and other cryptocurrencies; and, due in part to regulation, this payment method may become increasingly impractical.



"Cryptocurrencies," they wrote, "add to the challenge of ransomware because they are considered to be 'borderless.'  The cryptocurrency community is expressly focused on building a set of technologies designed to reduce compliance and financial processing costs.  After obfuscating the extorted funds, ransomware criminals may either withdraw the funds into hard cash or, because cryptocurrencies have become increasingly common and their value has been steadily rising, they may keep their profits in cryptocurrency and use them to pay for other illicit activities.



"While cryptocurrencies are difficult to trace, blockchain analysis can help interpret public blockchain ledgers.  And with the proper tools, government agencies, cryptocurrency businesses, and financial institutions can understand which real-world entities transact with each other.  Blockchain analytic companies are able to show that a given transaction took place between two different cryptocurrency exchanges, for example, or between a cryptocurrency exchange and an illicit entity, such as a sanctioned individual or organization.  Within blockchain analysis tools and Know Your Customer (KYC) information, law enforcement can gain transparency into blockchain activity in ways that are not possible in traditional finance."



So clearly the rise of cryptocurrency, this solves the Western Union loophole or catch that used to be a problem.  It's just not so much anymore.  Still, it's not as if transferring to bitcoin, as we see, means that it drops into a black hole.  We have seen and we've talked on this podcast about how the movement of cryptocurrency from one chain to another can be traced, and how it dropping out of specific wallets can also be seen.  What the blockchain is, right, is a transactional ledger which is secure and cannot be spoofed, yet that means it cannot be spoofed.  And if you want to get your coin out of a wallet,  it will appear on that ledger in order for that to happen.



The report discusses also the rise of RaaS, Ransomware as a Service, that threat model and problem.  The report observes that:  "Carrying out a ransomware attack does not require technical sophistication.  Ransomware as a Service is a business model that provides ransomware capabilities to would-be criminals who do not themselves have the skills or resources to develop their own malware."



LEO:  They've made a good start just taking down some of those; right?  Those are probably pretty easy to get rid of.



STEVE:  Right.  I did note, I didn't have it in the show notes, but apparently there are some dark websites where law enforcement has begun to post in the dark web forums little warning notes, like sooner or later you're going to make a mistake.  We'll be waiting.  So it's just to add a little bit of a creep factor.  And I'm sure it's like on its face it's blown off.  But at some point, as they do make arrests, and I forgot to mention that as part of the Emotet takedown there were individuals in Ukraine who were arrested as part of this.  So some of the people behind the Emotet botnet are currently arraigned, and they're moving through the local justice system for them.



In 2020, two-thirds of the ransomware attacks analyzed by the cybersecurity firm Group-IB were perpetrated by cybercriminals using the Ransomware as a Service model.  Two-thirds.  So this model follows similar evolutions in the mainstream software and infrastructure industries, which have seen success from Software as a Service and Infrastructure as a Service in the traditional, on the Internet.  It's like, hey, that works.  Let's try it.  And we've talked about how successful it is.



They wrote:  "In the RaaS model, there are at least two parties who establish a business relationship, the developer and an affiliate.  The developer writes the malicious program that encrypts and potentially steals the victim's data.  The developer then licenses this malware to the affiliate for a fixed fee or a share of successful ransom payments.  The affiliate executes the attack, potentially also including additional business arrangements like purchasing exploits or using cryptocurrency brokers and washers."



And they conclude:  "In this model, even a non-technical affiliate can successfully execute ransomware attacks by purchasing the necessary exploits and malware.  RaaS can be contrasted with more traditional ransomware gangs in which a cohesive team both builds the malware and executes the attack.  The Sodinokibi, Phos, Dharma, and GlobeImposter ransomware variants are all known to operate under the RaaS model."



The report had some sobering things to say about nation-state actors.  And to me, this seems like the ultimate problem since proactive protection by one's own local government is pretty strong protection.  The report wrote:  "Of particular interest to the task force was the relationship between ransomware and national governments.  Many ransomware criminals operate with impunity, as their countries' governments are unwilling or unable or uncaring to prosecute this form of crime.  In other cases, the organizations executing ransomware attacks may be state-sponsored, and may in fact be helping nations evade economic sanctions imposed upon them by other nations.



"For example, in an April '21 announcement" - so just last month - "of new sanctions against Russia, the U.S. Department of Treasury made a direct connection between Russia's Federal Security Service (FSB) and ransomware hackers, noting that 'to bolster its malicious cyber operations, the FSB cultivates and co-opts criminal hackers, including the previously designated Evil Corp, enabling them to engage in disruptive ransomware attacks'" - right, against the West - "'and phishing campaigns.'" In other words, we're suffering while they're popping champagne corks and in Russia eating caviar and partying.



Anyway, they finish, saying:  "Proceeds from ransomware may help finance terrorism, human trafficking, or the proliferation of weapons of mass destruction.  For these reasons, direct affiliation between ransomware attacks and governments is intentionally shrouded in secrecy, making attribution and accountability challenging.  Countering state-sponsored attackers will require broad application of carrot-and-stick methods and international cooperation."  And unfortunately, to that I say, and good luck to us.



As I mentioned, I don't know what you do about that.  The report distills what I'm sure must have been endless committee meetings and hearings into just four goals.  The four goals are:  deter ransomware attacks through a nationally and internationally coordinated, comprehensive strategy; disrupt the ransomware business model and decrease criminal profits; help organizations prepare for ransomware attacks; and respond to ransomware attacks more effectively.



As I mentioned, it further details each of those four goals with multiple objectives within each goal, each consisting of one or more specific actions.  Since I've provided the link to the 81-page PDF in the show notes at the top of this section, I won't drag everyone through the seemingly endless and mind-numbing hierarchical list.  But suffice to say that it is truly comprehensive, and it is hopeful.



Long ago on this podcast we observed that for - and we often talked about it, Leo.  For a surprisingly long time, hacking was just mischief.  Early on here we were covering email viruses, observing that they didn't do anything other than attempt to procreate.  They seemed to exist just to spread.  And we also bemoaned for quite some while the fact that Microsoft didn't seem to be taking much action against them.  So the only conclusion would have been that they must have been created by their authors just to see whether they might work.  The first botnets that we reported on were largely benign.



And even way back in November of 1988, Robert Morris launched his famous worm from a terminal at MIT by leveraging a hole in Sendmail's debug mode, coupled with a buffer overflow in the fingerd network daemon.  Robert just wanted to see whether it might work.  But because it was so much more effective than he expected, it caused far more trouble than he intended.  By the way, he ended up being a tenured professor at MIT.  But he also got in trouble.  He got himself out of it.  His dad was at the NSA, so maybe that helped.



LEO:  He actually was quite brilliant.  Who was I talking to that was good friends with RTM?  Oh, I can't remember.  But he said this guy was brilliant, yeah, yeah.  Go ahead, sorry.



STEVE:  So compared to when we began looking at and discussing these issues every week, today's cybercrime world is barely recognizable.  I mean, I remember talking about like how it used to seem like science fiction.  It's like, really?  I mean, even the word "cybercrime."  Now no one is laughing.  It's no longer the realm of speculative fiction.  It exists, and it's become nation-state-sponsored, revenue-generating big business.  With criminals being protected by their own governments, the ability of law enforcement I'm worried to curtail ransomware seems quite limited.  And unlike Emotet, where the threat was diffuse and significant only because of the size of the network, that could be brought down.  But ransomware attacks are different.  They're significant individually.  Individual attacks like against Scripps are significant.



And if the years of this podcast have revealed any truth, it's that we're currently unable to reliably create complex and secure networked systems.  We'd like to be able to do that.  We just seem unable to.  So I'm glad that this ransomware task force exists.  But in the absence of full international anti-ransomware cooperation, including those nations that are hostile to the interests of other nations, like China and Russia against the U.S., it's not clear to me that huffing and puffing is going to amount to much.



I mean, I'm glad that a task force has been assembled.  It makes sense that it would be.  I mean, these things got to be so recurrent that I stopped talking about them on the podcast because it was just, you know, there is a sense of, well, you've seen one, you've seen them all.  But the good news is we have an administration that looks like they're willing to take action.  There is a carrot and stick.  In their sanctions against Russia they did talk about state-sponsored ransomware crime gangs which had been traced back there.  So we'll see if some of this can be dealt with.  But again, Leo, as you said, we spotted the problem.  The problem is it makes money.  And it's difficult to stop something that makes money.



LEO:  Yeah, yeah.  But I think there's all sorts of things a task force could attack besides the Ransomware as a Service, which clearly makes it way too easy for any idiot to do this.  You should have a certain level of skill if you're going to get into this.  But also teach companies how to prevent and mitigate ransomware attacks.  I mean, you're never going to stop malware ever.  But you can do a lot to help people protect against  malware.  And I think that that's one - I don't know how much the task force is going to work on that.  But that's, I think, a huge and very valuable effort.



STEVE:  Maybe they could do a contract with ITProTV to create an educational video.



LEO:  Most of our sponsors help you in one way or the other with this kind of stuff.  Certainly on this show anyway.  You know, I was thinking about Robert Tappan Morris because every time you think of his name you think of the Morris Worm, and you think of the first computer virus.  And that he was the first person ever convicted under the Computer Fraud Act and all that. 



STEVE:  Right, right.



LEO:  But really he transcended that.  He's a brilliant guy and has done amazing things since then.  It's kind of a shame that he's so tarred with that one act that he even says was innocent.  He was doing the kind of things that a lot of guys do.  He was trying stuff out.  He didn't expect it to get away.



STEVE:  Oh, Leo, it's a good thing that we didn't have the Internet when I was growing up.



LEO:  I know, exactly.  Exactly.



STEVE:  That would not have turned out well.



LEO:  Like young Dan Kaminsky, your mother would have had to go yell at somebody.



STEVE:  Well, and given the mischief I got up to without computers, I don't want to think about what would have happened.



LEO:  Precisely.  It's normal.  You have no frontal lobe.  You're going to do crazy things.  So Morris was the co-founder with Paul Graham of Y Combinator and has done - if you read his Wikipedia entry, you'll get an idea of all the things he's done.  That's where I was thinking - Paul Graham wrote an amazing article about RTM and what a great - he's still alive, and he's still very active, but what a great guy he was.  So, and I have huge respect for Paul Graham.



Sir, you have completed your duties, your assigned duties for this day.  You may go have some fine Italian food, if that's what you desire.  Are you still going out every week to the Italian place?  That's awesome.



STEVE:  Yup, we are.



LEO:  Isn't it amazing?  Life is back.  For some of us.  Not for all of us.



STEVE:  Yeah.  I'm waiting for my best buddy.  He's got his first Moderna.  I think he's got it, and Moderna is a four-week  interval as opposed to Pfizer there's three.  So it was a few weeks ago.  So a couple weeks from now he'll be fully vaccinated, then we give him another couple weeks to let that set into his immune system.



LEO:  Let's party.



STEVE:  And Javier's is our Mexican place.



LEO:  Can't wait.



STEVE:  And they're going to look at us and, like, where have you guys been?



LEO:  Oh, man.  It's exactly right.  When we go in...



STEVE:  We're pretty well known.



LEO:  You know those people who were ordering takeout from you for the last year?  That's us.



STEVE:  Uh-huh.  That kept you guys afloat.



LEO:  Yeah.  That was us.



STEVE:  Yes.



LEO:  We're back, baby.  So I do hope all of you get the vaccine soon, if you haven't got it already, and we can get back to life.  And for people in India and other places where it's just tragic...  



STEVE:  Oh, Leo, boy.  Ooh, ouch.



LEO:  I feel so bad.  And Ontario in Canada they're just suffering.  And, wow, I really feel lucky that we have this vaccine and that we've been able to get it to almost half the population now.  So it's really, really good.



Thank you, sir.  I'm glad you're well, and I'm glad you're here to do this show.  Steve joins us every Tuesday, right after MacBreak Weekly.  I should warn you we're going to be a little bit late, not next week but the week after.  This Week in - not This Week in Google.  Just Google.  You've heard of them?  It's a little company, could do a search engine, has its Google I/O keynote on May 18th at 10:00 a.m.  And it's scheduled for two hours, which means we won't get MacBreak Weekly started till about an hour late, which means you might be - you're used to this.



But I just give you a little heads-up, and a heads-up to the audience, if you watch it live.  We'll be starting maybe around 2:30, thereabouts.  Normally 1:30 p.m. Pacific, 4:30 Eastern, 20:30 UTC on a Tuesday afternoon.  You can tune in TWiT.tv/live for the live audio or video feeds.  If you're doing that, join us in the chatroom.  They're chatting along as Steve talks.  That's irc.twit.tv.



We also have, for people who want to listen after the fact, we have copies of the show.  Steve's got them at his website, GRC.com.  He's got the 16Kb version.  If you're really bandwidth-constrained, but you still want to hear it, that's the smallest audio file we've got.  He also has an even smaller file, but it's not as fun.  You can read because we've got transcripts.  I think most people read as they listen, or do what I do, which is use the transcripts to search because it's a great way to jump into a particular part of a show to find the thing you're looking for.  And all of that's at GRC.com, along with SpinRite, the world's best mass storage - I said that right this time.



STEVE:  Thank you, you got it right the first time.



LEO:  The world's best mass storage maintenance and recovery utility.  6.0 is out now.  You can get it, and we'll get a free upgrade to 6.1, which is in active development and will be out soon.  Well worth getting.  Everybody who has mass storage of any kind should have SpinRite.  While you're there, GRC.com has so many other fun things.  All of the rest of it's free, like ShieldsUP! to test your router and, oh, I can go on and on and on.  The DNS Benchmark is very valuable if you're choosing a DNS server.  Just check it out, GRC.com.



We have audio and video of the show at our site, TWiT.tv/sn for Security Now!.  When you get there, you'll also see a link to a YouTube channel.  All the shows are there, if you for some reason like YouTube.  You can also subscribe in a podcast program.  That actually is probably the best way because then you can automatically get it the minute it's available and have it ready for you whenever you're in the mood - Pocket Casts, Stitcher, Overcast, you know, all of the usual suspects.  If your podcast player has a review section, please leave us a five-star review.  You want everybody to know about Security Now!.  This is an important show for everybody to listen to, I think, every week.  Thank you so much, Steve Gibson.  God bless.



STEVE:  My pleasure.



LEO:  May the 4th be with you.



STEVE:  Next week we're on time.  It's the week after next that you're warning us.



LEO:  It's the 18th.  The 18th.  I just wanted to give you a little heads-up ahead of time.



STEVE:  In that case, Leo, I'll be here.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#818

DATE:		May 11, 2021

TITLE:		News from the DarkSide

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-818.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a new (and old) thread to our global DNS infrastructure.  We ask what the heck Google is planning with two-step verification, and we examine a huge new problem with the Internet's majority of email servers.  We look at the reality of Tor exit node insecurity, touch on a new sci-fi novel by a well-known author, share a bit of closing-the-loop feedback, then take a look at this latest very high-profile ransomware attack from a previously low-key attacker.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Some serious security issues with the Exim email server.  We're going to talk about a big infrastructure problem, the Colonial Pipeline hit by ransomware.  What's it mean for infrastructure in general?  And then Steve's got a Picture of the Week that's actually - I think it's an IQ test.  It's all coming up next - you'll pass - on Security Now!. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 818, recorded Tuesday, May 11th, 2021:  News from the DarkSide.



It's time for Security Now! with this fellow right here, we call him James Tiberius Gibson, the captain of the good ship Security Now!.  Steve Gibson is here.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.



LEO:  What's up?



STEVE:  Once again, well, you know, I did not want to talk about DarkSide.  But there was no way not to...



LEO:  I think you have to.  I think you have to.



STEVE:  There was no way not to talk about DarkSide.  And what was interesting - because how much time have I spent promising our listeners that we wouldn't keep talking about ransomware?  But when this thing moves from an incidental concern from IT people to something where our parents or grandparents or those who predate the Internet are like, what?  Ransomware?  What's that?  I mean, and when it steps out to dramatically affect our infrastructure - oh, and this group has a weird twist also, like they have an ethics page posted on their site on the dark web about their intentions.  Anyway, we'll get to that.  There was enough interest about this, like enough insider information that our listeners would not have picked up from the mainstream media that I thought, okay, we've got to talk about that.



But this is Episode 818 for Patch Tuesday of May, which we'll be talking about next week because we have to wait to see what happens.  We're going to look at a new and old threat to our global DNS infrastructure.  We also ask what the heck Google is planning with their so-called two-step verification.  We examine a huge new problem with the Internet's majority of email servers.  Microsoft Exchange, that was March.  And they're by no means the biggest player.  It turns out that the biggest player, Exim, has some really bad problems.  So buckle up.  We're also going to look at the reality of Tor exit node insecurity, Leo, and really substantiate the statements you've been making when you're talking about our VPN sponsors, that just using Tor doesn't do the problem.



LEO:  Yeah, yeah, yeah.



STEVE:  We're also going to touch on a new sci-fi novel from a very well-known author, share a bit of closing-the-loop feedback from our listeners, and then we're going to settle down and take a look at this arguably highest profile ransomware attack ever from what was previously a low-key attacker.  We've never talked about DarkSide before.  We're talking about Ryuk and all these other guys.  And this player's sort of interesting.  And for those listeners who haven't, well, actually, you and I, all of our conversation about our Picture of the Week was before you hit the record button.  We have a picture that we're not going to explain.  And we will explain why.



LEO:  It's an IQ test.  Actually it's not.  It's a test of your educational levels, maybe.  I don't know.  I don't think it's an intelligence test, but it is a test.  So we'll have that in a moment.  All right, Steve.  Are you ready for the IQ test?



STEVE:  So the bad news is nothing we could say, like I can't even describe this because if I were to describe it, I fear that I would say something that would provide a clue.  So I'm not going to do that.  Everyone knows where the show notes are.  You can get them at GRC.com/sn or /securitynow.



LEO:  Or if you're watching the video you're seeing it.  But, yeah, for our audio listeners, we don't want to describe it, yeah, because we don't want to give it away.



STEVE:  Yes, yes.  If you're watching it, it's onscreen right now.  It's just fun.  It is a two-frame cartoon, very clever, and you'll enjoy the fact that you get it.



LEO:  Let me just check the poll.



STEVE:  And probably be annoyed if you don't.



LEO:  In our Discord right now we're asking do you get the Picture of the Week.  In other words, do you get the joke, because it's a joke.  16 do; 9 do not.  And it's got to be frustrating for those who don't because it's just not obvious.  Unless it is.  It's one of those things.  If you know, you know.



STEVE:  And for what it's worth, it's well done.  I mean, it's just...



LEO:  Oh, yeah.  They got it all right, yeah.  I know what you're talking about, yeah.



STEVE:  Exactly.  Exactly.  It was done correctly.  So we'll just leave that as a puzzle for the listeners.



LEO:  We'll tell you next week, how about that.



STEVE:  Oh, I like that.  Very good.  You've got one week before the spoiler hits.  So see if you can take a look at the picture and test yourself.



Okay.  So the best name - the best name.  The best thing about this flaw is I think its name.  The flaw is TsuNAME, obviously meant to be tsunami, so with a little bit of fudging of the spelling, because it's about name servers.  So tsunami, or TsuNAME.  And this is one of those clickbait-y stories, but it's still interesting and I think educational.  When I first encountered the industry's coverage of this, with its portents of doom, I thought that some new nightmare must have been found with DNS, just when we needed Dan the most.



But when I dug into the story, I learned that it boils down to an interesting way for a domain's DNS records to be misconfigured such that when a naive, and I'll explain what I mean by that, a naive recursive DNS resolver is asked to resolve one of these misconfigured domains, that recursive server, serving as a DNS resolver, will get itself into a name resolution loop, which causes it to pound away on that domain's authoritative DNS servers without end.  It turns out there's a way to put DNS into an infinite name resolving loop.



Now, if this had never occurred to anyone since man walked the Earth, it might be somewhat more alarming.  But not surprisingly, this had previously occurred to the guys who built DNS.  RFC 1536 - yes, four digits, it's an oldie, 1536 - published way back in October of 1993, was titled "Common DNS Implementation Errors and Suggested Fixes."  So, yeah, things can go wrong, and how to fix them.



Section 2 of that RFC 1536 bears the title "Recursion Bugs."  And after a bit of shortening for the podcast, it reads:  "When a server receives a client request, it first looks up its zone data locally and in its cache to check if the query can be answered.  If the answer is unavailable from either location, the server seeks names of servers that are more likely to have the information in their caches or zone data.  The server chains this request to these known servers closest to the queried name.  This process repeats until the client is satisfied.



"Servers might also go through this chaining process if the server returns a CNAME record" - we've talked about that, the canonical name record, which is an alias - "for the queried name.  Some servers reprocess this name to try to get the desired record type.  However, in certain cases, this chain of events may not be good," is what they wrote in 1993.  May not be good.  "For example, a broken or malicious name server might list itself as one of the name servers to query again.  The unsuspecting client resends the same query to the same server.  In another situation," they wrote, "more difficult to detect, a set of servers might form a loop wherein A refers to B and B refers back to A.  This loop might involve more than two servers."



Okay.  So with that bit of background, here's what the guys who reminded us what was written 28 years ago said in their published paper's opening abstract.  They said:  "The Internet's Domain Name System is one of the core services on the Internet.  Every website visit requires a series of DNS queries, and large DNS failures may have cascading consequences, leading to unreachability of major websites and services."  Okay.  That we all know.  They said:  "In this paper we present TsuNAME, a vulnerability in some DNS resolvers that can be exploited to carry out denial-of-service attacks against authoritative servers.  TsuNAME occurs when domain names are misconfigured with cyclic dependent DNS records.  And when vulnerable resolvers access these misconfigurations, they begin looping and send DNS queries rapidly to authoritative servers and other resolvers."  And they said:  "We observe up to 5,600 queries per second."  



They said:  "Using production data from .nz, the country-code top-level domain of New Zealand, we show how only two misconfigured domains led to a 50% increase in overall traffic volume for the .nz's authoritative servers.  To understand this event, we reproduce TsuNAME using our own configuration, demonstrating that it could be used to overwhelm any DNS Zone.  A solution to TsuNAME requires changes to some recursive resolver software to include loop detection and caching cyclic dependency records.  To reduce the impact of TsuNAME in the wild, we have developed and released CycleHunter, an open source tool that allows for authoritative DNS server operators to detect cyclic dependencies and prevent becoming victims of TsuNAME attacks themselves."



And they conclude with the abstract:  "We used CycleHunter to evaluate roughly 184 million domain names in seven large, top-level (TLD) domains and discovered 44 cyclic dependent name server records, likely from configuration errors, used by 1,400 domain names.  A well-motivated adversary could easily weaponize this vulnerability.  We have notified resolver developers and many TLD operators of this vulnerability.  Working together with Google" - and actually also with Cisco, I'll get to that in a second - they said, "we helped them to mitigate their vulnerability to TsuNAME."



So later in the paper they discuss their use of this CycleHunter tool and show that they found a total of 3,696 DNS resolvers which were not protecting their queries from this cyclic DNS misconfiguration.  They manually tested the DNS resolvers Unbound, BIND, KnotDNS, spelled K-N-O-T, which is DNS, Quad9 and Quad1.  All of those passed.  But Cisco's OpenDNS and Google's DNS both got themselves caught in cyclic lookup loops.  They informed both companies, and both fixed their problems quickly.  That's, you know, it's an internal thing.  I don't know if Cisco's OpenDNS, I mean, presumably they make that available to people, whereas Google's DNS is a service of Google, so they would have fixed that in-house.  Anyway, and interestingly, DNS developers, it turns out, do need to always be, and generally are, on the lookout for DNS looping errors.  They note that the changelog for the Unbound DNS resolver contains 28 entries related to looping.



So anyone doing recursive DNS needs to clearly make sure that  they don't get themselves chasing their tail endlessly.  Given the numbers, it seems unlikely that this would have happened.  But somewhere in their report, I read the whole thing, they noted that while they were observing some range of domains, one new problem appeared.  Like somebody brought up some new zone records and apparently just made a mistake.  And sure enough, a new recursion problem occurred.



So this is happening from time to time.  As long as resolvers don't chase their tail endlessly, but realize, wait a minute, I'm just caching my lookups, and I've just been asked to look up the same thing I was asked a moment ago, I'm in a loop.  And so this is the Kobayashi Maru.  I'm not going to proceed any further.  In which case these occasional lookup problems, they'll probably get found because lookups will be broken if they recurse and never complete.  But certainly DNS, you know, anyone operating a DNS server wants to make sure they don't have one, which is just going to sit around, I mean, you're using up your own local network bandwidth when you are making 5,600 queries per second to other servers out on the Internet.  So that's not something that you want to have happen.



So what this all boils down to is that two of the industry's many DNS server families were failing to detect DNS lookup loops.  And, sure enough, there were a few definitions out there that would cause those servers to become stuck.  The benefit of this research is that it identified those servers and got them patched, and they did develop this CycleHunter tool of theirs to allow administrators of DNS to check up on their own DNS zone definitions for any cyclic lookup trouble.  It's TsuNAME, T-S-U-N-A-M-E dot io.  You can go there, and they have the full tech report for anyone who wants it, and also a pointer to their freely available tool CycleHunter to allow people to make sure that they're not stuck, and they don't have like a misconfigured DNS that could be loading down their servers without them knowing.



Okay.  So I labeled this one, "Huh, Google?"  Last Thursday Google's Mark Risher, R-I-S-H-E-R, their Director of Product Management for Identity and User Security, posted to the Google blog under the "Safety & Security" section an entry titled:  "A simpler and safer future  without passwords."  Okay, now, unfortunately, that's not what his blog post addressed.  And no one seems to be exactly sure what his blog was trying to say and what it did address, since it led to many confusing and misleading tech press headlines.  I saw a headline, "Google wants to enable multi-factor authentication by default"; and another headline, "Google is turning on two-factor authentication by default"; and another one, "Google will start automatically enrolling users in two-step verification soon."



And on top of that, I saw many users who read this to mean that Google would be requiring the use of two-factor authentication.  And I can certainly see how one might get that, you know, come away with that feeling from the confused headlines.  It's also not helpful that Google has apparently decided to create a new term and abbreviation.  Everyone already knows what two-factor authentication is.  In fact, the headlines, generally two of the three used that, even though Google didn't, because that's what we call it.  We call it two-factor authentication, typically abbreviated 2FA.  But now we have Google's 2SV, which is what they're using, which is two-step verification.  Okay.  But if you first put in your email address, then you put in your password, then you're asked to do something else, aren't we already up to three steps of verification?



LEO:  That's a good point.  They just don't want to act like it's two factors; right?  They just want to say it's another step; right?



STEVE:  Yeah, okay.  But if you need to go get your phone, arrange to unlock it with your identity, then respond to a prompt or a text message or a one-time password, we're up to about six or seven steps by that point.  I've lost count.  Anyway, so I read through Mark Risher's blog posting, and here's the problematic paragraph that no one is quite sure how to interpret.  He wrote:  "Today we ask people who have enrolled in two-step verification (2SV) to confirm it's really them with a simple tap via a Google prompt on their phone whenever they sign in."  Here it comes.  "Soon we'll start automatically enrolling users in 2SV if their accounts are appropriately configured."  Uh, what?  So I have no idea what he means when he says "We'll start automatically enrolling users in two-step verification if their accounts are appropriately configured."  What does "appropriately configured" mean?



LEO:  [Mumbling]



STEVE:  Yeah, huh?



LEO:  I wish they were clearer on this.  I mean, they in their minds know what that means, but they haven't told us.



STEVE:  Well, yes.  And you're reading my mind, Leo, because in the show notes I wrote, "And that's the problem.  It apparently means something to Mark.  But it's gobbledy-gook to the millions of people who read Google's blogs, and also apparently to the tech press, which tried to write news stories around it."



Okay, now, as we all know, you either have second-factor authentication enabled for authentication to your Google account, as I do, or you don't.  There's no third setting labeled, "Well, I'm open to the idea, hit me up when you want."  We don't have that.  So the only thing I can figure is that, I don't know, Mark woke up last Thursday, and his calendar told him that it was World Password Day, as indeed it was.  So he thought, oh, crap, that's right, I'm Director of Product Management for Identity and Security.  I'd better think of something to say.  So he banged out that confusing blog post to the world.



I think what we need to take away from his aberrant posting is that Google is a fan of using more than just our email address and password for authentication.  We know that's true.  And that in the interests of their users they plan to arrange to somehow encourage more of their users to add a second factor.  Or, as they put it, "another step" to their logons.  But as for what Mark wrote last Thursday to celebrate World Password Day, I have no idea what he could possibly mean by "automatic enrollment in 2SV," two-step verification, nor does anyone else at this point.  Maybe they don't know.  But looking at just what a mess this caused out in the press, if they thought that removing FTP support from Chrome might cause a ruckus, just watch what happens if they start surprising their users with the presumably unwanted additional complexity of two-step verification, which sounds like it's more like six or seven steps.  I guess we're going to find out.  And Leo, thinking about this further, they do have, they've authorized Android phones to get involved in a simple authentication cycle; right?



LEO:  I think they have - that's what they're talking about is single sign-on.  It works on an Apple phone, too, by the way, if you have the Google app on your Apple phone.



STEVE:  Right.



LEO:  And that may be what they're thinking.  And that's what Microsoft uses, that single sign-on, which is great.  I love it.



STEVE:  So would they be aware of it for users, but see that a user has the app and then say, hey, happen to know you're an Android person.



LEO:  Exactly.



STEVE:  So you can do this.



LEO:  They wouldn't even say that.  They just would start using it.



STEVE:  Really.



LEO:  Yeah.  But if you didn't have the app, it wouldn't mean anything.  So you'll get a notification on your phone.  And so it'll say "click okay on your phone."  I've seen actually this happen.  I mean, it happens to me all the time with Google.



STEVE:  But if you're on your desktop logging in?



LEO:  Yeah, it says click okay on your phone.



STEVE:  Oh, okay. 



LEO:  And then, if that doesn't work, it says "Try another way."  You know, they give you - it's not like a - but I think honestly that's maybe why he calls it two-step, because it isn't - in fact it's one step because, I mean, it's one factor.



STEVE:  That's back.



LEO:  Well, no, I like single sign-on.  But with Microsoft, for instance, when you sign on to Windows, instead of saying what's your password, it says what's your, you know, you put your Microsoft account email in there.



STEVE:  Right.



LEO:  And then it says, okay, look on your phone for the number 80 and tap it.  And I think it's a far preferable way.  There's no password at all.  And that's kind of what Google does with their single sign-on.  And I've seen this happen with single sign-on.  I suspect that's what he's talking about.  But the problem is it isn't clear at all what he's talking about.



STEVE:  No.  Nor did he in any way - nowhere did he talk about the end of passwords.  He just said we're going to add steps.



LEO:  But that's what single sign-on in effect does.  You don't enter your Microsoft password now when you first set up Windows.  But you have to have the authenticator app on your phone, and Microsoft knows that you do, and knows that you've used it.  Similarly Google would have to know that you have that capability.  And you're right, on a Pixel phone you don't need an app.  On an iPhone you need the Google app.  And then I love it because then I just tap okay on my phone.



STEVE:  Leo, I worked on something called SQRL for quite a while.



LEO:  Yeah, it's kind of SQRL-ish.



STEVE:  I'm well aware of the benefits, yes, indeed.  Let's take a break.  I'm going to sip some water, and I'm going to talk about 21 nails in Exim's coffin.



So Tor's exit nodes.  Since 2015, a Tor network researcher who goes by the moniker, I guess it's Nusenu, N-U-S-E-N-U.  I googled that, thinking maybe that was a term or something that I've never heard of before, as sometimes is the case.  No.  There was no reference to Nusenu except this guy, N-U-S-E-N-U.  Anyway, whoever he is, Nusenu has been tracking the deliberate abuse of the Tor network by quite determined and lately quite increasingly determined attackers.  And of course as our listeners know, through the years the TWiT network has enjoyed the sponsorship of various high-quality VPN providers, as it does at the moment.  And in talking about the various benefits and reasons to use a VPN, you, Leo, often cite the dangers inherent in Tor exit nodes.  Once everybody hears what this researcher has been tracking, I doubt that anyone will or should feel comfortable using Tor without added protection.



LEO:  I seem to remember the NSA, or was it the CIA, ran some Tor exit nodes.  So, you know, just keep that I mind, I guess.



STEVE:  Yes.  Okay.  So because this was fascinating to me, and we've talked about Tor a lot, Tor is a cool concept.  It used to be The Onion Router, T-O-R.  And the idea was that you the user would choose a series of Tor nodes, typically three.  The first one you connect to.  Then one in the middle.  And then an exit node at the end.  And from each of those nodes, you would obtain their public key.  You would then use the first node's public key to encrypt your traffic.  And after that, that you would take that first encrypted traffic, and you would use the - oh, wait, I got it backwards.  You'd first use the last node's public key to encrypt your traffic.  Then you would use, to that, you would then use the middle node's public key to encrypt that, sort of like shells of an onion.  And then you would use  the first node's public key for the final encryption.



So what you've got now is this triple-encrypted thing.  Think of it like an onion with successive layers.  So now you send this to the first node.  It's been encrypted with its public key, so it has the matching private key that it uses to take the encryption wrapper off.  And of course the reason you do this is that nothing that went between you and that first node can be seen by anybody, your ISP and so forth, because it's been encrypted.  So that node, that first node is able to take off the outer wrapper.  Now it's looking at a thing with two layers of encryption.  It doesn't know how to take off another layer because the layer that it's now got on the outer surface was encrypted using the middle Tor node's public key.  So all it can do is send it on to the Middle Tor node.



So it does that.  Middle Tor node knows its private key so it can take off the wrapper that nobody else can take off, which it does, which gives it the address of the exit node.  But it can't go any further because it doesn't have the exit node's public key.  So it sends it to the exit node.  The exit node does have its private key that matches the public key that you originally got.  So it's able to remove the final innermost wrapper of encryption.  And now that thing you wanted to send through this Tor network is back in plaintext, and out it goes onto the Internet.  And that's the problem is that that exit node that removed the final layer of encryption has decrypted fully after three bounces, the original plaintext that you put onto the Tor network.  What is it doing with it?



Okay.  So he's been tracking abuses of Tor exit nodes.  Two days ago, this is why it popped up on my radar, he posted his most recent update to his earlier work which began in August of 2020 titled "Tracking One Year of Malicious Tor Exit Relay Activities Part II."  And in his posting on Medium two days ago, Nusenu - maybe that's his name, I don't know.  Anyway, he says:  "In August of 2020 I reported about 'How Malicious Tor Relays are Exploiting Users in 2020.'"  That was Part I.



He said:  "Back then I made the hypothesis that the entity behind these malicious Tor relays" - and, okay, just to get everyone's attention, as many as one quarter of all Tor exit nodes are malicious.  Okay?  So not a couple.  But your chances of hitting one are high, especially because you typically rotate among different nodes as you go.  So the opportunity of your traffic exiting from a malicious node, depending upon when you're using Tor, is as high as 25%, and it rises as you use it over the course of its use.  So anyway, my point is this is a big deal.



He made the hypothesis that the entity behind these malicious Tor relays is not going to stop its activities anytime soon.  He said:  "Unfortunately, this turned out to be true."  In this follow-up post of his earlier - and by the way, in the show notes I have all three links:  his very first one, this middle one, and then the one from two days ago.  He says:  "I will give you an update, share what additional information we learned about the attacker since August 2020, and to what extent they were and still are active on the Tor network."



So again, before I go any further, I'll share the extent of the trouble that Nusenu has uncovered.  In August 2020 posting he explained:  "What is this attacker actually exploiting, and how does it affect Tor users?"  He said:  "The full extent of their operations is unknown, but one motivation appears to be plain and simple:  profit.  They perform person-in-the-middle attacks" - and I guess we're no longer calling that man-in-the-middle, it's person-in-the-middle to be gender neutral - "person-in-the-middle attacks on Tor users by manipulating traffic as it flows through their exit relays."  As I said, the exit relay has it back in the clear.  He said:  "They selectively remove HTTP-to-HTTPS redirects to gain full access to plain unencrypted HTTP traffic without causing TLS certificate warnings."



Okay.  So of course we know all about this; right?  You can't muck with TLS or you're going to break the authentication which is protected by the certificate, and you'll get bogus certificates.  Also, it's encrypted if it's over SSL/TLS.  So you really can't get anything done.  But if the initial traffic is HTTP, and the far site returns a redirect to HTTPS, what these guys are doing is they're saying, oops, nope, we're not going to have the user moved over HTTPS.  And we've spoken about this many times.  GRC, for example, redirects anyone coming in over HTTP to HTTPS.  It's not possible to access GRC without HTTPS, though it is possible to begin with HTTP and then be moved over to HTTPS to continue.  And while web browsers all assumed HTTP, remember we've also talked about this, that's finally beginning to change.  No idea what took them so long.



Until the assumption was being made, this moving people from HTTP to HTTPS was a necessary step since everyone entering just by typing GRC.com would default to http://GRC.com.  And I should note, as our listeners will recall, GRC was among the first domains to be added to Chrome's permanent HSTS list, which Mozilla duplicates, and that explicitly gives Chrome and Firefox permission to always silently promote any and all HTTP queries to HTTPS, and it makes it quicker because it saves the HTTP to HTTPS redirect roundtrip and so forth.



Anyway, Nusenu in his posting continues.  He said:  "It is hard to detect for Tor Browser users that do not specifically look for the https:// in the URL bar.  This is a well-known attack called 'SSL stripping' that exploits the fact that users rarely type in the full domain starting with https://."  He says:  "There are established countermeasures, namely HSTS Preloading and HTTPS Everywhere.  But in practice, many website operators do not implement them, and leave their users vulnerable to this kind of attack."



He says:  "This kind of attack is not specific to Tor Browser.  Malicious relays are just used to gain access to user traffic.  To make detection harder, the malicious entity did not attack all websites equally.  It appears that they're primarily after cryptocurrency-related websites, namely multiple bitcoin mixer services," which we talked about last week.  He says:  "They replaced bitcoin addresses in HTTP traffic to redirect transactions to their wallets instead of user-provided bitcoin addresses.  Bitcoin address rewriting attacks are not new, but the scale of their operations is.  It is not possible to determine whether they engage in other types of attacks."



He said:  "I've reached out to some of the known affected bitcoin sites, so they can mitigate this on a technical level using HSTS preloading.  Someone else submitted HTTPS Everywhere rules for the known affected domains."  And he notes that HTTPS Everywhere is installed by default in Tor Browser.  "Unfortunately," he says, "none of these sites had HSTS preloading enabled at the time.  At least one affected bitcoin website deployed HSTS preloading after learning about these events."  Okay.  So I have to say I am astonished that any sort of bitcoin transaction site might be lacking in such basic security awareness and provision.  But since bitcoin is unregulated, it's user beware.  And if this is the state of cryptocurrency security, I guess I'm less surprised that we keep hearing about this or that cryptocurrency exchange being hacked.



Elsewhere, Nusenu notes that SSL stripping and person-in-the-middle attacks are only one of many potential problems with Tor's inadvertent hosting of malicious exit nodes.  As an example, he considers the instances where a new remote vulnerability is discovered in Firefox and thus in the Tor version of Firefox.  Running a large network of exit nodes would allow attackers to immediately reach back down their end-node connection to exploit such newly discovered vulnerabilities before the Tor users' browser had a chance to update.



So just how big is the problem?  Is it a couple of nodes that users are likely to exit from?  Well, as I said, no.  The graph above in the show notes shows just how big the problem is.  The graph's scale on the left is difficult to read.  But the uppermost number is 26%.  Nusenu's caption for that graph reads:  "Figure 1:  Malicious Tor exit fraction measured in % of the entire available Tor exit node capacity over time by this particular malicious entity between July of 2020 and last month,  April of 2021."  He said:  "Peak value:  The attacker did manage approximately 27.5% of the Tor network's exit capacity on January 2nd of 2021."



Okay.  And it's interesting, the graph sort of shows a rising percentage, then a sudden drop.  And then it'll rise again and drop.  And then it'll rise again and drop.  And then it'll rise again.  And in the case of the largest and longest one, it rose, and it kind of slowed down, and then dropped.  Well, okay.  What's happening is that the bad guys are being found.  I mean, there is active combating of malicious exit nodes by Tor network administrators.  But this is all sort of volunteer exit node; right?  I mean, we talked about how, you know, anyone who wants to can contribute to the Tor network by setting up their own exit node, where they allow users' traffic to come encrypted into their system, get decrypted by this exit node that they run on their network, and then out it goes onto the Internet.  I don't want to run one, but good Samaritans do.



It turns out that bad Samaritans do, as well.  And that because they are set up quickly, and due to the nature of the way they're set up, it is possible to track their aggregation over time, which is what Nusenu has figured out how to do.  And so what we see is a large population of malicious nodes built up.  While they are active, as many as, actually more than, one out of four connections over Tor is exiting through a node controlled by malicious parties who are hoping you're going to do something without TLS encryption.  And god help you if you do because these people are not working in your favor.



He did also note, though, that they're not mucking with all traffic.  They are being selective about what traffic they mess with.  And of course that does make their detection more difficult.  So I guess that's good.  So he said that there's better than, as a consequence of 27.5%, better than a one in four probability, which as I noted rises over time since exit nodes are being randomly chosen and rotated.  So the chance that a user not using some form of encryption will have traffic exiting through a malicious node - now, of course, it also is dependent upon where in this weird sawtooth cycle of malicious activity, node activity growing and then being suddenly cut off, like where in that cycle you happen to be using the Tor network, well, that matters, too.  But it demonstrates that you just can't take it at face value that the use of Tor is going to be secure.



So the bottom line here is there's no free lunch.  Tor provides, as we know, some valuable services.  But it's not a panacea.  Any user of Tor must assume - and by the way, it's gotten way worse in the last couple years.  This was not true when we first talked about the Tor network in the beginning, and even over the course of the last few years, while this guy Nusenu has been tracking this, although his tools are getting better, so maybe he's better at finding the problem, he's concluding that it is really getting worse, and way worse in 2021 than it had been before.  So any user of Tor should assume, must assume that the exit nodes they're emerging from may be under the control of malicious entities who will take any and every opportunity to interfere with and subvert the user's traffic if they can.



He wrote:  "We know about mitmproxy, sslstrip, bitcoin address rewrites, and" - get this - "download modification attacks.  But," he said, "it's not possible to rule out other types of attacks.  Imagine an attacker runs 27% of the Tor network's exit capacity and a Firefox exploit affecting Tor Browser gets published before all users got their auto-updates."  And, wow.  A download modification attack?  Talk about chilling.



You use Tor to go get something that you want to keep very private.  That's the reason you're using Tor.  But the website that offers whatever it is doesn't support HTTPS.  And apparently there are a lot that still don't.  Okay, you know, they just say, hey, we're not going to do that.  Still, you want it badly.  So you download it over Tor.  Even if the site in question was 100% legitimate, who knows what you actually downloaded?  HTTP offers zero authentication of the other end's identity.



It was noted that a Tor HTTPS-only browser would be one solution.  And about that, Nusenu wrote, he said:  "The HTTPS-only mode, which might land in Tor Browser based on Firefox 91 ESR, would be a strong protection.  But there are still some uncertainties with that as well," he says, "as a Tor Browser developer points out on a Tor mailing list.  When Tor Browser migrates to Firefox 91 ESR," he wrote, "we will look at enabling HTTPS-only mode for everyone.  But there remains a significant concern that there are many sites that do not support HTTPS," he said, "especially more region-specific sites, and the question of what messaging Tor Browser should use in that case."



In other words, unfortunately, it's still not practical to force HTTPS.  Yet arguably it's not safe not to have HTTPS if you're using Tor, without some other kind of protection.  So I think our takeaway here should be that Tor needs to be used with a full awareness of its inherent dangers.  While it can significantly obscure its users' real-world location and identity, many entities, both malicious and, Leo, as you noted, law-enforcing also, may be closely monitoring everything they can about a user's activities or about Tor's users' activities.  And even in some cases, if they're malicious, actively modifying and subverting any traffic that's available to them in the clear.  So whenever using Tor, keep in mind the danger of HTTP and the real need for some other privacy and security protecting tunnel such as a trustworthy VPN.  At this point, knowing what I know, I wouldn't consider using Tor without the added protection of a VPN.  I just, you know, I don't think you can.



LEO:  Hey, did you skip the Exim story?



STEVE:  Oh, my goodness.  How did I?  Thank you.



LEO:  I mean, you might have on purpose because, you know.  But I just thought I'd mention it.



STEVE:  No.  Thank you, thank you, thank you.



LEO:  Well, it wasn't me.  The chatroom and Jason and everybody went, "Hey, what about our Exim story?"  You did tease it.



STEVE:  I sure did.  And here it is.  So, okay, 21 nails are not going to kill Exim.  Nothing will kill Exim.  But it does mean that, if you or your organization is using the extremely popular, and we'll talk about just how popular in a second, Exim email transfer agent, which is the default email transfer agent provided by many Linux distros including Debian to send and receive email, you will definitely want to be sure - I mean, like this is one of those, okay, like pause the podcast and go update - you've got to be sure that you're running the most recently patched version.



Two months ago in March, E-Soft performed an Internet-wide study, probably due to the Microsoft Exchange Server debacle, studying the Internet's email servers.  They approximated that 60, six zero, percent of the publicly reachable mail servers on the Internet were running Exim - 60%.  So that obviously makes it, without any further computation, the most popular email server on the Internet, period.  Unfortunately, Exim, E-X-I-M, is short for "EXperimental Internet Mailer."  And after 17 years of its presence on Git, it might be nice if, today, it was a bit less experimental.



In response to Qualys's most recent security research, which we'll get to in a minute, all of the most widely used Linuxes  CentOS, Red Hat Enterprise, SUSE  have rolled out fixes.  Debian's "oldstable," codename Stretch; its "stable," codename Buster; and its "Still-in-development," thus Sid versions, they're all updated.  But the "unstable," which is codenamed Bullseye, remains vulnerable.  The problem is that there are hundreds of also-ran distributions, and it's of course up to each individual distribution to update their own packages and to then work to get those updated and replaced online, old instances updated and online.



So, okay.  Since most of - and of course 21 nails is 21 vulnerabilities.  Most of the 21 serious vulnerabilities Qualys uncovered date back to Exim's emergence 17 years ago, in 2004.  That is to say, all versions of Exim on the Internet are vulnerable.  So we're back in the all-too-familiar position of having publicly known and remotely exploitable vulnerabilities in email software that may not be receiving regular maintenance.  And a great many Internet-connected appliances may be based upon a build of Linux with a publicly exposed email agent running Exim.



So what did Qualys find?  The security researchers at Qualys dubbed their report "21 Nails" because from a source code audit - they just read the source.  From a source code audit they found 10 vulnerabilities that can be remotely exploited.  And most of the entire 21 can be exploited either in Exim's default configuration or in what they said was a very common configuration.  And, as I mentioned before, most of them affect all versions of Exim, all the way back 17 years to 2004.



There are 11 local vulnerabilities.  And I'll just give you a sense for that.  Link attack in Exim's log directory.  Assorted attacks in Exim's spool directory.  Arbitrary file creation and clobbering.  Arbitrary file deletion.  Heap buffer overflow in queue_run.  Blah blah blah.  Those are local.  So those are not remote.  We're mostly worried about the remote ones because that's where the attacks are going to come from, largely.



So we have, in all versions of Exim, 60% of the servers on the Internet, right:  Integer overflow in receive_add recipient.  Integer overflow in receive_msg.  Out-of-bounds read in smtp_setup_msg.  New line injection into spool header file.  Heap out-of-bounds read and write in extract_option.  Line truncation and injection in spool_read_header.  Failure to reset function pointer after BDAT error.  Heap buffer underflow in smtp_ungetc.  User-after-free in tls-openssl.c.  And Heap out-of-bounds read in pdkim_finish_bodyhash.



Okay.  So those all sounds tricky and techie.  Qualys has published a detailed write-up, I've got the link in the show notes, showing step-by-step code mistakes in the source and exploitation mechanisms.  But they stopped short of working exploits.  However, since Exim is open source and published under the GNU GPL, there's no point in attempting to obfuscate any of this.  So we can expect to be seeing still more trouble downstream as remote attackers use any older and not-just-updated Exim instances as their means of gaining entry to internal enterprise and government networks.  We already know what's going to happen.  I mean, this story has already been written.  I'm not going to go into the blow-by-blow detail here.  It's all available, as I said, on Qualys's excellent vulnerability disclosure.  But here's how they introduced their research.



They said:  "We recently audited central parts of the Exim mail server and discovered 21 vulnerabilities, 11 local and 10 remote.  Unless otherwise noted, all versions of Exim are affected since at least the beginning of its Git history, in 2004.  We have not tried to exploit all of these vulnerabilities, but we successfully exploited four Local Privilege Escalations and three Remote Code Executions."  They have four bullet points:  "We will not publish our exploits for now.  Instead, we encourage other security researchers to write and publish their own exploits."  Oh, yeah.  What could possibly go wrong with that?  They said:  "This advisory contains sufficient information" - and indeed it does - "to develop reliable exploits for these vulnerabilities.  In fact, we believe that better exploitation methods exist."  Sure.  Why not try some?



They said:  "We hope that more security researchers will look into Exim's code and report their findings.  Indeed, we discovered several of these vulnerabilities while working on our own exploits."  Oh, Jesus, they're cascading.  And, finally, they said:  "We will answer to the best of our abilities any questions regarding these vulnerabilities and exploits on the public 'oss-security' list."  And then there's a link in the notes.  And they said:  "Last-minute note.  As explained in the timeline, we developed a minimal set of patches for these vulnerabilities.  For reference and comparison, it is attached to this advisory and is also available at" - and then we have the link.



So in their disclosure, as opposed to the vulnerability disclosure in their announcement, basically, they wrote:  "Once exploited, they could modify sensitive email settings on the email servers, allow adversaries to create new accounts on the target mail servers."  And it's worth noting that Exim already has a history of trouble.  Back in June of 2019, Microsoft warned of an active Linux worm targeting an earlier Exim remote code execution bug.  And a month later, attackers started exploiting vulnerable Exim servers to install the Watchbog Linux trojan, which as a consequence added them into a Monero cryptomining botnet.  We know that's not going to happen now. Now what's going to happen is ransomware.



And the U.S. NSA, the National Security Agency, said last May of 2020, a year ago, that the Sandworm Russian military hackers have been exploiting that same critical Exim remote code execution since at least August of 2019.  In other words, we already have evidence of an older remote code execution vulnerability, known, published, and patched years before, still being leveraged by bad guys a year later.  Now Qualys has just dropped another goodie bag of these vulnerabilities in the email servers running 60% of the Internet's domains into the public discourse.  Of course, the Microsoft Exchange Server catastrophe showed us just how vulnerable an exploitable email server can be.  Now the whole world knows that Exim, the most widely deployed email server, can now be remotely exploited.



As Qualys themselves wrote:  "This advisory contains sufficient information to develop reliable exploits for these vulnerabilities.  In fact, we believe that better exploitation methods exist."  Oh, joy.  And if we thought that updating and cleaning up the big mess created by Exchange Server was a problem, just try doing that with the Internet's Exim servers, especially all those that are embedded into firmware-based appliances and long-forgotten dusty closets.  Yes, we will be talking about this, I'm afraid, in coming months.



LEO:  Those dusty closets are full of bad stuff, I'll tell you.



STEVE:  Oh, Leo.  It's not just dust bunnies.  It's bad guys.  And they're going to use this to get into corporate networks and to launch more ransomware.  Because now botnets are considered quaint, as is Monero mining.  Why do that when you can extort millions of dollars from a juicy target?



LEO:  Well, we're going to talk about that in a little bit, too, yeah.



STEVE:  We are.



LEO:  Steve, let's go with some extra stuff here.  Come on.



STEVE:  Indeed.  Yeah.  We have a novel.



LEO:  I'm so excited.



STEVE:  Yeah.  When I checked it out over on Amazon, I was told that I could have it for free as part of my Audible free trial.  So when we next talk...



LEO:  Wait a minute.  You're going to listen to it?



STEVE:  No, no, no.  I'm not.  But I know many - I just wanted to mention that it...



LEO:  I thought you were going to go Audible.  I was going to just fall off my ball.



STEVE:  I was going to mention you could have somebody read it to you, if you would like.



LEO:  Actually, Andy Weir uses a really good reader.  Lisa and I listened to "The Martian" together driving on the road to Hana in Hawaii.



STEVE:  Nice.



LEO:  We'll never forget it.  It was like a life experience that we shared that we'll always remember really, really well.



STEVE:  Okay.  So what we have for our listeners who don't yet know...



LEO:  I haven't said yet, yes.



STEVE:  Andy Weir, who is famous for having written "The Martian," has a new novel which the reviewers are just falling all over themselves for.  It's called "Project Hail Mary."  It's a solid five stars.  I looked at the demographic breakdown of stars, and it's like 84% are fives, and the balance are fours, with only a couple threes.  For example, Nick, who reviewed this on the fourth, the novel just came out a week ago, he's a verified purchaser.  He said:  "I don't even remember pre-ordering this book.  It just showed up in my Kindle app this morning."  He said:  "So I decided to read the first chapter before starting work.  Four hours later, I can finally put the book down since I'm done."



LEO:  Wow.



STEVE:  Now, I don't like to read that way because...



LEO:  It's gulping, not chewing and tasting.



STEVE:  You look around, and it's like, wait, what happened?



LEO:  What happened?  Where am I?  It is a 16-hour book.  So that's a good amount of reading in four hours.



STEVE:  Yeah, he went fast.  So he says:  "'The Martian' was a great story.  'Artemis'" - that's another one that Andy Weir wrote.  "'Artemis,' he says, "was a great story.  This one is better than either of those."  He says:  "If you like science fiction with actual science, this is for you.  If you like stories with interesting, well-developed characters, this also has that.  If you want excitement and a thrilling plot, here you go.  If you want romance and sex, well, there you're completely out of luck.  But if that was the kind of book you wanted, I doubt you'd be reading this review anyway.  Speaking of, why ARE you still reading this review?  Go read the book.  It's way better than this."



Somebody else said:  "Andy does it again."  He said:  "A spiritual sequel to 'The Martian' that had me grinning throughout the entire book.  Made my inner nerd squeal with delight on many occasions.  Has everything I ever wanted in a sci-fi book, just didn't realize it until now.  Read it.  That is all."



And I'll share one more, another five out of five.  I mean, they virtually all were.  This one's subject was "Stop reading this review.  Read 'Project Hail Mary.'"  He said:  "A previous reviewer said:  '"The Martian" was a great story.  "Artemis" was a great story.  This one is better than either of those.'  Wrong.  This one is MUCH better than either of those."  He said:  "Instant classic."  He said:  "If you mixed Asimov's 'The Gods Themselves' and Heinlein's 'Citizen of the Galaxy,' and added in a few gallons of Clarke and Niven, it would be like this.  I'd write more, but I'm off to re-read the novel."



LEO:  Oh, my goodness.  I want to get this now.



STEVE:  It sounds really good.



LEO:  Actually, you know, I want to get Andy - I interviewed Andy Weir of course after "Artemis."  It's interesting because "Artemis" was the beginning of a new series for him, and this book does not continue that.  Maybe he's planning to down the road.



STEVE:  So this is not a spoiler, and I have not read the book.  But this is something about a team of three go off on some distant mission to save the Earth.  And only one guy is left to solve, like, to figure this out.  So again, as I said, that's not a spoiler.  I've not read the book.  I don't know anything about it.  But wow.



LEO:  I'm going to try to get Andy in and do a special interview because...



STEVE:  Given that he apparently has really outdone himself.



LEO:  Yeah.  We interviewed him after "The Martian," and I think I interviewed him again after "Artemis."  So we should really get him for this.  All right.  We don't have the show anymore, but maybe we'll put it in Club TWiT or something like that.  Very cool.  Very cool.  I can't wait to read it.



STEVE:  Sounds like a win for our listeners.  Paul Babiak, he posted in the grc.securitynow newsgroup under the subject "One possible solution to QNAP vulnerability."  Actually, he found what I was maybe suggesting as a solution, a walkthrough of an installation of OpenMediaVault for the QNAP hardware.  I've got a YouTube link and a link to OpenMediaVault.org.  You can install non-QNAP firmware onto your QNAP NAS in order to get something that, I mean, it could - I was going to say, I was going to hedge my bets here and say, wait a minute, can I really assert that it's more secure?  Yes, because it could be not be less secure than what you're getting from QNAP.  So yes, thank you, Paul.



And also Jon S. sent by DM, he said:  "First hack that hits close to home.  Sitting in the ER of Scripps Health with my wife."  This was on Sunday.  He said:  "They were hacked a few weeks ago and are still doing all charts and orders via paper records.  The process is taking about 4 to 6 hours longer than normal for doctors to get lab work back.  Nurses are making notes on square sticky note pads.  I'm an IT sysadmin and security guy."  And obviously a listener to Security Now!.  And he DM'd me.  He says:  "This upsets me to no end.  Thought I'd share a few pictures for observations."  And he did include some photos of some screens of computers that are down at Scripps.  So we talked about the Scripps Health attack last week, and here he is.  I also told him that I hoped everything was okay with for whatever reason he was in Scripps ER with his wife.  But it really is having real-world consequences.  These things do.



Okay.  And I'll just mention that I have nothing huge to report on the SpinRite front.  I am unglamorously working my way through the code, line by line, changing the sizes of the registers and the variables used to manage drives, to accommodate today's larger than 2.2TB drives, containing any partitioning and any file system.  And also, since we'll be living with and using this codebase after it's converted from 16-bit real mode segmented code to 32-bit protected mode flat model, and also booting under UEFI and BIOS, and also to host native operation for USB and NVME mass storage, I am taking some time to clean things up a bit while I'm there, as I'm moving through it, to get it a little bit more ready for its future, which seems bright.



Now that I have access to upper memory, which I have never had before, I'm able to move some of the things that SpinRite had been cramming into lower memory up into upper memory to ease the pressure on the use of lower memory, which eliminates some jumping through hoops.  So anyway, I'm at work on it, and I am posting updates to the newsgroup.  And when I have them, new code to test, as I mentioned before.  And that's all been going well.



Okay.  News from the DarkSide.  Because this latest high-profile ransomware attack has been extensively covered by the popular press, I assume that our listeners already know that the largest fuel pipeline in the United States, run by a company called Colonial Pipeline, and actually the pipeline is also called Colonial Pipeline, it was shut down late Friday when they were forced to terminate all of their network operations in an effort to contain a ransomware attack.  And I assumed that there wasn't much more to know.  But in doing my due diligence for the podcast, I discovered that was not the case.



So Colonial Pipeline is keeping rather quiet about specifics, likely following advice coming at them from many sides.  But the FBI has confirmed that this was a ransomware attack conducted by DarkSide, a new Ransomware as a Service group, and remember we talked about Ransomware as a Service, how that's like the new way to do this.  And what we're developing is essentially a ransomware economy and sort of an ecosystem where we're getting specialization among the players that then form a chain.  So there are what do with the money specialists, bitcoin mixing and so forth.  There are the software development specialists, and there are the hack-into-the-system specialists.  And they're actually, I think they call them "access agents" or something.  I saw that the other day, it's like, oh, goodness.



Anyway, these guys are new.  They first appeared on the scene in August last summer, 2020.  So just to set the stage for anyone who may have been out hiking through the wilderness over the weekend and offline ever since, incredibly, Colonial Pipeline is responsible for transporting refined petroleum products - gasoline - between refineries located down in the Gulf Coast to markets throughout the southern and eastern U.S.  When its pipeline is up and running, as it always is, it transports 2.5 million barrels per day through the 5,500 miles of pipeline to provide an astonishing 45% of all fuel consumed by the East Coast.



So when the East Coast's petrochemical fuel supply suddenly and unexpectedly drops by nearly half, markets are upset, and states of emergency are declared, as has happened, by the Biden administration for Washington, D.C. and the seven states that the pipeline runs through.  This was temporarily done to lift restrictions on fuel transport by road in an endeavor to keep at least some fuel moving.  But good luck with that.  At 42 gallons per barrel, tanker trucks are not going to match a continuous flow of the 105 million gallons of refined fuel which normally flows through that pipeline every day.



The Governor of Virginia today, just today, Tuesday, declared their own state of emergency.  Their declaration begins:  "On this date, May 11th, 2021, I declare that a state of emergency exists in the Commonwealth of Virginia to prepare and coordinate our response to the voluntary shutdown of the Colonial Pipeline due to a cyberattack on its business systems' informational technology infrastructure on May 7th.  If prolonged, the pipeline closure will result in gasoline supply disruptions to various retailers throughout the Commonwealth, since the pipeline is the primary source of gasoline to many Virginia retailers."  And yesterday North Carolina declared a similar emergency, and gas station pump rationing has been instituted there.



Okay.  So now the famous SolarWinds attack, as we all know, made the news in March, loudly, because it was labeled "the most significant cyberattack ever."  So, okay, whoo, big headlines.  And people could be upset by the idea of that, especially since the attacks were credited to Russia-linked cybercriminals.  But the idea of that was the attack's only real effect on most people.  This time, of course, this is an effective attack against critical American infrastructure, forcing declarations of emergency.  When you cause the shutdown of nearly half the supply of gasoline to a large and influential portion of the U.S., the problem is no longer theoretical or superficial.



Okay.  So what about DarkSide?  I found a copy of their extortion demand note.  Actually I found many of them over time because this has been on the cybersecurity industry's radar since, as I mentioned, last summer.  And I have a - I'm getting close to the screen so that I can read this.  Maybe I can zoom in.  Although zooming in it's so fuzzy.



LEO:  Fine print, yeah.



STEVE:  Yeah.  It doesn't really help very much.  So they said:  "Welcome to DarkSide.  Your computers and servers are encrypted.  Backups are deleted.  We use strong encryption algorithms so you cannot decrypt your data.  But you can restore everything by purchasing a special program from us, Universal Decryptor."



LEO:  How thoughtful.



STEVE:  Yeah, isn't that nice they make that available, Leo, for the low, low price of several million dollars.  Anyway, they said:  "This program will restore all your network.  Follow our instructions below, and you will recover all your data."  And  then they said:  "What guarantees?  We value our reputation.  If we do not do our work and liabilities, nobody will pay us.  This is not in our interests.  All our decryption software is perfectly tested and will decrypt your data.  We will also provide support in case of problems.  We guarantee to decrypt one file for free.  Go to the site and contact us."



Then they say:  "How to get access on website.  Using a Tor Browser, download and install Tor Browser from this site."  And they point you to TorProject.org.  "Open our website."  And then they give us an onion domain, http, okay, no "s," http://darksid, and it's just "sid," and then fqzquhtk2.onion/ and then a big crypto-looking thing, looks like Base64 all caps.  Then they said:  "When you open our website, put the following data in the input form," and then they give a key.  Then they said:  "!!!DANGER!!!," three exclamation points on either side.  "Do not modify or try to recover any files yourself.  We will not be able to restore them."  And then "!!!DANGER!!!"



So, okay.  That's these guys.  In addition to the ransom note, victims of a DarkSide attack receive an information pack informing them that their computers and servers are encrypted.  The info pack lists all of the types of data that were stolen, and provides the URL of a "personal leak page" where the data is already loaded, waiting to be automatically published, should the company or organization being extorted from choose not to pay up before the deadline expires.  DarkSide also tells victims it will provide proof of the data it has obtained, and is prepared to delete all of it from their own storage once payment has been received.  I did also see, although this may have been earlier, I didn't see it in this particular attack, the doubling of the ransom demand in equivalent dollars if negotiation isn't concluded by a certain date.



Now, what's weird about these people is they appear to imagine that they're running a business more than a crime ring.



LEO:  They act like that, don't they.  It's like, we're a serious enterprise.



STEVE:  Yeah.  They really do.  Yeah.  Well, and when they released a new version of their software two months ago which could encrypt data faster than before, they issued a press release...



LEO:  Now 20% faster.  Geez.  Oh my god.



STEVE:  Yes, we'll mangle and tangle your network in half the time as previously.  They invited journalists to interview them.



LEO:  Oh, yeah, sure.



STEVE:  And their website on the dark web lists all the companies they have attacked and hacked and what was stolen from them.  And, get this Leo, they have an ethics page.



LEO:  Oh.



STEVE:  Listing which types of organizations they will not attack.  They've stated that they will not attack hospitals, hospices, schools, universities, non-profit organizations, or government agencies.  And I suppose after this, what they've just stepped in, they'll be adding "critical infrastructure" to that list.



LEO:  I have to figure Seal Team 6 is about to jump in their window.  This is not going to go well.



STEVE:  Exactly.  So anyway, that's something different about these guys.  They said they intend to cause no harm, they just want money.  On the website they wrote:  "Our goal is to make money and not create problems for society.  We do not participate in geopolitics, do not need to tie us with a defined government and look for our motives."  And in this case they realize they have probably painted a huge bull's-eye on themselves.  They indicated that they had not been aware that Colonial Pipeline was being targeted by one of their affiliates.  They wrote:  "From today, we introduce moderation" - a little late, but okay.  "We introduce moderation and check each company that our partners want to encrypt to avoid social consequences in the future."



So we know that they used the Salsa20 symmetric cipher with a custom matrix - and actually switching to that would have been responsible for the speed increase because it's very quick - and RSA-1024 for their public key operations.  So from a tech standpoint, their crypto appears to be well designed.  And that's been the consensus of the security industry since they appeared back last August.  Their ransoms have generally ranged from 200,000 to two million, so not nutty 50 million requests.



And traditionally much of this podcast is focused upon developing an understanding of just exactly how porous most of our network and, well, our computer and network security is today.  We look at the details, and we attempt to determine why these problems happen and what might be done to prevent such trouble in the future.  And unfortunately we've reached the conclusion that we're not ready for the world.  Most, if not all, of our existing IT infrastructure is not ready to stand up to determined attack.  Look what just happened with Exim.  This is going to be a catastrophe.



And it's a sad fact that we have to somehow deal with.  Much more focus, time, and attention is going to have to be put into the security side of our technology.  It's going to burn a bunch of time, effort, and money just to prepare.  But there's just no way around it.  It's expensive.  It's a waste of resources or consumption of those.  But it has to happen. 



LEO:  Well, that's what we talked about last week with this governmental task force.



STEVE:  Right.



LEO:  Right?  The timing was interesting because of course...



STEVE:  Oh, isn't that weird?



LEO:  ...then there's a massive infrastructure attack shortly after that.



STEVE:  Yup.  Yup.



LEO:  We clearly have to do something.  This has gotten out of hand.  And, you know, it's only a matter of time before something really serious gets hacked.



STEVE:  Well, yes.  And I had that same thought.  We've talked about how bad as COVID-19 has been, there are previous viruses like the Spanish flu of 1812 or whenever it was, where actually, if that one had happened today, the consequences would have been far worse.  My point is we get wakeup calls.  Remember the old expression, "Fool me once, shame on me?"  Wait, no, wait.  "Fool me once, shame on you.  Fool me twice, shame on me."



LEO:  Fool me three times, George Bush.  No, no, that's something else.



STEVE:  So, you know, we like having the lights on.  Lights are handy.  And having power for refrigeration and all the things that we use electricity for now.  Whenever we have a brief outage of our electric supply, often scheduled by our local supplier, you walk around flipping switches on rooms when you walk into them and think, oh, shoot, I forgot, we don't have any power.  We really, really, really are vulnerable.  And so again, this is inconvenient.  And I won't say in any way am I glad for this.  I am certainly not.  Except, as I said, the SolarWinds attack was arguably, ooh, bad headlines.  Bad Russians.  But now we don't have gas on the Eastern seaboard.



LEO:  Not good.



STEVE:  You couldn't get a better wakeup call.  You couldn't get a better, you know, a declaration of emergency by the administration to allow for more tanker trucks to run north and south.  Good luck.  That's 105 million gallons a day, that monster pipeline.  And Leo, we've also talked about a monoculture.  How about a mono pipeline?  That's just, you know, this whole, quietly in the background, everything is getting consolidated.  So we end up with many fewer, much less redundancy, and it becomes much more critical.  The lack of redundancy becomes protected.



LEO:  Apparently it blew up in 2016 and was shut down for two weeks.  So it's not the first time this pipeline has failed.  It just does seem like it's a very, very vulnerable setup.



STEVE:  It's fragile, yeah.



LEO:  Yeah.  Wow.  Boy, it just - it feels like we're hanging by a thread at all times.  I'll be honest with you.  Modern civilization is so interdependent and so unredundant.  That's why the Internet is such a miracle.  It's designed to survive catastrophe.  But apparently nothing else is.



STEVE:  We hung onto it.



LEO:  Yeah, yeah.  Oh, man.  That's scary.



STEVE:  And the Internet's dodged a few bullets.  We talked about Dan and discovering the danger that DNS was in.



LEO:  That's right, the DNS, yeah.



STEVE:  Okay, so here's Exim.  I guarantee you, you know, how much did we have to talk about the Exchange Server problem?



LEO:  Yeah, yeah.  It's not over.  Just beginning.  Well, Steve, we've come to the end of this grim edition of Security Now!.  As always, we thank you for elucidating these difficult topics and giving us at least some hope that something can be done about it.  Steve Gibson's at GRC.com, that's his website.  That's where you'll find of course SpinRite, the world's finest mass storage maintenance and recovery utility.



STEVE:  It's starting to roll off your tongue, Leo.



LEO:  Comes just right off, just like that.  No longer just hard drives.  Anything you store your data on.  You'll find it there.  6.0 is the current version.  Work proceeds apace, as Steve mentioned, on 6.1.  You can participate in that development and of course get a free copy of 6.1 if you buy 6.0 now.  You really need it.  While you're there, you can get a copy of this show, too.  Steve has the only 16Kb audio version of this show, for good reason.  But if you're bandwidth-impaired, you'll be glad.  He also has transcripts written by an actual human being.  Elaine Farris does such a nice job with those.  That's at GRC.com.



And of course, as always, it's free.  64Kb audio versions, as well.  We have audio and video at our website, TWiT.tv/sn.  So you can download it there.  If you want to watch us do it live, it's every Tuesday at about 1:30 p.m. Pacific, 4:30 Eastern, 20:30 UTC.  The livestreams are at TWiT.tv/live, audio and video.  And if you're watching live, you should chat with us live at irc.twit.tv.  Steve, I hope you have a wonderful week, and we'll see you next week.



STEVE:  Will do, my friend.  Ciao.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#819

DATE:		May 18, 2021

TITLE:		The WiFi Frag Attacks

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-819.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we follow up on last week's "News from the DarkSide" with a surprising amount of happenings including the dark web's rejection of further ransomware.  We look at blockchain analytics which are used to follow the dark money, the mixed signals now coming from the DarkSide group, and a live list of more than 2,000 ransomware attacks during the past two years from the dark web.  We cover last week's Patch Tuesday that you won't want to miss.  We have a bit of miscellany, including the "Unidentified Aerial Phenomena Task Force" which is actually a thing, and some closing-the-loop feedback from our listeners regarding last week's Andy Weir's "Hail Mary" book mention.  Then we take a close look at the biggest non-Colonial Pipeline news from last week:  a new round of research which revealed a range of attacks on WiFi's security.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We are going to kick off by explaining last week's Picture of the Day for those of you who couldn't quite figure out why it was funny or even interesting.  But then we're going to talk about the DarkSide attack and what's happening to the DarkSide hackers.  We'll also get a review of Patch Tuesday.  That was last Tuesday.  Steve has a thumbnail for you.  And then finally we're going to wrap things up with this new WiFi attack that affects every version of WiFi encryption known, the Frag Attacks.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 819, recorded Tuesday, May 18th, 2021:  The WiFi Frag Attacks.



It's time for Security Now!, the show where we get you and your loved ones to safety somewhere in the middle of your house, let's hope within a concrete bunker.  It is getting crazy out there.  But there is nobody better to report that than Mr. Steve Gibson, the host of Security Now!.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.



LEO:  What's up?



STEVE:  Great to be with you again.  Well, the big news, actually it was like a week ago, was the announcement of some new attacks on WiFi.  So I thought, okay, that's what we're going to talk about.  But then we just kept getting more news, as our last week's episode was titled, from the DarkSide.  So we're going to follow up on last week's News from the DarkSide with a surprising amount of the happenings, I mean, including the dark web's rejection of further ransomware.  We look at bitcoin analytics, which are used to follow the dark money as it moves around.  We've got mixed signals now coming from the DarkSide group themselves.



And something that's really interesting, when I was digging around I found a live list of more than 2,000 ransomware attacks during just the past two years that is posted and maintained on the dark web.  We're also going to cover last week's Patch Tuesday because this is the third Tuesday of the month, and we don't want to miss that.  We've got a bit of miscellany, including - I don't know, Leo, if you saw "60 Minutes" from Sunday?



LEO:  No.



STEVE:  The second of the three segments that "60 Minutes" always does, they do three per Sunday, was on the "Unidentified Aerial Phenomena Task Force," which is actually a thing.



LEO:  Oh, yeah.  They don't call them UFOs, notice.



STEVE:  That's correct, they're no longer UFOs.  They are UAPs.



LEO:  Yeah, because they don't want to imply that it's really an alien, it's just we don't know what the hell it is.



STEVE:  We don't know what it is, but it appears to be something is going on.



LEO:  Well, it is something, but I don't think it's aliens.  That's a little [crosstalk].



STEVE:  I'm not saying it is.  I'm just, you know, these things are behaving in ways they don't understand.



LEO:  Right.



STEVE:  So we'll talk about that.  Also we've got some closing-the-loop feedback from our listeners regarding last week's recommendation of Andy Weir's "Hail Mary" book, which you and I were talking about before we began to record this.  So we'll touch on that with no spoilers.



LEO:  Yeah.



STEVE:  Then we're going to take a close look at the biggest non-Colonial Pipeline news from last week, which as I mentioned is a new round of research which comes to us from some people who have paid their dues and whose research we believe.  They were the guys behind the original, it was like 2017, the WiFi Frag Attacks.  I mean, not frag attacks, no, sorry, the - now I forgot it because I got myself confused with frag attacks.  Frag Attacks is this week.  It was - we'll get to it when we get to it.  



LEO:  They were KRACK; right?  It was called KRACK.



STEVE:  KRACK, the KRACK Attacks, yes.  They are back with more attacks after the KRACK attacks.



LEO:  KRACK is back.  This time it's FRACK.  All right.  Big show.  Really big show.  And will you explain the Picture of the Week from last week for those...



STEVE:  Yes, I will.



LEO:  No spoilers.  And we have a new Picture of the Week.



STEVE:  Oh, good point, good point.  We did promise to close that loop.  Yup.



LEO:  Yeah, yeah.  Do you want to explain first, or show the new one?



STEVE:  Explain first.



LEO:  Okay.  Let me pull up the old one.



STEVE:  If I were to do a two-word clue that would, like, people would smack their foreheads against their hands, I would say "Doppler shift."



LEO:  Yeah, that should pretty much do it for you.



STEVE:  That ought to do it.



LEO:  All right.  So let's show you the picture again real quickly.  So it starts - there's two frames, two panes.  One, an old man looking to the left.  There's a little blue car coming toward him.



STEVE:  Towards him, yes.



LEO:  Looking to the right, there's a big red car going away from him.



STEVE:  Right.



LEO:  How did this happen?



STEVE:  So we know a couple things.  Everyone's familiar with the classic phenomenon because it's not something we...



LEO:  [Demonstrating]



STEVE:  Exactly, that we experience when, for example, a train roars past.  You hear a higher frequency as it's approaching and a lower frequency as it's leaving because the waves, in this case sound waves, are compressed as it's moving towards you because the source is approaching you, and the reverse happens as it's moving away.  Well, exactly the same thing happens with light, at of course a way higher, well, not air being compressed and rarified, it's electromagnetic radiation.  So you get both physical foreshortening, thus the scrunched-up car which is blue because that's a higher frequency of light as it's approaching.  And as it's leaving you get it appearing stretched out and red, which is a lower frequency of light.



LEO:  Which Edwin Hubbell, the astronomer, called "red shift."  Right?



STEVE:  Exactly, you have blue shift and red shift, exactly.  



LEO:  That's what gave it away to me.  Hubbell in 1929 figured out that you could use the shift in the spectrum of the light of stars to determine how far away the star was, which is pretty darn cool.



STEVE:  Exactly, by determining their relative motion to you.



LEO:  Yeah, yeah.



STEVE:  So very cool.  And this week's picture is just sort of, comparatively, a throwaway.  I had it in the stack.  You stumbled upon it last week, probably from someone posted it in the chatroom.  I mean, it's fun.  It shows the classic plastic-shelled 3.5" diskette that has a - actually I have a Sony label that looks just like that, but mine does not say "Bitcoin Wallet" on it.  I wish it did because then maybe there would be a chance I could recover it.



LEO:  You could use SpinRite to get it back.



STEVE:  That's right.  And there have been many, you know, a lot of fun has been had with the idea of messing magnets with diskettes of all forms through the years.  So here we have probably a strong round refrigerator magnetic, looks like it's on a refrigerator.  I'm familiar with that texture of plastic-coated sheet metal that the "Bitcoin Wallet" labeled diskette is  being held against the refrigerator with.  So anyway, yes, how not to store your cryptocurrency.  I wouldn't put it on a diskette, by the way, anymore.  I mean, they're reliable, but  there's way better ways to do that.  So anyway, just sort of a fun picture.  And we've got more coming in the future.



Okay.  So some DarkSide follow-up.  The team at FireEye - they also call themselves Mandiant, the research group.  Eight of them put their names on this report because it was extensive.  And I'm just going to talk about the first third of it because they go deep into the operating mechanism of the actual ransomware that DarkSide is known to be pushing and which of course now famously infected the Colonial Pipeline organization.  They've done a bunch of deep and delicious research into the group and their software.  And they originally took this work public last Tuesday on the 11th, while we were doing this podcast, essentially, last week.  But after the news of the apparent DarkSide takedown surfaced, they updated their post just last Friday, adding the following preface.



They said:  "Mandiant has observed multiple actors cite a May 13th announcement that appeared to be shared with DarkSide RaaS (Ransomware as a Service} affiliates by the operators of the service.  This announcement stated that they lost access to their infrastructure, including their blog, payment, and CDN servers, and would be closing their service."  That is to say, DarkSide apparently announcing that they're closing their service.  Now, I've got a little story about Toshiba here in a minute that sort of makes you wonder about that.



But they also said:  "Decryptors would be provided for companies who have not paid, possibly for their affiliates to distribute.  The post cited law enforcement pressure and pressure from the United States for this decision."  And the FireEye Mandiant guy said that:  "We have not independently validated these claims, and there is some speculation by other actors that this could be an exit scam."  So I'm just putting that out there because it's out there.  We don't know one way or the other.



What we do know is that beginning in November of 2020, the Russian-speaking actor known as "darksupp" (D-A-R-K-S-U-P-P) began advertising the DarkSide Ransomware as a Service on the Russian language forums, two of them, exploit.in and xss.is, obviously as in cross-site scripting.  And interestingly, in the past few days, both of these sites, and I've got a lot more to say about that in a second, have indicated that they would no longer host ads and forums or postings, contents, and threads, for ransomware services, stating that it has drawn too much unwanted attention from law enforcement.  I actually - we have some translated-from-Russian quotes that we'll get to.  Anyway, since that's also big news, we'll have more to say about that later.



Okay.  But last month, April 2021, darksupp, apparently like the guy behind DarkSide, posted an update for the DarkSide 2.0 Ransomware as a Service that included several new features and a description of the types of partners and services they were currently seeking.  And so from that we gain some more information about them that we didn't have before.  Affiliates retain a percentage of the ransom fee from each victim.  Of course I would argue affiliates get the lion's share, right, of the ransom fee, which was one of the things that impressed us when we first started talking about this several years ago was that the services were doing the right thing by basically taking a commission, essentially.



So based on the advertisements that have now been seen, the operators, that is, the Ransomware as a Service operators, in this case DarkSide, take 25% ransom fee when the amount paid is less than half a million dollars.  And that decreases from 25% for less than a million dollars down to 10% for fees greater than 5 million.  In addition to providing builds of DarkSide ransomware, the operators of this service also maintain a blog accessible via Tor.



LEO:  I think it's ironic that Apple takes a larger cut on the App Store than DarkSide does of the ransomware.



STEVE:  Yes.  Oh, and Leo, on the next page of the show notes - you might want to put this on the screen - we have a picture of the control panel that the affiliates use in order to do this.  It's sort of amazing.  The actors use this site, their Tor site, to publicize their victims in an attempt to pressure those organizations into paying for the non-release of the stolen data.  A recent update to their underground forum advertisement also indicates that actors may attempt to DDoS victim organizations.



The actor darksupp, who's apparently behind DarkSide, has stated that affiliates are prohibited from targeting hospitals, schools, universities, nonprofit organizations, and public sector entities.  And this may be, as we would imagine now, an effort by the actors to deter law enforcement action since targeting these sectors may invite additional scrutiny.  Affiliates are also prohibited from targeting organizations in Commonwealth of Independent States (CIS) nations.



So the original November 2020 advertisement boasts some features which they wanted to make clear of their service, the DarkSide.  The ability to generate builds for both Windows and Linux environments from within the admin panel.  Encrypts files using - and we knew this last week - Salsa20 encryption along with RSA-1024 public key crypto.  Access to an administrative panel via Tor that can be used by clients, meaning their affiliates, to manage DarkSide builds, payments, blog posts, and communication with their victims.  The admin panel includes a blog section that allows their clients, their affiliates, to publish victim information and announcements to the DarkSide website for the purposes of shaming victims and coercing them to pay ransom demands.



Then in an update that we talked about, middle of last month, in April, they added automated test decryption.  They said the process from encryption to withdrawal of money is now automated and no longer relies on support, meaning there's no response delay from darksupp and his minions behind the scenes.  It's all now an automated process.  They're also available, they have DDoS for targeting both at Layer 3, which is at the network layer, and Layer 7, at the protocol layer.



And they said:  "Seeking a partner to provide network accesses and a person or team with pentesting skills."  And just for entertainment value, and actually to show how slick and polished this looks,  I have in the show notes a screenshot of this control panel, which is available through the Tor network, a means to get to their site, showing all the switches and bells and whistles and stuff that is there.



LEO:  It's really kind of polished.



STEVE:  It really is.



LEO:  It's surprising.  But it shows you that they're acting, they feel, with complete impunity.  And probably because they're Russian nationals, maybe even because they have some government protection, they just don't feel vulnerable to anything.  So they figure, well, let's do it right.  Let's make a nice little site here.



STEVE:  Right.



LEO:  They're probably very good coders.



STEVE:  Their physical security is safe.



LEO:  Right.



STEVE:  They feel like they're able to put things up in Tor.  They're transacting using bitcoin.  So it's like, you know, nanny nanny nanny, you can't get us.  So would-be affiliates are required to pass an interview, after which they're provided with - yes, they're interviewed.



LEO:  Yeah, we don't want any - no losers here.



STEVE:  That's right.  That's right.  Then they're given access to the admin panel and told to have at it.  And using this panel, affiliates can perform various actions such as creating a ransomware build for themselves, providing content to the blog, managing their victims, and contacting the backend DarkSide support if they've got questions or need help.  The Mandiant guys have identified at least five Russian-speaking actors who may currently or have previously been DarkSide affiliates.  The relevant advertisements associated with a portion of these threat actors have been aimed at finding either initial access providers or actors capable of deploying ransomware on accesses already obtained.



Some actors claiming to use DarkSide have also allegedly partnered with other RaaS affiliate programs, including Babuk and the Sodinokibi, also known as REvil.  And I guess it should not be surprising that affiliates might be maintaining relationships with more than one Ransomware as a Service provider at a time.  I suppose that at some point the convenience of using the RaaS service, maybe the size of the piece of the action which the ransomware provider takes from the ransom payment would become a consideration, how responsive they are, how trusted they are and so forth.  So, you know, nothing prevents the affiliates from setting up relationships with multiple Ransomware as a Service providers.



So in their report the FireEye Mandiant guys provided detailed affiliate-specific information about three specific affiliates.  I won't go into each of them here.  But it was interesting to see that - I did go through them myself.  And I saw that each of the three were clearly distinct and quite different from the others in their means of initial penetration and the way they moved within networks once they were in.  They clearly felt like very different threat actors where the only obvious link between the three was that they all decided that they were going to use DarkSide as their ransomware attack package.



And so the Mandiant guys concluded their general discussion in the first part of this long blog posting by writing.  They said:  "We believe that threat actors have become more proficient at conducting multifaceted extortion operations, and that this success has directly contributed to the rapid increase in the number of high-impact ransomware incidents over the past few years.  Ransomware operators have incorporated additional extortion tactics designed to increase the likelihood that victims will acquiesce to paying the ransom prices.



As one example, in late April of 2021, the DarkSide operators published a press release" - get this, Leo, the DarkSide put out a press release - "stating that they were targeting organizations listed on the NASDAQ and other stock markets.  They indicated that they would be willing to give stock traders information about upcoming leaks..."



LEO:  Everything but the squeal, baby.  Just use it all, baby, everything.  Gonna make money in every possible way.



STEVE:  That's right.  We're going to switch into the insider trading business, giving stock traders information about upcoming leaks "in order to allow them potential profits due to stock price drops after an announced breach."  Wow.  "In another notable example," they wrote, "an attacker was able to obtain the victim's cyber insurance policy data and leveraged that information during the ransom negotiation process, refusing to lower the ransom amount given their knowledge of the policy limits.  This reinforces that during the post-exploitation phase of ransomware incidents, threat actors can engage in internal reconnaissance and obtain data to increase their negotiating leverage."  They said:  "We expect that the extortion tactics that threat actors use to pressure victims will continue to evolve through 2021."



And they finished:  "Based on the evidence that DarkSide ransomware is distributed by multiple actors," and in fact I think, oh, no, I was getting myself confused about a number that we'll get to in a second.  Anyway, they said:  "...distributed by multiple actors, we anticipate that" - and this is a term of art now - "TTPs, the tactics, techniques, and procedures used throughout incidents associated with this ransomware will continue to vary."  And as I said, given the three very different users of DarkSide affiliates, that they did detail, they really looked like entirely separate entities.



So thanks to the colossal focus brought to bear by the Colonial Pipeline attack  which, if nothing else, the DarkSide operators certainly regret in retrospect  the industry at large has been able to get a detailed look into the operation of a Ransomware as a Service operation, arguably with more detail and focus than we've had so far.  It's been widely noted that cryptocurrency has been an enabling factor for ransomware since it potentially solves the problem of the bad guys getting away with the goods.  But does it really?  Let's take a look at what we find when we follow the money.



A company called Elliptic was founded eight years ago to develop and deploy blockchain analytics.  And they're certainly not alone now.  Blockchain analytics is a thing.  In this case, they use it for tracking financial transactions on the dark side of the blockchain.  Tom Robinson is Elliptic's co-founder and chief scientist.  He recently shared what they had learned about DarkSide after aiming their blockchain analytics at DarkSide's transactions.  First, they needed to identify DarkSide's wallet.  He wrote, based upon - and I guess I've changed the person of this.  So based upon their intelligence collection, that is, on Elliptic's intelligence collection and analysis of blockchain transactions, they were able to positively identify the bitcoin wallet used by DarkSide to receive ransom payments from its victims.



Now, "bitcoin wallet" is sort of a shorthand; right?  What it actually means is the bitcoin address, which is to say the public key which is associated with the private key stored by the wallet.  But because the blockchain is just an immutable ledger of all transactions which have been asserted and verified by the mechanisms, the crypto mechanisms of the blockchain, when you say "we have the wallet," what it really means is they identified the public key associated with one transaction.  Then they went back through the entire transaction history in order to track everything that has happened, all the transactions against that particular public key that's been posted to the blockchain ledger.



So what they said was - so that is blockchain analytics.  They said:  "This was the wallet that received the 75 bitcoin payment made by Colonial Pipeline on May 8th."  They said by following the blockchain backwards they were able to determine that this wallet has been active since March 4th, meaning that was the first appearance, right, of a transaction against the same public key and, they wrote, has received a total of 57 payments from 21 different wallets.



Now, depending upon the size of those, they didn't articulate those any further.  We don't know if that was 57 individual extortion payments or if other financial transactions were happening using the same wallet.  But money was apparently coming in.  They said "received a total of 57 payments from 21 different wallets."  So not 57 different wallets.  But it could have been from some exchanges that would tend to aggregate payments through the exchange.  So you would see money coming in from fewer wallets representing still more ransoms.



They said some of these payment amounts exactly match ransoms known to have been paid to DarkSide by other victims, such as the 78.29 bitcoin, worth 4.4 million at the time, that was sent by the chemical distribution company Brenntag a few days earlier, on May 7th.  And I don't explicitly cover Brenntag.  It's in the tech press now.  And it absolutely is a confirmed, another DarkSide ransom that was paid, 4.4 million in this case.  They're a big German firm with several, I mean, like 1,200 employees in hundreds of locations.  So a big operation.



And they said:  "The affiliate payment for both the Colonial Pipeline and Brenntag ransom payments were transferred to the same bitcoin address, which suggests that the same affiliate was behind the original infections and intrusions into both of these organizations.  This also revealed that a previously unknown ransom payment for approximately $320,000 was made to DarkSide the day before, on May 10th.  And those bitcoins originated from the same exchange that was used by Colonial Pipeline.  That was presumably just a coincidence, since Colonial's payment had already been received in full earlier."  But as I said, you might have fewer wallets sourcing money into a single wallet because they're being consolidated through an exchange, which as these guys note is the case here.



So they said:  "In total, that DarkSide wallet has received bitcoin transactions since its March inception totaling $17.5 million.  Now, we know that DarkSide has been active since last August.  So previous ransoms would have been paid to other wallets."  And again, there's no reason that anyone needs to stick with the same wallet for any length of time.  You just, you know, you can create those literally out of thin air by generating a new private key, creating its matching public key, and then having transactions occur against that public key.



So we know what's coming in, and we've seen some affiliate payments going out.  What else is going out?  Thanks to modern blockchain analytics, the destination wallet of any monies sent from another wallet can also be determined.  We know that there are reports that DarkSide had ceased operations and that it had its funds seized.  First of all, that's easier said than done.  And those in the know are highly skeptical that the people behind DarkSide would be maintaining a so-called "hot wallet" online.  The blockchain is, as I have said, able to accrue transactions to a wallet without the wallet being present.  And if it's not online, and/or if its private key is not compromised, it's not possible to confiscate a wallet's funds.



So again, they claimed that their money was stolen.  It's like, okay, maybe if you're really lame.  Anyway, what we do know, thanks to blockchain analytics, is that the wallet in question was emptied of the 5 million in bitcoin it contained last Thursday afternoon.  Some have imagined that the funds were seized by the U.S. government.  But if so, they didn't get the same ransom bitcoins which were paid to DarkSide since the majority of those coins were previously known to have been moved out of the wallet the Sunday before, on May 9th.  So again, the bitcoins, it's not like which bitcoins came in and which ones went out.  It's just a quantity.  It's not a number of individual things.



So okay.  By tracing previous outflows from the wallet, Elliptic was able to gain some insights into how DarkSide and its affiliates were laundering their previous proceeds.  They found that 18% of the wallet's bitcoins were sent to a small group of exchanges, and an additional 4% was sent to Hydra, which is the world's largest darknet marketplace.  It serves customers in Russia and the Eastern bloc.  Hydra offers cash-out services alongside other illicit things - narcotics, hacking tools, and fake IDs.  And these allow bitcoin to be converted into gift vouchers, prepaid debit cards, or cash rubles.  So if you're a Russian cybercriminal, and you want to cash out your crypto, Hydra is a place where you would do that.  Although in this case, 4% was sent to Hydra from the money that Elliptic was tracking, so not a huge amount.



The owners of any wallet are known and identified only by their public and private keys, which are themselves cryptographically strong random numbers.  And bitcoin transactions are conducted between those random numbers, making them inherently anonymous.  And in that sense the blockchain is a little bit reminiscent of the Tor network.  As we know, traffic goes into Tor nodes and emerges elsewhere such that the interconnections among the endpoints are not directly knowable.  But also, similar to the Tor network, the appearance of absolute and perfect anonymity which they both present, it actually begins to collapse as soon as either one, the Tor network or the bitcoin blockchain, begins to interact with the outside world.



By carefully examining and modeling individual transactions on the blockchain, which functions, as I said, as an immutable public ledger, we can know when a ransom victim pays a known sum to a known bitcoin wallet.  That transaction exists because it's recorded on the blockchain.  And the subsequent movements of its funds can be followed.  Bitcoin mixing services, which we've talked about briefly before, have arisen specifically to fragment, confuse, scatter, and gather bitcoin funds to thwart this sort of transaction tracking.  And we even now have the notion of so-called "chain hopping," where funds are moved between different forms of blockchain in order to further obscure their movement.



So in the typical cat-and-mouse back-and-forth, there has been an attempt to evade the fact that, yeah, bitcoin has many advantages; but, in reality, perfect anonymity is not one of them.  Just as it isn't perfect with Tor.



So one last note is, and I don't know what - the timing of this was interesting because Toshiba was attacked by DarkSide.  Last Friday, the French subsidiary of Toshiba Tec Corp., which manufactures barcode scanners, point-of-sale systems, printers, and other equipment, said that it was struck by the DarkSide ransomware, which has impacted some regions in Europe.  Toshiba Tec shut down networks between Japan, Europe, and its subsidiaries to, as they put it, "prevent the spread of damage," while recovery protocols and data backups were implemented.  Reuters reported that the Toshiba subsidiary said that only a minimal amount of work data had been lost.



Toshiba apparently said:  "We have not yet confirmed that customer-related information was leaked externally," though the company did acknowledge that "it is possible that some information and data may have been leaked by the DarkSide group."



So when this news surfaced Friday, DarkSide's leak site was still inaccessible, but DarkSide said that they were taken down.  Remember that there is some decoupling here; right?  So DarkSide is the source of the ransomware, but it was an affiliate that would have done the breaching of Toshiba.  So it's certainly possible that DarkSide could have said, as they appear to have, okay, we're done.  This is not worth it, all the grief this is causing.  We're sorry about your pipeline.  We're out of business.  Then an affiliate used the ransomware which had been produced by that control panel earlier to attack Toshiba.  Maybe they'll get a free key in order to decrypt themselves.  We don't know.



Anyway, when this news surfaced on Friday, DarkSide's leak site, as I said, was still inaccessible.  But ZDNet successfully accessed a cached version of their site which had been archived by KELA's Darkbeast search engine, which was news to me.  Https://ke-la.com is a search engine for the dark web.  The archive data that ZDNet found shows stolen passport scans alongside project documents and work presentations allegedly belonging to Toshiba.  So it appears that some exfiltration did occur, and DarkSide's leak record posted last Thursday the 13th indicates that over 740GB of data was stolen from Toshiba.  So exactly as you were saying earlier, Leo, lots of gigabytes of data is often exfiltrated by these guys.  



LEO:  Yeah.



STEVE:  And the timing of this is interesting since, as I said, it does follow by several days the apparent takedown of much of DarkSide's operational infrastructure.  But again, these things are decoupled.



LEO:  Brian Krebs had a really weird trick, I don't know if you saw it on his blog.  It turns out DarkSide and many other ransomware programs will not activate if you have a Russian language virtual keyboard installed.



STEVE:  Keyboard installed, yup.



LEO:  Russian, Ukrainian, Belarusian, Tajik, Armenian, Azerbaijani, Georgian, Kazakh, Kyrgyz, Turkmen, Uzbek, Tatar, Romanian, Russian, Azerbaijani, Uzbek, or Arabic.  And so it could be, he suspects, could be a couple of things, partly that they don't want to get in trouble with Russian security.  Right?  So, and he also points out this probably isn't a good mitigation.  Although why not?



STEVE:  Well, what will happen is it's different to have it installed than to have it active.



LEO:  Right.



STEVE:  And right now the ransomware is naive to whether you're actually using the Russian keyboard or not.



LEO:  Right, right.



STEVE:  So it'd be good in the short term.  But, yeah, you don't want to rely on it.



LEO:  I wouldn't completely count on it.



STEVE:  It's a cute hack.  And Leo, let's take our second break.



LEO:  Okay.



STEVE:  And then we're going to talk about some more stuff.  The real world inconvenience caused by the Colonial Pipeline attack has brought unwanted scrutiny  unwanted by those being scrutinized  to the entire supporting ransomware ecosystem, and that's from advertising for new affiliates to the laundering of their ill-gotten proceeds.  As we know, obviously this new model for ransomware, Ransomware as a Service, requires bringing the presence of that service to the attention of new potential affiliates on an ongoing basis.  So it's extremely significant that the two most popular Russian language hacking forums on the dark web, "xss.is" and "exploit.in," after feeling the pressure of that new and definitely unwanted scrutiny, have reacted by banning all future discussion of ransomware across their sites.



Last Thursday the admin of xss.is, which has been serving as the central hub, that is, xss.is has been serving as the central hub for almost all of the top Ransomware as a Service providers, announced that Ransomware as a Service on the forum is hereby prohibited.  All prior posts relating to ransomware will be deleted, and no new posts relating to ransomware will be allowed.  The admin's post states that:  "Ransomware affiliate programs, ransomware rental, and the sale of lockers, as they are called, are prohibited, and all existing topics will be deleted."  I found a translation of the Russian language posting, which has some interesting bits of feeling in it.



The translation reads - it's got a couple topics.  "Degradation on the face."  And again, remember this is a translation from Russian.  But this is what was posted by the person running the admin of xss.is:  "Newbies open up the media, see some crazy virtual millions of dollars that they will never get.  They don't want anything, they don't learn anything, they don't code anything, they just don't even think.  The whole essence of being comes down to 'encrypt - get $.'  They just run to GitHub, look for locker sorts there, and run to encrypt everything they see.  Since our forum is aimed at beginners, this factor is important to us."



Then the next subject was "Too much PR."  It says:  "Lockers (ransom) have accumulated a critical mass of nonsense, nonsense, hype, noise.  When you meet the 'Ransomvarny negotiator' profession, you understand that you are in the looking glass or just crazy.  Moreover, 90% of this madness was created artificially, feeding this hype.  Those who make good money on this noise," he says, "(exchanges, insurance, intermediaries, media, et cetera)."



And then "Ransomware became political."  Peskov, that's the Russian guy who was forced to explain this over on Russia's side, "Peskov is forced to make excuses in front of our overseas 'friends.'  This is some kind of nonsense and exaggeration.  The word 'ransom' was equated with a number of unpleasant phenomena:  geopolitics, extortion, government hacking.  This word has become dangerous and toxic."  And then he finishes:  "Lockers will exist for a long time.  This phenomenon was too loudly promoted."



Okay.  That's the end of that original posting.  The initial response to that by several of the ransomware gangs - so now we're talking the REvil gang, Sodinokibi, well, same, DarkSide, you know, those guys, was that they would be leaving xss.is and moving to exploit.in.  That is, until exploit.in followed suit the following day, last Friday, and also moved, as xss.is had, to ban all ransomware discussion and advertising from their forums also.  And perhaps not surprisingly, on Sunday, day before yesterday, both forum sites went down due to sustained DDoS attacks, doubtless launched by one or more of the now-banned RaaS gangs.



Xss.is has been struggling to remain online, and here's the post recently made by its admin, and this one was translated to English by a Russian-speaking English speaker.  So but this is what xss.is admin just posted:  "We are under a powerful DDoS attack.  Requests and orders to 'eternally kill' the forum are sent to almost any more or less serious DDoSer in the community.  They offer decent money.  I'm sure that the attacks were paid for by one of the offended adverts of RaaS programs banned.  Guys, calm down.  Do not be offended and bring chaos around you.  We are tech specialists, not thugs.  For those who are having difficulty getting the message, I will repeat it more bluntly.  We receive 'signals,'" which he has in quotes, "including political signals.  The era of ransomware is over for all sane people."



LEO:  Oh, I wish that were true.



STEVE:  I know.



LEO:  I don't think so.



STEVE:  I know.  He said:  "I consider myself and the forum to be an adequate component of our society.  Please accept this information.  If you happened to work in ransomware, it's time to forget everything and find other activities or come up with other options for monetizing your accesses."



LEO:  Go get a job.



STEVE:  He says:  "Believe me, my decision for the ban will save your own," and then asterisks, so probably your own asses.  He said:  "Honestly, you should strongly and sincerely thank the forum from the bottom of your heart and understand the 'signals,'" again in quotes, "that we all receive.  I state this now with all seriousness and responsibility.  For those who have some free money left, you can always donate to our favorite forum, XSS, instead of wasting this money on DDoSes.  We will keep running hacking contests and pay the authors of the articles.  Thank you all for your attention."



So okay.  There are some people who live in this world, and their take on this is this is, I mean, obviously, Leo, I agree with you.  This is not the end of ransomware.  It's not going to go away because the two forums that were the main clearinghouses and meeting places and advertising venues for these things have said not here any longer.  But it's going to, I mean, it's going to probably slow things down or change things a bit.  The oblique references to "signals," you know, we receive signals, including political signals, strongly suggests that there is an overwhelming amount of anti-ransomware pressure being brought to bear in the wake of this Colonial Pipeline disaster.



LEO:  As there should be, yes.



STEVE:  Exactly.  And of course it's not up to the admin of this popular Russian meeting place to unilaterally declare that, quote, "The era of ransomware is over for all sane people."  Unfortunately, it's turned out to be highly lucrative, so it will continue.  But this does suggest that moving forward the organization of Ransomware as a Service will likely need to be conducted much more quietly and less overtly than it has been until now.  And it probably also means that to some extent the exploitation of these ransomware lockers, you know, the actual ransomware itself, may return to their previous origins, being used more by their own developers than those who were able to farm out that and create the whole affiliate concept.



Okay.  So I have one other really cool tasty bit.  During my recent digging around, I stumbled upon a live spreadsheet which purports to list, and based on my quick checking appears to, the past two years of ransomware attacks by victim, gang, and date.  At the moment, this list carries the headline "List of victim organizations (2,203) attacked by ransomware gangs (34) released on the dark web."  The list appears to have been compiled by an organization calling themselves DarkTracer, and they have a nice-looking site.  DarkTracer (T-R-A-C-E-R) dot com.  And it likely lags a bit in its listings since it does not yet list the Colonial Pipeline attack.  But to check it out a bit, I noted that it does contain 99 entries for DarkSide, starting with August 8th, 2020.  And we have heard previously that that's when DarkSide first emerged.  And I looked for the first DarkSide entry in the list.



And for anyone who's listening, I created a bit.ly, I mean a GRC shortcut to a PDF of it.  I did not want to directly point anybody at this live list from lord knows where.  So I carefully created a PDF:  grc.sc/darktracer.  So grc.sc/ D-A-R-K-T-R-A-C-E-R.  That will redirect you to a PDF I am hosting at GRC, a 66-page listing of more than 2,200 attacks.  Anyway, I looked at the first one that was allegedly by DarkSide, and it said that Brookfield.com was attacked on August 8th.  I did a bit of googling and revealed that, yes indeed, the Toronto Star carried the report dated August 25th with the headline "Canadian real-estate company Brookfield Residential suffers data breach by new ransomware group DarkSide."  And for anyone who's interested I have a link to that Toronto Star report.



So anyway, as I said, since I would not feel comfortable pointing our listeners at a live spreadsheet being hosted by an apparently benign but still unknown entity.  I printed a snapshot of it as it is today to a PDF, stripped it of all extraneous metadata, and am hosting the PDF at GRC.com.  It is fascinating and a little sobering to look at it, grc.sc/darktracer (T-R-A-C-E-R).



And because I don't want to keep anybody from the live data if they want it, I have a link in the show notes with a big red "ORIGINAL SOURCE:  LIVE GOOGLE SHEET (WARNING)."  So you are able to view it, the original source material, live.  And the original snapshot that I saw that led me to this one was older than this one, and this one is current as of today.  I think there was an attack on the 17th, yesterday, and a few shown on the 18th.  So it appears to be legitimate, and it certainly is fascinating.  And I thought that our listeners would find it interesting.  So grc.sc/darktracer will take you to today's snapshot, a safe PDF, which was printed from the actual spreadsheet.



And then just to end this discussion of ransomware on a lighter note, I saw a tweet from PeterM, who repeated something that he saw, tweeting from @AltShiftPrtScn, dated 6:17 this morning.  Avaddon, which is one of the Ransomware as a Services, and there's lots of listings for them in that PDF, "Avaddon victim who didn't pay asked the attackers to please leak their data in full because they were having trouble restoring some backups from their files.  The threat actor clearly didn't understand, as they responded by saying if the victim didn't cooperate they would leak their data."



LEO:  Oh, whatever you do, don't leak my data, bad guy.  Whatever you do.  Holy cow.



STEVE:  Yeah.



LEO:  Oh, my god.



STEVE:  Okay.  So we're at the third - yeah, right, please, we're having problems restoring from backup.  Please leak our data.  Yeah.  There are some files that we need that we can't get otherwise.  Wow.



LEO:  That's a great one.



STEVE:  Okay.  So we're at the third Tuesday of May.  Wait.  The third?  Oh, yeah, third Tuesday of May.  So we're able to look back on last Tuesday's comparatively sedate Patch Tuesday.  Whereas we have seen past updates delivering fixes, as we know, for well over 100 flaws, last week was a mere 55 fixes affecting Windows; Exchange Server; Internet Explorer, believe it or not; Office; Hyper-V; Visual Studio; and Skype for Business.  However, that said, there was definitely some excitement.



Of those 55, four of those fixed were critical vulnerabilities, 50 were important, and one was moderate.  Three of the vulnerabilities are publicly known, although unlike last month, none of them are under active exploitation as of the time of this release, which is good.  Unfortunately, it's not clear how long that will be the case.  But it probably doesn't matter.



There was one particularly juicy baddie that is worrying the industry a little bit.  It was assigned CVE-2021-31166, and it's a potentially wormable remote code execution vulnerability in the HTTP protocol stack of only the most recent releases of IIS, which is Microsoft's web server, for Windows 10.  It's wormable because it requires no action on the recipient's part.  An unauthorized, unauthenticated remote attacker simply needs to send a specially crafted packet, a query, to any vulnerable Windows 10 server.  And they all were vulnerable.  All of those that were vulnerable, were vulnerable - what? - before the patch came out, which will run the attacker's code in the kernel.  And if that code chose to scan for other publicly accessible, or even internally accessible for that matter, hosts, we'd have a new Internet worm on our hands.  Consequently, this one carries a CVSS rating of 9.8 out of 10.



And wouldn't you know it, some security researcher just couldn't help but show off their mad haxor abilities by publishing a working proof of concept which is now up on GitHub.  He wrote: "This is a proof of concept for CVE-2021-31166 (HTTP Protocol Stack Remote Code Execution Vulnerability), a use-after-free dereference in http.sys patched by Microsoft in May of 2021.  According to this tweet" - and then he cites it - "the vulnerability has been found by @_mxms and @fzzyhd1."  Looks like "fuzzy," doesn't it.  Yes.  Do a fuzz on your hard drive.



Anyway, even so, this probably won't amount to much because non-corporate users, who are more likely to have the latest version of Windows 10, will probably have updated and patched and are also typically isolated behind their NAT routers.  And these days few home users are running a public web server, and certainly not on port 80, probably.  I don't even know if you can still.  And at the other end of the scale, it's unlikely that any corporate Windows Server installations are crazy enough to be running the latest Windows 10 instances of Server.  This bug was recently introduced into the code and only affects Windows 10 Server 2004 - poorly numbered, of course - and 20H2.  So the two most very recent instances of Windows 10 Server, hopefully no enterprises are running those publicly exposed.  If so, be a good idea to fix that because now there's a proof of concept posted about how you can take advantage of it.



There was also another remote code execution flaw in Hyper-V, which also scores the highest severity among all flaws patched this month.  It even beats that one.  That one was 9.8; this is 9.9.  Microsoft's advisory said:  "This issue allows a guest VM to force the Hyper-V host's kernel to read from an arbitrary, potentially invalid address.  The contents of the address read would not be returned to the guest VM.  In most circumstances, this would result in a denial of service of the Hyper-V host" - in other words, a blue screen crashing everything - "due to reading an unmapped address.  It is possible to read from a memory-mapped device register corresponding to a hardware device attached to the Hyper-V host which may trigger additional hardware device-specific side effects that could compromise the Hyper-V host's security."  What that really means is we actually do know how this really bad problem could be leveraged to completely compromise Hyper-V security, but we don't want to say that.  We just want you to patch it.  So anybody who's in any way associated with Hyper-V and needing its protections would be well advised to patch last Tuesday's update.



Let's see.  In addition, there was an update that addressed a scripting engine memory corruption flaw in IE, believe it or not.  And four more flaws in Microsoft Exchange Server, which continues to dog Microsoft.  This makes it the third month in a row Microsoft has continued working to fix that troubled product since the ProxyLogon exploits in March.



LEO:  Geez.



STEVE:  I know, Leo.  They just cannot get it right.  Well, you know, it's an email server, and they just - it didn't get much attention.  And now that it is, they're looking at it going, oh.  And you know, this is what we've seen before, too.  Remember that when there was that spate of RDP problems, and Microsoft said, oh, maybe we should take a look at RDP.  We haven't looked at it for a while.  And then they just began spitting out patch after patch after patch as if, you know, they've put the A team on it because suddenly it became important, and those guys are like, who wrote this crap?  And they just kept finding fixes for it.



LEO:  Yeah, it is, it's like the Eye of Sauron.  It moves around, yeah, yeah.



STEVE:  Exactly.



LEO:  Oh, let's pay attention to this now.



STEVE:  So otherwise the update addresses a large collection of privilege escalation bugs in Windows Container Manager Service, an information disclosure vulnerability in Windows Wireless Networking, and several remote code execution flaws in Microsoft Office, Microsoft SharePoint Server, Skype for Business, Lync, Visual Studio, and Microsoft Media Foundation Core.  So in other words, hopefully it's a week downstream, everybody's already updated, and you're like, okay, fine.



Okay.  So on to a bit of miscellany.  I found a review of the first book of The Frontiers Saga.  And it's long, so I'm not going to share it all.  But I'll just share the opening because it was fun.  And the reason I'm bringing this up at all is that it's so well written.  The reviewer is a listener.



So he said:  "On a recommendation from Steve Gibson on his Security Now! podcast, I've started reading The Frontiers Saga by self-published author Ryk Brown.  This is a review of the first book in the series, called 'Aurora CV-01.'"  He says:  "The Frontiers Saga is classical science fiction space opera stuff, best summarized as a cross between Ronald D. Moore's 'Battlestar Galactica' and 'Star Trek: The Next Generation.'  Sounds a bit run-of-the-mill at first glance, but it raises eyebrows immediately based on the sheer scope of the work."  And then he quotes Ryk talking about basically 75 books that he's going to write.



The last paragraph I'll quote.  He says:  "'Aurora CV-01,' the first book in the franchise, which I've just finished, was originally published 10 years ago.  Since then, Brown has finished two series, meaning 30 books.  That's on average three books, of 200 to 300 pages each, a year."  He says:  "And the guy just keeps on going and going.  He's like some sort of anti-George R.R. Martin with his output.  That alone impresses me enough to give him a shot.  And I must say I have not regretted it."



Okay.  That's just the beginning of a much longer review.  I made it the shortcut of the week for anyone who hasn't yet been motivated.  I would suggest that you read Andy Weir's most recent work, which we know is "Hail Mary."  And then, if you're a person who just loves sci-fi, again, I can't recommend it highly enough.  The review is at grc.sc/819, this week's episode number.



I just did want to touch on, Leo, because sci-fi is an interest that we share.  And I'm a bit bemused, I suppose is the right word, by the whole question of UFOs.  I thought it was interesting that "60 Minutes," you know, a serious long-running 60-minute news magazine that airs on CBS on Sunday nights, did a segment on what they refer to as UAPs, Unidentified Aerial Phenomena, and that there's actually an Unidentified Aerial Phenomena Task Force.  Wikipedia has an entry describing it.  And that there, I mean, that this thing, this entity, this organization, this task force, exists, and it has a budget from Congress and will be submitting a report, I think a month from now, if I remember correctly, about as far as they know what is going on.



I would suggest that, if anyone is interested, because what we saw was some video, it was not brand new video, it's a few years old.  But it's real video.  On "60 Minutes" they discussed a number of sightings, like quadruply confirmed sightings, two different fighter planes, both people in the cockpit in the front and the back, all saw and recorded on camera and tracked on radar and blah blah blah blah blah.  And so, you know, they talk about how, you know, the behavior of these things.  And I just wanted to go on record as saying, if you're interested, go find "60 Minutes" from last Sunday.  And it's some interesting stuff.  I have no explanation for this stuff.  Nobody is suggesting that these are extraterrestrial.  And frankly, Leo, the more I mature in my understanding of human nature, or maybe entity nature, the more glad I am about the speed of light barrier.



LEO:  Yeah.  Yeah.



STEVE:  And the distance we are from anything else.  You know, even on this ball of dirt, the oceans kept us apart from each other for a long time, and that was a good thing.  As soon as we started being able to sail across the ocean, all hell broke loose.



LEO:  Well, look what air travel has brought us, pandemic-wise, you know.



STEVE:  Yes.



LEO:  Yeah.  Probably best just to stay home, everybody, please.  Even the aliens.



STEVE:  Yeah, exactly.  Just, you know, it's a long-ass trip.  Do not - there's nothing here.  All we have is bitcoin, and we're not sure about that.  So just cool your jets.



LEO:  If you're using jets.



STEVE:  That's right.



LEO:  I think it's much more likely there's optical illusions.  There's all sorts of things that can cause people to see things.  No one's denying that everybody on the plane saw it.  So that's not the question.  It's just an unidentified thing.



STEVE:  If you haven't watched this segment, Leo...



LEO:  I'll watch it, yeah.



STEVE:  I really - I would commend you to watch it.  It's, I mean, I'm, again, one of the things I've noticed about me is I'm complete - and I found this when I was debugging SpinRite early on, is I'm completely comfortable saying "I don't know."  I don't have to have an explanation for stuff.



LEO:  Yeah.  Yeah, I don't know.



STEVE:  If there's a bug, I don't know.  And that's fine.  But that's where you begin to do your research, if you're a researcher.  You start with "I don't know," and you start trying to figure things out.



LEO:  Yes.



STEVE:  We had an interesting follow-up two days ago from somebody who posted on April 21st, a listener.  He tweeted to me, and he's got a terrific short Twitter, you know, @krv is his Twitter handle.  He said originally:  "You asked for someone's FLoC ID.  Here is mine:  'Your FLoC ID is 5393.'"  Then two days ago:  "FYI, if you're still interested, my FLoC ID is now 6501."  He says:  "I'm not sure how often it changes as I haven't been checking it regularly."  But yes, presumably weekly.  And so I think, you know, it still remains an interesting solution to me.



And two pieces of feedback from our listeners who heard us talk about "Hail Mary" book last week.  Zap Anderson said:  "Yes, @SGgrc, 'Project Hail Mary' by @andyweirauthor is indeed AWESOME," all caps.  He said:  "Just binged the Audible book."



LEO:  That's 16 hours.  That's quite a binge.



STEVE:  "Just binged the Audible book."  And he said:  "Narrator and ... other sounds awesome."  He said:  "It's fudging great," and I don't think he meant fudge.  And then Arnold Ochoa, who also has an amazing Twitter handle, @a8a.  He said:  "@SGgrc If you have the chance, you should give @andyweirauthor's 'Hail Mary' a chance on Audible.  No spoilers, but there are things there that can't be in the book.  You'll know what I mean once you 'read' it."  So anyway, thank you for the feedback, listeners.  Everybody I've heard anything from so far has said, oh, wow.  And Leo, you should mention that you're going to have  Andy on.



LEO:  We are.  Andy Weir, who I interviewed when "The Martian" came out, I interviewed when "Artemis" came out, so this will be my third time with Andy.  I just think he's the greatest.  And I would say this book is his best yet.  If you liked "The Martian," it's very similar to that.  I think you will love "Project Hail Mary."  He will be our guest on a special episode of Triangulation.  We'll put it out on the Triangulation feed and on the TWiT events feed.  This Friday, 3:00 p.m. Pacific, 6:00 p.m. Eastern, that's 22:00 UTC, Friday.  Let's see, this is Tuesday, so it would be the 21st of May.  And I hope you will listen.  And if you're in the TWiT Club, Club TWiT, we will probably fire up the Discord and give some Club TWiT members a chance to ask Andy questions.  So I think that'll be fun, too.  So please join me.



STEVE:  Yeah, the trick is that there are some things you really want to ask him having read the book.  And so you're thinking maybe about dividing it into a pre-read and then a "danger, spoilers ahead" where, if you haven't read it, you absolutely don't want to finish the podcast until you have.  And then you'll be really glad that that second half of the interview is there.



LEO:  Exactly.  As I listen to it, there are things I'm desperately dying to ask him.  But pretty much anything you say about the book is a spoiler.  So, I mean, literally, you can't say anything about the book.  I'll have to ask him about it.  But my guess is we'll do a half hour, 45 minutes with him, saying "no spoilers," and then, okay, if you haven't read the book, pause.  Read the book.  We'll see you in a few hours



STEVE:  Or maybe break it into two separate pieces.



LEO:  Depending on how much time Andy's willing to give me, that's not a bad idea, as well, yeah.  He's great.  I love him.  His story is fantastic.  And he self-published "The Martian," became a huge hit, not only a bestselling novel, but a movie.  And I think this new one, man, I can't wait to see the movie.



STEVE:  And I heard it already was going to be a movie.



LEO:  Oh, no doubt that it's optioned.  It's just too good, yeah.  So you've got to read, well, you're in the middle of something else, I guess.  Otherwise you [crosstalk].  



STEVE:  I am.  But I will get to a point where the action pauses for me, and I will absolutely jump on it.  In fact, I think I already bought it; but I just, you know, it's got itself downloaded, and it's waiting.



LEO:  Yeah.  You're going to love it, yeah.  Frag Attack.



STEVE:  So as we said at the top, the discoverers of the WiFi KRACK Attack are back.  I've been wanting to say that all day.  The KRACK Attack, which we of course covered in detail at the time, was a key reinstallation attack that was able to break WPA2 encryption by forcing nonce reuse.  The same lead researcher and team have been quite busy behind the scenes.  They'll be initially presenting their new set of Frag Attacks.  And actually it ought to be capital F, lowercase r, capital A, lowercase g, except that that makes it look a little awkward, because it's both fragmentation and aggregation.  So it's obviously breaking them apart and putting them back together again.  And Frag Ag, that doesn't really roll off the tongue.



So, but anyway, Frag Attacks.  They're going to be presenting it at the forthcoming USENIX 2021 conference and then later, in much greater detail and depth, during this summer's Black Hat 2021 conference.  Which I guess maybe will actually be held in person.



LEO:  Ooh.



STEVE:  I wonder what they're - I haven't heard about that.



LEO:  I don't know if we know yet, yeah.



STEVE:  Yeah.  Anyway, these guys, okay.  So I'm going to go over these because they're interesting from a theoretical "what could possibly go wrong" standpoint.  But this is not the end of WiFi as we know it.  This is not a meltdown.  This is not, well, actually that's a bad choice of words because Meltdown was not a meltdown.  But we're going to be fine.  So what they discovered was three fundamental vulnerabilities inherent in the design of the WiFi protocol.  Although again, as I said, you've really got to work to make them happen.  So these were not implementation errors specific to anyone or more particular devices, but rather mistakes in the design of WiFi itself.  And along the way they also discovered a handful of specific WiFi protocol implementation errors where the protocol itself isn't the problem, but the way the code was written to implement it was.



Okay.  So here's how they introduced and framed their discoveries.  And I tweaked it a little bit just for readability.  They said:  "We present Frag Attacks, fragmentation and aggregation attacks, which is a collection of new security vulnerabilities that affect WiFi devices.  An adversary who is within range of a victim's WiFi network can abuse these vulnerabilities to steal user information or attack devices."  Doesn't sound good.  They said:  "Three of the discovered vulnerabilities are design flaws in the WiFi standard and therefore affect most devices.  On top of this, several other vulnerabilities were discovered that are caused by widespread programming mistakes in WiFi products.  Experiments indicate that every WiFi product is affected by at least one vulnerability, and that most products are affected by several.



"The discovered vulnerabilities affect all modern security protocols of WiFi, including the latest WPA3 specification.  Even the original security protocol of WiFi, WEP" - remember WEP back in the day - "is affected.  This means that several of the newly discovered design flaws have been part of WiFi since its release in 1997.  Fortunately, the design flaws are difficult to abuse because doing so requires user interaction or is only possible when using uncommon network settings.  As a result, in practice the biggest concern are the programming mistakes in WiFi products, since several of them are trivial to exploit.



"The discovery of these vulnerabilities comes as a surprise because the security of WiFi has in fact" - this is them speaking - "has in fact significantly improved over the last years.  For instance, previously we discovered the KRACK attacks.  The defenses against KRACK were proven secure, and the latest WPA3 security specification has improved.  Unfortunately, a feature that could have prevented one of the newly discovered design flaws was not adopted in practice, and the other two design flaws are present in a feature of WiFi that was previously not widely studied."  Whoops.



They said:  "This shows that it remains important to analyze even the most well-known security protocols.  Additionally, it shows that it's essential to regularly test WiFi products for security vulnerabilities, which can, for instance, be done when certifying them."  And there's a little jab in the ribs to the Wi-Fi Alliance, you know, also known as the CYA Alliance because they do little except say, oh, it's not our fault.



Anyway, they finish:  "To protect users, security updates were prepared during a nine-month-long coordinated disclosure that was supervised by the Wi-Fi Alliance and ICASI.  If updates for your device are not yet available, you can mitigate some attacks, but not all, by assuring that websites use HTTPS and by assuring that your devices received all other available updates."



Now, Leo, I was not familiar with the abbreviation "ICASI."  



LEO:  ICASI.



STEVE:  Which they're referring to in their opening.  So I googled it and looked it up.  So it's either the International Culinary Arts and Sciences Institute...



LEO:  No, okay, wrong.



STEVE:  I don't think so.  Or Industry Consortium for Advancement of Security on the Internet.



LEO:  That sounds right, yeah.



STEVE:  And that sounds like...



LEO:  ICASI.org.



STEVE:  That's the one.



LEO:  Yeah.



STEVE:  Okay.  So they then provide a demonstration showing three examples of an adversary abusing a few of these vulnerabilities.  The first uses the aggregation design flaw to intercept sensitive plaintext information, in this instance the target's username and password, if not otherwise encrypted, is available.  In other words, they're able to break the WiFi wrapper, the WiFi encryption, getting to the underlying raw data, the so-called, you know, the plaintext within the WiFi packet.  But hopefully you're over HTTPS, so you've got TLS tunneling in place, and encryption and authentication anyway, so you're okay.  But they show that it's possible to crack the actual encryption offered by WiFi.



Then they demonstrate how an adversary can exploit insecure IoT devices by remotely turning on and off a smart power socket.  I'm sure mine is vulnerable, that little cheesy thing for $5.  But it works, even though it's talking to China.  And, finally, they demonstrate how the...



LEO:  Steve Gibson's lights are on.  Steve Gibson's lights are off.  Steve Gibson's lights are on.  They're off again.



STEVE:  And we unplugged it because it was annoying.  Oh, well.  Back to a light switch which we now know you push down when you're in the U.K. to turn things on, rather than up.



LEO:  That was a stunning revelation.



STEVE:  Isn't that, yes.



LEO:  Still reeling.



STEVE:  And finally they demonstrate how the vulnerabilities can be abused as a stepping stone to launch more advanced attacks.  And they specifically demonstrate how an adversary can take over a WiFi connected Windows 7 machine inside a local network.  So anyway, the various WiFi flaws can be abused in two ways.  Given the proper conditions, as I mentioned above, they can be abused to steal sensitive data, breaking the WiFi encryption.  And an adversary can also abuse the Wi-Fi flaws to attack devices within a victim's home network.



They felt that the greatest practical risk was likely the ability to abuse the discovered flaws to attack devices in someone's home network.  They noted, as I often lament, that many smart home and IoT devices are rarely updated, and that WiFi security is the last line of defense that prevents someone from attacking these devices.  Of course, the good news is you can't do that from Russia because you're out of range of WiFi.  So thankfully, for any of this stuff to work, you've got to be within radio range of the target's network being attacked.  On the other hand, that's possible, if you're a determined attacker, like if you're someone maybe authorized to get access or not.  Anyway, unfortunately...



LEO:  You mean that black van outside my house, that's not really a TV repairman?



STEVE:  Yeah, that's got all those weird...



LEO:  Weird antennas.



STEVE:  ...Yagi antennas aimed at your house, yeah.



LEO:  I just thought he was a TV repair guy.  I didn't know.



STEVE:  I think they're checking your signal strength, Leo.  We're not sure which signal, though.  Anyway, so the flaws can be abused to exfiltrate transmitted data.  Okay.  So taking a look in more detail at this, we've got, to give our listeners a sense for these things, I mean, I've got it now.  Having read through all this, I want to convey that because they're kind of interesting.



So we have plaintext injection vulnerabilities.  Several implementation flaws, remember, okay, separate from design flaws, can be abused to easily inject frames into a protected WiFi network.  Okay.  For example, an adversary can often inject a carefully constructed unencrypted WiFi frame.  This can be leveraged into a DNS spoofing attack to trick the client into using a malicious DNS server.  And when used against routers, this can also be used to bypass the NAT firewall to allow the adversary to subsequently attack devices on a local WiFi network.



Okay.  So how can an adversary construct unencrypted WiFi frames so they're accepted by a vulnerable device?  Get a load of this.  It turns out that some WiFi devices will simply accept any unencrypted frame that arrives, even when they are connected to a protected WiFi network.  In other words, it means that the attacker doesn't have to do anything special.  Two of the four home routers that they tested were affected by this vulnerability, and several IoT devices were affected.  And some smartphones were affected, as well as were many WiFi dongles on Windows.  All of these things, even though you bring up, you have like encryption on the network, and you bring up an encrypted connection, they will incorrectly accept plaintext frames when they are split into several fragments.  Turns out the fragment reassembly process sidesteps the check for encryption, and the packets are processed without any encryption as plaintext.



They also found that some devices will accept plaintext aggregated frames that look like handshake messages.  So an adversary can exploit this by sending an aggregated frame where the start of the frame resembles a handshake message, but whose second subframe, that is, pieces of frames, individual frames that were aggregated, that second subframe contains the packet that the adversary wants to inject.  This, the fact that the front of it looks like a handshake, slips the inbound aggregated frame past the naive WiFi parser's state machine.



Such vulnerable devices first interpret the frame as a handshake.  That moves it to a different place.  Then the vulnerable devices pass it on.  And the subsequent pieces of the aggregated frame are treated as unencrypted and merged right into the conversation.  Just, again, weird edge cases, but you could imagine a sufficiently motivated adversary.  Somebody really into getting some device on someone's network protected by encryption to misbehave could take advantage of this.



And, finally, several devices process broadcasted fragments as unfragmented frames and will accept broadcast fragments when they are sent unencrypted.  So just a mistake in the code of the WiFi stack.  An attacker can abuse this to inject packets by encapsulating them in the second fragment of a plaintext broadcast frame, which will be accepted by the router.  So, yes, security is difficult.



Those were implementation mistakes.  As I noted, we also have a few fundamental design flaws.  The first design flaw, that is, as a consequence present in all devices, is the frame aggregation feature.  Remember I was just talking about the idea that you'd have an aggregated frame made up of smaller frames.  It turns out that frame aggregation is a feature of WiFi.  It increases the overall speed and throughput of a network by explicitly allowing the aggregation of multiple small frames into a single larger aggregate.  To implement this feature, the header of each frame contains a flag to indicate whether the encrypted transported data contains a single or an aggregated frame.



But unfortunately, this "is aggregated" flag is not authenticated and can be modified by an adversary, leading to a victim being tricked into processing the encrypted transported data in an unintended manner.  It can be abused to inject arbitrary network packets by tricking the victim into connecting to their server and then setting the "is aggregated" flag of specifically selected packets.  They said that nearly every device they tested was vulnerable to this attack.  They're just, you know, it was a flaw in the design of all of WiFi that does not authenticate the "is aggregated" flag.  So you can get up to mischief with it.  We've seen these sorts of mistakes throughout the life of this podcast.



It turns out this ability to inject packets can be readily abused to intercept a victim's traffic by making it use, for example, a malicious DNS server.  So here's an instance where you would like to have your DNS running over HTTPS to an external anchor, an external resolver, just to prevent anybody from getting up to any hanky-panky with DNS.



They said this design flaw could be fixed by authenticating the "is aggregated" flag in the WiFi standard.  And in fact the standard does contain a feature to authenticate the flag.  Unfortunately, this defense is not backwards-compatible.  That is, if one end of a connection tried to enforce it, and the other end wasn't enforcing it because it requires a slightly different protocol, then you don't have a connection.  It'll break, completely break backwards compatibility.  So as a consequence of that, in practice, it's never used because only in a deliberately set up instance where somebody exactly knew that both ends of the connection were going to be using this flag, then they could bring this feature on, which nothing else would be compatible with.  So in practice it never happens.



There's also something known as the "mixed key" attack.  They said this one abuses the deliberate frame fragmentation feature which is also built into WiFi.  Frame fragmentation increases the reliability of a connection by deliberately splitting larger frames into smaller fragments.  When doing this, every fragment that belongs to the same frame is encrypted using the same key.  However, the receivers of these frames are not required to check the keys of these individually fragmented and individually encrypted packets.  So, if present, they will dutifully reassemble fragments decrypted using different keys.  And this permits an attacker to slip their own packets into the mix.



In practice, this can allow an adversary to exfiltrate selected client data.  Unlike the unfixable "is aggregated" flaw above that we just talked about, this one can be fixed in a backwards-compatible manner by only reassembling fragments that were encrypted under the same key, since anything else would always be an attack.  But that would require that our WiFi protocol be updated and fixed.



The third and final fundamental design flaw is the - oh, and this is a weirdo, the "fragment cache" attack.  Okay.  It's still, I mean, it's quite obscure.  But still it's there.  When a WiFi client disconnects from the network, the device is not required to flush and remove any still non-reassembled fragments.  They stay in memory.  These researchers provided examples of how this could be used in practice against hotspot-like networks such as something they called "eduroam" and "govroam," and against enterprise networks where users distrust each other.



In those cases, selected data sent by the victim can be exfiltrated.  This is achieved by injecting a malicious fragment which will remain in memory in the shared access point's fragment cache.  When the victim then connects to that access point and sends a fragmented frame, selected fragments will be combined, reassembled, with the injected fragment which was originally provided by the attacker.  So basically you can arrange to leave fragments deliberately in an access point and cause them to be picked up and merged with other users' traffic on its way out of the network.



It turns out, even though it is really obscure, not surprisingly, that one would be trivial to repair in a backwards-compatible manner, simply by requiring that endpoints flush any residual fragments from memory whenever the connection state of any connection changes.  I mean, like, yeah, why not?  That would be simple to do, at least in theory, but it does require things be updated.



Okay.  And we'll wrap this up by coming back to a few remaining implementation vulnerabilities we did not touch on.  Some routers, it turns out, will forward handshake frames to another client, even when the sender hasn't finished authenticating.  This vulnerability allows an adversary to perform the aggregation attack and inject arbitrary frames without user interaction.  Another extremely common implementation flaw they discovered is that receivers do not check whether all fragments belong to the same frame, meaning an adversary can trivially forge frames by mixing the fragments of two different frames.  Again, a lot of these are going to be completely resolved as long as you've got HTTPS, that is, your own encryption outside of the encryption provided by WiFi.



And Leo, do you remember, at the beginning of this podcast WiFi wasn't encrypted generally.



LEO:  Right.



STEVE:  Remember most people just, they just like, oh...



LEO:  They left it on as a benefit.



STEVE:  That's right.  We want to share it with our neighbors.  Oh, passwords, those are pesky things.  When our friends come over, they just want to get on the Internet.



LEO:  Yeah, no, I always left it on, yeah.  I thought it's unneighborly to turn it off.



STEVE:  Amazing.



LEO:  Yeah.  We've come a long way.  Yeah.



STEVE:  Things really have changed.  Yes, we have.  Anyway, they said additionally, against several implementations, it's possible to mix encrypted and plaintext fragments.  Unbelievably.  And, finally, some devices don't support fragmentation or aggregation, but are still vulnerable to attacks because they process fragmented frames as if they were full frames.  Under the right circumstances, this can be abused to inject fragments.



So the researchers pointed out and notified all relevant parties nine months ago of the problems they found so they could and would be fixed, and so that any devices that were being updated would have the benefits of those fixes.  So it's very likely that since nine months is lots of time, that things that we use have just been fixed over the course of time.  And of course IoT devices are not currently receiving updates to their WiFi stacks, and very few if any can ever be updated.  Fortunately, the attacks are all edge cases.  They are difficult to implement in practice, and they do all require attackers within radio range of the target.



So Leo, that black van, yeah, that's a problem.  But if nothing else, this is one more reason to always place any questionable devices onto their own network.  I am seeing that more and more, by the way.  I'm seeing other places are recommending network segmentation as the only good solution for dealing with IoT and just stuff you don't want on your internal network of high-value devices.



LEO:  Yeah.



STEVE:  So Frag Attacks, probably fixed.



LEO:  Not worth freaking out about.



STEVE:  Not worth freaking out about.



LEO:  But keep an eye on that van on your curb.



STEVE:  Yeah.  I would, when you see the Yagi antenna swinging around to point at you, that's a problem.



LEO:  Well, and then there are situations where you have neighbors, like if you're in an apartment complex, you don't know who, you know, if your neighbors decide they want to spy on you or attack you, they're right there, and you can't tell they're on your same network.  Same thing in an office building.



STEVE:  And hacking tools are becoming increasingly available.



LEO:  Yeah.



STEVE:  Once upon a time they were sort of obscure.  Now you go on to GitHub.



LEO:  Everybody has Wireshark.



STEVE:  Yeah.



LEO:  Yeah.  Just download Kali Linux, you're set.  You can attack your neighbors.  It's great fun.  And I think people probably do it just, you know, literally for fun, just because they can.



STEVE:  Yeah.



LEO:  Let's snoop.  Let's - you saw the Eufy cameras that people were able to log into.



STEVE:  Oh, getting the - whose bedroom is that?  Oh, lord.



LEO:  Eufy, which is Anker's home stuff, has said, well, we've sent out a patch.  Now you should unplug your camera, plug it back in, change your credentials, you should be fine.



STEVE:  Whoopsie.



LEO:  Yeah, that's the one thing I really worry about.  You know, they get my lights, big deal.  But I don't want them to get into the cameras.  I really don't.  That's why Lisa won't let any cameras in the house.



STEVE:  I was going to say, Lisa's policy continues to prove to be the correct one.



LEO:  If you want to look in my backyard, have at it.  Let me know if anything's going on back there.  But not my house.



Steve, as always, a fascinating listen, and it's every Tuesday right here on this network.  We do Security Now! normally, we were a little delayed today because of the Google announcement, but normally it's about 1:30 Pacific, 4:30 Eastern, 20:30 UTC on a Tuesday afternoon.  You can stream the live audio or video if you want to listen live or kind of participate in our chatroom or a Discord server.  You can stream that at TWiT.tv/live.  And of course as with all our shows now, if you're in Club TWiT, we keep a live audio channel open in the Discord server, giving you a chance to raise your hand and ask questions, that kind of thing.



Steve Gibson has copies of this show that you can download at GRC.com.  He's got a couple of unique versions, a 16Kb audio version, which is a little scratchy, but it's the smallest audio version you can get.  He's got an even smaller version, that's the human-written transcript, so you can read along as you listen.  That's all at GRC.com, along with SpinRite, his bread and butter, world's finest hard drive maintenance and recovery utility.  Sorry, mass storage maintenance and recovery utility because it works on everything that spins and doesn't.  GRC.com.  Lots of free stuff there, too, like ShieldsUP! and all sorts of good stuff.



We have copies of the show, audio and video, at our site, TWiT.tv/sn.  There's a YouTube channel dedicated to Security Now!.  You'll find a link there, TWiT.tv/sn, to the YouTube channel, plus a bunch of buttons you can press to automatically subscribe in your favorite podcast application.  If you do that, you shouldn't have to worry, you're just going to have it on your phone or your device, ready for a listen whenever you're in the mood.  However you do it, we don't want you to miss an episode.  There's always important information.



Steve, have a wonderful week, and I will see you next week on Security Now!.



STEVE:  Will do.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#820

DATE:		May 25, 2021

TITLE:		The Dark Escrow

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-820.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine Firefox's just-released and welcome re-architecture under codename "Fission."  We look at a new and recently active ransomware player named "Conti" and at a recently paid, high-profile mega ransom.  We then ask the question, "When they say IoT, do they mean us?"  We examine the implications of a new industry term, "mean time to inventory."  We'll then lighten things up a bit with a new form of CAPTCHA and, of all things, a screensaver I discovered that I cannot take my eyes off of.  (Leo, it's not quite as bad as whatever that game is that you cannot stop playing, but still.)  We'll then share an ample helping of closing-the-loop feedback from our terrific listeners, after which I want to conclude by predicting what I would bet we're probably going to next see emerge from the evolving ransomware business model  sad though it is to utter the phrase "ransomware business model."



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a great show for you.  Brand new feature in Firefox.  It's called Firefox Fission.  Steve explains it and shows you how to turn it on.  I did immediately.  We'll also talk about a new form of CAPTCHA that involves playing Doom.  I like this.  Even has the sound.  And then Steve's vision for the future of ransomware.  Sort of.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 820, recorded Tuesday, May 25th, 2021:  The Dark Escrow.



It's time for Security Now!, the show where we cover your security, your privacy, your safety online with Mr. Steven Gibson of GRC.com.  Hello, Steve.



STEVE GIBSON:  And yes, ladies and gentlemen, those of you listening and watching live, check your clocks.  It's actually not quite 1:30 a.m.  Wait, p.m.



LEO:  We're early.  Shall we just stop and wait for three minutes?



STEVE:  No, no, no, no.  Let's see how much we can cram in before the clock hits 1:30 and the official start time.  This is Episode 820 for May 25th.  And I titled this "The Dark Escrow" just because dark is cool; you know?  I mean, you can kind of have like dark anything, and it's neat.  Like the dark melon.  Well, maybe not that.  But anyway, as a consequence of some of the aftermath of what happened with the DarkSide ransomware when they tiptoed into the Colonial Pipeline mess, and some things that have happened since, which we're going to talk about, I have sort of some thoughts about where we're probably going to go next.  So I wanted to share that.



But we've got lots of interesting stuff to talk about.  We've got Firefox's just-released and welcome re-architecture under codename "Fission."  We've been waiting for this for a while.  They're a little late to the game.  It turns out - we'll talk about this - it's difficult to do what they've done.  Chrome did it, and the Firefox, we've been waiting for them to follow.  And it's now something that all Firefox users can turn on.  I immediately did.  And it's a good thing.



We're going to look at a new and recently active ransomware player named Conti since they're looking like they're going to be something we'll be talking about to some degree in the future.  So I thought I would introduce our listeners to Conti.  And also at a recently paid, high-profile, what you would have to call literally a "mega ransom."  We then ask the question, when they say IoT, do they mean us?  And we examine the implications of a new industry term, "mean time to inventory."  And it's not good.  We'll then lighten things up a bit with a new form of CAPTCHA.  And anyone who wants to cheat can - I'll tell you that it's this week's GRC shortcut.  So those who've been paying attention know what the URL would be for this week's shortcut, and it's kind of fun.



Then, of all things, I want to share a screensaver that I discovered, that I cannot take my eyes off of.  And Leo, it's not quite as bad as whatever that game is that you cannot stop playing.  But still it's absorbing more of my time than I want to admit, just sitting there, like, whoa, look at that.



LEO:  I don't know if staring at a screensaver's worse than playing a game.  But, all right.



STEVE:  Yeah, I'm not getting any points for it, that's for sure.  Okay.  Then we're going to share an ample helping of closing-the-loop feedback from our terrific listeners because there was just a bunch of stuff that came in that I wanted to share.  And then we're going to conclude by predicting what I would bet we're probably going to next see emerge from the evolving ransomware business model, sad though it is to even utter the phrase "ransomware business model."  Oh, and we do have a great Scott Adams cartoon as our Picture of the Week.  So I think another great podcast for our listeners.  And we can begin officially, now that it is now 1:30.



I've had this one in the queue for a while, and I thought, yeah, now is the time.  This is on the theme of being careful what you ask for.  So we have a three-frame cartoon by the brilliant Scott Adams.  We have the boss is addressing three of his employees.  And so in the first frame we have the boss saying, "Our goal is to write bug-free software.  I'll pay a $10 bonus for every bug you find and fix."  And then in the middle frame we have the three employees.  The first one, "Yahoo!"  And then the second one says, "We're rich."  And the third one says, "Yes!  Yes!  Yes!"  And then, sort of wondering if he's come up with the right policy, we see the boss saying, "I hope this drives the right behavior."  And one of the employees says, "I'm going to write me a new minivan this afternoon."  So, yeah, if your employees are able to find their own bugs, well, that may not be the best way to produce bug-free software, is the point.



So Firefox has finally achieved sustained Fission.  Fission is Mozilla's name for full-site isolation.  That is, fission of course being breaking things apart.  The original design for all web browsers was as a single app running on an operating system.  Or a bit more formally, a process being hosted by the OS.  And the trouble was browsers have kept growing more and more complex, to the point that the line you know has become blurred between an OS app and what a browser can do with a web page.



Case in point, the other day I followed a link to a drag-and-drop mechanical electrical circuit design page where, for example, a capacitor was emulated by a balloon being filled up.  An inductor was created by a flywheel.  A resistor was a narrowing pipe and so on.  And I initially took the page for granted, until it occurred to me that this amazing, fully animated creation was not an app in a classic sense, but this was being entirely done on a web page in my browser.  And we're all kind of getting used to that.



So yeah.  Today's browsers have become incredibly complex and capable.  But as we know, complexity is the enemy of security.  It's not impossible to have both.  But it turns out that it's impractically expensive to actually have both.  So we get features that mostly work.  And as for security, we hope for the best while we fix the flaws that are later uncovered on the fly, after the fact.



But browsers are sort of a special case for problems because the presence of the near certainty of flaws as we just keep fussing with our browsers, making them more and more capable, but more and more complex, raises the specter of containment.  If flaws are inevitable, then what we want is to at least contain them.  The last thing we want is for a flaw to be leveraged to reach across web browser pages, or really across domains, to infect an unrelated page to leverage its access to some other site, for example, where we're logged into our banking site.  We don't want some sketchy page we're visiting to be able to peruse the other tabs we have open and say, oh, look what we found here.  Let's go there.



And a perfect analogy is, for example, of like this problem, the need for separation is my insistence upon applying network segmentation for IoT devices which are inherently high risk.  If we cannot guarantee that our light switches and our blow dryers will not attack us, at least we can contain any potential damage by placing all of those less trustworthy devices onto their own low trust network segment so they can't even see the rest of our internal network.  So it's a form of sandboxing.  And this exactly mimics the designs that browsers have been working to adopt for several years.



It's taken years because switching from a mono process architecture, which is where they all began, to a process per domain is far more easily said than done.  Google initially released an experimental site isolation feature that they had already been hard at work at for quite some time in Chrome 64, back at the end of 2017, and it became generally available essentially about half a year later in May of 2018.  Mozilla realized that was where the future would be.  So they began work on the same thing the month before Chrome's general availability, in the Mozilla case in April of 2018.



They formally announced their plans to do it nearly a year later, I mean, it's really that hard, in February of 2019.  And then that's when they disclosed the code name Fission.  And a little more than two years later, here we are, last week, it's finally here.  But even so, it's not yet turned on by default.  Anyone listening to this podcast who's a Firefox user - I know, Leo, you are - who has a current release of Firefox, which of course you get just by making sure you go to like About Firefox, and then it'll update it, if it hasn't already, can turn this on.



Go to about:config, which we're often visiting, about:config in the Firefox URL bar.  Then search for "fission," F-I-S-S-I-O-N, and locate fission.autostart.  I think it's like the fifth or sixth one down.  And it should now - you should set it to true.  And after making those changes, Firefox won't auto prompt for a restart, as Chrome does.  But if you go to about:profiles, that page in the upper right contains a manual restart button that will do the trick, that'll restart Firefox.  You'll come up, and from then on every tab you open - actually, it's more than that.  It's even more granular.  Every domain you visit will get its own process.



So by creating a separate standalone OS process for each domain, which the browser pulls content from in order to prevent anything nasty from escaping, essentially what we're doing is we're leveraging the mature process separation that our OS has long been enforcing.  Basically the browser sort of is turning over responsibility for really keeping the containment of domains by creating a domain per process.  And the reason it's tricky is that if you then, as many pages do, have frames that are pulling in off-domain content, then that needs to be in its process.  Yet even so, it needs to get rendered in the page in this process.



So again, what we've seen is years of work going into this for our browsers.  Safari has something, kind of a weak version of this, but hasn't really stepped up to do it because, I mean, it really is, it's like starting over from scratch in order to do it.  Firefox has it.  Now that Chrome has it, of course that means that Chromium has it, which means that all the other, well, Edge for example from Microsoft, and Brave and Vivaldi and all the Chromium-based browsers, also get it just as a consequence of being Chromium-based.  So clearly it is more resource intensive.



One of the problems early on had been that a lot more RAM was being used because basically what looks like one thing that you're running on your desktop, especially considering the number of domains that your typical web page pulls from now, well, if we really want containment, we've got to fire off an OS process for every one of those.  So you just can't throw this together.  In order to make it work and make it fast and continue to make it small, that requires some tricky work.  Anyway, we've got it now in Firefox.  It's been available in Chrome for a while.  It's the standard moving forward.



The latest ransomware on the block is called Conti.  And based on the fact that the FBI has recently identified 16 different successful penetration attacks by Conti, starting up from like nothing a short time ago, I have a feeling we're going to be talking about those attacks in the future.  So I thought we ought to put it on our map.  Conti is believed also to be a Russia-based, if not backed, cybercrime group known as Wizard Spider.  So Conti technically is the ransomware, also sort of the initiative.  And the terms, they get kind of mixed up.



But Wizard Spider is the group that is behind Conti.  They use phishing attacks to install the TrickBot and the BazarLoader trojans that subsequently provide remote access to the infected machines.  Then using that remote access, they move laterally through networks, stealing credentials and harvesting unencrypted data stored on websites and servers, as we know.  That's now the first move is to exfiltrate everything they can off to the cloud somewhere.



Once the attackers have stolen everything of value and gained access to Windows domain credentials, what's interesting is they now explicitly wait for a quiet time on the network based on whatever entity it is that they have infiltrated.  You know, probably like early, very early on a Sunday morning local time.  Or maybe very early on a Saturday morning, if they note that Saturdays stay quiet.  The point is they're wanting as much time as possible before they're discovered, after triggering and deploying the encrypting Conti ransomware throughout the network.



So the Wizard Spider Conti gang then use, of course, the stolen data as leverage to force their victims into paying a ransom by threatening to release it on their ransom dark leak site if they are not paid.  Recent high-profile Conti ransomware attacks include the FreePBX developer Sangoma, the IoT chip maker Advantech, Broward County Public Schools, and the Scottish Environment Protection Agency.  The big attack that recently captured everyone's attention was their infiltration, data exfiltration, and subsequent encryption of Ireland's Health Services Network.  That was actually on the radar when I did the podcast last week, but it didn't really stand out except for the fact of what it is.



Ireland's Health Services Network is known as HSE, for Health Service Executive.  It's Ireland's publicly funded healthcare system, which was forced to shut down in its entirety Friday before last.  The Irish National Health Service said:  "We have taken the precaution of shutting down all our IT systems in order to protect them from this attack and to allow us to fully assess the situation with our own security partners."  That IT outage led to widespread disruption across the country for all of its healthcare, resulting in limited access to diagnostics and medical records, transcription errors which occurred due to the use of handwritten notes, and slow response times for healthcare visits.



Naturally, in a system which had become dependent upon IT, if you lost all your IT, you were in trouble.  We found a snapshot of the dialogue which then ensued between HSE and the bad guys.  They said:  "As you already know, we infiltrated your network and stayed in for more than two weeks, enough to study all of your documentation, encrypted your file servers, SQL servers, downloaded all important information with a total weight of more than 700GB - personal data of patients (home addresses, phone numbers of the contact), employees (home addresses, employment contracts, scans of personal documents, phone numbers), contracts, customer bases, consolidated financial statements, payroll, settlements with partners, bank statements.  The good news is that we are businessmen.  We want to receive ransom for everything that needs to be kept secret, and don't want to ruin your business.  And amount at which we are ready to meet you and keep everything as collateral is $19,999,000."



LEO:  We are businessmen.  We just want to tell you...



STEVE:  We are greedy, greedy businessmen.



LEO:  Maybe their definition of businessmen is not quite the same as mine.



STEVE:  Wow, $19,999,000.  So for some reason...



LEO:  Oh, oh, a dollar off.



STEVE:  Yeah, well, a thousand dollars off.



LEO:  Thousand dollars off.



STEVE:  One thousand less than 20 million.  So apparently, sensing that they had hooked a big fish, the attackers demanded, as this note says, $1,000 shy of $20 million ransom.  Now, get this.  The Prime Minister of Ireland said they would not be paying any ransom.  Then, as part of their ongoing negotiations - and perhaps in part due to the long shadow just recently cast by the DarkSide attack which shut down, of course, as we know, the Colonial Pipeline - last Thursday the gang behind Conti, these Wizard Spiders, posted a link to a "free," as they put it, "free" decryptor.  Get your free decryptor, which will work for all of the HSE encrypted data.  Researchers have confirmed that the provided tool will decrypt the files, though it is still being inspected more closely to make sure it doesn't contain any other malicious content.



Okay.  However, the bad guys still insist upon being paid just shy of $20 million ransom, threatening to go public with their trove of extremely confidential Irish citizen health records data.  They said:  "We are providing the decryption tool for your network for free. But you should understand that we will sell or publish a lot of private data if you will not connect us and try to resolve the situation."



Okay.  Now, in an odd-seeming bit of whimsy, the High Court of Ireland issued an injunction against the Conti ransomware gang, demanding that the 700GB of stolen HSE data be returned and not sold or published.  What?  The High Court has issued an injunction against a hidden, probably Russian, cybercrime organization?  To what end?



The injunction was received by the HSE against the Conti ransomware gang from the High Court of Ireland.  But without any formal method to service the Court's order, government representatives uploaded it to the Tor dark website associated with the gang, I guess as their means of serving them.  The order prohibits the attackers from publishing, selling, or sharing any of the stolen data with the public.  And then, get this.  It also demands that they return the stolen data and identify themselves by revealing their full and true names...



LEO:  Identify yourselves.  You vagabond.



STEVE:  ...email addresses, and physical addresses.



LEO:  Sure, why not?



STEVE:  Which, you know, yeah, exactly.  You can ask.  Which led me to wonder what sorts of mind-altering substances might be in use by the High Court.  This feels like something more than a long afternoon in an Irish pub.



Okay.  So what's up with this apparent loss of sanity?  No one believes for a moment that the Conti gang will acquiesce to the demands of the High Court of Ireland, no matter how sincere they might be.  But there is some outside hope that the country providing cover and domicile to the attackers might be willing to track them down - uh-huh - and at least prevent them from leaking the stolen data.  You have to imagine that Russian intelligence knows exactly where these guys are holed up.



But the next day, last Friday, the Irish Times Security & Crime Editor, Conor Lally, explained in a pair of tweets that the injunction is never intended to prevent the Conti gang from leaking the data.  Rather, it was issued to prevent the press, or anyone else, from publishing the contents of any stolen data if it were to subsequently be leaked by the ransomware gang.



In Conor's first tweet, he said:  "The injunction is not a super injunction in the traditional sense.  We can report about it and report if data is published.  The injunction is designed to stop/limit the distribution of the data/docs in Ireland after they are published by the attackers."  And then in his follow-up tweet he said:  "The injunction doesn't stop the media reporting if the attackers leak the data, which one assumes is likely.  It just means media, and anyone else, cannot publish/share the actual documents when they are leaked."



So I checked just, I think it was this morning again, to see if there had been any update since late last week.  There was some buzz about some disclosure several weeks ago, but it seems unlikely because there isn't any, you know, nothing has happened since, and this all happened afterward.  So anyway, we'll see what happens with this gang.  But Conti is now in the big-time, and they've gotten the attention, presumably deliberately.  I don't know if these guys are a Ransomware as a Service.  I don't think they are.  So there's no middleman that they're dealing with.  And we will be talking about the whole RaaS stuff here shortly.



I did, however, want to take note of literally a mega ransom.  A huge firm, CNA Financial, based out of Chicago, has paid up big-time.  And I'll also note that insurance companies in general have begun backing away.  The U.S. insurance giant CNA Financial reportedly paid $40 million to a ransomware gang to recover access to its systems following an attack back in March.  And this registers as one of the biggest ransoms paid to date.  This was reported first by Bloomberg, citing "people with knowledge of the attack."



The adversary that staged the intrusion is said to have allegedly demanded 60, six zero, million a week after CNA, which as I said is based in Chicago, began negotiations with the hackers.  So they talked them down 20 million, which, you know, is good.  And that culminated in the payment two weeks following the theft of company data.  In a May 12th statement, CNA Financial said it had "no evidence to indicate that external customers were potentially at risk of infection due to the incident."  Likely there was exfiltration, and they are assured that the data will go no further.



The attack has been attributed to a new player on the scene, the "Phoenix Cryptolocker," according to a BleepingComputer report back in March at the time.  The strain is believed to be an offshoot of WastedLocker and Hades, both which are known to have been used by the Russian cybercrime network, Evil Corp.  A year and a half ago, back in December 2019, U.S. authorities sanctioned Evil Corp, we talked about this at the time, and filed charges against its alleged leaders Maksim Yakubets and Igor Turashev for developing and distributing the Dridex banking trojan to plunder more than $100 million over a period of 10 years.  Law enforcement agencies also announced a reward of up to $5 million for information leading to their arrest.  Today, both remain at large.



And remember that last October 2020, the U.S. Department of Treasury issued a "guidance," as they called it, warning of penalties against companies making ransom payments to any sanctioned person or group.  This prompted ransomware negotiation firms to avoid dealing with blocked groups such as Evil Corp.  The Treasury Department said:  "Companies that facilitate ransomware payments to cyber actors on behalf of victims, including financial institutions, cyber insurance firms, and companies involved in digital forensics and incident response, not only encourage future ransomware payment demands, but also may risk violating the Office of Foreign Assets Control regulations."



So the surge in ransomware attacks has always had an impact on the cyber insurance industry.  And this is something we have been expecting.  One firm, AXA, announced earlier this month that it will stop reimbursing clients in France should they opt to make any extortion payments to ransomware cartels.  This underscores the expense of ransomware indemnification, where insurance firms grapple with successfully underwriting ransomware policies while confronting the rising payout costs that threaten their bottom lines.



And to that end, a report just released by the U.S. Government Accountability Office (GAO) last Thursday revealed that the soaring demand for cyber insurance has driven insurers to raise premiums while limiting coverage.  The amount of total direct premiums written jumped up 50% from 2016 to 2019, from $2.1 billion to #3.1 billion.  And those numbers of course are two years old now.  So one imagines the rate of payment is even higher.  The GAO noted that:  "The continually increasing frequency and severity of cyberattacks, especially ransomware attacks, have led insurers to reduce cyber coverage limits for certain riskier industry sectors, such as healthcare and education [unfortunately] and for public entities, and to add specific limits on ransomware coverage."



So we've been watching this unfold on this podcast.  It was inevitable, and now it's happened.  So when they say "IoT," do they mean us?



LEO:  UoT.



STEVE:  A headline at Threatpost from last Wednesday caught my eye.  It read:  "Keksec Cybergang Debuts Simps Botnet for Gaming DDoS," with the subhead "The newly discovered malware infects IoT devices in tandem with the prolific Gafgyt [spelled G-A-F-G-Y-T] botnet, using known security vulnerabilities."  So I thought, IoT devices.  What IoT devices exactly?  Are they some obscure widget that no one we know uses?  Turns out no.  They're referring to the incredible number of Linux-based NAT routers  that virtually everyone is using.



The Threatpost piece goes on to talk about a recently developed botnet named Simps, S-I-M-P-S, which has emerged from the cyber underworld for the purpose of carrying out DDoS attacks aimed at gaming targets and others.  It's hosted on other people's consumer routers and forms part of the toolset being used by this Keksec cybercrime group.  The Simps botnet was first spotted in April being dropped on IoT devices, and by that I mean NAT routers, by the Gafgyt botnet.  And I suppose one good botnet deserves another.  So this was one botnet planting a second one. 



Gafgyt is a Linux-based botnet that was first seen seven years ago, back in 2014.  It targets vulnerable IoT devices such as routers made by Huawei, Realtek, Asus, and Dasan's GPON home gateway devices, of which a quarter million are on the 'Net.  In other words, not obscure, unsupported light bulbs somewhere, but our NAT routers.  And in the present infection campaign, this Gafgyt botnet is compromising, looking for and compromising Realtek and Linksys endpoints.  It then fetches and installs the Simps bot using Wget.  Simps itself then uses the Mirai and Gafgyt modules for its own DDoS functionality.



So our takeaway here is these routers, I mean, our NAT routers are only being discovered because they are in some way responding to incoming packets.  Way back in 1999, on October 8th, my god, nearly 22 years ago, some guy named Paul Thurrott wrote the very first article for a site called WUGNET, the Windows User Group Network.  Paul's article was titled "Protect your Windows PC with Steve Gibson's ShieldsUP!."



LEO:  Nice.



STEVE:  Paul was the first person to write anything.



LEO:  Really?  Oh, that's awesome.



STEVE:  Yup.  So the case I made back then, when I was, as far as I know, the first to use the term "stealth" to refer to an Internet-connected device that did not respond in any way to incoming probes, was that it was worth deliberately violating a de facto rule of the Internet, which was that all devices having TCP/IP stacks must respond to a ping, and that closed ports should respond with either a TCP RST or an ICMP Port Unreachable.  That nearly 22-year-old advice has aged well.  It's withstood the test of time.  So when they refer to "IoT devices," they do mean us.



At my other location I have an Asus router.  It's not on the front line.  It's safely positioned behind a FreeBSD pfSense router since I need features such as pfSense's powerful static port translation and its IP-based incoming packet filtering.  But after a tweet I received this morning, I'm now excited to get home to update my Asus by hand because it may be the last time I ever need to do so.  I'll have more to say about that when we get to this week's listener feedback.  In the meantime, please, please, please make absolutely certain that the routers you're responsible for and the routers of those you care about do not have any connection-accepting ports statically exposed to the Internet.  Any appearance of convenience that something that might be listening might be offering is just not worth the risk.



So we have a new term introduced:  Mean Time To Inventory.  Everyone's familiar with the abbreviation MTBF, right, Mean Time Before Failure.  Now the industry is coining a new abbreviation, MTTI, Mean Time To Inventory.  This refers to the startling speed with which bad guys have begun to scan the Internet for newly released vulnerabilities after that vulnerability's first public announcement.  In this case the term "inventory" refers to them adding penetrated devices to their "inventories."



Now, in both cases, MTBF and MTTI, we'd like them to be as long as possible.  But at least in the case of this new MTTI, it turns out that a study recently released by Palo Alto Networks'  Cortex Xpanse research team reveals for the first time just how startlingly short today's MTTI actually is.  They frame their research by explaining:  "Malicious actors are opportunistic predators, constantly searching for vulnerable targets.  Unfortunately, adversaries are much faster at finding vulnerable assets to attack than defenders are at finding those same assets to secure.  It's not just an arms race," they write, "in terms of conducting cyberattacks and protecting against them.  There's also a sprint to detect systems vulnerable to cyber threats."



They said:  "To help enterprises gain ground, the Palo Alto Networks Cortex Xpanse research team studied the public-facing Internet attack surface of some of the world's largest businesses.  From January to March of 2021, we monitored scans of 50 million IP addresses associated with 50 global enterprises, including a subset of the Fortune 500, to understand how quickly adversaries can identify vulnerable systems for exploitation.  In this report, we share our key findings, information on the top threats in attack surface management, and insights on how to ensure your organization remains secure."



Okay.  So we've talked about how this race to patch versus race to penetrate is happening for quite a while now.  But we've been lacking in metrics.  What the Cortex Xpanse team found was that potentially juicy zero-day vulnerabilities can prompt attackers to begin scanning within as few as 15 minutes following first public disclosure.  Now, think about that.  This is not just a scan for a port.  This is a scan for a specific vulnerability that they didn't know about 15 minutes earlier, located at a specific port.  That means that attackers are writing and deploying custom scanning code within 15 minutes in order to be scanning for not-yet-patched vulnerabilities that fast.  This really does change the landscape for serious remotely exploitable vulnerabilities.



And get this.  The researchers noted that attackers worked even faster when it came to Microsoft Exchange, with first vulnerability scans detected no more than five minutes after the release by Microsoft of the patches.  Now, recall that I talked about how it seemed clear that the bad guys must already have a mature database.  All these different groups must already have databases indexed by port and probably also by what's known to be answering queries at that port for the entire Internet.



So the moment a new vulnerability appears, for instance in Exchange Server, they're not scanning all 4.3 billion IPv4 addresses.  They're able to immediately extract the list of all known Exchange servers currently accepting connections over SMTP, POP, and IMAP, whatever the vulnerability is listening on, in order to then immediately begin exploitation.  And today this literally happens in the blink of an eye.  When this happened to Microsoft Exchange, the researchers over at F-Secure commented that vulnerable servers were being hacked faster than they could count.



It's also been noted that the general availability of inexpensive cloud services has helped not only well-established APT groups known to be using them, but also smaller cyber criminal groups and individuals, to take advantage of new vulnerabilities as they surface.  This Cortex Xpanse group report notes:  "Computing has become so inexpensive that a would-be attacker need only spend about $10 to rent cloud computing power to do an imprecise scan of the entire Internet for vulnerable systems.  We know from the surge in successful attacks that adversaries are regularly winning races to infect systems before they can be patched against new vulnerabilities."



And, interestingly, the Palo Alto Networks group's research also highlighted that, not surprisingly to any of our listeners, remote desktop protocol, RDP, was the most common vector for security intrusions among enterprise networks.  It alone accounts for one third of all security problems overall.  The report says:  "This is troubling because" - well, it's just troubling, period.  But they said:  "This is troubling because RDP can provide direct admin access to servers, making it one of the most common gateways for ransomware attacks."



And I don't know if I mentioned, actually, publicly on the podcast that there are instances where - there are databases of compromised RDP login credentials which are for sale on the dark web.  So affiliates of Ransomware as a Service who aren't themselves super skilled at engineering intrusions, they'll buy a credential and use it to log in, and then begin their penetration.  And you know, if it weren't for the blessed pervasive ubiquity of NAT routers behind which all of us with Windows systems are able to hide, the world as we know it today would have already ceased to exist.  Can you imagine if the world's entire inventory of remotely accessible devices weren't just enterprises who have to have a public presence, but were also every single last powered-on Windows machine and IoT device.



The nutty IP purists, with their heads well positioned far up their you-know-whats, where the sun don't shine, have always decried the use of NAT.  They say that the Internet was designed for every device to be directly addressable and accessible to every other.  Well, thank god that never happened.  Just because every IPv6 user will be receiving their own personal 64,000 IPv6 address space, don't ever consider directly mapping those external IPs through to your devices on the inside.  It's already bad enough that Microsoft gave us UPnP so that Xboxes could autonomously solicit incoming traffic.  The last thing we need is to step out from behind the protection of those billions of little hardware firewalls that everyone is using today.  With a mean time to inventory numbered in the low minutes, none of us would stand a chance.  So, whew.



Okay.  Two bits of fun.



LEO:  Yabba Dabba Doo.



STEVE:  Oh, and the sale of SpinRite 6.  Very cool.  Okay, Leo, you're going to want to go and test your skill.  It took me an embarrassing number of times to prove I was human:  grc.sc/820.  It is our Shortcut of the Week.



LEO:  I hate these CAPTCHAs.  I just hate them.



STEVE:  Well, this is the Doom CAPTCHA.  It's a joke.



LEO:  My doom or your doom?  Oh, my doom, huh?  Okay.



STEVE:  Well, no.  It is the game Doom.



LEO:  Oh.  Oh.



STEVE:  Yes.



LEO:  Okay.  So kill four enemies.  I think a computer could do this very easily.  One, two, I mean, really, how hard is this?  Oh, game over.



STEVE:  Yeah, you didn't do it quick enough, Leo.



LEO:  You've got to do it fast.  Computer can do it slowly.  I see.  Whoa.  Oh.



STEVE:  Okay, see, now...



LEO:  You know what?  I like that.



STEVE:  This tells me you really have been spending a lot of time shooting stuff.



LEO:  I spend a lot of time playing Doom.



STEVE:  It took me, like, 10 tries.



LEO:  What?



STEVE:  To get that green checkmark.



LEO:  One, two.  Oh, I see, the red progress bar is my time.



STEVE:  Yeah.



LEO:  I get it, yeah.



STEVE:  Yeah.



LEO:  Yeah.  You don't like this, then.  I get it.  I take it.



STEVE:  No, I just thought it was just - it occurred to the guy last Saturday morning.



LEO:  That's funny.



STEVE:  He coded it by the end of the day.  It made #1 Product of the Day over on Product Hunt.



LEO:  Product Hunt, yeah.  It's just a little embed.  Look at that.



STEVE:  Yeah.



LEO:  So simple.



STEVE:  It's just a cute little thing.  So anyway, I just - I wanted to share it with our listeners.  I thought, I knew that a lot of us old-timers would recognize that and get a kick out of it.



LEO:  Oh, wait a minute, I didn't have the sound turned on.



STEVE:  Oh, yeah, yeah, yeah.



LEO:  Is that Doom sound in this?



STEVE:  Oh, yes.



LEO:  Oh, yeah?  Let's see.  Oh, yeah, baby.  Oh, yeah, baby.  It's Doom.  Okay.  Wait a minute.  But I don't mind because I got the Doom sound effect.  That's hysterical.  I wonder how Carmack is at this.  That's great.  How fun is that?  It's just hysterical.  Love it.



STEVE:  Okay.  A little less overtly entertaining, but this is the one that I just find myself staring at.  I know this is completely random, but a few months ago I looked at Windows 10's built-in screensavers and realized that as far as Microsoft appears to be concerned, screensavers have fallen into disfavor.  Or perhaps they've migrated over to the Windows Store.  I don't know.  I didn't go there.  Since I often leave my Win10 machine on and unattended, like during dinner, when I'm taking a walk with Lorrie after dinner or whatever, and since my workstation is in our family room so that I'm able to be working while still being nominally present, clanky mechanical keyboard notwithstanding, I decided that I wanted something fun on the screen when I wasn't using the machine.  So I went looking for a satisfying screensaver.



Several months later now, I'm enjoying what I found, so much that I wanted to share it with my listeners, who often tell me that my taste matches theirs.  Maybe that'll happen again.  A developer named Terry Welsh has written a collection of open source, open GL screensavers.  He wrote them for Windows, but this one and most others have also been ported, because they're open source, to OS X and Linux.  This one is called Helios, which is the one that for some reason I find transfixing.  So they're all at ReallySlick.com, that's Terry's site, ReallySlick.com/screensavers.



But I have to say I was not a fan of Helios's default settings.  Out of the box, it was way too busy for me.  So it needed some tweaking to match my taste.  And I've captured the settings panel I use with it so that others can see it the way I see it.  So it's in the show notes for anyone who's interested.  So, let's see, I have ion size at 10.  Number of emitters, I left it at 3, I think that was the default.  Number of attracters at 3, I think that was the default.  Animation speed is 10.  Camera speed is 1.  I think I slowed that down to 1.  Motion blur is 50.  I think I turned that up to 50.  And then the frame rate has no limit.  It's at zero.



Anyway, see what you think.  Watch it for a while.  You can download a zip of his that contains all 12 of them.  And then if you just drop it in your Windows System32 folder and then go to select your screensaver, it may be set to none right now, you can see all of them and poke around.  So there is another one that I just started looking at, Microcosm, which Lorrie likes a lot better.  It produces some really cool-looking kind of liquid 3D objects which, you know, if that's more your thing, check out Microcosm.  Anyway, just to point people there.  You know, see what you think.



Okay.  Some closing the loop stuff from our listeners.  JP wrote:  "On today's Security Now! you discussed Tor and HTTPS."  He says:  "By definition, Tor hidden sites are not going to use HTTPS.  Getting a cert would make mockery of being hidden.  And a self-signed cert these days just pops up flags."



So JP's assertion was interesting to me since I had never looked into the issue of Tor .onion sites themselves using HTTPS.  JP was a bit confused about our previous discussion, however, since in that discussion of the problems with Tor exit node security we were talking about non-HTTPS connections being made through Tor to external websites on the Internet, not internal .onion sites.  But that left the interesting question about obtaining TLS certs for .onion Tor hidden sites.  It seemed to me that any ACME-based TLS certificate issuer such as Let's Encrypt would be what one wanted; right?  I mean, you don't want to identify yourself.  But you do want to assert your domain name, which is what ACME-based automation of TLS certificates allows.



So it turns out that, until recently, only EV, believe it or not, Extended Validation certs, could be issued for .onion domains.  And it was truly by coincidence that it appears DigiCert, as we know, my chosen certificate authority, appears to be the choice for EV .onion certs.  It was initially unclear to me why EV was required.  And it would seem that needing to authenticate oneself to the level required to obtain an Extended Validation certificate could hamper some of the value provided by .onion domains.  But as we'll learn in a moment, there was a rationale behind that.



But first, I discovered that .onion domains have a long history of HTTPS access.  Seven years ago, when Tor users would attempt to visit their Facebook accounts, Facebook's geofencing security would trigger to lock that user's account because the traversal through Tor would cause the user to appear to be connecting to their account from some foreign land.  To fix this problem, while also allowing Tor users to have a better experience when connecting to Facebook, way back in 2014 Facebook launched the dedicated Tor address https://facebookcorewwwi.onion.  Using this SSL/TLS authenticated and encrypted onion site, Tor users could access the site directly without fear that doing so might freak out Facebook's geo-aware security.



So yes, traditional security certificates have long been available for Tor's .onion sites.  However, I also found a CAB, you know, the CA/Browser Forum, a CAB Forum ballot, where certificate issuers, 15 different certificate authorities, and four customers - Apple, Microsoft, Google, and Mozilla - voted unanimously, with a few abstentions, but no nays, in favor of opening up DV and OV certs to .onion domains.  And Let's Encrypt was among those voting in favor of having this happen.



The explanation of the purpose of the ballot was also quite informative.  It says:  "This ballot will permit CAs to issue DV and OV certificates containing Tor onion addresses using the newer version 3 naming format.  In ballot 144, later clarified by ballots 198/201, the Forum created rules for issuing EV certificates containing onion addresses.  A primary reason for requiring EV level validation was that onion addresses were cryptographically weak, relying only on RSA-1024 and SHA-1.  More recently a newer 'version 3' addressing scheme has removed these weaknesses.  For much the same reason that EV certificates are not always a viable option for website operators, for example, sites operated by individuals" - or I would argue sites wanting to be secure, but not identify themselves - the ballot says "many onion sites would benefit from the availability of Domain Validation and Organization Validation certificates for version 3 onion addresses."  Which, by the way, is now the standard in Tor.



They said:  "The Tor Service Descriptor Hash extension required in the EV Guidelines to contain the full hash of the keys related to the .onion address is no longer needed as this hash is part of the version 3 address.  Older version 2 onion addresses are still in use, so this ballot does not remove the existing EV Guidelines requirements for onion names."



So this balloting occurred back in February of 2020, so more than a year ago.  I haven't been able to locate any evidence of anyone other than DigiCert issuing .onion certs, and those EV.  But it appears that Let's Encrypt is all onboard for this, so I would imagine that it's just a matter of time before this starts happening, if it hasn't yet.  But again, I mean, I didn't, like, scour the Internet.  But a quick search didn't turn up anything.



I mentioned going home to perform maybe the last manual update I would ever need to of my Asus router.  Mikael Falkvidd, who is a friend of mine, he was one of the hosts of the SQRL presentation during the trip I made around Europe.  I found a tweet from him this morning saying:  "Hi.  I just wanted to let you know that our Asus routers now support auto update.  This feature was not included in the release notes, but a fix for the frag attacks were included."  And he gave a screenshot of the page, which I included here, showing the ability to turn auto updates on and specify what time of the day, typically the wee hours of the morning, when you give the router permission to update itself.



And there is some talk about the way to recover in the event of a failed update.  If that updates, and if it's a fallback to the previous firmware, both fail, then there is a recourse for the user.  But, you know, bravo.  Let's hope this becomes standard operating procedure.  It's, you know, way easier for Linux-based routers because they have a lot more resources to work with.  What we need is for our light bulbs and our electric plugs to be able to do that, too.



Jared Stein tweeted:  "Steve, since you always talk about science fiction books, I was wondering if you could suggest a starting book, one that would either lead me into continuing to read it or determine it's not for me."  He said:  "I do really appreciate Security Now! and all you bring to the community.  Regards, Jared."



Well, okay.  So there are as many science fiction authors as there are musicians, and taste for the work of this or that author is probably as personal as taste in music.  But one of my favorite authors is, as we know, Peter F. Hamilton.  And there goes another sale of SpinRite 6.  Thank you.  One of my favorite authors, as I was mentioning, is Peter F. Hamilton and his "Fallen Dragon."  It's a standalone novel, a great example of his imagination.  It is a little militaristic, so that's okay.  But it's not based on military, it's just it's a great read.  And if you like that one, then his pair of novels, "Pandora's Star" and "Judas Unchained," would be next in line.  He then gets into trilogies.  And, boy, Peter has never written a short book.  I guess actually there is a novella.  Novella?  Novella.



LEO:  Novella.



STEVE:  Yeah, or two.  But generally they're really satisfying, and they are really long, but really fun.  Also I've got two tweets regarding "The Martian," which was going to remind me to ask you about how the Andy Weir interview went on Friday.



LEO:  Oh, it went great.  He's such a cool guy.  I just love him.  And, yeah, highly recommend it.  We put it out on the Triangulation feed, as well as the TWiT events feed.  So it's about an hour and few minutes of Andy talking about, well, the first half is spoiler-free.  And then we put up a big sign that says, "Spoilers."



STEVE:  Good, good, good, good, good, good.



LEO:  Because I had questions I wanted to ask him about the book specifically.  So, but yeah, we do at least half an hour spoiler-free.  Listen to the first half hour, read the book, then listen to the second half hour.  It's easy.



STEVE:  Very cool.  Kerry Blue Life tweeted:  "Steve, thanks for 'The Martian' recommendation years ago.  Andy Weir has done it again with 'Hail Mary.'"  He said:  "I was surprised how emotional it could be."  And Leo, did you finish it?  Because you had, like, two hours left, I think.



LEO:  Oh, yeah.  I finished it before I talked to him, yeah, yeah, yeah.



STEVE:  Okay.  And then Craig tweeted:  "Thanks for 'Hail Mary.' Work on Monday is so much closer now <sigh>."  I guess he listened to it all weekend.  And he said:  "BTW, great narrator, same as the Bobiverse books."  He says:  "I kept waiting for Bob or piggies to show up."  Now, I have no idea who Bob and the piggies...



LEO:  No idea either, yeah.



STEVE:  Bob and the piggies.  At least we know that "Hail Mary" is really good.



LEO:  Really good.  Yeah, the guy, I asked him about R.C. Bray, who read "The Martian."  And I guess he just wasn't available.  But the guy they have read "Hail Mary," you don't listen to audiobooks, so you don't care.



STEVE:  No.



LEO:  But for those who do, Ray Porter does a fantastic job, I would say as good as R.C. Bray.



STEVE:  Very cool.



LEO:  Yeah.  And the R.C. Bray version of "The Martian" is gone.  I don't know why.  Wil Wheaton reread it.



STEVE:  And given the power of Andy's pull, I would imagine he could get anybody, I mean, that Audible could get anybody they wanted to do it.



LEO:  Yeah.  He did offhandedly mention, I did not pursue it, that R.C. and Audible didn't always see eye to eye.  But I don't want to read too much into that.  He also mentioned they've already sold the movie rights to "Project Hail Mary."



STEVE:  Yay.



LEO:  And that Ryan Gosling will play the lead in it.



STEVE:  Oh, my god, they've cast it already.



LEO:  Oh, yeah.  Lord and Miller are directing it.  Yeah, I think after - "The Martian" almost won an Oscar.  "The Martian" was, you know, a huge success.  In fact, it was, you know, you think about Ridley Scott, the guy who directed it, and all the great movies he's done like the "Aliens" movies, "The Martian" was his highest grossing movie ever.  So, you know.



STEVE:  And you know, it's going to - had popular appeal.



LEO:  It really did.



STEVE:  Yeah.  And I will say the book was so much better.  I read the book before seeing the movie on purpose.



LEO:  It's always better to read the book first, I think, yeah.



STEVE:  Yes, yes.  And "Jurassic Park," same way.  There were so many things, it's like, wait, wait, wait, you left this out.  It's like, oh. 



LEO:  Especially for me with science fiction.  I always prefer to read the book.  Either the book's going to spoil the movie or the movie's going to spoil the book.  But I just feel like the book is always going to be the true vision.



STEVE:  Oh, "Ender's Game," so much better to read.



LEO:  Oh, much better in the book.  And "Ender's Game" has a twist, which will be spoiled for you.  So read the book.  Don't watch the movie.  It's much better to be spoiled by the book than it is by the movie.  Let's put it that way.



STEVE:  Yeah.



LEO:  He said he's got a percentage of the gross for "Project Hail Mary," so he'll be doing okay.



STEVE:  Good for him.



LEO:  You always want to do that.  He's a producer on the film.



STEVE:  Good for him.



LEO:  And Lord and Miller are - they directed "The Lego Movie," the "Jump Street" movies, the "Spider-Man:  Into the Spider-Verse."  So they have a good track record, mostly with animated movies.  But we'll see.  I think it'll be a good movie.  I'm excited.  It's a great book.  Read the book.  Always read the book.  



STEVE:  Well, there's no way they're going to put lame directors in charge of a movie with that much potential.  



LEO:  Exactly.



STEVE:  So, yeah.



LEO:  Yeah, yeah.  And you're absolutely right.  You should read the book first, yeah.



STEVE:  Okay.  I think this is my last little bit of feedback.  But it was an interesting question.  Mike Lawrence tweeted:  "@SGgrc Have you given any thought to vaccine e-passport verification/privacy?"  He says:  "One concern is verification can induce a record for tracking activities, but I feel like there's a public key solution to that."  And yes, there is indeed a public key solution to that.  In fact, there's a public key solution to most things.



So I played around with this a bit yesterday.  The largest possible standard QR code for 8-bit binary data can encode 3K bytes.  I took a headshot of myself and used JPEG compression to reduce its size to 3K and pasted it into today's show notes.  It's entirely recognizable as me.  A QR code's digital data could be signed with a government's private key and subsequently unspoofably verified with the government's matching public key.  So, for example, a credit card-size vaccination ID could be created containing its holder's photo, its signed QR code, and its signature, side by side.



Then, when needing to prove vaccination status, say at an arena, or maybe for indoor dining, or perhaps even dating, people could present their card to the ticket agent, the receptionist, or their date.  Upon scanning the card, the validity of the QR code, that is, the QR code's signature, thus the QR code, could be instantly and locally, that is, without any communications, verified without any need to phone home.  And the QR code would also present the user's face on the verification screen for comparison to what's shown on the card and with the face of the person presenting the card.



So to be clear, I'm not proposing that this is what we or anyone should do.  I'm just noting that today's crypto technologies provide us with such a flexible toolkit that they can be used to provide solutions to nearly any problem.



Now, Mike also asked about privacy.  The system I've described is able to validate that a visually recognizable and digitally scannable image of an individual can be signed using a private key, and that signature can therefore be authenticated without any communications.  But to be more useful moving forward, if a query were allowed to a trusted, non-tracking, privacy advocacy group, then the individual's relevant vaccination history could be retrieved, presumably without any logging, to make this single card also useful in the future for any possible vaccination boosters or next pandemic vaccines and so forth.



So anyway, just a proof of concept that, yeah, as a country it's not clear what's going to happen in the future.  Looks like hopefully we're going to get out of this current COVID-19 mess without the need of any proof of vaccination.  We'll see how that goes.  But for what it's worth, it would be possible to create a separate health status card whose signature could be verified locally with an optional check to see if there are any updates.



Okay.  So I wanted to finish up this week by making an observation about something that's going on in the dark underworld.  There are now around 20, maybe it's 21 since we began the podcast, individually identifiable ransomware groups with most now, though not all, operating under the Ransomware as a Service model because it's proving to create additional value through specialization of function.  And thus arises the problem of the responsibility to pay affiliates their share of a ransom after payment has been received from the victim.



In the case of DarkSide's decision to abruptly shutter their operations and/or being forced to do so, we don't have full visibility into exactly what went on there, affiliate postings have begun appearing on dark web forums complaining about nonpayment of affiliate commissions which have been earned, so to speak, and which are now due.  And yeah, I agree, "Oh, boohoo."  But the existence of well-known dark web forums means that this is now happening in plain sight for all RaaS operators, you know, Ransomware as a Service, RaaS operators, and current and would-be affiliates to witness.  Service operators want to attract affiliates, and affiliates want to be reliably paid.  In this environment, the presence of dark web forums means that we now have a marketplace with low-friction information flow and communications.  This in turn means that three things are likely to happen.



First, the notion that not all RaaS operators are the same will evolve.  RaaS operators will begin to acquire a reputation for reliable and timely payment.  And since to a large degree ransomware is ransomware and cash is king, reliability of payment will largely dictate future affiliate choices, and affiliates can be expected to be extremely fickle.  Any mistake or payment dispute will instantly doom any RaaS service.  It's obviously over for DarkSide.  No one would ever trust them again, especially as the underworld is witnessing the many complaints about nonpayment of earned commissions.



Now there's competition among RaaS service providers.  So I expect that the second thing we're going to see is some jockeying over commission rates.  The only thing that affiliates care about is money.  So as ransomware matures, we can expect to see commission rates settle and mature, too.  Those services which have built the best reputations will be able to charge a higher price for the use of their ransomware by taking a larger piece of the pie, and newer upstart services which are not yet established and trusted may need to lure new affiliates to use their product by offering the use of their ransomware at a greater discount than the more well-established operators.



Hooked a big fish?  Want to keep more of what you're about to earn?  Consider encrypting your target's network with Newbieware.  We only take 5%.  We also have the fastest encryption around so your target will never know what hit them.  And we have big pipes, hosting your ill-gotten goods on AWS, the industry's most reliable cloud storage.



And, finally, the third thing I expect we're going to be learning about before long will be the emergence of another player in the evolving increasingly specialized multi-component Ransomware as a Service ecosystem:  ransom escrow services.  The publicity surrounding the DarkSide collapse is likely to bring about the emergence of a neutral intermediary to manage the money.  Escrows are a time-honored system for holding and transferring valuable assets among untrusted parties.  The cryptocurrency system makes it easy to have the ransom paid to a wallet that's not under the control of either the Ransomware as a Service provider or their affiliates.  This helps to ensure that the affiliate will be paid, no matter what might happen to the RaaS service.



When tens of millions of dollars are at stake, and when payment might be an all-or-nothing proposition, shaving off a quarter point for escrow commission will probably seem like a wise investment.  It will give affiliates the payment assurance that they will now be clamoring for, and it will allow RaaS services to bootstrap themselves by offering to escrow ransom payments as an option.  Given the dynamics of this dark ecosystem, I'll be surprised if we don't learn about ransomware escrow services appearing before long.



For completeness, I should note that there have been some informal first stabs at something like this.  We noted a year or two ago when the REvil ransomware gang deposited $1 million worth of bitcoin into a different hacking forum as a means of attracting affiliates.  They wanted to show that they meant business.  And to show that they, too, meant business, DarkSide placed 22 bitcoin on deposit with the admin of the XSS forum.  But this was more in the form of a guarantee than an escrow.  And 22 bitcoins won't begin to cover the sorts of ransoms we're seeing recently.



So this wasn't an escrow.  As we detailed last week, DarkSide victim funds flowed directly into DarkSide's bitcoin wallet, which had been identified by Eclipse.  And moreover, claims now being made against the DarkSide bitcoin guarantee stash, which the XSS forum is administering, are meeting with trouble being paid.  This also suggests why that XSS admin may have said that ransomware is no longer welcome there.  This admin is likely quickly getting fed up with the unwanted responsibility of being DarkSide's unpaid de facto guarantor.  And one wonders what happens to any unclaimed guaranteed funds.  Who gets to keep them?



It does appear that DarkSide did the best they could after they stumbled into the Colonial Pipeline nightmare.  Their affiliates who successfully encrypted victim networks have all received the corresponding decryption keys which allow them to pursue negotiations with their victim companies independently, at least those who have not yet paid into DarkSide's bitcoin wallet, though that's not what they signed up for, either.  They wanted their own intermediary.



And after writing all of the above, it occurred to me to Google the phrase "cryptocurrency escrow," which returned more than 2.5 million hits.  So escrowing cryptocurrency is obviously not a new concept.  However, no reputable commercial cryptocurrency escrow service wants to receive a letter from Ireland's High Court demanding that they freeze funds in escrow.  So the dark web will need to establish its own dark escrow services.  I expect we'll be hearing about such a service before long.



LEO:  You know the other thing this points out is there are some real good avenues for federal law enforcement to disrupt this because, as you point out, reputation is so important.  We don't know who brought down DarkSide's servers and who brought down their payment system.  



STEVE:  Right.  But it hurt them.



LEO:  It hurt them.  Whether they did it on purpose or not, it hurt them.  That's really an interesting pressure point that law enforcement could use.  Instead of trying to catch these guys, damage their reputation.  That puts them out of business, anyway.



STEVE:  Yeah. 



LEO:  Interesting.  I hope we don't see a whole - somebody in the chatroom said, you know what Steve's left out is the corporate acquisitions and mergers.  I'm a businessman here.  I'm doing business.  What's your problem?  I think you're taking that a little too far, the business thing here.  But we'll see.  It is interesting, though, that they themselves want to pretend that they're a legitimate business.  



STEVE:  And they say they are.  It's like, hey, we're really sorry that your, you know...



LEO:  We're in it for the money.  It's not personal.



STEVE:  You know, you can't access your CAT scan right now.  We want you to.



LEO:  We do.



STEVE:  But, you know, we're businessmen.  Just pay us.  All we want is your money, and then we'll let you have your stuff back.



LEO:  I'm in waste disposal.  That's my business.  Olive oil sales.  It's a good business.



STEVE:  Yeah.



LEO:  Yeah.  Wow.  Well, I hope that this is more of a humorous essay than it is a roadmap for the future of ransomware.



STEVE:  Lay down your bets, ladies and gentlemen.  I'll guarantee you we're going to see the dark escrow appear.



LEO:  Yeah.  Wow.  Steve is at GRC.com.  That's his website, the Gibson Research Corporation.  Lots of things there.  But you start with SpinRite, the world's finest hard drive, sorry, mass storage recovery and maintenance utility.



STEVE:  And really, I want to thank our listeners.  I wouldn't be at all surprised, Leo, that those two yabba-dabbas we heard weren't from somebody who said, I want to hear my own purchase celebrated.  And so thank you very much.



LEO:  I've long thought you should turn the yabba-dabbas up because - except that it would, eventually, you'd hear so many of them, it would really disrupt the show.



STEVE:  Let's hope.



LEO:  I'm working on a little counter that I could put on the set that shows the current Club TWiT membership number.



STEVE:  Oh, cool.



LEO:  Because I'm hoping people will want to get that spinning around.



STEVE:  Yeah, yeah. 



LEO:  You know, just as a fun thing to do.



STEVE:  Yeah, it's a good idea.



LEO:  Let's go to the tote board.  Yeah, make him yabba-dabba.  He gets a yabba-dabba whenever somebody buys the world's finest mass storage recovery and maintenance utility, SpinRite.  6.0 is the current version; 6.1 is imminent.  Join in on the fun.  You'll get a free upgrade, and you get to participate in the development of this fantastic, much-needed tool.  Steve's got lots of free stuff there, too, like ShieldsUP!, Paul Thurrott's favorite tool.



STEVE:  Thank you, Paul.



LEO:  Isn't that great.  I had no idea that he was the first to discover it.  That's wonderful.  When he was working for WUGNET, of all things.  Let's see, what else?  There's lots of free stuff.  But you should also go check out the podcast.  It's also free.  He's got the only 16Kb audio version of the show for the bandwidth-impaired.  He has a very nice transcript he commissions from Elaine Farris so you can read along as you listen.  He's also got the 64Kb audio.  That's all at GRC.com.



We have audio and video at TWiT.tv/sn.  We also of course put it out as a podcast so you can subscribe in your favorite podcast player and get it automatically, the minute it's available.  If you do like the show, give it five stars, please.  It really helps us spread the word.  And I think everybody should be listening to Security Now!.  It's that important.  Certainly anybody who's responsible for anybody else's computing systems.



We do the show every Tuesday, usually about 2:00 p.m. Pacific, but today we were on time, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  You can watch us live at TWiT.tv/live.  There's audio and video there.  Live chat during the show in two places, irc.twit.tv, and Club TWiT members also get access to our Discord server, which is fun, very active all times of the day or night, not just about our shows, but all sorts of stuff going on in there, including a Linux show we do on Saturdays.  There's a TWiT+ feed, and of course ad-free versions of all the shows.  If you've interested in Club TWiT, it really helps us out.  Seven bucks a month, just go to TWiT.tv/clubtwit.  And for you Club TWiT members, thank you for your support.  We really appreciate it.



Steve, have a wonderful week.  Have fun tonight.  And I'll see you next Tuesday on Security Now!.  Bye-bye.



STEVE:  Right-o.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#821

DATE:		June 1, 2021

TITLE:		Epsilon Red

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-821.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we begin by examining the recent advances made by the just-released Chrome 91, and revisit Google's configurable long-term activity logging.  On the ransomware front we look at yet another likely addition to the ransomware ecosystem:  trusted third-party file decryptors.  We anticipate next week's activation of the Amazon Sidewalk ultra-wide area network, look at the questionable claims of another massive cyberattack, and at WhatsApp's privacy struggles with India and Brazil  couldn't happen to nicer folks.  Then we'll touch on just a single bit of trivia before plowing into a detailed examination of the operation of the newest ransomware in town:  Epsilon Red.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  Chrome 91 has some interesting new features that command line heroes will really enjoy.  We'll talk about new ransomware.  It's called Epsilon Red, and it apparently is mostly written in PowerShell?  Plus a revisit to Amazon Sidewalk and why maybe you don't really want to turn it off.  It's all coming up next with Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 821, recorded Tuesday, June 1st, 2021:  Epsilon Red.



It's time for Security Now!, the show where we cover your security and privacy online with this guy right here, Mr. Steve Gibson.  It's the musical.



STEVE GIBSON:  For those of you don't have video, Leo is pointing at me on the screen.



LEO:  I am.  It's the greatest showman, ladies and gentlemen.  We're doing a musical version.



STEVE:  I am here by voice or vision or whatever.  So we're at June 1st, and lots of fun stuff to talk about.  We're going to begin by examining the recent advances made by the just-released Chrome 91.  Oh, and Leo, after I finished the show notes, I saw that Firefox just got its major expected facelift.



LEO:  Yeah.  Yes.



STEVE:  So I restarted my Firefox, and it's like, ooh, that is nice looking.  So, yeah, that happened, too.  We're also going to revisit briefly Google's configurable long-term activity logging, which sort of ties into Chrome 91.  On the ransomware front, well, actually I skipped over the mention of the fact that this podcast 821 is titled Epsilon Red, which is the name of a, just discovered last week, yet another ransomware strain.



This one is really weird, though.  And we have first of all a lot of information about it because it's easy to know a lot about it, for reasons we'll get to.  And it just sort of also maybe suggests that we're seeing another change in this whole ransomware world.  And of course changes keep happening every week because, unfortunately, it's a happening place.  But before we get to that, we're also going to take a look at yet another likely addition to the ransomware ecosystem up at the top of the show, which seems to be emerging, which I guess I would call "trusted third-party file decryptors."



LEO:  Oh, geez.



STEVE:  Yeah, I know.  It's crazy.  We're also going to anticipate next week's activation of Amazon's Sidewalk, which we talked about in early December of last year, 2020, Amazon's ultra-wide area network, using that LoRa 900 MHz radio stuff.



LEO:  I've invoked your name several times in our discussion of it because you talked about it late last year and gave it kind of a preliminary, anyway, seal of approval.



STEVE:  Yes.  From a technical standpoint, I think they did everything right.  And of course now the tech press, well, and even the less tech press is jumping up and down screaming about...



LEO:  Turn it off, turn it off, turn it off, turn it off.



STEVE:  Exactly, exactly.  So we're going to revisit that.  Also we're going to look at the questionable claims of another massive cyberattack.  Microsoft got a lot of press last week saying, oh my god, 150 corporations have been attacked.  It's like, okay, not really.  And WhatsApp's privacy struggling is happening with India and Brazil, you know, couldn't happen to nicer folks, so we'll touch on that.  I've got just a tiny bit of trivia, and then we're going to, as I said, plow into a detailed examination of the operation of the newest ransomware in town that has named itself Epsilon Red.  And of course we do have a fun Picture of the Week.  So I think 821 will be another good podcast.



LEO:  Busy, busy, busy.



STEVE:  We have a picture of soup, looks like chicken noodle soup because it's got, like, I see little chicken bits and some carrots.  But mostly it's star-shaped noodles filling the bowl.  And of course you'd think, okay, how is that a picture for Security Now!?  Well, the caption is what brings it all home.  It says:  "When your alphabet soup is password protected."



LEO:  Then it's all little stars.



STEVE:  You can't see any of the letters.  All you get is little stars.



LEO:  I love it.



STEVE:  And it's like, hmm, yeah.  Anyway, I thought that was a kick.  Somebody sent it to me.  Thank you, whoever you are, you nameless follower.



LEO:  Meme maker.



STEVE:  I do appreciate it.  Okay.  So Chrome last week moved to 91.  I needed to trigger an update, despite the fact that I sort of - like I always have Firefox open.  That's my background, tabs down the left-hand side, always open.  But I'm finding like I'll just jump to Chrome when I'm just doing sort of temporary things, a few tabs across the top, like when I want to go to GRC's forums, or TweetDeck lives on a tab in Chrome.  So it's just it's easy for me to do that.  So I'm, like, opening it, and I'm in there all the time.  Yet it still doesn't update itself until I go About Chrome.



So they talk about we'll be rolling this out over the next couple weeks.  And I guess that's what "rolling it out" means is that, if you happen to go looking for the new version or see where you are, then it's like, oh, okay, yeah, hold on a second, and then you get it.  Otherwise you'll get it sometime.  Anyway, so presumably it's going to be gradual.  As of last Tuesday, all of the channels, the three different levels, have advanced by one.  So the stable desktop channel gets 91.  The beta gets 92.  And the Canary, built constantly, gets 93.



The release announcement shows that Chrome 91 for the desktop fixes 32 security vulnerabilities, eight of them designated as high severity.  So, what, one in four; right?  Eight of 32.  And of those 32 vulnerabilities which were fixed, 21 were reported to Google by external security researchers.  And there's money to be made doing this, as we've talked about in the past.  The researcher who reported a heap buffer overflow in Chrome's autofill earned themselves $20,000 for that little reported discovery.  And that was one of the eight high-severity problems.



But even a report that Chrome rated as low severity, which was an out-of-bounds read in the V8 JavaScript engine, netted its discoverer $15,000.  And there were a bunch of $3,000, $5,000, and $7,500 awards.  So just kind of keep in mind that it might be possible to pay some bills while helping to make Chrome a bit safer for everyone, if you're someone who likes to poke around at this stuff.



Chrome 91 supports for the first time the use of the clipboard for pasting content into the browser.  Like, for example, maybe it would be handy to have in webmail.  Until now, data transfer could only be done using drag-and-drop.  It was not possible to use a CTRL+C or CTRL+V to paste into the web browser from the clipboard.  91, I guess they figured out how to convince themselves that they were able to make that safe and not have it prone to abuse.  So we get that in Chrome 91.  And also they brought down now to the shipping release that additional protection of NAT slipstreaming.  We talked about how they would be adding the block of port 10080.  Remember that's that whole NAT slipstreaming problem.  It was going to be coming soon, even though Firefox had been blocking this thing, that particular port 10080 since last November.  Chrome finally said, okay, we're convinced that we need to do this.  So that landed in 91.



There's also more good news for Chrome and for all Chromium browsers.  As a result of a new JavaScript compiler and the use of the new way of optimizing code location in memory, Google is reporting that Chrome 91 will execute, that is, the Chrome we can all get now, executing JavaScript code 23% faster.



LEO:  God, that's amazing.  I don't know how they - it's incredible, yeah.



STEVE:  Isn't it?  And that was exactly how I felt because, you know, they keep doing this; right?  We've already had a bunch of surprising code improvements.  The product manager, Thomas Nattestad said:  "In 91, Chrome is now up to 23% faster with the launch of a new Sparkplug compiler and [what they referred to as] 'short built-in calls.'"  He says - I got a kick out of this instrumentation.  They said:  "These save over 15 years of our users' CPU time each day."  So it's like, whoa.



LEO:  That's a lot of nanoseconds.  Wow.



STEVE:  That's like you're going back in - you have to be going back in time in order to save 15 years in CPU time per day.  Of course they mean aggregated over all of the use of Chrome.  But still.  He said:  "Sparkplug is a new JavaScript compiler that fills the gap between needing to start executing quickly and optimizing the code for maximum performance."  And I dug into this a little bit.  Essentially, they're not doing that much optimization because optimization takes time when you could already be executing.  So let's not worry about it too much.  Let's get started doing something.



And then their short, built-in calls optimize where in memory, he said, "we put generated code to avoid indirect jumps when calling functions."  This is all sort of it gets involved with 32- and 64-bit code where the length of the pointer determines how far you're able to describe a relative jump.  And so if you're smart about packing where you need to go based on where you are, then if you need to go a shorter distance, you can use shorter pointers, and that ends up being faster.



So anyway, I dug into both of these new features to see whether there was anything that I could usefully report back to our listeners that would, like, fit in a podcast.  But they both involve such deep computer voodoo - and that's not doo-doo, that's voodoo - and machine-level architecture considerations, that after coming back up for air, the only thing I can meaningfully summarize is to say wow, I'm sure glad these guys are on our side, and that we get the benefit of their apparently endless amazing technology for free.  I mean, this browser, you know, the Chromium browsers, and of course Firefox is managing to keep pace, they just keep giving us more.



Since I couldn't just leave it at that, for anyone who is interested in how it could be possible - exactly following your immediate reaction, Leo - to still find another 23% to squeeze out of an already squeezed and resqueezed system, I have included links to the deeply technical articles I found in the V8.dev blog, which document and describe exactly what Sparkplug and short built-in calls accomplish, and how.  So they're on page 2 in the show notes, for anyone who is interested.  Again, I can't, like, get into it here.  But if you have an interest in how this could still happen, and maybe, for example, in the depths of code-on-the-fly JIT compilers and the tradeoff between optimizing more versus getting something done, rather than keeping the person waiting, it's all there.



We've talked previously about Chrome's decision to begin enhancing the URL field with commands.  And, you know, I'm not sure about this.  It's possible to type "delete history" into the URL, or "wipe cookies," or "edit credit card," or "update card info," or "launch incognito mode," or just type "incognito."  You can also enter "edit passwords," "update credentials," "update browser," like instead of going to About Chrome or Update Google Chrome.  I think maybe I should try just saying "update browser" next time and see if I can give it a little kick in the butt.  Anyway, I could have used either of those last two, like "update browser" or "update Google Chrome," before doing the About Chrome thing, if only I'd remembered.  Perhaps next time.



But that's also the trouble.  I mean, the reason I'm wondering about this whole approach, anyone who's used the command line, like someone who immediately opens Terminal in Linux, we already understand - and I know you do, Leo - the power of the command line.  It is arguably the most powerful way of getting things done.  But it assumes a certain level of commitment and memory and interest and expertise.  



LEO:  I don't think most people are ever going to do it.



STEVE:  No, no.  And meanwhile, as we know, the world has moved to multilevel nested discoverable menu systems.  That's what everybody wants is just, you know, let me click in here and browse around, see what my options are.  And then if there's an arrow that looks like I'm getting warm, let's go down that hole and see what's there.  So unless you are clearing cache or wiping cookies often, and perhaps you are, to me it seems unlikely that you're going to hold seldom-used URL bar commands in your head.



LEO:  Here's my guess.  This is for support.  This is so a support person can say, okay, type "delete history" in your command - although I have to say my experience has been, when I tell somebody to do something in the URL bar, they say, "What is that?"  I mean, they don't...  



STEVE:  Right, right.



LEO:  The address bar, they don't really know.  But if you can get over that hurdle, like there's a place where you type on the browser, type "delete history" on that, I think that's probably what they anticipate.  And then people like us maybe will remember it and use it.



STEVE:  I've told the story of my realtor, who is a very good friend, who didn't understand that the Internet was not "The Google."



LEO:  Right, right.



STEVE:  I mean, like she just - she asked questions of "The Google."  And when I tried to tell her once, go type in http:, she's like, "What?  Into the Google?"  Okay, Judy, okay.



LEO:  I've had that exact experience, yeah.



STEVE:  So in any event, the reason I bring all this up today is that the Chrome folks apparently think that they're really onto something with these URL commands.  So back at the beta level of Chrome - this is not in Chrome yet, but it's coming - you can now type, or will be, well, in beta you can, and soon the rest of us, if we care.  Get a load of this, Leo.  "Run Chrome safety check."



LEO:  Wow.



STEVE:  That's one.  Or "create doc."  You can actually type "create doc," which would immediately create a new doc in Google Docs, which, like, seems to be a stretch to me.  But okay.  Or "manage Google account."  So it's becoming like they're tying it in more tightly into Google services, which you access from the Chrome URL.  Which, again, it's like, uh...



LEO:  They're nerds.  They're just nerds, and they want to do it themselves, and that's crazy.



STEVE:  Though a more Google Account feature than a Chrome feature, I thought that our privacy-conscious listeners might also like to know that Google Accounts MyActivity monitoring page can now be password protected.  So if you go to - and this is the way we do now.  I guess you'll be able to go to Manage Google Account eventually.



But right now, myactivity.google.com/myactivity.  Okay, that's not easier, certainly.  But anyway, I went there last night.  And sure enough, I was immediately prompted with a "Safer with Google" balloon which gave me the option for the first time of password protecting the MyActivity page, which uses the link in the show notes.



So their whole point is that, if you're sharing a machine and sharing Google with some lookie-loos who might be poking around to see what you've been up to, maybe you'd like to password-protect the page.  Now, I don't think I've ever looked at MyActivity, though I know we've talked about this before.  But we're again on the topic.  And while we are, there are two other options to consider.  First of all, you can opt to have Google auto-delete your activity once it ages to either three months or 18 months or 36 months.  Or against the threat, which they caution you about, of receiving a less personalized web experience, you can instruct Google not to save any data at all, thank you very much.



And the last time I visited this page I apparently set it to auto-delete after 18 months, for some reason wanting to keep my personalized experience.  But in revisiting it yesterday for the podcast, I decided that I could live with a less personalized web experience, all things considered.  So I've instructed Google to delete everything and to no longer save anything.  I really wasn't worried about anyone seeing what I had previously been searching for, but it's nice to remember that Google is keeping all of that history unless you tell them not to.



So it may come as no surprise to anybody, but for anyone who doesn't know, you can go to your MyActivity page, and you can say, you know, forget after 90 days, or just maybe don't save it at all.  And at the risk of not having ads quite as closely tailored to you as Google seems to think they are, although I've really never really noticed the effect.



Okay.  As our main topic today, we'll be taking a close look at  Epsilon Red, a curious, for reasons that will become clear later, newly discovered breed of ransomware.  But something else is emerging from the ransomware ecosystem that's worth examining.  The other ransomware news of note, despite ongoing attacks here and there that don't really rise to the level of cataclysmic, was the news that New Zealand-based Emsisoft - whom we've referred to recently because they're very involved in ransomware.  I mean, they're security researchers.  They're good guys.  They've created their own independent ransomware decryption tool which, when it's provided with the master key from the attackers - you know, no doubt by way of the victim.



You know, the victim pays the ransom.  The attackers give the victim the decryption key.  Then, should you choose to do so as a victim, you don't have to use the attacker's possibly sketchy decryptor.  You can use Emsisoft's independent ransomware decryption tool, which is reputed to be safe and reliable and much faster.  It turns out that the decryptors are not very fast.  Emsisoft's tool is aware of the encryption employed by 50, five zero, different breeds of ransomware.  And it has the added benefit of not having been written by the same people who just finished attacking you, if you're the victim in the first place.  Instead, it was written by a reputable security firm.



This means that it's not necessary to take the added time as a victim to have this attacker-provided decryptor reverse engineered, analyzed, and validated to verify that it won't make an already bad situation worse.  And it turns out that that's something that responsible victims are having to do.  They get the decryptor, and then they find some security firm, and they say, uh, is this safe for us to run?  We'd like to get our data back, but we just got this from the bad guys, and we just paid them.  So what do we do?



So what's happening is that growing experience with attacker-provided decryptors shows first of all they are not all that reliable.  Some inadvertently mangle larger files.  They just don't deal with really huge files correctly.  And almost universally they decrypt far less quickly than they encrypt.  Now, I have no explanation for that, since the bulk data encryption that they would be doing would be by a symmetric cipher.  And a symmetric cipher should be symmetric, not only in its keying, but in its performance.



We do know that the bad guys will be motivated to get as much encryption done as quickly as possible since any discovery of their ongoing encrypting operation of course would result in plugs being pulled out of walls as quickly as possible in order to shut down the encryption of whatever it's discovered that they're doing.  So it certainly behooves the attackers to optimize their encryption speed wherever possible.  But as for decryption, it's easy to imagine that there's no big rush there.  They will have obtained their ransom payment.  They will have provided a functioning unlock master key and some piece of software which you can apply the key to which will decrypt your files.  So they probably feel they've met their obligation.  But their victim will still be offline and out of business until presumably all or most of certainly their most important machines have been decrypted, which all reports indicate can take quite some time.



But in both cases of the two high-profile attacks we've recently discussed - the first one of course against Colonial Pipeline and the second against HSE, remember that's Ireland's national public healthcare system - their respective decryptors, the first for the DarkSide ransomware and the second for the Conti ransomware, which we talked about last week, were too slow to be of use.  Colonial Pipeline, after paying $4.4 million in ransom, wound up restoring the bulk of their files from their own backups.  It wasn't clear whether they might have selectively decrypted some individual files that had been critically changed since those backups were made.



So an intelligent strategy might have been to restore everything from our own backups, because that we could trust completely, and then where necessary selectively decrypt files that were newer than those backups, which also had critical data, and then make sure that those are properly decrypted.  So maybe it was a hybrid strategy.  We do know that HSE, Ireland's national healthcare system, used Emsisoft's decryptor which ran at twice the speed of the decryptor provided by the Conti gang and was much more trustworthy.



So what I think we're going to begin to see is yet another component being added to this ecosystem, with faster and far more trustworthy file decryptors being sourced by trusted and well-known security firms.  For properly designed encryption, the master decryption key will still be required.  In other words, having that decryptor won't help you without the key.  But it certainly makes sense for the ransomware attackers maybe to even publish their file encryption formats which, thanks to the miracle of public key crypto, in no way weakens the encryption; right?  All of that can be published, and without the key it does you no good.  But doing so would serve to further mollify the victims and provide additional assurance of reliable file recovery which the bad guys, after all, are wanting to sell, essentially, as one of their services.



So don't be surprised if we don't see more of this.  Emsisoft appears to have a head start, but there's probably some additional revenue for reputable security firms to be making by saying, hey, we've got decryptors for these ransomware products.  Give us the key.  You can trust the product because we're good guys and we want to help you get your files back faster.



I saw some metrics.  In some cases the Emsisoft decryptor was three or four times faster.  And if you're talking about thousands of systems, and you're worried about the integrity of them, first of all you want the decryption not to fail, so you want the decryptor to work right.  And apparently they don't always.  Ryuk's decryptor is known to have problems on large files.  And you don't want it to take weeks to get back online if you've got lots of servers.  So time is money.



LEO:  That's what happened to Colonial Pipeline, I remember.  They paid the fine, got the - was it REvil?  Got the decryptor, and it was...



STEVE:  It was DarkSide.



LEO:  DarkSide, that's right.  It was so slow that they ended up just restoring from the backups and saying, oh, screw it.  We'll just move on.  How much do these guys charge, though, for their Emsisoft...



STEVE:  That's a good question.  I could not see anything there.  I would imagine it's something, but it's probably nothing like the ransom.  



LEO:  Yeah, but you already paid the ransom.  You already paid the 5 million, or 50 million.  It would be insult to injury to say, oh, and please, we need $5,000 for the Emsisoft decryptor.



STEVE:  So here's the problem.  Are you going to run the decryptor from the bad guys without...



LEO:  Yeah, you don't want to anyway, I'm sure, yeah.



STEVE:  Right, without paying someone to look at it.  So if you're going to pay someone to look at it, why not instead just pay to run a known safe decryptor?



LEO:  Exactly, yeah.



STEVE:  So I do think there is an aspect of economics there that really does...



LEO:  It's an interesting niche.



STEVE:  It is; isn't it?  It's weird.



LEO:  It just makes you say don't get it in the first place.  God.



STEVE:  Yeah, yeah.



LEO:  I know that's not always possible, obviously.



STEVE:  So my little own show notes title for this next piece was "Stepping Off the Sidewalk."  So it was our Security Now! Episode 796, which we recorded on December 8th of 2020, titled "Amazon Sidewalk."  It was the topic for the whole podcast.  And it presented our typical deep technical dive into the detailed design and operation of Amazon's announced and forthcoming Sidewalk offering.  And independent of the creepy feeling that some people get from the idea of enabling bidirectional sharing of heavily encrypted low-bandwidth Bluetooth and 900 MHz LoRa (capital L, lowercase o, capital R, lowercase a, radio) over the participating networks of those in close proximity, we concluded - as you reminded us, Leo, correctly - we concluded at the time that from a technology standpoint, Amazon appears to have done everything right.



Sidewalk is back in the news for us today because Amazon has announced that one week from today, next Tuesday, June 8th, the Sidewalk system goes live.  And as we discussed and expected at the time, it will be enabled by default for all those using compatible devices.  And that's been an issue of some controversy.  So unless individual users preempt its auto opt-in, their Echo speakers, their Ring video doorbells, their Ring floodlight cams and Ring spotlight cams, will be participating in this communal signaling network.  Predictably, the click-seeking tech press is jumping up and down in a froth over neighbors stealing our WiFi, which has nothing whatsoever to do with Sidewalk.  



LEO:  Yeah, I was a little disappointed.  Dan Goodin at Ars Technica...



STEVE:  Yes.



LEO:  ...acted as if...



STEVE:  Yes.



LEO:  I thought better of him, to be honest.



STEVE:  I did, too.  I didn't quite shed a tear, but I thought, oh, Dan.



LEO:  Yeah.



STEVE:  Yeah, he was very down on it.  And it has nothing to do with anyone sharing anybody's WiFi.  As we concluded in our careful analysis late last year, the system's total bandwidth usage is extremely low, only being useful for signaling-class applications, not big media streaming.  You can't do that over this.  Remember that LoRa, which is this low-bandwidth, long-range radio, it actually uses frequency chirps which are slow to do because you have to chirp the carrier.  The good news is it makes it high penetration because it prevents there from being any resonances with the carrier that would prevent the signal from going through.  But it means it doesn't have a high bit rate.  You can't do a chirp very quickly.



Okay.  So it is also quite thoroughly encrypted, in addition to being a signaling-class application, deeply encrypted.  So Amazon's intention here is clear.  They want the system to be adopted so they've designed themselves out of it.  Remember that even they can't see into it the way it's designed.  The upside of leaving this thing enabled is you get low-power roaming Bluetooth or LoRa devices able to access an unknown Amazon user's network over a triple-layered, deeply encrypted tunnel, which has - I think what we're going to see is many ultimately compelling use cases as this thing spreads.



And so, Leo, remember you and I were just talking last week about how once upon a time, if not most of us, well, probably most of us, if not all of us, were deliberately running with open unencrypted WiFi networks because we wanted to share our Internet connectivity with our neighbors.  It was considered, you know, a neighborly thing to do.  It's like, hey, why not?  Let's let people use it if they're in the area.  And today, of course, we no longer do that because we've learned that's not safe.



But allowing Amazon's Sidewalk to remain enabled is not the same as that at all.  The design, which we talked about at the end of 2020 - anybody can go back to Episode 796 and listen to the end of it again, if you want a refresher.  The design is clearly intended to absolutely prevent any possible abuse of the system.  A roaming wireless device that reaches out and connects to Sidewalk has zero access to the hosting network it's connecting through, just as the hosting network has zero access to the roaming device's data.  It was very well designed, and we know how to do this sort of thing now.



You could sort of think of it a little bit like a VPN tunnel that is, like, triple layer protected.  And recall from our previous discussion that not even Amazon, as I mentioned, has access to the Sidewalk data.  It is still encrypted.  Think of the Tor network and successive onion layer routing.  It's like that.  When Amazon gets it and forwards it to the service provider offering the service that the device at the other end wants access to, it's still encrypted when Amazon has it.  And it's only the service provider that is ultimately able to unwrap that inner layer of the onion in order to work directly with the device on a point-to-point basis.



So the hysterical press which talks about yet another intrusion into our privacy is really clueless on this.  And, you know, we're beginning to see this more and more.  These things are complicated.  The example we used last year was the Apple and Google initiative for have these two users been in proximity to each other.  It was like, oh, my god, the sky is falling.  Even though we looked at it, and it was well designed.



Okay.  So all that said, I fully understand that some of our listeners may be thinking, no way am I letting Amazon do this.  In that case it's absolutely possible to opt your own devices'  participation in Sidewalk out of the network.  Under Amazon's - can I say the word, the "A" word?  Anyway, we all know the word, A-L-E-X-A.  You go to More > Settings > Account Settings > Amazon Sidewalk, and you'll find an on/off toggle.  It'll be on until you turn it off.



LEO:  Yeah, that's what I think some people, it bothers them that Amazon, knowing that no one's ever going to turn it off, has it on by default.



STEVE:  Yes.



LEO:  But I think they also knew no one would turn it on if it were off by default.  



STEVE:  Correct.



LEO:  So why do you think Amazon's doing it?  That's the real question.  I think people don't trust Amazon, so they assume there's some nefarious intent.



STEVE:  I can't see any.  I really do imagine, if you had a low-energy tag around the neck of your pet, and it wandered off, like away, you would, I mean, how many times have we seen like lost dog and cat posters stapled to telephone poles?  That happens.



LEO:  And Tile, which was really concerned because Apple was going to eat its lunch with their AirTags, was able to use it, which at least gives it a chance to succeed.



STEVE:  Right.



LEO:  And I was trying to think, is it Amazon using it to track its delivery trucks?  But no, I don't think they need that.  Are they tracking delivery packages?  Well, in order to do that you'd have to put a fairly expensive device with a radio transmitter and receiver in the package.  You're not going to do that.



STEVE:  And, you know, I mean, maybe they've got some longer term game.  Remember that it's only the newer devices that have the LoRa.  So the whole system falls back to Bluetooth Low Energy unless you've got that newer 900 MHz radio.  And they've only been putting it into some of their Ring things recently.  So it's also going to take quite a while for this network to achieve critical mass.  But I think, you know, how about like an elderly person...



LEO:  Oh, yeah.



STEVE:  ...like "I have fallen; I can't get up."



LEO:  Happens all the time.



STEVE:  Or panic alarm.



LEO:  Or, you know, I get regular alerts from elderly people with various forms of dementia who've wandered off, and their family wants to know where they are.  You get a little bracelet or a necklace for them, and you will know.  And it's pretty accurate location, you think?  I mean, how...



STEVE:  Yes, yes.  Because even if it had access to multiple locations, it could do some...



LEO:  Triangulate, yeah.



STEVE:  ...signal strength triangulation, exactly.



LEO:  And it goes half a mile.  I mean, you only need an Echo device every half mile to have some connectivity.



STEVE:  And remember, Amazon did an experiment, I think it was in Seattle, where they let their employees take home a Ring.  And within, like, a month, there was no square inch that did not have LoRa coverage.  The entire...



LEO:  And that's what scares people, what you just said.  There's no square inch that is not covered by Amazon's special network.  I think there's a huge public benefit to this.



STEVE:  I do, too.



LEO:  And Dan Goodin's entire argument on Ars Technica is, well, you know how wireless protocols are often flawed.  Well, yeah.  But...



STEVE:  Yeah, have you updated Windows lately?



LEO:  The presumption that at some point somebody's going to hack it is what concerns him.  And of course that's possible.



STEVE:  Yeah.  So maybe they'll have to fix it.  Oh, darn.  That's been done before.



LEO:  Right.



STEVE:  By the way, when I turned my Windows 10 machine on to do the podcast, Leo, I had no icons on the desktop.  



LEO:  Oh.



STEVE:  They just - they all went away.  So I thought, uh, okay.  And that was a problem because I use one of the icons to instantly log into our Zoom session.  So I just thought, oh, let's just try rebooting.  And they came back.  So thank you.



LEO:  Windows at it again.  Well, now Edge has decided that it should remind me every time I use it, you really would like to have Bing as your search engine, wouldn't you?



STEVE:  Oh, are you getting that?



LEO:  No.



STEVE:  I know.  



LEO:  I don't want Bing.  No.



STEVE:  No, no.



LEO:  It's very annoying, I have to say.



STEVE:  Okay.  So I suppose that after the high-profile Colonial Pipeline attack and the HSE, you know, the Ireland attacks, the press is a bit keyed up for any news of cyber shenanigans.  Consequently, when Microsoft announced last Tuesday that another major attack had occurred, although there was really nothing particularly special about this one, the popular press jumped on it as if it was big news.  I listened to a number of non-technical newsy shows, and it was like, oh, my god, Microsoft announces 150 different organizations attacked.  It's like, okay, what?



So, okay.  So where did this come from?  Tom Burt, Microsoft's Corporate VP for Customer Security & Trust, triggered all this by writing:  "This week we observed cyberattacks by the threat actor Nobelium targeting government agencies, think tanks, consultants, and non-governmental organizations.  This wave of attacks targeted approximately 3,000 email accounts at more than 150 different organizations.  While organizations in the United States received the largest share of attacks, targeted victims span at least 24 countries.  At least a quarter of the targeted organizations were involved in international development, humanitarian, and human rights work.



Nobelium, originating from Russia, is the same actor behind the attacks on SolarWinds customers in 2020.  These attacks appear to be a continuation of multiple efforts by Nobelium to target government agencies involved" - I'm having a hard time keeping a straight face, but we'll get there - "involved in foreign policy as part of the intelligence-gathering efforts.  Nobelium launched this week's attacks by gaining access to the Constant Contact account of USAID."



Okay.  So, yeah.  This was a significant phishing attack enabled by the breach of a single mass mailing account at the mass mailing service, Constant Contact.  If USAID's account is compromised, as it was, then the result is pretty much guaranteed to be exactly what happened, and with exactly the demographic spread that we saw.  This wasn't in any way targeting those specific organizations.  The targets were entirely a function of the account that was compromised.  Now, okay, perhaps USAID was targeted.  That's possible.  But were this not tied back to the same group who were behind SolarWinds, though this bears zero resemblance to that amazing work, it would never have made the news.



And by the way, everybody has their own name for these guys.  Microsoft wants to call them Nobelium.  Okay.  But we know them better as APT29, sometimes as The Dukes, often as Cozy Bear.



LEO:  Oh, it's Cozy Bear.



STEVE:  It's Cozy Bear.



LEO:  I didn't know that.  Oh, okay.



STEVE:  Yes.  I know.  FireEye calls them...



LEO:  Can we just come up with one name for these clowns?



STEVE:  Yes.  Exactly my point.  Exactly.  FireEye calls them UNC2452.  Palo Alto Networks' Unit 42 refers to them as SolarStorm.  CrowdStrike calls them StellarParticle.  Volexity calls them Dark Halo, and Secureworks likes to call them Iron Ritual.  But, you know, it would be far less confusing if we could all just agree to call them, what, something.  Cozy Bear is fine.



LEO:  Cozy Bear is well known, yeah.



STEVE:  Yes.  Or APT29.  But no.  So as I said, otherwise this was just your run-of-the-mill email phishing attack.  The email sent to those individuals on the USAID mailing list contained an HTML attachment.  When the HTML was opened by the email's recipient, JavaScript in the HTML would write an ISO file to disk and then encourage its recipient to open it.  That would result in the ISO file being mounted, at which point an autorun shortcut link would auto execute a DLL contained in the ISO, which would in turn result in the Cobalt Strike Beacon being executed on the system.  In other words, yeah, don't click links in email.  Right?



LEO:  Oh, no.



STEVE:  Yeah.  But since it really did come from USAID and was likely convincing, thus spear phishing, some recipients might have opened the attachment and proceeded to get themselves infected.  Again, not good, but not any sort of high-level dastardly sophisticated attack reminiscent of SolarWinds.  If we wanted to blame anyone, blame Microsoft.  Why exactly is it that opening an attachment in an email can launch an HTML page... 



LEO:  Oh, good point.



STEVE:  ...that can run JavaScript, that can write an ISO file to our local machine's mass storage, and then mount the ISO and launch a DLL it contains?  How is that ever going to be a safe thing to let users do?



LEO:  Yeah.  Wow.



STEVE:  Ugh.  In any event, if you happen to hear about Microsoft warning of some huge new attack targeting 150, oh my god, different organizations, yes, those were 3,000 phishing emails sent to the addresses that were reachable from a breach of USAID's Constant Contact account and nothing more.  So, yeah.



LEO:  Okay.  All right.



STEVE:  We have another instance of, and I just - to me this is fascinating because I have no idea how this is going to settle out, the great encryption struggle.  India recently put in place new regulations that would require messaging apps, such as WhatsApp, to trace what they called the "first originator."  I don't know how that's different than the originator.  You can't have the second originator.



LEO:  The second originator.  That's a good point.



STEVE:  But okay.  First originator, maybe that's an English translation thing, of messages shared on the platform, thus breaking encryption protections.  Since India contains WhatsApp's largest user base by count, coming in at 530 million users, WhatsApp has sued the government of India - good luck with that - over their new Internet regulations.  A WhatsApp spokesperson said, very indignantly:  "Requiring messaging apps to 'trace' chats is the equivalent of asking us to keep a fingerprint of every single message sent on WhatsApp, which would break end-to-end encryption and fundamentally undermines people's right to privacy."  Now, remember who's speaking here; right?  They said:  "We have consistently joined civil society and experts around the world in opposing requirements that would violate the privacy of our users."



Okay.  Wait a minute.  Wasn't it WhatsApp that was changing their privacy agreement, in contravention of their original promise to never share data with their parent company Facebook, to now do exactly that?  And in doing so triggered a mass exodus from the WhatsApp platform, whereupon they quickly backpedaled?  Okay, yeah, well, in any event, India's new legislation reads:  "Significant social media intermediaries, which are defined as being platforms with 5 million or more registered users in India" - so, yeah, at what was it, 530 million?  WhatsApp qualifies as a significant social media intermediary.



They said:  "Providing services primarily in the nature of messaging shall enable identification of the first originator of the information that is required only for the purposes of prevention, detection, investigation, prosecution, or punishment" - in other words, pretty much anything we want - "of an offense related to sovereignty and integrity of India, the security of the State, friendly relations with foreign States" - in other words, if someone asks you who's generated that message.  Anyway, "...or public order or of incitement to an offense relating to the above or in relation with rape, sexually explicit material, or child sexual abuse material punishable with imprisonment for a term of not less than five years.  Intermediary shall not be required to disclose the contents of any message or any other information to the first originator."



Okay, now, the new legislation also requires the providers of qualifying messaging platforms, that is, pretty much anybody with at least 5 million users, to remove non-consensual sexually explicit material within 24 hours and appoint a resident grievance officer for acknowledging and addressing complaints from users and victims.  In other words, getting themselves involved in the content.  So this forms another step in the accumulating battle over encryption.  States are understandably demanding access to their citizens' communications for the prevention of abuse that is doubtless helped along by having unbreakable encryption.  WhatsApp is currently also doing battle with Brazil over their proposed legislation that would "force companies to add a permanent identity stamp to the private messages people send."



So in response to WhatsApp's legal challenge to India's new digital rules on grounds of violation of user privacy - and again, look who's talking - the Indian government last Wednesday said it is committed to the right to privacy of its citizens, but added that it's subject to "reasonable restrictions" and that "no fundamental right is absolute."  Unfortunately, mathematics is absolute.  You either do the best job possible you can to ensure privacy, and of course encryption makes that possible, and offer it as a compelling benefit of your service, or you don't.  So again, states are beginning to say no.  Companies are saying yes.  And who knows what's going to happen?  Wow, interesting.



I just wanted to mention to our listeners that after finishing Book #10 of The Frontiers Saga, Ryk Brown's 30-volume so far, or 30-novel sequence, and yes, it's my third reading, I'm a third of the way through...



LEO:  Wow, you love those books.



STEVE:  I really do.  They are just so much fun.  I just, you know, I was thinking about this.  It's very, for me, it's like  music.  People listen to music they like, even the same music they like, over and over.  And for me it's like that.  It's just a form of pleasure.  So anyway, Book 10 ended at a good pausing point.  And I thought, this is my opportunity.  So I've just cracked the cover of Andy Weir's "Hail Mary."



LEO:  Oh, good.



STEVE:  When I wrote the notes, my Kindle told me that I was at 10%.  But I got finished a little early today, and as I was waiting for MacBreak Weekly to wrap up, I moved to 14%.



LEO:  That's the weird thing about Kindle reading.  They don't do page numbers, for obvious reasons.



STEVE:  Yeah.  It's all resizable, yup.



LEO:  Yeah.  So they tell you a percent, which, you know, you can really tell a Kindle user because that's what they'll say.  Oh, yeah, I'm at 14%, not page 58 or chapter 2.  Although you could do chapters.



STEVE:  Well, I have a good buddy who wrote to me last night.  He said, "Have you started 'Hail Mary' yet?  I'm at 20%."  To your point, Leo.  And he said, "I think there's a physics problem that I want to discuss with you.  But," he says, "I don't want to be a spoiler, so when you get to..."  



LEO:  20%.



STEVE:  Oh, actually "When we know what the black things are," I think is what he said.



LEO:  Oh, okay.



STEVE:  So he said, "Then let's talk."  So he's at 20.  So by the time I have 6 more percent, that'll happen today, or later today...



LEO:  It's hard to put down.  It's a real page turner.



STEVE:  Yes.  I really like his writing style and his humor.  It's just right for me.  So I have no idea what's in store.  But anyway, I may be on the other side of the book by next week's podcast.



LEO:  Oh, I bet you will.  I'd be surprised if you're not, yeah.  Now, the guy who's doing all he can to eliminate ransomware, Mr. Steve Gibson.  Good luck.



STEVE:  Thank you, yes.  We will need it, collectively.



LEO:  Yes.



STEVE:  The security tech press has jumped on the news of another new player in the unfortunately burgeoning field of ransomware with headlines including, let's see, Sophos said:  "A New Ransomware Enters the Fray."  BleepingComputer:  "New Epsilon Red Ransomware Hunts Unpatched Microsoft Exchange Servers."  Silicon Angle:  "New Epsilon Red Ransomware Is Targeting Unpatched Microsoft Exchange Servers."  Heimdal Security:  "Epsilon Red Ransomware Goes After Unpatched Microsoft Exchange Servers."  And Security Week:  "Cybercriminals Target Companies With New Epsilon Red Ransomware."  Okay.  So...



LEO:  There he is.  Epsilon Red.



STEVE:  Yes, there he is.  Boy, you do not - looks like every tentacle has a different bad tool on it.  There's like a spinning saw blade and a pincher thing and a flamethrower.  Anyway...



LEO:  Watch out for the pincher thing, I've got to tell you.  That thing hurts.



STEVE:  Yeah.  His name, the name of the malicious group, comes from the Marvel universe.  Apparently it's a lesser known character, but it's named Epsilon Red.  And, interestingly, it's a Russian super soldier with four tentacles who can breathe in space.  Because you know that's handy.



LEO:  Oh, yeah.



STEVE:  If you're going to be in orbit, you don't want to mess with those pesky spacesuits.  And besides, the tentacles are really incompatible with wearing a spacesuit.  I'm not sure how you're going to do that with all those tentacles.



LEO:  You don't want to bring a chainsaw into the spacesuit.  That's always a bad idea.



STEVE:  No.  That's not going to turn out well.



LEO:  Yeah.



STEVE:  So what interested me about this was that Sophos encountered this new entry in the field several weeks ago and thoroughly took it apart, well, inasmuch as there was anything to be taken apart.  This thing, such as it is, is predominantly - get this, Leo - a collection of PowerShell scripts.  Which for me begged the question...



LEO:  What?



STEVE:  Yes.  It is mostly PowerShell.



LEO:  What?  Okay.



STEVE:  It begged the question, what explains this method of this thing's construction?  And upon reflection, if I were to give this ransomware a longer name, I'd call it Epsilon Red Cashing in on a Craze.



LEO:  Okay.



STEVE:  Sophos security researcher Andrew Brant phrased it in his report last Friday:  "A bare-bones ransomware offloads most of its functionality to a cache of PowerShell scripts."  He wrote:  "In the past week, Sophos analysts uncovered a new ransomware written in the Go programming language that calls itself" - so they didn't name it - "calls itself Epsilon Red."  In other words, yes, probably Russian and this lesser known super soldier with four tentacles.  "The malware was delivered as the final executable payload in a hand-controlled attack against a U.S.-based business" - which is unnamed in their report - "in the hospitality industry" - that's all we know - "in which every other earlier stage component was a PowerShell script."



Okay.  Now, based on the cryptocurrency address provided by the attackers, it appears that at least one of their victims paid a ransom of 4.29 bitcoin on May 15th, at the time valued at roughly $210,000.  Okay, so they made some money.  $210,000, that's not chicken scratch.  They wrote:  "While the name and the tooling were unique to this attacker" - so the name and the tooling, that is, the PowerShell, were unique to this attacker.  Here's what's interesting.  The ransom note left behind on infected computers closely resembles the note left behind by REvil ransomware, though it adds a few minor grammatical corrections.  There were no other obvious similarities between Epsilon Red and REvil.



Okay.  So I assume that Andrew is suggesting here that the purveyors of this new ransomware borrowed the ransomware note used by REvil, but otherwise wrote their own malware, such as it is, in PowerShell, from scratch.  So Andrew said:  "It appears that an enterprise Microsoft Exchange Server was the initial point of entry by the attackers into the enterprise network.  It isn't clear whether this was enabled by the ProxyLogon exploit" - which of course were the things that were patched in March - "or another vulnerability."  He wrote:  "but it seems likely that the root cause was an unpatched Exchange Server.  From that machine, the attackers used WMI" - Microsoft's Windows Management Instrumentation - "to install other software onto machines inside the network that they could reach from the Exchange Server."



He said:  "During the attack, the threat actors launched a series of PowerShell scripts, numbered 1.ps1 through 12.ps1, as well as some that were just named a single letter from the alphabet."  I think C and S, as I recall.  He said:  "That prepared the attacked machines for the final ransomware payload and ultimately delivered and initiated it."



He says:  "The PowerShell orchestration was itself created and triggered by a PowerShell script named RED.ps1 that was executed on the target machines using WMI," the Windows Management Instrumentation.  He said:  "The script retrieves and unpacks into the system32 folder a .7z archive that contains the rest of the PowerShell scripts, the ransomware executable, and another EXE.  It uses the machine's Task Scheduler to run scripts numbered 1 through 12, except for 7 and 8.  It also creates tasks for scripts named 'S' and 'C.'



"For example, when attackers ran the 2.ps1 script on a machine, it executed a command that deleted the Volume Shadow Copies from the computer."  He says:  "This is an important precursor to the attack, as these files could be used to recover some or all of the files encrypted by the attackers."  Right?  The Volume Shadow Copies is the way you roll back a Windows machine if doing something hurts it.  He says:  "A PowerShell script named c.ps1 appears to be a clone of an open source tool called Copy-VSS, part of a suite of penetration testing tools named Nishang. The Copy-VSS script permits an attacker to copy the SAM file, which an attacker could use to retrieve and crack passwords saved on the computer."



The PowerShell scripts also use a rudimentary form of obfuscation in which the threat actors appear to have added in some square braces and brackets at random into the script, thus breaking up the lines of PowerShell script code, and then use a command that later strips out what they had added.



"While this technique doesn't have much of an effect on our ability to analyze the files after the fact" - because of course you just ignore them - "it might be just good enough to evade detection of an anti-malware tool that's scanning the files on the hard drive for a few minutes, which is all the attackers really need."  Just a few minutes to get themselves going.  



"That red.ps1 script unpacks RED.7z into the %SYSTEM%\RED directory, then creates scheduled tasks that run the unpacked scripts.  But then it waits one hour and executes commands that modify the Windows Firewall rules such that the firewall blocks inbound connections on all TCP ports except Remote Desktop Protocol's 3389/tcp and [sadly] the communications port used by," he writes, "a commercial tool called Remote Utilities, which uses port 5650/tcp."



And as I've mentioned before, Remote Utilities is an excellent remote desktop management facility.  It's the one I've chosen for my own use.  Lorrie uses it, thanks to me, to remotely manage the laptops being used by her home neurofeedback clients.  And my tech support guy, Greg, who runs a computer consultancy on the side, uses it to manage hundreds of his client machines.  So it's wonderful, and it's annoying to see it abused like this.  But I suppose that's how Mozilla felt when their wonderful free Firefox Send turned out to be totally taken over by bad guys so that they had to end up taking it down.



Anyway, Andrew notes that, oddly, the port blocking does this by first blocking inbound traffic to ports 80 and 443, then redundantly blocks entire ranges of ports that include 80 and 43, but also exclude those two, the RDP and remote utility ports.  So it blocks 1 through 3388, 3390 through 5649, and  5651 through 65352.  So, okay, this just sort of seems - the whole thing seems like amateur league.



"Upon closer inspection," he says, "one of the first things the attackers did after gaining access to the target's network was to download and install a copy of Remote Utilities and the Tor Browser.  So," he writes, "this seems like a way to reassure themselves they will have an alternate foothold if the initial access point gets locked down."



Andrew then notes a few of the attractive features of Remote Utilities.  He writes:  "The commercial Remote Utilities software used by the criminals has several features they might find helpful."  Unfortunately.  "For one thing, they can use it for free.  Anyone can submit an email address through the company's website and receive a free license key by email that allows them to use the full capability of the product on up to 10 machines, in perpetuity.  The company's Viewer software includes the ability for a licensed user" - that is, licensed only to that degree - "to generate a digitally signed executable installer, preconfigured with a password and other preferences embedded into the EXE.  Users choose their options, which get transmitted back to the company via the application to generate a unique one-click package executable, digitally signed," which again will help it to pass through any AV tools that are on the lookout, which then downloads.



"The threat actor can then deploy this installer, which runs unattended, and automatically synchronizes to their Remote Utilities Viewer console."  And the Viewer console can also serve as a remote desktop client as an added convenience.  Anyway, as I said, Remote Utilities is terrifically cool and very functional, and it's annoying that these guys are using it for a malign purpose.  But that's the nature of all of these things.  They're also using our Windows machines for malign purpose.



He said:  "We found that the attackers had generated at least two of these one-click installer executables, which they downloaded to several machines on the target's network and ran.  The installer was named 'rut' [so remote utilities], rutserv.exe, and the attackers stored it in different filesystem locations on different machines they downloaded it to."  So trying to be a little more sneaky, apparently.



"Initially, the malware runs the scripts numbered 9 and 12.  This is followed by a 180-second delay, before then creating the tasks for 1 through 6, 10, 11, S, and C.  By default, the attackers extracted these files to a folder named RED under the %SYSTEM% path.  Each of these scripts accomplishes a specific task" - again, remember all PowerShell, so just readable, basically command macros - "accomplishes a specific task the threat actors used to prepare the system prior to launching the ransomware.  Many of these tasks involve hindering security or backup tools, but also involve disabling or killing processes that, if they were running, might prevent a complete encryption of the valuable data on the hard drive."



He said:  "It isn't clear whether the attackers were just being thorough, or if they weren't sure they could do what they set out to do, because in several cases the scripts issue redundant commands to accomplish the same goal."  I know, Leo.  It's just a...



LEO:  It's just classic crap coding.  Like say it again just in case.



STEVE:  Yeah.  It's a hodgepodge...



LEO:  A hodgepodge.



STEVE:  ...of different methods.  For instance, they say, 1.ps1 looks for processes that contain any of the following strings in their process name, and attempts to kill them.  And then we've got like just a mass of strings:  sql.  Sql with a capital Sql.  SQL all caps, you know, because they couldn't do a case-insensitive match, apparently.



LEO:  Didn't understand regular expressions, obviously.



STEVE:  Yes, yeah.  That would be, like, too much.  Cylance with a capital C and not.  Oh, here we have another instance of sql because they forgot they already did that first.  I know.  Backup.  Oh, here's V-E-E-A-M.  What do you know.



LEO:  Oh, yeah, Veeam's in there, yeah.  Oh, yeah.  They want to disable Veeam.  That's the first thing they want to do.



STEVE:  That's right.



LEO:  But it's in there twice or three times, I noted.



STEVE:  Oh, my lord.



LEO:  No, really, we don't want you to turn that one on; okay?



STEVE:  We got Outlook.  We got Word.  We got Excel.  Office, OneNote, Firefox, wordpa, isqlplusservice.  Oh, here's sql again, so that's now the third time they've done that.



LEO:  Ironically, the chat room's saying PowerShell is case insensitive.  So all of this is just silly, silliness.



STEVE:  Wow.  Winword, MS Access, PowerPoint, Wordpad.  Here we have VeeamAgent, so it's in there again.  Oh, SQL, all caps, for the second time.  Wow.  Yeah.



LEO:  Oh, my, it's funny.



STEVE:  So he says, and so Andrew says:  "These strings indicate the attackers are not only trying to shut down security tools, but also database services, backup programs, office applications, email clients, QuickBooks, and even Steam, the gaming platform."  Oh, yeah, Steam is in there in the middle.  Oh, and The Bat!.  Because, you know, that's a super popular email program.



LEO:  I use it.  I like it.  At least like the name.  That's funny.  Do they have the exclamation mark with The Bat?



STEVE:  Wow.  No.  Just The Bat.



LEO:  No?  Oh, they're going to have to add another entry.



STEVE:  Uh-oh.



LEO:  Uh-oh.



STEVE:  So that was 1.ps1.  2.ps1 deletes all the Volume Shadow Copies on the system by running a single command, "vssadmin.exe delete shadows /all /quiet," because, yeah, you don't want to echo anything anywhere.  3.ps1 disables automatic repairs that Windows might try to run upon a reboot.  And of course you wouldn't want to do this all like with one PowerShell script because - we don't know why.  4.ps1 then attempts to delete the Volume Shadow Copies using a different method.  WMIC, you know, Windows Management, shadowcopy delete /nointeractive.  Then we do a Get-WmiObject Win32 shadowcopy, piping it to a number of different expressions because why not.



5.ps1 executes two commands that, between them, delete Windows Event Logs, which would hinder an investigation.  Similarly to 1.ps1, 6.ps1 attempts to kill, not processes, but services, based, yes, on a list of strings that may appear in the services' names.  Guess what:  sql, Sql with a capital S, SQL all caps, and Titan, Cylance with and without a capital C, Defend, Veeam again, oh, also with a lowercase v and uppercase V.  Backup twice.  Oh, yeah.  Anyway, it also disables Windows Defender by setting the following Windows registry key.  So surprisingly, they apparently didn't give it its own PowerShell.  They just figured, oh, let's be a little fancy and do two things here in a single PowerShell file.  Wow.



9.ps1, which is executed first, attempts to invoke the Uninstaller for security software from Sophos, Trend Micro, Cylance, Malwarebytes, Sentinel One, Vipre, Webroot, and several cloud backup agents.  10.ps1 then redundantly runs the dropped p.exe executable, which suspends the processes that contain the following strings and clears their logs.  And this is a catchall.  Here's Veeam again, Outlook, Word, Excel, Office, I mean, Thunderbird, SyncTime, WinWord, MS Access, PowerPoint.  So I guess - oh, The Bat! is there again.  VeeamAgent.  Sophos.  VSS, you know, anyway, just a grab bag of things that, hey, let's stop this process if it's running.



11.ps1 adds yet another layer of redundancy, if that's what you want to call it, executing the following commands that delete Volume Shadow Copies - they really want to get rid of those - again, for the third time, as well as changing recovery options and clearing event logs in yet another way.  So I won't bother everybody with these, but another list of commands, a bunch of BCD edit things and so forth.  Anyway, this level of redundancy, they say, may be an indication that this threat actor is unsure of their own tool's capabilities, but aren't taking any chances.  Eh, why not?  We found this on the 'Net.  Let's run it.



12.ps1 grants the "Everyone" group access permissions to every drive letter that might exist on the machine to ensure as many files are encrypted as possible.  Whew.  The red.ps1 script also deletes itself, the .7z archive, and the local copy of 7-Zip from the system when it runs, removing that additional evidence.  In addition to the ransomware executable itself, Sophos recovered and analyzed another ancillary executable that the attackers deployed on the target machines.



The file, just called p.exe, appears to be a custom-compiled version of an open source tool called EventCleaner, which was created to erase and manipulate the contents of Windows event logs.  So again, no big custom single EXE that, like, takes responsibility and does this.  Instead, just sort of this weird hodgepodge of PowerShells and random small EXEs that each only do one thing, that they run a few times just to make sure that the last time they ran it, if it didn't finish or get everything cleaned, that maybe it would do it a next time.



We also mentioned that there were other PowerShell scripts delivered in that .7z archive the attackers dropped on the target machines.  Although they saw no evidence that they were executed in the context of the attack, the scripts numbered 7, 8, and 9 serve important purposes:  7 logs off practically all open sessions on the computer; 8.ps1 is a redundant copy of the same firewall rules script included in RED.ps1.  The ransomware itself, finally we get to that, is called RED.exe.  It's a 64-bit Windows executable written in the Go language, compiled using MinGW, and packed with a modified version of UPX.



The executable contains some code taken from an open source project called godirwalk, which is a Go program to do a walk of the directory system.  It gives it the ability to scan the hard drive on which it's running for directory paths and compile them into a list.  Get this.  The ransomware then spawns a new child process that encrypts each subfolder separately, which after a short length of time results in many copies of the ransomware process all running at once, contending for the limited resources of the machine.  So not the most efficient way to encrypt the thing.  The ransomware itself is quite small as it only really is used to perform the encryption of the files on the targeted system.  That is, it doesn't do anything else.  PowerShell scripts do the rest.  It makes no network connections.  And because functions like killing processes or deleting Volume Shadow Copies have been outsourced to the PowerShell scripts redundantly, that program, RED.exe, is very simple.



In the sample that Sophos saw, it doesn't even contain a list of targeted file types or file extensions, which all well-behaved ransomware do.  That is, you know, they encrypt the important things.  They don't bother encrypting EXEs and DLLs.  This thing will encrypt everything inside every folder it encrypts, including other executables and DLLs, which of course can render programs or the entire system nonfunctional, if the ransomware decides to encrypt the wrong folder path in the process of encrypting every file.  Then you end up with a dead machine.  And it adds the file suffix .epsilonred to the files and redundantly drops a ransom note in each folder because of course you have run a separate copy in every single folder.



And interestingly, the ransom note closely resembles, as I mentioned before, a shortened version of the note used by REvil.  But where the REvil note is riddled with spelling and grammatical errors, the note delivered by Epsilon Red has gone through a few rounds of edits, making its text more readable to an audience of native English speakers.  And the ransomware note is familiar.  It starts off with the same headline:  "What happened?" which is the question that REvil asks.  And then it says:  "Your files have been encrypted and currently unavailable."  So still not got English quite right, but better.  "You can check it.  All files in your system have Epsilon Red extension.  By the way, everything is possible to recover (restore), but you should follow our instructions.  Otherwise you can NEVER return your data."



Then:  "What are our guarantees?  It's just a business, and we care only about getting benefits.  If we don't meet our obligations, nobody will deal with us.  It doesn't hold our interest.  So you can check the ability to restore your files.  For this purpose you should come to talk to us.  We can decrypt one of your files for free.  That is our guarantee.  It doesn't metter" - M-E-T-T-E-R - "for us whether you cooperate with us or not."  Okay, I don't know what that means at all.



LEO:  It doesn't metter.  It does not metter.  Is not metter.  You do what you wish to do.  We don't care.  We make money either way.



STEVE:  "But if you don't, you'll lose your time and data 'cause only we have the private key."



LEO:  Only we.



STEVE:  Oh, I see, yes.  It doesn't matter whether you do it, though we really would like your money.



LEO:  You'll be sorry, but it's okay.  You don't have to worry about it.



STEVE:  They say:  "Time is much more valuable than money."  Okay.



LEO:  Except to us because money is everything to us.  We wrote many PowerShell scripts over many, many, many nights, yes. 



STEVE:  It took, yes, big ASCII editors.  Then they say:  "Data Leak."  They say:  "We uploaded your data, and if you don't contact with us, then we will publish your data."  And now, Leo, I'll just take a moment to mention there is no indication that any exfiltration was ever performed.  So...



LEO:  Oh, that's interesting.



STEVE:  Yes.  So...



LEO:  As great Comrade Nimzowitsch once said, the threat is greater than execution.  Is chess.  You would understand.



STEVE:  So get this.  Under "How to Contact," they say:  "You have two options.  Chat with me," so that's interesting.  "Chat with me.  Visit our website:  http://epsilons.red/" and then Sophos blacked this out.  "When you visit our website, put the following key into the input form.  Then start talk to me."  Option 2:  "Email me at," and then there was an address blacked out @protonmail.com.



Okay.  Now, note that Sophos discovered no indication that any of this hodgepodge of bits and pieces of PowerShell scripting or small single-function executables ever did any exfiltration of the victim's data.



LEO:  Wow.



STEVE:  Yeah, huh.  So given everything else we've seen...



LEO:  We also incompetent.



STEVE:  Yes.  And we borrow extortion letter from REvil because they're better with English.



LEO:  They are good writers, very good writers.  We love their prose.  Is good.



STEVE:  So given everything else we've seen about this concoction, it seems almost certain that no actual exfiltration of any kind was done.  After all, all that is is a threat; right?  They don't have to produce any plaintext.  They will just say they'll decrypt a file if they're given one.  So there's that.  They don't evidence having any infrastructure to back up either their threat or their victims' data.  And in order to engage with attackers, their victims are instructed to visit a specific page on a website located, not on the dark web, where all other ransomware sends its victims, but to a regular normal public Internet site at the domain Epsilons, plural for some reason, dot red.  Note that since this was written up, the Epsilons.red domain has disappeared.  No surprise there.  Wonder who could have, I mean, anybody could have taken it down.  It wasn't hidden.



So, you know, operating styles of this sort leave their own sort of fingerprint; right?  What do the facts in evidence suggest?  The encryption malware as described is bare bones, but it does get the job done.  It uses a publicly available directory recursion tool to build a list of directories.  Then it spawns individual instances of an encryptor for each discovered directory.  Each encryptor operates indiscriminately, without any file extension-based encryption filtering.  It simply encrypts the entire contents of every directory it's run in.



Does it even use a public key?  Maybe.  But it might simply use a static key.  In which case obtaining a copy of the encryption EXE, if you could undelete it from the hard drive where this was run on, this is a PowerShell-based approach, so it does delete it after the fact.  But that would allow for decryption without paying the ransom, potentially.  We've certainly seen many instances of lame ransomware whose analysis resulted in the creation of free decryptors in the past. 



And besides that one encryption EXE, everything else was either freely obtained and reused, or written as PowerShell scripts.  Being scripts, that saved them from issuing the commands by hand.  But it is certainly far lower tech than the ransomware systems that have come before.  And this certainly doesn't lend itself to an affiliate model.  You know, you can't sub this out.  This is just ridiculous.



So this guy used a public website for his extortion and cribbed much of the text of the ransom note being used by the REvil gang.  Taken as a whole, more than anything else, this has all the hallmarks of somebody in a hurry who's attempting to get into the diminishing pool of Exchange Server machines before they're all gone.  As we all know too well, it's trivial to locate Exchange servers and to penetrate any that haven't been patched since March.  But as I noted at the start, Sophos did track down the cryptocurrency address being used by these guys, or as seemed more likely, this person, since this feels like a one-man shop.  And they found that someone paid the equivalent of $210,000 to the address where this person was trying to collect money.  It would be very interesting to know whether the victim who paid that money ever got their files back.



The reason I'm curious is that this attacker didn't bother to set up a Tor hidden .onion site, and the exfiltrated data extortion threat has all the appearances of being empty.  So what else might be empty?  In our current environment of rampant and high-profile ransomware, it seems inevitable that there will be low-end attackers, probably like this guy, who trade on the reputation, such as it is, of high-end ransomware, which does go to some pains to assure the successful recovery of encrypted files because they want to maintain the reputation of, you know, their reputation as if you pay us the ransom, you actually will get your files back, and we won't leak them on the 'Net.  Any naive victim who doesn't know any better would have no way of discriminating whether they've been attacked by a - and I can't believe I'm saying this - "reputable ransomware attacker."



LEO:  You know. 



STEVE:  Yeah, one of the good ransomware attackers.



LEO:  One of the good guys, the well done ones, yeah.



STEVE:  Yeah, exactly.  Operating in good faith, who actually has developed the capability to restore encrypted systems versus this half-baked attacker who's trading on the public's knowledge that once ransoms are paid, it's actually possible to bring systems back online.  Yeah, if you get attacked by one of the good ransomwares, instead of this PowerShell nonsense.  Presumably, the attacker is able to decrypt a single file as proof of their ability to do so.  At least he does offer that in his ransom demand.  And since all files were encrypted indiscriminately, the affected systems probably no longer boot or run at all.  So each one would need to be booted using recovery media in order to gain access to the system's mass storage.  What a mess.



LEO:  Wow.  You have found a real gem in the annals of ransomware, I've got to tell you.  At least it's got a good logo.  And it's not the logo, that's just the character it's based on.



STEVE:  Yeah.



LEO:  It's got a good name.  Didn't even bother getting a logo yet.  That's how you could tell he's one of those amateurs.  All good malware has a logo.



STEVE:  That's right, yup.  Not Epsilon Red.



LEO:  So I can't wait to hear what your physicist friend says about that problem in - and I think I know what he's talking about.  You know, I asked Andy, because there are a lot of - there's a lot - he tried his best, of course, to make it scientifically accurate.



STEVE:  And it is, after all, fiction.



LEO:  It's fiction.  So there's a couple of things, yeah, that are a little bit made up.  But he, you know, I think was quite admirable in his, you know, his first book, "The Martian," was used in classrooms as science curriculum.  And I suspect he thinks the same thing might happen to this one.  And it's true.  I mean, if you gave people those problems and said, okay, how would you solve this, it'd be kind of fun.  Kind of interesting.



STEVE:  At least we know that, yes, well, especially the beginning with the string and, you know...



LEO:  Yeah, exactly; right?  There's a lot of that, yeah.



STEVE:  Yeah.  It was a lot of fun.



LEO:  Yeah, yeah.  I really enjoyed it.  I think he's great.  And you know I think he's back on form.  There's somebody in the chat room who is Canadian, so he insists that it's Emsisoft, not Emsisoft.  How the hell you'd know that, I don't know.



STEVE:  Okay.  Well, I - yeah.



LEO:  He's a Canadian.  He cares about these things.



STEVE:  So he would know about them in New Zealand?



LEO:  I have no idea.  I have no idea.  It's all in the Commonwealth, Steve.  They all bend a knee to the Queen.  That's what matters.  Steve Gibson will never bend a knee to bad guys.  He is the king, as far as we're concerned, our security guru.  You'll find his work at GRC.com.  That of course includes SpinRite, the world's best hard drive, sorry, mass storage recovery and maintenance utility because it works on all mass storage including SSDs, which is really good news because that's pretty much what everybody's, certainly what I'm using.  I haven't bought a spinning drive in a long time.  Except for my NAS, come to think of it.  SpinRite 6 is current.  6.1 is imminent.  If you buy 6 now, you'll get a free upgrade to 6.1.  But even more importantly, you'll get to participate in the development of 6.1.  That's at GRC.com.



Also there, of course, this show.  Steve has two unique formats of this show.  We both have the 64Kb audio.  I have video at the website TWiT.tv/sn.  He has, uniquely, 16Kb audio.  Do you have an ffmpeg script that you do this with?  Or you manually...



STEVE:  Actually, I still use Cool Edit.



LEO:  Cool Edit.



STEVE:  From the old days.



LEO:  You go, drop this down.  Okay.



STEVE:  Yeah, because I normalize the amplitude to 100%, which brings it up to full.  And then I scrunch it down by a factor of four.



LEO:  It sounds like Thomas Edison singing "Mary Has a Little Lamb."  But it is the smallest audio version of the show.  There's also a very small transcription of the show which is very handy if you like to read along as you listen, or just read along by itself, or use it for search.  Those are by the great Elaine Farris.  You can get that and the 16Kb and the 64Kb audio at GRC.com.  We have audio and video at TWiT.tv/sn.  You can download it there.



You can also, if you want, there's a YouTube channel.  In fact, if you go to that website, TWiT.tv/sn, there's a link to the YouTube channel, also a link to automatically subscribe in Google Podcasts, iTunes, and a variety of other podcast applications, plus an RSS URL that you can paste into Google Chrome and see what it does.  I don't think Chrome probably does RSS anymore, but other browsers maybe.  No, none of them do.  But paste it into a podcast app, and it should say, yeah, subscribe.  And you should say yeah.  And then you'll get it automatically.  If that podcast app does offer reviews, please leave Steve a five-star review.  He has earned it today, and every week works very hard to bring you the show.



We also have a free IRC, if you want to chat along while you're watching live at TWiT.tv/live.  That's irc.twit.tv.  After the fact, the conversation continues at our TWiT Forums, that's twit.community.  Steve has his own forums, as well.  What is that, GRC.com/forums?



STEVE:  Forums dot.



LEO:  Forums.grc.com.  Excellent.  And we also have a Mastodon instance which is like Twitter, minus the noise.  And that's at  TWiT.social.  Both of those are free to join.  We welcome your participation.  Steve, have a wonderful week.  Have fun with "Project Hail Mary."



STEVE:  I'm going to do that.  And we'll be back next week for Episode 822.  Yay.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#822

DATE:		June 8, 2021

TITLE:		Extrinsic Password Managers

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-822.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week I want to start off with a calm rant to summarize why today's computer security is so atrocious.  I think it's worth a bit of a reality check on that.  Then we're going to look at a new feature in Firefox and at Firefox's apparent jump in performance.  We'll touch on three new ransomware victims, look at what's been learned about how Colonial Pipeline was breached, and at the curious news that the FBI somehow managed to snatch all of DarkSide's bitcoins.  We'll look at the latest good and bad news regarding WordPress, and at GitHub's updated policy regarding posting proofs of concept for ongoing attacks.  I've finished Project Hail Mary, so I have a comment to make there, and I want to address the surprisingly controversial question of NAT versus IPv6.  Then we'll wrap up by examining the question of whether password managers should be intrinsic to our browsers or extrinsic.  I think we're going to have some fun.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with the great cybersecurity awakening of 2021.  He says solving ransomware, it's as easy as fixing your software.  We'll also talk about what happened to the bitcoin that was headed for the Colonial Pipeline hackers, and why Firefox is so much faster.  Plus a look at Tavis Ormandy of Google's suggestion that you stop using a password manager.  Really?  It's all coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 822, recorded Tuesday, June 8th, 2021:  Extrinsic Password Managers.



It's time for Security Now!, the show where we cover your security online, your privacy, your safety, and a little bit about how things work with this guy here who knows, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Just a little bit about how things work.  Often how they don't work, actually.



LEO:  Well, yeah, half the time.



STEVE:  On this podcast.



LEO:  You know, I noted that this is the 42nd anniversary of the release of the 8086.  And I thought I'd just mention that to you.



STEVE:  Ah, yeah.



LEO:  The beginning of the x86 architecture, which it turns out the designer never thought would last.  He said, "Had I known we'd still be using it 42 years later, I wouldn't have done segmented memory.  I wouldn't have done a lot of things."



STEVE:  It was, for its time, I think it was the right chip.  I mean, segmented memory, I'm in the middle of it now because everyone knows I'm in the process of working on the next SpinRite, and it's always used a segmented memory model.  And it is a pain from a - well, of course I'm writing it all in assembler, too, which doesn't help because I have to do all this by hand.



LEO:  You have to manage it, yeah.



STEVE:  Yeah.  But, I mean, it's a pain to deal with it.  But in terms of efficiency, if you assign objects to segments, then the segments become pointers to objects, and all of the pointers within the object are zero-based instead of being some random offset.



LEO:  Oh, so that's kind of cool.



STEVE:  It is.  It is.  There's a lot to be said for it, and a lot to be said actually for the x86, once you get to know it.  Someone posted somewhere, I saw it, like the 10 weirdest x86 instructions.  And, oh, there are some strange things.  I mean, where you've got to scratch your head and think, okay, if I had to use it, that instruction, what could I possible use it for?  I mean, they're a little bizarre.



But anyway, this is Episode 822 for June 8th.  And as you immediately grokked when you saw the title of this episode, "Extrinsic Password Managers," a whole bunch of our listeners regaled me with tweets and emails saying, "Hey, Tavis" - of course famous Tavis Ormandy of Google - "just talked about password managers, and he thinks they're bad.  So what do you think?"  And it's like, okay, we've got to talk about that.



But I want to start off with what I'm going to try to keep as a calm rant.



LEO:  Oh, boy.



STEVE:  I'm just going to try, I'm going to try to not let myself get worked up, although it really does kind of wind my spring, summarizing why today's computer security is so atrocious.  I think it's worth a bit of a reality check on that because it's so easy just to kind of take it for granted and go, oh, that's the way things are.  So I just, as a consequence of the past week, where I've been having to listen to all of the popular press talk about Colonial Pipeline and the meatpacking system and ransomware and, you know, how we're going to fix this, I just thought, okay, timeout.  So we're going to do that first.  And then I think we're going to take our second break.



Then we're going to look at a new feature in Firefox, at Firefox's apparent jump in performance, which I can't believe I'm experiencing to the degree I am.  We'll touch on three new ransomware victims, just naming them, I'm not going to spend time there; look at what's been learned about how Colonial Pipeline was breached; and at the curious news that the FBI somehow managed to snatch all of DarkSide's bitcoins.  I mean, there's been a lot of strange things going on the last week.



We'll look at the latest good and bad news regarding WordPress and at GitHub's updated policy regarding posting proofs of concept for ongoing attacks.  I finished the "Project Hail Mary" book, so I have a comment to make about it there.  Of course no spoilers.  And I want to address the surprisingly controversial question, which I stepped into unwittingly, of NAT versus IPv6.  Then we'll wrap up by examining the question of whether password managers should be intrinsic to our browsers or extrinsic.  I think we're going to have a lot of fun this week.  And of course we've got a great picture.



LEO:  Great topic, a lot of them.  And I have some thoughts on the password manager thing, as well, because I think Tavis is a security guru and so forth; but I think he's also, as is often the case with these people, a little bit of a purist in his point of view.  So I'm curious to see what you have to say about it, as well.



STEVE:  So our Picture of the Week is just - it's one from my archive that I get from our listeners.  It's six frames of a cartoon.  I got a kick out the fact that written vertically off down to the lower left it says "Giffs not jiffs."  



LEO:  I'm with you on that.  I'm with you.



STEVE:  Okay.  So the first frame we've got this guy sitting in front of his laptop, and he's thinking to himself, "Hmm, this article looks like it might be interesting."  So in the next frame he's showing a little bit of surprise.  He suddenly has eyebrows that are lifted, and clearly the screen is showing him, "Accept cookies?"  And so, yeah, okay, fine.  And then the next frame he's a little concerned.  One eyebrow has dropped, and he's looking at "Disable your adblocker," which he's being told to do.  Then the next frame, he's not looking happy now.  He's kind of got - both eyebrows are down, and it says, "Sign up for our newsletter!" in another dialog box.  And finally, in the second to the last frame he's like squinting and wincing because he's now been confronted with "Allow notifications from this site."  And in the final frame he's turned around, and he's walking away thinking, "*Pft!*  Not THAT interesting."



LEO:  Yeah, I've been there, done that.



STEVE:  Oh, my god, what we're all being confronted with these days is just, you know.  It was inevitable, Leo, the commercialization of what was once a fun playground for the techie nerds.  Now it's big business.



Okay.  So listening to the last week of the press talking about, I mean, like with no understanding of the ransomware problem, I just thought, okay.  I'm going to try to lump all of the problems into one relatively short presentation.  I titled it "The Great Cybersecurity Awakening of 2021."



LEO:  Yeah.



STEVE:  Because, you know, okay, it's good, right, that the rest of the world is where we've been.  We've been talking about this problem specifically, ransomware, for so long that I have repeatedly attempted to promise that I would stop talking about it.  But it just keeps coming up.



LEO:  Well, you can't now.  I mean, it's become the cause clbre in security.



STEVE:  Right.



LEO:  It's all anybody's talking about.



STEVE:  Well, and in fact last Monday Lorrie and I attended a small dinner gathering.  And as the resident computer security guy, I found myself attempting to explain why most of what we were hearing about how this or that group was going to be appointed or created to get to the bottom of this was wrong and impossible, but understandable because no one wants to hear or believe that there is no simple fix for this - or, more truthfully, no fix at all, simple or otherwise.  87.8% - this is where I'm trying to keep myself calm - 87.8% of the world's desktop and laptop machines are running an operating system which is so riddled with bugs that they needed to stop releasing them as they became ready, or no one would have been able to get any work done.



So now they're clumping them up into monthly releases of between 50 and 150, where every month a handful are rated critical, and patch first with highest priority, because those are known to be currently in use, compromising unwitting people every month, every single month, month after month, with no diminishment or apparent end.  And as we all know, Microsoft was informed of a horribly serious vulnerability in their Exchange Server product, in all of them forever through time, late last year.  Yet it took until March for them to produce a patch, which they then did a week before they were planning to as an emergency because they believed news of this oh so juicy latest in a never-ending line of vulnerabilities had somehow gotten loose.



And of course it's not just Microsoft.  Many of the largest players have now synchronized their monthly vulnerability patch release cycles to Microsoft's.  So a monthly patch fest has evolved because we are apparently unable to produce software without serious exploitable flaws.  And just last week, we noted how the latest ransomware, which was mostly just a handful of PowerShell scripts, was getting into people's computers when they clicked on a link in a perfectly authentic-looking and specifically targeted email that loaded and rendered an HTML page which contained and ran some JavaScript which secretly downloaded some malware and then politely explained to its user that they needed to click once more to open the document.  Whose fault is that, exactly?



Our email clients finally, but only after a long siege of exploitation, have started to actively refuse to have anything to do with executable content.  Thank goodness for that.  But of course there's a workaround.  Since we want the power and flexibility of having web apps, and since a web app might need to save something to our local computer, we've given JavaScript the ability to do so.  Repeat after me:  What could possibly go wrong? 



So now the bad guys bootstrap.  A benign-looking email loads up an HTML page containing a little hidden benign-looking bit of JavaScript.  And when given permission by its unwitting user, it  downloads the executable file on behalf of the email that was originally received.  How do we robustly solve that problem within the framework of computing that we've been making up as we go along?  I have no idea because though no one wants to hear it, all of our systems are fundamentally and deeply broken.  Why?  Because the economics are all wrong.  And those economics create perverse incentives.  We reward new features because those can be seen.  But security is invisible.  No one gets credit for making something more secure because you can't prove a negative.



Before the release of Windows XP, Microsoft's Steve Ballmer famously jumped around onstage declaring that XP would be the most secure operating system they had ever created.  History shows that it was the worst by far.  But Ballmer's assertion was unchallengeable at the time because, as we've often observed, true security is only proven over time when, as, and if that unprovable negative is gradually proven by never happening.  So how the heck do you reward that? 



So we have some problems which are due to errors appearing in systems that are so complex that we've become tangled up in our own code.  All we can do there is frantically patch and patch and patch all of the mistakes that we've made as we find them.  And separately, we have problems like the email to JavaScript malware download bypass which arise from the abuse of the deliberate design of our systems.  It's not a bug, it's a feature.  Yet it's costing companies many millions of dollars in lost revenue, lost reputation, and ransom payments.  Everyone wants to assign blame somewhere.  Out of sheer desperation, enterprises are now sending their own employees baited emails, trying to trick them into clicking on a link that they shouldn't in order to pounce on them.  Aha, your prior training has apparently worn off.  Back to the reeducation camp with you.



What is wrong with us that we are now blaming the user for behaving in a perfectly normal and understandable fashion by responding to an email that appears to be in every way perfectly legitimate?  We would like to shoot the messenger, but we can't find them.  So we're going to shoot the recipient instead.  We have to shoot somebody, apparently.



As for features versus bugs, we were once assured that Windows 10 would be the last Windows ever.  Someone somewhere decided that change was bad for security.  And they were right, of course.  Now we hear rumors of Windows 11.  Oh, joy.  That's what we need.  Apparently Windows is going to get lovely rounded corners for its rectangles to distract us from the minor detail that all of our desktop's icons have just disappeared.  We're all so terrified now to click a link in an email that perhaps not having those sharp pointy corners will calm us down a bit.



During that dinner party, where everyone lost their appetite and stopped eating, I pointed at an AC wall plug that's controlled by a cloud-based service.  I explained that the plug was connected back to servers in China, and that the software running inside that itty-bitty computer contained in the plug was known to have a handful of remotely exploitable vulnerabilities such that, if at any point someone in China wished to infiltrate the house's network to snoop around, it could be done.



And I noted that the exploitation of a vulnerability in the plug's firmware would only be necessary if the plug had not come preloaded with a deliberate backdoor, which would simply open when asked to allow foreign access.  How would we know?  There's no certification process.  There's no qualification process.  We click "Buy Now" on Amazon, and that little miracle is on our front doorstep the next day.  It may have a UL Seal of Approval to attest that we won't be electrocuted when we plug it in, but that does nothing to regulate the foreign packets that flow right back from our household's internal networks to China, a country with whom the U.S. has a very complex relationship.  Today, we are frantically deploying millions, if not billions, of Internet of Things devices throughout our lives because they are shiny, incredibly inexpensive, and do neat stuff.  But there's zero oversight anywhere in the design, implementation, and delivery of these devices.  They're cute little time bombs just waiting to go off.



Accountability is another problem in the computer industry.  If your car's brakes fail unexpectedly, or its wheels fall off when you take a corner, there are consequences for its manufacturer.  They're accountable.  Software companies are not.  There are no consequences for Microsoft when they wait three months before patching a horrific vulnerability that had been demonstrated to them, the exploitation of which has without any doubt been incredibly expensive for their users.  But not for Microsoft.  Microsoft requires everyone touching its obviously defective software to explicitly waive all expectations of their software's performance or fitness.  It's in every license agreement.  They say it may work; it may not.  We don't know, either.  But either way, the risk is all yours because we did our best, and everyone knows that software, despite its name, is hard. 



So what have the natural consequences of all this wrought?  We have insecure hardware, processors, and memory running insecurely designed software, written in insecure languages, implementing insecure protocols and APIs, by people who require no formal training or certifications of any kind to create any of this.  It's a black box in a black box in a black box.  But it's also one other thing that we apparently prize more than anything and everything else.  It is astonishingly inexpensive.  That Chinese wall plug has been working flawlessly for a year, and it cost $5.  I love it.



You can now purchase a breathtakingly powerful and useful laptop with a free Windows operating system, soon to have rounded corners, for a few hundred dollars.  And storage, oh my god.  And what operating system am I sitting in front of right now as I write this?  Yes, the same, 87.8% of the world, Windows.  I'm completely satisfied with it.  It works great.  Overall, what it manages to do is a miracle.  Okay, so yes, last week when I fired it up, actually the Win10 box, to record this podcast, all of the icons had disappeared from the desktop.  I waited a while to see whether they would reappear by themselves, and when they didn't, I rebooted.  Now they're back.



Since most people have a very limited understanding of how their own bodies work, we rely upon highly trained medical professionals who have obtained extra education and certification.  The system was designed to remove all possible sources of error.  So the resulting medical care is astonishing.  It can also be astonishingly expensive.  And no one who has not been trained in the law should attempt to write a complex legally binding contract.  But sometimes we need one.  So we train up attorneys in the law.  We require them to prove that they know how to write properly complex contracts by passing the bar.  But now that contract will really cost you.  But software, which may have been written by someone in his mother's basement, hey, it's free.  And it's worth what you pay for it.



So throughout this little rant, I've attempted to touch on a number of points.  Looping back to the original issue, all of a sudden people are saying that now they want security.  But that ship has sailed, and it sunk.  Much as we might wish we could, we can't just dust off Steve Ballmer and have him jump around onstage to declare today's problem solved.  You can't slap a fresh coat of paint on top of the rickety and flaky computer systems and technology we have collectively and deliberately built, placing features before security, and expect to suddenly have any actual security.  And more importantly, no one, no one would actually be willing to pay the cost to obtain true security, even if we knew how.  And there's no reason to believe we do.  The systems we have are not secure, and at this rate  they're never going to be.  But my god, are they inexpensive.  And soon they're going to have really nice rounded corners.



LEO:  I wonder if it's possible, though, I mean, if you started from scratch, to design a secure operating system.  Aren't hackers so determined, and there's so much money to be made in exploiting them, is it possible to have secure software?



STEVE:  I would say it's possible to have secure software that doesn't do much.



LEO:  Okay, that's fair.  Yeah, yeah.  But a general purpose operating system, could you do that?



STEVE:  Yes.  Well, for example, the original iPhone, the problem was...



LEO:  Didn't do much.



STEVE:  ...it didn't do much.



LEO:  Didn't even have cut and paste.



STEVE:  No.  You had - the home screen wasn't even full.  It looked like there were things missing because there were only icons kind of in the upper half and half of the last line.  And you were looking at it thinking, okay.  I thought Jobs was a real pain to work with.  How did he let this out of the barn?  And so, but damn, it was secure because it was all from one place, and it didn't do much.  My example of the malware downloaded when you click email, the problem is we want web apps which are able to save files on our computer.  It wouldn't be much use if you could look at it, but you couldn't get at it.  It's like, wow, this document looks great.  Wish I could do something with it.



LEO:  Right.



STEVE:  And that's the problem is that we breach the sandbox of the web browser deliberately because we want the feature of allowing a document to be downloaded to our desktop.  And so a properly, a cleverly designed bit of JavaScript convinces a perfectly normal, sane, you know, this poor employee has been through several rounds of security awareness training, and they get an email from their boss from Panama, who happens to be in Panama right now, saying, "Hey, Sally, following up on what I asked you to do, here's the report you've been waiting for." Which is probably exactly what Sally's been waiting for.  So she says, "Oh, good," and clicks the button.  And now she's just infected her entire company with laterally spreading ransomware and the screen goes black.  We see it in movies all the time.  Unfortunately, these chickens have come home to roost.



And so the real thing that has happened is that, as you say, Leo, because of the incentive, which crypto currency leveraged with ransomware has created, I've long been talking about security as porous; right?  It isn't perfect.  The harder you press on it, if you press hard enough, you will squeeze some data through a surface that's trying to resist that.  It's the reality of what we have today.  And so, yeah, if we were happy with the original iPhone and its half screen full of icons, that's a secure thing.  But you can't do much with it.  You can't do what you want to.  Same thing for web apps.  If they can't touch the computer, then they're not that useful.



LEO:  So, I mean, somebody asked on the radio show this weekend, well, what do we do about all this?  And I pointed out that security is layered.  There's no one layer that's going to fix all of this.  Certainly we could make more secure operating systems.  I don't think we'd ever make a perfect operating system.  If you're going to connect to the Internet, you're going to have an attack surface.



STEVE:  And Leo, remember that Windows was never meant for the Internet.



LEO:  Right.



STEVE:  It was meant for a modem.



LEO:  Why is why, by the way, our mobile operating systems are more secure, because they knew those would be under attack.  So they are marginally more secure.  In fact, I think actually you can make a pretty good case that iOS is - there's malware out there, but it's fairly secure.



STEVE:  Yes.



LEO:  So I guess it's possible to make something more secure if you really give your mind to it.  And then of course companies need to do a better job of training employees.  They need to do a better job of defending their own perimeter.  There's a lot of things companies can do.  Governments need to do a better job of putting pressure on rogue states to knock it off.  It's kind of a mess.  But I think that it's going to take a lot of different efforts in a lot of different arenas to fix this.  It's no one thing.  You're right, I mean, Windows is horrific.



STEVE:  Well, and the other gotcha with security is it is the classic chain; right?  The weakest link in the chain.



LEO:  Right, that's right.



STEVE:  To have security, every single link in a chain of 100 links - which 100 different groups and organizations and people all contributed their own link to, saying, oh, yeah, yeah, my link is really secure, don't worry about it - every single link has to be secure because, as you said, there's now a tremendous incentive to find the weak one.  And you just pull hard enough on both ends, and that chain will find the weak link for you.



LEO:  Yeah.  So is there any hope?  Or is it just going to continue to get worse and worse and worse?



STEVE:  I really do think that three digits is not enough numbering for this podcast.



LEO:  I've been saying that for a while, Steve.  I just want you to know.  You can't stop.



STEVE:  We're at 822, and time is running out.



LEO:  Yeah.  I don't think we're going to fix anything by 999, that's for sure.



STEVE:  I don't think so.  I'll do a little bit more news before we take our second break.  Firefox will soon auto-update on Windows, even when it's not running, which I thought was interesting.  This new feature will be in, well, it is in the Firefox 90 beta.  Everyone is now running on 89.  So the next major release should bring, when 90 goes to mainstream, we ought to all have that.  Kirk Steuber, who's Mozilla's Platform Engineer, said:  "Until now, Firefox has only downloaded and installed updates when the user runs it."  And in my experience, not even then.  You've got to go poke it.  You've got to go do About Firefox, and it goes, oh, hold on a second, and then spins its little widget for a while, and then lets you restart it.



He says:  "This means that users who only use Firefox infrequently may well be out-of-date.  It also means that if they open Firefox again in response to a Firefox marketing campaign" - like to see some new feature - "they may not immediately get the features which have been advertised."  So he says:  "Background Update aims to address this problem by allowing updates to be downloaded and installed, even when the user is not running Firefox."



So by default there will be a ping which looks for an update every seven hours, when the browser's not running, to check for new updates.  I thought that was interesting.  Had it been eight, then it would fall on the same three hours every 24-hour cycle.  But seven being odd and prime and not a multiple of 24, it means that it's going to kind of be roaming around, and probably everybody's browser will be doing it at different times, so that's kind of cool.  Anyway, so every seven hours it'll check to see if there's anything new.  And if so, it will get it.  It also installs a little service, I think I had it here somewhere - oh, the Mozilla Update Service - to bypass the Windows User Account Control since services are able to run with system privileges.  And this allows it to get the data from Mozilla in the background to update itself.



So anyone who wants to disable this, if you don't like it, you can go to about:preferences, look for updates, and then fuss with the UI which is presented there.  And for the time being this only applies to Windows.  They've announced no intention to do this either for macOS or Linux.  So Firefox will be getting background updates by default with its next major release.  And as I mentioned before, speaking of Firefox, my podcast prep workflow is to assemble a bunch of - basically assemble a collection of many stories of the week from a number of different sources.  And I build them in Firefox using its left-hand vertical column of tabs which, you know, it doesn't have natively, but I use tree-style tabs.  Then I open Chrome to edit the show notes in a Chrome Doc, and that's what produces the PDF every week.  I also open the little desktop outliner that I've been using ever since the Palm Pilot because it had a desktop version where I do most of the writing.



So I'm bouncing around among all three tools.  And yesterday evening, after updating the instance of Firefox to 89, which as I said, it didn't do by itself, but I looked, and it says, oh, yeah, hold on a sec.  And this is the one that we talked about last week, and you got it while we were on the air, Leo, where the UI got kind of cleaned up and polished.



LEO:  Mm-hmm, mm-hmm.



STEVE:  I am consistently noting that it is running far faster than it ever has.  I mean, I wasn't expecting it to.  I didn't think about it.  But I'm so used to this workflow that as I was just, like, clicking on tabs and deleting them as I was covering topics, it was just like, wow.  This is a lot faster.  And we know that what it did was it broke everything down in individual processes, so that may be part of it.  But I'm just saying, for what it's worth, if you haven't looked at Firefox in a while, after you start it, let it settle down, then go into About Firefox to give it a little kick in the butt to make sure that you get 89, and see what you think because, I mean, I'm very impressed with how much, I mean, it's viscerally faster.



Again, I wasn't looking for a speed increase.  And it wasn't even the first time I noticed it.  It wasn't until the third or fourth time that it just did something instantly that I was used to, like, waiting for.  And it's like, wow, this is getting faster.  So, very cool.



Also, Edge is taking its own approach to HTTPS switching.  As we know, Google's Chrome now finally defaults to HTTPS when given a so-called "schemeless" URL, like TWiT.tv, GRC.com.  And Firefox has also added an HTTPS-only mode designed to secure web browsing by rewriting URLs to use the HTTPS protocol.  At the moment, in the case of Firefox, it's still disabled by default. Google had been performing experiments before they went with it, and they now have.  But hopefully Mozilla will catch up.  Until then, for Firefox, it can be enabled from the browser settings.  But of course it's not our listeners who would be enabling it who are the most endangered by it not being on yet by default.  It's everybody else.



In the case of Edge, here's what Microsoft has done.  They've kind of gone their own way.  They say:  "Starting with Microsoft Edge 92, users can preview the Automatic HTTPS" - which is their name for it, Automatic with a capital A, HTTPS - "feature, which automatically switches your connections to websites from HTTP to HTTPS."  They said:  "When sites are loaded over HTTP" - and this we all know, but there's a little bit in here, that's good, to set the context - "attackers can view or change page content in transit, or redirect you to a different location than you expected.



"Most websites now support HTTPS, which can help protect against these man-in-the-middle attacks.  However, too many of these sites aren't configured to require HTTPS, leaving open a short window of opportunity for attackers before the site can redirect to the more secure protocol.  Some sites may not redirect visits from HTTP to HTTPS at all, leaving some visitors with a less secure connection.  To help protect your information as you browse, we are introducing a feature called Automatic HTTPS" - oh my god, yes, you're the last to do it, but good - "now available for preview in Canary and Developer channels with Microsoft Edge 92.



"Automatic HTTPS switches" - here's the curious part - "switches your connections to websites from HTTP to HTTPS on sites that are highly likely" - what? - "to support the more secure protocol.  The list of HTTPS-capable websites is based on Microsoft's analysis of the web, and helps enable a more secure connection on hundreds of thousands of top domains.  Automatic HTTPS upgrades" - thank god they didn't try to put a trademark on that - "upgrades your connection only on HTTPS-capable domains by default in order to prevent connection errors and potential performance issues."



So, okay.  Now, as we know, many sites like GRC and TWiT have been publishing a strict transport security header for some time.  I've got a max age of one year.  It's 31536000, probably seconds, which I'm saying after a browser encounters that from my server it can sticky remember that for one year.  TWiT's max age is better, Leo.  Yours is 604800000...



LEO:  How long is that?



STEVE:  ...which is almost two years.



LEO:  Wow.



STEVE:  And that's actually - that means that you did it more recently.  It used to be that one year was the maximum, back in the beginning when I implemented it.  Your guys waited longer and so are more current because it now should be longer.  So I'm going to have to update mine.  I learned all this this morning.  It's like, hey, TWiT's got it right.



LEO:  Well, we switched later than most because we switched only when we had to.



STEVE:  Right.



LEO:  But credit Patrick Delahanty for doing it right, and maybe Russell had something to do with it, too.  But, yeah, they know what they're doing.  They're good.  We have good engineering.



STEVE:  So Microsoft says:  "This protocol switch process happens automatically and without intrusive notifications, so that you don't have to think about your connection to websites.  Simply browse as usual.  If you'd like even tighter security and don't mind potentially encountering connection errors more frequently, you can in Edge opt to switch all navigations from HTTP to HTTPS using the toggle at edge://settings/privacy."  And they said:  "If you want to test it right now, you have to open edge://settings/privacy and turn on 'Automatically switch to more secure connections with Automatic HTTPS.'"  And so forth.



So anyway, they're catching up.  In a couple releases, as soon as it gets out to the main channel, it'll be available.  They've sort of taken the cautious approach of doing something, I mean, probably they've, you know, they've got Bing; right?  So they're spidering the 'Net.  And from all of the servers like mine and TWiT's, they're seeing our formal declaration that, yes, we will absolutely be supporting TLS from now until a year or two from when you ask.  So that's probably what they've done is they've just basically incorporated that information.  Maybe they've done offline tests of both to see, although that could be a little sketchy because it's not necessary for a site to be completely orthogonal in its support for HTTP and HTTPS.



Once upon a time we were all only selectively supporting HTTPS during, like, secure events, and then dropping our users back to HTTP because that's what everybody did.  And you were supposed to be able to do that.  Well, fortunately we know those days were not really as secure as we were hoping they were, and they are long gone.  So anyway, Edge is joining the rest of the group, a little bit with their own flavor, but they'll be getting it right.



I promise to keep the enumeration of new ransomware victims short.  So I'll just note that Fujifilm acknowledged last Wednesday that it had been hit by a ransomware attack.  It's believed to have been launched by the QBot Trojan, who have recently teamed up with the REvil group.  So the Qbot Trojan gets in and basically hands over access to the REvil group to perform their ransomware attack.  The Massachusetts Steamship Authority, which is Massachusetts' largest ferry service, was hit by a ransomware attack, also last Wednesday, which led to ticketing and reservation disruptions.



And the University of Florida Health, also known as UF Health, is a healthcare network of hospitals and physician practices that provide care to counties throughout Florida.  They suffered a ransomware attack that forced two of their hospitals to shut down portions of their IT network.  So they're back to using pen or pencil and paper until their systems are restored.  So yes, amid all of the fur flying and outrage about the Colonial Pipeline attack and the fact that we can't get hamburgers anymore, the ransomware attacks just keep on happening.



We believe that we know how Colonial Pipeline was breached.  Bloomberg reported on Friday some of the findings by Mandiant, which is the group within FireEye who has been working with Colonial Pipeline to figure out how this happened.  As always, attribution and post-attack forensics is difficult.  But there's very strong evidence to support the theory that the attackers used a compromised VPN account password.  Yup.



LEO:  It was just like the Florida water plant.  They were all using the same password.



STEVE:  Yup.



LEO:  And the account was no longer active, but it was still usable.



STEVE:  Right.



LEO:  Ridiculous.



STEVE:  I know.



LEO:  No two-factor.  Ridiculous.



STEVE:  The VPN login in question, which lacked any multifactor authentication protection, was not in use, but it had been left active, and it was at the time of the attack.  The account's password was discovered inside a batch of leaked passwords on the dark web.



LEO:  And you know why that was.  Oh, go ahead, I'll let you finish the sentence, yup.



STEVE:  This suggests that an employee of the company may have reused that same password on another account that was previously breached.



LEO:  So Colonial was not requiring password managers.  They were letting employees set their own passwords, monkey123.  Oh, I use it on everything.  It's easy to remember.  Unbelievable.  Unbelievable.



STEVE:  So the takeaways are a little late.  And it's always easy to admonish with "I told you so" after the fact.  But unused accounts should always be disabled.  Authentication should require multiple factors.  And I suppose that, while I've never been a fan of forced password changing, so long as the new passwords are unique and not shared, forcing a change might have prevented this entire mess.



I was recently informed that my logon to the management portal for Level 3 would be expiring, since I had not logged into it in six months.  Okay, that's annoying, but it's good policy.  And for things that are mission critical, like remote VPN access into a corporate network, the pain is clearly worth the gain.  So, yeah.  The one good thing that will arise from this attention, this is not unwanted attention.  This is good attention that the world is now paying to this because, as we've often talked about, the CIOs, the Chief Information Officers, have been running around the C-suite executives, screaming about needing more, more, more.  We need more budget.  We need more closet space.  We need, you know, whatever it is.  They are resource constrained.  We need to replace this crap which is 20 years old because we can't - and the bosses, "Well, it works, don't it?"



LEO:  It works.  Till it doesn't.



STEVE:  Exactly.  It works until nothing suddenly does.



LEO:  And this was the IT department that was hacked.  So surely they should have done better.



STEVE:  Again, the beauty of the press is that when the executives go home, their wives are now asking them, "Honey?"  Things that never occurred to them to ask.  You know, "What's the budget for your company's security?  Because, you know, I would really hate if Mabel at the club was able to scold me for your company being attacked."



LEO:  Just put plastic bags of gasoline in their trunk.



STEVE:  Exactly.



LEO:  Which should never have to happen.



STEVE:  Okay.  So we got the word also that the FBI has struck back, which begs the question, "How, exactly?" 



LEO:  Yeah, no kidding.  I would love to know how.



STEVE:  Yesterday's press from the U.S. Department of Justice was victoriously titled "Department of Justice Seizes $2.3 Million in Cryptocurrency Paid to the Ransomware Extortionists DarkSide."  Now, okay.  I've excerpted the interesting new parts, removing the remedial "What is ransomware?" bits.  But here's what they said:  "WASHINGTON - The Department of Justice today announced that it has seized 63.7 bitcoins currently valued at approximately $2.3 million.  These funds allegedly represent the proceeds of a May 8th ransom payment to individuals in a group known as DarkSide, which had targeted Colonial Pipeline, resulting in critical infrastructure being taken out of operation.  The seizure warrant was authorized earlier today by the Honorable Laurel Beeler, U.S. Magistrate Judge for the Northern District of California."



Okay, so now everybody's got to get their two cents' worth in.  So we have Deputy Attorney General Lisa O. Monaco for the U.S. Department of Justice said:  "Following the money remains one of the most basic, yet powerful tools we have.  Ransom payments are the fuel that propels the digital extortion engine, and today's announcement demonstrates that the United States will use all available tools to make these attacks more costly and less profitable for criminal enterprises.  We will continue to target the entire ransomware ecosystem to disrupt and deter these attacks.  Today's announcements also demonstrate the value of early notification to law enforcement."  Let us know.  They said:  "We thank Colonial Pipeline for quickly notifying the FBI when they learned that they were targeted by DarkSide."



So now we have the FBI's Deputy Director Paul Abbate added:  "There is no place beyond the reach of the FBI..."



LEO:  Oh, please.



STEVE:  I know, I know, you can run, but you can't hide - "...to conceal illicit funds that will prevent us from imposing risk and consequences upon malicious cyber actors.  We will continue to use all of our available resources and leverage our domestic and" - I can hear the music in the background - "our domestic and international partnerships..."



LEO:  [Vocalizing].  Oh, no, that's "Get Smart," never mind.



STEVE:  Yeah, good, "...to disrupt ransomware attacks and protect our private sector partners and the American children."  Oh, sorry, the American public.  I got confused.



LEO:  Well, the children, too.



STEVE:  That was a different FBI speech.



LEO:  Yes, that's right.



STEVE:  Acting U.S. Attorney for the Northern District of California Stephanie Hinds chimed in, saying:  "Cybercriminals are employing ever more elaborate schemes to convert technology into tools of digital extortion.  We need to continue improving the cyber resiliency of our critical infrastructure across the nation, including the Northern District of California."  Okay, so just to name one.



LEO:  Well, there's a reason, because the warrant was a subpoena to a bitcoin exchange in Northern California.



STEVE:  Ah.



LEO:  And so the thinking is they didn't crack the password or anything like that.  There was a custodial wallet.  The hackers didn't do a good job of securing their wallet.  There was a custodial wallet which the FBI got into, probably Coinbase.



STEVE:  So they said:  "We will also continue developing advanced methods to improve our ability to track and recover digital ransom payments."  And then, finally, and this is just more nonsense.



LEO:  You've got to do these press-releases, though.  It's in the great tradition of J. Edgar Hoover.  You've just got to do this, yeah.



STEVE:  It absolutely is.  So they said:  "As alleged in the supporting affidavit, by reviewing the bitcoin public ledger, law enforcement was able to track multiple transfers of bitcoin and identify that approximately 63.7 bitcoins, representing the proceeds of the victim's ransom payment, had been transferred to a specific address, for which the FBI has the private key, or the rough equivalent of a password needed to access assets accessible from the specific bitcoin address.  This bitcoin represents proceeds traceable to a computer intrusion and property involved in money laundering and may be seized pursuant to criminal and civil forfeiture statutes."  And then it continues with a bunch of self-congratulatory paragraphs which we will skip.



So your notion of there being a vulnerable public exchange is certainly, I mean, that makes a lot of sense, Leo, because I was explaining to Lorrie the other day, actually it was at a dinner party, that while the cryptocurrency itself may be absolutely impenetrable, it's only valuable, it's only useful if you're able to move those coins, those virtual math coins in and out of specific currencies, fiat currencies that exist and are useful in the real world.  So that transaction to and from the real world creates a point of vulnerability. 



LEO:  Often these exchanges have what they call a "custodial wallet," where in effect they have the keys to your wallet so that they can move stuff in and out for you.



STEVE:  Right.



LEO:  And if that were the case, and a warrant were presented to that exchange, they would say, "Oh, yeah, here." 



STEVE:  Yeah.



LEO:  So it doesn't mean the FBI cracked the wallet.  It means that the hackers voluntarily handed the keys over to a exchange in order to turn it into money, probably.



STEVE:  Right.  Right.  So the other possibility that occurred to me, without those facts, is that they asked for, the hackers asked for payment in Monero, which cannot be traced.  Unlike bitcoin's quite visible public transaction ledger, Monero was designed to be untraceable.  But the DarkSide group indicated, oh, also remember that the DarkSide group - oh, no.  They indicated that ransom could also be paid via bitcoin for an additional 10%.  So they wanted Monero.



LEO:  Right.



STEVE:  But if you can't, we'll take bitcoin with a 10% extra vulnerability fee.  So we also know that Colonial did not bother using the decryptor provided by DarkSide, which ended up being given to them for free, because it was too slow and buggy.  But Colonial nevertheless did pay the ransom.  So some have speculated that the ransom was paid, along with the 10% extra for paying via bitcoin, specifically so that the FBI could track the coin flow, which bitcoin permits.



LEO:  Ah, interesting.



STEVE:  What's also odd is that, as we covered at the time, the Eclipse folks who analyzed the bitcoin transaction ledger and were the first to identify the wallet being used by DarkSide claimed that the ransom paid to DarkSide had been immediately transferred out of the group's wallet.  So maybe it went to this exchange that you're talking about.



LEO:  Had you and I used custodial wallets for our bitcoin - we were too secure.  I looked at Coinbase, said I'm not giving you my wallet.



STEVE:  Right, I'm not, exactly.



LEO:  We might still have our bitcoin, had we done that.  But okay.



STEVE:  Yeah.  Well, but on the other hand, how many times between then and now have we covered stories of exchanges being compromised.



LEO:  Yeah, yeah, exactly, yeah.



STEVE:  So technically it would mean, if in fact Eclipse was right, and the transaction went in and out of the wallet they identified as belonging to DarkSide, that would mean - and besides, bitcoins are fungible.  It's like saying "These are the bitcoins."  Well, no.  I own the number two; you know?  You can't have number two.  I have two.  And it's like, well, wait a minute, I just wrote it down over here.  No, no.  That makes no sense.  So anyway.



There are people who know exactly what transpired here, and they're not talking.  But I'm extremely skeptical that this was, as you said, Leo, an actual breach of DarkSide's wallet.  As we know, a bitcoin wallet is an abstraction.  It's simply a public key to which bitcoins have been virtually transferred.  And this virtual wallet's owner holds the matching secret private key.  And a private key is an easy secret to keep.  So if they had kept their wallet private key secret, no technical kung fu will somehow magically liberate the private key from its holder.



LEO:  Sometimes I wish it would, to be honest with you.



STEVE:  Yeah.  Yeah.  So I'd be willing to bet my dinner that social and political pressure was brought to bear directly on DarkSide and that they were instructed in this scenario by the sorts of Russians who you don't say 'no' to, to immediately transfer the entire content of their bitcoin wallet to the following bitcoin address, which was a wallet created by and under the control of the U.S. Federal Bureau of Investigation.  And you know, I mean, that is an absolutely plausible scenario.  If someone knocks on the door, as we said from the beginning, the Russian intelligence services, they know exactly who the bitcoin guys are.  And so if they come knocking and say you just stepped in a big pile of you know what over there in the U.S., and you need to send your money to this address, and we're going to watch the ledger to verify that you do.  It could have happened that way.  So not a technical win.  Pure and simple behind-the-scenes political leverage applied.



LEO:  This was, by the way, that new Ransomware and Digital Extortion Task Force at the DOJ that did that.



STEVE:  Yeah.



LEO:  So I'm glad they're taking this stuff seriously.



STEVE:  Yeah.  And again, when you take meat away from Americans, and when the Eastern Seaboard runs out of gas...



LEO:  Yeah, it gets a little serious.



STEVE:  That gets some attention.



LEO:  Yeah, yeah.



STEVE:  So this is not some geek who's like, oh, well, sorry you got hacked, reload Windows.  This is getting to be serious.  And I'm glad for that.



LEO:  Yeah.



STEVE:  Okay.  WordPress is force-installing Jetpack to five million sites.  Last Tuesday the Jetpack folks, who create and maintain one of the most popular plugins for WordPress, and I will tell you that that's the one that I was using...



LEO:  Oh, yeah, I use it, too, yeah.



STEVE:  Yeah.  It is the right one for managing a WordPress site.  They acknowledged that they had quietly fixed and pushed out an update to resolve a privately reported vulnerability that, had it been exploited in the wild, would have been not good.  Their disclosure for Jetpack v9.8 said:  "We found a vulnerability in the Carousel feature and its option to display comments for each image."  They said:  "Thank you to nguyenhg_vcs for disclosing this issue to us in a responsible manner.  We have no evidence that this vulnerability has been exploited in the wild.  However, now that the update has been released, it is only a matter of time before someone tries to take advantage of the vulnerability."



And of course it's in PHP.  And in the coverage of this they showed, like, the code that was changed; right?  They said:  "We consequently invite you to update your version of Jetpack as soon as possible.  To help you in this process, we worked with WordPress.org Security Team to release patched versions of every version of Jetpack since 2.0.  Most websites have been or will soon be automatically updated to a secured version.  And in fact I think by the time this actually was released, it had been.  And the show notes, it's page 9 of the show notes, at the top of them, shows the versions released include, and I can't even read them, I mean, there's one, two, three, four, five, six, seven, eight, nine, 10, 11, 12, 13, 14 per line, and seven lines.  So, yeah.



LEO:  All the versions.



STEVE:  All the versions.  And then they said:  "If you are running any of these versions, your website is not vulnerable to this issue," only because we just patched it for you.  So and in fact in their coverage, BleepingComputer provided the current download stats, which are available on the WordPress plugin site, but you need to parse some JSON in order to get it.  So it showed that today there had been 3,454,856 downloads.  Yesterday, 632,530.  Over the last seven days, 5,250,265.  So, and all time, get this, 231,457,948.  So yes, Jetpack, super popular, you and I are both using it, Leo, and in the last week the current 5,250,265 all got themselves updated before news of this went out in order to keep everybody secure.



And, you know, I understand that the idea of updates being force-installed makes many people queasy.  I received some well-considered blowback from my suggestion a few weeks ago that allowing our routers to auto-update should be welcomed with open arms and celebrated.  A number of people felt that this would also open us to supply chain attacks, if malicious firmware was ever allowed to get into all of some manufacturer's routers via their update servers.  Okay, point taken.  But I think it's a matter of the least bad of two options.  Allow routers to continue using known defective and vulnerable firmware, thus exposing their unwitting users to significant danger which will never be cured, or allow improvements to that firmware to be pushed when needed.  So on balance, I suspect that we're heading toward a more "pushy" future.



Another piece of WordPress news, the plugin is named Fancy Product Designer, but perhaps a more fitting name would be Fancy Site Destroyer.  The Wordfence security guys have observed active scanning to exploit a critical zero-day remote code execution flaw which allows for complete WordPress and WooCommerce site takeover.  So this is not the happy ending that the Jetpack guys had.  A problem was found, it would have been bad if it got loose, if news of it got loose, because the vulnerable audience was five million.  The good news is the person who found the problem responsibly reported it.  It got patched and fixed, and nobody had to do anything.  So five million remote takeovers were avoided.  In this case we have 17,000 that are not going to be avoided because this thing has no update built in.



The Wordfence security guys have observed, as I said, active scanning to exploit a critical zero-day remote code execution flaw which allows for complete WordPress and WooCommerce site takeover.  The problem lies in a plugin known as Fancy Product Designer.  Anybody listening who has that, fix it now.  It is a visual product configurator plugin for WordPress, WooCommerce, and Spotify.  It allows its users to customize products using their own graphics and content.  Sales statistics show that Fancy Product Designer has been sold and installed on more than 17,000 WordPress websites.



Wordfence's Ram Gall said:  "The WordPress version of the plugin is the one used in WooCommerce installations as well, and is also vulnerable."  The Shopify version of the plugin mitigates and likely blocks the vulnerability because Shopify uses stricter access controls for sites hosted and running on its platform.  However, on WordPress and WooCommerce, successful exploitation of the Fancy Product Designer flaw allows attackers to bypass built-in checks which would otherwise prevent uploading of malicious executable PHP files.  And as we know, once you can get a malicious PHP file placed into a directory from which an HTML query will invoke it, it's game over.  In short, the flaw allows attackers to completely take over vulnerable sites.



And as the WordFence folks noted, the hunt for those 17,000 sites hosting that plugin is underway now.  Ram Gall added that:  "This attacker appears to be targeting ecommerce sites and attempting to extract order information from site databases."  And, he added:  "Due to this vulnerability being actively attacked, we are publicly disclosing minimal details to alert the community to take precautions to keep their sites protected and to update."  But again, it's just PHP, folks.  So you look at an old version and the current version, and you can see what got changed and fixed.  Attacks targeting the thousands of sites running the Fancy Product Designer plugin started more than four months ago, first being seen on January 30, 2021.



So I would say what that says is, if you were using Fancy Product Designer, updating it is probably not sufficient.  You need to really closely examine your site because good guys, I mean, well, yeah, good guys can close it, but only after, in this case, the bad guys may have gotten in.  Since the vulnerability is under active exploitation and was justifiably rated as critical severity, customers are advised to immediately install the Fancy Product Designer 4.6.9 patched version which was released last Wednesday on June 2nd.  And as I mentioned, Wordfence will be holding off on releasing additional details about the vulnerability until a greater percentage of sites running Fancy Product Designer are updated to the latest version.



And since there is no notification system or built-in auto update, no way for the Fancy Designer people to push this out to those sites, hopefully they have some way of contacting the site's users and saying there's a critical vulnerability.  You need to really take this seriously and update now.  And I hope they do the responsible thing and say, since attacks began late January of this year, and sites have been vulnerable for four months, and it's not difficult to determine whether they are vulnerable remotely, you need to assume, unfortunately, we're sorry to have report this, that since you've been using this thing that you purchased from us for fancy designing, your site may have been taken over or compromised.



GitHub responded as I think we would have expected.  We talked about how they somewhat controversially removed a proof of concept from their site because it was demonstrating how to exploit whatever it was, I think it was an Exchange Server exploit at the time.  It's a good thing that Wordfence is withholding details.  But details need to be withheld longer than they are being.  Given current best practices in the security industry, I would argue those are no longer the best.  So they have officially announced a series of updates to the site's policies to address the recently controversial questions surrounding how it will handle malware and proof-of-concept exploit code that's uploaded to GitHub.



Under Section 2 of GitHub's Acceptable Use Policies, they now state:  "Under no circumstances will users upload, post, host, execute, or transmit any content that directly supports unlawful active attack or malware campaigns that are causing technical harms such as using our platform to deliver malicious executables or as attack infrastructure, for example by organizing denial-of-service attacks or managing command-and-control servers, with no implicit or explicit dual-use purpose prior to the abuse occurring."



In other words, that's the first clause of what I read covers the idea of posting a proof-of-concept exploit for an attack for which there is no current mitigation, or even after updates have been offered, but systems are still vulnerable, which was the instance in which GitHub had pulled the previous proof of concept.  And I've got in the show notes a much more lengthy description of the change of policy, if anyone is interested, and a link to it from GitHub.  But basically it talks about that in greater detail.



The point being, yes, we're going to change our terms to be more in line what we think is reasonable, which is why should we be hosting proof-of-concept code which allows bad guys to grab that and immediately leverage attacks in the wild against servers or anything which is now vulnerable.  So I think they pretty much had to make it clear that that's what they were going to do.  And yes, people should not be posting widely available, public proof-of-concept code which can immediately be leveraged and taken advantage of.



Okay.  So a bit of miscellany.  I inadvertently set off a bit of a firestorm with my admittedly strongly worded statements two weeks ago about NAT.  Okay.  And I have in the notes IPv6.  I didn't even refer to IPv6.  One person tweeted via DM.  He said:  "You're completely conflating NAT and firewalls.  You can certainly have a firewall without NAT," he says, parens, "(if you're not out of addresses) and have an easier to understand environment."  Okay.  And he didn't mention IPv6, and I hadn't either.  But over in GRC's newsgroups someone posted:  "Instead of being scared of IPv6, why not learn a bit about it and how security is provided for IPv6-connected devices?"



Then this person quoted a line from Episode 850, I guess it was, no, 822 is - anyway, he's got the wrong episode number.  But he quoted me saying:  "The nutty IP purists, with their heads well positioned far up their you-know-whats where the sun don't shine, have always decried the use of NAT."  And so this guy continues:  "They're right."  Meaning the IP purists.  He says:  "NAT is an annoyance that provides nothing other than reducing the use of valuable IPv4 addresses."  He continues:  "You do not need NAT to provide security.  All you need is a stateful firewall that only allows packets in that are part of or are related to an outgoing connection.  You" - and here we have all caps - "DO NOT need to be translating between different IP addresses to achieve that.  This provides EXACTLY [all caps] the same security that NAT does."



Okay.  First of all, duh.  For the record, I never suggested otherwise.  I never, in any way, intimated that NAT was the only way to obtain the equivalent of a stateful firewall.  In fact, my chosen personal firewall for the PC, which I endorsed 21 years ago in 2000, was ZoneAlarm.  A bunch of embarrassingly old pages are still up on GRC talking about it.  Zone Alarm's claim to fame, along with being application-centric, was that it was inherently stateful.  It tracked connections and only allowed incoming packets for connections that had been previously established.  There was no NAT involved anywhere.



But the entire world desperately needed the security provided by stateful packet-inspecting firewalls back then, 21 years ago, while personal home networks were growing like weeds and needing many, many of their own IP addresses on the LAN; when ISPs only had the one to give.  Where was IPv6?  Nowhere.  And where is it today?  Still mostly nowhere.  Oh, sure, some ISPs are now, 21 years later, finally beginning to deploy IPv6.  Was the entire world supposed to wait for IPv6 before we could have more than one device attached to our ISP's single-IP DSL or cable modem?  NAT was a godsend, and it still is today.  Someday we won't need NAT, but I'll wager that we're still going to be using it.  And in any event, most users still have no choice because today, in 2021, IPv6 is still not ready for primetime.



And one last point.  The guy who posted over in the GRC Security Now! newsgroup wrote, in caps, about IPv6:  "This provides EXACTLY the same security that NAT does," which is also incorrect.  "Anyone who understands security" - as you referred to earlier, Leo - "appreciates the concept of multiple layers of protection."  Having a stateful firewall provides one good layer, yes, whether it's translating IP addresses or not.  But having a local network of private and non-publicly routable IP addresses is another massively useful layer of security.  Everything that happens inside our local networks is local and off the 'Net, until and unless something wants to reach out onto the public Internet through our NAT router.



Getting everything to work through NAT has been a pain in the butt.  We've had to develop robust STUN and TURN protocols and develop publicly accessible rendezvous servers to directly interconnect two devices which wish to peer when both are sequestered behind their respective NAT routers.  But that's all been figured out now, and it works.  And that sequestration also helps to keep us safe the rest of the time.



So anyway, I got a bunch of confused responses, and some obviously incorrect.  So I just wanted to go on the record.  I'm not anti-IPv6.  I'm still waiting for it.  It's still trying to happen.  And I get it.  It is, but we couldn't wait for it.  We got NAT, and it gave us the security that we needed.



LEO:  Yeah.  In fact, unfortunately, Carrier NAT has put off IPv6.



STEVE:  Yes, right.



LEO:  By solving the IP address scarcity problem.



STEVE:  Right.



LEO:  I know, I can't believe we're still talking about this after all these years.



STEVE:  And Leo, this speaks to the inertia that we have.



LEO:  Yeah.  Why change it if it's not broken?



STEVE:  Right.  And let's make the tiniest change we possibly can.  All of our equipment is IPv4, so let's just stick another big Carrier Grade NAT in front of it, and then everything can stay IPv4, and we don't have to replace any of our equipment.



LEO:  Yeah.  That's the real reason, isn't it.  It's down to money again.



STEVE:  Yeah.  And expediency.



LEO:  Yeah.



STEVE:  Okay.  "Project Hail Mary."  I finished reading the book this weekend, and I very much enjoyed it.  One thing I can say without any doubt or question is that any possible movie that is shorter than about eight hours will necessarily utterly fail to do the book justice.



LEO:  Well, I should tell you the same guy who wrote "The Martian," who I thought did a very good job with "The Martian," is writing the script for "Project Hail Mary."



STEVE:  Good luck.



LEO:  Yeah, it's going to be challenging.  There's a lot of...



STEVE:  The way I would put it, Leo, is that the book will be influential to the movie.



LEO:  Andy said he was very happy with the script.  He's seen it, and he was very happy with it.



STEVE:  Well, okay.  It's a shame that you could not make a faithful movie from this book.



LEO:  It'd be a better series.  Make it a series.



STEVE:  Leo, it would be, yes, it would be a miniseries.  I actually put that in the show notes here because the only way you could do it.  On the other hand, it would be a miniseries for us.  The general public would probably fall asleep.



LEO:  Too much physics.  I really don't want any more physics problems, thank you very much.



STEVE:  Right, exactly.  It was a fun read.  So here's what I would say.  If you are going to see the movie at some point, if you imagine that the movie would interest you, and I think it should, I think our listeners should definitely do it, please allow me to urge you to read the book or have Audible read the book to you before you see the movie.



LEO:  Oh, yes.  I always say that, though.



STEVE:  Yes.  I mean, but more for this than anything I can ever imagine because, Leo, I cannot imagine how you could do this in two hours.  I mean, there were eight hours of content in just the problem solving, let alone setting up the problem and all of the politics and all the committees and all of the other stuff that was happening elsewhere, away from our main character, or that the character was involved, I mean, I just, again, I read "Jurassic Park," and I was annoyed when they left out some things that I thought were really wonderful.  They're just going to have to leave everything out in order to make a movie of this.  So really, really, really, it was a fun read.  I really think our listeners would get a kick out of it.



LEO:  Totally would.  If you like this show, you will love, I think, "Project Hail Mary."  It has a very nice ending, as well, which is good.



STEVE:  It did, yup, it did have a happy ending.



LEO:  Yeah.



STEVE:  Okay.  Extrinsic Password Managers.  We're going to talk about that next.



LEO:  Very interesting.  I'm so glad.  The other thing that you didn't address, but it's a rapidly developing story, is the use of the FBI and the Australian federal police of what was billed as an encrypted messaging service, ANOM.



STEVE:  Ah, yes, where they snuck themselves in.



LEO:  They were in it for three years.  They took it over and ran it for three years and apparently caught a bunch of people.  But I want to see what the prosecutions show because I also worry that this is a pretext for saying, see, it's so great when we can see all the messages.  We need a backdoor into all of them.  In fact, they've already proposed that in Australia on the heels of the ANOM revelation.



STEVE:  And somebody tweeted to me with this news.  The way I learned about this was him saying, one of our listeners saying, "Steve, this is what you've been saying is the problem with iMessage all along."  Which, yes, if you're not managing your own keys, somebody else is.



LEO:  Yeah, somebody else is.  All right, Steve.  Let's talk about this blog post.



STEVE:  So the name Tavis Ormandy is one we've often mentioned on this podcast because Tavis is a prolific security researcher at Google.  He's constantly finding problems in this industry's security designs and implementations, posting to Google's zero-day project and starting timers to require companies to fix their stuff or else.  So when Tavis posts on the topic of password managers to his own informal blog, it comes to the attention of many who are interested in topics of security.  And many of those people listen to this podcast and wonder what I think of what Tavis says.



Now, you know that Tavis is on the techie side because his domain where this blog is located...



LEO:  The URL, what is the point of that?



STEVE:  ...is, okay, so that's an instruction for the x86.  It's compare and exchange eight bytes.  The domain is cmpxchg8b.  And in a multiprocessor environment, you need to give it the lock prefix so that you lock the execution against other processors doing it at the same time.  So this domain is lock.cmpxchg8b.com.  And I was talking earlier about the crazy instruction sets, and we were talking about 8086.  Get this.  The compare and exchange eight-byte instruction.  So there's 32-bit registers.  In this case EDX is one 32-bit register and EAX is another.  So the description of what this one instruction does is compares the 64-bit value in the register pair, each 32-bits, EDX concatenated to EAX, with the operand, which is the destination.  If the values are equal, the 64-bit value in ECX/EBX, a different pair of 32-bit registers, is stored in the destination operand.  Otherwise, the value in the destination operand is loaded into EDX/EAX.



The destination operand is an eight-byte memory location.  For the EDX/EAX and ECX/EBX register pairs, EDX and ECX contain the high-order 32 bits, and EAX/EBX contain the low-order 32 bits of a 64-bit value.  So yes, that gives you a sense for the world that Tavis and I live in, programming in assembler and the x86 instruction set from time to time.  That's actually - a variation of that is actually rather handy for implementing semaphores, but that's a topic for a different time.



Anyway, we've established that Tavis is a techie.  So he was not  overly wordy in what he wrote.  So as I looked at this, I thought for the podcast any attempt I might make to summarize would likely be longer than what he explained.  So I've removed his examples and his pointers to specifics.  But I think that the best way for me to get to this is just to share what he wrote.  And then I'll respond coherently.  You and I, Leo, will talk about it.



So he wrote, Tavis wrote:  "I've spent a lot of time trying to understand the attack surface of popular password managers.  I think I've spent more time analyzing them than practically anybody else, and I think that qualifies me to have an opinion.  First, let's get a few things out of the way.  For some reason, few subjects can get heated faster than passwords."  He says:  "Maybe politics and religion, but that's about it.  It's okay if you don't like my opinion.  Second, everyone needs to be using unique passwords.  I don't have to use a password manager to do that.  Whatever system works for you is fine.  If you want to use a notebook in a desk drawer, that's totally acceptable.



"Okay, let's begin."  He says:  "Conceptually, what could be simpler than a password manager?  It's just a trivial key-value store.  In fact, the simplest implementations are usually great.  Good examples of simple and safe password managers are KeePass and KeePassX, or even Pass if you're a nerd.  Things start to go wrong when you want integration with other applications, or when you want data synchronized by an untrusted intermediary.  There are safe ways to do this, but the allure of recurring subscription fees has attracted businesses to this space with varying degrees of competence.  I'm generally skeptical of these online subscription password managers, and that's going to be the focus of the rest of this article.



"I often say that 'Use a password manager' is bad advice.  That's because it's difficult to tell the difference between a competent implementation and a naive one.  The tech press can review usability and onboarding experience, but can't realistically evaluate any security claims.  So how do you propose users tell the difference?  For that reason, I think 'Use a password manager' is so vague that it's dangerous.  A good analogy is telling someone with a headache to pop any pills they find in the medicine cabinet.  Maybe they'll get lucky and find an aspirin; or maybe they won't, and you'll be making a call to poison control.



"Advice on this topic needs to be specific."  Well, and ours has been, always, of course.  He says:  "It's better to recommend implementations that are well designed, rather than general product categories.  This position is surprisingly contentious.  Many people argue any password manager is acceptable, and that I'm sowing fear by actually evaluating vendor claims."  He says:  "I remain unconvinced."  He says:  "My primary area of interest is how remote attackers can interact with your password manager."  Okay, that's certainly reasonable.



He says:  "I'm not interested in things like testing how resistant encrypted blobs are to offline cracking.  This might be a valid concern for some.  But in most cases, if an attacker is in a position to access or tamper with encrypted state, then you were in trouble whether you used a password manager or not.  There are two common issues I run into," he says.  "The first is that trusted user interface elements are injected into potentially hostile websites.  The second is that different components IPC" - and that's inter-process communicate - "over web-accessible channels, for example, WebSockets, postMessage, et cetera, without adequate mutual authentication."



He says:  "Let's discuss user interface elements first.  Most online password managers use content scripts, Javascript that is inserted into every website you visit.  It's really easy to write content scripts, but really tough to make them tamper-resistant.  That's kind of a problem, because they're going to be hosted in hostile environments.  How isolated worlds interact is complicated enough, but password managers make matters even worse by blurring the distinction between user interface and content.  We've already established that one component of online password managers must be injected into potentially hostile environments.  How can those components communicate with other components?



"One naive solution would be to just use XHR or WebSockets to a local HTTP endpoint.  This sounds appealing to developers.  They're the native way to communicate on the web.  The problem with this solution is that it's very difficult to differentiate between your content script and a hostile script running on the same page, but in a different world.  Essentially, every implementation I've looked at has got this wrong, resulting in critical game-over vulnerabilities."  He says:  "Vendors come up with all kinds of hacky solutions to this, often involving inherently racy background scripts that try to verify a tab's origin.



"Another gripe I have with online managers is that they render browser sandboxes less effective.  Modern browsers use a sandbox architecture to isolate components that can go wrong.  The problem is that online password managers effectively inject privileged components into these sandbox processes with extensions.  The purpose of sandboxing is to isolate potentially compromised components from each other.  But if you stuff all your valuable secrets inside the sandbox, then what's the point?  I worry that people don't understand the tradeoff they're making here.



"Despite what your vendor says, if their network is compromised, the attacker can read your passwords.  Here are some selected marketing claims from password manager vendors:  'No one apart from you, not even us, has access to your passwords.' Or 'We keep your information private, secure, and hidden, even from us.'  And finally, 'Your data is secured in a way that only you can view it and manage it.  Our employees can't,' and so forth."



He says:  "These claims are nonsense.  An attacker or malicious insider in control of the vendor's network can change the code that is served to your browser, and that code can obviously access your passwords.  This isn't farfetched.  Altering the content of websites (i.e., defacement) is so common that it's practically a sport.  The reality is that you have to trust your vendor to maintain their infrastructure and keep it safe.  The existence of encryption - bank grade, military grade, or not - does not alter this."  He says:  "Perhaps you think this isn't a big deal.  You already trusted them when you installed their software.  Fine.  But these claims are front and center in all marketing, so vendors must believe their customers care about it.  I think these claims are bending the truth to assuage legitimate concerns.



"It's easy to poke holes in marketing stuff, but there are some other fun ones I noticed from real password manager vendors.  'Keystroke encryption protects everything you type from being read by cybercriminals.'"  He says:  "Oh, okay.  Or 'Many of the .NET assemblies are obfuscated.  So even using a disassembler, users are unable to view critical areas of methods, functions, and classes.'"  And he says:  "Well, I certainly feel safer."  Et cetera, et cetera.



So he finishes:  "If you want to use an online password manager, I would recommend using the one already built into your browser.  They provide the same functionality" - okay, we'll talk about that in a moment - "and can sidestep these fundamental problems with extensions."  He says:  "I use Chrome."  Yeah, no kidding.  "But the other major browsers like Edge or Firefox are fine, too.  They can isolate their trusted UI from websites.  They don't break the sandbox security model.  They have world-class security teams, and they couldn't be easier to use."  I'll just interject here that they also share the common networking problem, which he blasted the other ones for.  "No doubt there will be many people reading this who don't like this advice.  All I can say is I've heard all the arguments and stand by my conclusions."



Okay.  So we obviously have a Google-centric person, and we have a Chrome-centric person, and we have an extremely smart and security-conscious person.  I find no fault with anything Tavis has said.  And yet I'm proudly and happily using not an intrinsic password manager, but an extrinsic add-on password manager.  Why?  Because I'm polyamorous.  I move among multiple browsers to suit my various needs.  I use Safari on iOS.  And Leo, I heard you mention yesterday...



LEO:  I do, too.



STEVE:  ...that you do, too.



LEO:  Yes.  And on macOS, actually.



STEVE:  Yeah.  Right.  I use both Firefox and Chrome, bouncing back and forth as needed.  And I am often depending upon a single bridge between them.  What we might term "intrinsic password manager lock-in" is a thing.  I don't want to be prevented from moving to another browser if I choose.  I'm not only polyamorous, I'm also fickle.  And I want the freedom to use whichever browser I want.  Also, I have not kept up with all of the many additional features offered by the best add-on solutions, but I know they offer a whole host of extras.  I do take advantage of the Secure Enclave-style synchronized storage for random notes which allow non-password things to be kept safe somewhere and kept synchronized.



So I guess my conclusion here would be that, if someone has no need to ever bridge browser families, nor any use for all of the many extra goodies that are offered by third-party add-on extrinsic password managers, then yeah, such a person's need would be amply met just by sticking with the password managers which have finally been added to our browsers.  But then you can't change your mind.  You can't go anywhere.  You're locked into that browser.  And I cannot speak to the theoretical loss of security which Tavis argues will necessarily accompany the use of any third-party tool.  I have no doubt whatsoever that there are many horrifically insecure and poorly designed password managers, just as with anything else.  But what I do know is that we are not seeing any evidence that the most carefully and well-designed third-party password managers are introducing exploitable vulnerabilities.  It would be such a disaster if they were that I'm sure we would know.  And we don't.



LEO:  Yeah, and - okay.  So obviously I don't completely disagree.  I understand what he's saying.  I think that he forgets that we live in the real world.



STEVE:  Yes.



LEO:  And by the way, I would like to point out it was only recently that Chrome's password manager did not expose your passwords in plaintext to anybody who had access to your computer.



STEVE:  I told the story a while ago of how, like, Lorrie couldn't remember some password.  I said, oh, let's go look.  And I showed her.  She says, like, what?  Yeah.



LEO:  And Chrome's explanation was, well, if they have access to your computer, you're screwed.  Well, okay, Tavis.  Tell me more.  You know?  So that's problem number one is he asserts that Chrome and Firefox and Safari store passwords securely.  I'll accept that, you know.  Certainly nobody has done more to make Chrome and others more secure than Tavis Ormandy.  But as you point out, it's not the ultimate solution because there's lots of other reasons we use password managers.  And everybody's cross-platform, I would think.  I mean...



STEVE:  This day and age?  Windows and iOS.  Windows and Android.



LEO:  Yeah.  If I only used Apple stuff, I think Apple does a very good job with their Keychain.  It's very secure.  It has a feature that Tavis kind of glosses over.  How am I supposed to generate these long strong random passwords?  He says use a notebook?  I don't think he means that.  You need something to do that.  Now, maybe you've got a tool that does that, or you've got a bag of dice or something.  I don't know.  But that to me seems like a potential flaw in this.  You do want some software to generate these passwords.



STEVE:  Yes.  I go to a random generator all the time just to grab mine, without a second thought.



LEO:  Yeah.  And then, finally, I wonder if maybe his objections could be solved if you were using a password manager - I understand what he's saying about breaking the browser's security model.  That's a fundamental thing.



STEVE:  Yes.  As a purist, the sandbox, you want to have the sandbox be...



LEO:  That I understand.



STEVE:  ...absolutely immutable.



LEO:  So what if I use - and most password managers, certainly Bitwarden and LastPass and 1Password, allow you to run, in fact have a standalone app.  It's not in the browser.  If you don't, in fact, for a long time I used it this way.  I would not install the browser extension because I was concerned about that.  I would merely open the app, search for the password, copy it and paste it in.  Would that be okay?



STEVE:  And now you've got the problem of that password existing on the clipboard.  And the beauty of having it automatically inserted into the form for you by a password manager is that it doesn't touch your external computer.  And the external computer is where malware lives.



LEO:  So I'd like to know more about how Tavis proposes doing this.  Does Chrome generate passwords?



STEVE:  I was just wondering that when you were talking about that.



LEO:  I don't think so.  Safari does. 



STEVE:  I think Chrome does.  I'm having a problem now with multiple things offering me passwords when I'm logging into a site for the first time.



LEO:  So that's problem number one is we need a way to generate a unique password every time.  It has to be easy and fast.  And truly random, by the way, not a pseudorandom number generator.  So we've got a truly random password generated by something.  And he's proposing that we just let the browser remember it.  And I guess then I could open the browser if I wanted to log into an app and copy it out of the browser.  Because remember, people use password managers for apps and accounts of all kinds, not just in the browser.



STEVE:  Yes, that is the other point.  I forgot to mention that also.  I do exactly the same thing.



LEO:  So I'm unclear what his - I'd like to know what his workflow is that he's so happy about.  It strikes me it's onerous and prone to flaws and errors.  And I think he's not living in the real world particularly.



STEVE:  And I think as he explicitly said, he's annoyed when he hears someone say "Use a password manager, period."



LEO:  That I understand.



STEVE:  Not saying use this or that known to be reputable, high end, time and experience tested password manager.



LEO:  Right.  And that's why when you vetted and approved of LastPass, I was thrilled because that told me this is reliable.  And one of the reasons I like Bitwarden is because it's open source and constantly being audited, has been audited multiple times.



STEVE:  And in fact, because LastPass wasn't open source, the only way Joe had of allowing me to verify what he had done was to allow me to play with a page which ran the same crypto that I was able to look at.  



LEO:  Right.  And we don't know what's happened since then, either, I could point out.



STEVE:  No.  No idea.



LEO:  So that's my big problem with closed source for security in general is just lack of accountability.  And I don't know, is the Chrome password manager part of Chromium?  Is it in the open source?  Or is it part of the stuff that's hidden by Google?  I would guess it's the latter.



STEVE:  Ah, interesting.  I don't know.



LEO:  And there would probably be good reasons for that.  But again, that's another issue.  Of course Tavis Ormandy trusts Chrome.  If I were a Google employee, I might, too.  But, you know, that's his company, not mine.  But I think the real takeaway, and I wish he'd just really left it at this, is the problem with password managers as an extension in your browser is it breaks the browser's security model.  Had he said merely that, I think that's a point very well taken.  Right?



STEVE:  Yeah, yeah.



LEO:  And that's something we don't really consider.  I actually have in the past because there have been JavaScript issues with all of these in the past.



STEVE:  Yeah.  And one story that I looked at but didn't get to, just because here we are at two hours, was there was some mention, and I saved all the tabs so I can catch up next week if it ends up being useful...



LEO:  That's another problem for another day.



STEVE:  ...is that there was just some mention about a consortium of the browser vendors getting together to look at improving extension security.  So we may, you know, like Tavis may be having to give up on the idea of leaving the browser extension-free because any extension is going to be doing this.



LEO:  Well, that's right.



STEVE:  Not just a password manager.



LEO:  What about ad blockers?



STEVE:  Right.



LEO:  We all use those.  I think as a net gain running UBlock Origin is a security positive.  But it does add potentially a problem because you're inserting, injecting JavaScript in.  I think his point is well taken, but I'm not sure I agree with the final conclusion.  Anyway, I'm going to keep using a password manager.



STEVE:  Amen.  I'm not going anywhere.  And I know our listeners aren't, either.



LEO:  No, yeah.  It's a really interesting post.  But this is what I've always thought about Tavis.  He's very, you know, he's a great engineer, brilliant guy, very black-and-white.  Right?  It's either good or not.  That's typical engineer.  One or zero.  And the world is sometimes just a little more gray than that.



STEVE:  And don't forget the lock prefix when you use the  compare and exchange eight bytes instruction.



LEO:  You know, I thought this is ridiculously cryptic.  And then at the top of the post he has what I presume is an ID to verify its authenticity, I would guess.



STEVE:  I looked at that, it's like, what the heck is that?



LEO:  That looks like a hash.  But I don't know.  I mean, is it an MDA hash that you could say, oh, yeah, this has not been modified?



STEVE:  Well, of course if you modified it, then you just modified the hash.



LEO:  Yeah, I just changed the hash.  So I don't know.



STEVE:  So, yeah, I don't know what he's doing.



LEO:  He's a kook.  He's a character.



STEVE:  Maybe he wants to have a unique search term on the global 'Net so that you can always find his posts by ID.



LEO:  Well, that's the good news.  If that's your TLD, no one's, you know, that wasn't hard to register.  I doubt there was a lot of competition for that.  Have you ever - you've never met him; right?  We should - I'd love to meet him sometime.  



STEVE:  Yeah, be neat.



LEO:  Find a chance to have a drink at RSA or something.  Steve Gibson, you're meeting him every week.  You'd better be here.  You can't miss this show.  Every Tuesday at 1:30 Pacific, that's 4:30 Eastern, 20:30 UTC.  We gather to talk about security in the most in-depth, intelligent way that exists on the Internet.  And we're so glad Steve does this, and we pray that he will continue past 999. 



If you want to visit his site, GRC.com is the place to go.  You'll find of course his bread and butter there, SpinRite, the world's best mass storage maintenance and recovery.



STEVE:  Thank you.



LEO:  I'll get it one of these days.  Mass storage maintenance and recovery utilities.  I say that because it used to be hard drives, and now it works for SSDs, too.  6.0 the current version. 6.1 is coming.  Buy it now, you'll get 6.1 free.  And of course you'll also get to participate in the development of  6.1, which is in very active development.  There's forums for that, and all his other forums.  The forums are very active at GRC.com.



You'll also find the show, 16Kb versions.  That's unique.  No one else makes a 16Kb version of the show.  He also makes a really nicely done, and on his own dime, I might add, transcript of the show so that you can read along as you listen, or you can use it to search.  All of that you'll find at GRC.com, along with a 64Kb audio version.



We have the 64Kb audio and video, as well, at TWiT.tv/sn.  There's a YouTube channel with all the shows, all 822.  Well, no, actually, because we only started doing video after a few hundred shows.  So the most recent 600 or so in video.  You'll also find links to your favorite podcast players and an RSS link if you want to add it manually to your podcast player.  That way you can get it the minute it's available of a Tuesday afternoon.  And if you use a podcast client, please, if you have a chance, leave us a five-star review.  Let others know how great Security Now! is.



Steve, have a great week, and I'll see you next week on Security Now!.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#823

DATE:		June 15, 2021

TITLE:		TLS Confusion Attacks

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-823.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we're going to start by looking at a moment-by-moment reconstruction of a recent Chrome browser attack-and-patch battle.  Then we're going to recap last week's industry-wide June patch fest, followed by looking at TikTok's controversial but unsurprising privacy policy update.  We need to also cover the wonderful spy novel-ish ANOM sting operation which lowered the boom on as many as 800 criminals.  For our happily infrequent Errata section we'll challenge an apparently erroneous statement I made last week.  I want to share an interesting laptop data recovery experience which BitLocker made much more complex a few weeks ago which I think our listeners will find interesting.  Then we're going to tackle this week's topic of some very troubling research which again demonstrates just how difficult it is to design robustly secure networked systems.



SHOW TEASE:  It's time for Security Now!.  Lots to talk about.  Industry-wide Patch Tuesday.  Is that such a good idea?  Lots of bug fixes.  Steve's got a list.  Also coming up in just a little bit, TikTok.  They got caught collecting your biometric information?  Really?  And then a great story from Steve about how he fixed a friend's laptop.  This was a life-or-death situation, and Steve rode to the rescue.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 823, recorded Tuesday, June 15th, 2021:  TLS Confusion Attacks.



It's time for Security Now!, the show where we cover your security and privacy online with the man and the myth and the legend, Mr. Steve Gibson.



STEVE GIBSON:  Big on myth.



LEO:  You're man and legend.  I don't know about the myth part.  Good to see you.



STEVE:  Oh, Leo.



LEO:  Uh-oh.  What's the matter?  Bad guys winning again?



STEVE:  We're all going to be very depressed by the end of this podcast.



LEO:  Uh-oh.  Uh-oh.



STEVE:  But that's the way it goes, unfortunately.  And that's the way it goes.



LEO:  That's the way it is.



STEVE:  That's the way it is.  We're going to start, however, by looking at I think a fun moment-by-moment reconstruction of a recent Chrome browser attack-and-patch battle.  Or maybe it was a pitched patch battle.  Anyway, then we're going to recap last week's industry-wide June patch fest, followed by looking at TikTok's controversial but unsurprising privacy policy update.  We need to cover also that wonderful spy novel-ish ANOM sting operation which was just breaking as we were recording last week's podcast.  And of course it lowered the boom on as many as 800 criminals.



For our happily infrequent Errata section, we'll challenge an apparently erroneous statement I made last week.  And actually based on something I just saw The Verge post, it now seems almost assured that it is incorrect.  Then I want to share an interesting laptop data recovery experience which BitLocker made much more complex a few weeks ago, which I think our listeners will find interesting.  I had it in the show notes last week, just like a note to talk about it, but we didn't have time.  I think we will this week.



Then we're going to tackle this week's topic of some very troubling research which again demonstrates just how difficult it is to design robustly secure networked systems, even if nobody makes any mistakes.  If there are no bugs, if there are no patches, if nothing is wrong, it still doesn't work.  And, yeah.  So we will discuss what I'm calling TLS Confusion Attacks, although they are unfortunately named the ALPACA Attacks.



LEO:  Oh, yeah.  I remember those.



STEVE:  ALPACA.



LEO:  ALPACA.



STEVE:  Yeah, well, ALPACA, yeah.  And we do have a fun, well, not very surprising,  but it's a useful Picture of the Week.  So overall...



LEO:  Is it a picture of an alpaca?



STEVE:  No.



LEO:  Oh, okay.  I had to learn recently the difference between an alpaca and a llama.  The alpacas...



STEVE:  They're not the same.



LEO:  No.  Alpacas are the cute ones.  Literally.  Look at a picture.  Just while I'm doing this ad.



STEVE:  Okay.



LEO:  Look at a picture.  Just google "alpaca" and "llama," and tell me if I'm not right.  That's how I remember the difference.  I am ready to fire up the Picture of the Week, Mr. G.



STEVE:  Well, this is pretty simple, but I got a little bit of a kick out of it.  It's just a single-frame cartoon, shows two bad guys in black hoodie masks.  One's got a mask on, the other's got a larger ski mask and glasses.  And the first guy says, "Hey, Harvey."  Oh, and they're both sitting in front of laptops, doing their dastardly deeds.  "Hey, Harvey.  Someone hacked into my bank account and stole all the money I made from ransomware.  This is so unfair."  Anyway.



LEO:  It's funny because it's true.



STEVE:  It's sad, yes.



LEO:  That somebody might be the FBI.  We don't know.  But yeah.



STEVE:  Yeah.  So Google is finding that with offering the world's number one web browser comes being the world's number one web target.  Using some reports published by Kaspersky Labs, I was able to reconstruct a timeline of some recent Chrome vulnerabilities and fixes.  And what it reveals is instructive.  So exactly two months ago, during April 14th and 15th of this year, Kaspersky Labs detected a wave of highly targeted attacks aimed at multiple companies.  Those were companies that are paying them to oversee their security, monitor their web traffic, keep an eye on things, thus the way they were able to detect this.



Upon closer analysis, Kaspersky discovered that these attacks were exploiting chained Chrome and Windows zero-day vulnerabilities.  Though they were unable to retrieve the exploit code itself, which was used to accomplish remote code execution in Chrome, they were able to obtain and analyze an elevation of privilege exploit that was used to escape the sandbox to obtain system privileges.  And remember that, while we tend to focus upon remote execution attacks because those are like so obviously bad, exploitable elevation of privilege vulnerabilities are also extremely powerful since they inherently breach the security boundaries that we rely upon to allow externally provided browser code, JavaScript and WebAssem, to run in our browsers, while curtailing what that code can do.  If code can arrange to make itself privileged, then "can do" is what results, and that's not what you want from code that you've obtained from someone you don't really trust.



So in this case the elevation of privilege exploit that they discovered had been fine-tuned to work against the latest and most prominent builds of Windows 10.  Well, not only the latest, but dating back to 17763, which was RS5; and included 18362, which was 19H1; 18363, 19H2; 19041, 20H1; and 19042, 20H2.  So, I mean, there was some serious attacking going on.  And it does all this by exploiting two separate vulnerabilities in Windows OS kernel once it gets free, once it escapes from the browser.



So five days after this discovery, on the 20th, Kaspersky had figured out what was going on, pulled a report together, and reported these vulnerabilities to Microsoft.  And two successive CVEs were assigned:  2021-31955, which was an information disclosure vulnerability, that's actually a kernel disclosure, which we'll be getting to when we talk about this last past week's patches; and also 31956, which is the elevation of privilege vulnerability.  Both of these in-the-wild vulnerabilities were patched, as I said, last Tuesday as part of June's patch cycle.



The observed attacks were all conducted through Chrome.  But as I noted before, Kaspersky was unable to retrieve the JavaScript which fully implemented the entire exploit.  But they did have a clue, the Pwn2Own competition that had taken place the preceding week, April 6th through the 8th, which we talked about at the time.  And of course Chrome was a prominent target of that.  During the competition one of the participating teams was able to successfully demonstrate an exploitation of the Chrome renderer process using a type mismatch bug.  And a few days later, on April 12th, the Chromium developers committed two new issues, 1196683 and 1195777, to the open source repository of V8, which as we know is the Chrome and Chromium JavaScript engine.  Both were type-related bugs.



One of these bugs, that 6683, patched the vulnerability that was used during Pwn2Own. And both bug fixes were committed together, along with regression tests.  Regression tests are JavaScript tests which are used to trigger the vulnerabilities.  And of course they're important because you want to keep those vulnerabilities from ever coming back by mistake in the past.  Later that same day, a user with the Twitter handle @r4j0x00 published a working remote code execution exploit on GitHub targeting an up-to-date version of Google Chrome.  That exploit used the vulnerability from issue 6683 to execute shell code in the context of the browser renderer process.  The exploit published to GitHub did not contain a sandbox escape and was therefore intended to only work when the browser was launched, and you wouldn't normally do this, with the command line option "-no-sandbox."  So not a huge concern, but still interesting.



Then on the 13th, the day before Kaspersky first became aware of the attacks in the wild, Google released Chrome update 89.0.4389.128 for Windows, Mac, and Linux, with fixes for two vulnerabilities.  The one, that CVE-2021-21220, used during Pwn2Own was one of them.  However, since several of Kaspersky's customers, who were attacked on those first two dates, April 14th and 15th, already had their Chrome browsers updated, Kaspersky believes that the Pwn2Own-originated vulnerability was not used in those attacks because it would have failed against those just-updated browsers.



Then, the next day, on the 14th, Google moved from their version 89 to version 90.  And of course we covered that move also.  There was a whole bunch of features fixed.  That was a major planned feature release.  And that brought out 90.0.4430.72 for Windows, Mac, and Linux.  This release closed the door on 37 vulnerabilities.  And on the same day, on that 14th, a new Chrome exploit was posted on GitHub, which of course released it to the public.  That newly published exploit used that second vulnerability, the 5777 which, even though it had been committed on the 12th, still worked on the just-released Chrome 90 from the 14th.



So, I mean, there was just like a - 89 apparently may have fixed it.  But technically, 90 regressed because it wasn't part of the planned release in 90, and that change had just been committed prior to, well, probably after 90 essentially was RTM'd.  So that problem, this 5777 problem, was fixed six days later on the 20th.  Kaspersky suspects that the attackers were also able to use the JavaScript file containing the regression test for that second problem to quickly develop the exploit and were probably using the second vulnerability in their attacks.  So talk about cat and mouse.



What do we learn from this?  We learn that attackers are extremely active and deft at scrutinizing everything that happens in public view.  They're looking everywhere at once.  In this instance, the results of the Pwn2Own competition likely primed them to be on the lookout for Chromium commits that would soon follow.  And they did.  The Chromium project is at a disadvantage of inherently being open.  It's a good thing to create JavaScript regression tests to make sure that bugs which have been fixed never return.  But as likely happened here, the appearance of the regression tests probably predated by eight days the deployment of an updated Chrome browser which fixed those flaws, due to just like a one-day timing uncertainty.  That created that eight-day exploitation window during which a problem was publicly known and documented, but not yet patched, and in the hands of Chrome's users.



We can also see from this almost minute-by-minute back-and-forth, that those who are responsible for security can never take a vacation day from their jobs.  Newly discovered vulnerabilities must be immediately stomped out, and those fixes must also be rapidly deployed.  And we can see that today's web browser attackers themselves are hyper-vigilant.  They know that they won't have much time to leverage any transient advantage that they might be able to briefly obtain.



And, finally, we learn that we should be so thankful that Microsoft had the wisdom to scrap their own independent web browser development in favor of their adoption of the Chromium project.  Web browsers can no longer be the domain of massive, slow-moving, bureaucratic behemoths.  Web browsers is no longer where Microsoft should be.  Putting any modern web browser up for the world to attack requires far too much agility.  Google has clearly optimized their Chromium group for short-cycle, nearly instantaneous response.  And in an example like this, nothing less would be sufficient to protect Chrome users from today's attackers.



So, whew.  We normally just sort of step back and look at the big major version changes.  But I thought that this was really interesting to see just how quickly any instance of a vulnerability is jumped on.  And it's not clear what percentage of vulnerabilities are being discovered themselves by the attackers, and how many, like in this instance, they're able to allow other people to discover and, just as a consequence of timing uncertainty, are still able to create an attack window that is unfortunately useful to them.  They clearly had other pieces of ammunition ready in order to create the chain.  They already had those Windows zero-days which got closed last week, yet they still needed a way to deploy them.  And the second that Chrome surfaced a means by which they could, that got chained into an attack, and Kaspersky found their customers being victimized through that brief little window of opportunity.  It's the world we're in today.  Wow.



LEO:  Think most attacks are chained like that these days?



STEVE:  Yeah.  It's really rare - an example of one that isn't, for example, is a credential breach in RDP.  We know that bad guys, in fact, this is how the attack that DarkSide used against Colonial Pipeline, we learned that it was almost certainly a credential for their VPN that was purchased on the dark web.  And so there is was like, wait.  This is the username and password?  Great.  Thank you very much.  And they just logged right into the network.



LEO:  Oh, just [crosstalk].



STEVE:  Exactly.  Exactly.  But what we're seeing is surprisingly sophisticated chained attacks.



LEO:  Yeah, because that wasn't an exploit.  That wouldn't take advantage of exploits.  That was just a breach, you know.



STEVE:  That was actually a front door for which the keys had gotten loose.



LEO:  But exploits are, that makes sense, increasingly chained because one doesn't do it by itself.  But yeah, that makes sense.



STEVE:  Yeah.  And the reason one doesn't is that typically you do have layers of security.  First you're in the Chrome code, so you've got to somehow get out of the Chrome code.  Then once you're out of the Chrome code, then you're still in the sandbox.  Now you've got to get out of the Chrome browser's sandbox in order to have any contact with the operating system.  Once you have contact with the operating system, you've got to be able to do something nefarious with that.  So now you need an elevation of privilege, not only to get out of the sandbox, but then to get into the kernel.  And so it's, yeah, it's a series of things you need.  And what's often the case is that they have a toolkit of exploitable, potentially exploitable pieces where they're just waiting for one more piece to fall into their lap, and then they can put them in a chain and go.



LEO:  Yeah, yeah.  Layered security in response to layered attacks and vice versa.  That makes sense, yeah.  And that's why it's so hard to defend, frankly.



STEVE:  Yes, yes.  And speaking of which, last Tuesday was the industry-wide Patch Tuesday.  And as I noted last week...



LEO:  You mean wider than Microsoft?  Everybody's doing it now?



STEVE:  Yeah, exactly.  As I noted last week, many other companies have decided to synchronize their patch cycles with Microsoft.  And you kind of wonder.  Is it to hide?  It's like, oh, no, everybody's doing it.



LEO:  Yeah, because I don't think it's ideal that you get a bunch of patches in a bunch of different things all at once.  That's just a recipe for disaster.



STEVE:  Yeah.  Intel in this case fixed 73...



LEO:  Oh.  Geez.



STEVE:  Yeah, security vulnerabilities which included some that were severe, impacting the UEFI/BIOS firmware for their processors, as well as their Bluetooth products, their Active Management Technology tools, which as we know runs down on the motherboard underneath everything else.  That's the AMT stuff.  And its NUC mini PC offerings, including some problems in its own security library.  Among other things in the security library there was a problem with a random number generator not being as random as hoped.  So I guess we - how many years have we been talking about these problems, Leo, with insufficiently random, random number generators.



LEO:  At least since the show began.



STEVE:  Yeah.



LEO:  That's why it's called a "pseudorandom number generator."



STEVE:  That's right.  So among those that were fixed, there were some rated critical; though, interestingly, Intel boasted that most were found internally.  Intel's Jerry Bryant, he's the guy who is their spokesman, and we've quoted him in the past.  In this case he said:  "Today we released 29 security advisories addressing 73 vulnerabilities.  40 of those 73, or 55%, were found internally through our own proactive security research.  Of the remaining 33 CVEs being addressed, 29, or 40%, were reported through our bug bounty program.  Overall, 95% of the issues being addressed today were the result of our ongoing investments in security assurance, which is consistent with our 2020 Product Security Report."  To which I thought, that's right, Jerry.  And if only you had found those problems before you deployed the buggy code into the wild, the world would not now need to scramble around to update our now-known defective devices before the forces of darkness are able to reverse engineer those changes to use them against all of the unwitting.  But I suppose better late than never.



Anyone using an Intel NUC  and I happen to be a big NUC fan, and I expect that's going to be my chosen platform moving forward  ought to check to see whether there's an update to their device's firmware waiting for them over at Intel.  Intel doesn't appear to offer a firmware appraisal tool.  I went looking for it yesterday, and there wasn't one that I could find.  So you need to figure out which model of device you have - the good news is you can just turn it over and look at its belly - and which firmware version it's running.  You can actually do that through the Windows Management Instrumentation, the WMI stuff, which I did, in order to get the BIOS version or just, you know, reboot and see what it says as it's coming up, and then see whether you've got the latest available.  Probably worth doing.



By far the winner of this month's critical patch derby was Adobe, who addressed 41 CVEs in their own Patch Tuesday last week.  21 of them were rated critical in severity.  They impacted Acrobat and Reader, Photoshop, Creative Cloud Desktop, their RoboHelp Server, Adobe After Effects, and Adobe Animate.



LEO:  Ai yai yai.



STEVE:  I know.



LEO:  I'm liking this idea less and less.  I mean, gosh, I've got Microsoft, Intel, and Adobe patches all coming in at the same time?



STEVE:  Just give up on Tuesday.



LEO:  That's a nightmare.  It's not good.



STEVE:  And you know, I know that things seem sort of gloomy in the software industry right now.  But really, we should count our blessings that Adobe never decided to do an operating system.



LEO:  Yeah, no kidding.  That's a silver lining, yes.



STEVE:  Can you imagine?  They were never able to make Flash safe.  So thank god we're not, like, some chunk of the industry doesn't have Adobe OS.  That would, you know, no, no.  Just no.  And speaking of operating systems, however, the original second Tuesday patcher, Microsoft, managed to break last month's 16-month low mark, which last month was just 55 flaws, by coming in this month with only 50 or 51, depending upon how one counts.  However, last month had only three zero-days, and this month we have six exploits appearing in the wild.  The vulnerabilities fixed span Windows desktop, SharePoint Server, Windows kernel, and Outlook.



Two of the vulnerabilities are related to a separate vulnerability in Acrobat Reader for which Microsoft released fixes in its Enhanced Cryptographic Provider.  By leveraging those flaws, an attacker could elevate their privileges on the targeted system if they trick a user into opening a specially crafted PDF file using a vulnerable version of Acrobat or Reader from within a not-yet-patched version of Windows.  So that got patched last week.  Microsoft stated in its advisories that it's seen these vulnerabilities being exploited in the wild. 



In other words, they still work.  Adobe had previously fixed this in its previous month's security update.  So if you're using Acrobat or Reader, having both patched would be safest.  That is to say, both Acrobat or Reader and Windows, because it's a combination.  You need problems in both in order to get exploited.  Fix them both.  Again, layers are good.



One of the critical vulnerabilities fixed this month was in the Windows Defender codebase which would have allowed an attacker to execute remote code on the host machine.  The good news is that Defender is continually keeping itself up to date independently, even under Windows 7.  Microsoft's Office MSGraph component also had a remote code execution vulnerability that could be used to deliver a malicious payload to a victim's machine through Microsoft Office, since the built-in MSGraph component can be embedded in most Office documents, which will then exploit the flaw when any one of those documents which has the MSGraph component embedded in it is opened.  So again, these are all ways that email, right, phishing email can attack a user because they just do something that should be fine, but isn't.



LEO:  Ugh.



STEVE:  Yeah.  It's just so wrong.  Another vulnerability being actively exploited - these are all things like, you know, these were all loose already; right?  I mean, Windows users were being hurt by these things, these six different things that got fixed last Tuesday.  In this case, there's a privilege escalation flaw, or elevation, in the DWM Core Library, which is what Microsoft calls it.  DWM is the Desktop Windows Manager.  It can be exploited by running an executable or script on the local machine.  It has a CVSS of only 8.4, so it's bad.  Microsoft only labeled it as "important," even though, again, actively exploited in the wild?  Oh, yeah.  I think maybe you need to get that fixed.



And finally, CVE-2021-31955, that's the flaw that I talked about before relative to Chrome.  That's the flaw that allows an attacker to read the contents of the Windows OS kernel memory.  They called it an "information disclosure."  I call it "game over."  The kernel is the land of exploitable secrets, and Microsoft stated in their advisory that it has also been actively exploited in the wild.  So, yeah, another Patch Tuesday and a few hundred overall, if you consider Intel, Adobe, and Microsoft, a few hundred fewer outstanding bugs in the software the world is using.  That would be a hopeful sign; right?  A few hundred fewer?  If we didn't appear to be creating them anew at an even faster clip than we're eliminating them.



I did know last week, but I didn't have a chance to get to it, but it was in one of those tabs that I had left open in Firefox that I mentioned.  And Leo, you know, unlike you, being "hip" is not a designation I have ever at any prior point in my life laid claim to.  I just never had that.



LEO:  Nor I, Steve.  Nor I.



STEVE:  Well, I don't know.  You're way hipper than I am.  You know what a lot of this stuff is.  All indications are that I'm headed in the other direction.



LEO:  You and me both, bud.



STEVE:  Those who are hip will know that TikTok is a popular short-form video sharing service.



LEO:  Oh, well, I'm that hip, yes.



STEVE:  See?  Okay, yeah.



LEO:  I knew that.



STEVE:  Not I.  You know?



LEO:  Okay.



STEVE:  Anyway, I'm sure that they're not happy that they recently made the tech news press due to a somewhat chilling explicit change in their service's privacy policy.  Okay, now, stepping back a bit, there's some interesting back story here.  It's likely that the recent changes to their privacy policy followed from a $92 million settlement of a class-action lawsuit.  We've talked about the super-tight Illinois Biometric Information Privacy Act, abbreviated "BIPA," B-I-P-A.  Illinois is where privacy lawsuits go to be filed since BIPA, as we've previously covered extensively, pretty much takes no prisoners.



In this case, the lawsuit was originally filed just over a year ago in May of 2020.  And the group of plaintiffs in this suit, which was consolidated from more than 20 separate cases originally filed against TikTok, reached a preliminary settlement just before the end of this February.  The suit alleges that TikTok violates BIPA - and boy, does it - when it collected and shared the personal and biometric information of its users without first obtaining their consent.



Attorney Ekwan Rhow, who is with the firm - and I had to read this a couple times, I kid you not - of Bird, Marella, Boxer, Wolpert, Nessim, Drooks, Lincenberg & Rhow...



LEO:  That's my password.



STEVE:  That's right.  They say use a bunch of words, string them together...



LEO:  Yeah.



STEVE:  Yes.  That probably is one of their passwords.



LEO:  I don't think they're in the dictionary, to be honest with you.



STEVE:  Boy.  Anyway, Ekwan was quoted saying:  "This is one of the largest settlements ever achieved in a consumer BIPA case, and one of the largest privacy class action settlements.  It  presents an excellent recovery for the class, and it serves as a reminder to corporations that privacy matters, and they will be held accountable for violating consumers' rights."  Another attorney in the case, Beth Fegan, added:  "Illinois is on the cutting edge of privacy law, and this settlement enforces those crucial protections.  Biometric information is among the most sensitive of private information.  It's crucial that privacy and identity is protected by stalwart governance to guard against underhanded attempts at theft."  And yeah, I'd love to know,  and you and I, Leo, agree on this also, what portion of the settlement went to the members of the aggrieved class.



LEO:  More than half, guaranteed, yeah, yeah.



STEVE:  And what portion those oh-so-concerned attorneys retained for themselves.



LEO:  Yeah.



STEVE:  But that's beside the point.  And although 92 million is an arresting sum, it's actually small potatoes when measured against Facebook's $650 million BIPA settlement.



LEO:  Wow.



STEVE:  That $650 million settlement was arrived at only after the judge rejected the previous $550 million proposal, arguing that the smaller figure would not be enough to compensate the sheer number of people in the class - probably all Facebook users - based on the penalties laid out in the BIPA law.



Okay.  So of course this is not the first time TikTok has made the tech press news.  They were also in legal hot water when the U.S. federal government was considering a ban on TikTok after privacy experts warned that the government of China might have access to personal information gathered through the app.  Okay.  But in any event, the recent settlement alleged that TikTok was using clandestinely captured biometric and personal data from users in the U.S. to target ads without meeting the informed consent requirements of Illinois's very rigid biometric state law, you know, privacy enforcing state law regarding biometrics.  And we've talked about just how facial recognition, BIPA has been used to slam the door on that.  So as part of the settlement, TikTok agreed to avoid collecting or storing biometric information, biometric identifiers, geolocation, or GPS data unless expressly disclosed in its privacy policy, which of course, fine print, who reads that?  But still.



We have TikTok's new privacy policy which is what has garnered so much attention and concern.  It says:  "We collect information about your approximate location, including location information based on your SIM card and/or IP address.  With your permission, we may also collect precise location data such as GPS."



Then under Image and Audio Information they said:  "We may collect information about the images and audio that are part of your user content, such as identifying the objects and scenery that appear, the existence and location within a image of face and body features and attributes, the nature of the audio, and the text of the words spoken in your user content.  We may collect this information to enable special video effects, for content moderation, for demographic classification, for content and ad recommendations, and for other non-personally identifying operations."  And, finally:  "We may collect biometric identifiers and biometric information as defined under U.S. laws, such as faceprints and voiceprints, from your user content.  Where required by law, we will seek any required permissions from you prior to any such collection."



So TikTok is now, finally, formally disclosing what they weren't before, thus the BIPA class action, which cost them $92 million, that they were presumably doing, collecting biometric information, and then they say "such as," but apparently also not limited to, faceprints and voiceprints.  And it should escape no one that the whole point of biometrics, that is, the metrics of the bio, is identification.  Again, not new information.  But now this is out of the shadows.  And given that only five states in the U.S. currently  that's California, Illinois, New York, Texas, and Washington  have laws which restrict the collection of biometric data, the updated privacy disclosure likely means that TikTok will not be required to obtain explicit permission from its users in all the other states of the U.S.  In other words, users are consenting to have their biometric data collected simply by agreeing to TikTok's terms of service, which most users are just going to say "Yeah, yeah, whatever" to.  So maybe they don't care.  The onus is on the user, of course, to decide, you know, to know what it is they're agreeing to.



On the other hand, that brings us to something else that happened recently that we have not yet had a chance to talk about.  And that's iOS 14.5, speaking of users explicitly agreeing to things.  One of the changes which has been made in iOS 14.5 was it required apps to obtain explicit tracking permission from their users.  It added the provision and the requirement for any apps wishing to track their users' activity across other companies' apps and websites to expressly request and obtain such permission.  Overall, the feedback has been a resounding "No, thanks."



The application analytics company, Flurry, has been sampling 2.5 million users since the release of iOS 14.5.  Their research has shown that the worldwide global "opt into tracking" rate has settled at about 25%.  In other words, 75% of users globally are saying, oh, I have a choice?  Then no thank you.  And users in the United States are even more tracking shy.  For the U.S., the "It's okay, go ahead and track me" rate has settled out at around 14%.  In other words, 86% of U.S. users want to see tracking 86'd from their online experiences.



So you know, Leo, with the anti-tracking stovepiping which Firefox is doing, with Google's moves to sort of, you know, to move from third-party tracking to FLoC, and with FLoC having such problems, I wonder if ultimately this thing, the whole tracking-ness is going to go by the wayside.  It's just going to have been sort of an upheaval that we went through because it happened when we weren't looking.  It happened because people couldn't really see it.  But then some companies started making privacy and non-tracking a feature.  Users decided, you know, we don't want it.  And then when they were asked, they said no.  So if you ask, then it's going to fail.



LEO:  And of course Apple's new iCloud Plus relay system is very much privacy - I think these companies are hearing consumers say we don't want tracking.  The thing that I think is important to note is what Google and others are doing is eliminating third-party tracking.  But at no point has Google said, well, we're not going to track you.  Google first-party tracking, in my opinion all it does is say that the only kind of tracking will be first-party tracking, which means companies like Facebook, google, Apple, Microsoft, all will have a huge dominant position going forward because no one can compete with them.



STEVE:  Right.



LEO:  But they will continue.  That's why Spotify is buying podcast companies, because you can't track in a podcast unless you own the app.  And then you can do first-party tracking.  If you think you watch stuff on YouTube and Google's not paying attention to what you watch, or you look at videos on TikTok, and TikTok's not paying attention to what you watch, you're missing how this stuff works.  That's how it works.



STEVE:  Yup.



LEO:  So I don't think tracking's going away.  I think third-party tracking is going away.  And I don't know if that's exactly the result people intend because all it does is entrenches the incumbents.  And that's not what you want, either, I don't think.



STEVE:  So the news of ANOM was breaking just as we were recording last week's podcast.



LEO:  Right.  And this is something, by the way, I just want to give you credit because a lot - we were talking about this on MacBreak Weekly.  I don't know if you heard.  But everybody jumps on these things so that they can get the hits; right?  Even if we don't know what happened, even if they're going to make up something that's not true.  But you, I give you a lot of credit, resist that temptation and do the research before we start talking about something like this.  And I really appreciate you doing it.  And of course details emerge over time.



STEVE:  Exactly.  So today I'm able to provide a comprehensive description of this classic, though quite high-tech sting operation.  Europol's press release of last Tuesday, the 8th, was headlined "800 Criminals Arrested in Biggest Ever Law Enforcement Operation Against Encrypted Communication."  So the ANOM sting operation, which is known as Operation Trojan Shield by the U.S. Federal Bureau of Investigation, our FBI, was called Operation Ironside by the AFP, that's the Australian Federal Police.  It is/was a collaboration by law enforcement agencies from as many as 20 countries.  It ran from late 2018 when it got off the ground, through just now, 2021.



And during that time the operation intercepted and exploited the intelligence obtained through 27 million messages.  Imagine just processing, I mean, like reading 27 million messages.  You'd want to be like handing them out.  Here's your 10,000 for today.  Have your staff take a look at them.  And here, a different country law enforcement, you take this 10,000 and let us know if you find anything.  So the messages were sent through and intercepted by the supposedly secure smartphone-based messaging app ANOM.  The ANOM service, which was widely used by criminals, was actually a trojan horse, covertly distributed by the U.S. FBI and the Australian Federal Police, the AFP.  It enabled them to monitor all communications taking place across the network.  And finally, through collaboration with other law enforcement agencies worldwide, the operation resulted in the arrest, as I said, and as that headline said, of over 800 subjects allegedly involved in criminal activity across 16 different countries.



Among the arrested people were alleged members of Australian-based Italian mafia, Albanian organized crime, outlaw motorcycle gangs, drug syndicates, and other organized crime groups.  At its height, the ANOM service grew to a service of more than 12,000 encrypted devices being held by over 300 criminal syndicates operating across more than 100 countries.  The platform's goal was to target deliberately, I mean, this whole thing was deliberately created.  And I'll get to that in a second.  Its goal was to target global organized crime, drug trafficking, and money laundering organizations, regardless of where they operated.



Very cleverly, the service was designed to appeal to what the underworld wanted by offering an encrypted device with features sought by the organized crime networks, including things like remote wipe and duress passwords.  We've talked about those before.  Duress passwords are those which could be given when a bad guy is under duress, which would have the opposite of the intended effect.  It would wipe rather than unlock a device.  So you could just see them rubbing their hands together.  It's like, oh, goodie, this has the features that we need.  These features gradually persuaded criminal networks to adopt the device, thus the way it became so widespread.



And the way this happened is the stuff of spy novels.  First, the shutdown of the Canadian secure messaging platform Phantom Secure in early 2018 left international criminals who were using it in need of an alternative system for secure communication.  And around the same time the FBI branch office in San Diego, California was working with a person who had been developing his own next-generation encrypted device for use by crime, by criminal networks.  That individual had been nabbed and was facing charges.  So he cooperated with the FBI in exchange for a reduced sentence.



He offered to develop ANOM and to then distribute it to the underworld through their existing networks with which he was familiar.  The first communication devices with ANOM were offered by this informant to three former distributors of that now shut down Phantom Secure system starting around October of 2018.  So that's when this all began to get off the ground.  The FBI also negotiated with an unnamed third country to set up a communication interception, but based on a court order that allowed passing the information back to the FBI.



LEO:  That's because the FBI's restricted on how it can collect information on U.S. citizens.



STEVE:  Exactly.



LEO:  So this is a real backdoor to that.



STEVE:  Exactly, uh-huh.



LEO:  But okay.



STEVE:  Yes.  Since October 2019, ANOM communications have been passed on to the FBI by this third country, exactly as you said, Leo, to get around our own laws.  During the culmination of ANOM's operation, a series of large-scale law enforcement actions were executed - that's what just happened a week ago - across 16 countries, resulting in more than 700 residential searches, more than 800 arrests, and the seizure of over eight tons of cocaine, 22 tons of cannabis and cannabis resin, two tons of synthetic drugs (amphetamine and methamphetamine), six tons of synthetic drug precursors, 250 firearms, 55 luxury vehicles, and over $48 million in various worldwide currencies and cryptocurrencies.  And innumerable spin-off operations are still planned for the weeks to come.



LEO:  The reason this all happened at once is I think that the jig was up; right?  Somebody tipped them that these ANOM phones weren't secure.  And so they had to roll it up, roll up the network, yeah.



STEVE:  Right.  And you'd have to do the whole thing at once.



LEO:  All at once, yeah.



STEVE:  Yes.  So Wikipedia had some interesting background information about the ANOM devices.  Wikipedia said:  



"The ANOM devices consisted of a messaging app running on smartphones that had been specially modified to disable normal functions such as voice telephony, email, or location services.  After checking that normal functionality was disabled, the messaging apps then communicated with one another via supposedly secure proxy servers, which then copied all sent messages to servers controlled by the FBI.  The FBI could then decrypt the messages with a private key associated with the message, without ever needing remote access to the devices.  The devices also had a fixed identification number assigned to each user, allowing messages from the same user to be connected to that user.  According to a since-deleted Reddit post discovered by Motherboard, the ANOM app was for Android.  A WordPress blog post described the app as using a custom Android OS."  



LEO:  That makes sense.  What else are you going to use?  Yeah.



STEVE:  It does, yeah.  "About 50 devices were distributed in Australia for beta testing from October 2018.  The intercepted communications showed that every device was used for criminal activities, primarily being used by organized criminal gangs.  Use of the app spread through word of mouth, and was also encouraged by undercover agents.  Drug trafficker Hakan Ayik was identified 'as someone who was trusted and was going to be able to successfully distribute this platform,' and without his knowledge was encouraged by undercover agents to use and sell the devices on the black market, further expanding its use.  After users of the devices requested smaller and newer phones" - hey, Rev. 2.



LEO:  Hey, yo, this phone is really big.  You got an iPhone, man?  I don't know why I'm using this big old thing.  You know what the best part is?  They charged them $2,000 every six months to use the phone.  Which is brilliant; right?



STEVE:  Beautiful.  Brilliant, yeah.



LEO:  Don't give them away because then people might not trust them.  Oh, I paid $2,000 for this.  It must be something.



STEVE:  Must be some deep crypto in this thing.



LEO:  Some good stuff on here, man.



STEVE:  That's right.  This is really uncrackable.



LEO:  Oh, uncrackable.  It's expensive.



STEVE:  It's interesting that the most commonly used languages on the app were Dutch, German, and Swedish.



LEO:  Oh, interesting, huh.



STEVE:  "So after a slow start," writes Wikipedia, "the rate of distribution of ANOM increased from mid-2019.  By October 2019, there were several hundred users.  By May 2021, a month ago, there had been 11,800 devices with ANOM installed, of which about 9,000 were in active use.  New Zealand had 57 users of the ANOM communication system.  The Swedish Police had access to conversations from 1,600 users, of which they focused their surveillance on 600.  Europol stated 27 million messages were collected from ANOM devices across those 100 countries."  And then the article concludes:  "Some skepticism of the app did exist.  One March 2021 WordPress blog post called the app a 'scam.'"  And Leo, that may be something like what you're referring to where people were beginning to say, uh, really?



LEO:  Yeah.



STEVE:  And anyway, I would call it a significant success.



LEO:  Notably, the guy you mentioned, the Turkish drug lord who really spurred the growth of this, has not been arrested.  He's living apparently a lavish lifestyle, I think is what the Australian police said, in Istanbul.  And I guess because he's in Turkey they can't arrest him.  But very wise, the AFP says, you know, Hakan, everybody thinks you set them up.  It might be wise to turn yourself in now because either we're going to get you, or they're going to get you.  So we'll see.  I have to say, though, it does raise the issue of why authorities want backdoors in devices.  I mean, this is a goldmine for them.  And immediately in Australia more laws were passed to encourage backdoors in encryption because...



STEVE:  Yeah, I mean, that's one of the big focuses on the podcast is the question, what's going to happen with this? 



LEO:  I think it's a big PR victory for the AFP and the FBI.  And I think that's really what this is mostly about.  But we'll see.  Let's watch the prosecutions.  I mean, it's a lot of this is pot.  Come on, man.  It's actually legal in many states in the United States.



STEVE:  Yeah.  And of course the reason for the success, I'm sure our listeners already got this, is that this was distributed explicitly to criminal gangs.  And every message, every transaction was being monitored.  That's not something that our FBI could do under any circumstances in the United States.  The most that I can see happening is that the equivalent of a search warrant, a highly targeted search warrant, where a judge, hopefully a judge with judgment, agrees that there is probable cause to believe that something wrong is going on.  And so selective decryption or tapping, very much like an old-school phone tap, right, where the FBI says we need to bring up a phone tap on these people because we need information that we have reason to believe we will get there, not we're going to monitor every conversation of everyone in the country.  Which with the much smaller ANOM group is what was happening.  So it's going to be really interesting how this shakes out.



LEO:  Yeah, no kidding.



STEVE:  So, Errata.



LEO:  Never.  Never.



STEVE:  Windows 10, the last Windows ever?



LEO:  Yeah?



STEVE:  Apparently not.



LEO:  No.



STEVE:  I was absolutely certain that we were clearly and formally told by representatives of Microsoft...



LEO:  Yes, I know.



STEVE:  ...that following Windows 8.1, the next Windows, to be called 10, would be free, would create - and remember this? - new revenue opportunities for Microsoft.  In other words, that users of this next Windows would become profit centers themselves for Microsoft.  And that it would be the last version of Windows ever.



LEO:  We've all been saying that.



STEVE:  Yes.



LEO:  Over and over.



STEVE:  And I was stunned last week during Windows Weekly, in her conversation with you, Leo, and Paul, when Mary Jo Foley said, "Uh, nope.  Microsoft never said that."



LEO:  Unh-unh.



STEVE:  And so I put this under Errata since...



LEO:  Jerry said it.  Jerry said it.



STEVE:  Exactly.  Since if I had been spreading an unfounded rumor, at least I wasn't alone.



LEO:  No, I said it, too, many, many, many times.  You probably got it from me.



STEVE:  Yeah, well, that's what we all believed.  Rich Woods of XDA Developers, he tweeted on the 11th last week, he said:  "The most mind-blowing news story from this week was broken by @maryjofoley on Windows Weekly..."



LEO:  Oh, thanks, Rich.



STEVE:  "...and it's that Microsoft never said Windows 10 was the last version of Windows.  One developer evangelist said it, Microsoft never corrected it, and everyone ran with it.  It became lore," wrote Rich.



LEO:  I said it on the radio all the time, so I guess I'm going to have to do an errata, too.  Thank you.  You're right.  Error.



STEVE:  So it turns out that back in 2015, Microsoft's developer evangelist Jerry Nixon stated that Windows 10 was the last version of Windows.  Quoting him exactly, he said:  "Right now we're releasing Windows 10.  And because Windows 10 is the last version of Windows, we're all still working on Windows 10."  In other words, he said that "we're releasing it" and "we're still working on it," clearly implying that Windows 10 would be an ongoing effort.  And indeed, that what's we've seen.  It would be difficult to say with a straight face, however, that this has all gone smoothly, what with Windows 10 2004 being released in 2010.  What?  Anyway, what a mess.



Last Wednesday, Mary Jo Foley explained that Microsoft themselves never publicly said, in plain language, that Windows 10 is the last version of the Windows operating system.  Their developer evangelist Jerry Nixon said it, and backed it up with evidence at the time.  And as Mary Jo noted, Microsoft's PR team never denied it.  So no one said he was wrong.  Maybe they thought it was the last one.



LEO:  You can even read, though, now that I'm reading the actual quote, you could even read that like the latest version of Windows.  Like it's not necessarily we're not - it's not explicitly we're never releasing another version.



STEVE:  True.



LEO:  It's the last version of Windows.  Well, it is.  It's the last version of Windows; right?  I mean...



STEVE:  So far.



LEO:  It is still the last version of Windows.  Not the last of all ever.  Just the latest, as in last as in latest.  So I'm not even sure Microsoft realized that he had said something that people would interpret that way.  So I don't know how, but this is very common in our industry, any industry; you know?



STEVE:  And you know, Leo, it may have just been we're just so tired that we were hoping it was true.



LEO:  We want it to be.



STEVE:  Please, oh, god, please.



LEO:  We all want it to be the last ever.



STEVE:  Just please stop.  Stop the madness.



LEO:  That's why it took off.  We all wanted it to be the last version.  I think that's exactly what happened.  We were hoping it was the last version.



STEVE:  Oh, oh, does this mean what I think it means?



LEO:  I don't think - and by the way, if you listened to that show, you heard Paul, Mary Jo, and I talk about what Windows 11's going to be, and none of the things you and I would like it to be, which is more secure, more reliable, rewritten from the ground up, all of that.  It's just going to be a nice thin glaze on top of the old doughnut.



STEVE:  Yes.  Apparently if by mistake you bump into the corner of a window, it will no longer draw blood.



LEO:  Yeah.  That's it.  That's exactly right.  No sharp corners.  It's a childproof version of Windows.  It looks very Mac-like, according to the releases that have come out in the last day.



STEVE:  Well, good.  I like the way the Mac looks.  It could use a little bit of an upgrade.



LEO:  It's pretty, yeah.



STEVE:  I did want to follow up once again, real briefly, on "Project Hail Mary."  Lorrie loved the book.



LEO:  Oh, good.



STEVE:  She blew through it, as I knew she would.  At one point she was standing - I just had to chuckle.  She was standing in front of the stove, reading the book with it open in front of her as popcorn was popping.



LEO:  See, that's why I do audiobooks.  I invariably pop my popcorn listening to an audiobook.  I'm completely with her on that.



STEVE:  Yeah.  And I will say she, because she's just such a dear heart, she got a little choked up at the end.



LEO:  Oh, yes, very touching.



STEVE:  With the way everything turned out.  I thought, oh, honey, that's cute.



LEO:  But actually Lisa - so Lisa had the same reaction.  Loved it.  And she said, "Give me another one like this."



STEVE:  I know.



LEO:  What do you suggest?



STEVE:  Well, and this is - perfect segue.  I wrote in my notes, seeing that she loved it so much, I gave her the first of the Honor Harrington books.  But after a couple of hours she asked whether the entire book would be about military space ordnance.



LEO:  By the way.



STEVE:  And I said...  



LEO:  Yes.



STEVE:  Uh, yeah.  There's a lot of that.



LEO:  It's not a woman's sci-fi book, I don't think.



STEVE:  No.  So now she's reading Daniel Suarez's "Daemon."



LEO:  Good choice.



STEVE:  And that one may be a hit.



LEO:  I think so.



STEVE:  She did, she's read enough of it that last night she said, "This is creepy."  And I said yeah, yeah.



LEO:  The thing that Lisa likes about Andy Weir's books, both "The Martian" and "Hail Mary," is the humor, the humanity of it.



STEVE:  Yes.



LEO:  And I've been trying - and first I thought, maybe the "Ringworld" series by Larry Niven.  But she said, "No, it's too old.  I want something newer."  So I said maybe Peter F. Hamilton's "Fallen Dragon."  But I think it's a little dry.  I think she wants something more human scale.  So I'm open to any suggestions for her, something recent.



STEVE:  Yeah, and "Hitchhiker's" is too slapstick.



LEO:  Yeah, I don't know if she'd like that.  Yeah.  I know what she likes because the thing about "Hail Mary" is very similar to "The Martian" in the sense that the protagonist has this great wry style and sense of humor.  Very much that sense of humor is what she likes.



STEVE:  What about "Artemis" in the middle?



LEO:  "Artemis" is good.  I think she gave up on it.  She tried it, didn't like it.



STEVE:  Yeah, and I'm the same way.  I don't know of anything else like that.  Normally sci-fi is, well, I mean, there's like New York Times Bestseller sci-fi.  I read something awful, can't even remember now what it was.



LEO:  It's always got lurid covers with monsters' wrapped tentacles around buxom women and stuff.  It's not good.



STEVE:  Yeah, it's not good.



LEO:  It's not good.  Actually Stacey Higginbotham has recommended a series that I just bought on Amazon.  I'll let you know.  You might like it.  I think unfortunately there's a considerable amount of space ordnance in it, which means you and I will enjoy it.  But I don't know if it's for everyone.  Let me see if I can find the name of that series because she really thought it was good.



STEVE:  Well, and of course Suarez's "Daemon" is not about that at all.



LEO:  No.



STEVE:  It's on Earth, and it's like creepy possible future.



LEO:  It's so fast moving and fun and just wonderful.  She recommended the - it's by Arkady Martine.  It's a series, the first book of which is called "A Memory Called Empire."  And the series is the Teixcalaan series.  But just remember Arkady Martine.  It's written by a woman.



STEVE:  You know, Lorrie may have never read the "Foundation" series.



LEO:  See, I think that's wonderful.  And I know Lisa hasn't.  But she'll say it's too old.



STEVE:  Oh, gosh.



LEO:  I know.



STEVE:  And it's going to be, have you seen the previews of what's coming from...



LEO:  Oh, no.



STEVE:  The "Foundation" previews?



LEO:  Oh, I'm going to go look at those as soon as the show's over.



STEVE:  Oh, Leo.  Oh, oh, oh, oh.  It's - oh.



LEO:  Now, have you read it recently?  Because I think, as great as that series is, it may...



STEVE:  I need to reread it.



LEO:  It may feel a little dated.  Somebody told me that they went back - this is not unusual.  You go back to old sci-fi, and times have changed a little bit.  Heinlein's really a good example of that, where it just feels dated.  So I don't know if - I don't know.  But I'm going to go watch those.  That's great.



STEVE:  Okay.  So I think our listeners will find this interesting.  A colleague of Lorrie's had his laptop stop booting.  It contained irreplaceable data - of course, old story - that had not been backed up. 



LEO:  Of course.



STEVE:  He had a whole bunch of EEGs which had been recorded and were there.  His Ph.D. thesis.  And it just - it wouldn't boot.  So he and Lorrie were chatting, and she said send it, you know, Steve will take a look at it.



LEO:  Wow.  That was nice of her.



STEVE:  And of course I was happy to.



LEO:  Oh, good.



STEVE:  And so it was actually three weeks ago today because it arrived on a Monday.  And so I brought it with me here on podcast Tuesday.  And it was sitting right here to my left.  And I had turned it on in the morning when I was still working on the podcast.  And it came up.  Everything looked good.  I got the little 3D blue Windows thing.  It had Windows 10.  Oh, it was a Lenovo, a P51s.



LEO:  Oh, that's a nice laptop.  That's a good, solid laptop.



STEVE:  Yes.  Absolutely beautiful solid laptop.



LEO:  Yeah.



STEVE:  And so I got the little spinning white dots, the little rollercoaster dots, and they spun a while.  And then it came up with that unhappy smiley face or frowny face, with an error I'd never seen before:  WHEA_UNCORRECTABLE_ERROR.  And I thought, oh, okay.  So then it said, don't worry, we're going to fix this for you.  And so it rebooted itself, and it went into the automatic repairing Windows, and it did that for a while.  Then it came up and said, "Could not fix your problem.  Try recovering your drive."  And so now I got the screen where you had multiple options of, like, restoring from a system restore, uninstalling recent updates, backing up to an image that had been made, those sorts of things.



Oh, and I forgot, I had googled "whea uncorrectable error."  And of course as Mr. SpinRite, "uncorrectable" sounds like a sector; right?  And I didn't know.  But googling didn't produce anything definitive.  For example, Microsoft was saying, oh, this could be caused by a recent update, so back out of any updates.  So I thought, well, okay.  So I tried that.  It wouldn't work.  I tried uninstalling, I mean, like nothing succeeded.  Very quickly, when I tried any of those things, it said can't do.  So I thought, okay, what are my BIOS options?  Rebooted the system.  It had diagnostics built in.  So I thought, oh.  So ran the diagnostics.  And everything except the mass storage, the storage entry, it failed.  It failed retests.  And so I thought, okay, well, that sounds like the hard drive is having problems.  So, yeah.  So then I booted my little Ubuntu Linux in order to...



LEO:  Oh, you're just warming the cockles of my heart there.  You've got your little USB key with Linux on it. 



STEVE:  And it's got a nice persistent file system.  So I'm able to install other things on it and sort of build a tool set over time.



LEO:  That's not the standard installer disk.



STEVE:  Correct.



LEO:  The live boot CD.  You actually made a real Linux system on there.  Nice.



STEVE:  Correct.  And in fact, because I'm still sort of a newbie, I stumbled around doing that.  And for anyone who's interested in following along, the latest Rufus has...



LEO:  Yeah, Rufus is great, yeah.



STEVE:  It has a slider on it where you're able to slide how much space you want to make persistent store.  And it does all the work for you.



LEO:  Oh, nice.



STEVE:  When it sets up a bootable thumb drive.  So after trying to manually create a file system like three or four times, and it kind of didn't work or it took too long or something, I stumbled on Rufus, and it's like, yeah.  You just slide the thing from the left where it's no persistent storage.  You slide it over to - I think I cut it in half.  So because it was a 32GB thumb drive, I made it 16GB of persistent store.  And it works perfectly.



LEO:  I'm going to have to try that.



STEVE:  It's just an overlay.  It's an overlay file system.



LEO:  So you actually are using the live CD ISO.



STEVE:  Yes.



LEO:  You're not installing it on the key.  Because that's what I would have done is just run the Linux installer.  And instead of installing it on a hard drive, install it on the USB key.  But you're actually using the live CD with some storage because normally it's a read-only volume.



STEVE:  Yes.  Exactly.



LEO:  Oh, interesting.  What a good idea.



STEVE:  It's really cool, and Rufus makes it like full GUI, just click here, thank you very much.



LEO:  Rufus.ie, a really good product.  Free.  Nice.  Really does a good job.



STEVE:  And it's being maintained continually.  I don't use it often, and typically it sees that there's a newer version of it and says, hey, you know, you might as well use that one.  I go, oh, okay.  And you don't even install it.  It just - it's an EXE.  It's like one of my...



LEO:  It's like one of yours.  It's probably written in assembler.



STEVE:  Okay.  So actually it's not.  It's open source, and I did look at some of its source when I was working on SpinRite's AHCI controller, AHCI driver to see if there was anything I could learn from it.  And I ended up - or maybe it was the - I think it was when I was working on the USB boot stuff because Rufus is also a formatter.  But it turns out mine is able to fix some thumb drives that Rufus still won't install on.



LEO:  Oh, interesting.  Ah, that's also good to know.



STEVE:  Okay.  In any event.



LEO:  Yes.



STEVE:  The Smartmontools stuff, it turns out, isn't useful for NVMe.  So you need to load an NVMe command that isn't normally part of the Ubuntu set.  So I did that, and I was able to look at the NVMe drive.  But it still seemed it was having some problems.  So open up the laptop, take out the little NVMe.  It was a nice Samsung OEM NVMe.  I stuck it into an NVMe-to-PCIe adapter and put it in a different machine.  Booted that up in Linux, and it could see it.  Oh, I also stuck it into an NVMe-to-USB adapter and plugged it into my Windows 7 machine.  Up it came, showing the drive looking fine.  It showed three partitions.  The UEFI boot partition in the big middle was the C drive with BitLocker.  So it was BitLocker encrypted.  And then at the very end was the WinPE, the recovery partition.



So the drive hadn't died, or at least didn't look like it had a problem.  Looked like it was okay.  So it's like, oh, okay.  So but I couldn't do anything with it because of course it was BitLocker encrypted.  And this laptop was Secure Boot, BitLocker encrypted.  It apparently came from Lenovo with Windows 10 installed and Secure Boot and BitLocker.  So that was a problem because I did have some dialog asking whether he had the backup key, the BitLocker recovery key.



LEO:  Yeah, it uses a certificate system for encryption.  And if you don't back that up, uh-oh.



STEVE:  Yes.  And because it uses TPM, it was tied to that hardware.



LEO:  That's right.  That's right.



STEVE:  So only being in that laptop would allow BitLocker to decrypt.  I asked him, do you have paperwork come with it?  Because I figured if Lenovo gave him a laptop that had BitLocker already enabled, they would have printed out that - it's a 48-digit BitLocker recovery key, which you need in order to decrypt a BitLocker partition if you don't, you know, if it's not in the native machine that it came from.  Anyway, he was absolutely sure he didn't have it.  I said, okay, what about OneDrive?  Because one thing that happens is, if you log into OneDrive, Windows 10 is supposed to back up the BitLocker recovery key to your OneDrive.  He looked.  It wasn't there.  I said, what about an earlier - because this was now 2018.  How about earlier?  He checked a different Microsoft account, also no BitLocker keys.  So he was absolutely sure he didn't have it anywhere.



Okay.  Meanwhile, I ran, to get a sense for the condition of the drive, I then ran the DD command in Linux using /dev/null as the output.  So basically it just did a read scan of the entire NVMe.  It was a 1TB Samsung NVMe.  I set the block size to 60MB because that's a good size.  And it read through the entire thing without error.  So plugged into...



LEO:  Ooh, that's good.



STEVE:  ...that other machine, booted Linux.  Yup, absolutely good.  Booted Linux, worked fine, without error.  So Linux is saying, just from a simple read scan...



LEO:  Hardware's good.



STEVE:  Hardware's good.  There is no problem with this drive.  And plugged into the USB adapter, my Windows 7 machine said, yeah, I see three partitions.  The middle one's BitLocker.  That's going to be a problem unless you've got the key.  But we're okay.  I mean, so the boot sector and all that stuff is there.  So I think, okay, plug it back into the laptop.  Doesn't work.  Go to the diagnostics.  Oh, he did not have the latest BIOS.  I updated his BIOS on the laptop.  It gave me much better diagnostics than it was originally shipped with, more detailed and many more tests.  And again, would not pass a retest.  It failed failed on the reads.  And then there were some other tests of just the NVMe itself, and those it passed.  But it would not read.  So then I thought, okay.  So maybe the NVMe slot has died.  So I took a different NVMe drive, plugged it in, works perfectly.  So this drive works fine elsewhere.  Another NVMe drive in the laptop, it works fine.  But this drive and the laptop won't work together.



LEO:  I have a feeling I know where the end game is on this one. Go ahead.



STEVE:  So here's the problem.  He needs the data.  It's BitLocker-encrypted.  He's sure that the key, the recovery key, doesn't exist anywhere.



LEO:  You've got to get this drive working.  There's just no way around it.



STEVE:  Got to get the drive working.  And the only instance of the key known to exist is in the Trusted Platform Module on the motherboard.



LEO:  You have to get it working on that P51.  No way around it.



STEVE:  Exactly.  Exactly.



LEO:  Well, I know what I would do.



STEVE:  And so the only thing I could think was that, like, how do you explain this weird drive behavior is that something bad happened, like age, just an age-related problem where the signal levels of that, that is being generated...



LEO:  Maybe just one cell.  Just one cell.



STEVE:  Well, or a signal line is a little bit out of spec.



LEO:  Oh, on the whole drive.



STEVE:  Such that this drive, yeah, like this drive and this particular interface chip in the laptop are no longer talking to each other.



LEO:  Interesting.



STEVE:  A different drive, no problem.  And it in a different machine, no problem.  But not those two.



LEO:  Yeah, because that WHEA error is a Windows hardware error.  So that's why you would think, well, there's a hardware problem here.



STEVE:  Right.



LEO:  That's interesting.



STEVE:  Right.  And so what was happening was the drive was just going offline.  It was not passing its diagnostics.



LEO:  Yes, can't talk to me, yeah.



STEVE:  So I told him, I said, look.  Talk to Lenovo.  If it came from them, maybe they have a record of the BitLocker recovery key.  You'll have to prove that it's your ownership and so forth in order to get them to do that.  So he spent a lot of time on the phone.  They instructed him to take it to one of their partners, one of their, like, corporate partner companies, not really even a consumer company.  And so I was getting ready to pack it up.  And I said, you know, there's one more thing I want to try.  It probably won't work.  But I've got to rule it out.  This other little piece of hardware is coming tomorrow.  I'm going to see if it does the job.  Because it had a Thunderbolt 3 port.  And I remembered that Thunderbolt - and we talked about this on the podcast.



LEO:  DMA access, yes.



STEVE:  Yes.  Thunderbolt is actually the PCIe bus.  It is a hybrid of the PCIe bus and display port.  And of course what's happened with PCIe is the reason we went from PCI to PCIe is that interconnect became too expensive.  As more stuff was happening, it no longer made sense to have - you couldn't have a 64-bit address bus on a 64-bit system, and a 64-bit data bus.  That was just - that would be 128 bits of, like, individual  wires.  So we went from a parallel bus architecture to a serial bus architecture, where now, instead of putting a whole bunch of things on a bus, you flip it over, and you make the bus be serial, and you then have a one-to-one relationship between the processor chip and each individual device in the system.  Well, the Thunderbolt port is one of those.  Amazon delivered a Thunderbolt 3 to NVMe case.  And the first one I ordered was wrong because it worked on USB.  So the second one, I had to make sure, and they did say this will not work on USB.  It looks like USB3.  It's not USB3.  It's Thunderbolt.



LEO:  Good.  Good.  Good idea.



STEVE:  So that's like, yes, yes.



LEO:  That's what I want.



STEVE:  That's the one I'm trying.  I put it in the case.  I plugged it in, and it booted.



LEO:  So your diagnosis was something wrong with that NVMe slot, that M.2 slot, timing on the pins.  So putting in an external connected NVM3 reader on the PCIe bus...



STEVE:  Because that's Thunderbolt.



LEO:  Thunderbolt.  TPM would still say, oh, I recognize that?



STEVE:  It did.  It recognized the drive.



LEO:  It decrypted it?



STEVE:  Yup.



LEO:  And you were able to read it.



STEVE:  Yes.



LEO:  Unbelievable.  What a story.  See, I thought you were going to end with SpinRite, you were going to SpinRite the thing.  But it really was a hardware error.



STEVE:  It was a hardware error.  The drive was fine.  They just wouldn't talk to each other on that connector.  



LEO:  That is bizarre.



STEVE:  Yeah.  And I said to him, I said, you know, frankly...



LEO:  You're lucky.



STEVE:  Yeah.  



LEO:  You're lucky I exist, is what he would say.  No one else is going to solve that, no.  That's a great story, Steve.  Boy, he is really lucky he knows you because...



STEVE:  Well, and of course the first thing I did, I made an image of it because, I mean, it was like this data was so crucial.



LEO:  Yeah, yeah.  Yeah, yeah.



STEVE:  I made an image of it.  He was desperate for some of it, so I installed the remote utilities and let him access it remotely to pull the files off that he needed.



LEO:  Wow.



STEVE:  Then after I had an image safely, I removed BitLocker, just to get rid of it because, thank you anyway, this is too important.  And I ended up shipping - I called it "the sidecar."  I actually, because it was running a little warm, I glued some...



LEO:  Heat sinks.  Nice copper heat sinks on there.



STEVE:  Some nice copper heat sinks to the top of the case.



LEO:  You're such a geek.  Wow.



STEVE:  Because he was going to be using it from now on.



LEO:  Oh, no.  Really.  I guess he has to; right?  He can't fix that laptop.



STEVE:  Well, maybe he could put a different NVMe drive in.  But I wouldn't trust it.  I would never trust it again.  So he has the laptop.  And he's also not financially constrained. 



LEO:  Get a new one, yeah.



STEVE:  I mean, he could instantly - he'll get a nice Carbon X1 or who knows what. 



LEO:  Lenovo should fix that, though.  The problem is proving to them that your obviously correct diagnosis is what's going on.  That's just amazing.



STEVE:  At this point it's old, and it's time.  But so anyway, he has it back.  It's got its cute little - basically the drive has been externalized.  So, I mean, and boy is it fast.  And that's another lesson.



LEO:  Sure, it's 40Gb.



STEVE:  I mean, it's running at the full speed of this drive.



LEO:  Yeah.  I love Thunderbolt.  That's amazing.



STEVE:  Yeah.  So what I told him is, use it like this as long as you want to.  You'll have to keep them together wherever they go.  Eventually...



LEO:  You're going to look a little weird.



STEVE:  Eventually, when you do replace, yeah, replace the laptop.  And then what's cool is you plug this into another laptop that also has a Thunderbolt 3 interface, and you'll just be able to copy the stuff over to migrate yourself to a new laptop.  So anyway, a cool story, which I thought you and our...



LEO:  Really wonderful story.  And kudos to you.  He's lucky because basically you're a hard drive wizard.  I would never have thought of that being, oh, there's a timing issue on the pinout.  I mean, that's remarkable.  But you did all - had you already ordered that M.2 external?  Or you ordered it because you thought this might be the solution? 



STEVE:  I ordered it because.



LEO:  Yes, okay.



STEVE:  I just thought, you know, Thunderbolt is - we've got Thunderbolt, and it's a PCIe.  Maybe it'll fool the laptop into thinking, oh, it's still plugged in.  



LEO:  Thinks it's an internal drive, yeah.



STEVE:  Yup.



LEO:  So it booted to it and everything.



STEVE:  Booted right up.  Didn't even complain.  I mean when I saw the little thing spinning, I thought, okay, well, here comes the blue screen.  And instead I got the blurry logon screen.  It's like [gasp], you know.



LEO:  It worked.



STEVE:  And I, I mean, and he was actually in tears.  He got choked up on the phone with me.  He was in tears with Lorrie.



LEO:  Wow.  You saved his life.



STEVE:  Because, I mean, it was his Ph.D. thesis was there.  A whole bunch of irreplaceable biomedical data was there. 



LEO:  He's very, very lucky that you were the guy he brought it to.  No one would have gotten that.  That's wild.  That's a great story.  Bravo.  Golf clap.  Would you like to take a break?



STEVE:  I'm going to do that, and then the TLS Collision Attacks.



LEO:  That was exhausting.  I'm exhausted just listening.  What a story.  I mean, that is really incredible.  I'm going to have to tell that on The Tech Guy.  That is just an incredible story.  Thing is, when I do, because I have to answer questions like this on the radio frequently, is I store away the knowledge that that's even possible.  I would not have thought that that pinout could somehow, some little issue with the pinout on the motherboard and that stock M.2 drive made it unreadable over time...



STEVE:  They just stopped liking each other.



LEO:  That's a bizarre error.



STEVE:  Yeah.



LEO:  But now it's in my mind, you know, if that happens again, I'll keep that in mind.  That is wild.



STEVE:  I guess the takeaway for our listeners...



LEO:  Back up.



STEVE:  Make sure you have BitLocker, that BitLocker recovery key.  Check right now.  And I will absolutely be setting him up with Sync.  He was like selectively using Dropbox and OneDrive, but not ubiquitously.  And for what it's worth I'm...



LEO:  Would you give him Syncthing, or Sync.com?  What do you think you'd use?  Because he's got HIPAA requirements.  I mean, if there's X-rays on there, things like that.



STEVE:  True.  True.



LEO:  He's got a requirement.  That's probably why he - I bet you he turned on BitLocker.  I doubt Lenovo ships with BitLocker on.



STEVE:  That would be interesting to know.  He says it's not something he ever did.  But he's also...



LEO:  That was years ago.  He might not remember.



STEVE:  Yeah, it was a long time ago.  I wanted to remind our listeners that I'm still loving Sync.  I use Sync, and I use Syncthing separately.  Grc.sc/sync, S-Y-N-C.  That is a referral link which will get you an extra gig.  Rather than five, you get six if you use that link, grc.sc/sync, S-Y-N-C, if you want to play with it.  It perfectly keeps my multiple locations synchronized.  The reason I like it is that it's also in the cloud, and it does versioning, like infinite versioning.



LEO:  And it's TNO.



STEVE:  Yes, it is.



LEO:  Trust No One.  End-to-end encrypted.



STEVE:  It is Trust No One, encrypted locally.  They can't get to it.  HIPAA-compliant.  And you're able to generate links for things you want to share, which allow other people to have the decryption occur at their end on the fly.  So, very cool.



LEO:  I'm signing up right now.



STEVE:  And Leo, before I forget about it, I just got a note from a Twitter follower who told me that Syncthing, the different peer-to-peer syncing that you and I like, just added encrypted folders.  So that means you're able to sync to a machine that is untrusted, if you ever have a need to do that.  You're able to assign a long password to a folder.  And when it syncs remotely, it will be encrypted before it leaves under that key and then decrypted as it comes back.  But everything stored in that synchronized folder will be encrypted, which is not a feature that Syncthing has had until now.  So it just got it.



LEO:  That's good to know.



STEVE:  Yeah.



LEO:  Yeah, I use Syncthing everywhere, all the time.  That's really my, well, it's not my primary backup, but it's one of my several backup systems because basically I have, just like you, you have multiple machines, multiple locales, and you want to have your source code directory synchronized everywhere.  I have my source code, my sync files, my dot files, my documents, my pictures, and my audio, all synced to all systems.  And it's a great way to do it.  It's peer-to-peer.



STEVE:  And if you have a Linux-based NAS, as I do, because I've got Drobos in each location, then I've got Syncthing running natively on the Drobos, and they're just pulling stuff.  They sync each other, and I sync to them.



LEO:  So that is a pretty good backup strategy.  Yeah, I do that on my Synology.  They have a community-based version of Syncthing available.



STEVE:  Nice.



LEO:  Looks like I already signed up for Sync.com.  I didn't even notice.



STEVE:  It is, it is...



LEO:  It's a terrible name, by the way.  They really - they should call it AvocadoSync or something just so that you would - because you can't google it.



STEVE:  Well, and think how much they must have paid for that domain, to have Sync.com.  However, the reason it would be right for John is that I don't think he - he's sort of a nomad.  He's not really a deep computer geek.  Syncthing is a little - you need to kind of know your way around, you know, things.



LEO:  It's geeky, for sure.



STEVE:  And it just, yeah, and it just does it to the cloud.  And so his entire documents folder would just be synced using Sync, and he just would never have this problem again.



LEO:  Oh, I remember why I don't use Sync.com.  No Linux client.



STEVE:  Ah.



LEO:  Get them to work on that.  Now, ladies and gentlemen, it's time for our titular topic of the day.



STEVE:  So I titled this TLS Confusion Attacks for reasons that'll become clear.  Some very interesting and quite depressing research will be presented at the forthcoming 30th USENIX Security Symposium and this summer's Black Hat USA in Las Vegas about six weeks from now, at the end of next month.  And even though it's not entirely new, it teaches us some interesting lessons about unintended edge case consequences.



Now, the researchers apparently struggled to come up with a cute name for this.



LEO:  Uh-oh.



STEVE:  Since the problem - yeah.  Since the problem they were exploring was the mischief that could be created by deliberately confusing the application layer within TLS-authenticated and protected connections, they had "Application Layer Protocol Confusion," ALPC.  Which is, you know, not really anything.  But if you add a pair of judiciously...



LEO:  Oh, god.



STEVE:  Yeah, add a pair of judiciously placed gratuitous A's into that, you can force this to become A-L-P-A-C-A.



LEO:  ALPACA.  At least it's memorable.



STEVE:  And that explains why I chose to name this podcast "TLS Confusion Attacks."



LEO:  But alpacas are so cute, Steve.



STEVE:  Well, regardless of their name, these attacks, they're a truly interesting instance of an unintended consequence edge case.  Or to use the official term, "Oops."  Here's what happened.  In the beginning, we had the UDP and TCP IP protocols.  UDP was mostly used for DNS.  But over the TCP protocol we ran TELNET and FTP and SMTP and POP and IMAP and HTTP, you know, and others.  Those were the so-called Application Layer protocols running on top or inside of the TCP Transport Layer.  And back then the world was simple.  But it was not secure.  Passive eavesdroppers could listen in on passing Internet packets to see what everyone was up to, so there was no assurance of privacy.  And active man-in-the-middle attackers could redirect traffic to other destinations without detection, so there was no authentication.



But we're clever.  So we grafted on SSL, which over the years evolved into TLS.  The idea was that our existing plaintext application protocols would be given different ports when their TCP connections should be authenticated and encrypted.  So HTTP over port 80 became HTTPS over port 443.  FTP's port 21 became FTPS over port 990.  And SMTP's port 25 became port 587 whenever TLS would be used to secure the SMTP protocol.  When using these alternate secured ports, immediately after establishing that famous three-way TCP handshake, a sort of shim would be introduced in between the TCP transport layer and the application protocol layer.  Before any application layer traffic would be allowed to flow, the two endpoints would need to exchange another set of packets to cryptographically establish the identity of one or both of the endpoints, thus providing endpoint authentication, and agree upon an encryption key that they would henceforth use to encrypt all subsequent communications, thus providing communications privacy.



Problem solved?  Pretty much, but not entirely.  The problem was, and has always been, that the SSL/TLS protocol is bound to the TCP connection, but not to the underlying application layer protocol whose traffic it is carrying.  In other words, the TLS protocol itself is unaware of the IP and port to which it is connecting.  The TCP protocol knows about that, but not TLS.  It's naive to that.  So it does the same thing if the connection is to HTTPS as if it was to secure SMTP.  TLS doesn't care at all.  But the underlying application protocol does care which port it's connected to because that determines which service it's talking to.  And therein lies the edge case.  Since the TLS is not bound to the connection's IP and port, they can be changed, and TLS won't care.  It won't even notice.  But since the underlying protocol does care, that creates a problem.  And this opens what appeared to be a safe and secure system to what the researchers term "cross-protocol attacks."



Here's what the abstract of their paper explains.  It says:  "TLS is widely used to add confidentiality, authenticity, and integrity to application layer protocols such as HTTP, SMTP, IMAP, POP3, and FTP.  However, TLS does not bind a TCP connection to the intended application layer protocol.  This allows a man-in-the-middle attacker to redirect TLS traffic to a different TLS service endpoint on another IP address and/or port.  For example," they write, "if subdomains share a wildcard certificate, an attacker can redirect traffic from one subdomain to another, resulting in a valid TLS session.  This breaks the authentication of TLS, and cross-protocol attacks may be possible where the behavior of one service may compromise the security of the other at the application layer."



Okay, so let me pause for a second.  What they're saying is that if, for example, GitHub were to use the same TLS certificate for HTTPS as for their Secure SMTP, it might be possible to redirect an incoming user's web browser connection, which is intended for GitHub's HTTPS port 443, to their secure SMTP port 587.  And because the same TLS certificate will be used to negotiate the connection's TCP security either way, it may be possible to take advantage of this protocol level confusion.



Okay.  So continuing with their abstract.  They say:  "In this paper, we investigate cross-protocol attacks on TLS in general and conduct a systematic case study on web servers, redirecting HTTPS requests from a victim's web browser to Secure SMTP, IMAP, POP3, and FTP servers.  We show that, in realistic scenarios, the attacker can extract session cookies and other private user data or execute arbitrary JavaScript in the context of the vulnerable web server" - in other words inject script - "therefore," they write, "bypassing TLS and web application security."



They finish:  "We evaluate the real-world attack surface of web browsers and widely deployed email and FTP servers in lab environments and with Internet-wide scans.  We find that 1.4 million web servers are generally vulnerable to cross-protocol attack, i.e., TLS application data confusion is possible.  Of these, 114,000 web servers" - so just shy of one out of every 10 - "can be attacked using an exploitable application server. Finally, we discuss the effectiveness of TLS extensions such as Application Layer Protocol Negotiation (ALPN) and Server Name Indication (SNI) in mitigating these and other cross-protocol attacks."



Okay.  So the main takeaway here is, I think, that not only is security difficult, it's even significantly more difficult than we know.  In fact, it might be even more difficult than we can know.



LEO:  Than we can.  That's the problem. 



STEVE:  Yes.



LEO:  Yes.  Your giveaway was when you said, "But we're clever."  Yeah, that's the giveaway.  Don't get clever.  Yeah.



STEVE:  Yeah, never get clever.  So to put this into context, okay, this is not the end of the world.  The attack requires sophistication and the ability to establish a man-in-the-middle position, the ability to actively manipulate the traffic coming and going from a victim in real-time.  But it's certainly within the reach of state-level attackers, and it does mean that users are not really obtaining the security that we think we've always had.  These attacks also require a very specific set of circumstances.



The researchers described what they uncovered.  They said:  "In practice, cross-protocol attacks are sensitive to many requirements, such as certificate compatibility, ability to upload, download, or reflect data, and application tolerance towards syntax errors caused by mixing two protocols in one channel."  Yeah.  So, I mean, it's an edge case.  They said:  "In our case study of cross-protocol attacks on HTTPS, using Secure SMTP, IMAP, POP3, and FTP application servers, we address these concerns in three evaluations.



"First, we identified 25 popular SMTP, IMAP, POP3, and FTP implementations and evaluated their suitability for cross-protocol attacks on HTTPS in a series of lab experiments.  We found that 13 of the 25 are exploitable with at least one attack method.  We also implemented a full proof of concept that demonstrates all three attack methods on a well-secured web server, using exploitable SMTP, IMAP, POP3, and FTP application servers.



"Second, we evaluated seven browsers for their error tolerance.  We find that Internet Explorer and Edge Legacy still perform content sniffing, and thus are vulnerable to all presented attacks."  Okay, so by content sniffing they're meaning, and I couldn't believe this, IE and Edge Legacy look at the protocol text to determine what the protocol is.  That is, does this look like HTTP?  Or does this look like FTP?



LEO:  They just call it "deep packet inspection" and then...



STEVE:  You're kidding me.  That's - you're kidding me.  Anyway, they said, "...while all other browsers allow at least FTP upload and download attacks.  And, third, in an Internet-wide scan, we collected X.509 certs" - which are the standard web certs - "served by SMTP, IMAP, POP3, and FTP servers.  We analyzed how many of these are likely to be trusted by major web browsers."  In other words, are they using the same certs?  GRC does.  It's easy.  And they're good, so why not?



"For each certificate, we extracted the hostnames in the Common Name field and the SAN."



LEO:  Storage Area Network.



STEVE:  Server, no, Alternate Names, yeah, Server Alternate Names, yeah, extension.



LEO:  Oh, okay.  We have unfortunately acronym overload here.



STEVE:  We do.  Well, because when you're only going to use three letters, you're in trouble.  "And checked if there exists" - ALPACA, that's pretty safe.  "And checked if there exists a web server on these hosts."  They said:  "We found," and here's where this number comes - "1.4 million web servers that are compatible with at least one trusted application server certificate," meaning that the same certificate is crossing between applications, web and mail, web and FTP, whatever.  They said:  "... making them vulnerable to cross-protocol attacks.  Of these, 119,000 web servers are compatible with an application server that is exploitable in our lab settings."



Okay.  So this is bad.  What can be done?  It's a decidedly mixed blessing.  Because while it's unlikely to occur, given the proper conditions, it can.  And when it's exploited, it can result in logged-on session hijacking because you're able to read the browser cookie, the session cookie which is supposed to be unreadable, otherwise we're back in the, what was that, it was Firesheep.  Remember those innocent days of yore, Leo?



LEO:  Yes, yes, yes.



STEVE:  You could go to Starbucks and just hop onto other people's login sessions.  We were so innocent back then.



LEO:  Oh, yeah.



STEVE:  And, okay.  And if you can inject malicious JavaScript, then you're running that malicious JavaScript in the context of the fully trusted web server, which means you can do anything.  The fact that it's unlikely to occur, unfortunately, reduces the pressure to make any changes.  Right?  There's not like Heartbleed or, for example, in Dan Kaminsky's famous fix for DNS, which only required that the DNS servers be fixed.  The changes that need to be made here have to occur at both ends of the TLS connections.  So all the clients and all of the servers.



There is currently a well-defined solution for this.  It's called ALPN.  That stands for Application Layer Protocol Negotiation.  It does exactly what its name sounds like, and what we need.  It's an optional extension for TLS connection setup, which allows the endpoints to explicitly agree upon the protocol that the connection will be carrying.  That's the thing that's missing from TLS now is that nothing tells TLS what it's going to be carrying.  But ALPN, an optional extension, does.  And it turns out that it does this without needing any additional packet roundtrips or anything.  It's just added to the existing TLS as one of the extensions in the already well-defined packets.



And since support for the HTTP/2 protocol needs to be able to smoothly upgrade an HTTP/1.1 connection to HTTP/2, in other words, that's exactly what we need here.  We need the HTTP/2 server to be able to negotiate an HTTP/2 connection with the other endpoint, only if both endpoints agree.  This is now being done via ALPN to the degree that HTTP/2 has been deployed.  So ALPN support is already emerging.



However, protection from web-based protocol confusion attacks, that is, these kinds of attacks, requires that all TLS connection-accepting services, which could be unwitting participants in protocol confusion, meaning all FTP servers, SMTP, POP3, IMAP, and so forth, also support ALPN and flatly reject and terminate any non-ALPN enhanced connections.  And I can't imagine a world in which that's ever going to happen.  I just, you know, it's hard enough to get moved from IPv4 to IPv6.  This is like, well, probably no one's going to get abused by this, and it's a theoretical attack, and really we have to replace everything, and we don't get any protection until we mandate that everybody do it, and anybody that doesn't gets hung up on?  No.  I don't recognize that world.  That's not the one we're in.  So we can imagine that future non-web services might begin to incorporate ALPN awareness, but that's entirely different from, as I said, refusing connections from remote clients that are not offering ALPN-enhanced TLS.  The outlook is not good.



They conclude their own paper, saying:  "We demonstrated that the lack of strong authentication of service endpoints in TLS can be abused by attackers to perform powerful cross-protocol attacks with unforeseeable consequences."  And now this is where Bruce Schneier's "Attacks never get worse, they only ever get better" is ringing in our ears.  We may be revisiting some new consequence that has been literally, these guys said, "unforeseeable."  So something unforeseen may emerge from this.



They said:  "Our Internet-wide scans showed that it is common" - I'm guilty - "for administrators to deploy compatible certificates across multiple services" - why not, seemed like a good idea - "possibly without consideration to cross-protocol attacks."  Yeah, I didn't think about that.  "We also showed that cross-protocol attacks are practical, although the impact is limited and difficult to assess from lab experiments alone. In the real world, cross-protocol attacks will always be situational and target individual users or groups.  However, it is also clear that existing countermeasures are ineffective because they do not address all possible attack scenarios.  We have identified one countermeasure that is far superior to others:  the pervasive use of the ALPN extension to TLS by both client and server.  Luckily, ALPN is easy to deploy with the next software update without affecting legacy clients or servers."



So, yeah, that's true.  You could put it out there, get it in place, and wait for everyone to have it, and then flip the switch to make it mandatory.  But again, it is only - it's necessary to make it mandatory, to actively refuse any non-ALPN-enhanced connections.  And I don't know if that's going to happen in our lifetime.  So I wanted to put this on everyone's radar because we may be coming back.  There may be ALPACA 2.



LEO:  Wow.



STEVE:  Yeah.  Unforeseen.  Like nobody ever said, I mean, it seemed like wrapping our TCP connections in TLS...



LEO:  Seemed like a good idea.



STEVE:  What could go wrong?



LEO:  Right.



STEVE:  Well, as I said, the official term is "oops."



LEO:  It's subtle, though.  I mean, I could see how you might miss it.



STEVE:  Yeah, yeah, yeah.



LEO:  Wow.  But that's the problem is we've gotten to the point now where any flaws...



STEVE:  The stuff is so confusing.  It's so complicated.



LEO:  Yeah.  That's what it really is.  It's these multiple interactions.  It's the complexity of the system is almost chaotic at this point, in which case you can't - if it's unpredictable, you can't do it right.  Interesting.



STEVE:  Yeah, I agree.  I agree.  I think that's a good analogy.  I think we are approaching chaos.  Formal, mathematical chaos.



LEO:  That is not - you're right.  Now I am depressed.  I was all happy because you solved the most impossible problem I've ever heard.  And now you just ruined it.  Steve Gibson, he's the guy.  Man, is he the man.  I'll tell you what, go to GRC.com.  He's got lots of great stuff there, free stuff, of course his bread and butter, SpinRite, the world's best hard drive, I'm sorry, mass storage recovery and maintenance utility.  I was sure that other story was going to end with a spin drive.  But you threw me a curve.  You threw me a curve there.  There's nothing wrong with the drive.  Very clever.  This is the guy you want working on your hard drive, trust me.  Did I say "spin drive"?  I meant SpinRite.  Apparently I said "spin drive."



STEVE:  We knew, we all knew.  Yeah, the most downloaded thing at GRC until 6.1 is available is the DNS Benchmark.



LEO:  Yeah, I'm not surprised.



STEVE:  3,000 downloads a day, every single day, day in and day out.



LEO:  It's a really good way to - because people I think are starting to realize they don't want to use their ISP's DNS servers.  But they don't want to use a slow one, either.  And so they want to - so they're thinking about Cloudflare or Quad9's or NextDNS.  There are a lot of them now.



STEVE:  And how would you know?



LEO:  How would you know which is the best?  So test it.  That's a great free download.  Steve's very generous.  A lot of great stuff there.  GRC.com.  He's also on Twitter at @SGgrc.  That's where you can DM him, slip into his DMs.  They're open.  You can also message him at GRC.com/feedback; right?  Yeah, GRC.com/feedback.  His forums are great, too, forums.grc.com.  Is that right?



STEVE:  That's correct, yeah.



LEO:  Steve, have a wonderful week.  We'll see you next time on Security Now!.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#824

DATE:		June 22, 2021

TITLE:		Avaddon Ransonomics

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-824.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week, believe it or not, we have yet another zero-day stomped out in Chrome.  We also have some additional intelligence about the evolution of the ransomware threat.  I also want to closely look at a curious WiFi bug that was recently discovered in iOS and what it almost certainly means about the way we're still programming today.  Under our Miscellany topic I want to share the SHA-256 hash of the developer release .ISO of Windows 11 that Paul Thurrott, I and many others have been playing with this past week.  I have a tip about creating an offline account and restoring Windows 10's traditional Start Menu under Windows 11.



A new purpose has also been discovered for this podcast which I want to share, and I've decided to explain in more detail than I have before what I've been doing with SpinRite's evolution  it's much more than anyone might expect  yet no more than is necessary.  Then we're going to conclude with the view of ransomware from Russia, from two Russian security researchers who believe they know exactly why the Avaddon ransomware as a service decided to shutter its operations and publish its keys.



SHOW TEASE:  It's time for Security Now!.  We've got a great show for you.  Steve's got a big SpinRite update.  All the deets coming up.  There's been another Chrome zero-day.  What is that, the sixth or seventh this year alone?  And then we're going to talk about ransomware, the economics of ransomware.  So two reports, one on how ransomware works and the other on how ransomware figures out how much to charge you.  All that's coming up and a whole lot more, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 824, recorded Tuesday, June 22nd, 2021:  Avaddon Ransonomics.



It's time for Security Now!.  Ladies and gentlemen, the moment you've all been waiting for, the host of our show, the star, Mr. Steve Gibson, here to protect you online.  Hello, Steve.



STEVE GIBSON:  Hello, my friend.  Great to be with you for our, oh, it's not our last, our penultimate podcast of June, having learned a few years ago what "penultimate" actually means.



LEO:  Now he uses it every chance he gets.



STEVE:  That's right.  So this is #824 for the 22nd.  I titled this "Avaddon Ransonomics."  I had to look at that Ransonomics word a few times.  It's what the Russians who wrote the article we will be talking about mostly used.  Very interesting.  Another less-in-the-spotlight, but still a little too much, major Ransomware as a Service enterprise has shuttered themselves.  And what's interesting about this one, we have a lot of - I pulled from a bunch of different sources before I quote some Russians that I found.  Another Ransomware as a Service group saying we're going to stop this.



Now, it's also been noted, and I did not have this in my notes, or didn't make it into the notes, that it looks like when these guys shutter themselves, there's some notion of an opportunity vacuum that's created which other groups step in to fill.  So it's not like the problem's all gone away.  And it also may be that this is just a change of identity.  Like they're saying, oh, sorry about that, blocking all of your gas and...



LEO:  Dave's not here, man.  Dave's not here.



STEVE:  Yeah, exactly.  And then they pop up under another name.  So anyway, we're going to talk about that.  But first this week, believe it or not, we have yet another zero-day stomped out in Chrome.  



LEO:  What?  My god.



STEVE:  Yeah, I know.  It's tough being number one.  We also have some additional intelligence about the evolution of the ransomware threat that I want to share.  I want to closely look, and I know that you guys talked about it, although I didn't hear it, but I know you did on MacBreak Weekly because the percent esses were part of the proposed names for...



LEO:  Such a hoot.



STEVE:  Yes, it is.  So a curious WiFi bug that was recently discovered in iOS and what it almost certainly means about the way we're still programming today.  I'm sure I'll have a different take on it than you guys did, just because I'm a coder.



Under our Miscellany topic, I want to share the SHA-256 hash of the developer release ISO of Windows 11, which Paul Thurrott on Wednesday, I, and many others on the Internet, and many in GRC's newsgroup, have been playing around with this past week.  And I'm sharing the SHA-256 hash so that if somebody wants to get it, they'll know that they've got a valid one.  I also have a tip about creating an offline account under 11 and also restoring the traditional Start Menu, which those who are using Windows 10 have gotten used to and who are grumbling about the way they changed everything in Windows 11.  Anyway, we'll be talking about Win11.  So rather than being like the author of Never10, as I famously was before, now I'm ahead of the game.



LEO:  Yeah, what the hell?  This is not the Steve Gibson I grew up with.



STEVE:  So a new purpose, Leo, has also been discovered, and this is big news, for this podcast, which I want to share.



LEO:  Have you discovered your special purpose?



STEVE:  I've discovered an unexpected application for the podcast.  And I've decided to explain in a little more detail than I have before - because I've received some people saying "Where the hell is SpinRite 6.1?" - what I've been doing with SpinRite's evolution, which it's much more than anyone might expect, yet no more than is necessary.  But it turns out what's necessary is more than a point release.  But that's what I promised.  Anyway, then we're going to conclude with the view from Russia.  I almost titled this "From Russia With Love," but I thought, well, I'd already hit print on the PDF.  



LEO:  Oh, that would have been fun.



STEVE:  That would have been fun.  Anyway, two Russian security researchers who believe they know exactly why the Avaddon Ransomware as a Service decided to shut down, and gave just shy of 3,000 of its attacked keys to BleepingComputer.  Lawrence Abrams has them.



LEO:  Good.



STEVE:  And of course we have a fun Picture of the Week that is apropos of what we'll be discussing when we get to Windows 11.  So I think another great podcast for our listeners.



LEO:  Nice.  Lots of good stuff coming up.  All right.



STEVE:  Okay.  Our Picture of the Week.



LEO:  Picture of the Week, yes.



STEVE:  I gave this the caption "Windows 11," and everyone will see why.  We have a four-frame cartoon.  The first frame we have the guy saying, "Let's make these changes to the current system."  And he's holding out what looks like a long list of things.  And she is now holding the list, and she says, "The current system works just fine."  And then in the third frame, "Why do you keep making pointless changes?"  And of course the answer is - he sort of is walking away, looking a little downtrodden, saying, "To keep justifying my ongoing employment."  So uh-huh.



LEO:  Uh-huh.



STEVE:  Why do you keep making pointless changes?  Well, we'll be talking about Windows 11 and its pointless changes.



LEO:  I think you're actually closer than - this is actually closer to the truth than people might really understand, yeah.



STEVE:  Yes.  Are we done yet?  Oh, no, boss.  Oh, no.  No, no.  No.



LEO:  Got to justify my existence.  I'm busy.  I'm busy.



STEVE:  Yeah, I've got a whole new look for the trash can, so hold on.  Okay.  So another day, another Chrome zero-day.  As I said last week, this is what it's like to be the world's number one web browser.  With glory comes some bruising.  We're not yet finished with the first half of the year, yet CVE-2021-30554 is the seventh actively exploited in the wild zero-day that the Chromium team has patched so far this year.  We're now at v91, and some other stuff in the middle, and it ends in .114, for all three desktops, which was released last week.  It resolves four security vulnerabilities including that -30554 which was a high-severity, use-after-free vulnerability occurring in WebGL, the Web Graphics Library, which is a JavaScript API used for rendering interactive 2D and 3D graphics in the browser.



As it's formally described - and, you know, this is the boilerplate for these things.  "The successful exploitation of the flaw could mean corruption of data, which might lead to a crash, and even execution of unauthorized code or commands."  Okay.  But we know that the bad guys are not going to be interested in corrupting some data or crashing the user's browser.  They want executing some commands of their own choosing.  Since this vulnerability was being actively exploited in the wild, in this instance we can ignore the lesser possibilities for abuse and go right to remote code execution as having been achieved and exploited.



And if the CVE number 30554 sounds familiar, that may be because 30551 was the previous zero-day, fixed just 10 days earlier.  This particular issue was reported to Google anonymously exactly one week ago, on the 15th.  And this .114 release of Chrome occurred just two days later, on Thursday the 17th.  This highlights the point I made last week about the turnaround speed that's required from today's web browser deployment developers.  They don't sleep so that we can.



In the show notes I have the six previous zero-days.  There was one on February 4th, then the next one on March 2nd, then March 12th.  Then we have April 13th, April 20th.  May somehow skated by because we had one in late April and one in early June.  And then the last one, the sixth one, on June 9th.



So Shane Huntley, the director of Google's Threat Analysis Group, tweeted two weeks ago on the 8th, so that was the day before the sixth zero-day.  And he said something at the end I don't quite understand.  Maybe you can figure out what he means, Leo.  His tweet was:  "I'm happy we're getting better at detecting these exploits and the great partnerships we have to get the vulnerabilities patched.  But I remain concerned about how many are being discovered on an ongoing basis and the role of commercial providers."



LEO:  You mean like Google?  Who do you mean?



STEVE:  Yeah, I don't know what that - and "the role of commercial providers."



LEO:  Maybe he's not talking about Chrome exploits.  I mean, that's bizarre.



STEVE:  Isn't that weird?  It's like...



LEO:  Commercial providers.



STEVE:  And so I put a link to his...



LEO:  Oh, I know what it is.  Maybe not all of these are being discovered by Google's Project Zero, but by other security providers, like Kaspersky and so forth.  And that's who he's thanking.



STEVE:  Ah.  "But I remain concerned about how many are being discovered on an ongoing basis and the role of commercial providers."



LEO:  Well, he shouldn't be concerned about that.  He should be grateful.



STEVE:  Yeah, yeah.



LEO:  Maybe he means commercial malware providers.  I don't know what he's talking about.  That makes no sense at all.



STEVE:  Yeah.  So anyway, I put his Twitter feed link in the show notes.  And I thought, what?  And so I went there and like read around his other, like maybe I could get a clue from what he'd said before or after that tweet.  So I found it on June 8th and read in the region, but no.  I have no idea what he meant.  So he is a character.  His photo made me think, like, well, okay, you do look like...



LEO:  That's a good-looking fella.  Yeah.



STEVE:  Anyway, so thank you, Shane, for these last five minutes of the podcast.  We have no idea what it is you're talking about.



LEO:  Go back to work, Shane.



STEVE:  But for what it's worth, we're concerned, too, about how many are being discovered on an ongoing basis because you're breaking records, and not the kind we'd like you to be breaking.  Keep finding them.  But how about stop making them?  That'd be better.



Okay.  So as we have been noting, ransomware perpetrators are increasingly purchasing their access.  The security firm Proofpoint has been tracking the ransomware underground for many years.  And I meant to put a link to their posting because they had a cool graphic, like showing all the interconnectivity of all the actors, TA-850, you know, Threat Actor 850 and Threat Actor blah blah blah.  And then, like, which malware droppers they were using and who they were attacking and blah blah blah.  Anyway, last Wednesday they released a report titled "The First Step:  Initial Access Leads to Ransomware."



The report detailed the means by which ransomware attackers are increasingly partnering with unaffiliated cybercrime groups to obtain access to high-profile targets.  Oh, you found it, yay.  Perfect.  This is the trend that we've talked about previously.  This was the way we believe the Colonial Pipeline attack began; remember?  An existing VPN logon credential was purchased on the dark web by a DarkSide affiliate, and that was used to gain entry into Colonial Pipeline's internal network.  Proofpoint's research confirms this trend, but puts a little more meat on the bone.



They explain that, they said:  "Ransomware threat actors currently carry out" - and oh, by the way, this is a new term, "big game hunting," so we'll be encountering that term a little bit later - "carry out big game hunting," although I have a feeling that that's the trend that's going to be changing as a consequence of the fact that the big game turned out to be loaded for bear and could shoot back.  Anyway, "...conducting open-source surveillance to identify high-value organizations, susceptible targets, and companies' likely willingness to pay a ransom."  I thought that was interesting.



LEO:  This animated GIF is cracking me up.  The hacker apparently does this over several days period of time.  I'm sorry, I didn't mean to interrupt, but I'm watching this.  It's bizarre, the way they're attacking.  Go ahead, I'm sorry.



STEVE:  So they said:  "Ransomware threat actors can leverage existing malware backdoors to" - oh, I'm sorry.  "Working with initial access brokers" - that's the other new term.  So we have big game hunters and initial access brokers.  "Working with initial access brokers, ransomware threat actors can leverage existing malware backdoors to enable lateral movement and full domain compromise before successful encryption."  They said:  "An attack chain leveraging initial access brokers could look like the following."  And so they have seven points.



First, a threat actor sends emails containing a malicious Office document.  Number two, a user downloads the document and enables macros, which drops a malware payload.  This is like exactly the scenario we've highlighted in the last couple weeks.  Three, the actor leverages the backdoor access to exfiltrate system information.  And four, at this point the initial access broker can sell that access to another threat actor.



LEO:  Ah.  So he's already in, but he's not going to do anything with it himself.



STEVE:  Right.  Exactly. 



LEO:  Wow.



STEVE:  So five, the actor then who purchased the access from the initial access broker deploys Cobalt Strike via the malware backdoor access, which enables lateral movement within the network.  Six, the actor, meaning the ransomware affiliate, obtains full domain compromise via Active Directory.  And then, seven, the actor, the ransomware affiliate, deploys ransomware to all domain-joined workstations.



So just like an organic virus which mutates to improve its chances of survival, we see here a similar mechanism of action.  Anything which works to maximize the ill-gotten revenue of malign actors will be reinforced.  So in this instance we're seeing growing evidence of increasing specialization within the ransomware business model.  We first saw ransomware gangs doing their own work.  Then the affiliate model appeared to create much larger and broader ransomware franchises.  We expect to soon see more formalized dark web escrow services as uninterested third parties are created to manage and apportion ransom payments among these different actors.  And now we're seeing the emergence of IABs (Initial Access Brokers) as the ransomware affiliate role divides and further specializes into initial entry and post-entry exploitation.



For many years on this podcast we've observed the situation that malware was present.  Like, a lot of it, everywhere.  It would get into a router border device and would typically set up a bot in a router that would contact a command-and-control server to await instructions.  And remember how I've said several times something like, "At the moment, the bad guys are focused upon the outside.  They appear to be curiously uninterested in whatever network they've gained access to."  And I observed that at some point that would change, and that things would then get a lot worse.  We're seeing the beginning of that, as those initial access brokers, I mean, even like labeling themselves that, start to inventory the systems they have long had access to, but haven't had any means of monetizing, other than perhaps having the device participate in a cryptocurrency mining pool.  



But now the networks behind those routers belonging to corporations of significant but lesser size will be examined as potential plunder targets.  One of the lessons that has been learned by the ransomware denizens is that, if you want to remain viable, it's far better to avoid what we might call "the Colonial Pipeline mistake."  And we'll be talking about that in a second, toward the end of the podcast.



So basically what that means is that attempting to hold infrastructure at ransom, while it may appear at first to be the mother lode, brings with it far too much unwanted political and law enforcement attention.  It is far better to sneak around under the radar, siphoning off and aggregating many more much smaller ransoms.  The REvil gang's subsequent attack on JBS Meat Packing was another such mistake.  Sure, they netted $11 million dollars, but they also got the U.S. to start considering ransomware to be terrorism.  And while Putin may bluster, shrug, and attempt to laugh it off, you have to know that he would have been made uncomfortable by the U.S. President facing him down one-on-one and making clear that this will not be allowed to continue.



My point is that carrying out 11 $1 million attacks against non-name-brand targets who no one has ever heard of would have been far wiser in the long run.  The ransomware affiliate model, enhanced with initial access brokers and third-party escrows, is evolving to enable exactly this.  It allows for scaling up the number of attacks while maintaining efficiency as the size of individual attacks is reduced for the purpose of staying clear.  This creates a blur which neither politicians nor law enforcement will lock onto the way they locked onto Colonial Pipeline and JBS.  It will tend to make many fewer headlines, and that's the point.



And remember back a few years ago when we were talking about how the networks of managed service providers were being compromised; and their clients, and one example stands out, like networks of dental offices were being held for ransom.  Those were much less sexy attacks, and no one cared much.  The local FBI would have been engaged, but those attackers never became big news.  We watched them on this podcast and were aware of them, but they were not cocktail party and casual dinner conversation.



I said earlier that anything which works to maximize the ill-gotten revenue of malign actors will be reinforced.  The clear takeaway from the recent high-profile attacks is that those were a mistake, and we have to know that the entire ransomware industry watched and learned.  What they learned was that the way to get rich is to streamline the system.  Don't attack big. Attack small and attack more.  Distribute the pain and distribute the influx of cryptocurrency.  To remain under the radar is to remain in business.  The gangs that learn that lesson and keep their money-grubbing affiliates in check are the ones who will remain active in the long run.



Okay.  So a weird and fun bug hit iOS.  An interesting and somewhat humorous bug was discovered in iOS's parsing of network SSIDs.  There's long been a concept in programming languages, at least since FORTRAN because I recall it being there, of using a so-called format string to describe the shape of the contents of either incoming input to a computer, or the way some output variables should be formatted for presentation on output.  So, for example, an output greeting might be formatted as a string, "Hello %s," where when that format string is used, the "%s" tells the computer that the next argument to the function is assumed to be a pointer to a string.



In this case, the "%" is known as an escape character, and the character or characters that immediately follow it specify the details of the format.  The "%" is called an "escape" because it signals the text parser to stop treating the input string at that point as literal text sent to the output, and instead, to insert some special formatting control.  So, for example, "%d" might tell the parser to treat another argument as a date and to format it accordingly.  And if the programmer wants to actually output a "%," then "%%" is often used.



Okay.  With that bit of background, a security researcher who was poking around at iOS somehow discovered, and don't ask me how, he's like, well, let's try this, see what happens.  He discovered that if a WiFi network's SSID name, you know, the name that you see in public when it comes up in a list of you can join any of these networks.  So that's the name that the beacon is broadcasting, the SSID.  If it is set to "%p%s%s%s%s%n" - so percent sign p, then four esses, percent sign esses, and then percent sign n - and an iOS device then attempts to join any WiFi network having that name, the device's WiFi would become immediately and semi-permanently inoperative.  A restart/reboot would have no effect, and all logon attempts to reverse the change would fail.  Any attempt to reenable the WiFi subsystem to fix the trouble would immediately crash before the user could use the subsystem to resolve the problem.



So this is one of those things that's sort of our collective fault in the security business, and more broadly the programming business, really, by choosing a programming design pattern which places convenience way in front of security.  One of the things that must be done, when a string that's under the user's control might be processed by code that's parsing for escape sequences, is for the user-provided string to be explicitly "de-escaped" first.  In the example case I provided above, this would mean doubling up any "%" characters so that they would be seen as the percents that they were apparently intended to be, rather than as the active "escape sequence" which would cause the parser to reach for a subsequently provided argument which, in this case, would be absent and would almost certainly lead to a crash.  So what must first have happened is that the SSID string which itself looked like escape-formatted text, confused some formatting parser somewhere in iOS and likely caused the internal WiFi system to completely hard crash, and crash and crash and crash.



So the concern was that, as news of this spread - and, I mean, every tech site that I saw had fun spreading the news.  The concern was that, as news of this spread, annoying jerks would immediately begin exploiting the discovery.  And indeed that did happen.  Postings began to appear telling naive users that they could obtain much faster WiFi by renaming their access points accordingly.  Shhh.  Don't tell anyone.  And of course when they did that, all their iOS devices crashed.  Fortunately, after some additional experimenting, it was discovered that the devices' WiFi function could be restored by going to Settings > General > Reset > Reset Network Settings.  That would flush out all of the existing sticky stuff and resolve the problem. 



So how did we get into this trouble in the first place?  We would really have to say that it was lazy language design.  The practice of mixing special-meaning control text in with literal text is nothing less than a kludge.  Some form of separate out-of-band specification should be used to govern such formatting.  Mixing those functions together into a single stream is a recipe for disaster.  So why do we do it?  We do it because it is so much easier to do it that way.  And as a result, many languages do.



Recall that when an HTTP GET query contains arguments, they take the form of a question mark followed by the name, an equal sign, and then a value, so-called "name=value pairs," and they're joined with an equal sign.  And those name-value pairs are separated by ampersands.  But what do you do, how do you have a name or a value containing an equal sign or an ampersand?  Once again, we're mixing literal text with control characters.  It can be done safely.  I lived in that world throughout SQRL's development since there was a lot of that going on.  And I was terrified of making any mistakes there because they would almost certainly be devastating and because, you know, it's so easy to make a mistake.  Languages, protocols should not be designed so that it is easy to, I mean, like you almost have to do it wrong.  And it's so difficult to do it right.



And indeed, countless mistakes have been made through the years with this HTTP formatting since the very beginning by web programmers who were not being sufficiently concerned and cautious.  Because, you know, the system is begging you to make a mistake.  And while I'm certain that the details of iOS's WiFi are different in detail, and that the problem will be trivial to repair, it does appear that exactly this problem is what just bit Apple.



LEO:  So is - pardon me?  Go ahead.



STEVE:  I was going to ask if the MacBreak Weekly guys had any additional specific information.



LEO:  No, I explained that it was a format string.  %p is a pointer.  So what you would do normally is a printf, and you'd put the format string in, and then you'd follow it by the things that correspond to each of the items.



STEVE:  Of the arguments; right.



LEO:  You'd have the pointer.  %s is an alternative string, so you'd have four strings.  And then you'd have a new line.  I'm guessing that what that actually got interpreted is as a pointer with four zeroes, in other words, a null pointer; right?  And that crashed it.  But who knows?  Maybe they do some URL encoding with it?  They're doing something weird with it.  And you're right, why aren't they sanitizing those inputs?  It's easy.



STEVE:  Yeah, yeah.  I mean...



LEO:  You don't trust everything that comes in over the transom.



STEVE:  Yeah.  Again, and that's the point, is you shouldn't have to, the language design should not be such that it's this easy to make that mistake.  This mistake keeps happening over and over and over because the language design is insecure.  It's lazy.  It's so easy and convenient that that's what many languages do.



LEO:  And I'm guessing that it is C that whatever code is handling it is written in, or Objective C maybe.  But that was the whole point of C was it lets you do anything.  Dereference pointers, reference pointers, point to any part of memory, you know, allocate memory at random, overrun it at any point.  That's the point of C.  C lets you do anything.  It's very powerful.



STEVE:  Right.  And it's very popular because programmers are jocks.



LEO:  We love it.  C's great.



STEVE:  You know, get out of my way.  I don't want any garbage...



LEO:  And I won't make a mistake.



STEVE:  I want to collect my own garbage.



LEO:  Yeah.  Stay out of my garbage.



STEVE:  So anyway, again, this is like, for our podcast, such a perfect example of something that should not have happened because it shouldn't be up to the programmer to be careful against the built-in mechanisms of the language they're using.  They shouldn't be using a language that can do this that way.  But we are.



So a little bit of miscellany.  Paul Thurrott, I, and many of those in GRC's newsgroups, and most of the rest of the world who have been curious, have been playing around with Windows 11 since last Tuesday when a development release ISO image first appeared on the Internet.  The moment I saw that the ISO had leaked I went searching for and found it.  Links were not difficult to find.  And I'm sure that they're still not today, as this has spread now even further and wider than it had a week ago.  A couple of thoughtful listeners also DM'd links they had found.



For the most part, the links tend to be transient since they're being removed by the powers that be as soon as they're found.  But even if I had stable links, I would be uncomfortable using this podcast to reshare them since Windows 11 isn't officially released, and its sharing could reasonably be considered promoting the use of what is essentially pirated commercial software.  The fact that it's been, and is being, so widely pirated doesn't make it any less so.



What I can do, however, is to protect our listeners.  We can offer our inquisitive listeners some protection in the form of the SHA-256 hash of the known-to-be-valid ISO file.  That way, anyone here who believes they may have obtained the ISO from who knows where can readily verify its validity and safety for themselves.  Being very cautious myself, last week I downloaded many of these 4.8GB apparent Win11 .ISOs from very different sources and checked each one's SHA-256 hash.  They all matched.  So they were all valid.  And I also confirmed that with some other hashes that others were also making.



This SHA-256 hash in the show notes, I've got the whole thing there.  Its first 32 bits, it starts out with b8426650, and its last 32 bits, it ends with 6da60dcb.  Those 64 bits alone, the first 32 and the last 32, provide 1 in 18.4 times 10^18 verification strength.  So if your hash begins and ends with those, you're okay.



For anyone who's interested in making a hash, there are various Explorer shell context extensions to show the hashes of files which are right-clicked on.  But Windows has two built-in commands to do the same job.  There's a standard command prompt command.  It turns out that the Windows certutil (C-E-R-T-U-T-I-L) has a hashfile forming function.  You say certutil -hashfile, and then the filename, and then SHA-256.  I've got this shown in the show notes also.  And then PowerShell has a built-in function, and it defaults to SHA-256.  It's Get-FileHash, then the filename.  Hit Enter.  It takes a while for a 4.8GB file.  But in both cases you'll get the hash.



And I haven't seen any instances of malicious ISOs.  But you've got to know somebody is going to create one.  So if you do go get this, and if you're curious, take the time to make sure that the hash matches the one that I've listed.  And having played around with it, it is indeed Windows 11.  And I have to say, oh, it is truly gorgeous.  It is very pretty.  But Leo, I'm a bit disappointed because I keep encountering plenty of pointy corners.



LEO:  It's supposed to be rounded.



STEVE:  Exactly.  Now, it occurred to me that it might be that the extremely high resolution of my monitor is not being compensated for, so that the subtle visual rounding is being lost.  I believe that on that machine I have my text-scaling set at least to 150 because the resolution is so high.  So what that would mean is, if they're rounding with a bitmap, then they're not scaling the rounding as they're scaling the text in order to keep the effect of the rounding the same.  Maybe they'll fix that.  But for whatever reason, what I'm seeing still seems quite pointy in places.  There are reports of Win11 install failures on older machines.  And when I heard you and Paul and Mary Jo talking about it last Wednesday, Leo, one of the reasons they were conjecturing that Microsoft may have done a Windows 11 is to promote the sale of new hardware.



LEO:  Yeah.



STEVE:  It's like, hey, you want 11?  Get it on this new machine.  But what's curious about that is it's certainly going to be able to upgrade over 10.  So one of the things that's interesting is that Windows 11 refuses to run due to the desktop or whatever machine it's running on, but probably a desktop because laptops are better this way, not having a Trusted Platform Module, not having TPM, and thus being unable to support Windows Secure Boot, which requires a TPM.  Support for Secure Boot has always been optional for Windows 10.  But we have heard that, and now the industry is confirming, that for some reason Microsoft has decided to make it mandatory, that is, Windows 11 must have a Trusted Platform Module.  So that would rule out its use, if it hadn't already been worked around.  And maybe they'll stomp that out by the time it gets to release.



LEO:  Remember, you're not using a release version.  In fact, there's a lot of things missing from what you're using.  We know that.



STEVE:  It is a dev release.  So anyone running Windows can first of all check for the presence of their hardware platform's TPM by running a little snap-in.  It's just called tpm.msc.  So hit the Windows+R, you know, the Windows key and then R, to open the Run dialog.  Then enter tpm.msc and hit Enter.  That'll launch the TPM configuration applet that's built into Windows - 7 has it, and I'm sure everything since does - and see whether the system agrees that it's got a TPM.  That'll tell you whether that platform will eventually run Windows 11.



I have links to two instances of web pages talking about the problems people have had last week installing Windows 11.  Fossbytes.com is one of them.  "Solve TPM 2.0 error installing Windows 11 fixed."  And basically it involves taking one particular file from the Windows 10 and substituting for Windows 11.  Maybe Windows 11 will end up fixing that, double-checking for it.  Depends upon how much Microsoft cares about locking this down.  I don't know what their position will be.



Oh, and one other really interesting thing.  I'm sharing this mostly because it came from one of our own very active people in GRC's newsgroup, where he discovered this.  The other potential gotcha hit people who do not wish to log into Microsoft during the installation and - I didn't want to because, I mean, this wasn't official, right, Windows 11.  I didn't want to be like, oh, yeah, I'm going to log on with my Microsoft account.  No.  But so you'd like to create an offline account.



Although Windows 10 Pro allows for bypassing this in the setup UI, the Home edition of Windows 11 does not.  So if Windows 11 is being installed on actual hardware containing a built-in Win10 Home OEM key, it won't give you the option of which version of Windows 11 you want to install, as I got when I installed it in a virtual box VM.  Instead, it'll insist upon installing the Home edition, and that in turn insists upon the creation of an online account.  In Win11 Pro, it offers the "I don't have Internet" option to bypass the establishment of an Internet connection.  But that's been deliberately removed from the options for the Home edition.



Okay, so here's the surprise.  There's a workaround.  A guy named Adam, whose moniker is Warwagon in the grc.securitynow newsgroup, discovered that it's possible to simply close the insistent "Let's connect you to the Internet" dialog by hitting the ALT+F4 key combination.  Well, anyone who's used Windows and likes the keyboard knows that ALT+F4 is the quick shortcut for killing an app.  It's the same as going up into the context menu and closing, you know, Close or Exit or whatever.  It just terminates the app.  So Adam discovered that that works for this "Let's connect you to the Internet" dialog.



Oh, he also told the guys at Neowin, and they wrote the following.  They said:  "However, here's where Adam's simple workaround came in handy, which is both amusing and surprising.  When Windows 11 Home prompts users to connect to a network, a simple ALT+F4 shortcut closes the prompt, and the screen proceeds directly to the local account creation page, something that is never offered to users in the usual process.  This bypasses the entire Microsoft account login screen, which is a nifty little trick for those who want to avoid signing into their accounts during the Out of Box Experience (OOBE) process, especially in these early days when most installs of the OS are happening on virtual machines."  So actually under a virtual machine you do get the choice of which version you want to install.  I chose Pro, but you can choose anything you want.  So anyway, just a neat little tip.



Oh, and those who are not fans of the new positioning and look of the Windows 11 Start Menu, you may know that it creates - now there's like the bar of items that you can click on that used to be over on the left, the shortcuts, they now float in the middle, continually recentering themselves as new additions editions appear.  And the Start Menu is on the left but floating with them in this group, looking very much like a Macintosh Dock.  There is a reg key setting, HKEY_CURRENT_USER \Software\Microsoft\Windows\CurrentVersion\Explorer\Advanced.  And once you get to the Advanced key, there's a whole bunch of little settings.  You will see Start_ShowClassicMode, which will currently have a zero in it.  Just change it to a one, reboot, and then you get, as the name sounds, ShowClassicMode; you get back to the menu you're used to from Windows 10.



And finally, Leo, before we take our second break, we have the new purpose that has been identified for the Security Now! podcast.



LEO:  Oh, yeah?  What's that?



STEVE:  This was tweeted from someone whose moniker is Lost World, @Bruin144.  He wrote:  "Security Now!.  Just the sound of the podcast by itself removes intruders."



LEO:  What?



STEVE:  "For the second time," he wrote, "in a few years I have used Security Now! playing on an endless loop to remove intruders - raccoons - from my attic.  A few years ago a mother raccoon and her babies invaded an inaccessible-to-humans part of my attic.  I put a speaker where she could hear it, and because raccoons don't like the sound of people talking, you and Leo prompted her to decamp."



LEO:  Why did he include me in this?  It could have just been you.



STEVE:  "This week a new raccoon defeated my security measures and moved in.  Eighteen hours of Security Now! later..."



LEO:  Chase any varmint away.



STEVE:  "...he moved on and out, and I repaired the mesh he had pulled down."



LEO:  That's hysterical.  Wow.



STEVE:  So just a tip to our listeners.  If you have a problem with raccoons...



LEO:  Security Now!.  It rids you of raccoons.



STEVE:  In less than a day you will be raccoon-free.



LEO:  That's hysterical.  Hey, I want to correct myself.  We were talking about that SSID string.  And in C++ and C and Python and many languages...



STEVE:  "\n."



LEO:  "\n."  A "%n" is worse.  The last character in that string, "%n," the corresponding argument - I'm reading from the C++ documentation.  The corresponding argument must be a pointer to assigned int.  The number of characters written so far is stored to that location.  



STEVE:  Ooh, god.



LEO:  So I'm guessing...



STEVE:  Who designed C++?  Oh.



LEO:  I mean, you should not be able to printf to a memory location.  But that's what this does.  So I'm guessing that really is - that last character there, that's the real killer.



STEVE:  It's surprising you still have a phone after that happened.



LEO:  So "%p" is a pointer, "%s" is a string, "%n" doesn't print anything at all, it just stores what's come before it into an arbitrary memory location.



STEVE:  Oh, oh, god, just shoot me now.



LEO:  No wonder it crashed the phone.  Good lord.  And you're right.  Why would printf have that capability?  It turns printf into a poke, basically.  Crazy.  Crazy.  



STEVE:  So wsprintf would send that to a buffer.



LEO:  Right.



STEVE:  So you might want to know how many characters had been stored in the buffer in order for like centering text on a line, that sort of thing.



LEO:  Oh, yeah.  But I bet you people use it for a poke.



STEVE:  But again, talk about dangerous.



LEO:  Yeah.



STEVE:  Talk about dangerous, it's like, yeah, no.



LEO:  No.  I think I would always assume that these printf commands print to standard out, not to memory.  That's terrifying.  Ws does.



STEVE:  Wsprintf does exactly that, yeah.



LEO:  Interesting.  I never use that one.



STEVE:  And it uses the same format string.



LEO:  Yeah.  Well, that's probably it is that these format strings are general.  They're generalized for all different kinds of stuff.  Wow.  Just crazy.  Crazy.



STEVE:  So that people realize I was being rhetorical...



LEO:  Oh, you've got it there.  You're not making that up.  He's got it.



STEVE:  No, this is Stroustrup's... 



LEO:  It's Stroustrup's book.



STEVE:  ...original, yes, C++ book.



LEO:  Wow.  Show the binding.  That's too thin.  That can't be the real thing.  Where's the - I have the other one that's really thick.



STEVE:  Well, this one was the original 1991 book.



LEO:  Oh, okay.



STEVE:  So, you know...



LEO:  My C++ book from Stroustrup is like a doorstop, which is all it's good for.



STEVE:  This is the spec.



LEO:  Oh, I get it.  So it is, it's very terse, sure.



STEVE:  Yeah, yeah, yeah.  I mean, it is, as it says down there, ANSI-based document.



LEO:  Oh, that's why.  Yeah, my book is actually, like, here's how you learn C++.  Which I quickly gave up on, by the way.  What a nasty language.



STEVE:  You should try to forget it, if you can.



LEO:  I loved C.  Loved it.



STEVE:  I do.  And C++ is largely now regarded as a mistake.  So it's like, well, okay.



LEO:  I bet it's still the number one language, though.  Maybe JavaScript or Java have superseded.  I don't know.



STEVE:  Yeah, actually I think JavaScript is, last I saw.  Because we've talked about that from time to time on the podcast.



Okay.  So I received a Twitter DM last week where one of our listeners asked, "What the hell is going on with SpinRite, and when are we going to get it?"  So, you know, after my working on SQRL, apparently without end, I think that's a reasonable question.  And it reminded me that everyone in GRC's spinrite.dev newsgroup knows exactly what's going on and where things stand because I periodically let them know.  But that's a small fraction of the people we have listening to the podcast.



And since everyone owns local mass storage that they care about, and since I know that many of our listeners own SpinRite 6 and are looking forward to this next release, I suspect that it would be reasonable to assume that most of our listeners would be interested in having some better sense for what is happening while they are being patient.  This guy not so much.  And because this v6.1 project has grown into so much more than I expected, I wanted to take a bit of time today to provide a bit more visibility into what I've been up to.



The last incremental development release of the work on SpinRite had the new SpinRite code finding all of the system's mass storage devices, regardless of how they were interconnected to the system.  It also determined the most comprehensive way that each device could be interfaced.  For example, a SATA drive attached to an AHCI controller port will be visible through the BIOS, and perhaps with BIOS extensions.  But it will also be visible directly through its hardware, which SpinRite is now able to access directly.



So the last test that I released for everyone to play with was enumerating all the drives and showing all of each drive's relevant data far more comprehensively than any previous release of SpinRite had.  That release went amazingly well, actually much better than I expected, probably because we've been moving forward carefully and leave only fully tested and verified code in our wake.



After that, the next thing I had planned to do was to bring the drive benchmarking system online, since SpinRite's built-in read performance benchmarking would have to be testing the read-channel of every drive.  So exactly one month ago today, on May 22nd, I posted an update under the subject "One thing leads to another," which was the beginning of the trouble I found myself stepping into.  So I want to share that post and the four subsequent posts I've made since about what I'm doing with SpinRite.  Even if you're not interested in getting your hands on v6.1, anyone who's interested in computer technology will probably find this little bit of snapshot interesting.



So May 22nd, "One Thing Leads to Another."  I wrote:  "Gang.  It occurred to me last evening that by the time I have the benchmarking system running for everyone to test, this thing will be close to finished.  Everything is interconnected, and one thing led to another.  I said earlier that in order for the benchmark to be able to read sectors from the drive, it would need to have a lot of the system rewritten and running.  That's turning out to be more true than I realized at the time.  One thing leads to another, and I've been busily following those leads.



"A very useful thing has been that I know what lies beyond v6.1. That's coloring many of the decisions I'm making along the way. I'm not really writing just for this, but also to a very large degree for this to be a near-term future where we're joined by native drivers for USB and NVMe.  This next SpinRite will have an architecture that's ready to accept them.



"Yesterday, I came up with a slick encapsulation for SpinRite's IO work:  a single function that replaces all of the scattered IO throughout SpinRite.  The problem was that sometimes SpinRite needs to use Real Mode 16-bit segment:offset buffers in low memory."  For example, the BIOS only knows how to transfer there, and sometimes it's able to use a 32-bit linear buffer in high memory, for example, when I'm able to use the hardware directly.  "And in order to reduce the consumption of low memory, some working buffers that used to be in low memory can now be moved into high memory since, for the first time ever, SpinRite 6.1 will be running in flat real mode."



So I explain:  "So each drive seen by SpinRite can be one of five different access classes:  BIOS only, Extended BIOS without hardware access details, Extended BIOS with direct hardware access details, an IDE or SATA drive on the PCI bus with Bus Mastering, or a SATA drive on PCI with an AHCI controller."  And then each of those, I've got little notes after each of those five which shows which of those the following six things apply to:  Limited to max CHS, that's Cylinder Head Sector size, which is 28 bits, 137GB; potentially any size drive; access to the entire drive plus SMART and the SMART Log data; segmented memory transfers only, that is, lower 16-bit region, below 1MB; possible use of large sector count transfers and linear RAM in high memory; and 16MB (32k sector) transfers to high memory.  So you actually sort of end up with a grid of different access types and then the details that each of those access types applies to.  This all needs to get figured out.



So I said I already had the concept of "selecting a drive into context" which has traditionally been shown by SpinRite's "Selecting Drive for Use" screen.  That concept has matured significantly to become much more generalized, flexible, and comprehensive.  Yesterday I realized that all of SpinRite's data transfer work could be merged into just three generic types: Transfer to/from a single-sector buffer, transfer to/from a single-sector scratch buffer, and transfer to/from a track buffer.  In each instance, the location of the buffer, the means of performing the transfer and of obtaining the results will depend upon the drive that's currently selected into context, the details of that specific drive, and the hosting system's BIOS features.



So this new function, named just "IO," will encapsulate all of those specifics.  I call it with a function code to specify the type of transfer I want.  It obtains the starting sector number, which is now 64 bits, from global memory.  And the length of the transfer is implied by the operation, a single sector or an entire track; but then the length of the entire track is also obtained from memory, and by the specific drive's characteristics.  There will also be a generic MOVE function to move data between the sector buffer and the track buffer, and my code will not need to worry about which of the buffers are in use because the context will know.



So then I explained SpinRite never had, nor needed, anything like this before since until v6, everything ran through the BIOS exclusively, and at v6 the BIOS was only being bypassed for a subset of special case accesses, that is, all the extra data recovery that I was able to add to v6.  And I finished with:  "The beauty of this abstraction is that it cleanly divides the drive characterization, which populates the drive features database, and all subsequent drive access IO from the logical operational parts of SpinRite.  And moving forward into the future, when things like subtle read-timing features are added, the functions offered by that single IO function can be augmented."



So that was the end of the first post.  And essentially what I've done is I've used an object-oriented philosophy to create a clean demarcation between the way the IO is being done to individual drives by the way they're connected and the technology, the best technology that I have to access that drive.  That's one side of the divider.  The other is all of the stuff SpinRite needs to do to access the drive.  But those things don't change depending upon the drive.  So I'm able to create an abstract function, which is what I have, this IO function, that allows that.



Then on the 29th of May - that was on the 22nd.  So a week later, on the 29th, one of the things that happened as I was working through the code, I was looking at moving one of the big buffers that's in low memory into high memory because that just frees up low memory, which is still resource constrained.  I ran across a whole bunch of code for the logging system.  And I looked at it, and I was on the mission of, like, changing that from running on a low memory-located log to high memory.  But I stopped myself and said, wait a minute.  Do I even want this anymore?  Because the way it has always worked is that SpinRite would maintain a log in the root of the drive that it was working on, and the user could specify how many previous logs to retain.



So all this code that I was looking at, and there was a bunch of it, it looked at the old log, and it parsed the old log to count, like to find where was the beginning of the first log entry that was older than the user's configuration setting now said they wanted so that it would only keep the most recent N log entries.  And then I would take that, and I would get rid of the older things, rewrite the log file, moving the most recent N logs down and then be appending the new log freshly to the top of the log.  And I thought, really?  So I put that out to the group, the grc.spinrite.dev group.  I don't think I've ever had 100% consensus on, no, this is not what we want anymore.



So the new SpinRite 6.1's new logging approach just does sequentially numbered logs.  It looks at the highest numbered log file it can find on the boot media, which is where it logs back to, and just chooses the next one.  You know, it's time and date stamped because it's a file, one file per drive.  You'll have the option of making it one file per use of SpinRite, since one use of SpinRite could run on multiple drives, that's the only choice you have, instead of retain N prior logs, which didn't make any sense to anybody anymore.  So anyway, that was one of the entries.  And in the process I simplified the code.  I just threw away all that old code that was doing all this crazy log file manipulation, and I don't have to bother with it now.



On June 9th I said:  "Gang."  Oh, this was "SR v6.1 Progress Report," June 9th, so earlier this month, a little over two weeks ago.  I wrote:  "I'm glad I'm doing this.  It's tedious, but necessary.  Everywhere I turn, the code needs to be rewritten or edited.  So I'm just plowing forward, fixing everything I encounter.  I'm no longer trying to get something for everyone to test.  There was too much interdependence for that to be feasible.  Or as I wrote before, 'one thing leads to another.'



"In order to catch every instance of something that needs changing, I change the name of a variable to force assembly errors due to the old name no longer existing.  That's necessary because the old variable might have been 16 bits, and the new one needs to be 64.  But it means that a daunting list of errors results from every reference to the now gone obsolete variable.  So I then move through one by one, addressing each of the references to the old variable.



"I'm currently working to fix all references to what was previously 'OperatingLocationLow' and 'OperatingLocationHigh' variables.  They were each originally 16 bits back in the pre-32-bit days."  Right?  Because this thing ran on an 8086 that didn't have any 32-bit math or registers.  So I had to have two variables, OperatingLocationLow, OperatingLocationHigh, each 16 bits.  And so they are both being replaced by a single 64-bit transfer location variable.



And I said:  "I've been working on this one for a few days, and I've whittled the list of assembly errors down to about 25% of what it was initially.  When I finally emerge on the other side of the variable updating, we'll have a new foundation for probing generic mass storage.  But at the moment I cannot even estimate what percentage of the way through I am.  At some point I'll receive a welcome surprise that there are no more errors because all references to the new variables will have been encountered and recoded.



"The problem, of course, is that even though I have and will be as careful as possible, I will have inevitably introduced some new errors.  So it will be necessary for me to step through the code to watch everything work at least once.  And that's fine too, since once that's done that new mass storage foundation will be real, solid, and functional.  And then I'll be able to get back to the area I was excited about earlier, where a single IO abstraction procedure hides all of the details of drive access.  Behind it will lie handlers for BIOS, PCI/IDE, and AHCI/SATA drives.  And adding handlers for USB and NVMe, and who knows what else in the future, will then be very straightforward."



Two days later, on June 9th, I posted "SpinRite's Source Code Line Counts."  I said:  "Gang.  During my after-dinner walk with Lorrie, I mentioned that once things had stabilized and settled down with SpinRite, that is to say, once I kind of thought I was done, I planned to read the source from top to bottom to find anything that I hadn't addressed.  She asked how long the source code was, and I didn't know.  So I just did a quick line count to see."



LEO:  I wonder what she thought you would answer, like, oh, it's 500 pages?  I mean...



STEVE:  Yeah, she's just like, well, how long is that?



LEO:  How long is that?



STEVE:  Because, you know, someone she cares about is going to read something.  How long is that going to take?



LEO:  It's surprisingly short.  It's really more a short story than a novel, I would say.



STEVE:  That's right.  Well, so in the show notes, for anyone who's interested, I have a link that I posted as part of the posting since the newsgroups are text only.  SpinRite currently has a line count of 27,556 lines.



LEO:  That's a good number of lines.



STEVE:  Now, that's not all code, since especially my newer code tends to have longer comment blocks at the top of procedures to explain anything that the procedure's long name doesn't already make clear.  At the same time, I heavily comment the ends of my lines, but those won't show up as additional line counts.  So it does give some sense for SpinRite's source code base.  I excluded a handful of files of UI content - the screens, the screen composition definitions, and the text that fills them, since they aren't code.  And most of them aren't changing.  Basically, the UI is pretty much the only thing that is surviving this conversion of SpinRite 6 to 6.1.  And even that has had a lot of facelift already.



I wrote:  "In the beginning, SpinRite was mostly a single SR.ASM file.  And you can see that heritage since SR.ASM remains by far the largest single file at 8,652 lines."



LEO:  Yeah, I noted that.  Is that the main code, kind of?



STEVE:  Yeah.  There used to be like one code file, SR.ASM, and then a whole bunch of UI files.  But I've been breaking it apart into smaller, more manageable and functional pieces during this recent work.  So things like MATH.ASM and MEM.ASM, which were once part of SR.ASM, are now separate files.  I broke them out since they needed lots of reworking and rewriting.  You could imagine that all the math had to be updated, and all the memory management needed to be fixed.



LEO:  I'd love to see some of this source.  You don't ever publish any of it, do you.  I know it's proprietary.



STEVE:  I haven't.  Yeah, I haven't.  But I wouldn't mind sharing some.



LEO:  Just a little bit.  Just a little bit.  Some of it.



STEVE:  It is fun to look at it.



LEO:  In your will, when you pass on, you know, let's open source it.



STEVE:  Oh, I'm definitely going to release the source once there's no more ongoing commercial work for me.



LEO:  That would be great.



STEVE:  I've stated that publicly to the gang, so, yeah.



LEO:  Excellent.  Nice.



STEVE:  And I'd like it to outlive me.  It looks like it might, actually.



LEO:  Yeah, well, you've certainly modernized it.  Boy.



STEVE:  Oh, yeah.  I'll be proud actually to release it.  So, okay.  So the final one, my most recent note from last Thursday, June 17th,  I said:  "Gang."  And this was titled "Another Update."  I wrote:  "I figured that since I've done something else again, I ought to loop everyone in on what's been going on."  And I should explain, I mean, I work on this thing 12 hours a day, 14 hours a day.  I mean, so for me, even though that was a week ago, the previous update, everything has changed since then.  I mean, because so many hours have happened.



So I said:  "Gang.  I figured that since I've done something else again, I ought to loop everyone in on what's been going on.  As I wrote previously, I updated everything to handle the shift from 32-bit sector addressing to 64-bits.  After finishing that, I returned to the work on the IO abstractor, which will be providing a uniform interface between SpinRite and all current and future drives and technologies.  The trouble I then encountered was what exactly I wanted the abstracted IO to do.  Things like did I want the full block transfer to always start at the beginning of the transfer block, or at an arbitrary sector offset?  Did I want the single-sector transfer to transfer to and from a single-sector buffer, or to and from an offset within the full-block transfer buffer?  And where did I want the DynaStat functions to place their transfer sample data?



"The point was I was developing an abstract function to do whatever SpinRite needed.  But unlike the system's underlying IO that is generic and doesn't know anything about SpinRite, I could design these abstract functions, or actually this one abstract function, to do exactly what SpinRite needed.  But I couldn't answer those questions of what SpinRite needed until I took a close look at SpinRite's core work loop to remind myself what exactly it was doing and how.  I had been avoiding doing that since I had been hoping to leave it as much as-is as possible.  Of course, I knew what it was doing broadly, but I hadn't looked at it closely under the new pure linear addressing mode approach."



Because that's the big thing that's changed is that, you know, the BIOS only sees things as cylinder heads and sectors, the traditional so-called "3D addressing."  There's an extension to it that kind of makes it linear, but it's very poorly supported, that didn't really happen much, mostly add-on cards that would bring a BIOS along.  But the motherboard never bothered to because as long as you can boot the OS, who cares anymore?  So anyway, so the point was that the group already knew that I had recognized the only way to go forward was to scrap this cylinder head-and-sector approach, which absolutely bears no relationship to reality any longer.  All drives are LBA, Linear Block Addressing.  NVMe, Linear Block Addressing.  Anything that we're talking to, Linear Block Addressing.



So I said:  "The short version is, it all had to go.  Nothing about the way it was written 34 years ago still made sense today.  And even though SpinRite went through five major feature upgrades, the last one was 17 years ago, half of its 34-year life ago.  As we know, SpinRite's original mission was to non-destructively low-level reformat drives.  It did this one track at a time.  It would read all of the data from a track, really, really reading it, no matter what.  Then it would low-level reformat that one track, which might cause verified defective sectors to be moved into different logical sectors and previously good logical sectors to suddenly become defective due to re-interleaving.  So SpinRite untangled all of that, rewrote the track's data back to the track, then moved onto the next track, and so on until it was finished.



"Even though SpinRite has not been doing much of that for quite some time, all of that logic had remained essentially unchanged until now.  SpinRite's original philosophy had never been updated.  It hadn't been getting in the way, but neither has SpinRite been operating at nearly the speed and capacity that its new drivers will now enable.  I suppose an analogy might be we've built powerful new jet engines, but we can't really hang them onto the balsa wood body that was sufficient when it was being powered by rubber bands.  An example would be that SpinRite's track buffer was a single 64K segment.  Since transfers cannot cross a segment boundary, this was an absolute limit.  64K is 128 sectors, so no transfer could be larger than 128 sectors.  But now we come along with 32,768-sector transfers into 16MB buffers.  There's just no way for SpinRite's existing core code to deal with that change.



"And when SpinRite was zipping along on a drive, it was doing track-by-track transfers.  But if it hit any trouble on a track, since SpinRite was always track-based, it would drop out of track mode into sector mode, where it would assess each of the track's sectors one by one to determine what to do about that track.  But it makes no sense, when we're transferring 32,768 sectors at a time, to 'drop into sector by sector mode' for all of the buffer's probably fine 32,768 sectors.  So the new SpinRite will have 'restartable' mass block transfers where a problem sector will stall the transfer, will work on that one sector, then resume the mass transfer starting with the sector that follows.



"Anyway," I wrote, "the point is this exactly matches the evolution of our media, and there's no getting around the fact that it needed to be done.  So although I have not yet rewritten the new inner core for SpinRite, I have completely specified its operation and design.  So I now know exactly what the new IO abstraction layer will need to provide to it, and I'm back to work on that."



So anyway, that's my most recent project status posting to the grc.spinrite.dev newsgroup.  And if it sounds like I'm pretty much rewriting SpinRite, then you have a pretty accurate sense for what I've been doing and for what was needed.  There really wasn't any way to just quickly graft on the new stuff that I had promised for this no-charge v6.1 release.  And the earlier discovery that SpinRite can repair solid-state media, and also our more recent discovery that it's going to be able to sense when specific regions of apparently healthy solid-state media are actually slipping into trouble means that there's a lot of life left in SpinRite.



So yes, I'm investing hugely, ridiculously, actually, in the work for a free upgrade.  But I have no problem with that since the moment 6.1 is launched, I'm going to set to immediately moving SpinRite over to its new home, that pure 32-bit real-time embedded operating system that will be able to dual-boot on either BIOS or UEFI systems, then immediately add native support for USB and NVMe hardware interfaces, then work to bring those subtle solid-state read-timing anomalies we discovered into SpinRite's UI, both to display those speed variations and to then selectively rewrite them, which we have already confirmed, in a very blunt way, actually does restore their speed and almost certainly improves their long-term read-back reliability.



And if I sound excited, you're right about that, too.  SpinRite has 34 years behind it so far.  I suspect it's going to easily hit 40 and probably go beyond.  So that's where we are.



LEO:  So you just described a decade-long plan, I think, roadmap.  I'm saying, I'm just saying.  I'm being optimistic here.  But good.  I want to keep you employed, fully employed.



STEVE:  We do not need to, I mean, I'm having so much fun being back to it.



LEO:  Yeah.



STEVE:  Yeah, I love to code.  I settle down here.  Lorrie is great about getting me out of the house in the morning.  I make myself a latte.  I settle down here.  And I just - I feel so good.  It's like after SQRL, where I felt like I was stealing time from SpinRite, now I'm finally doing what I'm supposed to be doing.



LEO:  This is your real mission.  Yes, I think so, yeah.



STEVE:  Yeah, yeah.  Just it makes sense, and I just love it.  So anyway, that's where the time is going.  Basically everybody is going to get for free a radically brand new SpinRite.



LEO:  Sounds like an all-new program, yeah.



STEVE:  It is.  But I did promise it.  And moving forward, everyone's also going to want 7, so I'm not worried about giving all this work away for free because it's just a tease, really.  I mean, it is what I promised I would do, but it's also a tease to 7 because wait till you see what I'm going to make SpinRite 7 do.



LEO:  Yay.



STEVE:  Yeah.  Okay.



LEO:  SQRL was aptly named, I have to say.  Unconsciously so, but I think aptly named.



STEVE:  Okay.



LEO:  That's good.  No, you know what?  You've got to have a hobby.  That's what I'm saying.



STEVE:  Well, with SQRL, I mean, and I thought about this.  I couldn't very well drop it when it was half done.



LEO:  No, no.



STEVE:  Because then we'd have nothing.



LEO:  Thank god you're persistent.  Absolutely.



STEVE:  I never quit.



LEO:  Yeah.  That's really a - I quit everything.  So I really admire your stick-to-it-iveness.  I have yet to finish a coding project, not one.



STEVE:  SpinRite has been the miracle of my life.  I have wondered, like, what would I have - I'm sure I would have come up with something.  But I don't know what it would have been.  And I'm glad...



LEO:  It's perfect.  No, this is...



STEVE:  ...it was SpinRite.



LEO:  You were living your absolute best life.  This is absolutely what you should be doing.  There's just no doubt about it.



STEVE:  Because it combines my love of hardware and software.



LEO:  It's perfect.



STEVE:  And finding good solutions and so forth.



LEO:  At this point I doubt anybody understands how hard drives work better than you do.  I mean, you really - mass storage, pardon me, because you've also done the SSD stuff.



STEVE:  I'm sure that the engineers that are developing this stuff do.



LEO:  Yeah, but they're narrow.  See, you have to know the entire range of possibilities.



STEVE:  Well, a perfect example is that, although it was painful, I have one AHCI driver that runs on everything.



LEO:  Right.  Perfect.



STEVE:  Everybody else has AHCI drivers.



LEO:  Right, specifically, yeah.



STEVE:  I don't need them.  I solved the one problem that runs on everything.  And again, so that's the way I work is it's harder, but we end up with something that has incredible longevity.  I mean, SpinRite 6, 17 years.  And SpinRite itself, 34. 



LEO:  It's amazing.  It's amazing, yeah.  



STEVE:  So anyway, and it doesn't look like it's over yet, either.



LEO:  On behalf of all of us, thank you, Steve.



STEVE:  Thank you.  Well, okay.  We're going to see a transformation in ransomware.  I talked about it in the first half.  Here's some interesting insider information.  So a month ago, while it was still running hard, Sophos, as part of their new "what to expect" series, posted:  "What to expect when you've been hit with Avaddon ransomware."  And they wrote - this is Sophos:  "Avaddon ransomware is a Ransomware as a Service that combines encryption with data theft and extortion.  Avaddon has been around since 2019, but has become more prominent and aggressive since June of 2020."  Okay, so think about that.  One year.  June of 2020.  "Affiliates or customers of the service have been observed deploying Avaddon to a wide range of targets in multiple countries, often through malicious spam and phishing campaigns that carry booby-trapped JavaScript files.



"Organizations hit with Avaddon ransomware face more than just data encryption.  There is also the threat of public data exposure on the Avaddon leak site and, more recently, the risk of distributed denial of service attacks disrupting operations.  These tactics are designed to increase pressure on victims to the ransom demand.  The following information may help IT admins facing the impact of an attack with Avaddon ransomware."  And they added in italics:  "According to reports appearing from May 17th, 2021" - so just the previous month - "the operators behind Avaddon ransomware have taken the service 'private,' possibly by being more selective about affiliates and their targets; and they have said we will not support attacks on sectors such as government, healthcare, educational, and charity organizations."  So that's interesting.



Last month, Avaddon was viewed as a real threat on the RaaS landscape.  In fact, Malwarebytes wrote:  "If you may recall, Avaddon is a big game hunting" - so now we have the abbreviation again, BGH - "ransomware as a service (RaaS) tool that the U.S. Federal Bureau of Investigation (FBI) and the Australian Cyber Security Centre (ACSC) warned organizations about last month."  Malwarebytes wrote:  "While various sectors of Australia were noted to be particularly targeted, the Avaddon strain has been instrumental in the successful network compromise of the Asian division of the AXA Group, one of the biggest cyber insurance companies in the world.  Avaddon threat actors were able to extract information about what appears to be client info - passports, bank account information, ID cards, contracts, fraud-related hospital files, and other medical reports containing sensitive data about patients, and more.



"Coincidentally, this attack came close to a week after the insurance giant announced that it would cease covering customers in France who pay up after being attacked by ransomware.  An insurance company refusing to cover for any monetary loss over a cyberattack will no doubt significantly increase the likelihood of victim companies refusing to cough up money to ransomware gangs."  And they finish:  "Schepisi Communication, an Australia-based telecom service provider, was also hit by Avaddon last month after its platinum partner, Telstra, fell victim to a ransomware attack by the same group.  The criminals claimed to have access to data of a large amount of SIM cards, mobile devices, contracts, and banking information, to name a few.  When the company refused to pay the demand, their official website was downed by distributed denial of service attacks, taking their website offline for several days."



Okay.  So according to the FBI, Avaddon ransomware actors have compromised victims through remote access login credentials such as Remote Desktop Protocol and Private Virtual Network credentials.  After Avaddon actors gain access to a victim's network, they map the network and identify backups for deletion and/or encryption.  The malware escalates its privileges, contains anti-analysis protection code, enables persistence on a victim system, and verifies the victim is not located in Commonwealth of Independent States (CIS) countries.  Finally, a copy of the victim's data is exfiltrated before the victim's systems are encrypted.



So I thought that Malwarebytes' use of the big game hunting (BGH) was interesting, especially in light of the fact that these guys have made what was probably the same mistake that the DarkSide gang made.  They became too high-profile.  Their attempt to take their operation private last month was likely their means of hoping to regain control over their out-of-control affiliates, who were attacking irresponsibly, or at least without apparent regard for social responsibility which, lo and behold, as I noted earlier, in the wake of DarkSide and JBS, has suddenly become a thing that ransomware attackers need to consider.



And then Friday before last, on the 11th, we received some surprising news from BleepingComputer, who had themselves received a surprise gift.  Lawrence Abrams, the founder of BleepingComputer, wrote:  "The Avaddon ransomware gang has shut down operation and released the decryption keys for their victims to BleepingComputer.  This morning, BleepingComputer received an anonymous tip pretending to be from the FBI that contained a password and a link to a password-protected ZIP file.  This file claimed to be the 'Decryption Keys Ransomware Avaddon' and contained three files.  After sharing the files with Fabian Wosar of Emsisoft and Michael Gillespie of Coveware, they confirmed that the keys are legitimate.  Using a test decryptor shared with BleepingComputer by Emsisoft, I," wrote Lawrence Abrams, "decrypted a virtual machine encrypted with a recent sample of Avaddon.



"In total," he wrote, "the threat actors sent us 2,934 decryption keys, where each key corresponds to a specific victim.  Emsisoft has released a free decryptor that all victims can use to recover their files for free.  While it doesn't happen often enough," he wrote, "ransomware groups have previously released decryption keys to BleepingComputer and other researchers as a gesture of goodwill when they shut down or release a new version.



"Over time, Avaddon has grown into one of the larger ransomware operations, with the FBI and Australian law enforcement recently releasing advisories related to the group."  And I think that may be the key.  "At this time, all of Avaddon's Tor sites are inaccessible, indicating that the ransomware operation has likely shut down.  Furthermore, ransomware negotiation firms and incident responders saw a mad rush by Avaddon over the past few days to finalize ransom payments from existing unpaid victims."  To me that sounds like they were given a deadline.



So he finishes:  "Coveware CEO Bill Siegel has told BleepingComputer that Avaddon's average ransom demand was around 600K.  However, over the past few days, Avaddon has been pressuring victims to pay, and accepting the last counteroffer without any pushback, which Siegel states is abnormal."  And he finishes:  "It's not clear why Avaddon shut down, but it was likely caused by the increased pressure and scrutiny by law enforcement and governments worldwide after recent attacks against critical infrastructure."  Emsisoft's threat analyst Brett Callow told BleepingComputer:  "The recent actions by law enforcement have made some threat actors nervous.  This is the result.  One down, and let's hope some others go down, too."



And this brings us to the view from Russia, with a lot of interesting inside information, brought to us by two Russians, Vitali Kremez and Yelisey Boguslavskiy.  Together they run AdvIntel  a contraction of Advanced Intelligence, A-D-V-I-N-T-E-L  and they offer unique insight thanks to having access to unique data and players in their home country.  They explain why it all comes down to one thing, and why I titled this podcast "Avaddon Ransonomics."  So I've edited and tweaked their write-up actually in some cases significantly to fix some minor Russian-as-their-first-language errors and to clarify things here and there.  But it's essentially untouched.



They begin by explaining the ransomware gang's name:  "The three-letter Hebrew root 'avad'" - and that's four letters, but okay - "from which the name Avaddon is derived has two main semantic interpretations, 'to destroy' and 'to lose or get lost.'  Indeed," they wrote, "these two meanings perfectly define the Avaddon ransomware, a destructive and malicious force which always managed to conceal and disappear."



They wrote:  "Today we shed light on this lost and hidden criminal empire using unique datasets, the full list of Avaddon victims ever targeted by the group over the year of its existence, discovered by AdvIntel.  This unique SIGINT data is supported by exclusive HUMINT findings, statements made by the Eastern-European underground cyber community leaders who worked with Avaddon, explaining and interpreting the group's rapid rise and even more rapid downfall.



"On June 11th, 2021, Avaddon released keys for over 2,000 victims containing the exact company breach names.  Our analysis of the confirmed victimology shows that some of them are the world's leading companies.  How did this group succeed in hitting so many companies within a year?  The answer is Avaddon created an entire ecosystem around themselves, a web of supply chains, international affiliates, sellers, underground auction managers, and negotiators.  They have established an organic ecosystem of criminal extortion economy, a form of 'ransonomics.'



"Of course, Avaddon was not the only group pursuing a diversified approach to building a larger business system.  However, they were likely the most creative ones.  They were the only Russian-speaking group that enabled, but promoted, international partners joining the team as affiliates that directly represented the coverage of Avaddon's attacks, reaching five continents.  One of Avaddon's largest attacks on a major financial institution occurred in May of 2021."  And of course that's the attack on AXA.  "It illustrates this integrated approach of building the ransomware-attacks economy.



"While investigating the AXA attack," they wrote, "we discovered 141 unique indicators for RDP compromises for the victim's domain.  This means that Avaddon was using the services of an RDP brute-forcing group.  Moreover, two weeks before the attack, a threat actor conveniently published a post on a major underground forum where Avaddon was based, auctioning classified information on the future victim.  This access seller happened to be connected to a malware developer specializing in data exfiltration tools.  In other words, before Avaddon performed their data-stealing operation, they were able to utilize the entirety of underground services and purchase the full set - RDP access, direct network access, and malware for data exfiltration.



"This innovative approach enabled Avaddon to perform several thousand attacks.  AdvIntel has analyzed Avaddon's victims' unique datasets to build the most definitive adversarial profile.  Traditionally, while profiling the group's victimology, companies rely on the data available in public, i.e., ransomware websites.  And indeed, even looking at this partial data, which only includes companies whose information was dumped on the shame blogs, we can see that Avaddon played a major role in the threat landscape.



"However, the victims whose names were published on the shame blog are only the tip of the iceberg.  AdvIntel's advanced dataset, covering all Avaddon victims, provides further visibility into the gang's operations.  For this statistical research, AdvIntel has selected a special high-value target dataset.  First, we defined the industries which were the primary targets for the group, manufacturing, retail, technology, and engineering being the most preferred sectors most likely because for the companies of these sectors even a brief interruption of business can imply fatal consequences.



"For the next step, we performed market research of the victims' revenue to identify the potential pattern of Avaddon attacks.  The total revenue of all victims was around" - and this is aggregate total earnings over their life - "35 billion USD.  This is the segment of the market which has been in one way or another threatened by Avaddon's malicious operations.  Avaddon's victims can be divided into three categories - small, medium, and large.  The average per-victim lifetime revenue was:  13 million USD for small businesses; 287 million USD for medium-sized businesses; and 3.7 billion USD for large businesses."



They said:  "Our next research goal was to calculate how much money the Avaddon group could make before their rapid retirement.  We have utilized our previous knowledge from threat actor engagements to develop realistic formulas of ransom demand calculations supported by the actual Avaddon cases.  Traditionally, all Russian-speaking actors are using the victim's annual revenue to calculate the ransom.  After identifying the revenue, they investigate the sector within which the victim operates.



"The most common calculation which according to our sensitive and credible source intelligence as used by Avaddon was the so-called '5x5' rule where 5% of the target's annual revenue is used to start the negotiations, with annual revenue estimated as one-fifth of the total historical revenue.  In other words, for a victim which has a total lifetime revenue of 7 million USD, the starting ransom price will be 70,000 USD.  Typically, Avaddon dropped the price during bargaining, and the end ransom was around 50,000 USD for a successful operation.



"However, not all companies out of the 2,000 victim list were forced to pay such ransom.  In many cases, the negotiation failed or the ransom was minimal, several thousand USD, especially in the beginning.  At the same time, bigger payments were demanded from larger entities.  Here, the '5x5' formula would be replaced by a more tempered scale for larger ransom involving 0.01% margins for annual revenue instead of 5%, et cetera.  So for a multi-billion dollar company, the demand was constrained to a few million dollars.



"After finalizing the calculations with a case-by-case study of each victim from the high-value dataset, AdvIntel assessed that the bulk of ransom payments came from over a thousand smaller-sized companies, from which was demanded between $30,000 to $70,000, and constituted the overall aggregate payment of 55 million over its lifetime to Avaddon.  Over the 500 larger businesses in the victim list, that constituted another 30 million, and the rest was divided between smaller payments.  Our assessment of Avaddon's lifetime, approximately one year, income is therefore approximately 87 million USD.



"Our team has also attempted to calculate the revenue of a core Avaddon team member based on these numbers.  Within Avaddon RaaS, over 70% of income went to affiliates.  Therefore, the core team, and especially the leader of Avaddon, received around $26 million.  This number was likely divided between at least four individuals, which made the approximate annual income, that is, for a year, 7 million USD.  For comparison, the median annual income in Russia is approximately 7,000 USD.  In other words, in one year of ransomware development, an Avaddon member made the same money as an average Russian would make in 1,000 years."  They wrote:  "This is the best illustration of how lucrative ransomware could be for the region."



So they finish, at length:  "If Avaddon was so successful, what could have motivated them to quit?  The likely answer is fear.  U.S. law enforcement and the Biden administration became very upfront regarding future retaliatory measures against ransomware and the new angle in which ransomware is seen as essentially an act of terrorism."  And remember, this is from two Russians.  "This new take," they write, "on digital extortion from the world's leading superpower had a direct effect within the underground community.  The above-mentioned ransonomics, which powered a carefully and meticulously built web of alliances and supply chains, began to rapidly fail.  Software brokers refused to sell malware to ransomware groups, forums banned Ransomware as a Service partnerships, and affiliates were left without means and services to disseminate the payload.



"The cybercrime world has always been similar to piracy, and it has its own black mark.  But after the Colonial Pipeline incidents, ransomware was clearly carrying the same black mark for the first time.  Avaddon, which was in the center of the dynamic and turbulent ransomware ecosystem, quickly realized the risks they might face.  This realization was likely caused by the recent intervention of politics into the cybercrime domain.  Overall, the inner logic of the Russian security landscape presumes that a successful cyber group will eventually become prominent enough to attract the state's attention.  Usually, law enforcement will turn a blind eye to cyber operations unless these operations target Russian citizens or businesses.  However, this status quo changed in May of 2021.



"After the admin of XSS, the largest dark web forum called for a ransomware ban, justifying it for political reasons.  The community of digital extortionists in Russia was observed to go through stages of paranoia.  This was also the result of multiple statements made in the last three months by the Russian government, the Russian Ministry of Foreign Affairs, and by President Putin personally about establishing an international Russian-American initiative to establish a joint cybersecurity landscape.  The Russian officials likely see this as a tool of deescalating the U.S.-Russian relationships, especially in light of the upcoming Biden/Putin summit scheduled for June 16th, 2021.



"Indeed," they wrote, "the Russian government traditionally goes through rounds of escalation and deescalation with the West.  The escalation phase involving military maneuvers in the proximity of the Russia-Ukraine border and in Northern Syria ended in April of 2021.  Now the Kremlin, aiming to address severe challenges in the post-COVID economic recession and the turbulent domestic situation, is interested in creating a certain framework of stability in the international arena and ensuring stabilized relationships with the U.S. to avoid unnecessary pressure.  Therefore, cybersecurity, a controversial issue for the U.S.-Russia relationship, is on the frontlines of this deescalation agenda.



"It is also noteworthy that some of the jurisdictions that were targeted by Avaddon - Iran, China, and Turkey - also have strong geopolitical ties with Russia and act as Russian allies or critical economic partners.  However, it's unclear if this could have led to any aggravation in the relationship between Avaddon and the Russian state.  Whatever the true rationale of the Russian politicians calling for international cybersecurity cooperation is, these recent statements have clearly had an impact on the underground cybercrime community.  AdvIntel has tracked multiple discussions between top-tier actors working with Avaddon who mentioned that one of the group's affiliates was apprehended by the Russian law enforcement on the eve of the U.S.-Russia summit, and that further arrests may follow against the ransomware leaders in order to secure the political landscape."



So to me it seems very clear that they were in a big hurry, Avaddon was, to shut themselves down.  Thus that weird behavior that was seen in the final days of Avaddon, basically taking anything they could get from the remaining victims and then finally releasing all the keys because for whatever reason they were going to be able - like for some reason they were going to be able to never get anymore ransoms paid again.  And so they scraped up the residuals that they could.  And then because they knew for whatever reason they were not going to get anymore ransom payments, they just released the keys for free.



LEO:  Right.  Very interesting.



STEVE:  Yeah.  And, you know, this is not U.S. propaganda.  This is two Russians with a Russian intelligence firm who have contacts, who know the affiliates of Avaddon, who are saying it's gotten too hot.  We can't do this.



LEO:  Putin says, "You cut it out for a little bit, okay?  We'll get you later."  Very, very good stuff, as usual, Steve.  I really enjoyed the update, too, on the SpinRite.  Can't wait to see some more stuff from you.  It's exciting.



STEVE:  Me, too.  I'm going to go working on it this evening.



LEO:  Well, if you want to know more, if you want to get a copy of SpinRite and get the free upgrade, all you have to do is go to GRC.com.  Forums.grc.com you can read up on it, keep up with what Steve's doing because he does post regularly to the forums.  And also while you're there you can get a copy of the show.  Steve's got a couple of unique formats.  He's got the 64Kb audio like we do, but he also has a 16Kb audio, very small audio file.  It's a little scratchier, but if you don't have lot of bandwidth, it might save you some download speeds, some download time.  He also has the human-written transcripts.  Elaine Farris does a great job with those so you can read along as you listen.  That's all at GRC.com.  You can leave feedback for Steve at GRC.com/feedback, or on his Twitter account.  His DMs are open.  His Twitter handle is @SGgrc.



We have 64Kb audio and video, as well, on our website, TWiT.tv/sn.  We do the show Tuesdays, right after MacBreak Weekly, so that's usually around 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  If you want to tune in and watch it live, there's a live audio stream and video stream at TWiT.tv/live.  People who watch live often like to chat with others who are watching live.  Couple of places to do that.  Our IRC, of course, is open at irc.twit.tv.



What else?  There's a YouTube channel with all the videos there.  Actually, if you go to TWiT.tv/sn, you'll find a link to the YouTube.  You'll find a direct link to various podcast players, but also an RSS link you can add to any podcast player.  Really subscribing is probably the easiest way to make sure you get your weekly fix of Security Now!.  And if your podcast program has a review section, do us a favor, leave a five-star review for Steve.  I think he earns that every single week.  Absolutely. 



Thank you, Steve.  Have a great week.



STEVE:  Thanks, buddy.



LEO:  See you next week on Security Now!.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#825

DATE:		June 29, 2021

TITLE:		Halfway Through 2021

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-825.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at the story behind an important Edge update and revisit Google's now-delayed FloC liftoff.  We consider the cost of Ireland's recovery from the Conti ransomware attack and ask who's responsible for the damage and data loss following the remote wiping of many Western Digital My Book NAS devices.  We take a moment to observe the passing of an industry legend.  Then we look at the mess surrounding questions of where Windows 11 will run.  I share my favorite web browser keyboard shortcut, and also my favorite website cloning tool, which I just had the occasion to use.  We have a worthwhile-looking cybersecurity Humble Bundle.  Then we'll wrap up by responding to two pieces of closing-the-loop feedback from our terrific listeners, and that will bring us to the end of the first half of an event-filled 2021.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with a little rant.  Why is it so hard to figure out what machines Windows 11 will run on?  It's just Windows 10; right?  We'll also talk about the My Book Live hack.  The true story is getting kind of interesting.  And then why did it cost Ireland $600 million to fix that ransomware attack?  It's all coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 825, recorded Tuesday, June 29th, 2021:  Halfway Through 2021.



It's time for the dweebcast.  That's a good name.  You've just renamed the show.  I'm talking Security Now! with this guy right here, the king of the dweebs - that's a mean thing to say - Steve Gibson.



STEVE GIBSON:  That's better than the myth.  I think I like that better than the myth.



LEO:  The man, the myth, the legend.



STEVE:  Yeah.



LEO:  Oh, I never thought about that.  There is no myth.  It's all reality; right.



STEVE:  We are going to be talking about a legend of the computer industry who we lost last week.  That was after the podcast finished.  So anyway, we've got a lot to talk about for Episode 825.  Actually we're closing in on the end of Year 16, Leo, so...



LEO:  Hush your mouth.  I don't want to get to 999 anytime soon.



STEVE:  No, that's going to be a dilemma.  Anyway, we are, with the finish of this podcast, halfway through 2021, thus the name of today's podcast.  We're going to look at the interesting story behind a very important Edge update and how some rent got paid.  We're going to revisit Google's now-delayed, well, FLoC flop.  We're going to consider the cost of Ireland's recovery from the Conti ransomware attack, which I think is very suspicious.  It's, like, got to be the most expensive expectation we've seen.  Also ask who's responsible for the damage and data loss following the remote wiping of so many Western Digital My Book NAS devices.  We're going to take a moment to observe the passing of an industry legend.  You know who that is.



And then we look at the mess surrounding questions of where Windows 11 will run.  And I even heard Andy touching on that during MacBreak Weekly.  I'm going to share, just because it occurred to me I was using it so much yesterday, my favorite web browser keyboard shortcut; and also, and I also used this yesterday earlier, my favorite website cloning tool.  Maybe that was on Sunday.  Anyway, I just had the occasion to use it again.  I thought, I've got to make sure everybody knows about this because it really, it just works.  And it turns out that's not an easy thing to find.  We also have a worthwhile-looking cybersecurity Humble Bundle.



And then I want to wrap up by responding to two pieces of closing-the-loop feedback from our terrific listeners, which as I said will bring us to the end of the first half of an event-filled 2021.  And of course we do have a great Picture of the Week, apropos of one of our topics.



LEO:  I haven't glanced at it yet, just in case it's something surprising.



STEVE:  I think we're going to have fun.  Don't be drinking any coffee while you look at it.  You may spit it out.



LEO:  Might spit it out?  Uh-oh.



STEVE:  That's right.



LEO:  You made me spit my milk through my nose again.  That's why we should rename you, and this was a suggestion from the chat room, thanks to Logan5, "the man, the mirth, and the legend."  How about that?



STEVE:  Oh, now, that I can go with.



LEO:  Yes, yes.



STEVE:  I gave our Picture of the Week the caption, "Why place an arbitrary lower bound on Windows 11's minimal requirements?"  And the picture is our beloved Windows 95 desktop.  And this is a completely spoofed picture because the PC Health Check will not run.  It won't even run on my Windows 7 machine, which I'm talking to you from right now.  But anyway, this was just somebody took the time to mock this up, which I got a kick out of, apparently running the PC Health at a Glance showing a 32MB, not GB, of RAM, a 1GB hard drive, also showing 25 years old.  And then apparently someone checked whether or not this machine would be able to run Windows 11.  That is the Windows 95 machine.  And lo and behold, no.  It says "This processor isn't supported" - it's probably an 8386 - "for Windows 11."  So oh, darn.  Anyway, we'll be coming back to that as a consequence of much activity in the last week on the topic.



LEO:  Oh, it's been crazy, yeah.



STEVE:  Oh my lord, yes.  Okay.  So here's a true interesting story.  On June 3rd, so the beginning of the month, what's that, like a little over four weeks ago, a little over three weeks ago, a team of non-Russian-speaking hackers who call themselves "Cyber Xplore" were searching for vulnerabilities on the Russian site Mail.ru.  And probably not hard to find.  Mail.ru is, wisely, one of HackerOne's many Bug Bounty program clients, and these enterprising hackers were hoping to pay the rent.  Their tool of choice for web application security testing is something known as Burp Suite, which they run on their browser of choice, which is Firefox.



The trouble was the web subdomain of Mail.ru that they were needing to poke at, and it was shown as redacted in the stories where I was trying to pull this information together, the mail subdomain was all in Russian, which none of them spoke.  They knew that Chrome would do translation for them, but they didn't want to use Chrome.  So they went looking for Firefox extensions to perform the Russian language translation.  But they soon discovered, when looking for a translation extension, that a great many of them had been removed due to critical security vulnerabilities.  And in thinking about this further, they realized that any page translator would need to have direct and deep access to the web page's DOM, you know, the document object model.  In other words, due to the fact that all these had been removed because of security problems, they realized that it's very difficult to make a translator fully secure; and, conversely, very easy not to.



So one of the members of the team had previously found multiple vulnerabilities in other Microsoft products, so they had some experience in dealing with Microsoft.  And what captured their attention was that Microsoft's Edge browser now had built-in translation.  That was something that had been added a while ago.  And since Edge also has a bounty program, they figured they might be able to get their rent paid.  So they decided to switch to Edge.



LEO:  This is such a funny story.



STEVE:  It's great.



LEO:  This guy, it's got to be like a 12-year-old script kiddie; right?  I mean...



STEVE:  Yeah, yeah.  It's like, let's see if we can make some money.



LEO:  Okay.  Let's see now.



STEVE:  So they switch to Edge.  They go back to the Russian site, and they use Edge's built-in translator.



LEO:  Yes.



STEVE:  They were immediately swamped with cross-site scripting error pop-ups.  They didn't quite believe it, so they did the same thing with Chrome, using its built-in Russian translator.  No pop-ups.  So Chrome's translation system appeared to be secure, whereas Edge's was looking like a total meltdown.



So they began digging into Edge, and they quickly discovered that Edge's translator was failing to properly sanitize HTML image tags.  This allowed them to provide their own malicious JavaScript, which would run in the context of the origin domain.  In other words, you could take over any site that you visited, like with Edge and a little bit of tweaking.  So as web browser security bugs go, it doesn't get much worse.  In fact, it's so bad that they realized that they had found a class of cross-site scripting problems known as UXSS for Universal Cross-Site - too bad it's not "G" for Gourmet.  Anyway, it's Universal Cross-Site Scripting.



They then verified that anyone accepting a friend request on Facebook could be compromised; that web-based applications, for example Instagram, published on the Windows Store would also be vulnerable because the Windows Store operates under the same Microsoft Edge Translator that was responsible for triggering this universal cross-site scripting attack.  And as regards to paying the rent, their story had a happy ending.  Edge is now significantly more secure.  And Microsoft replied:  "Thank you for taking the time to share your report.  Based on the assessment of our engineering team, we have determined that your case #65633 is eligible for a U.S. $20,000 bounty award under the Edge on Chromium Bounty Program.  Congratulations."  So they published...



LEO:  Nice.  Very nice.



STEVE:  Isn't that great?  They published their timeline on the 3rd of June.



LEO:  See, it's good not to know Russian.



STEVE:  Yes, it comes in handy.



LEO:  Comes in handy.



STEVE:  On the 3rd of June they sent the report to Microsoft.  On the 7th, four days later, a reply from Microsoft saying that they were reviewing their June 3rd report.  The next day, additional impact information was sent.  On the 15th, report was triaged.  The 17th was the notification that they had been awarded a $20,000 bounty.  Two days later, on the 19th, a pre-release patch was issued.  And then on the 24th, last Thursday, a patch update was pushed.  A CVE was assigned.  So that's not too bad.  Microsoft was first notified on the third, and the bug was patched and pushed out exactly three weeks later, as I said, last Thursday on the 24th.



So that's not the three days which appears typical, or at least possible, for the Chromium team.  But it sure beats the catastrophic three months during which Microsoft apparently twiddled its thumbs before publishing a patch for the Exchange Server ProxyLogon flaw which, you know, gave us all of our excitement toward the beginning of this year.  So a happy ending.  These guys got their rent paid.  It paid off to poke around.  And I'll just remind our listeners that some of these problems are not hard to find.  You just have to kind of try stuff and, you know, use something that does web application security checking.  There are a bunch of free tools and open source tools available for that.  And just do things.  And when stuff happens, then pursue it, and maybe you'll be able to pay your rent, too.



LEO:  Really, that is really - a lot of exploit discovery is just trying things; right?



STEVE:  Yes, yes.  The automated version of that we call fuzzing; right?



LEO:  Right.



STEVE:  And the human - but you can also fuzz as a human.  You can just do things that the fuzzers won't do because they haven't been aimed at it.  And it's things like this.  It's like trying combinations that haven't been tried before.  It's sad, but that's pretty much all it takes to find something that crashes or something that pops up and, wait a minute, this looks like a cross-site scripting vulnerability.  Look, explore this further.  Because it's unfortunate that the security industry, or the security of the industry is currently at this state where, yeah, just do something.  And you might discover a vulnerability and make tens of thousands of dollars.



LEO:  Yeah.  That's hysterical.



STEVE:  Okay.  So we're not yet FLoCed.  Of course, I had to title this that.



LEO:  Mm-hmm.



STEVE:  The future of user profiling remains uncertain.  Now, as our listeners will recall, back near the start of COVID, the very clever Bluetooth-based, privacy-enforcing, exposure notification device proximity tracking technology, which was jointly designed and developed by Apple and Google, was met with skepticism.  No one understood it.  So in the immortal words of the Monty Python troupe, "Run away."  And Amazon's recent rollout of their beautifully designed, triple-encrypted, multilayered tunneling, low-bandwidth Sidewalk technology was greeted with hysteria by the popular press, claiming that it allows your neighbors to use your WiFi.  Gasp.  A well-meaning non-technical friend of mine phoned, warning me to disable Sidewalk immediately.  And of course those of us who share this podcast know that's not at all what it is.



Meanwhile - reality check - hundreds of millions of people are blithely plugging all manner of inexpensive IoT devices into their home networks, joining them to their internal LAN WiFi, whereupon those devices immediately connect back to servers in politically hostile foreign lands over which there is absolutely zero oversight or security.  But trust in Apple, Amazon, and Google, who are all carefully designing super-secure solutions, oh, no.  Run away.



In a similar vein, I was, and I continue to be, enamored of Google's FLoC technology.  Yes, warts and all.  If we must have user browser history profiling, it seems to me that being tagged with an amorphous and periodically changing interest-based cohort identifier beats the hell out of having everyone carrying unique third-party cookies around which uniquely and statically identify them individually, rather than as merely a faceless member of an amorphous cohort.



I would far prefer that legislators simply outlawed all forms of online profiling.  We know that the EFF will be satisfied with nothing less.  But that doesn't appear to be close to happening.  And just like the $5 IoT devices which connect to cloud servers located in hostile countries, many people are missing the forest for the trees because let's not forget that these days most of us are already being identified by a highly static 32-bit identifier known as an IP address.  Some identity blurring occurs thanks to multiple machines located behind NAT routers having a single public IP address.  But if IPv6 ever succeeds in giving each and every endpoint its own IP, which is its goal, that blurring will also disappear.



So I wanted to briefly revisit FLoC today because, as with those other well-conceived and explicitly well-designed solutions, Google's FLoC has landed with a hard thud.  Not one other browser has agreed to adopt FLoC, including those that are based on Chromium's own open-source codebase - Brave, Edge, Opera, and Vivaldi.  And Firefox, not based on Chromium, is also a definite no, thank you.  A recent analysis by Digiday discovered that Amazon - Amazon - is already preemptively blocking Google's cookie-free solution across its various web properties, including Whole Foods, Zappos, Shopbop, and Goodreads.



So as a result of all of the FLoC pushback, the reason we're talking about it today, is that Google recently updated their rollout timeline, which is putting it politely, announcing that they would be delaying FLoC's wider rollout from its originally planned usage starting early next year to now late year after next, meaning somewhere toward the end of 2023.  And I don't know how they arrived at that.



LEO:  Sounds like the 12th of never, I think, yeah.



STEVE:  Yes.  I think that's the case.  And perhaps not coincidentally, Google has been hit with some new regulatory setbacks in the EU, after the European Commission opened a wide-ranging investigation into Google's digital advertising business to examine its "plans to prohibit the placement of third-party 'cookies' on Chrome and replace them with the 'Privacy Sandbox' set of tools," meaning FLoC, and assess its "effects on online display advertising and online display advertising intermediation markets."  So it sure sounds to me as though there's some moneyed political lobbying going on behind the scenes there.  And in a similar move earlier this month the UK's Competition and Markets Authority, their CMA, announced that it's taking up a "role in the design and development of Google's Privacy Sandbox proposals to ensure they do not distort competition."  So again, there are clearly some powerful forces behind this legislative saber-rattling.



Of everything that is happening, the third-party cookie stovepiping that was introduced in Firefox 86's "Strict" privacy mode is the best solution until something better comes along.  By breaking the browser's traditional single shared cookie store into individual "stovepiped" per domain cookie stores, third-party cookies will continue to be honored in Firefox in exactly the way they were originally designed to be.  But when a user who received a third-party cookie in one domain then visits a different domain, that third-party cookie from the same third party will not be returned.  Rather it will be given a different cookie for that stovepiped first-party domain.  So this may be the solution.



And of course the problem is that we have fingerprinting and other sorts of persistent storage that those that want to track us are using.  And of course the fact that, even with Firefox's solution, the fact that all of those various queries will still be coming from the same IP means that all of that fancy dancing we're doing in the browser, whether with cookies or fingerprinting or FLoCs, amounts to very little. While we run around in circles, the tracking companies are probably chuckling because they're thinking, hey, you know, we got the guy's IP, and that's not changing very often.  So we know what they're doing, even when they try to bob and weave.



Okay.  This headline brought me up short.  And I thought, what?  The headline was "Irish Ransomware Attack Recovery Cost Estimate:  $600 Million."



LEO:  What?



STEVE:  I know.



LEO:  That's crazy.



STEVE:  $600 million.  It's like, how expensive were those servers, and did they melt?  It's like, what?  So back in the middle of last month, Leo, you'll remember it was about six weeks ago, we covered the news that Ireland's national health system, known as the HSE, that stood for the Health Service Executive, was hit by the Conti ransomware gang.



LEO:  I remember, yeah.



STEVE:  Yup.  And this forced them to take their entire national healthcare IT infrastructure offline.  Also recall, not only was the Conti gang demanding - it was an odd amount.  It was $1,000 shy of $20 million in ransom.  And, what, is that like there's some limit that gets triggered, or some transaction limit?  Who knows why?



LEO:  You get a little discount.  You get, yeah, a little bit off.



STEVE:  That's right.  So it was $1,000 shy of 20 million that they wanted, figuring that they'd hooked a big fish.  And then, remember, Ireland's Prime Minister himself declared that no ransom would paid.  And not only that, in something that was a little curious, the High Court of Ireland then issued an injunction against the Conti ransomware gang, whom they couldn't find, demanding that the 700GB of stolen HSE data be returned and neither sold nor published.  And, further, that once having done that, the members of the gang identify themselves by revealing their full and true names, their email addresses, and their physical addresses, then come to Ireland to turn themselves in to Irish law enforcement immediately.



LEO:  You must turn yourself in immediately.



STEVE:  This is the High Court of Ireland.  We shall not be denied.  Right.  Well, today we have an update on the situation in Ireland.  First off, it will surprise no one to learn that the Conti gang members, doubtless based in Russia, were somehow able to resist the urge, the compulsion, to comply with the Irish High Court order; and that all gang members, as far as we know, remain unidentified and are still at large.  What has surprised many, however, is that Paul Reid, the HSE's director general, has estimated the recovery costs to total $600 million.  600 million.



LEO:  Wow.  Maybe they should have paid; you know?  Geez.



STEVE:  Well, actually this is not even for the key.  It was given to them.



LEO:  Oh.



STEVE:  Yes.  So upon closer examination, the great majority of that appears to be more than just recovery.  During the hearing, which was last week, Reid noted that the immediate cost of recovery would total 120 million.  Which, okay, is still far more than...



LEO:  Still a lot, yeah.



STEVE:  ...the 20 million requested in ransom.  Reid stated that further investments in replacing and upgrading the affected systems and other expenses, he said, which is a real question mark in my mind, would bring the total cost to an estimated $600 million.  Now, I'd sure love to see an itemization of that.  He predicted it would take months for HSE to fully recover from the attack.  Among the many expenses was the cost of hiring technical experts.  Okay.  Maybe I'm for hire.  I hadn't considered this before.



LEO:  Yeah, you know, there's good money in there.



STEVE:  If he's got $600 million he needs to find a place for, you know, I might be able - no.  Not until after SpinRite 6.1.  Don't worry.



LEO:  Okay, thank you.



STEVE:  But, you know, yeah.  Apparently they're in no hurry to get this thing fixed.  So anyway, Reid said:  "We have also engaged international expertise."  Okay.  They didn't phone me.  "There are costs we will incur in the future, and we need to put in place a security operation center" - apparently it's going to have lots of big screens, Leo, very impressive - "to monitor our network on a more comprehensive basis."  Yeah.  Maybe that would be a good idea.  So it does sound more as if he's softening them up for his forthcoming budget.



He also reported that, so far, HSE has decrypted 75% of the affected servers.  Despite threats from the Conti group to leak the hacked stolen data, HSE stuck to the Prime Minister's refusal to pay and instead forwarding all the information they had about the attack to Ireland's National Cyber Security Center.  And then, a week after the attack, the Conti gang provided a decryptor, which Irish officials began testing.



So, much as has happened in other major attacks where the gang suddenly realized, oh, crap, we stepped in a big one here, let's just try not to have Putin's goons come after us.  We're going to try to be a little socially responsible after the fact.  What's interesting is that a week after the attack, they provided them with a decryptor.  The decryptor's been used to decrypt three out of four of the affected servers.  Yet they're saying that, oh, this really hurt, and we're going to need $0.6 billion, right, $0.6 billion to recover from this.  So I guess they're going to get some really pretty shiny new servers, Leo, and maybe a big network operations center with those screens where you've got little blinky lights all over the map showing connections and things.  It's got to be like what they have on TV for that much money.



LEO:  That's crazy.



STEVE:  Yeah, it's nuts.



LEO:  Crazy.  Maybe they're just throwing everything out and starting over.



STEVE:  It may be that their stuff is really old, and they're able to make a case for, like, look, we can't fix it.  We've got to replace it.



LEO:  Yeah.



STEVE:  Maybe, Leo, they had a bunch of Western Digital My Book NAS devices.



LEO:  Oh, lord.  Oh, lord.  Geez.



STEVE:  So I titled this next one "Dude, where's my data?"  Last Friday, Western Digital posted the following.  They said:  "Western Digital has determined that some" - I love that.  Turns out maybe 55,000, but we'll get there in a second - "that some  My Book Live and My Book Live Duo devices are being compromised through exploitation of a remote command execution vulnerability.  In some cases, the attackers have triggered a factory reset that appears to erase all data on the device.  We are reviewing log files which we have received from affected customers to further characterize the attack and the mechanism of access.  The log files we've reviewed show that the attackers directly connected to the affected My Book Live devices from a variety of IP addresses in different countries.  This indicates that the affected devices were directly accessible from the Internet" - which of course they were designed to be - "either through direct connection or through port forwarding that was enabled either manually or automatically via UPnP."  Which, again, they were designed to do.



"Additionally, the log files show that on some devices the attackers installed a trojan with a file named .nttpd,1-ppc-be-t1-z, which is a Linux ELF binary compiled for the PowerPC architecture which is used by the My Book Live and Live Duo.  A sample of this trojan has been captured for further analysis and has been uploaded to VirusTotal."  And it lights up like a Christmas tree.  They said:  "Our investigation of this incident has not uncovered any evidence that Western Digital cloud services, firmware update servers, or customer credentials were compromised."  Well, okay, no evidence, but we'll see that it's completely possible.  They said:  "As the My Book Live devices can be directly exposed to the Internet through port forwarding, the attackers may be able to discover vulnerable devices through port scanning."  Uh-huh, yeah.  That did happen.



Then they finish:  "We understand that our customers' data is very important."  Okay.  We sold them something to store it, after all.  They said:  "We do not yet understand why the attacker triggered the factory reset."  Okay, well, there's lots of speculation on the Internet.  "However, we have obtained a sample of an affected device and are investigating further.  Additionally, some customers have reported that data recovery tools may be able to recover data from affected devices, and we are currently investigating the effectiveness of these tools."  Huh.  "The My Book Live series was introduced to the market in 2010, and these devices received their final firmware update in 2015."



Okay.  End of posting, so they had a five-year maintenance life after they were introduced to the market in 2010.  So what we have here is an unfortunate situation.  We have an instance of long-abandoned IoT NAS devices continuing to be used for six years past their end of support life.  You can't really blame Western Digital for retiring support after five years.  It's their right to do so.  Much as we've said it's Microsoft's right to decide, okay, we're not going to keep supporting Windows 7.  Sorry about that.  Well, maybe if you pay us we will; but most of you, no.  Nor, with two important exceptions, can you really blame the users of those apparently perfectly well-functioning NAS devices for continuing to use them.  They appeared to be working well the day after their support ended, and even a year after their support ended.



And this reminds me of an experience I had as a youngster, definitely at the end of my teen years.  I was responsible for paying for my car insurance, and I received a notice that my insurance had lapsed.  I was horrified.  But I was also hungry, and I wanted to go...



LEO:  This sounds familiar.



STEVE:  I wanted to go - yeah, doesn't it?  And I wanted to go get some food.



LEO:  Yeah.



STEVE:  So, Leo...



LEO:  What did you do?



STEVE:  I got in my car; and, to my amazement, it still ran.  Even without insurance.



LEO:  No insurance, and it works.



STEVE:  I guess it didn't know.  And neither did those Western Digital My Book Live NAS devices know that their support had ended.  They just kept on running.



LEO:  Yeah.  Ended six years ago or something.  I mean, a long time ago, yeah.



STEVE:  Yeah, exactly.  It was six years ago.  Now, the plot thickens a bit when three years after that end of support, in 2018, a serious remote command execution vulnerability was found and made public.  The flaw was assigned a CVE of 2018-18472, which NIST, you know, the N-I-S-T, described as:  "Western Digital WD My Book Live and WD My Book Live Duo (all versions) have a root Remote Command Execution bug via shell metacharacters in the /api/1.0/rest/language_configuration language parameter.  It can be triggered by anyone who knows the IP address of the affected device."  Okay, in 2018.  Lay it out.  There it is.



The problem was first identified by WizCase in a 2018 report titled:  "Vulnerabilities found on Western Digital My Book, Netgear Stora, Seagate Home, and Medion Lifecloud NAS."  WizCase's report begins:  "NAS devices have become the storage device of choice for many small and medium businesses.  They're inexpensive, easy to operate, and you can add additional storage if you're running low on space.  But is it secure enough to protect your company's data?  That was the question on our mind when we brought in two security researchers..."



LEO:  Is there an alarm going off?



STEVE:  Oh, what do you know, spam.



LEO:  You have a spam alarm?  If I had a spam alarm, it would never stop going off.



STEVE:  So they brought in two security researchers, they said, "to see whether they could exploit any vulnerabilities in the leading NAS devices."  And remember there were those four.  "We focused on discovering only critical vulnerabilities that can be exploited remotely without any user interaction.  Meaning authentication bypasses weren't enough.  We wanted to execute commands on the devices remotely, with the highest privileges.  We were successful in every device."  So at the time of this, Leo, all four of those NASes were remotely exploitable with root remote privileges.



They said:  "All four NAS devices tested suffer from a zero-day, unauthenticated root remote command execution vulnerability.  The vulnerabilities allow hackers, governments, or anyone with malicious intention to read files, add/remove users, add/modify existing data, or execute commands with highest privileges on all of the devices."  They finished:  "It's our belief that there are many other NAS devices that suffer from similar vulnerabilities.  Both the vulnerabilities" - and they were dubbed 2018-18472 and 18471 - "remain unpatched at the time of this publication."  Okay.  And this was three years, in the case of the WD, three years after the device went out of support.  They said:  "There are nearly two million affected devices online."  That was then, 2018.



So we don't know how many of those nearly two million online NAS devices were WD My Books at that time.  That was 2018, and now we're three years later.  What we do know is that finding such devices has never been easier.  The public Internet can be scanned, and it has been.  A very recent count revealed 55,348 Western Digital My Book Live devices located, identified, known to be connected, and publicly accessible across the Internet.



So following last week's destruction derby, we need to collectively ask ourselves where the blame falls.  Those forensically reviewing the logs have suggested that the owners of the WD NAS devices may have been caught in the crossfire between two warring groups.  Given the detection of a Linux trojan on the device, it was a PowerPC-based Linux trojan, it seems that most of those WD NAS devices that were still in use had been found and commandeered into the service of a botnet years ago.



LEO:  So they had actually, probably since 2018 when that exploit was published...



STEVE:  Yes.



LEO:  ...been co-opted, but sitting passively.



STEVE:  Exactly.  The users had no idea.  It behooved those running the botnet to have those things stay on the 'Net so that they could be used for DDoS attacks and scanning for other things on the 'Net and so forth.  So it's believed that their subsequent destruction via a factory reset wiping may have been the consequence of a rival group wishing to shut down a rival botnet. 



LEO:  I love this.  This is hysterical.



STEVE:  So all of this lost data occurred as a side effect, as I said, caught in the crossfire between two warring groups.  So I did say before, with two important exceptions, can you really blame the users of those apparently perfectly well-functioning NAS devices for continuing to use them?



LEO:  No.



STEVE:  Those two important exceptions are, first, is it safe to continue to use anything that's connected to the Internet after its ongoing maintenance support has ended?  Okay, that's a good question.  At the same time, is it really practical to expect users of an expensive piece of equipment that's apparently working perfectly well to stop using it just because support, which it apparently doesn't need, is no longer available?



LEO:  By the way, I think Amazon's still selling them.  I mean, believe it or not.



STEVE:  Oh, wow.



LEO:  Yeah.  I know.  I can buy one for 373 bucks.  Oh, if you want it delivered by Friday, 399.  So these are just some old computer stores who had some stock, and they're still selling them, which is depressing as hell.



STEVE:  It is.  Secondly, we know in this day and age that anyone who is not maintaining multiple, and this is what I heard you mention when you were talking about this on a previous podcast, anyone who's not maintaining multiple backups of their important data is inherently placing that data at risk.  After last week's disaster, many people were posting that they were totally hosed by the loss of 2TB of irreplaceable data.



You know, many years ago I designed an advertisement which to my surprise won some acclaim at PC Magazine for being the most responded-to advertisement in the magazine's history to that point.  That ad began with the simple headlines:  "Hard Disks Die."  Then it posed the question:  "Ever Wonder Why?"  The point being that all mass storage systems are in a perpetual battle against the forces of entropy.  And in the end, entropy will win.  It always does.  As we know, nature abhors a sharp edge.



So it would be nice to think that Western Digital might have sent their registered owners of those drives a notice in 2018 warning them to take those drives offline because a critical remote compromise problem had been identified and would not be repaired since the drives were now three years out of service, out of warranty, out of maintenance.  I would be surprised if that had happened, but Western Digital had moved on by then, three years earlier, to newer devices.  So I guess I'd conclude that the responsibility falls on the users of those systems.  They were obtaining many years of continued service life from an out-of-maintenance device.  And in the cases where they were screaming about losing valuable information, it was probably going to happen sooner or later anyway.  So, oops.  You know?  Maybe lesson learned?  But Leo, your point about these things still being available for sale...



LEO:  That's really shocking, isn't it.  I can't believe somebody's selling them.



STEVE:  It's horrifying.



LEO:  Yeah.



STEVE:  It's horrifying.



LEO:  Yeah.  And Western Digital abandoned these, I mean, really abandoned them, hard abandoned, because they knew there was a critical exploit in 2018 and did nothing.



STEVE:  Yeah.



LEO:  But I think, you know, I mean, yeah, you should make sure everything you have is being updated, preferably automatically over the air, and not use stuff that is out of date.  But that's easy to say.  The people who are buying these are buying them at big box stores, and it's a big hard drive, and they're using it for backup.



STEVE:  And it's got a brand name.  I mean, Western Digital is a great name.  So they're probably thinking, hey, Western Digital, that's great.  Wow.



LEO:  That's too bad.



STEVE:  How big?  A couple of terabytes?



LEO:  The one I can buy right now for that $383 is 3TB.  So 3TB.  And yeah, just because it's labeled backup, people go, see, it's backed up, and then erase the original.



Before you go into this next story about John McAfee, I do want to tell people what you're about to hear might be triggering if you're considering suicide.  There is a National Suicide Prevention Lifeline in the United States.  You can call right now for free and get free confidential support, if you're in distress.  Great crisis resources for you or your loved ones.  It's 1-800-273-TALK.  1-800-273-8255.  And we just want to be responsible since we're going to talk about John McAfee next.



STEVE:  That's good.  And we know that COVID has been an extra stressor for people.



LEO:  Especially teenagers.  I know of two teenagers who took the very poor choice, I think because of loneliness during COVID.  So, yeah, we're all going through it, but you don't have to go through it alone.  And if you're not in the United States, you can google "suicide prevention lifeline," and you'll be able to find one in your area.



STEVE:  Good.



LEO:  We don't want to lose you.  We want you to be around.  Anyway.



STEVE:  Yeah, I was unhappy when I was younger.  And, you know...



LEO:  It's normal.  And that's the problem with suicide.  It's a permanent solution to a temporary problem.  You know?  Things do get better, I know.  But sometimes we just can't take it.  And don't do it.  Don't do it.



STEVE:  So I wanted to note that last Wednesday John McAfee was found dead by hanging at the age of 75 in his jail cell in Barcelona, Spain.  His extradition to the United States, where he would have been facing a number of legal charges of willful tax evasion, had finally been approved by a court in Spain.  And despite his earlier statements that he would never take his own life, and he said that foul play would definitely be involved if he ever appeared to have done so, everyone assumes that he changed his mind, and that that must have been what happened.  His attorney said that his nine months in prison had brought him to despair, and attempts to revive him had failed.



And as we all know, John was a character and a half, with a life full of antics.  I think that the first time we talked about him on this podcast was when he was being sought in connection - of course he was famous, right, because of McAfee and McAfee Systems and McAfee AV.  I didn't realize he had some connection to ZoneAlarm, which was a little horrifying for me.



LEO:  He, yeah, well, but back in the day I think he was quite a bit more respectable.  You know, he made 100 million selling McAfee to Intel.



STEVE:  Yeah.



LEO:  So he did quite well.  But he, as far as we know, he squandered almost all of it in kind of oddball things.



STEVE:  Well, and things went weird, too.



LEO:  Yeah.



STEVE:  I think the first time we talked about him was when he was being sought in connection with the murder of his neighbor, a guy by the name of Gregory Faull, F-A-U-L-L.



LEO:  In Belize.  In Belize.



STEVE:  Yes.  He was his next-door neighbor in Belize.  This neighbor had been found dead, shot in the back of his head with a 9mm.  And prior to that, Gregory had previously confronted John after one of John's quite aggressive dogs had bitten someone in the area.  The dogs were apparently known to get loose and run wild in packs, terrifying the community.  So he was a source, McAfee was, of adventure and controversy.



LEO:  Adventure is a good word for it.



STEVE:  In his earlier years he had worked at NASA, Xerox, and Lockheed Martin, before launching the world's first commercial antivirus software in '87.  And in fact he and I interacted just once by phone.



LEO:  Well, that's what I was curious, if you had met him, yeah.



STEVE:  It was before his launch of McAfee AV.  After I had written a series of three columns in InfoWorld, which he was reading, which imagined with as much detail and accuracy as I could exactly how a theoretical software virus would behave.



LEO:  Oh, interesting.



STEVE:  And I don't recall now how clear I made it that this was conjecture.  But a quite animated John McAfee, who was unknown by the PC industry at the time, phoned my office, wanting to compare notes and virus samples.  He was sure, and amazed to discover, that I had viruses, clearly, because I had exactly described the behavior of the viruses he had.  And he was very disappointed to learn, and actually it took me some time to convince him and like talk him down, and I'm unsure that I ever really did.  I think he just didn't really believe that my three-column series about software viruses was entirely written from my imagination as a software developer, not as a virus discoverer.  Anyway, I said, "Sorry, John.  I mean, like, really, really, really, I don't have any.  If I was a virus, this is how I would behave."  And he's, like, "Really?  Oh, well, I thought we could, you know, I'd show you mine if you showed me yours."  So anyway.



LEO:  I saw some stories about him fairly aggressively calling people to get information or copies of viruses.  He was working at Lockheed when he got a copy of Brain in the late '80s and started writing McAfee.  But, you know, I think he wanted to write an antivirus, but he needed to understand what it was he was blocking, what he was preventing. 



STEVE:  Yeah.  [Crosstalk].



LEO:  [Crosstalk] worked; right?



STEVE:  It's funny you mention that, Leo, because I was thinking the same thing this morning, like okay, we know how they work now.  So would it have been behavior based?  It's hard to imagine it would have been signature based because, what...



LEO:  There weren't any.  There were four or something, yeah.



STEVE:  Right, exactly.  Exactly.  Yeah.  So it's crazy.



LEO:  He probably was trying to come up with heuristics so that you could watch for a certain kind of behavior.  That's the ideal way to do it, signatures plus heuristics.  But I don't know, yeah.



STEVE:  Yeah.  And we didn't have an Internet back then.



LEO:  Right.



STEVE:  So they had to live, they had to jump from floppy to floppy.



LEO:  You had to send him a floppy, yeah.  Hey, John, I got one.  It's on a floppy, here.



STEVE:  We didn't have USB.  We didn't have thumb drives.  All we had, the only thing that was transportable was diskettes.



LEO:  Right.



STEVE:  And so the viruses, such as they were, had to be very tiny.  I think I remember that some of them lived in Track 0 because there was still - I think there was still cylinder alignment.  So I think there was space on Track 0 after the boot sector.  And so you'd have - there were, like, I remember boot sector viruses, I mean, they had to be...



LEO:  That's right, that's right.



STEVE:  ...really, really small.



LEO:  So what you'd do is you'd put it on the boot sector of a floppy.  And if somebody booted that floppy, attempted to boot from that floppy, it would infect their system.  This is pre-hard drive.  Or did it have hard drives?



STEVE:  Oh, yeah, if they had a hard drive.  Or it would go into RAM and then move onto any other diskettes that...



LEO:  Any other floppy you used, yes.



STEVE:  ...that they then stuck in.  And before you knew it, I mean, and I remember there were like red floppies that were infected that researchers were, like, using.



LEO:  Yes.  Don't touch.  Don't touch.  Yes.



STEVE:  Wow.  Okay.  So a fun topic, and one that is up in the air.  Where exactly will Windows 11 run?  And the subtitle is don't ask Microsoft because they have no clue.



LEO:  They've actually changed the story several times already.



STEVE:  I know, Leo.  What a mess.  So, okay.  The trouble is there's no difference between Windows 11 and Windows 10.  And everyone knows it.  It's the same operating system.  So Windows 11 can run anywhere that Windows 10 runs, unless Microsoft chooses to place what you'd have to consider somewhat arbitrary limits on where they will allow Windows 11 to run.  And there's just no way that's going to go down well.



On my own lovely Intel NUC that I was just talking about last week, which is a fast 4-core Intel i7-6700HQ Skylake processor with 32GB of RAM, a very large GUID partitioned NVMe mass store, and TPM v2.0, I received that screen on the show notes above, saying:  "This PC can't run Windows 11."  It says:  "The processor isn't supported for Windows 11.  While this PC doesn't meet the system requirements to run Windows 11, you'll keep getting Windows 10 updates."  Okay.  So, right.  So for some reason this perfectly reasonable Intel NUC, i7-6700, perfect little machine, nope, won't run it.  Now, it runs great in a VM.  I am running it in a VM.  So, okay.  But apparently not natively.



So because there's no actual legitimate reason why Windows 11 cannot run everywhere and anywhere Windows 10 runs, Microsoft themselves hasn't yet decided where Windows 11 should be allowed to run.  Their own most recent statement, as of yesterday, essentially admits this.  They said, and I quote:  "Today we're releasing the first preview build of Windows 11 to the Windows Insider community."  Meaning that's not that earlier dev one we were talking about last week and the week before.  This is it, Windows Insider community.



They said:  "In support of the Windows 11 system requirements, we've set the bar" - okay, right, it's a bar.  Where are we going to set it?  We haven't decided yet.  So, oh, wait, wait, if it's too high, you can't jump over it.  If it's too low, then you don't have to jump very hard.  So we've set the bar, and it's settable, for previewing in our Windows Insider Program to match the minimum system requirements for Windows 11.  Okay?  So we've decided how much RAM you should have, how big your hard drive should be, those things.  You know, it's all variable; right?  How many cores you should have.  We think two's enough.



Okay.  "With the exception," they wrote, "for TPM 2.0 and CPU family/model.  By providing preview builds to the diverse systems in our Windows Insider Program" - meaning maybe other people, maybe Windows Insiders have NUCs just like I do.  Wouldn't want to rule them out.  Anyway:  "We will learn," they wrote, "by providing preview builds to the diverse systems in our Windows Insider Program, we will learn how Windows 11 performs" - what a crock - "across CPU models more comprehensively, informing any adjustments" - informing any adjustments to the bar, apparently - "we should make to our minimum system requirements in the future."  And I wrote here:  "What a load."  Anyway:  "We look forward to the product feedback" - oh, they're going to get some.  Oh, and Leo, "and learnings."



LEO:  They love that word.  I hate that.



STEVE:  They're looking forward to the learnings.  Not one learning.  We're going to have multiple learnings.  Oh, baby, I guarantee you're going to have multiple learnings coming from this.  "As it's an important step," they wrote - yeah, deciding where it should run - "to prepare Windows 11 for general availability" - or perhaps limited availability - "this year.  Thank you to the Windows Insider community for your excitement" - uh-huh - "and feedback thus far!"  Oh, yes, it's already very exciting.  Given the mess and confusion this is creating, and I loved you guys last week, Leo, talking about how, I mean, Paul and Mary Jo were just shaking their heads.  How could they have screwed this up any more?  I mean, it's their own OS.  Anyway, they're getting blowback.  They're going to be getting blowback.



Okay.  So here, Leo.  I actually have a solution to this, believe it or not.  I think that what should be done is obvious.  There's a beautiful compromise available.  Unlike Windows 10, Windows 11 should require that any available security technologies be enabled on any platform where it runs.  But given that, it should run anywhere Windows 10 runs.  In other words, both of the systems I routinely use have a TPM.  One of them is v1.2.  That's the one I'm sitting in front of.  The other is v2.0, that Intel NUC.  And there's nothing wrong with v1.2.  It works just fine.  It's secure.  But neither of those TPMs are enabled or initialized on my hardware.  Both systems also offer Secure Boot, but neither have it enabled.  Microsoft claims that their telemetry shows that they have seen up to a 60% reduction in malware when TPM-enabled features, like Windows Hello and BitLocker encryption, are used on supported devices.  Now, it's unclear why that should be true at all, unless it's correlation and not causation.  Meaning people running with those security features enabled tend to also be more cautious and careful.  But okay.



LEO:  So that's an important point.  TPM does not help you avoid malware.



STEVE:  No.  No.



LEO:  It's for things like BitLocker.  It's a secure, basically hardware security chip; right?



STEVE:  It does, when it is - yes.  It's like a Secure Enclave.  So if you have Secure Boot enabled, it will prevent a rootkit virus, for example, from getting into your system.



LEO:  Right.



STEVE:  So that's useful.  So it creates a secure anchor, and it verifies the signature of each item in a chain, up to and including Windows is running.  So that's what Secure Boot is securing, is like that whole process.  They also said that devices using the new Windows driver model, meaning signed drivers, can achieve a 99.8% crash-free experience.  And of course that's apparently so long as you don't run Windows Update, which as we all know has the tendency of spoiling everyone's crash-free experiences.



Okay.  So if the price of allowing me to run Windows 11 on systems that can be run with greater security is simply turning on those features, which I haven't needed to or bothered to so far, that's a choice I will make.  But tell me that I cannot run Windows 11 on hardware where I know it can run just fine, well, good luck with that.  The machine I'm sitting in front of while we record this podcast is equipped with an older Haswell processor, specifically because remember Microsoft originally threatened not to support Windows 7 after Haswell.  So that forced me to immediately go get a Haswell-based system because I wanted to run Windows 7.  They were later forced to backpedal on that one when corporate America refused to make the move to Windows 10, which no one wanted at the time.  And corporate America insisted upon being able to run Windows 7 on more current hardware, so Microsoft ended up saying, okay, fine.  Because they could.



So anyway, just to be clear, it seems it will be really interesting to see how this plays out for the rest of the year.  And we have six months, so there's time.  To me, I would have no trouble if Windows 11 looked and said, hey, you've got a TPM.  Turn it on.  Your system will do Secure Boot.  Turn it on.  And make you do that in order to run Windows 11.  That seems okay.  And there's been discussion of this for the last couple weeks.  The problem is TPM 1.2 is fine.  And TPM, it first appeared on laptops.  Many fewer desktops, older desktops, have it.  And so I think the problem is there will be many desktops running Windows 10 where Windows 11 can run just fine.  But if they stick to requiring TPM 2.0 and Secure Boot, those systems are not going to be able to run 11.  For no reason.  I mean, it's the same as Windows 10.  It just has better-looking icons and rounded corners.  And boy, did you see the list of things they took out, Leo?  That's really nice.  They got rid of a bunch of the crap that nobody wants.  Of course Xbox is still there.



LEO:  This is the thing that puzzles me because you famously wrote the program Never10 because you never were going to go to Windows 10.  Now you're all upset because you can't go to Windows 11.  But I'm a little confused.  I actually thought the thing people would hate the most, until the Microsoft Event, was that they centered the Start Menu.  And I thought, oh, we're going to hear so much about it.  Microsoft said "Hold my beer" and came up with something to get people really incensed.  You know, we'll wait and see.  It may not be - they've already changed the specs a little bit.  And by the way, they changed that compatibility checker, too, without telling anybody.



STEVE:  Yeah.



LEO:  So I think they're going to be a little sensitive to the pushback.  But it's funny, I mean, it is Windows 10; right?  Just cosmetically different?



STEVE:  Yes.



LEO:  Do you want it because they took things out?  Is that why...



STEVE:  Leo, if you click down a couple layers, you can still find a dialog for Windows 95.  



LEO:  Oh, yeah.  Oh, absolutely.



STEVE:  I mean, it's the same operating system.



LEO:  No, that's absolutely the case.  So, yeah, I figure - I guess you can live without it.  The only issue will be how long will they give you security updates for Windows 10.



STEVE:  Yes.



LEO:  They've already committed to 2025, but they can extend that, as well.



STEVE:  They can.  And so I've gotten used to 10.  I had to make sure that SQRL ran under 10.  I run 7, and I run 10.  New systems that I set up are all running Windows 10.  All the laptops that Lorrie's using for her remote home neuro clients, they're all running Windows 10.  You know, I've made peace with it.  I have no problem with it.  I just think we need to keep Microsoft honest.  And the idea of saying, oh, yeah, we're not going to let you run 11 on systems where it can, and we're not sure why...



LEO:  Microsoft's real problem is communication.  They just for some reason...



STEVE:  Oh, boy, they really stepped on it this time.



LEO:  Yeah, yeah.



STEVE:  Okay.  So speaking of, the next headline here I've titled "Why Not WhyNotWin11?"  There's a new piece of well-intended, but very poorly written, junk known as "WhyNotWin11."  You can most easily find it by going to https://WhyNotWin11.org. But don't go to WhyNotWin11.com, which is a domain that was grabbed up by someone else, who then ignored the author's pleas to synchronize with him.  And don't go to http://WhyNotWin11.org because that won't properly redirect you to GitHub.



Okay.  So the whole thing is a mess.  I'm sure its author means well.  It might even eventually provide some useful information.  But you'll need to push past Chrome's and Windows' malware alerts because the app's compiled script is changing minute by minute as its author keeps trying to get it right  thus preventing the code from ever maturing and having the chance to earn a reputation  and the executable is unsigned.  Since the app initially seemed useful, and since I could verify the safety of its operation from its source, I briefly toyed with offering to sign it for the guy.  But having watched its subsequent implosion and mismanagement, GRC will never have anything to do with it.  Lawrence at BleepingComputer picked up on it and gave it a lot of attention last week, which brought a lot of attention to it.



LEO:  We mentioned it on TWiT, as well.  Daniel Rubino plugged it.  So, yeah.



STEVE:  Yeah.  And so Microsoft, as we said, has tripped over themselves, creating a vacuum for it.  And it may settle down.  My sense is that ultimately Microsoft's own PC Health Check tool will be what people should use.  But I wanted to make sure everybody knew about it.  However, the coolest thing about WhyNotWin11 is that it made me aware of a very slick and quite capable 100% free Windows scripting tool and environment called "AutoIt Script."  And that's something that I wanted to put onto our listeners' radar.  I've tweeted about it.  I mentioned it in GRC's newsgroups.  It got a bunch of people excited.  AutoItScript.com, A-U-T-O-I-T-S-C-R-I-P-T dot com.  It compiles quite capable scripts.  The scripting language is Turing complete.  It's a complete scripting environment.  It compiles them into standalone and independent EXEs that do not require any .NET libraries.  It runs under any edition of Windows.



The language is extensive.  It allows for Windows UI to be implemented to create quick Windows automation apps.  And it includes a wonderful and complete 6.8MB old-style compiled Windows Help .CHM file.  The help file contains a clear description, tutorials, a language reference, a GUI reference.  It's able to invoke COM objects in order to make that simple.  It runs PowerShell.  You can script run-as events, completely script your existing Windows apps.  It might be just the ticket for enterprise IT admins who need to quickly get something automated and pushed out without resorting to VB.NET or something heavier.  Anyway, I just wanted to make sure it was on everybody's radar:  AutoIt Script.



I use one particular browser shortcut like crazy, and that's CTRL+L.  Happily, it's universally supported.  It takes you to and highlights your URL, and you can imagine while I'm putting the podcast together because I've got links to everything in the show notes, I'm often needing to grab the URL that I'm looking at.  So I just wanted to make sure everybody knew about CTRL+L.  It is just really, really handy.



LEO:  It's good to remind people because I forget.  And that is a very useful keystroke, really useful.



STEVE:  Yeah.  It just jumps you like right off the page to the URL and highlights it so you can then do a CTRL+L.



LEO:  You can copy it or replace it, yeah.



STEVE:  Exactly.  CTRL+C or CTRL+V if you want to copy over it and then go somewhere else.  Also, for years there was a program, it was called Teleport Pro, which was my go-to when I needed to clone a public website.  Sometimes you need to do that.  And I'm sure that old-timers among us have sometimes needed to end up going to the web archive, trying to find something, like a link is broken because a site that we just assumed would always be there disappeared.  There are a few reference sites that I use like crazy.  And a couple times one of them, there's one at I think it's Ctyme.com, it's got an instance of Ralf Brown's Interrupt List.  I'm sure, Leo, you remember the Ralf Brown Interrupt List.



LEO:  I don't.  I wish I'd had that back in the day.



STEVE:  Oh, it's like the standard reference for, like, everything.  And because I'm working with SpinRite, I'm down in IRQs and interrupts and INT 10 VGA BIOS calls and things.  And so I'm constantly using it.  And a couple times over the last year it's been offline for a while.  And I've thought, oh, crap.  Like, I mean, there are other sources of this.  Ralf Brown is a professor at Carnegie Mellon.  And back in the DOS days he created, he began compiling this, and it just became the galactic standard.  In fact, if you Google Ralf Brown, R-A-L-F Brown, so it's not - yeah, Ralf, R-A-L-F B-R-O-W-N Interrupt List, you'll get a ton of hits on Google.



Anyway, a couple days ago I just thought, you know, I have to copy this site just in case it ever actually goes away forever.  What I used is my favorite now go-to website copy tool that again, I just wanted to tell everybody about.  I made it this week's GRC shortcut.  So you can get to it with grc.sc/825, grc.sc/825.  It's Cyotek WebCopy.  It's complete free.  I like this company.  They seem to be good guys.  It's donation ware.  If you like it, give them some money.  They've been maintaining it for a while.  This is one of several things they offer. 



Anyway, there's really not much more to say except to say it just works.  It gets the job done.  It does a good job of taking a public site.  It's got all the bells and whistles you could want for, like, don't go offsite.  Don't go down more than N number of levels.  Don't bother pulling images.  Don't blah blah blah.  Or whatever you want.  It's also able to create a localized copy on your hard drive so that you then end up with a running copy of the site that was offline so that you never have to worry about something that you depend upon disappearing.  So grc.sc/825.



I have a page over in my forum.  I have my own private forum where my blog is over at forums.grc.com.  I have a page of my favorite things.  And I'm trying to keep that current, and I added this to that page.  So if you ever kind of remember that I had once mentioned something like what was that site for syncing, what was that Syncthing, what was that WebCopy thing, anyway, if you think of it, you can check that page.  And I am keeping it current.  And a Humble Bumble.  Bundle.



LEO:  You always call it a Humble Bumble.  I think it's the funniest thing.



STEVE:  I do, a Humble Bumble. 



LEO:  Yeah.



STEVE:  And that's bad because I created another shortcut which is not Bumble, it's Bundle.  So grc.sc/bundle.  And I realized that from time to time, when bundles come up, I can simply change where that shortcut points.



LEO:  That's a good idea, yeah.



STEVE:  So the most recent bundle, yeah, it'll always be grc.sc/bundle.  This is a cybersecurity bundle, Cybersecurity 2021 bundle by Packt Books.  And here's what it's got.  Looks like a bargain to me.  One dollar.  One dollar gets you three books:  "Mastering Azure Security," "Cybersecurity Attacks - Red Team Strategies," and "Metasploit 5.0 for Beginners."  One dollar.



Okay.  For $10, you add eight more to that.  "CompTIA Security+"; "Cybersecurity Threats, Malware Trends, and Strategies"; "Cybersecurity - Attacks and Defense Strategies"; "Mastering Malware Analysis"; "Learn Kubernetes Security"; "Learn Wireshark"; "Mastering Python for Networking and Security"; and "Cyber Minds."  I have no idea what that one is.



And then, for an additional $8, for a total of $18, you get 13 more, totaling 24 books:  "Microsoft 365 Security Administration"; "AWS Certified Security - Specialty Exam Guide"; "Learn Kali Linux 2019"; "Mastering Windows Security and Hardening"; "Learn Computer Forensics"; "Practical Mobile Forensics / Third Edition"; "Practical Threat Intelligence and Data-Driven Threat Hunting"; "Digital Forensics and Incident Response"; "Mastering Linux Security and Hardening / Second Edition"; "Practical Hardware Pentesting"; "Ghidra" - is that how you pronounce it, Ghidra?



LEO:  Yeah, that's that reverse engineering tool.



STEVE:  Yes, yes.  And it is not simple.  So believe me, "Ghidra Software Reverse Engineering for Beginners," we're all a beginner.  I looked at that thing, and it's like, whoa.



LEO:  Yeah, it's amazing.



STEVE:  "AWS Penetration Testing"; and "CISA - Certified Information Systems Auditor Study Guide."  All of that for $18, and it's a charitable contribution.  Has it all been going to charity?  I think it's all going to charity.



LEO:  No, a percentage goes to charity.



STEVE:  Oh, a percentage, a percentage to charity.  So anyway, grc.sc/bundle, B-U-N-D-L-E.  And, I mean, even if some of those are not good, wow, you know, $18.  There's got to be some good stuff in there.



LEO:  They're all eBooks.



STEVE:  Yes, yes.



LEO:  You have to be okay with that.  But that makes it easier to search them, so that's a benefit.



STEVE:  Yeah.  And PDFs, you're able to search a PDF pretty quickly. 



LEO:  Yeah.



STEVE:  Okay.  Two pieces of closing-the-loop feedback.  A frequent and very useful Twitter DMer sent this.  He said:  "Re: SN-824," which of course was last week.  He said:  "Surely 'the role of commercial providers'" - and first of all, to remind people, you and I, Leo, were scratching our heads.  That was something that - was it a Google person?  Somebody was talking about the rate at which vulnerabilities were occurring, and he referred to the role of commercial providers, and we were thinking, what in the world is he talking about?  Didn't make any sense.



He said:  "Surely it must be the commercial exploit vendors getting their hands on these, rather than Google and the Chromium project."



LEO:  Right, right, right.



STEVE:  He says:  "I guess they have reason to believe at least some of these zero-days" - oh, that's right, it was in the context of six zero-days so far this year.  In fact, there had been six, and that was number seven, were being sold on the open market before exploitation started in the wild.  So anyway, I wanted to thank him for that.  I'm sure that's what the Chrome guy was referring to.



And finally, Mementh tweeted:  "Serious question, Steve.  Windows 11 might require TPM.  How TNO is it?  Can I trust it to keep the secrets the NSA wants from me from getting out?  Would you put info behind it that would cost you your life if it got broken?  I can't recall what your opinion on it was, and I recall the drive you fixed was locked by it."  I thought that was a great question to wrap this up.  The answer is no.  I did some digging during that week that I was trying to come up with some way to unlock the contents of that BitLockered and TPM key-protected drive to bypass it.  What could I do?



Turns out it's actually not difficult.  The TPM chip which exists in chip form when it's not bound into the Intel firmware, and I suspect it may be a different story when it is in the Intel chipset, but I'm not sure.  If it's part of a chipset and in an external chip in the family, then it may still be possible.  The point is the TPM chip, when it's a standalone chip, is on the motherboard, and it can have a digital signal analyzer hooked up to its pins, and its communication can be and has been decoded.



So certainly the NSA knows how to do that.  There's cool pictures, if you go to "Decrypt TPM" in YouTube, you'll find some YouTube videos of people doing that.  You use a digital trace, a digital signal capture device, and out comes all these cool-looking little square wave signals.  And that could be decoded.  And the key will be moving across one of the pins, digitally encoded, and you can capture it and crack the encryption in the case of the TPM.  So the secrets are being kept there.  But unfortunately they move over the wire which is exposed.  So not something that you could trust your life with.  But a great question.  Thanks for asking.



LEO:  And I had to laugh because - and I thought of you during the Windows 11 announcement when they said "This is the most secure version of Windows we've ever made."  And I thought, when have they not said that?  But you mocked that I remember when Steve Ballmer said that back with Vista or XP or one of the older ones.



STEVE:  And because we know, we know the story.



LEO:  Right.



STEVE:  Security is only something that you can see that did happen in retrospect when nothing bad happened.



LEO:  Right.  You don't know until you put it out in the world, basically.



STEVE:  Right.  Basically you cannot prove a negative.  And all you have is no evidence in the beginning of whether it is secure or not.



LEO:  We did our best.  You could say, "We did our best.  We tried really hard."



STEVE:  Yeah.  And we really thought that if we would only allow it to work on processors that you couldn't use till next year, that nobody would have a problem this year.



LEO:  I suspect it really comes down to selling more PCs, frankly.  That's what we've speculated.



STEVE:  Yeah, yeah.  Isn't that sad?



LEO:  That is sad, yeah, yeah.  But really, traditionally in the Windows environment, that's when you got a new version of Windows was when you bought a new computer.  I think most normal people don't upgrade.  Windows 10 broke that mold by offering a free upgrade to everybody.  But that's why they had to give it away for so long.



STEVE:  You know, my older Apple devices still work.  But they are slower than the newer Apple devices.



LEO:  Yeah.  That's right.



STEVE:  Right here is an iPhone 6 that I use because it's got this wonderful little hole.



LEO:  It's got the headphone jack.



STEVE:  I love that hole.  Oh, my god.



LEO:  Miss that, yeah.



STEVE:  Oh.  Now, and it's plugged in.  The battery's still 100% good because I don't think it's ever been unplugged.  Actually it was in my pocket for a while.  But I never let it discharge much because we know that lithium-ion batteries don't like it.  Oh, and by the way, Leo, I heard you talking about your exploded Pixel 4.



LEO:  Oh, so depressing, yeah.



STEVE:  Yeah.  I just had the battery in my iPhone 10, the iPhone X...



LEO:  Swell up.



STEVE:  It was replaced last Friday because it was still working perfectly.  It was funny, too, because I went to the genius at the Apple Store, and he said, "Oh, this is never going to pass the diagnostic."  I said, "Yes, it will."  He says no.  I mean, you could see all of the silver clips had, like, they were - it was like the screen had popped out of the backing. 



LEO:  Yeah, yeah.



STEVE:  Yeah.  And he ran their diagnostic, and he says, "I'll be darned.  Works perfectly."  I said, "I know."



LEO:  But you need to replace it because it's going to explode if you don't.



STEVE:  Well, yes, I was worried that if I ever had to travel, the TSA would look at this and go, uh, we're not letting you on the plane.



LEO:  What causes lithium-ion batteries to swell?  Because they don't all.



STEVE:  It's overcharging and outgassing.  So if you overcharge the cell, it produces gas.  And the gas then...



LEO:  Expands, yeah.



STEVE:  ...causes the battery to expand and pushes everything else out.



LEO:  Interesting.  And it seems to happen with age sometimes.



STEVE:  Yes, because what happens is you end up with some little tiny - can't remember now what the metal is.  I don't think they're nichrome.



LEO:  Oh, interesting.



STEVE:  But there's some little microfilaments.



LEO:  Microfractures.  Oh.



STEVE:  Which start to bridge.  And that causes the chemistry to get a little freaked out, and then it begins to outgas.



LEO:  Okay.  So it's, I mean, the Pixel 4 XL is not that old.  It's a couple years old.  And it's swollen enough that it pushed the back off.  And I guess I probably shouldn't continue to charge it; right?  That means it's time to either replace the battery or get a new phone.



STEVE:  Yeah, whatever.  I mean, I actually have somebody who had...



LEO:  You don't think it will explode?



STEVE:  No, it won't explode.



LEO:  Okay.



STEVE:  No.



LEO:  So if you tried to jam it back together again, you might puncture it and then cause a fire.  But if you just let it expand and let it expand naturally...  



STEVE:  Well, and it's got nasty goo in it.  You don't want to, like, have this goo...



LEO:  I know.  It's toxic.  No, I know.



STEVE:  You don't want that goo coming out.



LEO:  Yeah.



STEVE:  So I would just let it be a rocking horse for a while.



LEO:  Not try - yeah, exactly, not try to reattach the back, but just let it...



STEVE:  And if it's a good phone, for example, my iPhone X is going to a buddy of mine.  Actually it's the [crosstalk].



LEO:  And I'm sure Apple replaced it; right?  They replaced the battery.



STEVE:  Yeah.  Yes.  They replaced the battery.  Cost $69 to do an out-of-warranty replacement.



LEO:  It's well worth it.



STEVE:  And it's as good as new.  It's no scratches.  It's gorgeous.  And it still runs just fine.  But in the interim I did get a 12 Pro, and oh, it's so nice.  It just - and this was my point is it does run faster.  And so I would have no problem if you chose to get new hardware because Windows 10 was no longer fast enough on old hardware.  But it ought to agree to run if it really does run.



LEO:  You'd think.



STEVE:  I mean, if the technology hasn't been obsoleted.



LEO:  Yes, you'd think.  But we brought this up, we've talked about this before because Microsoft some years ago said we're not going to support these pre-Haswell chips, as you mentioned.  And that makes sense because they're doing, I think, a lot of coding and patching to the chip, and they don't want to support older chips; right?  I understand that.



STEVE:  Right.  And that absolutely makes sense.  It was, yes, and in fact installing Windows 7 on a Skylake does - because Skylake chipset doesn't support the same USB drivers.  And Skylake was only USB3.  If you had an older motherboard, you needed to, like, you needed to get the USB3 drivers for the motherboard and install them into the DISM image in order to get the thing to install because as soon as - it would boot up.  It would start the install.  And then it would die when it tried to switch to its own drivers, which didn't work on your hardware.  So you had to jump through some hoops.  But I'm running it.  It's like, it works just fine.  I've installed it on a number of machines like that.  But yes.  It certainly makes sense not to ask them to keep supporting older chipsets at some point.



LEO:  Yeah, at some point.  Two years later?



STEVE:  It's like, sorry, it's the same, yeah, it's the same as 10.  I mean, it's running on all...



LEO:  Yeah, it is 10.



STEVE:  It is 10.



LEO:  It is 10.  I think it's time to replace, by the way, this iPhone I got 14 years ago.



STEVE:  Happy Birthday to iPhone.



LEO:  Maybe it's time to replace this one.  This one, ironically, the battery has never swollen on.  So 14 years later, the original iPhone.  Steve Gibson, we're done.



STEVE:  We are.



LEO:  We're done.  Great show.



STEVE:  [Crosstalk] podcast.



LEO:  Everybody should run out and buy SpinRite quick so you get the free upgrade to 6.1.  He's working on it hard.  By getting 6.0 you'll also participate in the development of 6.1, so that's nice.  You'll find SpinRite at GRC.com, the world's best hard drive maintenance, mass storage maintenance and recovery utility.  We also invite you to go there for some unique versions of this show.  Steve maintains a 16Kb audio version, if you ever want it to sound like the original Thomas Edison gramophone.



STEVE:  Once upon a time Elaine had a very slow satellite connection.



LEO:  Right.



STEVE:  That's right.  And that's what started this was that it was burdensome.  Oh, and she had a tight bandwidth cap.  And so it was like...



LEO:  That's really who it's for.  Anybody who has a bandwidth cap doesn't want to spend extra bits and doesn't mind that it's a little scratchier.  But it's a lot smaller.



STEVE:  I don't know, Leo, [intentionally obscured audio].



LEO:  Now, the transcripts are even smaller, and those are great.  Elaine writes those, does a great job listening to our words and turning them into English prose.  You'll find that and the 16Kb version and the 64Kb audio version at Steve's site:  GRC.com.  While you're there, leave a question, a comment, a suggestion, just praise at GRC.com/feedback.  You can also tweet him.  He's @SGgrc on Twitter, and his DMs are open.



We live at TWiT.tv, and that's where you'll find this show and all the shows we do, both audio and video.  I think that's about it.  We'll see you next Tuesday about 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  You can watch the live stream as we do this show and all of our shows at TWiT.tv/live.  Thank you, Steve.  Have a great week.



STEVE:  As we begin the second half of 2021.



LEO:  Hard to believe.



STEVE:  Oh, I know.  I mean...



LEO:  I still feel like we're in 2020 in some ways.



STEVE:  Okay, buddy.  Bye.



LEO:  Take care.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






