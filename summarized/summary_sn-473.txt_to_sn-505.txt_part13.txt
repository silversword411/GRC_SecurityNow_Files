GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#473

DATE:		September 16, 2014

TITLE:		Google vs. SHA-1

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-473.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After we catch up with interesting security news of the past week, Steve and Leo examine Google's surprising, controversial, and unilateral decision to suddenly and significantly deprecate ALL web server certificates signed by SHA-1 that will be valid past 2016 - even though 92% of certificates (with lives of at least two years) signed in January 2014 were SHA-1.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and he's ready to rip Google a new one.  Seems like Google's policy on the expiration of SHA-1 generated certificates is premature folly.  We'll find out exactly what Steve's all het up about, next.  Stay tuned.



LEO LAPORTE:  This is Security Now! #473, recorded September 16th, 2014:  Google vs. SHA-1.



It's time for Security Now!, the show that protects you and your loved ones online, your privacy.  This is the guy in charge, our king of security, Mr. Steven "Tiberius" Gibson.  And he is at GRC.com, the Gibson Research Corporation, creator of SpinRite, but also a well-known security expert because, not only does he talk about it, he does it.  He lives it.  He breathes it.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again.  Speaking of which, I got a notice from my ISP, Cogent, who supplies the bandwidth for my T1s, saying that I have been participating in a UDP reflection attack against some poor victim.



LEO:  What?



STEVE:  And, yeah, it turns out that it was - it's my Cisco router at this end of my T1s.  It was responding to SNMP queries.  And someone found it and was bouncing packets off of it.  So of course that was a little minor annoyance.  It's like, oh, well, didn't know that was happening.  So I turned that off.



LEO:  But that's the right thing for Cogent to do, and any ISP.



STEVE:  Oh, absolutely.



LEO:  Because they'll [indiscernible] that traffic coming out of you.



STEVE:  Yup.  Yup.  Actually, what happened was the victim, who was being flooded with this, they were - I was receiving spoofed IPs and bouncing SNMP replies to, I mean, unwittingly, of course, to the target, along with lord knows how many other similar open SNMP servers.  And so the victim complained to Cogent that an IP within the Cogent block, they had no idea who...



LEO:  They don't know it's you, right.



STEVE:  They don't know it's me.  But they said this IP.  And then Cogent looked it up and said, oh, that's - oh, my god, he's got 64 IPs?  What's he doing with all those?



LEO:  So Cogent didn't observe the oddball traffic, I guess because it's not that oddball, it's just an SNMP...



STEVE:  Well, and remember, that's a T1.  I'm basically blowing through a straw and trying to create a whirlwind.  I mean, and so it's like [demonstrating].



LEO:  Well, that's what's interesting about amplification attacks because they do allow a single person with even dialup bandwidth capabilities to initiate an attack that's sufficient to DDoS even big servers.



STEVE:  Well, yes.  But my point was, I was only able possibly to contribute...



LEO:  Yeah, you were a small portion of it.



STEVE:  ...1.5Mb because they were - the router is here at this end of the T1s.  And so I'm sure they, well, lord knows how many other people they had...



LEO:  One of a small group.



STEVE:  One of a small group.  Or a small piece of a large group, I think is probably the case.



LEO:  Yeah, yeah, yeah.  Interesting.



STEVE:  So we have some interesting news.  And today's topic is Google vs. SHA-1.  And when I decided to defer discussing this and give it its own episode, I was not completely sure there was enough to talk about.  But I am now.  It's really interesting.  The industry has reacted very negatively and, I mean, with a lot of pushback against Google because, first of all, it was very short notice, and it's quite heavy-handed.  So that's the topic that we'll get to after we cover the news.



We're going to talk about Comcast vs. Tor.  There was a flurry of is Comcast disconnecting people using Tor?  I want to briefly talk - many people asked about Tim Cook's appearance on Charlie Rose and what I thought about what he had to say.  LinkedIn was discovered to have made a mistake.  There's a bad, just today, pre-KitKat problem with Android.  And LastPass has an iOS 8 announcement.  We've got a little bit of telephone, and we already talked about iPhone stuff, so, I mean, not telephone, television miscellany, and then a great topic.



LEO:  Awesome.  A busy day, as always, here at Security Now! Headquarters.  And onward we go.



STEVE:  Okay.  Now, first...



LEO:  Yes.



STEVE:  Yesterday's Triangulation.



LEO:  Oh, did you enjoy that?



STEVE:  Oh, my goodness, Leo.



LEO:  Isn't he great?  I love Lawrence Krauss.



STEVE:  I wanted to make sure all of our listeners knew of this fabulous Dr. Lawrence Krauss interview you did.  He was just delightful.



LEO:  Yeah, I agree.



STEVE:  I mean, a lot of energy.  Very literate.  He's a physicist and a cosmologist.  And, but, I mean, just compelling.



LEO:  He's, you know, it's funny, because he's one of the best science writers out there today.  He's written a number of great books.  And my son Henry is a huge fan of his.



STEVE:  No kidding.



LEO:  Yeah, because he got Henry into physics.  He read his books, and Eric Greene's books, and fell in love with physics.  And that's where Lawrence Krauss deserves a lot of credit.  Of course he's an advanced experimental physics theorist.  He works on dark energy.  But a great communicator, yeah.



STEVE:  Oh, I just, I mean, so I think I didn't say this well.  Everybody listening to this podcast has to watch yesterday's Triangulation.



LEO:  Well, I couldn't agree more.



STEVE:  It was fabulous.  I mean, it really was.  I love that he said, I mean, it was so pithy.  There were just so many things he had.  I was thinking, wow, you know, his students are lucky people.  He was talking about like how he's a physicist, and he deals with the excited states of matter.  And he said the two most exciting states to be in are "confused" and "wrong."  And he really understands the essence of the scientific method, that it's not about being proven right, but the only time you're learning is when you realize, oh, crap, what I thought is completely wrong.  And that's an exciting thing.  That's not to be ashamed of.



LEO:  Didn't you love that?  Yeah, yeah.



STEVE:  Yes, yeah.  Oh, it just, I mean, and in fact I was hoping that Audible was going to be a sponsor this week because I took the trouble to verify that his most recent book, titled "A Universe From Nothing:  Why There Is Something Rather Than Nothing," is on Audible.



LEO:  Yeah, yeah.



STEVE:  So I think Jenny's going to get it and listen to it and/or "read" it, as people say.  And it just sounds - oh, actually I think she downloaded it on her Kindle because she said she thought she would be better reading it than listening to it in order to not have it just go by, so that she can focus on it.  But, and I may do the same thing if I can find some time because I just loved yesterday's interview.  So I want to make sure that our Security Now! listeners who didn't know about it will take the time to go listen to it.  It's absolutely worthwhile.



LEO:  Episode 167 of Triangulation.  You can find it at TWiT.tv/tri167.  And of course it's on everywhere else, you know, iTunes and all of that stuff.  Yeah, he's great.  And I was actually quite pleased because at the end of it he said, "Hey, this wasn't bad at all."  I think he was expecting the worst.



STEVE:  Well, it was interesting, too.  I was watching him.  Whatever he was doing, he was studying something to get himself ready for it.



LEO:  Yeah.  He was reading the foreword - so the premise for getting him on was he'd written the foreword to a new science fiction short story collection, which he'd written more than a year ago, so he was rereading his foreword so he knew what he said.  Because he thought, and I think this was the problem, he thought this was going to be all about the book.  And it wasn't.  That was the excuse for getting Lawrence Krauss on the air.  I just, you know, because I love his stuff.  He was on a cruise that I was on, it was a Scientific American cruise for the Australian total eclipse a couple of years ago.



STEVE:  I remember, when it was overcast.



LEO:  Yeah, he was so peeved.



STEVE:  You came back talking about how, well, I'm sure there was an eclipse up there somewhere.



LEO:  Yeah.  He was mad because it felt like the captain just didn't want to get to the eclipse, he was going to stay in the clouds.  But I had seen him speak, and I was very, very impressed.  I knew of his books.  So we just - it was just an excuse to get him on.  And I think he was happy to talk about that.



STEVE:  Well, I want to make sure our listeners know.  I loved it.  And I can't imagine anyone who enjoys this podcast would not equally enjoy this guy because he was just - he was terrific.  I mean, it was just - it was as fast as you could go, he was coming out with really fun observations.



LEO:  That's the best part about the show, which you've been on twice.  Triangulation is an interview show, and it's fun to get smart people.  And to have an hour to talk to them is such a pleasure for me.  I just love the opportunity.  And we use it really as an excuse to get people I want to talk to on.



STEVE:  Yeah.  It was just great.



LEO:  Like you.



STEVE:  Well, thank you.  You get me every week, like it or not.  So Comcast vs. Tor.  What I think this was is another example of just sort of the lumbering size of Comcast.  And you can imagine a culture where the support people are not super technical.  Maybe there's a few geeks who sort of tend to run the herd and like to sound like know-it-alls.  Because it sounds like some of the customer support people were sort of, like, going complete off script, not really understanding what they're talking about.



But the reporting from DeepDotWeb was that - and this is just a couple days ago - that Comcast had been repeatedly asking, well, first of all, Comcast knew that their customers were using Tor and then were contacting them and repeatedly asking which sites they were visiting with Tor.  So DeepDotWeb wrote:  "Reports have surfaced that Comcast agents have contacted customers using Tor and instructed them to stop using the browser or risk termination of service.  A Comcast agent named Jeremy allegedly called Tor a, quote, 'illegal service,' unquote.  The Comcast agent told its customer that such activity is against usage policies.  The Comcast agent then repeatedly asked the customer to tell him what sites he was accessing through the Tor browser.  The customer [thankfully] refused to answer.



"The next day the customer called Comcast and spoke to a different agent named Kelly, who reiterated that Comcast does not want its customers using Tor.  The Comcast agent then allegedly told the customer" - and I had a quote here, and it looks like it didn't make it into my notes.  But it was essentially it's an illegal service, and it's against our policies, and people only who are only doing illegal things are using Tor, and therefore you should not be using it.



So after about a day went by, one of the VPs, Jason Livingood, posted an official Comcast response titled "Setting the Record Straight on Tor," flatly denying all of this, denying that these conversations occurred, citing them as being from a chatroom where apparently they weren't.  And again, I think it sounds to me like this group of Comcast support people just were sort of off script, that this - maybe somebody said it, and the legend grew.  Who knows.  But anyway, so for what it's worth...



LEO:  It wouldn't be the first time Comcast support people have gotten a little heat for their off scriptness.



STEVE:  Right.  And on one of your podcasts recently, one of your bright people said something like, "Never ascribe to malice what is probably explainable as a mistake," sort of thing.



LEO:  Yup, yup.



STEVE:  It's like, I don't really - this just didn't feel like they were perpetrating a policy.  It's just the simpler answer is normally the right one, and it's just the Comcast support people are absolutely clueless.



LEO:  I can't think of any reason Comcast wouldn't want you to use Tor unless they were afraid there was illegal activity going on in their network, and you're using Tor to hide that.  But that's the same thing with BitTorrent.  You can't assume that because somebody's using a legitimate protocol that they're doing it illegitimately.



STEVE:  Right.  And ask the EFF how they feel about any of these things.



LEO:  Right.



STEVE:  I mean, they've been sponsors of that, and for a while stopped taking bitcoin, then decided, oh, we were wrong, we're going to take it again.  So, okay.  So Tim Cook was on Charlie Rose.  And because of the deep dive we did into Apple iOS 7 security, we've absolutely verified that, while Apple may not have the keys for decrypting iMessages, because they are managing the keys in a way that is completely transparent to their users, they have the absolute capability of reading iMessages, if they want to.



And so what Tim Cook was quoted as - what Tim Cook said, and I watched the interview, was "We are not reading your email.  We are not reading your iMessages.  If the government laid a subpoena on us to get your iMessages, we can't provide it.  It's encrypted, and we don't have the key."  Okay.  So I think that is factually accurate, but it's not effectively accurate.  It's not operationally accurate.  They have the ability, we know they have the ability to have the keys.  I mean, they actually have the keys.  They may not be using them, but he says "We don't have the key."



Well, yes, you do have the key.  You're providing them to each of us so that we can cross-encrypt our iMessages to each other.  So by definition you have to have the key.  Still, he's in the top floor of the building, and you've got to go about halfway down probably until you actually get to people who understand the technology of this.  And so I...



LEO:  That's probably the case, yeah.



STEVE:  Yeah, I'm sure it's not deliberate.  I'm sure this is what he's been told.  And the reason I got all this feedback from our listeners is, wait a minute, who's right here?  And it's like, well, I'm sure he believes he's right.  And you can see it as a way of being right.  But I think technically he's not.  He also did say, "Our customers are not our product."  He carried on about that for a while.  He says, "These gadgets here" - and he had laid them out on the table in front of Charlie.  He says, you know, "These gadgets are what we're selling."  We're not selling our customers' data, our customers' lives, our customers' experiences.  And, I mean, he went to some effort to sort of demonstrate, I think, or differentiate himself from - clearly the elephant in the room there was Google that he was referring to.



LEO:  And the NSA, and Facebook, and...



STEVE:  Yeah.  And he said, "We go out of our way not to have our customers' data.  We don't want it."  And the fact is, our own analysis of the design of their system, one of the conclusions I came to after the three episodes we did on iOS 7 was exactly that.  It was evident to me from a technology standpoint they were working to have as little responsibility as they could while still delivering the experience, the "it just works" experience, which we know is difficult to offer for security because that is oftentimes at odds with convenience.



LEO:  I would love it if, I mean, I understand why you give Charlie Rose an interview, because it's very prestigious, he's on Bloomberg, he's on PBS.  But Charlie is not known for his technical acumen, nor is he known for his hard-hitting questions.  And that's another reason perhaps that they chose him for that interview.  But I would love, I mean, I would love Tim Cook, maybe if he wants to bring along some expert technical people with him, to come on our network or some similar network where you'd have actual expertise, so that we can ask him some a little bit more challenging questions about this stuff.



STEVE:  Yeah.  And I wonder if he can answer those, Leo.



LEO:  No, well, that's why I said maybe he'll bring in somebody who does.  Of course he can't.  He's the CEO.  I don't interview CEOs.  You notice I very rarely do CEO interviews.  They don't know nothin'.  And they're not going to say that they do.



STEVE:  It's like the U.S. cyber czar guy, where he boasts that he doesn't know what end to plug in.  And it's like, oh.



LEO:  And I don't need to.



STEVE:  Okay, yeah.



LEO:  I just sign the checks.



STEVE:  Yeah.  And if I had that job, just shoot me right now.  I'm sure I'd be screaming and then tied up in a straightjacket in about a week because of just - it's all about politics and bureaucracy.  It's not about technology.



LEO:  Right, right.  And he's never going to come on a challenging venue and try to answer these questions.



STEVE:  No.  Why?



LEO:  He should, but he doesn't need to.



STEVE:  How does that benefit Apple?



LEO:  Yeah.  Well, that's the exact right question.  How does that benefit Apple?



STEVE:  So LinkedIn made a mistake.  And this is not a big breach.  It's gotten some bad press, I think.  I mean, it's not - it's a goof.  Some clever security guys, the two founders of Rhino Security Labs in Seattle, Benjamin Caudill and Brian Seely, they leveraged an unintended side effect of a LinkedIn feature.  LinkedIn has a feature - because it's all about getting you linked in.  When you are setting up an account, LinkedIn says, hey, we'd like to help you connect to other people on LinkedIn who you know in your other social networking environments, like your Gmail address book or your Yahoo! contact list.  So can we have access to that?  And you say, oh, that sounds handy, so, yeah.  And so LinkedIn goes and sucks out all of your contacts in this other facility and then does a cross-reference of the email addresses of the people you claim to know - thus the problem - against LinkedIn, the addresses LinkedIn knows everybody in LinkedIn has, and then populates your connections list in LinkedIn.



LEO:  That's not a bug.  That's a feature.



STEVE:  Yeah.  Except that it makes it rather automatable.  And that's what these guys did.  I'm trying to remember the guy, I'm not remembering his name, someone famous who's gotten into technology...



LEO:  Ashton Kutcher?



STEVE:  No.  Shoot.



LEO:  Charlie Rose?



STEVE:  Anyway, it doesn't matter.



LEO:  All right.



STEVE:  It'll probably come.  So what they did was they just put into their address book a ton of email guesses, just guessing famous people's email addresses, all kinds of permutations, their names and various ways and so forth.  Oh, Cuban, Marc Cuban.



LEO:  Yeah.



STEVE:  I knew it would come.  So, and it turns out LinkedIn filtered through all of those on their behalf and said, oh, yeah, here's Cuban's email address.  And they didn't...



LEO:  But didn't they have to have his address to begin with?  I don't understand.



STEVE:  No, no.



LEO:  Just his name.  You just put Marc Cuban in there.



STEVE:  No.  What they did was they created fake address book entries in Gmail or Yahoo!.



LEO:  So how much information had to be in that entry for LinkedIn to give them the email address?



STEVE:  I think they had to have the email address correct.  But the point was they were able to build a huge fake contact list that was all of these guesses, and LinkedIn did the cross-referencing.



LEO:  Oh, it confirmed one.



STEVE:  Yes.



LEO:  Got it.



STEVE:  Precisely.  And then they actually leveraged this into an interesting social engineering deal.  Cuban has got some new social networking app...



LEO:  Yeah, Cyber Dust, yeah.



STEVE:  That's it.  And so they waited for a tweet to appear, they made a comment of that, then they used the fact that they had his email address in order to get - basically in order to get some work from Marc, saying, hey, would you like us to check your system?



LEO:  You've got a little problem, Marc.



STEVE:  Yeah, because we just hacked LinkedIn.  So anyway, that's what that's about.  It's not - it was being billed as like a major flaw in LinkedIn.  It's like, well, okay.  I'm not sure how you offer this facility without opening it to abuse except, well, I just don't know because you could certainly have valid email addresses which LinkedIn doesn't know.  So a bunch of non-collisions are not going to disqualify you or demonstrate that you're trying to hack that facility.  And one of them is going to match if you guess a lot.



LEO:  And apparently having that email address is the first step towards a larger social engineering hack, getting more information.  The Apple example, the iCloud hack, they had to have a correct email address to begin.



STEVE:  Right, right. They had to have some foothold to get into the system.



LEO:  Right, yeah.



STEVE:  Well, there is, however, a bad problem that was just recently discovered.  And this affects all pre-KitKat versions of Android, KitKat 4.4, which is just now, as of like a couple days ago, at 24.5% share.  So three quarters of Android devices are still pre-KitKat, that is, this affects them.  What was found was an incredibly easy-to-exploit bypass of the same-origin policy that protects browsers.



So to remind everybody, same-origin policy is a crucial, essentially firewall feature of browsers which restrains what code received from a website can do based on the domain name, the idea being that it is free to, like, ask for other assets and do other things, as long as they are within the same origin.  That is, if you receive code from GRC.com, that code can interact further with GRC.com.  But it can't on your behalf go do something with Amazon because that would be bad.  I mean, it could on your behalf make a query to Amazon.  Your browser would give Amazon your Amazon cookie, your session cookie, because that's what browsers do, and the JavaScript could capture that, and you'd have a serious problem.



Well, that's what exists on the default Android browser, the so-called AOSP platform browser.  AOSP stands for the Android Open Source Platform browser, which is installed by default on all of these many phones where the user hasn't switched to any of the alternative browsers.  And it is as simple as prepending a unicode null in front of the URL of the JavaScript.



And so what this means, for example, is that, if a user using that browser on a pre-4.4 - it was fixed in KitKat quietly.  But a user using one of those vulnerable browsers visits a website which doesn't have their best interests at heart.  It's able to present them with a page containing JavaScript that gains access to all the pages they have open in the browser.  It's able essentially to crawl the so-called DOM, the Document Object Model hierarchy of all of the pages and, for example, collect the session cookies which they may have current, and even issue requests on behalf of them to other sites that are popular to which they may be logged in and acquire their session cookies and thus hijack their current session and current credentials.



So I've got a link here in the show notes to - Rafay Baloch is the researcher who found this.  And the proof of concept is as simple as a couple lines of HTML.  I mean, it's just trivial.  You do a /u0000, which is a unicode zero, and then the URL you want.  And you're able to demonstrate that this is happening.  So the takeaway is for our listeners to, if you are on a pre-4.4 Android, stay away from the default Android browser.  Chrome and Firefox and others should be fine.  And you can use this URL to verify that you either are or are not vulnerable.  He discovered it on what is apparently his own phone, which was - I had it in the notes here, and I'm not seeing it in front of me.  Oh, a Qmobile...



LEO:  A weird one, a Qmobile Noir A20, which I've never even heard of.



STEVE:  Yes.  But he also verified it on the Galaxy S3, the HTC Wildfire, Sony Xperia, Motorola, and others.  A very simple proof of concept, it is now - it's already made it into all versions of Metasploit.  So the bad guys have it and may be getting up to some mischief with it.  So again, if this affects you, be advised that you want to stay away from that browser on the pre-KitKat versions of Android.



And some good news, anticipated.  You were already anticipating it on MacBreak Weekly, the podcast before this, and that is that LastPass just announced that they will be shortly, but apparently not at launch, but soon after, adding support for iOS 8 and doing everything we want.  They said in their posting:  "Following Apple's announcement of iOS 8 in June" - oh, right, the announcement in June - "we've been hard at work to bring the platform's new security and authentication features to the LastPass mobile experience.  Now, with the impending release of the platform, we're thrilled to announce the LastPass app will be available for iOS 8 with Touch ID integration and a Safari extension for automated web logins.  This marks a tremendous shift," they wrote, "in our ability to bring a seamless login experience to LastPass users on iOS."



And all of us who are LastPass users on iOS are saying, yay.  No more need - I was talking about it a couple weeks ago, about having to switch over to the LastPass tab or the LastPass app, get the password, copy it, then, you know, and I mentioned how I copy the password first, then my username second, so that it overwrites the password in the clipboard and so forth.  I mean, things like that, that all goes away.



So the third-party app extension for Safari allows them to integrate into Safari so it'll just be able to populate the fields the way it does on desktop browsers.  And then with Touch ID integration, they'll be able to ask for a fresh thumbprint, essentially, or fingerprint from iOS.  iOS will then prompt the user to, on the fly in real-time, provide an authentication thumbprint for that instance of login.  And then the return comes back to LastPass.  Applications get nothing but a yay or nay.  Like, yes, the person successfully authenticated just now.  And then LastPass will proceed to do its work for us.  So, and they said available soon, no specific date.  But that's super good news.



Miscellaneousness:  We already talked about iPhone stuff that I had in my notes because I wanted to briefly talk with you about that.  I saw last night at Mark Thompson's recommendation - Mark Thompson, a buddy of mine at AnalogX.com and friend of ours.  He said, "Steve, you've got to go look at the special about Fox's forthcoming series 'Gotham.'"  And so I made some time last night.  It's 22 minutes long and is available now on the Fox site.  And my Fox affiliate, I guess, is airing it on Saturday, so it may also - you may be able to get it on regular Fox TV.



I wanted to just give a heads-up to our listeners, it looks really good.  I was initially not that excited about it.  It's like, oh, okay, maybe.  But wow.  It's a fabulous-looking cast.  It tells the story of the evolution of the DC Comics bad guys from early - yeah.  "The Legend Reborn" it's called.  And it just really looks great.  So I just wanted to give our listeners a quick heads-up.  Go check it out if it sounds like you might be interested.  Twenty-two minutes, and if you're not hooked or convinced by then, then it's probably not for you.  But it just - it really looks good.



And of course many people, I tweeted my excitement about this last night, and I got a bunch of people saying, yeah, Steve, now that Fox knows you love it, they'll cancel it, like they did "Firefly" and "Almost Human."



LEO:  Or even better, run it out of order.



STEVE:  Exactly.



LEO:  The mayor vows to find the Wayne murderer, and then the murder is the next episode.  That'd make a lot of sense.



STEVE:  That's right.



LEO:  You know, this is an endless, really, isn't it, an endless well of inspiration is this DC Comic stuff.



STEVE:  Boy, yeah, it sure is.



LEO:  How many times have Batman's parents been killed?  Many, many, many times.



STEVE:  Yeah, you can keep turning the clock back and reinterpret.



LEO:  Yeah, yeah.



STEVE:  We're going to reinterpret.  "Batman Returns."  "Batman Begins."  "Batman Tries It Again."



LEO:  You know what's fun, there's a - of course they were seeing a play, or an event.  They were going to something downtown in Gotham, and then the young Batman with his mom and his dad walk out of the theater and get robbed at gunpoint, and the parents get shot.  And what's changed is what they were going to see.



STEVE:  Oh.



LEO:  And, yeah, there's a history.  Let me see if I can find Bruce Wayne's parents.  Because in the original DC Comic, Batman No. 1, it was something really ancient.



STEVE:  Right.



LEO:  So I'll find it, and you can keep on, and I don't want to slow you down.



STEVE:  Yeah, so it was interesting, I was just going to say while you were looking that, in this special, we're seeing it's all, like, shot behind the scenes.  So they show how this is all being shot in New York because they want that gritty real city feel.  And they have some wipes where they show what the cameras actually see and then how they've been reimagined.  And I don't know how they do any of this.  But this wipe goes across, and you see, like, some gargoyles appear.  But mostly the buildings are still kind of the same, but the facades have changed.



LEO:  Yeah.



STEVE:  It's just cool technology.  It's like, wow.  Yeah, so, really neat.



LEO:  So in "Batman Begins" they were seeing "Mefistofele," an opera.



STEVE:  Okay, yup.



LEO:  In the original Batman I think it's the...



STEVE:  No wonder the young Bruce - or actually you like opera.



LEO:  I do.



STEVE:  But I was going to say no wonder the young Bruce Wayne wanted to leave.



LEO:  Mom and Dad, let's get out of here.  Well, in the original DC Comic they were seeing "The Mark of Zorro" starring Douglas Fairbanks, the 1920 version.



STEVE:  I love the Internet.



LEO:  Yeah, I mean, it's fascinating.  Somewhere somebody has probably published a list of all of the different shows that they were at.



STEVE:  No doubt.  No doubt.  So speaking of cool technology, last Thursday I turned over the UI complete functioning client of SQRL to the guys who have been - I don't think there are any gals, so I'll say "guys" - over in the newsgroup who've been pounding on it.  And it's holding up very well.  I've now been pounding on Wine because there's some weird display anomalies that I've been chasing down because I would like to be able to have it run under Linux and on the Mac, also, using Wine as the interface.  So there's some display and some printing problems which I've been working on.  But so another step forward.  Once that gets nailed down, and then I think there are a couple UI things people found, then I implement the online protocol, and we will have an easy-to-use, free, robust, secure, and anonymous identity system for the web.  So getting, each week, getting another step closer.



And since I've been talking about SpinRite and RAID recently, I got a nice piece of email that I ran across last week for the Q&A when I was going through the email, that I saved to this week, from a Patrick in Pittsburgh, Pennsylvania who wanted to share his experience of SpinRite saving his RAID array.  So even, yes, having a RAID means that a drive can die, and you have redundancy problems, it's not complete protection, as we will see.



He wrote:  "Steve, I heard you discussing SpinRite and RAID arrays a few episodes back and thought I'd share a success story.  I moved across the country" - okay, so he's in Pittsburgh now.  Maybe he was out here before.  "I moved across the country about a year ago; and, during the move, a Synology disk array fell out of the back of the moving truck."  And then he says, parens...



LEO:  Literally fell off a truck.



STEVE:  Literally.  He says, "fell off while it was parked," he said, "but it was still bad.  When I plugged it back in, all sorts of audible beeps, amber lights, and console messages indicated that one of the disks was past the point of repair and needed to be replaced."  So here was a situation where he was in trouble.  He said, "I took the damaged disk out of the array and put it into an old desktop, then let SpinRite do its thing.  When SpinRite was finished, I slipped the disk back into the array, and it's been humming along for over a year now without any trouble.  That's the second time SpinRite has saved me.  Thank you for an amazing product and an amazing podcast."



LEO:  Yay.



STEVE:  And Patrick, than you for an amazing success story.  I appreciate it.



LEO:  SpinRite saves the day.  All right, Steve.  First of all, what is SHA-1?



STEVE:  So we've talked about certificates a lot on the show because they are the meat and potatoes of Internet security.  The way, just a quick refresher, the way the system works is that somebody running a server wants to be able to assert their own identity to someone connecting to the server.  So they generate a certificate that has their information, their domain name and other information, the name of their company and where they're located and so forth.  They generate the certificate.  They create a hash of the certificate.  And they get the hash signed by the certificate authority that essentially is saying, okay, all of the information that is in the certificate is valid.  So the user connecting to the server receives the certificate and verifies that the hash is correct, and that the signing of the hash is correct.  So both of those things have to be true.  The hash needs to match the contents of the certificate and be validly signed.



Through history, as our understanding of cryptography has gotten stronger and evolved and, significantly, as the power of our computers has just been exponential with no apparent end, we've moved through different technologies of hashing.  And we discussed on this podcast essentially the death of MD5.  MD5, Message Digest 5, was the previously very popular hash which all of the Internet was using a decade ago.



And you'll remember, Leo, when we talked about this because the academic guys who did this, they used a wall of PlayStation 3's in order to create a fraudulent certificate that had the company name MD5 Collisions, Inc.  And what they did was they watched the rate at which, I think it was RapidSSL was the certificate authority.  And it turns out that RapidSSL was, like, almost all the certificates that RapidSSL was issuing were MD5s then.  And this was in a period where the first chinks were discovered in the armor of MD5, back in '95.  And it took 13 years to go from "we see some problems" to a successful attack.



So it's one thing to find some problems, and an entirely 'nother scale to turn those into an effective attack.  And even so, they needed to anticipate the details of the certificate that would be issued by RapidSSL in the future because it took so long for them to crunch, to essentially crack the hash, to create, to solve the problem of creating a second hash, or a second certificate that hashed to the same value as the first certificate.  They managed to do it.  There was a tiny window of opportunity, and they then pounded RapidSSL with a bunch of certificate requests when they thought that the one that they were anticipating coming along would, and they had the correct solution.  They got the certificate issued.  And as I remember it was an intermediate.



So they had - they'd created their own certificate authority, an intermediate certificate, which could be used to then sign any other certificates they wanted.  So this was a horrifying failure of the crypto system.  But they weren't bad guys.  They told everybody.  And the industry collectively shrieked.  All the browsers immediately blocked that fraudulent certificate, which they freely confessed to having created and never used it to do anything else bad, and the browsers all blocked it so they never could.  And everyone quickly stopped using MD5.  Which was fine because SHA-1 was the successor to that.  And SHA-1 seemed strong and was already well supported.



So it was just - and this is one of the issues which Google has used to motivate them for what they decided to do a few weeks ago, or decided to announce a few weeks ago and will be doing in November.  And that is that, because everyone was using MD5, and MD5 seemed fine, everyone kept using it.  There was no big hurry, no emergency to move off of MD5.  And Google's position is that we're in the same place now with SHA-1, the successor to MD5; that, in the future, computing power is going to continue to get stronger.



And what that means in the real world is the practical cost of cracking the hash to create a fraudulent certificate, which is the single thing we're worried about - we're worried that some actor could create a fraudulent certificate that would be accepted by all the web browsers, and they would be able to impersonate websites as a consequence.  To do that, they have to solve the SHA-1 hash challenge, essentially.  They need to modify a certificate without modifying its signature.  And that's the key.  That way the signature stays valid and trusted by an existing certificate authority, yet they've changed the contents.



And that is specifically what hashing is designed to prevent.  The idea is it is supposed to be computationally infeasible to create a given hash signature from content that you want to hash.  And it's the computational infeasibility which no one is arguing over time is incrementally becoming less infeasible, which is to say more feasible.  The question is, when?



And some of the dialogue I've seen on the 'Net I had to sort of chuckle at because people have said, oh, in this post-Odin - post-Odin - post-Snowden era, no one any longer doubts the interest of governments in cracking crypto, which is completely ridiculous because in the post-Snowden era does anyone imagine that the NSA can't just simply create any certificate they want?  Of course they can.  One of these certificate authorities that we all trust is a front, or they have employees deeply planted in a certificate authority, or who imagines that the Hong Kong Post Office that our browsers trust won't do whatever the Chinese government wants them to?  Of course they will.



So, again, remember that you always attack the weakest link in the chain of links which is security.  And the weakest link is not the crypto.  The weakest link is almost never the crypto.  It's something else.  And so people don't really bother attacking the crypto because that's hard.  Hitting somebody over the head, that's easy, and getting them to tell you your password, or having NSA-sympathetic employees in a company, or just there's no way, I mean, the Department of Defense is a certificate authority.  So I imagine they can pretty much make whatever certs they want to.  So I would argue that's worrying about the wrong thing.



So what happened is on August 19th, less than a month ago, out of the blue - oh, first I should say back last November, so nearly a year ago, November of 2013, Microsoft - and we talked about it on the podcast - Microsoft announced the formal sunsetting of SHA-1 in 2017.  So four years in advance, Microsoft said, you know, it's time.  We're going to, in 2017, we're going to stop Windows, Windows servers, Windows clients, browsers, anything from us, we're saying night-night, sunsetting SHA-1.  Nobody had a problem with that.  I mean, it just was sort of a blip.  It was like, oh, okay.  2017, not a problem.  Four years, plenty of time.



And remember that non-EV certs are issued for either two or three years, EV certs only for two years.  So setting that deadline out four years in the future didn't upset anybody because that told everybody well in advance to plan not to try to be using SHA-1, if you care about Microsoft at all, and it's not possible not to care about Microsoft, in 2017.  Just, you know, in 2015, when you make your two-year cert, or in 2014 this year if you make a three-year cert, any cert that would cross into '17, you're now responsible for choosing the next generation in the secure hash algorithm, which is what SHA stands for, which is it's technically SHA-2, except that SHA-2, unlike SHA-1, is a family of hashes with different length outputs.  SHA-256, 220 - is it 226?  Yeah, I think there's a 226, 256, I think 384, and 512.



And, for example, SQRL uses both SHA-256 and SHA-512 for different things.  I use SHA-512 as part of SQRL's entropy generation system, where I'm just hashing all this noise coming in from all these different chaotic sources and state of the processor and things that are unknowable to attackers, and that all gets poured into a big SHA-512 to generate enough entropy to create identities and for SQRL's various rather modest needs for entropy.  So it's SHA-256 is where we're going next from SHA-1.  So it was fine that Microsoft said this.  And I think everyone's like, okay, yeah, you're right, by then it'll be time.  Plenty of notice.



Out of the blue, three weeks ago, Ryan Sleevi, who's one of the security guys at Google, on August 19, makes a blog entry:  "Intent to Deprecate:  SHA-1 Certificates."  And what was the source of concern, the reason the industry reacted very differently to this announcement from Google was this was not in 2017.  This was in November that this would happen.  That is, three months, 90 days later, Google was saying, "We've decided we're going to create," and this is their words, "a slow-motion emergency.  We've been unimpressed with the way the industry has reacted in the past."  They looked at MD5, and they use MD5 as an example.  They think that was, you know - nobody, they're saying, will move until they have to.  So we're going to make them.



Now, the problem is, as far as I could see looking at everything, the only problem is notice.  The reason Microsoft's decision didn't upset anybody is that was plenty of notice, I mean, for people to plan.  Big organizations need to plan.  For example, Nick Sullivan, who we talked about back in the - I want to say Backblaze.  Was it Backblaze?  He's at CloudFlare.  And he was really upset.  He wrote in response to Ryan's posting:  "This timeline for deprecating SHA-1 is very aggressive and puts us (CloudFlare) in a bind.  Currently we provide certificates to our customers signed by GlobalSign's SHA-1 intermediate, with a three-year expiration.  All customer certificates from this year are valid for part of 2017.  We still use these SHA-1 certificates because a large percentage of the web visitors of our customers are using Windows XP SP2, which does not support SHA-256.  It's therefore not realistic to expect everyone to be able to upgrade to SP3.



"This change" - and he wrote this three weeks ago, so this is current.  "This change will force our customers to have to choose between having a mixed content warning" - and I'll talk about what Chrome is going to do in a second - "on Chrome or cutting off a large portion of their visitor base.  Can we please delay this move until at least next year?"



So he's writing this in 2014.  So here's what Chrome does.  Chrome is - and this is starting in November.  I think it's Chrome 39, I didn't write it down, but that's the number that sticks in my head.  Chrome 39, which is expected to come out in November, its behavior changes if it sees that the certificate it is receiving from web servers was signed by SHA-1.  And it's worth noting that today, today, at the day that this is looming over us, 92% of the web is signed by SHA-1.  That is, there's been...



LEO:  Wow.



STEVE:  Yes.



LEO:  Including some of Google's servers.



STEVE:  Look at that chart, Leo, on the first page of the show notes.  I put that there so you could display it.  That shows SHA-1 and SHA-256.  SHA-1 has just started to come down off of 100%.  SHA-256 just started to come up from 0%.  So, I mean, this is, there's no question, this is a premature move on Google's part.  And as I said at the beginning of this, and this is a bit of a double standard, yes, there it is on the screen, that's the current relationship that you're showing now between SHA-1, just peeling off from 100% off the top at the beginning of this year, versus SHA-256 just beginning to come up from the bottom.  So 92% today is SHA-1 certs, all of which Google isn't - it announced three weeks ago they're going to start flagging as insecure in November on Chrome.  And so...



LEO:  So it's in Canary now, which is in a very, very early pre, it's almost pre-beta because there's a Chrome Beta and then Chrome Canary.



STEVE:  Right.



LEO:  But you're saying they're going to move this into the full Chrome by the end of the year.



STEVE:  November, yes.



LEO:  Wow.



STEVE:  I know.  It is extremely aggressive.



LEO:  So that means that 92% of the web will - what will happen when we go there?  We'll get a warning?



STEVE:  Exactly.  So here's the way it works.  They've designed this to penalize certificates that will be living - certificates seen today which will be living at two different points in the future.  The first point is in 2016.  So at and after January 1st of 2016.  If a certificate today has an expiration in 2016, their user interface declares it insecure today, although it isn't.  And that's what's wrong with this is they're saying this certificate is insecure today.  What they're trying to do is they're trying to put artificial pressure on the industry to move today in order to prevent Chrome from complaining about certificates which, if you don't move, will eventually be insecure.



I mean, and again, this is arbitrary.  There's no problem with SHA-1.  It's like, from what I saw, it was 2021 where, if things continued to go exponential, and people got crazy hashing chips, and if we continued on this exponential rise, 2021 was where the cost to crack made it begin to be feasible for nongovernmental agencies.  Because, again, governments, I'm sure, don't have to bother cracking anything.  They just get certificates if they want them.



Okay.  So if the certificate would expire during 2016, then you get a yellow warning symbol over the "http" in the URL, or maybe it's over the lock.  So Chrome is saying there's a problem with this site's certificate, even though that's not true.  It's absolutely not true.  If you're unlucky enough to have more recently purchased your certificate - and in January of this year 92% of the certificates purchased in January were SHA-1, and certificates are either two or three years long.  But certificates purchased in January would be valid for two years.  January 2014 would be valid in 2016.  And most people purchased three-year certificates because you get a discount.  You get a better price per year if you do that.  And so they're valid in 2017.



So, and of course certificates have continued to be purchased all through 2014 with SHA-1 predominantly because that's the standard currently.  If the certificate has its expiration in 2017, then not only do you get a stronger warning in the URL, it's like red with crosshatches, but you get an additional "mixed content" pop-up.



LEO:  Hate that.



STEVE:  Yes, that requires you to click through.  And this happens in two months.  This happens in November.  So, and again, not because there's any problem, but because Google decided we want to create what they're calling a slow-motion emergency.  And here's the double standard.  Google is using SHA-1.  They have their own intermediate certificate which allows them to mint certificates on the fly.  They create three-month-long certificates, and they're issuing them all the time, moving them forward three months at a time.



So notice that they're forcing all of the rest of the industry, I mean, 92% of the industry has to remake their certificates or have Chrome, which is now the dominant browser, complaining about their website security when they're nothing wrong with their website security, while Google continues using short-term SHA-1 certificates that won't be expiring in 2016 and 2017 because they only mint them for three months because they've got that all automated, and they're continually churning them out.  It's why I had to stop using one of those neat Firefox plugins, because it kept seeing new Google certificates all the time and was warning me that Google certificates were changing.  I had to stop using it because it was creating so much noise.  So this is really a double standard.  And again, Google is using SHA-1 because there's nothing wrong with it.  But they just decided we're going to force everyone to reissue certificates.



Jeremy Rowley, who is an executive at DigiCert, of course my certificate company of choice, he also responded many times in this thread to Ryan.  His first response was - and later ones were much longer and full of bullet points and raising all kinds of good points because, again, this is unilateral, you could argue, abuse of power.  Google has earned the position they have with Chrome, and now they've just decided, okay, we're going to wield it as we choose to.  And it's not a problem for us, even though we're using SHA-1 certs, too, because we can mint them on the fly.  So we won't be tripping our advance warning systems.



Jeremy wrote:  "With rekeys, duplicates, early renewal programs and so forth, I think most of the certificates valid in 2016 will be replaced well before then."  So he's saying there is already natural churn and a movement in this direction.  He said:  "Considering many CAs are working to move existing SHA-1 customers to SHA-2 before 2016, showing a UI degradation now will probably only serve to upset website owners rather than spur faster adoption.  Most of these customers are on a set transition plan that will move them to SHA-2 well before the deadline, despite having a certificate currently that extends past the end of 2015.  At least consider a window in the validity period range where the transition will likely happen before 2016, despite a post-2016 validity period, such as March 2016," he just suggests.



"Putting the degradation on certs with a validity period past March 2016 will likely have the same effect in spurring a transition to SHA-2, but let people keep their current transition plan intact."  So essentially Jeremy is saying, is wording differently what the CloudFlare guy said, which was, wait a minute, you know, this is just too soon.  Microsoft said 2017.  Google, if you want to say sometime in 2016, if you want to push it forward, okay.  But don't push it to 60 days from now.  That's wrong.  I mean, it's really a problem.  So that's the story.  It's I think telling that Google is - the first line of Ryan Sleevi's post is "The use of SHA-1 within TLS certificates is no longer sufficiently secure."  That's how he starts this.  Yet that's all that Google uses.



LEO:  So if there were - somebody in the chatroom said, hey, if it were Heartbleed, you would update, even though you had just bought a certificate, you would update it.  Isn't there a security issue with SHA-1?  Or no?  You're saying there is no issue.



STEVE:  No, there is no known problem, or we wouldn't all be using it.  Google wouldn't be using it.  There's no known problem.  What they're trying to do, they're looking at the past.  And, I mean, they're not wrong about...



LEO:  Because of improvements of computational ability.



STEVE:  Yes, exactly.



LEO:  But we aren't there yet.



STEVE:  Correct.  And we're not going to actually be feasibly there until 2020 something, like 2021.



LEO:  This does seem like a kind of premature rush to fix this problem.



STEVE:  Yeah, I mean, to me it almost feels like they just want to be first.  They want to be the ones to yell "Fire" in the theater, just so that they can.  And they want to do that.



LEO:  That's kind of a shame.



STEVE:  It is.  I mean, and so what is going to happen is there are a lot of us who - oh, and I should say, Leo, when I minted my first - when I went to DigiCert, the default is SHA-256, and I had compatibility problems.  That is to say...



LEO:  Oh, that's interesting.



STEVE:  Yes.  GRC is using an SHA-1 cert right now today.  And in fact I want to see whether I can reissue an SHA-1 cert that expires on midnight of New Year's 2015 to thumb my nose at Google, essentially continuing to use SHA-1 while not triggering this ridiculous notification, this bogus "Your site is insecure; you're not protected; there's a security problem."  I mean, that's what users are going to believe.



This is going to be - watch what happens in November.  This is going to be a disaster because a lot of us are on the inside.  We're following this.  The CA industry is - they're taking steps.  But there are an awful lot of sites now that are going to have users saying, hey, what's wrong with your server?  It's not secure anymore.  Then it's like, okay, yes, it is.  I mean, ignore that.  So that's bad.  We don't want people being told and taught to ignore the security, the lack of security notification.  It's taken us until now to get people to start paying attention to that and notice if the thing is green or if the padlock is closed and so forth.  Now we're going to be saying, oh...



LEO:  Ignore that.



STEVE:  Oh, that's just Google.  That's just them being picky, and everything is really fine.  So you can ignore what that says.  But that's not the message we want to start teaching.  But it's going to start happening in November.  Yeah, now, so what this means is it means that all servers, 92% of the certificates need to be either reissued under SHA-1 so that they're not - so that Chrome will see, oh, my god, that they're not valid in 2016, that they expire on New Year's Eve of 2015, at the end of 2015, or go to SHA-256 certs.



And so certificate authorities will need to create a system that makes this easier.  And, I mean, there were some good - I'm not arguing with many of the points that Google made, that Ryan made in his posting.  There was a lot that was valid.  He raised the point that, as an industry, we're too rigid.  The MD5 catastrophe, where no one should have still been using MD5, but we all still were, and suddenly there was a great panic to get away from MD5.  That's, I mean, he's not wrong about that.  And he's not wrong that just dealing with certificates is not really frightening, but it's something you only do every three years typically.  And then it's like, oh, you've got to, you know, and we see them, like people being caught off guard.  They expire.  And then suddenly, oh, my god, our certificate's expired.  You run around trying to get them updated.



I mean, it's just - they're arguing that, in general, this shouldn't be a problem.  It should not be a problem for us to do this.  It should not be a problem for the entire Internet to leave SHA-1 in 90 days.  I don't know what they're smoking up there, but this is going to be interesting in November because the entire Internet will not be off of SHA-1 in November.  There's just - there's no chance.  And people are going to get yellow triangles and say, "Okay, what does that mean?"  "Oh, ignore that."  Oh, geez, okay.



LEO:  We should point out that Google Chrome Canary is - just because something's in Canary, it's for testing purposes, doesn't mean it's going to migrate to the Chrome that everybody uses.  Not even to Beta.



STEVE:  Oh, no, it's...



LEO:  I know it's their intent.



STEVE:  Okay, yes, that's absolutely right.  I've got people complaining about mixed content warnings on my site now.



LEO:  But you shouldn't, because anybody who's using Canary is a very advanced user.  And I don't even use Canary.  I mean, I do occasionally, but it's not really recommended.  And they could very easily at this point back down.



STEVE:  Yes.



LEO:  It's not in the - so I bet they will.  I mean, it seems like they have to.  Seems odd.



STEVE:  I know.



LEO:  Has anybody responded to these criticisms?



STEVE:  Oh, Leo, oh, my goodness, yes.  I mean, if you click on the - it's the link, let's see, where is it?  Oh, you see the pie chart.  That's from Netcraft.  That's current.  It's "Out of the blue," so it's a page above the blue pie chart, the groups.google.com message.  That's Ryan's posting.  And this thing, I mean, the industry is really not happy.  So, yeah, I mean, it's an education looking through that, yeah.  So there's Ryan's posting.  And if you go down you'll find familiar names.  I recognized Jeremy's name immediately, and Nick Sullivan's name, because these guys are active in the industry.  But this is Google's stated intent with Chrome, basically using the power of Chrome to force the industry to change.  When there's no problem.



LEO:  Right.  Oh, wow.  Huh.  Well, I'm glad you raised the awareness on this.  I can only think that they'll back down on this.



STEVE:  I can't know.  I don't know.  But it's like, hey, we like to have exciting podcasts, and I have a feeling in November we may be having a few.



LEO:  Yeah.  Well, if they go ahead, it's going to be a nightmare.  I mean...



STEVE:  It's going to be an absolute meltdown.



LEO:  They could also change how Google Chrome reacts to these particular certs.  That's the default reaction right now, but they could have a special reaction.



STEVE:  I don't - so, okay, so here's the problem.  This is clearly a pressure move.  One of the reasons the industry is upset is that this is Google "Do No Evil," basically commanding the industry to do something it actually doesn't need to do.  There is no need for this to happen.  Microsoft's 2017 sunset was just fine with everybody, and way in advance of computational feasibility for SHA-1 being a problem.  But they're just saying, no, we want you to do it now, just because we can, because we're Google, because we have the power to force the industry to change.  Nobody wants to be strong-armed, I mean, just on principle.



LEO:  Well, I imagine what the upshot of this will be, people like me will say "Stop using Chrome."  So that's something they may want to consider.



STEVE:  And so my point was that, in response to yours, is that, when you connect to a site, you're either secure or not.  I mean, it's like, how do you say - how does the user understand that there's a battle going on between Google and the web server, and you're the innocent bystander being used to put pressure on Google's behalf against the site, that Google is trying to leverage their users of Chrome to put political pressure to do something that the site actually doesn't need to do.  And the political pressure they're putting on the site is claiming that the site is insecure.  I mean, there's nothing worse.



LEO:  Now, there wouldn't be a warning if the cert expires before the end of the year in 2015.



STEVE:  Correct.



LEO:  So can they - but they'd have to reissue certs that go beyond.



STEVE:  Yes.  Everybody on the Internet.  I mean, this is the problem.  As Jeremy said, companies have systems, have cycles, have planning.  I mean, and the CloudFlare guy, how many sites do they host?  Tens of thousands of sites that all have to change.  And here's the other issue, Leo, the reason I wanted you to bring up that other page?  That's the page of SHA-256 compatibility.  Look through it.  I mean, the early Windows phones are not compatible.  XP SP2 is not compatible, doesn't know about SHA-256.  There are all kinds of other things that are going to break just because they're in environments that can't move.  And the problem is they don't have to move except Google's decided, eh, we're going to make them.  We're going to make everybody do this.



LEO:  That's kind of Google's point is we have to do this; right?  Or everybody would just sit on what they've got right now.  So...



STEVE:  Except we already had the Microsoft deadline of 2017, a hard deadline nobody is upset about.  And the CloudFlare guy, Nick Sullivan, and Jeremy at DigiCert, all they're saying is, 90 days?  Come on.  Give us a, you know, come on, I mean, that's too soon.



LEO:  Some people in the chatroom are saying, well, maybe Google knows of an attack, and they just don't want to tell anybody.



STEVE:  That's absolutely possible.  You're right.  Although...



LEO:  And so they think there is some urgency that maybe we don't think exists.



STEVE:  Maybe then Google shouldn't be using them, either.



LEO:  But those are short-term certs, which they'll stop doing soon, I presume.



STEVE:  Why?  Their browser doesn't care.  They can march right along through the rest of the year and through all of 2015, right up to their own deadline.  And then that gives them plenty of time.  They've got a year from now before they have to worry about it.



LEO:  Is it conceivable that Google knows the government has cracked these, and can't say, but wants people to create government-proof certs?



STEVE:  Well, in that case, Google doesn't care about the government spying on their users despite all their talk...



LEO:  Because they're not using them.



STEVE:  Because they're using SHA-1 right now.  And presumably they will all through 2015.  I'm going to.  I'm going to see if I can get DigiCert to cut me off on midnight.  And then, okay, fine, Google.



LEO:  It's very interesting.  I have to think, I mean, I'm reading this Google Groups posting.



STEVE:  For the first time, yeah.



LEO:  Yeah.  And I have to think there'll be something more substantive in response from Google, I hope, to this show.



STEVE:  Actually, Google doubled down on it with a formal security blog posting.  I read it, but I don't think I have the link here in the show notes.  And it basically said, yes, this is what we're doing.  It had a different headline, and it was not - it wasn't just cloning what Ryan posted.  It was, like, Google's formal declaration.  It's like, okay.



LEO:  Well, well, well.



STEVE:  Like I said, we are not going to have any dull podcasts.



LEO:  It'll be very interesting, yeah.  Well, Google, let's hear from you.  Because this is weird, frankly.  And I don't really understand the scope of it.  They're claiming all this is going to affect fewer than 1% of sites.  But it's more like 92% of sites.



STEVE:  Yeah, uh-huh.  Everyone else thinks that.



LEO:  Why is their number so low?  Where are they getting that number from?



STEVE:  I don't know what they're thinking of.



LEO:  All right.  Well, get ready because I imagine people will go to Firefox from this, frankly.  Go ahead.



STEVE:  And, well, yeah.  Okay.  The other thing I wanted to mention was remember that the way the system is set up is, in order for this to be effective, that is, if SHA-1 is a problem, then we can't have any SHA-1 accepted.  By that I mean, if a web server is switching to SHA-256, and it's got great security on into the year 4000, so, great.  It's using SHA-256.  But if SHA-1 is a problem, or believed to be a problem, then no browsers can accept SHA-1.  That is, that's what we actually have to prevent is the acceptance of SHA-1 by any browser because a bad guy, I mean, because the browser doesn't know that a given site has an SHA-256 certificate, if they receive an SHA-1 fraudulent certificate from a fraudulent site.  If the browser is still willing to accept SHA-1, then we still have a problem.



So what would have happened is that, by 2017, there would, with four years of notice, nobody would generate any sympathy for still trying to use SHA-1.  And all the browsers would - Mozilla would issue a new Firefox, removing support for SHA-1.  Lord knows Chrome would, although they'd have to stop using it themselves first.  And we know that Microsoft will.  And at that point we are then safe from any future use of SHA-1 in the year 2021, when it might theoretically be computationally feasible.  Remember, governments don't need to crack certificates.  They just issue them.  There's no question that the NSA can have a certificate for any site that it wants.  If we don't believe that today, we haven't been paying attention for the last year.



LEO:  Right.  Wow.  All right, well, be very interesting over the next few months.



STEVE:  Fun times.  Fun times, yeah.



LEO:  You'll find Steve Gibson at GRC.com.  That's his website.  Questions, thoughts about this or any of our topics can be fed to him at GRC.com/feedback.  We'll probably be doing a Q&A episode next week, so this would be a good time to do that:  GRC.com/feedback.  You'll also find 16Kb versions of this show there, along with full human written transcriptions and lots of other great stuff, including SpinRite.



STEVE:  I got email from Elaine last week.  Toward the very end of the podcast, when you and I were - we were, like, talking over each other.  And I said something that made absolutely no sense.  And I can't remember now what the phrase was.  But so she sent it to me, she said, "I'm going to hold the transcript until you tell me what you meant."  And I read it, and I said - I wrote back, "I have no idea."  Just moved out of whole - it's like I said something like "The Romans are in the trees" or something.  It's like, what?  It's like, oh, I have no idea what that was.



LEO:  That's why we have humans.



STEVE:  Yes.  Thank you, Elaine.



LEO:  So these transcripts make sense.  You'll also get lots of great stuff like SpinRite, the world's best hard drive maintenance and recovery utility at GRC.com.  So, yes, it's Steve's bread and butter, so check it out.



STEVE:  It fuels all of this.



LEO:  Yeah.  Work proceeds on SQRL.  You can read about it there and a whole lot more.



STEVE:  Yup.



LEO:  We have full quality audio and video at our site, TWiT.tv/sn.  And of course the best thing to do is subscribe to every single episode on your favorite podcatcher.  There are lots of them, including dedicated TWiT apps on all the platforms.  And that way you can make sure you don't miss an episode.  We do Security Now!, by the way, Tuesdays, right after MacBreak Weekly, 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That's 2000 UTC.  And in two weeks...



STEVE:  Yes.



LEO:  Is that right?  Or is it three?  Three weeks.



STEVE:  On the 30th.  Three weeks.



LEO:  No, that's two weeks.  On the 30th or the...



STEVE:  Yeah, two weeks, yeah.



LEO:  Anyway, that's right, because Microsoft is, believe it or not, announcing the next version of Windows on September 30th.



STEVE:  Oh, thank god.



LEO:  So Mary Jo Foley and Paul Thurrott will be at that event in San Francisco on the 30th and will immediately after the event come up here and do a special edition of Windows Weekly in this time slot.  And then you will be going into the Windows Weekly time slot the following day.



STEVE:  Yes, exactly, so I'll be on Wednesday at 11:00.



LEO:  October 1st, Wednesday.



STEVE:  Ah, right.



LEO:  Right, just for - but that's two weeks hence, and that's just for that week, and then we'll back to normal.



STEVE:  Yup.  And we'll remind everybody next week.



LEO:  Yeah, yeah, of course.



STEVE:  We mostly have to - we have to remind ourselves, as well.



LEO:  And, frankly, that's what that was for.  Don't worry, folks.



STEVE:  And everybody, don't forget about yesterday's Triangulation.  You will not regret that podcast.



LEO:  Oh, thank you, yeah.



STEVE:  Thanks, my friend.



LEO:  Thank you, Steve.  We'll see you next time.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#474

DATE:		September 23, 2014

TITLE:		Listener Feedback #197

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-474.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  The iPhone 6 is here.  We'll talk a little bit about iPhone security.  And then we've got lots of questions about all sorts of things coming up next with Steve Gibson and Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 474, recorded September 23rd, 2014:  Your questions, Steve's answers, #197.



It's time for Security Now!, the show that protects you and your loved ones, your online presence, your privacy.  It's really expanded, hasn't it, to privacy as much as security.  Steve Gibson is here.



STEVE GIBSON:  Oh, boy.



LEO:  Go ahead.



STEVE:  Yeah, I was just going to say that I heard the questions you were receiving during your Tech Guy show on the weekend.  And oh, boy, are people, like, wound up and worried about this.



LEO:  That's an interesting issue.  And we're going to...



STEVE:  Yeah, it really is.



LEO:  We have a Q&A episode.  But I think your take on this is very valuable.  You and Jeff Jarvis might be on opposite ends of the continuum.  I don't think you're in completely disagreement.  But, and I think I'm more on the Jeff Jarvis end.  But the issue comes up a lot of trust and privacy.  And my feeling is, if you get too crazy about this stuff, then we're not going to get the technologies that we have.  I mean, if you're going to use the Internet and technology, if you want it to be safe, completely private and safe, you're going to break it.



STEVE:  Yeah.  I think we're going through a rough patch as a consequence, I mean, in the entirely predictable reaction to the Edward Snowden revelations and the NSA.  Arguably, nothing has really changed.



LEO:  Yeah.



STEVE:  One of the things, one of my followers broke down the CA Trust Root Store in iOS 8, which Apple published.  They said, "Here are the trusted roots that we trust in iOS 8."  And we'll talk about that here in a minute.  But it's very interesting.  It absolutely supports my contention that us running around in circles like something's on fire is just an expenditure of energy for no purpose.  The idea, I mean, and my point is that I'm sure deep in the bowels of the intelligence agencies all of us, all of our handwringing over maybe there's a flaw in the pseudorandom number generator that got slipped into this, and oh my god, you know, while the DOD, the U.S. Department of Defense has - and I'm scrolling down to look for it here - five trusted root certificates in the Apple trust.  So they can make any certificate they want.  They don't need to crack any crypto.  They have keys to the front door.  They don't need any freaky backdoor, like oh, my god, maybe the bits have a slight skew from pure entropy.



LEO:  Well, that's interesting because we didn't know this for sure last week.  We were saying it's likely.  And so that is the fact.



STEVE:  Yeah.  And the Hong Kong Post Office is listed in Apple's list.



LEO:  But is that the Chinese government, the Hong Kong Post Office?  Is that...



STEVE:  Who imagines that, if the Chinese government says "We'd like a certificate," that Hong Kong Post Office is going to say no.



LEO:  Right, right.



STEVE:  I mean, it's probably an operating branch.  So anyway, so what I started to say was I don't think there's been any massive change at all.  I mean, one of the questions in the Q&A, which we'll get to, is a great discussion starting point for the work that Google is doing to move things forward.  And I completely agree with its assertion and the idea that in general it's just useful to, I mean, these are useful things to study, useful things to look at, and the Internet ought to move to encryption, if only because we've gone from AOL email as pretty much all anyone was doing to real dependence.  I mean, in the same way you sort of, you know, my advice about people using PCs, they would say, "Oh, yeah, I don't really back it up because there's nothing on there.  We just surf the 'Net and answer email from Aunt Edna."  Or, and this also came up back in the days of firewalls.  It's like, "Oh, we're really not worried about the security of our computer."



And I said, well, you know, what's going to happen is your usage is going to creep over time.  It's going to expand.  Your bank will say, hey, you know, we'll give you a lower rate if you won't ever show up in our facilities, if you'll just do this online.  I was planning a trip for a nephew's wedding over the weekend, and I had to change plans at the last minute.  And I was at the gate, and this gate attendant said, "Well, do you have a smartphone?"  And I said yeah.  And she said, "Well, it's cheaper if you just go over and do it on that, if I don't have to talk to you."  It's like, oh, okay.



LEO:  That's a good tip.  Thank you.



STEVE:  So, yes, thank you.  So what happens is our usage expands, but our security lags.  And it's that window that exists between our expanded usage and security.  Security lags, I mean, and this is really what Google was working to directly address in last week's topic of forcing end-user sites to fix their certificates preemptively, is they were looking at the lag they saw last time and saying, oh, we have the power to force a change, so let's use it.  And so what I'm seeing is a continual increase in people's use of the global network for things that are increasingly private.  So whereas it might have just been fan mail from Aunt Edna, now it's things that they realize they really do want to imagine they're keeping private.



And even though I would argue ultimately they can't because governmental power can crack our crypto unless, I mean, sort of the generic operating crypto.  If I encrypt something with a key that only you and I share, Leo, I'm absolutely certain that I can send that blob to you, and it cannot be cracked.  But things like website communications, which are now encrypted increasingly by default, yeah, that can be opened if somebody with sufficient resources like a government chooses to do that.



But still in general I think the movement toward everything being encrypted, I mean, that's where we're headed.  And everything being encrypted is better than it not being.  If nothing else, it prevents the casual sniffing which we've seen in open WiFi situations that just discloses an amazing amount of information.  And so we're just sort of moving in the right direction and having a lot of fun in the meantime.



LEO:  Yay.  Well, we've got a Q&A today.  You've got tech news.



STEVE:  We do.  I do have the note - I've not gone through this whitepaper.  I'm probably just after because there's not a huge...



LEO:  The Apple, the Apple whitepaper, yeah.



STEVE:  Yeah, sorry, thank you.  I'm looking here at the words "Apple iOS Security," and I realize our listening audience can't see where my eyes are focused.  It's been such a short time since we did an exhaustive coverage of iOS 7, and there are apparently some things that have changed.  But the bulk of iOS 8 security was reflected in that iOS 7 security.  So I plan to read through it and probably come back with, okay, here's the things that I see that have changed in 8 from 7.  And, I mean, and there has been news of improved security.



LEO:  Well, the big, the TLDR, the big one is that Tim Cook has said, and of course we trust him, that they now encrypt the data on the iPhone in such a way that they cannot hand it over to the feds.



STEVE:  Yes, I think that's really interesting, that they're saying that no longer can they even accept phones in this escrowing queue where ultimately they get to it, and then they perform some sort of brute-force attack.  They're saying no.  And I think he's clearly keyed in on exactly the angst that some of your callers over the weekend were expressing.  They're saying we're about privacy because these little slabs of beauty are our product, you are not.  Whereas - and of course he's clearly aiming at Google, saying their harvesting of everything they can learn is the way they generate more revenue.  So he's using that as a differentiating point.



LEO:  Absolutely, yeah.



STEVE:  Also CloudFlare announced what they call "Keyless SSL" that I want to just take note of.  Google and Dropbox have teamed up with a new venture.  Google, a bunch of a people tweeted me about a "malvertiser" that was operating under Google's nose, which they stomped on.  And I have a huge thanks to offer Android users everywhere.



LEO:  Uh-oh.



STEVE:  And 10 really interesting questions and talking points from our listeners.



LEO:  Coming up on Security Now!.  All right.  All right, Steve.  Let's get into it.



STEVE:  I will do a deep dive into the iOS updated whitepaper, which as Rene expected, I'm well aware of, and see what I can find that they've changed.  But it's hard for me to imagine what that might be because as far as I could tell they pretty much have it nailed.  But what I thought was interesting, there's a blog posting, as I mentioned, of an analysis that was done.  His name is Karl Kornel, K-A-R-L dot K-O-R-N-E-L dot U-S.  And so if our listeners are interested, there's more details that I'm going to cover here.  I'm just going to touch on some of his brief, sort of the bullet points here.



So, for example, there are, in iOS 8, 222 trusted root certificates, meaning that any certificate signed by any of those 222 roots, is trusted because we are trusting all of those roots.  The bulk of the certificates, those root certificates, are signed using 2048-bit RSA signatures, and that's 138 of the 222.  So 2048-bit, which is sort of the - that's the existing but fading out standard being replaced rather quickly by 4096-bit signatures.  Forty-four of the certificates, the root certs are signed using 4K-bit RSA signatures.  And this is all kind of confusing because these are, I mean, 4096 bits is an incredibly long signature, but that's because RSA itself isn't as strong as some of our newer technologies.



So, for example, also the next-generation ECC, the elliptic curve signatures, 12 of the CAs have 384-bit.  And so that's 384 bits of ECC signature is roughly equivalent to the strength of 4096-bit RSA.  That is, you just need a lot more bits to make the problem under RSA sufficiently difficult to solve, to the same similar difficulty as you can get using only 384 bits of elliptic curve.  And since bits take time to process, that's also why ECC is seeing much more popularity.  It achieves equivalent strength with a much shorter key, and that equates to much faster processing time because you just have to deal with fewer bits.



So those are the various keys.  The predominant signature algorithm is still SHA-1; 149 of the CAs are hashing their certificate using SHA-1.  So it's 149 SHA-1.  Next down is what we were talking about last week, SHA-256, 42 certificate authorities use SHA-256; 17 SHA-384; and one of them SHA-512.  And oddly enough, there are three certificate authorities that have signed their cert with MD2 that's, like, I'm curious actually to know which three they are because that's just - that's crazy, MD2.  I mean, that's worse than MD5.  And 10 CAs have their certs signed by MD5.



The problem is that the root doesn't expire.  These root certs, they, like, have expirations in 2038.  And I'm not sure if they go any further.  2038 is a weird year because I think that's the year that the UNIX time wraps around.  And we're going to be, if the podcast is still going in 2038, we may actually have a Y2K experience then because, when the UNIX time wraps, we may be in for some fun because - although it's been understood that that's happening for a long time, and extensions have long since existed for that.  But I do, for some reason, I'm remembering certificates expiring in 2038.



The point is that the roots don't expire because they're built into our infrastructure.  It's the certificates that they sign which expire every two or three years and need to be continuously renewed.  So some interesting demographics there.  However, I'll just wrap by saying that Karl scanned, just visually scanned the list and noted a number of governments that have trusted root certs in Apple's iOS 8 store.  And I don't mean to be singling Apple out at all.  I mean, I'm sure this is the same certificate store that is in the Macs.  And if anything, Microsoft trusts twice as many.  As I remember, they're in the 400s of root certs.  So Microsoft is probably a superset of these.



But, for example, we've got a certificate not only from the Hong Kong Post Office, but China itself.  The China Internet Network Information Center is a trusted certificate signer.  Japan has three CAs, certificate authorities.  The Netherlands has three.  Taiwan has one.  Turkey has one.  And the United States has five, as I mentioned, via the Department of Defense.  So these are all equally trusted, meaning that, in the same way that Google, well, Google may be an exception, at least under Chrome, because they do so much certificate pinning.  Like they're able to spot certificates, forged Google certificates if you're using Chrome because they look at the exact signature, not just to see if the signature is valid.  But what I was going to say was that all these roots being trusted is, I mean, what that implies is that they can sign a certificate for any website they choose, and no alarm gets raised.



Now, anyone scrutinizing the certificate chain would see that this terminates in an odd place if it wasn't signed by VeriSign or DigiCert or GoDaddy or one of the biggies.  It was signed by China, or it was signed by the U.S. DOD.  But for selective decryption, that is, for selective interception of specific traffic, it's difficult to imagine that, because they risk exposure, because they can't do this and have it completely unseen, but they certainly can do it on demand, I'd be very surprised if this wasn't something that was being done on a limited basis, that is, if this wide body of trust isn't doing things we wouldn't expect.



And everyone will, actually people who have either started recently listening to the podcast from the beginning or have really good memories will remember the podcast when, after years of being away from looking at the trusted root, I had an occasion to look at it, and I came back on the podcast, and I said, oh, my god, Leo.  I mean, I remember when there were 12.



LEO:  I do, yeah, yeah, yeah.



STEVE:  Remember?  And I remember saying...



LEO:  And the Hong Kong Post Office has been the butt of a joke ever since.



STEVE:  Yeah.  I remember saying, "This is bad."  I mean, and then I explained why my mind was blown, that, like, without me paying attention or anyone particularly paying attention, it had gone from, like, 12 companies who were in the business of selling certificates to, like, the Hong Kong Post Office and everybody else who we were trusting equally.  And so just like, well, that's the way it works.  But again, I think the point here is to understand what's going on.  And that's what the podcast is for, to explain that what we're getting now is a useful next level of encryption.  But it is still not TNO.  TNO is different.  TNO means you're not even trusting the root certs.  You're not trusting anybody.  TNO, Trust No One, means you have arranged to have a key, you've encrypted your data yourself, and you've given it to somebody else to whom you have somehow managed to communicate that key.  That technology I believe cannot be cracked.  I mean, period.  I mean, really, truly.



But that's not the security most people use.  Most people use a security which is good.  It's like iMessage.  It's like, if Apple is handing you the keys - people say, "Oh, Apple doesn't have the keys."  Well, yes, they do, because they've given me the key which I've used to sign a message to someone else.  So they could also give me a key to sign a message to them, and I wouldn't know it.  So the point is we are getting encryption.  It's better than not having it.  But it isn't TNO.  TNO has the beauty of being absolute.  We can say this is absolute security.  And it isn't what most people use.  But most people really don't need that level of crazy absolute security.



CloudFlare is a service that we've talked about.  One of our favorite techies, John Graham-Cumming, is one of the technologists there, over in the U.K.  And he did the book, what was it, it was the really tech...



LEO:  A couple of things.  One was the travel, like the top 30 spots geeks should see in the world.



STEVE:  Yeah, yeah, yeah, really neat things.  Yeah.



LEO:  He's a neat guy.  We've known him for years.



STEVE:  Yes.  Anyway...



LEO:  He also got Alan Turing's name, he got the apology from the British government.



STEVE:  Oh, did he.



LEO:  Yes.



STEVE:  Nice.  That's right, I forgot, yes.  And we did talk about that.  And in fact somebody sent me or tweeted something, I don't remember what it was, but it was just recently, they had gone to the museum and were really moved by the strength of the apology that was now there and made...



LEO:  Was it Tony Blair?  I think it was - I don't think it was Cameron.  I think it was Tony Blair.  Anyway, yes.  So he's a great guy.



STEVE:  So the question is, their business is protecting websites from attack.  And they've had a problem, which is, if they are what the web browser connects to when it wants a secure session, they have to have the keys for the website that they're standing in for, and they need to stand in for the website in order to filter the traffic.  In their blog posting announcing - and this is just in the last week - announcing what they call "keyless SSL," they explain how two years ago, in 2012, they got a call from one of the world's largest banks, in New York, at a time when they were just a small startup.



And this banker, the, like, CEO or CIO, said, "We're suffering denial of service attacks of a strength we can't handle.  We need to talk.  Can you guys come?"  And the author of the blog posting for CloudFlare said, "We were a small team," and he took a little tangent and talked about who wore shorts too often and the Hawaiian shirts and so forth, and said please don't wear your khakis to the meeting of the president of the largest bank in the world.



So they flew to the states.  They flew to New York, met with the banker or the CIO.  And the problem was that the bank wanted the protection, needed the protection of a massive pipe and denial of service filtering technology in front of the bank's network; yet, being the bank, they could not release the keys.  They said, in fact, any discovery that we have lost control of our private server keys requires an immediate disclosure to the U.S. federal government.



LEO:  Wow.



STEVE:  I mean, it is critical.  So these guys flew home.  And it's funny because he said that they spent some time on the chalkboard, and the engineers' minds got engaged.  And they named someone, I don't remember his name, and they said he's the kind of guy who cannot sleep when he's working on a problem.  And he says, "That is a hiring criteria at CloudFlare."  So...



LEO:  I love it.



STEVE:  Yeah, it was great.



LEO:  I want to work there.



STEVE:  Yes.



LEO:  I love that.



STEVE:  So they've just announced a solution to the problem.  It's not hard to do it in a way that doesn't scale.  It's very difficult to do it in a way that scales.  And I've not looked at the whitepaper.  There's a technical nitty-gritty details whitepaper.  I will check it out and figure out and see if there's enough meat there because it's interesting.  It's an intriguing problem in security.  Basically you need to farm out, you need to subcontract the SSL, the TLS, HTTPS negotiation to a third party while never giving them your security certificate.  So somehow they've arranged to proxy the connection.  And again, immediately you can see how it's possible.  We've talked about the SSL handshake, how there's a communication process.



So one could imagine that there was probably a way for them to send a query to New York to get some of the crypto stuff, which then comes back, and then they send it to the client and so forth, where they're sort of being a privileged man in the middle, but they need to do it in a way that doesn't disclose any of the sensitive crypto material that the party that they're standing in for has.  And they've solved it.  So anyway, I got - a bunch of people wanted to make sure that I knew about that.  I do.  And I will dig into it and see if I've said all that really needs to be said, or if it's an interesting topic for the podcast.



Meanwhile, Google and Dropbox have - this just sort of is a news bullet, not a lot of technical news here, in fact none.  But I thought it was interesting that they had formed a team.  They've created a new entity called Simply Secure at SimplySecure.org.  And pretty much nothing is there right now.  I guess they've just sort of - they created an organization called Simply Secure.  Their charter is to search for ways to bring the security in the lab to the real world, recognizing that - and one of the team leaders has spent time at Google.  She, too, was involved in the second-factor work and just sort of in general in security-focused, customer-facing, user-facing security.



And we all recognize that there is cryptographic technology that isn't yet being used.  I mean, my own SQRL system, which is not a breakthrough, it's just the application of standard crypto.  It's like, look, that's why I was tempted to call it HIPS, Hiding In Plain Sight, because it's like, okay, why hasn't anybody done this?  So that's an example of something really simple, really secure, that just isn't being used.  So anyway, we don't know what's going to come out of them, but I wanted to just sort of note the spawning of this organization, SimplySecure.org, by Google and Dropbox.  And we'll kind of keep an eye on it and see if they come up with something interesting.



And Google did have a problem this last week, they shut them down on Friday, with what's called a "malvertiser."  They were serving ads through their DoubleClick subsidiary - remember they bought DoubleClick a few years back - from another ad network called Zedo, Z-E-D-O, dot com.  And one thinks that this was one of those domain-name-driven companies, where it's like, okay, what names are left?  Zedo is left.



LEO:  Yeah.



STEVE:  Okay, fine.  Well, that's only four letters.  That's good, we'll go with Zedo.



LEO:  You did check SQRL.com, I hope.



STEVE:  Oh, yeah, that was gone a long time ago, unfortunately.  Although I got it in a few random, off-brand domains, just to have it.



LEO:  Hey, at this point parents ought to check the web to make sure they can get their kids' names for the URL.  Don't name a kid John Smith.  I mean, forget it, you'll never find him.



STEVE:  Yeah, and, boy, will he get spam.



LEO:  Right.  Right.  So I think parents - watch, because kids names are going to get wild soon.



STEVE:  Yeah.  I think it hasn't - it's been a while since I've mentioned, but Jenny told me that she had her friend, Diana, who was just being buried under spam.  And unfortunately Diana has her own domain name for her yoga dojo or whatever it's called.  And so it's diana at yogadojo.com.  And when Jenny said what can she do, I said she can change her email address.  And I've looked at the packet traffic at GRC's SMTP servers.  And it is random, it's not even lists.



LEO:  They try all common first names.



STEVE:  Yes, yes.  Something connects, and it just sits there and goes through Bob and Bill and Benny and Bert and Bernadine and so forth.  And for a long time I was steve@grc.com.  And of course I was being killed, not because I was, I mean, I had an email address for a long time, but because my email address was just Steve.  And what I realized was all - in fact, it's one of the nice things we have now is if - I'm using hMailServer.  And it will see that behavior and put in a temporary blacklist of any web server that connects.  And it had, like, three misfires of name that just don't exist in our domain at all, it just says, okay, this guy's just guessing.  We're just going to block from now on, you know...



LEO:  Smart, smart.  That's good.



STEVE:  Yeah, blacklist them.



LEO:  Yeah.



STEVE:  So anyway, this Zedo.com was probably, I mean, I looked at their website.  They look legitimate, too.  So I think what happened was they were inadvertently hosting a malicious ad that somebody sent through their network, which they then sent through DoubleClick, which then Google sent out to Last.fm was one of the big sites hosting this malvertising, The Times of Israel, and The Jerusalem Post.  So draw your own conclusions.  But those were the three that were mentioned as being the heavy carriers of this malicious ad which was hosting JavaScript, of course, which would then download the Zermot downloader, Z-E-R-M-O-T, which is well known.  Microsoft knows about it, Windows Defender and Security Essentials both know about it.



So pretty much anybody who had good, active, up-to-date antimalware would probably not have had a problem.  But anybody who wasn't running antimalware and visited those sites, and I don't think you needed to click, I think it was a no user action required, the script just ran and somehow leveraged some behavior in the browser to get outside of the browser sandbox, and people were being infected.  So the moment Google found out, which was last Friday, they foreclosed, they lowered the boom on Zedo.



LEO:  Yeah.  And this isn't the first time this has happened.  We've seen it happen with any kind of - Yahoo! has had it happen to them - automated advertising platform.  They're set up so that you don't have to get anybody's approval.  You just buy an ad, and you put it in there.  They've got to fix that.  That's not a good, you know, unattended HTML and CSS and who knows what else is not a good thing.



STEVE:  Yeah.  It is really, I mean, it's an inherent problem with the way the advertising model has developed.  I mean, and I've talked about this.  I see, because I'm using NoScript, I'll like click on the little logo in the toolbar.  And I look at the number of domains which are enumerated there by NoScript which are referred to by the page I am visiting and trying to provide their own content to this page.  I mean, so the truth is that servers are trusting a vast network of other content.  And it's just sort of - it sort of accrued over time like barnacles.  It's like, oh, well, we want to be able to use the features of jQuery.  So jQuery is now one of the blobs that each web page we serve, I don't mean "we" GRC because I don't use them.  But that's the way these things are done is browsers are pulling from an incredible number of third parties.



And one type of third party that just tends to be a little more in the gray zone is ad servers.  They're just serving lots of ads.  And so, and the fact that they have the ability to change the content at will, and in some cases to make them sensitive to the context of the user or where they're visiting, it's like, well, ads on this site will tend to have this kind of content.  That means that you're not able to lock them down and check the script and then ask it to qualify through some checksum.  The ads are just changing all the time.



So it's a disturbing aspect of the way we're using the web.  And we'd like to be able to turn off JavaScript, but I'm running into more and more sites that, over time, we would expect this, over time sites are becoming increasingly dependent upon scripting.  They're wanting to run code in your browser to offer you the more, the web, whatever version we're on now - I think I heard Andy say it's 49.2, you know, web version whatever - in order to give us the features that we want.  So less and less, running with no scripting enabled at all is becoming infeasible.  Okay.  My huge heartfelt...



LEO:  I'm waiting for what this is.  This is good.  This is - something's going on here deep.



STEVE:  Thank you, thank you to all Android users everywhere.



LEO:  Okay, you mentioned this.  Now I'm worried.



STEVE:  Because when I posted over the weekend that my life had been changed by the ability to install third-party keyboards, I got tweets back saying, "Welcome to 2010."



LEO:  Yeah.  This is the new meme from Android folks, yeah, yeah.



STEVE:  Gibson, it's like where have you been, where have they...



LEO:  Ooh, predictive text.  Are you excited?  Are you excited?



STEVE:  Okay, so Leo.



LEO:  We had that on the BlackBerry, I think.



STEVE:  I've ended up settling for Swype.



LEO:  Oh, really.  Okay.



STEVE:  Yeah.



LEO:  You know you can swipe on SwiftKey.



STEVE:  Oh, I know.  But Swype does a few things that I like better.  If I Swype a word, and it's wrong, backspace removes the entire word.



LEO:  That's nice, yeah.



STEVE:  That doesn't happen on SwiftKey.



LEO:  Okay, okay.  That's good, yeah.



STEVE:  So normally that's a better thing.  Also, although there's more a bit of a learning curve associated with this, when iOS first came out, you and I were talking about how you could hold a key, and then you'd get a little submenu that would pop up.  Or you could just, like, stroke upwards from the comma or something, and you would get a double quote.  I like those power features.  Under Swype, the entire shifted keyboard is always there without shift, if you just hold.  So, for example, I now know that G is open parens and H is closed parens.  And so to me that's valuable.  I did have to learn it, but now I can - because I like to parenthesize things, that's nice.



LEO:  You iPhoners, you're just so cute.



STEVE:  And, okay, okay.



LEO:  By the way, no, that's a huge - SwiftKey does that, as well.  But that's a huge feature, I agree.  I agree.  I use it all the time.  For numbers and all punctuation.



STEVE:  And swiping Z down to the spacebar gives you a quick exclamation point.  Swiping M, I think it is, or L down gives you a question mark.  Anyway, the point is, oh, my goodness.  And I have given it some words.  I was just chuckling because I'm having to go, like, back and forth across the keyboard, blah blah blah blah, like Busterfreedonical or something like that.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Some crazy word.  And it says, yeah, there you go.  And it's like, oh, my god.  Anyway, I'm having dinner with Jen, and I'm going to change her life, too, because she did upgrade to 8, but I haven't had a chance to sit down with her and show her this.  And my best friend Mark's going to join us.  And this, I mean, oh, my god.  Well, you know, I cannot stand that old keyboard on iOS pre-8.



LEO:  I've hated it for years, yeah.



STEVE:  It was the worst thing.



LEO:  It kind of bugs me because it still pops up whenever you enter a password.  So you have to kind of go back and start using that keyboard, which is...



STEVE:  Yeah, and there's a couple problems.



LEO:  I understand why.



STEVE:  Tweetbot has a problem, I guess, with third-party keyboards.  I don't think it's the keyboard.  It's Tweetbot.  So I can't use them yet.  But these things will get fixed.



LEO:  A couple of points, though.



STEVE:  But I just wanted to say thank you, thank you, thank you.  Wow.



LEO:  A couple of points.  First of all, press and hold backspace will delete a full word back on SwiftKey, so it does have that capability.



STEVE:  Ah, okay, good.



LEO:  You just have to hold it for a little longer.



STEVE:  And we should mention SwiftKey is free, but Swype is either one or two...



LEO:  Right, 99 cents.



STEVE:  Okay, 99 cents.



LEO:  Yeah.  The other point, well, it's a question because of course the first thing that happens when you install a third-party keyboard is Apple puts a very long, very scary warning, "That keyboard is capturing all your keystrokes and sending it back.  We don't know what they're doing with it."  Android, to Google's credit, does the same kind of warning.  But it seems to scare people.  So you're not worried about that?



STEVE:  Okay.  So SwiftKey does that.  Swype doesn't.  Now, okay.  Also I should mention that Swype runs on the iPads.  SwiftKey doesn't.  So...



LEO:  Well, SwiftKey runs in an iPad, but it doesn't do Flow.  Doesn't do...



STEVE:  Yes, sorry, correct.  It doesn't do Flow.  They claim that they don't have sufficient memory, that is, that the memory allocation...



LEO:  Oh, that's interesting.



STEVE:  ...that the pads give them isn't enough to allow them to do Flow.



LEO:  Right.



STEVE:  And Flow is the only thing I want.  Oh, my god.



LEO:  Oh, I agree.  It's much faster than typing.



STEVE:  Yes.  And I saw you mention, Leo, that you, like, swipe - you Flow down to the spacebar as if you're doing multiple words in a single swipe, which I'm not.  I'm lifting my finger at the end of a word.



LEO:  No, I am, too.  I don't know...



STEVE:  Oh, okay.  Okay.



LEO:  Yeah, yeah.  No, I am, too.



STEVE:  Yeah.  Then I just misunderstood.  So, okay.  So I really like the idea of networking because I'm a multi-device person.  I've got a pad next to me.  There's one that lives in the car.  I've got my new big megaphone.  And so the idea that SwiftKey would be cloud-syncing the things it's learning about me on these different devices, that's a convenience.



However, I received a ton of tweets over the weekend from people say, well, yeah, but SwiftKey - because I first tweeted about SwiftKey, saying, oh, my god.  And then the more I looked at it, I thought, you know, I think I just sort of do like Swype better.  Well, for one thing, I really like being able to do the Flow over on the pads, and I'm still a pad user.  Although Flow on a big keyboard isn't really, you know, it's a lot of movement.  Although I guess your fingers are still moving when you're tapping on a big keyboard.  But anyway, I just wanted to say thank you to Android users.  If you're the reason these apps...



LEO:  You can also thank Android users for these big phones, too.  I mean, I don't think Apple would have done a 5.5" phone if it weren't for all the...



STEVE:  Oh, in fact I wanted to mention the funniest reaction that I was noting of myself is when - because I got the white bezel gold tone, champagne, whatever the hell they call that, iPhone.  It's the first one I have ever got that isn't black.  But I thought, eh, what the hell, it looks pretty.  And every time my eye fell on it, I thought Samsung.  I mean, it just...



LEO:  The white one looks a Samsung?  Yeah.



STEVE:  It does.



LEO:  It really does.



STEVE:  It's, I mean, and I'm so - after years of these big white Samsung phones, that's what I think I own.  I look at it, and my brain says, "Okay, that's a Samsung."



LEO:  Guess I went Samsung, and I didn't even know it.  Yeah, I think those were the two issues I had with iPhone were the screen size and the keyboard.



STEVE:  Oh, yes.  And I now look at my 5s, and I think...



LEO:  It's dinky.



STEVE:  ...how did I ever - no wonder I never actually used it.  I had, to give you a sense, lifetime talk on my iPhone 5, which I happened to see as I was decommissioning it was three minutes.



LEO:  What?



STEVE:  I've never had a...



LEO:  Three minutes?



STEVE:  I've never spoken on my iPhone 5 except, like...



LEO:  You have no one to call.  Who you going to call?



STEVE:  I don't use it.



LEO:  Have you started using - we're not going to turn this into the iPhone show.  But have you started using in messages the audio?



STEVE:  I see that.  I haven't yet...



LEO:  Jenny uses an iPhone.  It needs to be to other iPhone users.



STEVE:  Yes, she does.  Oh, and that's the other thing.  In the whole iPhone versus Android, because I've been listening to you for the last week, I wanted to mention that it is also a function of ecosystem.  I don't know a single Android phone user.



LEO:  Well, you know me.



STEVE:  My entire family, all my friends.  But, I mean, like the people I'm in total constant texting mode with.  And we have, like, iMessage groups.



LEO:  And in that case, that's a very compelling reason to use the iPhone because, for instance, iPhoning to my daughter, half the time I don't text her, I just give her an audio thing.  Same thing to Lisa, she's an iPhone user.  And that really is compelling.  You can send pictures very easily the same way:  Hold the picture thing down.  It'll snap a picture and then slide up.  It'll send it.



STEVE:  Yeah.  And I do agree with you, that double-touch nonsense about sliding the screen down?  I just think that's, like, somebody said, hey, you know, we can sense when you tap the Touch ID without pressing the button.  So...



LEO:  Let's do something with that.



STEVE:  ...what can we do?  Exactly.  Let's make that something.  It's like, oh, okay.



LEO:  Some people love that.  And you know why I don't care about it is because Android phones have these menu keys at the bottom.  And so most of the stuff that I want to do is within reach of my thumb at all times on an Android phone.  I realized - so maybe I'm not being fair to the people who use iPhones who are really thrown by this mega screen.  You call it your megaphone.  I like it.



STEVE:  It's the megaphone.  I also feel like they're halfway there on the screen rotation.  Boy, is it buggy in some places.  And it just doesn't work.  And it's like, okay.  Either do it or don't, but don't choose not to do it when maybe you ought to.  So it's like - or I just think - I think it's a little - it's showing - oh, and in general I should just say that the feeling I've had in listening to you talking about this is, or in some cases ranting, as you were at various points over the weekend...



LEO:  I've been in rant mode for a whole week.



STEVE:  And I was in agreement in some cases.  It feels to me like Apple is struggling with the phone's identity.  It began as a beautiful closed system of very simple, like duh, use it, apps, where there was nothing hidden.  I mean, there was like, they were all of them beautifully crafted, very simple.  But they are trying to power this thing up into a pocket computer.  And now we're getting interapp communication.  And we've had, thank goodness, copy-and-paste functionality to transport information back and forth.  But, I mean, the problem I think we're having now is that their interface is beginning to collapse.  The super simple UI is struggling under the demands of a much more sophisticated device that really wants, like, multiple-choice dropdown menus and a more classic desktop UI, yet we're not getting them.  Instead we're just kind of getting  funky operation.



LEO:  Yeah.  I haven't decided, but I think I'm going to stick with Android.  I'm waiting to get my cognac leather-backed X.  And we'll see.



STEVE:  And I'll just say again I agree with you that I think the watch is a fiasco.  I think it's...



LEO:  I'll be interested to see what happens there, yeah.



STEVE:  Yeah.  Especially at the price that I've heard people guessing.



LEO:  $6,000 [laughing].



STEVE:  And I wanted to mention, when Dvorak talked about melting it down, that the gold is not worth nearly what the watch retail price will be.



LEO:  Well, I don't know how many ounces of gold you think it is.  Four?  That would be, what, 12, 2,400 bucks.  I don't know.



STEVE:  I guess the price of gold has gone up.



LEO:  Oh, it's a lot, yeah.



STEVE:  I bought a bunch when it was $400 an ounce, so...



LEO:  Well, hold that gold.  Is it in your backyard in a hole?  I can't remember what it is an ounce now, but it's quite expensive.



STEVE:  Yeah, it sort of crept up.  I got a great little note I just wanted to share, that actually follows up on a question I guess we answered.  It was Martin who wrote from Frankfurt, Germany.  I ran across this on - he sent it on September - where are we?



LEO:  $1,200 an ounce.



STEVE:  Okay, cool.



LEO:  So, yeah.  If there's four ounces in there, you're going to have to charge $6,000.



STEVE:  Boy, yeah.



LEO:  But it's not 24-karat gold, it's 18-karat gold.



STEVE:  Is that harder or softer?  That's harder, yes.



LEO:  The lower the karats, the harder the gold.



STEVE:  Right, right.  So anyway, Martin says Level 2 "look but don't touch" actually does save the day.  And he said:  "Hello Steve.  Thanks for answering my question about how SpinRite on Level 2 actually fixes things on one of the last shows.  Only a few days later I was witness to it actually fixing a huge problem using Level 2.  A friend's work PC refused to boot, and his company's IT department gave up on it without being able to recover ANY," Martin has in all caps, "of his valuable data.  Of course the backup had silently failed without him or anyone else noticing, and his data was gone.



"So we gave SpinRite a try on Level 2, and it slowed down and started working a lot harder about a quarter of the way in, seemingly not moving any further.  So my friend lost patience and turned the machine off.  I told him not to give up and just let SpinRite run for however long it takes.  Well, after about eight hours of chewing on the drive, it was finished.  The PC booted again with complete data recovery.  Hooray for SpinRite.  Now I am his hero, but actually you are.  Thank you very much on behalf of my friend who got all of his data back thanks to SpinRite.  Martin."



And I'll just say I don't have a problem, although this is technically not how we license SpinRite, our listeners know that if someone is in trouble like this, I don't have a problem with a friend helping a friend.  And this friend now knows about SpinRite, so he may spread the word or grab a copy for himself.  So thanks for sharing, Martin.



LEO:  You're very generous and genial.



STEVE:  We've got some great talking points and questions and feedback from our listeners.  So I'm glad we do this, 197 times.



LEO:  I am, too, actually.  It's become kind of an important part of the show overall is to give people a chance to get clarification and get ideas from you.



STEVE:  And there's some pithy stuff every so often.  We have one great note.  As you say, we're never going to be finished talking about the stringing Ethernet across a great distance.



LEO:  Oh, no, no, more?



STEVE:  All of us have just been put in our place.



LEO:  Oh.  Probably by somebody smarter than Nietzsche.



STEVE:  An interesting gal.



LEO:  Matthew Urch kicks us off, though, Matthew, pronounced like "church," Toronto, Ontario, Canada.  He found us four weeks ago:  Hey, Steve.  I found the podcast a month or so ago, and I've been working to get caught up on all the years of great content I've missed between new episodes airing.  He says he's listened to the first 93 so far.  You've got quite a way to go.  What is it, nine years of shows?  However, whenever I hear a suggestion of yours and/or Leo's, since the suggestion took place in some cases the better part of a decade ago, I always wonder what the current state of those suggestions are.



Kerio Firewall, remember that?  The Astaro Gateway.  Blink from eEye, remember that?  Really just an update on items that you've thoroughly discussed or suggested numerous times in the past.  Reason I ask, I recently listened to the Blink from eEye episode.  When I looked it up, the company has been acquired, the product has been re-branded, and the only option is requesting a quote.  I don't even know if it's still the same product.  Anyway, thanks for the great content.  I look forward to getting stuck in traffic so I can listen to more Security Now!.  And by the way, I'm planning on buying SpinRite very soon.  That is one of the flaws of being such a long-time successful show.



STEVE:  Yeah, I guess.  I wouldn't call it a flaw.  I would say that it's a consequence of the fact that the show really is two things.  Clearly we care about the news of the day.  I mean, it's just interesting, talking about Google's decision to force the change in certificate signature technology, that's really interesting.  How can we not talk about that?  Now, a decade from now that'll be of historical interest, but clearly not as useful.  On the other hand, the fundamentals of the way the Internet works, which we've done a series on, or the fundamentals of computing technology, which Matthew will be getting to here pretty soon.  Those are almost timeless.  So we have a mix of things.



Now, if we didn't archive them, then we'd purely be broadcasting into the ether.  You'd get the ones you could and have no access to the past.  I think it's really super useful.  But I'm sorry, Matthew and anybody else, it doesn't make sense for us to add to the burden we're already carrying of, like, oh, and here's where we stand with the Kerio Firewall and Blink from eEye.  I mean, we can't, you know, we're making archive episodes available because certainly for some purposes they're valuable.  But not for here's our favorite twitch from 10 years ago.  It's just that there is information that is going to age and decay and no longer be useful mixed in with the stuff that's timeless.



LEO:  Look.  Somebody in the chatroom pointed out National Geographic continues to publish magazines, and you may have a stack of them, but the fact that you've gone back to 1963 to read that article doesn't put a burden on National Geographic to correct it.



STEVE:  Ah.



LEO:  It's frozen in amber.



STEVE:  Been published.



LEO:  Been published, done with that.  So what I encourage you to do, and I'm sure you're doing this, is listen to the current episodes.  If you want to listen to the past ones that's great.  But recommendations for current products from old episodes, they're meaningless.  They don't...



STEVE:  It is true, though, that we're building on knowledge.  And so I was...



LEO:  Oh, yeah, no, it's good to listen to the old ones.  Yes.



STEVE:  Yeah, I don't want to discourage anybody from filling up their new multi-gig pocket device with this stuff because there is plenty there.



LEO:  It is called "Security Now!."



STEVE:  Yeah.



LEO:  Now.  Robert Osorio in Lady Lake, Florida brings back the bouncing battery mystery:  Steve and Leo, the answer to why a dead battery bounces is from cannotunsee.net, why a dead battery will bounce and a new one does not.



STEVE:  So there's a video link in the show notes.  I don't know if it's worth going through it.  It's actually pretty long, Leo.  But I'll summarize it as follows, and remember that I think we talked about this on the podcast.  This sort of hit the meme of the day a few months ago where bizarrely enough it was found that a dead battery bounces actively, and a live battery with still juice in it to give just thuds.  And, I mean, it was just a great Internet meme that occurred.  And so these guys do a series of experiments.



LEO:  They actually built a device so that they would have the same trajectory each time.



STEVE:  Yeah, yeah.  So, I mean, and...



LEO:  Oh, look it, it does.  It's true.  You really see it.



STEVE:  Boing oing oing oing oing.  Yeah.



LEO:  This is like a ping pong ball.



STEVE:  And now charged up, blunk.



LEO:  Yeah.  No, that's true.  Well, there we go.  That's proof positive it does it.  So why does it do it?



STEVE:  So it turns out that a used-up battery is - oh, and then they have theories of outgassing, or I don't remember what they called the other one.  Apparently there's something called a "recoilless hammer"?  Never knew about that.



LEO:  Oh, yeah, yeah, yeah.



STEVE:  You can get a hammer that's got, like, BBs in it.



LEO:  Right.



STEVE:  And when you hit something with it...



LEO:  It thuds, yeah.



STEVE:  Anyway, so the point is that - and this is the way - I would normally never be able to remember which bounced and which didn't.  Is it the charged battery that bounces, or the discharged battery that bounces?  Now I have a way of never knowing because what happens is the electrolyte is completely dried out in a used-up battery.  It is not gooey at all.  It is dry.  And so it acts as a solid.  Oh, and so here they're doing outgassing.  They're dropping something on the battery to see if it's springy or not.  So they're dropping a slug...



LEO:  Oh, lord.  They really did this seriously.  That's amazing.  They care a lot about it.



STEVE:  The point is that a battery filled with wet goo doesn't bounce.  It thuds because the properties of the goo essentially absorb the battery's kinetic energy.



LEO:  That makes sense, yeah.



STEVE:  Whereas the dry battery bounces like a bunny rabbit.  So now we know.  Thank you, Robert.  And in this video that I link to, they get around to sawing the batteries open and, like, sticking stuff in and stirring it around.  And you see that the one that just thuds, that's got charge left in it, is just a gooey mess inside; whereas the dead one, oh, my goodness, it looks like a dry creek bed.  So complete difference.



LEO:  Cannotunsee.net.  And that's actually a great site.  They've got a lot of interesting stuff on there.  It's a tumblog.



STEVE:  It's like something like old guys, retired engineers or something, having dinner or something.



LEO:  They have some sort of ad for ROMEO:  Retired Old Men Eating Out.



STEVE:  That's it.



LEO:  I don't know what it is.  Is it a group?  I don't know what it is.  But maybe you and I should join.  Melissa Good in Miami, Florida teaches old engineers something about Ethernet.  Steve, one reason why fiber should be used between two houses 400 feet apart is because Ethernet over twisted pair's limit is 328 feet, or 100 meters.  I'll leave the whole issue of power imbalance alone.  Love the podcast.  Never miss it.  Melissa.  Okay, okay, okay, okay.



STEVE:  I just loved it.  It just sort of - just ended the debate.



LEO:  We stand corrected, yes, yes.



STEVE:  Should two houses 400 feet away be connected by Ethernet?  Uh, probably not because it's a 100-meter limit, which is 328 feet, and that's less than 400.  So there's the answer to our question.  Doesn't matter about balanced loads and current loops and shielded wires and all this mumbo-jumbo.  Nope, it's just too far away.



LEO:  You may also remember we talked a little bit about two-factor authentication at gas pumps using zip codes.  And of course we said that's not going to work in Canada.  Well, Faiz Imam in Montreal, Canada solves the mystery of the Canadian gas pump zip code authentication:  MasterCard is aware of the issue of gas pump authentication, he writes, and has an ingenious workaround that maintains the spirit of the zip code.  It's really quite simple.  You take your Canadian postal code, for example, J3N 4N5.  Just keep the numbers, 345, then add two zeroes at the end:  34500.  Enter that into the gas pump, and it will be accepted.  This is not a trick.  It's official MasterCard policy.  And he quotes MasterCard.ca.  This way you still need info only you know, and apparently MasterCard, but it fits within the U.S. standard.  Users of Visa and other cards will be out of luck.  Just an FYI for Canadian MasterCard users.  I don't know how they publicize that.



STEVE:  Yeah, it's interesting.  But we have.



LEO:  It's cool.  Now you know.



STEVE:  Yeah, now we know.  And just for the record, there was a ton of feedback from our very correct and security-conscious listeners who were noting that, well, you know, you probably could guess a zip code because after all it's not a random five numbers, it's tied to your geography, and they probably have some idea, blah blah blah.  So it's like, okay.  Or you can certainly guess the first several digits because, as we know, the zip code is actually sequential based on physical location.  And I'm in a 926 area, and so...



LEO:  I think it's better than nothing.



STEVE:  It's absolutely better than nothing.  I'm happy I'm being asked.



LEO:  It's a pretty low standard, but it is our standard.



STEVE:  Yeah.  It does not meet our crypto high entropy standard.  But then anything that did, nobody could remember.  And the beauty is pretty much you know what your zip code is.



LEO:  Right.



STEVE:  Just it's just not a random five digits.  And that means that other people could have an idea, too.  So I wanted to just acknowledge all the people who said, eh, it's really not that good.  It's like, eh, it's better than nothing.



LEO:  Eric follows up with a final thought about his new installation of Windows XP on a Virtual Machine.  Steve, thanks for answering my question about the need to install updates into a new, VM-isolated Windows XP instance.  You said you should.



STEVE:  Yup.



LEO:  One additional note:  I realized I did need to go online anyway, at least briefly, to authenticate Windows.  Oh, that's a good point.



STEVE:  Ah, yes.



LEO:  So even if I have to just do it once, I'll be doing the Windows Update.  Thanks.  Eric.



STEVE:  Yeah, it was a good point.  I thought that was a good point because I was saying, oh, my god, the one thing you do know about a virgin installation of XP is that every worm written in the last decade or even more is targeting that OS.  And so absolutely bring it current.  And so then it was like, yeah, but if there's absolutely really no Internet connection, then you really don't have to; right?  I mean, it's not going to just decay by itself.  No.  But as he noted, I mean, like, I'm sure he did this, and then Windows was saying, "I haven't been authenticated."  He's like, oh, crap.  I do have to give it an Internet connection in order to get Microsoft to bless it.  So if I'm doing that, I might as well update it.  So, yeah.



LEO:  Question 6.



STEVE:  Oh, and...



LEO:  Go ahead.



STEVE:  During one of your away missions, with Father Robert, I noted that my little postage weigh scale system didn't seem to be receiving XP updates, even though I did the cute little "I'm XP Embedded" hack to the registry.  I did want to follow up and say it definitely is.  I turned it on the other day and, oh, look, it's got a bunch of updates to receive.  So it might have just taken a while to get synchronized and caught up or who knows what.



LEO:  Oh, good.



STEVE:  But so that hack is keeping XP updated and has not been shut down yet.  So it's not like XP actually died, for anybody who cares.



LEO:  I think it makes sense that Microsoft, who surely knows about it by now, just says, well, you know, if somebody's going to do that, we won't get in their way.



STEVE:  Yeah.



LEO:  Kirill in State College, PA notes that having nothing to hide is not the point:  As a regular Security Now! listener since 2008, I thank you for what you're doing to enlighten your listeners and viewers.  But lately I cringe every time I hear you or Leo say that it's fine for lots of stuff to be unencrypted because the information in question is not sensitive.  Certainly one purpose of encrypting information is to protect the information from unwanted disclosure, but the other is to maintain privacy as a general principle.  By taking that approach, if it's not sensitive it doesn't need to be hidden, well, then you miss the latter aspect.



If 99% of your communications are in the clear, and suddenly you use Tor or PGP for something, you might as well be waving a big red flag that says "Pay attention to what I'm doing, this is important, and I want to keep it secret."  The point of routinely encrypting everything is to make it impossible for our NSA overlords to distinguish between someone actively trying to preserve his or her privacy, thus potentially singling that person out for closer surveillance, and everyone just going about their routine business.



STEVE:  So this really is the question that I was referring to earlier, where I agree that in general it makes sense for us to be increasing our use of security.  We clearly see that we're moving in that direction with more and more sites implementing HTTPS.  I think that he was responding, though, when he said "Every time I hear you and Leo saying sensitive stuff doesn't have to be encrypted," for example, probably he was referring to our conversation about email.  And that's sort of a special case, only because it is really difficult, unfortunately, to encrypt email.  That's been one of the things we've been talking about here over the last few months with PGP and Gmail and Yahoo's announcements that they're going to start focusing on this more.



It's just that our clients and email itself, unlike web serving, or web surfing and web browsing, there the protocol that Netscape introduced with SSL 1.0, the messiness is completely encapsulated in the connection.  And we do have that with email to some degree.  Unfortunately, it's only the connection that is optionally encrypted, not the envelope that we're mailing in.  So part of our conversation about this that we just had a week or two ago was that, you know, with email, eh, we're probably just going to have to kind of give up on that one and use messaging, or any of the forthcoming communications systems which will have been designed cryptographically strong from the start, and just sort of let email be like, eh, well, fine.  As everyone knows it's in the open, so don't send anything important there.



But I certainly also agree with his notion that every Internet - all the packets on the Internet should look like random nonsense.  You should not be able to put a packet sniffer on the 'Net, which we know PRISM was.  PRISM was the NSA's suck-it-all-in and, you know, do keyword searches and so forth on all this wealth of unencrypted data.  It's easy enough for us to wrap that in encryption that we probably should, not to thwart the NSA because I don't really think we can, but just because, once the technology has been put in place, then we get encryption for free, the way we have it now with using HTTPS.  It's essentially for free.



LEO:  Yeah, I mean, I used to say the same thing, that everybody should use PGP because then no one will stand out when they do use PGP.  A couple of points to make, though.  First, that implies that somehow, if you use PGP, the feds will be able to crack it.  And if it's strong encryption, it doesn't matter whether it stands out or not.  If you trust the encryption, you trust the encryption.



STEVE:  Good point.



LEO:  Certainly enough traffic is encrypted that the feds are still going to have a challenge.  They're not going to have a super quantum computer and have to only focus on one email.  The second issue, well, you raised the issue that the difficulty involved, on everything, even HTTPS server, means that it's not necessarily practicable to encrypt everything.



STEVE:  Right.



LEO:  And we do know, by the way, that the feds decide that anything that uses Tor or PGP is by default suspect and included in their databases.  So, I mean, he has a point there.  But it's not like being in their databases means that suddenly they can read it.  They still have to crack it.



STEVE:  Right, right.



LEO:  So I think it's sufficient to occasionally use it, would be my point.  You don't have to use it a hundred percent of the time.  But if everybody used it a third of the time, see, it's hard for - as you point out, I have to get your key to send you an encrypted thing.  Every email I send out is not going to be encrypted.  It never will be.



STEVE:  Right.



LEO:  Because I'd have to get everybody's keys ahead of time.  But if you encrypt a third of it, I think that's sufficient to bug the feds and to mean that they cannot focus on any particular thing.



STEVE:  Yeah.  For me, for example, my use of encryption is with Jungle Disk to encrypt everything that goes out of here for archival.  So I have offsite archiving.  I will absolutely, I wouldn't consider not encrypting it myself before it goes.  So there's nothing there.  I mean, it's our corporate information.  It's all of the work I do, all my source code and everything.  There's trade secret stuff in there.  It's like SpinRite and everything.  So I absolutely don't want that to fall into someone else's, basically into any one bad guy's hands.  I really wouldn't mind the government having it.  I assume that they wouldn't do anything wrong with it.  It's for pure business-related intellectual property privacy.  That's my use of encryption.



LEO:  I think it's, you're right, it's a flag.  But is it...



STEVE:  And, you know, and our story we talked about last week about the crazy - the guy's name was Jeremy, the agent at Comcast who was basically trying to hold people out as being exceptions for using Tor.  This sort of plays into that, too.  At the moment, someone using Tor does seem more suspicious.



LEO:  Right.



STEVE:  It's like, well, what are they trying to hide?



LEO:  Right.



STEVE:  Sort of it begs the question.



LEO:  Yeah.  And Faiz's point, well taken, is that if everybody used Tor, then nobody would - but it's just not practicable.



STEVE:  No.



LEO:  So use it as much as you can.  Encrypt as much as you can.



STEVE:  It's really slow.



LEO:  And I have many correspondents who routinely use encryption with me.  And I encrypt back.  And we do that because there's nothing in there, but it's just, well, yeah, it just adds to the noise.



STEVE:  Yeah.  Fill your drives with this, you feds.



LEO:  I think that's sufficient.



STEVE:  Yeah.



LEO:  Everybody should have some sort of S/MIME or PGP encryption installed and use it when you've got somebody's keys, and that's enough.



STEVE:  Yeah.  Well, and right now you and I have encrypted packets moving over the Internet, streaming back and forth with audio and video.  Do we think it is impossible to crack?  No.  But it's certainly not in plaintext, and I assume somewhere there's a hard drive sucking it in in case it's ever useful for something.  It's like, well, knock yourself out.  You can also get it unencrypted on YouTube and on GRC.com and on TWiT.tv.



LEO:  Won't you be surprised when you find that out.



STEVE:  Yeah.  And it has the benefit of having been edited a little bit, too.



LEO:  Yes, it's a little cleaner, yes, absolutely.  Spyros in Upstate New York shares his theory on this HTTPS up-ranking Google's doing:  Over the last few weeks I've listened to your discussion as to why Google might be up-ranking sites that offer secure HTTP, and whether this is a good idea.  The theory I have is Google's attempting to increase the amount of encrypted traffic flowing over the 'Net.  To what end?  Well, with all the fear of being watched, it would seem an abundance of encrypted data would make the snoopers' job harder.  Same point as Faiz.



STEVE:  Yup.



LEO:  It's just a theory, but I hadn't heard it brought up, so I thought I'd mention it.  Keep up the great work.



STEVE:  Yup.  And this plays into the same thing.  I think I actually would argue that, to the degree that Google's ranking algorithm, and I watched you and Jeff and Gina have an interesting talk about this last week, just like, wow, what do you think that algorithm looks like?



LEO:  Yeah.



STEVE:  Probably won't fit on the back of a napkin anymore.



LEO:  No.



STEVE:  So it's a multi - certainly their ranking architecture is very sophisticated.  It's been - the complexity's been increased both to improve the quality and also to thwart abuse because we know that the SEO, there was a big flurry for a while back in the early days where it became, you know, the idea of spoofing the search engine's ranking was a big deal, and people would do things like fill pages that the user couldn't see with keywords that the search engine would see.  And if the search engine wasn't differentiating between what the user could see and not see, that opened them up to abuse.



So my point is that I think as one's additional signal, not heavily weighted, but just an additional signal, sites - and understand we're talking about a mathematical algorithm that is not sentient.  It is a spider sucking in web pages, I mean, an unbelievable number of web pages.  And its goal is to offer users the absolute best links it can.  So it needs to use any signals that it can find from the noise.



I think a useful signal, again, not one or zero, but some fraction of a percent of merit, is whether the site supports HTTPS.  Because, again, in general, although I don't like the notion of noncommercial sites being dinged as a consequence, but sites that use HTTPS, again, when you're a blind spider, that's probably a useful signal.  I do think Google is encouraging the use of security.  We know they are.  We talk about it all the time.  Google is pushing for a secure Internet.  Yay.  But I also think it's useful for search ranking as one of many signals going into the algorithm.



LEO:  That's a good point.  That's a site then that's not a fly-by-night site.  It's not...



STEVE:  Correct.



LEO:  It's a serious site that paid money to get a cert.



STEVE:  Yes.



LEO:  Actually, that's a very good point.  It's more than just security.  It is a good signal.



STEVE:  Yes.



LEO:  By itself.



STEVE:  I think it demonstrates an investment has been made by the people.  They care...



LEO:  We know for instance they use as a signal how long your domain registration is.  If it's a one-year or shorter registration, you're ranked lower than if it's three years.  If it's three years, you're here.  You mean to be here.  You spent more money on it.  It's less likely a spam site.  A certificate would be very similar to that.  So maybe it's - they couched it in security terms, but I think there is actual value in it over and above that.



STEVE:  Yeah.



LEO:  Yeah, you make a good point.  Here, so does Mike in Florida.  He asks a question Steve has never heard before, ha-ha:  When you do a full, not a quick, but a full format of a hard drive, Steve, does it repair the disk?  In other words, if I'm getting disk errors, can I just format it, full format?



STEVE:  And oddly enough, I don't think anyone has ever asked me that.



LEO:  No, you're not being sarcastic.



STEVE:  No, I'm not.



LEO:  Oh.  I thought that would be the first thing people would ask you.



STEVE:  I talked recently about how nobody anymore actually does a format of a drive.



LEO:  No, because drives are too big.  It takes forever.



STEVE:  Yeah.  It just is not practical.  And what it's doing is, when you do a so-called "long format," and that word is now an understatement to the extreme, is in the old days it was going out, I mean, there was no such thing as a quick or a short format.  Format was format.  That's the first thing you would do on your 30MB ST-238 RLL drive that had 23 sectors per track.  I should remember how many cylinders...



LEO:  You know all of this, don't you.  



STEVE:  Yeah.  So...



LEO:  1024, right?  No.



STEVE:  I think it was.  No, actually you could push it to a little further.  I think it was a 1050, actually.  You could go a little further.  There was some unused space at the end that they just sort of left, and you could actually put data out there.  So what it was doing is it was looking at the sector headers.  So it was looking for so-called "bad sectors" that had been factory marked as this sector contains a defect, do not use it.  It would then look - typically sectors that were half a K, they were 512-byte sectors, it would use 4K sectors, so it would use eight of those half a K sectors, those 512-byte sectors, to create a cluster.  So any cluster in the directory, in the file system, that contained even one bad marked sector, the whole cluster would be marked as unallocatable or bad in the file allocation table in the directory.



So that's what that all was.  That process doesn't fix anything unless the sector is repairable, has like an ECC soft error, and reading the sector might cause the drive to say, oh, I didn't realize there was a defect that I need to get sort of thinking about here.  I'm going to spare that out and swap in a good sector.  So it certainly doesn't do data recovery.  It's not a bad thing to do unless you value the length of time you have left to be alive because it's going to take forever to format that thing.  It's really slow.



LEO:  How long does it take for like a 2TB drive?



STEVE:  Oh, days.



LEO:  Days.  What, days?



STEVE:  Days, days.



LEO:  Oh, well then nobody's going to do it.



STEVE:  No.  And...



LEO:  Then the answer is moot because who's got, you know, that's crazy.



STEVE:  And what we've done is we've just gone to an "assume the drive is good," and we'll deal with problems if/as we encounter them.



LEO:  Right.



STEVE:  And nobody was marking those bad, the sectors bad, anyway.  And when we switched to the new IDE drives, which have intelligence in the drive, they're supposed to handle that.  So the drive never has any bad sectors.  If it did, it would have swapped them out for spares.  So that's really the theory under which there are no more bad sectors, is drives are smart now.



LEO:  More questions for you, Steve.  Question 9 from Jeffrey, Allentown, Pennsylvania.  He wants to share his experience with POS, which can mean two things.



STEVE:  Yes.



LEO:  Yeah, and maybe it's the same thing...



STEVE:  And in this context it really means both.



LEO:  It's the same thing, both.  But I have personal experience working for a point-of-sale merchant services company - that's what POS stands for normally.  I can explain why these point-of-sale computers are running unpatched Windows XP Embedded, point-of-sale ready.  My company had issues where our software would break after applying a critical Windows update.  This bug hugely annoyed the merchant because, of course, when the system's down, they can't make any sales.  So for a period the company enforced a policy of not letting any of our POS systems ever run Windows Update.  I think this is true in many businesses for a lot of reasons.



STEVE:  Yup.



LEO:  Windows Update can break things.  And in a mission-critical environment, that's not what you want.  And this is a distressingly common policy, he adds.  I strongly suspect that both Target and Home Depot had set up their OS images not to run updates.  The common belief has been that simply disabling access to IE would be sufficient to keep them safe.



STEVE:  Yeah, I thought that was neat feedback from the field.  Nothing surprising, but of course the Home Depot recent escapade is being regarded as the largest, most critical breach in history.



LEO:  What a mess.



STEVE:  Yeah, it is a huge mess.  And apparently there are ex-employees now, and we have to consider that they're ex, so they're no longer part of the faithful.  But they've been providing information that Home Depot was fully aware of the security problems that their systems had and essentially did nothing.  I would say chose to do nothing, but they didn't chose to do anything.  They didn't choose to do anything, which is passively choosing to do nothing.  But, yeah.  And as you say, Leo, well, this is the reason Microsoft went to the Second Tuesday of the Month.



Remember that once upon a time before this, patches would just come out randomly at just arbitrary times and be like, oh, here's an update, which drove the IT people crazy because they had to do some planning.  What we found is, because patches would occasionally interact with specific software on corporate machines, that these patches were killing things.  And so IT said please, please, please, please, A, give us a schedule and so that we know when things are happening.  We will set time and people, personnel, whatever's required, aside to vet these changes on our specific systems with our vertical applications, whatever it is we're doing to make sure they don't break anything.  And then let us redeploy those within our Intranet.  And of course that's now the model that's being used.



But the problem is these embedded systems, they don't feel like they have a computer in them.  They don't feel like they have Windows XP Embedded.  They feel like, it's like, oh, so it's a keypad and a mag stripe reader.  Well, how can that get in trouble?  Well, we know how.



LEO:  Our last, our very last question comes to us from Kevin in New York.  He wonders about the long-term reliability of solid-state drives based on their error correction, ECC rate:  I have an older model Sandisk, 128GB SSD.  While I've not been too hard on it - 55TB of writes over the course of a little over two years - how would he know that?  Is something keeping track of that?



STEVE:  Boy, I bet.  He has something that's doing that.



LEO:  Yeah.  once in a while I run SpinRite on Level 2, largely to look at the error rate, and I have noticed some issues.  It seems that over the past year the ECC corrected rate has steadily increased from around 7,000 - that's per minute?



STEVE:  It's not clear.  SpinRite has a total, and it also reports a ECC rate in per megabytes.



LEO:  Per megabytes, okay.  Yeah, I've seen that.  This looks like that.



STEVE:  Yeah.



LEO:  Around 7,000 to close to 15,000 and a full erase before restoring data has no impact on the error rate.  The SSD rates itself as having 95% life remaining, so it seems like that may be a bit inaccurate.  Furthermore, with the increasing error rate as the drive is used, it makes me wonder how long this drive will last before data begins to become corrupted.  So what are your thoughts, Steve, on the reliability of solid-state drives where over time, as you use them, the ECC has to work harder?  We should say that ECC means you're not losing data.  But it does mean that there are failures; right?



STEVE:  Yes.  And, okay, so two things.  Or a couple things.  The neatest thing - well, okay.  One of the many neat things that SpinRite does is this note, this idea of capturing the SMART data on the fly, which SpinRite processes to show you the rates at which errors are happening.  Nothing else does this.  And it is such - it's really, it's like it's underused intelligence which happily Kevin is taking advantage of.  The point is that the SMART system doesn't really tell you anything unless it's under load.  But nothing that puts it under load reads the SMART system except SpinRite.  So he's able to say, and he has here, that he has seen an increase in the rate of corrections being required by this SSD.  Now, the fact that he has done a full erase and restore, and the rate didn't drop, that's - and he understands that, and he's right.  I doubt 95% life remaining is right.  I would worry or wonder if it even had 40 or 50%.



LEO:  Huh.



STEVE:  I think this is a very - I think this is a danger sign.  Now, the better thing to do would be to have been monitoring this over time, where it would have been 7,000, 7,000, 7,000, 7,000, 7,000, 15,000.  That is, if you saw - or probably seven, eight, nine, 10, 11, 15.  The point is, if you saw a need in a curve of how much ECC is being required, that would be an indication that, like, something bad has happened.  Or it's now aging at an accelerated pace because it's getting into trouble.  But what the rate means is that, if he hadn't erased it and restored it, that is, hadn't just recently rewritten all of these capacitors - remember that these are little floating capacitors.  They're little tiny bits of conductive silicon which have a crowd of electrons sitting on them.  And they're going to be bleeding out, bleeding off.  That charge is going to bleed at some rate, very low, so that typically you have retention times in a hundred years, or like of a hundred years.  But if there are defects, the leakage can be higher.



And the reason writing is fatiguing is that it's poking holes in the insulation, and the process is called "tunneling," in order to, like, force those electrons through this insulative barrier to strand them out on this little island.  And that process fatigues the insulation and increases the leakage.  Now, if he had only been doing retests and saw the error rate increase, that could indicate that we're seeing bits are leaking that are requiring correction.  Except this is freshly rewritten, and he's seeing a greater error rate.  And that's what scares me.  That's a great test he performed.  And frankly, I don't know in terms of writes, I mean, what is it, it's 120GB SSD upon which he's written 155TB.  So that's not, that's, what, 60 writes of the whole drive?



LEO:  Yeah. 



STEVE:  It's something like that.  So it doesn't seem like many writes.  I agree with him.  But, boy, do keep it backed up.



LEO:  I have to say that, first of all, it's an older drive, as he says.  And I think that the drives are probably getting better.  But also...



STEVE:  Nice hat.



LEO:  Do you notice what it says?  I'll show you the hat in a second.  But also that I just anecdotally do not hear of a more, of a higher failure rate on SSDs.  And I use SSDs all the time.



STEVE:  I agree.  I agree.



LEO:  So that's one drive.  Maybe he's got a bad one.  We don't know.  The question is should we be concerned about longevity in SSDs in general.  And I haven't seen any evidence to suggest that.  But maybe you have.



STEVE:  No, there was - there was a meme that ran through the Internet in the last week, and I didn't pick up on it.  I was busy working, and it kind of got past me.  But it was something about the amount, it was like data being written to SSDs that was fatiguing them.  I'm sure somebody knows about it, probably Simon Zerafa, our buddy who's an amazing fount of tweets.  I'm sure he knows what it was.  And in fact it may have been from him.  He's probably going to put it in my stream after the podcast, and I'll pick up on it and check it out.  And I'll add it to the notes for next week.  Because there was something that went by that was - I thought it was interesting, but I just - I was overloaded at the moment, so I didn't add that to my pile.



LEO:  Right.  Yeah, I mean, I'll just, from my own experience and talking to people, I have not heard about any problems with SSDs.



STEVE:  Yeah.  I agree.  Although...



LEO:  In fact, it may well be they're more reliable than spinning drives in the long run.



STEVE:  The good news is SpinRite recovers them.  So for what it's worth, that's why there's plenty of life left in SpinRite.



LEO:  And he didn't leave one for you, but I thought this was an appropriate hat to wear during the show.  That eagle you might recognize is the emblem of the National Security Agency.



STEVE:  Nice.



LEO:  United States of America, established 1952.  And apparently one of our listeners works for the NSA and dropped it off.  So I'll be wearing this around as I travel around London.  I don't think I'll have too much trouble, you think?



STEVE:  No.  No, I have a hat that I was given by some FBI agents.  And one time I was out riding on the bike paths in Irvine, and some really rude people just, like, almost forced me off the path when I was wearing my regular, actually I think might have been a SpinRite hat or something else.  And I was really - it was really just disrespectful.  They could have easily moved over.  And so I just had this inspiration.  It's like, oh, I'll wear my FBI hat.  And what a change it made.  It's fantastic.  I mean, I look like an agent, all dressed in black.



LEO:  People are - you look like an FBI agent anyway.



STEVE:  I do.  And so this hat, it cinches the deal.  People, I mean, they, like, avert their gaze and move off into - and they're now, they're in the weeds, and I'm in the middle of the...



LEO:  Yeah, they're not going to mess with you.



STEVE:  ...sidewalk.  So it's, yeah, it's very nice.  Solved the problem.



LEO:  Thanks, Mark, for leaving this hat for us.  He's off to run in the Big Sur Marathon, but he thought it'd be fun to leave this behind.  By the way, the eagle is holding a key, a big key.  I wonder what that key unlocks.



STEVE:  So we don't have you next week, and the podcast is Wednesday; right?



LEO:  Yeah.  So here's, yeah, this is the time to talk about all of this.  I'm going to London on Sunday.  I'll be back pretty quickly, the following Sunday, so I'm not going to miss any TWiTs.  But I will miss one Security Now!, and Father Robert's...



STEVE:  And you're wishing that you had made a longer reservation in London.



LEO:  I do.  I absolutely do.  But duty calls.



STEVE:  So it's vacation; right?



LEO:  Yeah, it's a six-day vacation, basically.



STEVE:  Very nice, very nice.



LEO:  Robert will be here.  He does a great job.  So I appreciate that.  And, yes, you're going to be at a different time because Microsoft - I can't, it's hard to - time is rushing by.  When we started this show, the current version of Windows was Windows XP.  It is Windows 9, the next version of Windows.



STEVE:  And I of course, I think I was no longer using NT, but I was probably using Windows 2000.



LEO:  2000, you were using Windows 2000, yeah.  So the next version of Windows.  Microsoft is going to reveal technical information on September 30th.  That's normally our day.  So what's going to happen is Paul and Mary Jo are going to be at that briefing, a small private briefing.  But they're going to come right up afterwards and do a special Windows Weekly at this time.



STEVE:  In this time slot.



LEO:  In this time slot, 1:00 p.m. Pacific, 4:00 p.m. Eastern time on Tuesday.  And so that will be Windows Weekly.  So we're going to put you in Windows Weekly's time slot the following Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 1800 UTC.



STEVE:  Ah, okay.  So it's not - I was told it was my old time slot.  Oh, yeah, no, it is.



LEO:  Yeah.



STEVE:  At 11:00 o'clock on Wednesday.  So we move me up to 11:00, but we drop me back to Wednesday.  Okay.



LEO:  Wednesday at 11:00.  That's all you have to remember, Steve.



STEVE:  Okay.



LEO:  Robert will be here; right?  Yeah, Robert will be here.  And then we'll be back to our normal schedule, and I will be back with many tales to tell of my adventures as a National Security Agency representative in Jolly Olde England.  That'll be interesting.



Steve Gibson is at GRC.com.  That's where you'll find, not only 16Kb podcast versions of this show, but also fully human transcribed, thank you Elaine Farris, transcriptions of the show.  You'll also find SpinRite, the world's best hard drive maintenance and recovery utility, and all the great freebies that Steve gives away all the time.  It's also a place to go for questions:  GRC.com/feedback, specifically.  That's where you should leave your questions for future feedback episodes.



We have full-bandwidth audio and video versions of the show at our website, TWiT.tv/sn for Security Now!.  It's also on YouTube.com/securitynow.  It's also wherever you get podcasts.  In fact, subscribe.  You're going to want the complete set.  We have not yet put out the leather-bound edition, so you'll have to make your own.  But you do that by getting every episode every week of Security Now!.  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, my friend.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#475

DATE:		October 1, 2014

TITLE:		Shocked by the Shell

SPEAKERS:	Steve Gibson & Father Robert Ballecer

SOURCE FILE:	http://media.GRC.com/sn/SN-475.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After covering a very busy and interesting past week of security and privacy news, Father Robert and Steve explain, examine, and dig down deep into the many fascinating details of the worst-ever, two-decade old, latent and pervasive Internet bug known as "Shellshock."



SHOW TEASE:  Apple lies about preventing spying, the FBI whines about us stopping spying, and Kevin Mitnick sells tools for spying.  Also BASH leaves us crying in our beer.  Security Now! is next.



FATHER ROBERT BALLECER:  This is Security Now!, Episode 475, recorded October 1st, 2014:  Shocked by the Shell.



It's time for Security Now!, the show that covers your privacy and security online.  I'm Father Robert Ballecer, the Digital Jesuit, in for Leo Laporte, who's currently roaming through Europe.  Here with me is the purveyor of truth, knowledge, and justice online, it's Mr. Steve Gibson.  Steve.  It's good to see you again, my friend.



STEVE GIBSON:  Hey, Padre.  It's great to be with you again.  We've been anticipating this for some length of time, ever since Leo said that he was taking what he now regards as a too-brief vacation.  He wishes, now that he was doing it, that he was going to be there longer.  I've been hearing him grumble about it, you know, "I'm going to be here for TWiT on Sunday and then back for TWiT on the following Sunday."  So he's missing no TWiTs.  He has been prerecording his Tech Guy show on the weekends in order to be able to have that happen.



Yeah, so you and I get to do this today.  And it's like an amazing opportunity.  I did send Leo email, I guess like the middle of last week to apprise him of something that we'll be talking about at the top of the show, which is the result of Mozilla briefly switching their Mozilla.org certs to SHA-256 and then realizing the error of their ways and switching back.  And so in the show there's a lot of week-to-week continuity.  And so I realize that Leo is going to miss a lot of the conversation that is happening this week.  And when that's happened before, I've found myself saying, "Oh, wait, yeah, you don't know about that."  And so I was a little preemptive this time.



So we couldn't have a more fun topic because I started getting tweets Wednesday of last week when the news of Shellshock broke, people saying, wait, you just did Security Now!.  We need another one right now.  And I said, eh.  You know, and actually it's been good that it's been a week because there's really been nothing individuals had to do.  Largely this was a function, it had the greatest impact against Internet-connected servers of various sorts.  And it's taken a week for sort of things to settle down and for us to know better where we stand.  So I think the timing is probably just about right.



FR. ROBERT:  I actually think it's perfect because one of the things that we see every time a new vulnerability comes up is every network is jumping in to be the first to try to explain it, to try to explain how bad it is.  It's really been kind of jumbled this last week.  It's not even a week since the exploit was first released to the world, and so many people have gotten it wrong.  There have been many patches that have failed because they don't quite understand the scope of the problem.  And so now that we've had a couple of days to look back, I think it's easier to look at it and say, okay, so this is the issue, not this.  This is the issue, not that.  And thankfully we have you.  So, I mean, I'm actually glad that this didn't break on Tuesday because, if it was Tuesday, it would have been a rush job, and then we would have had to correct errata.



STEVE:  Well, and it is a tricky technical problem.  There was one person's communication posited that maybe this wasn't actually a bug.  And they demonstrated some useful application of processing a command after the function.  And we'll rewind this and start at the beginning here in a second.



But the point, but what I was put in mind of was something very controversial from the early days of this podcast, the so-called Windows Metafile bug, where in looking at the code that was in Windows at the time, it looked to me to be deliberate.  That is, not that it was a bug, but that at the time, back in a day before there were bad guys - and there actually was such a day, and I think that's where this same BASH problem originated, or some of the practices that ended up being able to exploit this characteristic of the BASH shell.



Back in those days, what Microsoft did with the Windows metafile was they had, basically, they had an interpreter which would interpret the contents of the metafile.  But there was one command that said jump into the metafile, meaning take it out of interpretation and into native code execution.  And I could easily see, like, the original designer of the Windows metafile, saying, you know, it might be handy if we weren't stuck just using the interpreter, if a metafile could also contain native code.



Now, again, not something you would ever do in this day and age.  But back in the Windows NT days, or even earlier than that when the original metafile format was put together, it wasn't that unreasonable.  And we sort of had that same thing happening with Shellshock where now when we look at it, everyone's just, [gasp] oh, my god.  But it's really, it sort of harkens from a time when it wasn't that crazy to do what is now common practice.  And now we look at it, though, with our contemporary understanding of the way exploits are being found and how what used to be innocent is now considered a horrible vulnerability, it's like, oh, yeah, that's really not so good.



FR. ROBERT:  Well, I mean, when you consider the fact that the Bourne-Again Shell was released back in 1989, so, I mean, we're talking about a utility that was created over two decades ago.



STEVE:  Before bad guys.



FR. ROBERT:  Before bad guys.  And before we really had a concept of what the Internet would be, that you would have your server facing the rest of the world.  That wasn't even in the programmer's mind.  And so it makes perfect sense that they would try to make BASH as functional as possible.  And I think, I'm right with you, I don't think this is a bug.  I think this was something that someone included in the original implementation of BASH as something that if, you know what, if we were connected to networks that we didn't trust, it would be very useful.



STEVE:  Yup.



FR. ROBERT:  And unfortunately we've continued using the same tool, and it has vulnerabilities.  I mean, can you imagine if we were still using Microsoft DOS from 1989 as our primary way to communicate with the outside world?  You wouldn't do it.  And there would be people crying foul, saying, oh, there are so many bugs, so many exploits, so many ways for someone to destroy your system.  And it's, well, yeah, of course, because that's not what it was made for.



STEVE:  Right, right.



FR. ROBERT:  So but the question now becomes, even if this is not a bug, even if this is intentional, why are we still using it?



STEVE:  Well, let's talk about that.  We've got some news to cover, also.  We'll talk briefly about Apple's OS X update, which they put up yesterday, but not with a great deal of emergency.  Also some news has come to light about the iOS 8 MAC address randomization that turns out to be almost next to worthless.  We were excited about it when we heard about it.  It seemed like a cool thing that they had done to iOS 8.  Turns out it's, eh, they've really overblown what they're doing.



Also I wanted to chat with you a little bit about what's been in the news this week relative to the head of the FBI complaining now about the fact that corporations have adjusted, as we knew they would, we talked about this a year ago, the Snowden revelations and the sense we've had that there's been some stretching of the U.S. Constitution.  I do want to talk about Mozilla's experience with SHA-256.  And a friend of ours, I don't know if you ever had the chance to meet Kevin Mitnick, but Leo and I both know him pretty well.  And it turns out he's opened what he calls the Absolute Zero-Day Exploit Exchange, so buying and selling zero-day exploits.  So we've got that to cover, and then we're going to do lots of deep - a deep dive into Shellshock.



FR. ROBERT:  So in other news, no real news this week, then.



STEVE:  Yeah, it was a sleepy week.



FR. ROBERT:  Any of those stories - iOS 8, Mitnick opening up the Zero-Day Corner Store, or Shellshock - could be the main story any other week.  The fact that we've got them all in the same week, something's weird happening, Steve.  I don't know what's going on.



STEVE:  Perfect time to have you.



FR. ROBERT:  Perfect storm.  Where do you want to start?



STEVE:  Well, at the top of the notes.  I always try to put a picture now in the show notes because I post them online.  I tweet the URL, although it never changes except the number increments.  But someone sent me this, I think it was yesterday, and I just loved it.  It's a picture of an airport security door keypad.  And the trick is, can we guess the number?  And I just love this because, for those who can't see, it's a three-by-four keypad, the number-style pad with a star and a, I don't know what that is in the lower right.  Normally it's a pound sign.  But the point is that it teaches us a lesson about the nature of security because, on the first day this was installed, it looked perfect.



Now there are only four buttons that almost have the paint rubbed off of them.  And we know why.  We know it's because those are the ones that are being pushed.  And they happen to be 3, 4, 5, and 6.  So not only do we know absolutely which buttons contain the code, but I'd even wager that this door opens with 3456 because, again, yeah, you know, in the beginning I'm sure it, you know, no one would be able to guess that it would be 3456.  They want to make it easy to remember, and so not some random combination of numbers.  And when the pad was first installed, you'd have no clue.  Now you look at this, and clearly the 3, the 4, the 5, and the 6 are the most often-pressed buttons there is.  Or there are.  So it's clearly what the code is.  Anyway, I just got a kick out of that.



FR. ROBERT:  Although you could combine that picture with a little bit of wear analysis.  JammerB, if you go back to the picture, I remember someone was trying to tell me, similar to this, if you look at the way the doorjamb is shaped, someone would probably be opening it with their right hand, which means they're probably going to rest against the side of the keypad.  Looking at where the wear is actually happening on the keys, so on the lower right-hand corner of the four, on the lower left-hand corner of the six, and top of the five, and then dead center on the three, it could be 4563 because that's where your fingers would naturally go if you were resting your hand on the side of the...



STEVE:  Yeah?



FR. ROBERT:  ...of the jamb.



STEVE:  Good point.  Good point.



FR. ROBERT:  But, yeah, I mean, the fact that you can, I mean, even if you had to do complete guesses, you go from a 12-key keypad to a four-key keypad.



STEVE:  Yes.



FR. ROBERT:  It's just now I have to look through airports to see how many of those doors look like that.



STEVE:  Anyway, I loved it because it's just a classic failure of security, something that starts out seeming like a good idea.  You know, sort of like a fence that just sort of decays and falls apart.  And it's like, even the cows are looking at it, thinking, you know, if I really wanted to go anywhere, this fence would no longer keep me in.



FR. ROBERT:  But fences only keep honest people honest; right?  So keypads aren't really going to keep you out if you really want to get in there.



STEVE:  And lazy cows in.



FR. ROBERT:  And lazy cows in.



STEVE:  Okay.  So support.apple.com/downloads will take all of our Mac listeners to Apple's current support page.  And the first item in the upper left at the time of this recording, support.apple.com/downloads, is Apple's apparently optional offer to patch OS X, OS 10, sorry, for the Shellshock bug.  So I wanted to put that at the top of the show.  This requires no reboot.  It's a tiny download.  It's like 3.5MB or something.  So it is easy to get.  You install it the way you install any Mac app.  It just says, okay, I'm going.  You have to give it your password, of course.  And then it fixes itself, and it says, "I'm done."  So it's not a crucial emergency because it's not going to be an exposure that most Mac users have.



But now, essentially, one way to look at this, and we'll come back around to this for the main topic of the show during our second half.  But a way to look at the whole thing is that there is now, probably somewhere in every UNIX system, a component that could be invoked in a way that could give the invoker more control over the system than its owner wants.  So that component should be removed.  It's just not good to have it there.  It's the sort of thing where you don't want to set up intrusion detection systems on your front lines to hopefully block any incoming known exploit because this thing is going to be with us for a long time.



And it is, already it is - there's just been a flood of Internet traffic, you know, trying to exploit this across the entire Internet.  There have been white hat hackers who've been scanning for it in order to get some sense for it.  But a flood of exploits against random IP addresses.  Everybody is picking this up who is looking at their incoming traffic.  So sooner or later, I imagine maybe with the next major update, Apple will include this, just fixing this.  But for our listeners who are more security conscious, because it's small, quick, easy to do, requires no reboot, when you've got OS X running, just go to support.apple.com/downloads and fix this.  Remove this problem from the systems that you're responsible for.



Again, not probably an emergency.  It doesn't look like the typically configured Mac has a vulnerability.  The only way I was ever concerned was there were some reports, and they were confirmed, of a malicious DHCP server being able to use the DHCP client in a Mac to invoke the shell and cause a problem.  And so that would have affected people.  And DHCP is the Dynamic Host Configuration Protocol.  It's the thing that the system uses when it comes up or when the network connects to obtain an IP address from the network.  And again, the nature of the way some of these have been implemented did invoke the shell.  And so if you were on a malicious network, that is, a network with a malicious DHCP server, which sort of hasn't been a problem in the past because DHCP wasn't vulnerable, again, this is a perfect example of the many different subtle ways that this could still get you in the future.  So it's worth removing it.



FR. ROBERT:  I actually read a report from Incapsula.  They've been a guest on one of my other shows, This Week in Enterprise Tech.  And they were saying how just on the domains that they protect, so that's about, what, 4,115 domains, they've seen since the attack, and this was up to Monday, since the attack was released, about 217,000 attempts to exploit BASH.  And their guestimation is that there's probably been about a billion attempts so far.  I believe they're going to come on this Friday on a special edition of TWiET to show us what a stream of BASH exploit attempts actually looks like.  That actually should be some pretty decent TV.



STEVE:  Cool.  I have that also at the end of our notes, in today's show notes, is from FireEye.  They did an analysis.  And I grabbed samples of the strings that they're seeing.  And we'll be talking about that here in about an hour.



So we were excited when we learned that MAC addresses were going to be randomized by iOS 8 devices when they were not connected to a WiFi network.  Which seemed like a fabulous idea.  Before iOS 8, your phone or your pads that have WiFi turned on, and as you're roaming around, you're in stores and malls and so forth, it's always scanning, probing for networks that it may know.  And traditionally it's been giving out its MAC address.  And the MAC address is supposed to be a globally unique, 48-bit identifier, globally unique because it has to be unique on a single Ethernet network.  And since you never know which devices may also be on the network with you, and it has to be unique or you'll have a MAC address collision, and those of us who've ever played with Ethernet networks extensively know that that's not a good thing to have, so they make them all unique.



Well, what this meant was that, essentially, you were a beacon as you walked among stores and in malls and movie theaters and so forth, basically broadcasting a token that represented you.  So the idea that Apple was going to respond to this and make them random until you actually connected, first of all, that's a very clever hack.  So the moment you hear about it it's like, hey, that's very nice.  Turns out, no.  Based on some analysis performed by Nick Arnott at iMore.com, who took a much closer look at iOS 8's MAC randomization, it is almost never active.  That is, only when the phone is in a deep sleep state for whatever reason is this in effect.  And it's like when the phone awakens out of deep sleep, even with the screen still dark, to receive push email.  Then it's not randomizing the MAC.  Anytime anything rouses it in any way, it returns to its fixed MAC.



Now, I don't know why because the hack that they originally described seems entirely feasible.  So I hope they get some pressure to, like, make this better.  Maybe they couldn't do it for architectural reasons.  Maybe there was a glitch.  Maybe they were - someone was lazy, and they didn't care enough to do it as well as they could have.  I haven't looked at it closely enough to understand why.



So my upset, I mean, it's like, [frustrated sound].  My upset is that they told us something which is not true.  And that's the one thing I don't want.  It's like, it's fine if you're going to offer something that's weak, but better than nothing.  But don't advertise it as your MAC address is always random until you're connected.  That's not factually true.  And Apple's on this big campaign now about them not collecting data at all.  And exactly, there's the page.  And privacy is built in, and rah rah.  And if you scroll that page down, I think to the second to the last item on the page, you'll see their statement.



They said:  "When you're out running errands with your phone in your pocket, WiFi hotspots have the ability to track your movements and behavior by scanning your WiFi MAC address.  A MAC address is a string of characters that uniquely identifies your device on a network.  With iOS 8, we've introduced an innovative feature designed to protect your privacy by randomizing your device's MAC address when the device is passively scanning for WiFi networks."  Not true.  "Because your MAC address now changes when you're not connected to a network" - not always true - "it can't be used to persistently track you."  Not true.  "This is in line with Apple's industry-leading effort to do away with persistent identifiers and is unique to iOS devices." 



So my problem is that's a lie.  That's a complete mischaracterization of a feature that they're touting.  So they've got to fix this.  Either tell us the truth, or make it true.  It would be great if they could make it true.  Again, I'm only annoyed that, based on Nick's reporting, this is almost never true.  It's, I mean, you could make it true, but you might as well just turn off WiFi.  I mean, because our phones and devices are always coming out of a deep slumber to look around and see what's going on, to receive push connections, to receive text messages, to do everything that they're doing while they're operating in the background.  All of those events drop this out of MAC address randomization.



So maybe there's an architectural limitation.  If so, they should have just kept quiet because it's useless the way it is now.  And I'm, obviously, you can tell, I'm really annoyed because, like, just don't lie.  Lying is not what you want to do if you want to convince us that, for example, you can't listen in on our iMessage sessions.  You've said that, too.  And I don't believe that.  So...



FR. ROBERT:  You know, the only time that this would actually work is if your smartphone wasn't acting like a smartphone.  I mean, the whole idea behind carrying your phone with you is that it's going to be able to notify you when something important is happening.  You're getting an email.  You're getting an iMessage.  Well, any of those events is automatically going to put the phone in a mode where this isn't going to be applicable.



STEVE:  Right.



FR. ROBERT:  Even then, what it sounds like to me is, when I heard about this, I thought, oh, cool feature.  Actually, I'd really like to see that.  I thought Apple got it right.  But this sounds as if this was just a PR thing.  Some PR person was talking to an engineer, saying, well, what are some of the new features that you're working on?  And they heard "privacy," they said, great, we'll sell that.  And the problem with doing this, and yes, you've said this much more passionately than I have, is that if you try to sell people on security features that turn out not to be security features, then the security features you actually have, I have no reason to trust you that they actually work.



STEVE:  Exactly.  Exactly.  And so, I mean, they've sold something that they've said, basically, you can no longer be tracked with your MAC address.  That's not true.  That is, they have said you cannot be tracked until you connect to a network.  Not true.  Period.  Now, it's also been noted that what the MAC is doing is also transmitting a bunch of SSIDs, that is, there's a fixed list of SSIDs that it's got in its beacon.  And that's not subject to change, even when the MAC address is randomized.  So there's still persistent sticky stuff which can be used, but not globally the way the device's MAC address can be.  I mean, that really, the MAC address is a nasty global tracking item.  And we were led to believe they had fixed that.  They didn't fix it, and they told us they did.



FR. ROBERT:  Right.  And I think that's the biggest problem.  Because people should turn it off.  If you really don't want to be tracked, your phone can't be emanating anything.  I'm not just talking about the MAC address.



STEVE:  That's a very good point.



FR. ROBERT:  You've got to put it into airplane mode.  Everything shuts off.



STEVE:  Yes.  Cell tower connectivity gives you, I mean, in all the movies now, that's how they're localizing people is checking their cell towers, which ones they're connected to.



FR. ROBERT:  [Sighing]



STEVE:  Yeah, really.



FR. ROBERT:  When you start sacrificing the integrity of your security solutions in order to make some PR hay, I worry.  And this is not just Apple.  I'm sure Google's doing the same thing.  Google has been also doing this big push on, well, our new phones, they can't be tracked, and they're NSA-proof.  Anytime I hear PR slogans like that, I just - I think either your engineers aren't being honest with you, or your PR people are lying.  It's one of the two.



STEVE:  Well, yeah.  And in fact this comes back to the famous comments about iMessage.  Tim made them on what's his name's show on PBS.  I can't think of the talk show host.



FR. ROBERT:  Charlie Rose?



STEVE:  Yes, on Charlie Rose.  He made a big point of saying we cannot intercept iMessages.  Except we know that they manage the keys.  That is, when we send a message out, they provide the other party's public key, which we use to encrypt messages for the party.  So it's true that they cannot decrypt those messages.  But since the key management is transparent, nothing prevents them from putting another public key into the key bag for themselves, in which case they will be able to decrypt the message.  So saying that they don't have the keys is different from saying we're unable to give you a key which we could use.  They clearly have the ability.  So again, it's like, well, yeah.



FR. ROBERT:  Yeah.  A smart person once convinced me that the only way to have true privacy is if you own all the keys.  Nobody else has a copy to anything else.  And if you lose them, they're gone.  If Apple is saying, well, we back up your iMessages in case you have to recover them, it almost implies, "and there's a way to recover your password," and therefore that means there's a way to recover your key.  Ergo, it's not secure.  Ergo, if they get a warrant, and the NSA really wants to look at your iMessages, they're going to be able to.  Again, just, you know, be honest with us.  Tell us that this is secure as long as we don't get a warrant from the NSA, someone tapping us on the shoulder saying, "This is a legal warrant.  You need to turn over your data."



STEVE:  Yeah, or that your MAC address is randomized is long as your phone is off.



FR. ROBERT:  Right, right.  Although the people in the chatroom, they're good.  They recalled that case.  Do you remember - this might actually have been before the iPhone was released.  There was an FBI operation where they were able to listen in on some Mafia folk in New York, even though a BlackBerry was off, because they were able to turn the BlackBerry back on without it looking like it was on, and they were able to listen in to the microphone.  And so now that's conspiracy theory.  It's wait a minute.  So unless I can take the battery out of my phone...



STEVE:  Exactly.



FR. ROBERT:  ...I can't ever assume that it's off.



STEVE:  And, gee, none of these Apple devices have removable batteries.



FR. ROBERT:  Although I hear that if you bend the 6 Plus, it no longer - it can't listen in anymore.  So maybe that's actually a security feature they couldn't tell you about.



STEVE:  Okay.  So we have to talk about, because this made a bunch of news this week, and I know you'll enjoy talking about it with me, that James Comey explained that he was "very concerned" about new Apple and Google privacy features.  He said that he was concerned that the two companies are, quote, "marketing something expressly to allow people to place themselves above the law."  And I heard in the news podcast just before this one, they were talking about this, and noting, I mean, basically that this was a reaction which we predicted a year ago in the wake of the Snowden revelations, I guess almost a year ago, that we have the technology to absolutely lock this stuff down.  And it'll take a while for it to get deployed.  But once it has, it's game over for the intelligence agencies.  This is not an insolvable problem if we choose to solve the problem.



And the argument is, as we've been covering all the Snowden stuff, these companies were begging to be allowed to disclose what they'd been compelled to do because, without being able to do that, consumers were fearing the worst.  And they were not allowed even to tell the truth, even to, like, say, give a number of requests that they had honored and so forth, as if a number was actually a national security issue.  I mean, basically the federal government has, I think by any measure, pushed their position way too far.  And so now they're complaining when the technology companies have reacted, giving their customers what their customers want.  And which unfortunately for law enforcement is all too readily possible.



FR. ROBERT:  I'm going to play minor devil's advocate here.



STEVE:  Okay, good.



FR. ROBERT:  I don't believe [indiscernible].  I believe in privacy.  I believe that you own your data.  I believe that, if you take the steps and are willing to put the resources into locking down your information, then it should be locked down.



Take a step back, and let's go before the Snowden revelations.  You could honestly argue in a forum, without some major lash-out, that the government had the right in extreme cases to be able to read communications, with a warrant.  I think most of us would have actually said, okay, yeah, that makes sense.  In fact, he mentions it when he's testifying.  He's saying, look, there should never be a closet that's locked completely from us.  If we need it in order to recover, say, a kidnap victim or stop a terrorist activity, then most people would say yeah.



The problem is, and you pointed this out, is the government has so far overstepped that we're no longer willing to even give them that little leeway.  We're saying, look, we were willing to give you the extreme circumstances clause.  But you treated it as if everything was an extreme circumstance.



STEVE:  Yes.



FR. ROBERT:  So again, it kind of harkens back to the Apple situation.  Why would I trust you?  Why would I believe you?  If you're going to cry wolf every single time and then tell me it's for my own good, I'm just going to stop trusting you.  I'm going to lock everything away.



STEVE:  Well, yes.  And I completely agree.  If there was a facility which under a warrant allowed this, I mean, that's the way our system has functioned, like from its founding.  And it's the issue of the judge and the warrant, which has been explicitly bypassed.  All of this, well, that's why it's called "warrantless wiretapping."  And the argument is like, well, tap it now because we need the information now, we don't have time to get a warrant, and similar things.  I mean, we've been hearing about basically these constitutional protections just being ignored.  I mean, and the fact, for example, that simply by calling someone a terrorist, they can be locked up without - and all of their civil rights suspended.



I mean, again, I understand the law enforcement argument for the instance that you can create that demonstrates the necessity.  But now the country is subjecting its entire population to that argument, en masse.  And that wasn't the way the system was designed.  And of course the problem is, and in fact there was a story that I ran across, and I don't have it in my notes today, it just flew by like two days ago, saying that the Chinese government was found leveraging and abusing some ability that Google had to decrypt or monitor its networks somewhere.  And so this was a demonstrated example of what is the concern.  And that is, if there's a backdoor, it won't only be opened under warrant by law enforcement.  It's inherently able to be opened by others.  And, you know, that's a concern, too.



FR. ROBERT:  And that's the plot of every hacking movie ever, that we always put in backdoors when we program a system.



STEVE:  Right.



FR. ROBERT:  Let me ask you this.  If we were to move to a perfect security system in which everyone had their own keys, and they were locked into their own devices, and the government couldn't access them in a technologically feasible way, you could say, and you'd be protected under your Fifth Amendment rights, "I don't remember my password."  They can't persecute you and prosecute you if you say you don't remember your password.  But if you, say, locked down all your devices with your fingerprint...



STEVE:  Yup.



FR. ROBERT:  ...they could compel you to touch the fingerprint reader.  Yes?



STEVE:  Yeah.



FR. ROBERT:  And that's perfectly within the law.



STEVE:  Yes.  And in the recent court cases that we've seen, it's been, if it's something you know, you cannot be compelled.  That's considered testimony against your own interests.  And as you said, the Fifth Amendment of the Constitution protects us from divulging that.  But if it is something physical, a physical key or a fingerprint, then you can be compelled to supply that.



FR. ROBERT:  The first time I heard about this, do you remember those little sensors that were available for PCs, the U.are.U sensors?



STEVE:  Yes.



FR. ROBERT:  It was the first time you had a low-cost, relatively accurate sensor that you could plug in via USB and get encryption for pretty much everything.  I was really big into that until we had a Jesuit who was a lawyer in the community, and he said, you know, that actually wouldn't protect you from search and seizure.  That's a physical item.  They could compel you to put your finger on that reader.  If you're actually concerned about having your information snooped on by law enforcement agencies, that's not the best way to do it.



STEVE:  Yeah.



FR. ROBERT:  And surprise, you know, 15 years later it's actually still relevant.



STEVE:  Okay.  So this was really interesting.  We talked a couple weeks ago about what I consider to be Google's heavy-handed mistake in announcing that, starting next month, this is October 1st, so in November, they're going to accelerate the deprecation of what they consider to be unsafe security certificates, web server identity certificates signed by SHA-1.  They're saying that the SHA-1 signature is no longer strong enough to protect us.  And Microsoft has already said they're going to stop honoring them starting in 2017.  That's the hard deadline that the industry has accepted.  We received that information from Microsoft back in November of 2013, so almost a year ago.  And nobody complained.  That gave us all of '14, '15, and '16, three years, to know that SHA-1 would be no longer supported by Microsoft, that Microsoft is a large enough presence that that effectively means no one else can use them, effectively.



So Google decided to just be preemptive, to march this way forward, starting next month.  And in a series of releases of Chrome, starting with 39, then 40, then 41, they're going to incrementally alarm their Chrome users about the certificates that sites are using now, that have certificates signed using the SHA-1 hash, even though they are signing all of their properties, all of the Google servers are now signed with SHA-1.  They're not changing that.  There's no indication that they are.  And in fact now we know you can't really.



I loved this little bit that I saw on Mozilla.org under Bugzilla.  Two guys in a dialogue, chatting about Mozilla's attempt to switch their servers over to SHA-256 today.  Someone named Jake Maul first posted:  "SHA-2 certs on www.mozilla.org cost us around 145,000 Firefox downloads per week."  Chris - I have a typo in my notes, it's Chris More - said:  "Yes, please don't change SSL certs on www.mozilla.org without checking with #www or #webprod" - I guess two people that are known - "as we killed one million downloads recently by switching to SHA-2.  A lot of the world is still running old browsers and come to our website to get Firefox."  Jake replies:  "Let's re-issue the cert for www.mozilla.org as SHA-1, expiring 2015-12-31.  That gives us the maximum amount of time to support old users without breaking Chrome or IE.  At that time, we may just have to start trying to detect WinXP users (ideally just pre-SP3, but that seems like it would be hard to detect) and force them to a non-SSL connection."



And he writes:  "Sucks, but better than giving them an error and making it impossible for them to download Firefox.  Firefox is a great fix for them because it ships with its own SSL stack and thus avoids the underlying OS limitation."  And Chris finishes, saying:  "Let's keep SHA-1 on www.mozilla.org until we find a better solution.  Switching to SHA-2 will kill 5% of our downloads, and that has a direct impact on ongoing Firefox usage unless we have a better solution to deal with legacy browsers.  Let's start the discussion now in a separate bug on how to handle legacy browsers before December 2015."  And in fact...



FR. ROBERT:  But Steve, wait a minute.  I mean, I understand why they want to do this.  This was a bit of a panic on their part.  But doesn't this just push the problem down the road?  I mean, aren't we going to run into this in December 2015 again?  Because as far as handling the problem, it's basically you have to upgrade your browser.



STEVE:  Okay.  So XP pre-Service Pack 3 has no knowledge of SHA-256.  So, and it turns out, believe it or not, I mean, these are the users, apparently, 5% of the people visiting Mozilla.org have a pre-Service Pack 3 version of Windows XP.  Windows XP and Chrome on Windows and IE on Windows all use the OS native cryptographic stack.  So IE and Chrome on Windows pre-Service Pack 3 cannot connect to any web server signed with SHA-256.



FR. ROBERT:  Right.  Which is why Firefox is perfect for them, because it has its own stack.  But...



STEVE:  Precisely.



FR. ROBERT:  I mean, if you look at Windows usage numbers, especially for XP, they're not going down nearly as fast as we thought they might.  Even though it's been deprecated, it's end of life, Windows XP is still running strong.



STEVE:  Right.



FR. ROBERT:  So it gets me back to that point, which is, well, at the end of 2015, the people who are using XP now are probably still going to be using XP.  If they haven't switched, it means they're not interested in switching.



STEVE:  Right.



FR. ROBERT:  So you're going to run into this again; right?



STEVE:  That's - yes.  But it's more than two years from now.  We have all of, I mean, it's plenty of time.  So, I mean, even the other certificate authorities, or actually all the certificate authorities, were really upset.  The CloudFlare people were really upset because this meant that they had to do a mass rekeying with very little notice.  The argument was, look, basically Google just dropped the bomb and said, everybody must change, or we're going to start penalizing sites that don't.



Now what we see is sites themselves will be penalized because the world isn't ready to change.  And so my position is, yes, it is only kicking the can down the road, but it's another two years of sites experimenting like this and beginning to come up with solutions to push people up to SHA-256.  Especially when Google themselves are not switching.  They can't switch because they don't want the lack of connectivity that the Mozilla experiment demonstrates you get today.



FR. ROBERT:  Yeah.  So it's a kick down the road, but it's a really long kick.  And maybe in two years all those XP machines will die.



STEVE:  Well, I guess my feeling is I won't feel the sympathy for them in two years that I do today.  They will, if nothing else, have had plenty of notice.  This just isn't sufficient notice.



FR. ROBERT:  Right, right.  I can see that.  I can see that.  So it's all about timing.  I mean, you could just wait for this problem to organically go away, rather than forcing a major change that's going to have a great impact on the people who are actually supporting your solution.



STEVE:  Yeah.  And, I mean, and I can see Chrome being proactive, maybe during 2016.  For example, we've already established a hard deadline, thanks to Microsoft, at the beginning of 2017.  So it would be beautiful during 2016, for the year leading up to that, for Chrome to start warning people and thus warning the sites through their visitors that this is looming.  But Chrome is doing that in 2014.  They're doing it this year.  They're doing it next month, they're starting this.  



FR. ROBERT:  They're overachievers.



STEVE:  Yeah.



FR. ROBERT:  Steve.  Kevin Mitnick.



STEVE:  Yeah.  I guess the world considers him, or at least in the past, one of the most notorious hackers.  He was jailed, I think, for about four and a half years.  He spent many months in solitary confinement.  There were a lot of people who were upset with the way Kevin was treated.  There was like an industry of Free Kevin T-shirts and mugs and things.  And Leo and I both know him.  We've met him.  He's really a nice guy.  I mean, he's like - he's really a nice guy.  And so I don't quite understand what's happened here.  I guess it might just be that he wants to make some money.  But he announced that he is going to start selling zero-day exploits to, quote, "discerning government and corporate buyers."



These will sell for no less than $100,000 each.  And although Kevin's company, MitnickSecurity.com, employs its own hackers, apparently to dredge up some of these, mostly he's serving as an exchange, a zero-day exploit reseller, purchasing exploits from those who discover them, and reselling them to his customers.  I don't know.  I'm just sort of at a loss.  It just seems, you know, he was regarded as - I think he was wrongfully regarded as a black hat.  Then he sort of was wearing a white hat for a long time.  And I'm afraid now it's sort of gone to dark gray because, I don't know, this seems to sort of endorse the notion of zero-day exploits.  I mean, it gives entities a means of acquiring them.



There are different things you can do.  You can sign up to be on a notification list so that, I guess, if you were Microsoft, and they acquire a zero-day exploit for Windows, Microsoft will have some notification means.  The problem is that that dramatically reduces its resale value.  So it's against Mitnick Security's interest to notify Microsoft because then Microsoft can patch it.  And the only reason to buy a zero-day exploit is either to preemptively patch a problem - and a $100,000 is a lot of money to pay for that.  Seems to me the market is clearly in exploits which are going to be used maliciously or for surveillance.  Somebody who has deep pockets is going to be paying $100,000 for zero-day exploits.  And they're going to want the largest window of exploitability possible.  Which means there's got to be something in the agreement saying that this will be kept absolutely secret until something.



So anyway, it's an interesting site, if anyone's interested.  He calls it The Absolute Zero-Day Exploit Exchange at MitnickSecurity.com.  And there's a lot more to read about it, for anyone who's interested.  I just thought it was, like, you know, I mean, interesting and maybe a little troubling.



FR. ROBERT:  Can I pay for the zero days with bitcoin?  That's the old - let's get serious here for a second.  Let's talk a little bit about how the security researcher field has traditionally worked.  And I know plenty of security researchers.  In fact, one of the ones I've been following recently, have you met a man by the name of Dan Geer?



STEVE:  His name I know.



FR. ROBERT:  Yeah, he was the keynote speaker at Black Hat this year.



STEVE:  Okay.  Yeah, that's why I know the name.



FR. ROBERT:  I'll talk about some of his theories a little bit later because that actually ties into Mitnick.  But if you're a security researcher, especially if you're sponsor of security researchers, so you work for one of the main research companies, typically you look for these zero days.  You look for these bugs.  You publish a report.  So you show exactly how it's used.  You show exploit code.



STEVE:  Demonstrate it.



FR. ROBERT:  You demonstrate it.  You offer it to the company that's vulnerable so that they can patch it.  And then you make your money off of selling your consultancy to companies, to say, look, are you sure you're patched?  We can do all of your vulnerability testing.  We've developed a software that will allow us to look through all your systems and tell you where you are and are not vulnerable.  And typically, if your security research company is able to find these zero-day exploits or these bugs in a timely fashion, then you make a decent amount of money.  That's a security researcher.



STEVE:  Yup.



FR. ROBERT:  What Kevin Mitnick is doing is arms supplier.



STEVE:  [Laughing]



FR. ROBERT:  Because there is no disclosure.  There is none of this old world, I'm researching so that I can make the world a better place.  It's, no, I'm researching so I get paid.



STEVE:  Yes.



FR. ROBERT:  I mean, and you touched on this.  No one's going to pay $100,000 except a company trying to exploit another company, or a government trying to exploit another government, or its own people.  And, you know, it really - you know him.  I don't know him except by reputation.  But I've always seen Kevin Mitnick as sort of like he's the antihero, you know, he's the guy who fought the government, he got away with it, and smirk-smirk, he's still doing what he's doing.



STEVE:  Yeah.



FR. ROBERT:  This just - it feels so wrong.



STEVE:  Yeah, it's sad.  I mean, this is not the Kevin that I remember.  So again, it's like I said, I don't know what happened.  Wow.  And I love your analogy.  I think arms supplier is absolutely apropos because we're no longer in a world where the Internet is optional, and where the notion of cyberwarfare is an abstraction.  I mean, it is surprisingly real.  I'm lagging behind a little bit.  I'm a little bit more still old school, where it's like, oh, come on, you know, really?  But yeah, really.



FR. ROBERT:  At Black Hat 2014, Dan Geer made a statement that sent chuckles and then some nervous chuckles through the audience.  And that was he thought that the U.S. federal government should actually buy up zero-day exploits and then release them.  That should be part of their job.  Part of their job should be to keep the infrastructure of communications safe.  And if that meant buying up zero-day exploits from hackers who would otherwise exploit them, basically give their money on the front end, rather than on the back end, then they should make that part of the responsibilities.  It's interesting that, you know, because I know Kevin was there, I'm wondering if he heard this and said, okay, that's not a bad idea.  How about this?  We'll sell it to you.  And if you're a good government, you'll give it to your people.



STEVE:  You know, one of the oddities of the software industry that has existed from day one is the license agreement that says "We're a company selling a license to use our software.  You're going to pay us money to do so.  But we're not going to give you any warranty of any sort over its merchantability or fitness for use or the fact that it has or has not any bugs."  So, I mean, and car companies would love to have that deal.  So would drug manufacturers and all kinds of other commercial enterprises that are producing property and intellectual property.



Somehow the software business has always had this hold-us-harmless clause in their license.  And I guess they're able to do it because of the power that they inherently have.  Microsoft was in a position to say, okay, so don't use DOS.  Good luck.  Don't use Windows.  Good luck.  You had no choice except to relinquish all right.  But it's weird that here we are in a situation where - and this comes from what you were saying, that a company, a commercial company with an incredible amount of cash, like Microsoft, is producing a series of operating systems and programs - Internet Explorer, Office, Outlook Express, oh my lord, that is completely vulnerable for years, creating all kinds of damage, and then people are suggesting, well, you know, maybe the federal government should further inoculate them by purchasing the bugs in their code and selling the solutions back to them.



And it's just like, what? What has happened?  How does any of this make any sense?  It's just so upside-down.  But that's the deal that software's always had, is just, you know, a zero liability situation.  I mean, nobody else has it.



FR. ROBERT:  That's actually another point that Dan Geer made in his talk, which is he wanted accountability for security.  Specifically, he said, look, we understand that developers are going to have bugs.  Bugs are part of programming.  But he believed in a world with total transparency.  He wanted zero transparent failure.  So when you have a software solution that fails, it is your responsibility to make sure that people know about it as soon as possible.  And that's shining the light on zero day.  Zero days don't exist if people aren't afraid to tell people that, yeah, we failed.  Eh, kind of strange.



Now, did you see the little shot that Kevin Mitnick took?  If you look at the Wired story, there was a security researcher - do you know Christopher Soghoian?



STEVE:  Oh, yeah, of course.



FR. ROBERT:  Of course, yeah.  He's a big, big voice against the use of zero-day exploits.



STEVE:  Yes, yes.



FR. ROBERT:  And he fired off a kind of a snarky tweet.  And he said, "Well, look, if you're going to sell zero-day, which I don't recommend, exploits using a convicted felon as a broker, well, that seems unnecessarily risky."  And Mitnick shot back, in typical Mitnick form, "My clients may use them to monitor your activities.  How do you like them apples, Chris?"  So, and again, that kind of breaks my vision of what Mitnick is.



STEVE:  Yeah.



FR. ROBERT:  I can see him like this kind of a person.  And I'm wondering, did you nail it?  He just wants to get paid.  Like I've been doing this game for the longest time, it's time for me to actually be comfortable.



STEVE:  Yup, cash in.  And I think he's wanting to leverage his celebrity.  He certainly has celebrity.  Everyone knows the name Kevin Mitnick.  So he just figures, hey, you know, I'm going to get paid.



FR. ROBERT:  Yeah.



STEVE:  He does have a book coming out, not quite published, called "The Art of Invisibility."  And it was described, I don't know what copywriter wrote this, but it says the world's most famous hacker reveals the secrets on how citizens and consumers can stay connected and on the grid safely and securely by using cloaking and countermeasures in today's era of Big Brother and big data."  And it's like, yes, unless they buy any of the author's zero days and use them [indiscernible].



FR. ROBERT:  I think we already actually talked about how you stay secure.  Turn off your phone, don't ever get on the Internet.  That's about it.  That's the only way you stay secure.  Oh, and by the way, don't get in a car that goes anywhere near a security camera, a traffic cam, or a license plate cam.  And also don't call anyone on the phone, and don't send any mail.  You probably shouldn't leave your house.



STEVE:  And don't use the transponders used to run...



FR. ROBERT:  FasTrak.



STEVE:  FasTrak, exactly, the FasTrak transponders.



FR. ROBERT:  Why, by the way, you have no choice anymore.  You know that.  In the Bay Area you can't go across a bridge without that.  They're not taking tolls on the Golden Gate, and they're going to repeat that down the chain here.



STEVE:  Wow.  So in Miscellany I have just one quick little thing.  I ran across what I thought was just a charmingly clever idea.  We talked years ago about the problems of webcams on laptops, and now often on desktop machines, that is, of the camera staring at you.  And my advice, my first advice was just take a small piece of the sticky top of a Post-it note and stick it over the lens.  That is, you just don't want this thing staring at you.  There are too many past and known ways for that to be used to eavesdrop.  In fact, we covered the famous case of an elementary school that was loaning these laptops out to their students, and the security firm that they were using were turning the webcams on in the students' bedrooms in the evening and spying on these elementary schoolchildren.



FR. ROBERT:  Also known as "child pornography."



STEVE:  Really, really...



FR. ROBERT:  I remember [indiscernible], yeah.



STEVE:  Really chilling.  So, and then one problem with that advice was that, if the system used the webcam to measure room illumination, then you would be losing the automatic brightness control.  So then the second-generation solution was use a piece of the frosted Scotch tape.  That would completely frost the image so nothing would come through, yet allow the light through in order to still give you brightness control.  Somebody came up with just a simple, elegant, I just loved it, solution.  I tweeted it.  It's on Kickstarter for only $5 for anybody who can't do their own.



I actually have a fascination with magnets, so I've got just a huge library of magnets.  But you're showing it now on the screen.  It's called Nope, N-O-P-E.  And it's Nope Live Free on Kickstarter.  So imagine two very thin disk magnets that are stuck to each other.  And they naturally just sort of roll around each other.  I'm sorry, they're stuck edge to edge, not flat, but edge to edge.  One of them is sticky, has adhesive on the back.  You stick that just to the side of the webcam hole.  And then the other one is able to sort of roll around, but easily roll and just sort of stay put, they sort of naturally stay put, over the webcam hole.  I just - it's so clean.  It's very elegant.  If you're a person who never uses your webcam, then, yeah, sticky tape probably makes sense.  But if you're like a frequent - say whatever it is you're doing is like several times a day you're using Skype, then it'd be nicer to have essentially a cover.



We've talked about covers that you can slide open and closed.  This one you just sort of roll the other magnet off to the side, opening the shutter, essentially, or bring it closed again.  Anyway, just wanted to make sure our listeners knew.  It's very simple, very clean.  I mean, if you find a source of magnets, you could just do your own.  But anyway, I just really - I thought it was great.  So thank you, Mike Cunningham, for tweeting that and for bringing it to my attention.  And the Kickstarter is doing really well because it's just, you know it's capturing people's imagination, saying, hey, I think that's kind of a cool idea.



FR. ROBERT:  Yeah, it's simple and it's elegant.  It actually looks kind of nice.  But Steve, I need something to cover over the microphone.



STEVE:  [Laughing]



FR. ROBERT:  I'm actually more concerned about what they'll hear, rather than what they'll see, because my laptop's always closed.



STEVE:  And actually that's a very good point.  Oh, and I should note that a couple people did wonder whether the magnets were thick enough to interfere with a laptop cover's closure.  That is, often laptops do have a gap between the lid and the bottom.  But some of them don't.  Some of them come down, right down tight.  So if you were using it on a laptop, because there is some nonzero thickness to these little magnets, you'd want to make sure that it's still going to be compatible with you being able to close your laptop.  Otherwise it's not so convenient.



FR. ROBERT:  Not so convenient at all.  But wait, we've got something big coming up because we do have to cover Shellshock, yes?  Now, Steve, the main event.  Everyone has been talking about Shellshock.  How much should they be afraid of this?  Is this bigger than Heartbleed?  Is this actually going to affect them?  Is this just something that system administrators have to worry about?  Tell us all about it.



STEVE:  Okay.  Okay.  So let's sort of get a foundation of understanding the problem.  UNIX has, that is, to give some underpinnings for those who aren't UNIX developers and hackers and users and so forth, and understand how this happened.  UNIX has always taken a sort of a toolkit approach involving the invocation of multiple small separate apps.  That's just sort of the way the UNIX culture of development works is you have a bunch of simple, capable tools, and you script them together.  You build up an ad hoc solution to solve a problem.



There are sort of two main ways of communicating between these separate pieces.  One is to pass things on the command line, either as arguments or so-called "piping," where you pipe the output of one of these into the input of the next in sort of a chain, and each one processes it in some fashion and then passes it on to the next.  Another convenient means of passing arguments is to use the so-called "environment."  The environment is the wrapper around the executable.  And among other things, the environment can have name value pair variables.  Meaning that you have a name equals a value, and really extreme flexibility over what the values are and what the names are.



People who've been around for a long time will remember back in the DOS days the path variable that tells the operating system which set of directories to look for executable files in.  There's a large set of standard environment variables which the operating system and applications refer to for their own operation.  But they can also be created on the fly.  And we can think of it sort of like a named scratchpad where data can be placed, and then another program can be invoked, and it looks in the environment for the variables, for the parameters and the arguments.



Well, the BASH shell, which as you mentioned earlier in the show is decades old, it processes the environment when it starts up.  It's become very powerful over time.  And even back then it was scriptable.  You could write small programs in it.  You could use it to invoke other programs.  So it could sort of be the hub.  One of the things that it could do is you could define small functions, that is, executable functions, in an environment variable.  And when BASH started up, it would read in the environment, sort of incorporating it into itself, and in the process define those functions.



So in this sort of toolkit glue approach, one of the things that was done very often in the earlier days was, as we began to have data submitted by users, submitted by web users to web servers, the so-called CGI was the typical way that - it stands for Common Gateway Interface - was the typical way that a user submission, that is, which is always a query, remember, users query the server, the user's query would invoke some code running on the server which would receive the data that the user sent.  And whatever that program emitted, whatever it generated, would be the response that would go back to the webpage.



Well, just because of the design of UNIX, the various parameters, the headers in the user's query were put in the environment because in the environment was a convenient way for the CGI script to reference things like the host header and the excepts header and the various query headers which are used by the operating system, or, I'm sorry, the headers that are submitted by the browser and then used by the CGI side to process the query.



So this is the way things sat for several decades, until several weeks ago somebody noticed that when the shell, the Bourne Shell, which technically stands for Bourne-Again - there was a Bourne Shell, B-O-U-R-N-E.  This is the Bourne-Again Shell, B-A-S-H, thus BASH.  When it is invoked, and it sucks in the environment and processes the values of the environment variables that it finds there, it turns out that after it processes a function definition, it continues looking at the balance of the value of the environment valuable.  And if that's a command, it will execute it.



Now, as we talked about at the top of the show, that's not necessarily, like, a horrible thing.  You could imagine back 20 years ago when the Internet wasn't, hadn't happened, that the designer of this could have thought, hey, you know, I'd like to be able to define a function and then invoke the function.  So you can actually do that, or could do that.  It's not clear today whether that still has survived.  You could, at the beginning of the environment variables value, have a function definition, you know, open parens, closed parens, open curly brace, contents of the function, close curly brace.  That's the function definition.  But then afterwards you could refer to the function that you just defined.



So you could argue that this never was a bug, that this was a feature that the original implementer of this extension to the shell thought, hey, this would be a handy hack.  And it no doubt is.  And it's entirely possible, just due to the nature of everything else going on, that this is sort of a relatively obscure feature of the shell that wasn't being used very often, that nobody just noticed until a few weeks ago that, over time, as the Internet did grow and mature, applications using the Internet continued to also use the shell.  That is, maybe began using the shell, and then it was handy.



So, I mean, the shell is always there.  On a given system you can count on it.  It's the default shell for UNIX and Linux systems generally.  And so because it's there, it's handy, you can count on it, UNIX developers just used it.  I mean, it became one of the tools that Internet-connected things took advantage of to do some of their processing.  And so the nature of what became thought of as a bug, certainly an exploit - although it may have been an exploit by design, innocently, several decades ago - was the observation that, if anything that a user outside of - a remote user connected to a server, if anything they did could allow their actions to create values in the environment, and then either in that same event or subsequently they could get the Bourne Shell to be invoked, they could use the fact that even a null function, that is to say, open parens, closed parens, open curly brace, semicolon, which is a null statement, closed curly brace.  That's a null function.  But then the balance will be handled like a command.



And if they could write that variable and something that they subsequently did invoked the Bourne Shell, they were essentially - it's hard for me to even say it.  They were essentially executing a command of their own design, remotely.  With the privileges of the shell, which in many instances are root or much higher than restricted privileges.  And so...



FR. ROBERT:  You know, Steve, I have no trouble believing that this was a feature.  I mean, it does sound useful.



STEVE:  Yes.



FR. ROBERT:  I put myself back in 1989, 1990.  Here's the problem I'm having, which is I know a lot of UNIX guys.  And they all tell me they never knew about this.  So if it was a feature, it was an undocumented feature, and then a lost feature.  Whoever put it in there just never told anybody else about it.



STEVE:  Yeah.



FR. ROBERT:  You know UNIX way better than I do.  Do you know anyone who even hinted that this was possible with BASH?



STEVE:  No.  And subsequently to this coming to light, I've seen people demonstrate the utility of it.  I think the only way to know, and unfortunately it's probably lost now, maybe there are, like, older copies of the source.  Certainly source from before a few weeks ago, before the mad patching, so, yeah, obviously there's going to be source around, would be to examine the source and see whether this looks like a mistake, or whether it looks deliberate.  Because this sort of thing, I would think that the source code would tell you whether this was a feature that the programmer, like there's a comment that says, you know, upon encountering the closing curly brace, continue parsing the line for anything else that we need to do, with the function we just invoked.  That would be a comment that the source would have if this were deliberate.  So I have not looked at the source to answer the question.  And I haven't read anyone anywhere either way saying yay or nay.



FR. ROBERT:  Wow.  Steve, we are going to get back to BASH and the vulnerability that's shellshocking the world.  But before that, let's hear some good news.  I want to hear some SpinRite testimonials.



STEVE:  Well, just one.  We've been talking about SpinRite and RAID arrays for the last few weeks.  And in fact our talking about it has incented other people who've used SpinRite to successful recover from RAID problems.  We talked about one, I think it was last week, where the array fell off the back of the moving truck.  The good news is it wasn't moving at the time, but the person was moving.  In this case, this is sort of a different one.



Bob Guarda in Ottawa, Ontario, Canada, he said:  "Hey, Steve and Leo."  And of course in this case Padre.  He said, "Just want to say hello, and that I am a longtime listener of Security Now!, and I'm also a proud owner of SpinRite.  As we all know, we 'computer guys' do the support for family and friends, and I'm no exception to this rule.  Here is a story for SpinRite - a success story, that is.



"A friend of mine has a Netgear ReadyNAS network NAS box.  When he purchased it, I set it up for him with four drives and RAID 5 configuration.  At the time I told him that this is a very good configuration because, should one drive fail, the information is still available.  The odds of two drives failing, well, that's super high.  This would help in keeping all of his pictures and videos safe.



"To make it even more safe, I set up the built-in backup utility of the Netgear NAS to do a weekly backup to an external drive connected to a USB port.  One morning, he gets an email from the device saying that Drive 1 had failed, and that another drive was about to fail.  The NAS box had turned itself off for protection.  He calls me up in a panic, and I tell him no problem, the worst scenario is that he has 'lost' [in quotes] one week of work.  He then admits that the backup had not worked in months.  He kept forgetting to tell me.  Yikes.



"He contacted Netgear for help and, after a valiant effort from both their Level 2 and Level 3 support at Netgear, the [in quotes] 'solution' was to get a data recovery company to save his data.  It appeared that Drive 1, 2, and 3 were all dead.  When he inquired at a local data recovery establishment, cost was $3000 starting, no guarantees.  Yikes," he writes.  "Then I recommended" - oh, he says, "Then I remembered that SpinRite does not care what the file format is on the drive.  Be it NTFS, FAT32, MAC OS, Linux, or RAID, it does its magic.



"So I said to my friend, 'You have nothing to lose since you already lost it.'  He agreed, and let me attempt to save his data.  So I did Drive 1, 3, and 4 at SpinRite Level 2.  Drive 2 was giving me the click of death, and the computer would not recognize the drive.  I figured, well, it's supposed to be RAID 5.  If I saved the other drives, the Netgear box should rebuild.  I replaced Drive 2 with a new drive and placed the freshly SpinRited," he says, parens, "(a new word?), drives into the NAS enclosure.  I powered up the unit and, voila, the RAID started to rebuild.



"After the RAID finished rebuilding, all of his work files and, most importantly, the videos and pictures of his two kids were available.  Thank you, Steve, for making such a great product.  And keep up the great work you do with Leo with Security Now!, one of the best sources of security information there is out there.  Thanks.  Bob, in Ottawa, Ontario, Canada."  And so, yeah, even having a RAID, as we have been talking about, isn't often enough protection.  If more than one drive dies, in this case three died.  Or I guess, no, all  of them died.  SpinRite was able to fix all of the that were still even willing to get online, and that was enough to rebuild the RAID and get this guy's data back.



FR. ROBERT:  I didn't know it worked for RAIDs.  I actually have, we have a little Netgear ReadyNAS over there, an NV+, that I've got to give it a go because its drives died.  And I just - I kind of threw it away.  I'm like, ah, I didn't want to deal with it.  I want to see if SpinRite will get it back because I completely forgot that it doesn't look at the OS.  It doesn't care what's on the drive.  It's actually just looking to see if it can read sectors.  It's going sector by sector and saying, I can't read this, move it someplace else.



STEVE:  Yup.



FR. ROBERT:  That's fantastic.



STEVE:  And it does recovery enough that you can get things back in order to recover your data.  So, whoo.



FR. ROBERT:  Although I have to say, he was saying his friend received an email from the RAID array essentially saying, yeah, I'm dead.  That's not what happened.  I know the ReadyNAS system pretty well.  It would have been sending him constant emails saying, hey, look, the error count is going up.  You really should probably do something about this.  And then when...



STEVE:  It does sound like his friend was being a little negligent all along.



FR. ROBERT:  Right.  Which just goes to show you, we could have all the tech in place to make sure that this stuff is redundant.  But if we're lazy about it, it doesn't matter how redundant it is.  It's going to fail.



STEVE:  And that's why I'm able to have blinky lights behind me and a couple employees to answer customers' questions.  It's what's made my life possible, is people almost always wait too late.  Few people, you know, the problem is they turned the drive on day before yesterday, it was fine.  They turned their computer on yesterday, it was fine.  They turn it on today, dead.  And, I mean, so really preventive maintenance has been demonstrated to be fully useful on hard drives.  But people generally don't do it.  They wait until it's too late.  And I get to be the hero, which I'm really glad for.  And as I've said before, I don't mind if someone helps a friend out when they're in need.  There are plenty of people with hard drives in the world, and we'll be fine.  But I just like to have our listeners protected.



FR. ROBERT:  And I have to say a lot of people will balk at, oh, $89 for something I'll use only once?  No, no.  It's $89 for something you're going to use on your worst day, at least up to that point.



STEVE:  Well, and actually for the rest of their lives.  I mean, SpinRite is about 25 years old now.  We honor upgrades even from Version 1.0.  Everybody knows that as soon as I get finished with SQRL I'm going back to SpinRite 6.1 and then probably moving on to 7.  So the purchase you make will - you can use it on all the machines you own, now and for the future.  I'm going to keep it alive.



FR. ROBERT:  I think I have a Version 3.  I may need to update that.  It's been a couple of years.  Oh, and by the way...



STEVE:  Okay.



FR. ROBERT:  ...if you ever use it on someone's computer that has gone completely dead, they will think you're magic, and they will wonder what this wonderful tool is that you've used.



STEVE:  That's right.  You get to be the hero and the guru, and then I'm your hero.



FR. ROBERT:  All right.  So we've had our dose of good news.  Thank you.  After all the vulnerabilities, after the BASH bunch, we got a little dose of happiness.  So drop us back into the sadness.



STEVE:  Okay.  So what I found really interesting was the industry's understanding of this, the graph was instantaneous.  Invariably, we were going to see the press comparing this to Heartbleed because Heartbleed is relatively recent.  It's the last most recent big bad thing that happened.  And so people were saying, oh, is this better, or worse, or how does this compare to Heartbleed?  And the answer is it doesn't compare at all.



The way to think about Heartbleed is that there was some  concern that, if a hacker tried really, really, really hard, really fast for a long time, they  might end up capturing a buffer that contained some sensitive keying information from a server.  After the initial announcement of the discovery of this potential buffer overflow, there were security researchers who said the region of memory that you capture is unlikely to contain anything.  So CloudFlare, among others, they put up a couple test servers and said, "See whether you can crack this."  The answer was yes.  Hackers were able to obtain keys after a lot of hard work.  They got lucky.



And in fact there was another exploit, I'm forgetting which one it was, but a few weeks we talked about one that was big and bad and was believed to have been another exploit of Heartbleed against that organization, a machine at that organization.  As I remember, it was a router.  It wasn't a main server, it was something in their network, like a VPN server or something.  But something was exposed to Heartbleed, and keys were extracted.  Oh, yeah, they were able to get VPN authentication keys and then get onto their network and then perform the intrusion that way.  So, okay.  So that's the nature of that.



This is completely different.  This is, if you find a server that is vulnerable, and it's trivial to find them, you basically - you can send them pings with your own IP address, and it will ping you.  And when you get pinged, you know, oh, I just found a - I just executed a ping command on a remote web server.  I can execute any command I want.  Consequently, this thing got a 10 out of 10 on severity, a 10 out of 10 on impact, a 10 out of 10 on exploitability.  The access vector was remote network, the worst it could be.  The complexity was low, the worst it could be.  The authentication, none required.  I mean, across the board.  This was red.  I mean, this was unbelievably bad.



And whereas when Heartbleed first was announced, you know, everyone sort of said, oh, that doesn't sound good.  We know buffer overflows are not good.  But we're not sure you're going to get anything of any value.  Well, and it took a while for, you know, two people to demonstrate, oh, we tried for a week, and a hundred thousand billion gazillion queries as fast as we could make them, and we captured some keys.  This is, you know, I basically sent out some probes, and 3,000 servers replied.  And that was only in a small piece of the Internet that I chose to check.  And I could have executed any command with relatively high privilege on any of those servers.  I mean, this is night and day amazingly bad.



And my very favorite hack is one that the guys at FireEye found.  They looked at their blogs and posted a number of the so-called techniques that they saw.  My favorite is a no-malware reverse shell.  You send a query to a web server, which is just GET /cgi-bin/.  So you're just - you're making a query at the root of the cgi-bin directory.  Oftentimes something is there to pick up the query and run.  You give it a specially formed - the query gets a specially formed user agent string, meaning that the cgi interface will take the user-agent header in this fake query of yours, stick it as an environment variable called "user-agent," and then the value.  And then what you give it is a command.



It's not common knowledge, which is to say many people are unaware of the fact that BASH actually has built-in commands for sending and receiving network traffic.  You need no other software to be installed on the system.  BASH itself can send and receive network traffic.  This simple command causes it to open essentially a reverse shell to the IP you provide, on the port you provide.  So you're an attacker.  You open a terminal session, listening on a port.  You send this command to a remote machine, causing its bash shell to connect to you on this port in interactive, "-i" means interactive mode, and you now have an interactive session with the root shell in this remote machine.  And it works.



FR. ROBERT:  And not only does it work, it's really easy to make it work.



STEVE:  Yes.



FR. ROBERT:  There are a lot of hacks that require timing, luck, and more than a little bit of skill.  This is, as you said, if you send out pings, you can find a bunch of vulnerable machines.  Throw the code at all the machines and see which ones respond and start up an interactive session, and you're in.  You're essentially sitting at the keyboard.



STEVE:  You have the dream, yes, you have the dream of every hacker on the planet, which is an interactive command line inside the heart of a server, a remotely located server that you just got access to.  So you could do anything you want.  You poke around.  You start sending the log files and the passwords file and, I mean, it's just - it's unbelievable.



FR. ROBERT:  Yeah.  This is not Heartbleed, where, okay, I might be able to capture some of the communications.  Maybe I'll even get a credential that will let me in.  This is, no, I'm not waiting for you to do something stupid, I could just take over.



STEVE:  This is not a backdoor.  This is a front door.



FR. ROBERT:  This is the front door [laughing].  The thing that gets me about this story is, as you said, it's got legs.  This, if I were still doing anything questionable, this would be the entry point for an advanced persistent threat.



STEVE:  Yes.  So now...



FR. ROBERT:  I wouldn't use it right away.  I would just make sure that I'm deep enough in the system, I've got enough privileges, that I'll be able to exploit something later on when I want to.  That's what I would - I would be doing a rush to get into every system before it gets patched.



STEVE:  So, yes.  Now we know the nature of the problem.  Here's the reason this thing has legs, is that it has breadth and depth.  The problem is that there is a vast ecosystem of stuff on the Internet.  Of course, famously, the Internet of Things.  Now, the IoT devices tend to be much leaner than big-iron servers.  So, and BASH, because it has all these capabilities, is a big shell.  There are much smaller shells which tend to be more often used in consumer routers and, you know, unfortunately, and light bulbs and switches and things.  But there's all sorts of other stuff.



For example, we know that webcams use the BASH shell to essentially make their little web server.  They've got little brain - I don't want to say "brain dead," but I started to say it.  Simple, simple-minded.  Simple-minded web servers just written in BASH script.  So webcams that you can connect to can probably be taken over.  I'm not sure what you could do with them, but you don't want your webcam taken over.  The point is that the shell is universally omnipresent.  And there are all kinds of things globally sitting on the Internet connected.  And it has been the habit of developers who are just putting together a quick hack for one thing or another to use the shell and to use some of these powerful features without understanding.  And the problem is a lot of this stuff gets baked into products.  It gets baked into firmware.  Or that was 10 years ago, and the developer who knows that's what he did has gone on to greener pastures.  He's moved on to other companies.



Yet this stuff is sitting there on ports, waiting for connections open to exploit.  Not just port 80.  Not just 23.  Not just, you know, the common ones.  But appliance ports and random function ports.  The problem is this is just scattered throughout the infrastructure, the deep infrastructure of the Internet.  And that's why we're going to be encountering this issue, I predict, for years to come.  It's going to take a long time for this to drain out of the Internet.  I mean, and to some degree it never will.



FR. ROBERT:  There's going to be an Internet support group for IT administrators who are - right now they're trying to think of every box they have sitting in a server, every forgotten piece of equipment that they haven't patched, they haven't updated in the longest time because they never thought it was important.  Because I guarantee you, if I go through my inventory, I can't remember every box I might have that has this vulnerability.



STEVE:  Yeah.



FR. ROBERT:  I mean, imagine how far back this tool goes.  That's how much time there has been to forget that you're using this on a box that's now going to become a vector for infection of your network.



STEVE:  Yeah.  And in fact, the intrusion detection systems immediately updated their patterns, trying to look for this open parens, closed paren, open curly brace, not much inside, close curly brace pattern, and catch it at the border.  The problem is there are many ways of obscuring that, and other ways to get this in.  And so it's in general, I mean, it's better to have that than not.  By all means, have that.  But you just - you can't count on it.  And there are doubtless devices that are not behind IDSes.



FR. ROBERT:  I know.  Actually, I was just thinking about that.  I have a few IDSes running in Brian Chee's colo right now that I'm pretty sure have this BASH vulnerability.  Now, that would be ironic.  Someone just owned that IDS.  Ah, Steve, is there any good news?  Is there some good news about this?  I mean, of course people have been applying patches, and the patches have worked like gangbusters; right?



STEVE:  Yes.  Well, okay.  So the very first patch came out and didn't solve the problem.  Then - this is one of the neatest things about open source.  What I love about open source, I think more than anything else, is what happened this past week.  Yes, it's unfortunate that this thing sat for two decades.  And no matter how many eyes were looking at it, nobody was looking at this particular aspect to see the problem.  So we could argue that open source - and, I mean, this is not the first time we've seen a failure of open source.  I mean, the Heartbleed vulnerability itself was introduced two years ago by a well-meaning programmer making a change where he didn't do a range check and should have.  So even the fact that it was - the fact that it was open didn't protect that from happening.



What I love about open source was the pile-on effect because everybody on the 'Net simultaneously had access to the source of BASH.  In mass multitasking, everybody attacked it at once.  And so within hours this thing was remediated and immediately fixed.  Now, the initial fix had a problem that it could be worked around.  And then people began bashing on BASH, essentially, really pounding on it hard, using fuzzers in order to find other things that would get through, and they did.  There were several other remote code execution vulnerabilities found.  So essentially an aspect of the Internet that had never received adequate focus suddenly got massive attention and, in a series of vulnerability patches, got tightened up very quickly.



And so, I mean, this, for example, as opposed to announcing, telling Microsoft about a vulnerability, and six months later nothing has apparently happened, despite the fact that it's there, and anybody else has been able to do it.  That's the beauty, I think, of the environment, the open source culture that we have today is that there's a huge number of really smart guys.  And, boy, you show them something like this, and you really get their attention.  It's like, oh.  Because everyone's got their own self-interest in mind.  They're like, oh, my god, this affects me.  And so, you know, I want to understand it.



FR. ROBERT:  As a Windows person, a person who spends most of his day in Microsoft Windows, let me reach out to my fellow Windows users and say, look, don't be that guy.  I know there's a few of you who love the fact that this seems to be hitting the open source community.  But as Steve says, just don't be smug.  Don't be a jerk.



STEVE:  Oh, Windows users have no...



FR. ROBERT:  Exactly.



STEVE:  Our pride has been smashed out of us a long time ago.



FR. ROBERT:  Security Now! spends 51 days of the year on Windows and one week of the year - well, actually I'm messed up with weeks and days.  You know what, I think you've just BASHed my head.



STEVE:  The UNIX problems are the exciting ones, I think.  They tend to be, you know, breathtaking problems.  Whereas the Windows ones are, okay, you know, we found a problem with a font parser over here, and so we patched it.  It's like, oh, okay.



FR. ROBERT:  We're kind of desensitized to Windows vulnerabilities.  We just know they're going to be there.



STEVE:  Yeah, but, boy, I'll tell you, the open source UNIX things, ooh, those are a lot of fun.



FR. ROBERT:  Steve Gibson is at GRC.com.  That's the place where you'll find SpinRite, the world's greatest maintenance and repair tool.  You'll also find 16Kb versions of this episode, transcripts, and of course some great information about security, everything from SQRL to BASH to whatever Mr. Gibson has been working on.  You'll also find an active forum for community members to discuss things like, well, what is the best way to hide in the sand now that all these exploits have come out in the open.  If you have a question, you can always submit them at GRC.com/feedback.  And maybe your question will be used on a future episode of Security Now!.



You can find all the versions of Security Now! at our show page at TWiT.tv/sn for Security Now!, and wherever fine podcasts are aggregated.  You could also use our apps or watch us live.  We gather every Tuesday - well, normally a Tuesday, today it's a Wednesday - 1:00 p.m. Pacific time, 4:00 p.m. Eastern, 2000 UTC at live.twit.tv.  I am Father Robert Ballecer in for Leo Laporte.  Steve Gibson, thank you so very much for fueling our nightmares.  And until next time...



STEVE:  Okay, Padre, thanks.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#476

DATE:		October 7, 2014

TITLE:		Listener Feedback #198

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-476.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  I'm back.  Steve's here.  We'll talk about the big JPMorgan breach and a whole lot more security news, plus we've got 10 questions from you, our fine audience, that Steve will answer.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 476, recorded October 7th, 2014:  Your questions, Steve's answers, #198.



It's time for Security Now!, the show that protects your security now, and there's never been a better time for a show like this.  Steve Gibson is here, the security guru.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  You know, we used to have, like, an opportunity to talk about fundamental technology things.



LEO:  Yeah.



STEVE:  That was one of our fun sort of divergences.  And now we're just panting to keep up with security breaches.  And, I mean, that's really the main focus of the podcast, of course.  But, boy, it really does seem like things are going crazy.  And we've got more of the same this week.  Just after last week's podcast, news surfaced of the largest single breach in history, which was JPMorgan Chase.  They had to make a securities filing where they for the first time told the world about a problem that began in June, which they discovered in July and didn't really get resolved until August.



LEO:  Wow.



STEVE:  And of course, while you were gone, last week's topic was Shellshock, this catastrophe that was discovered in BASH that's been around for decades.  Then also we're going to talk about the return of BadUSB, the exploit code, or I should say exploit code, not the original Black Hat Conference exploit code, but some other guys duplicated that and posted it to GitHub.  So it's now public.  And even, it turns out, the Bugzilla bug tracker has itself a bug.



LEO:  Oh, my.



STEVE:  So the question is, does it report on itself?



LEO:  Oh.



STEVE:  We've got a little sci-fi miscellany.  I picked up an interesting question about SpinRite that I thought I would answer in the spirit of today's Q&A.  And our 198th Q&A with actually one, well, all good questions, of course, because I was able to choose among hundreds.  But specifically, one really interesting one about - that you'll be interested in, and our listeners will be, I think, because one of our listeners discovered that his HTTPS switchover was blinding his advertisers to clickthroughs.  And that does happen.  So we'll be talking about that.  And all the news of the week, as well.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Wow, it's a busy day.  Steve Gibson is at GRC.com.  That's his website, the Gibson Research Corporation.  He's also @SGgrc on the Twitter.  And you have really taken to that Twitter thing.



STEVE:  Actually...



LEO:  You didn't like it at first.  I had to talk you into it.  I remember this.  Don't deny it.  We have tapes.



STEVE:  I'm sure that's true because, you know, I'm...



LEO:  Early days, nobody...



STEVE:  ...only a little bit younger than Jerry Pournelle.



LEO:  This show predates Twitter, we should point out.



STEVE:  It does.  And I've really always been a fan of non-real-time communications.  I love email, and I love newsgroups.  I mean, GRC runs a very active newsgroup server.



LEO:  I love it, too.



STEVE:  And it's just it's valuable to be able to schedule that stuff when you want.  But so first I was only DM'ing because I just sort of didn't understand why everybody else would want to...



LEO:  Read your stuff.



STEVE:  Read my responses to individual people.  So and then people were like, well, I can't DM you if you're not following me.  And so that caused a lot of confusion.  And finally I, like, said, okay, fine.  And so now I'm just responding.  And mostly what it is...



LEO:  You're using it in a very sensible way, I think.



STEVE:  Well, and it's really thanks to, again, my followers, who are typically our listeners, is it's the huge dragnet.  They're all out there finding things and reading things and interested in topics that relate to the podcast.  And so they make sure that I'm aware of those things.  And oh, my goodness, that's valuable.  So I encourage it, and I read my feed.  I see everything that anybody sends.  It's just an absolute win for me.



LEO:  Yeah, yeah.  So if you want to tweet him, @SGgrc.  You can also read him if you don't tweet him.  Just make sure you follow him.



STEVE:  Yeah.



LEO:  Yeah.  So...



STEVE:  Okay.  So okay.  So top of the week is - and this was picked up through the news, and the SANS Institute has, like, several articles about it - JPMorgan Chase reported what turns out to be the largest breach we know of; 76 million households and 7 million small businesses had their not really critical data stolen.  But any data stolen from the nation's largest bank is a problem because we want to believe that these guys really take security seriously and understand security.  And so what was discovered was essentially what we're now calling an APT, an Advanced Persistent Threat.



Some attackers, and it's funny, as I'm reading these stories, I'm seeing that the standard media, and even the technical press, uses the term "hacker."  And for many years I was scolded by people who were offended by my use of that term.  So for a while I was saying "malicious hacker," trying to create that modification.  Now I'm just much more comfortable saying "attacker."  I think "attacker" is, like, the right phrase to use.  So as I'm reading these I'm having to remind myself, okay, these are attackers that we're talking about, because I no longer really think of a hacker as being necessarily bad.



So under the condition of anonymity, people who are knowledgeable of the investigation, so this is even now there's - this is still under wraps, and it's all third-hand, although multiply sourced, and so the people reporting, for example, in The New York Times are sure of their facts.



LEO:  So you mean JPMorgan Chase has never gone public with this?



STEVE:  Correct.



LEO:  This is all regulatory filings that they had to make.



STEVE:  Yes.  And it turns out that there's sort of a weird - it's sort of an odd characteristic of our current laws, which is, even this sort of an institution need not disclose if there's no clear financial impact to their customers.  And they're stating that they have no evidence that a penny was fraudulently transferred from any customer accounts.  So they believe that names, addresses, email addresses, and phone numbers were exfiltrated.



LEO:  But not credit card numbers.



STEVE:  Correct.  Not Social Security numbers.  Not credit card numbers.  And so not the most sensitive information.  Oh, and not passwords.  And they have seen no evidence of fraud resulting from this breach.  They do believe that the attackers are based in Russia.  And for reasons that aren't clear, because again we're sort of dealing with, well, don't quote me on this, but I'm familiar with the investigation that these other people say, not me personally, and like they're involved with high echelons of the Russian government.



So some people are speculating that this is as a consequence of the escalating sanctions that the U.S. government is imposing on Russia due to the whole Ukraine issue.  But again, this is all speculation.  Although apparently, because enough forensics has been found, they're absolutely sure that this data, these attacks came from Russian IP addresses.  That much seems clear.  So apparently the security team discovered this breach, as I mentioned at the top of the show, initially in July, and was able to post-date the initial intrusion to June.  The attackers over this period of time attained the highest level of administrator privilege available in dozens of the bank's servers.



LEO:  Not good.



STEVE:  No.  They reached more than 90 different machines.  But sort of paradoxically, no evidence of any fraud that resulted.  So it's really sent a chill through the ranks of cyber-focused people in our government that this sort of thing happened.  And then the next...



LEO:  Was it Shellshock?  Do they know how it happened?



STEVE:  No.  And it does predate any public knowledge of Shellshock.  But again, we don't know how long and whom might have been aware of the Shellshock vulnerability.  What was really interesting was that they determined that a complete list of the programs and web applications being used on the servers was obtained, and that apparently from logs it looks like that this was very methodical.  The Russians got a list of all the software, then went through methodically looking for unpatched vulnerabilities in all of that software.  Which, I mean, so while we all agree that obscurity is not security, it's handy to have some obscurity when you can.



And so the idea that the bad guys got an inventory of all the software that was on these machines and then methodically swept it for any vulnerabilities that were known, I mean, that's a high-end attack.  That's how - that's what you do when you're not in a hurry, and you're determined to get penetration.  So, yikes.  And the next day we heard that nine other unnamed major financial institutions have also had breaches, maybe part of this same group.  It's believed part of the same group.



LEO:  It's interesting that they didn't attempt to make financial transactions.  Maybe they didn't have the capability.  Or maybe they were just interested in kind of that basic information, which is useful and worth something on the black market anyway.



STEVE:  Oh, yeah.  I mean, yeah, 76 million customers of JPMorgan Chase, names, addresses, email addresses, and phone numbers.



LEO:  Yeah.



STEVE:  So yeah.  You'd rather not have that...



LEO:  But not Social Security numbers.  Probably not enough information for identity theft.



STEVE:  And no passwords.



LEO:  Not credit cards, no passwords.



STEVE:  Right, right.



LEO:  Still, concern.



STEVE:  Yeah.  And, you know, to find out that they have been in touch, that they've been into, that they've penetrated 90 servers and obtained full root level access.  So the presumption is they could have done whatever they wanted to.  But maybe the servers they had access to didn't have the information that would have been dumped.  You can imagine that there's probably a lot of servers at JPMorgan Chase.



LEO:  And, too, remember that we've known for years that this stuff happens a lot.  And banks, because they have no obligation to report it and don't want to scare their customers, usually don't.



STEVE:  Right.



LEO:  It just happened that in this case they had to.



STEVE:  So in breathless news we have the headlines:  "Yahoo Servers Were Owned by Bash Bug Hackers."  And so it's like, oh, okay, that does not sound good.  So it turns out that even that headline was incorrect.  Yahoo!'s CISO, Alex Stamos, clarified what happened over this past weekend.  He explained that, although the attackers were looking to exploit BASH, I mean, you know, BASH, the whole Shellshock bug is still sweeping the Internet, with hackers trying to get into servers using it.  He explained that they happened to take advantage of a different bug, maybe without knowing it. 



He was quoted saying:  "It turns out that the servers were" - and this is like a small number of servers that are Sports API servers.  He said:  "It turns out that the servers were in fact not affected by Shellshock.  Three of our Sports API servers," he said, "had malicious code executed on them this weekend by attackers looking for vulnerable Shellshock servers."  So if we read that carefully, that sounds like they were recruited into a botnet, and that is in fact the attack pattern is that we're seeing that, I mean, there are worms already.  And so it sounds like something got into these servers, and it may not have been a Shellshock vulnerability, but the Yahoo! servers were recruited to look for other vulnerable Shellshock servers, which is not surprising.



He continued, saying:  "These attackers had mutated their exploit.  This mutation happened to exactly fit a command injection bug in a monitoring script our Sports team was using at that moment to parse and debug their web logs.  The affected API servers are used to provide live game streaming data to our Sports front end and do not store user data.  At this time we have found no evidence that the attackers compromised any other machines or that any user data was affected.  This flaw was specific to a small number of machines and has been fixed."  So this splashed headlines, I guess because Yahoo! is so well known, and the press is just frantic for Shellshock BASH bug stories.  And so, you know, it's like, okay.



LEO:  Fine.



STEVE:  Yeah, nothing there.  Now, this is interesting because we've got a lot more information now.  We talked, it was a couple months ago, in July, when Karsten Nohl demonstrated the Bad USB exploit, essentially.  I mean, basically he put into certainly this podcast's communal knowledge the fact that some number of USB devices have rewriteable firmware, and that's a bad thing because you look at the USB device, and it looks like a thumb drive.  We assume that all it is is passive storage.  But in fact it's got a microcontroller in it.  And now we know a lot more.



What happened is that two other security researchers last week at the DerbyCon hacker conference revealed their research.  And we've talked about Adam Caudill before.  So Adam Caudill and Brandon Wilson demonstrated that they had followed in Karsten's footsteps and - unlike Karsten, who has never published anything.  He demonstrated his stuff just to sort of hopefully stir the industry to clean up its act.  Well, these guys, Adam and Brandon, decided, you know, it's been a few months.  Nothing apparently has happened.  We're going to turn the heat up a little bit.  So they put their entire exploit kit up on GitHub, all documented, all open source.



LEO:  Oh, that's nice to know.



STEVE:  So what's interesting is that, for anyone who's interested in playing with this, I'm not obviously promoting this for nefarious actors.  But it is interesting to know more.  So, for example, we know that the USB drives which can be attacked are based on a, I guess you pronounce it Phison, P-H-I-S-O-N.  Phison is one of the largest Taiwanese-based suppliers of USB thumb drives.  And I'm sure they're relabeled, and in fact I know they are because, for example, the Patriot 8GB Supersonic Xpress is one that is vulnerable or exploitable; the Patriot Stellar 64GB Phison; Kingston's DataTraveler 3.0 T111 8GB drive; Silicon Power Marvel M60 64GB drive; and Toshiba's TransMemory-MX Black 16GB drive.  And probably many, many more.



So their kit is, you know, they just built this, not necessarily to be widely used, but in order to sort of create some foundation.  So, for example, they built it around .NET 4.0.  So you have to have that installed in a Windows machine.  They use  Visual Studio 2012 Express, which is a free download from Microsoft.  The Express versions of Visual Studio are.  There's something called the Small Device C Compiler, which is an open source C compiler used for, as it sounds, small devices, meaning various microcontrollers.  Among them is the 8051, which of course has been an Intel standard which I think Intel is no longer supporting, but it just sort of - it acquired, not self-awareness, but critical mass in the industry.  So, like, many people...



LEO:  Oh, but self-awareness would be fun, yeah.



STEVE:  That would be good.



LEO:  Yeah.



STEVE:  We'll have that in the next conference.  And so anyway, it's a Harvard architecture, four banks of, I think it's eight registers per bank.  It's a little eight-bit microcontroller.  But that's what this company, Phison, uses.  And that's what these guys wrote and altered the firmware for.  So they consider themselves white hats.  I mean, for example, so they wanted to clarify what they did.



And so in Adam's companion blog he said, okay, what did we release?  We released a patch to demonstrate the feasibility of creating a hidden partition on a USB thumb drive.  So that's there.  So if somebody were interested in doing that, for example, for their own purposes, they could get any of these drives and/or check whether any drives they have may be already workable.  There's a utility and EXE that they provide which allows you to stick in a thumb drive, and it'll poke at it to see whether it's compatible with their firmware.  And then you could play games.



They also implemented what they called a "password bypass."  Some of these drives, the firmware itself supports password protection.  What they did was they created a firmware modification such that it won't defeat the password if it's already there.  But if you were to modify the firmware first, then it essentially neuters the subsequent application of a password that would otherwise have been supported by the firmware.  So again, they're trying to demonstrate - they were sort of like trying to walk a fine line.  They were demonstrating alterations to thumb drive firmware that does interesting things, but deliberately trying not to hurt anybody.



For example, they explicitly said "what we did not release."  And Adam wrote:  "We did not release self-replication.  There's no self-replication code anywhere," he writes, "while it's possible that it could be done, and we've talked about how to do it, it won't be released here."  He said:  "I am confident that we, Brandon and I, could build a system that would infect PCs, then infect a significant percentage of thumb drives, and then infect other PCs.  But," he says, "But, and this is a big but, what we released doesn't make that easier in any significant way.  Your average script kiddie will never be able to do it.  There are only a small number of people" - I think he underestimates that.  But he wrote:  "There's only a small number of people that would be able to do the work needed to pull that off.  Those people could already do it before we released what we did."



He said:  "The threat of this happening is the same as it's always been."  So they're obviously sensitive to claims that they are escalating.  And I would argue a little bit.  I would say, you know, the more of this kind of work that's out there, it facilitates more than if it weren't there.  And certainly they're...



LEO:  They're just kind of showing off.  There's no real value, is there, to publishing this?  Do we learn anything from it?



STEVE:  Yeah.  I think maybe it keeps it in the air.  And he ends by saying that what we're hoping for is that manufacturers will add code signing [audio dropout] to prevent future modifications.



LEO:  So it's kind of like Firesheep.  It's like, well, let's set the whole thing on fire, and then they'll have to do something.



STEVE:  Yeah.  I mean, and he also acknowledges, I don't remember now if it's on GitHub or in his blog posting, but somewhere he says it's clear that all of these devices are already out in the world.  So if a change were made tomorrow, and who knows if it's even ever going to be made, then if it were made, it would still take a decade for, like, all of the existing drives to fill up and die or go away or become obsolete.  So essentially we have a problem.



And anyway, so again, I'm responding to sort of overwrought press stories saying, oh, my god, BadUSB is back and now it's public.  It's like, yeah, okay.  And essentially what Adam has written is saying we were curious, so we poked at it, and we were able to do it, too.  And I guess his point is it is reproducible.  It's not difficult.  And by us doing this, we really haven't changed anything because, I mean, and he is right.  You'd need to be able to write 8051 assembly language, or C, I guess, but disassemble the firmware, reverse engineer it, figure it out, make modifications, and then move forward.  So it's a project, but certainly not beyond state-level actors.  That would be trivial for them.



Now, again, bringing a little bit of sanity to the Bugzilla report.  What the press said was that a "Bugzilla Zero Day Exposes Zero Day Bugs."  So here's the story.  What was found was that a non-default configuration of Bugzilla could allow privileges based on email domain.  The default installation doesn't do that.  But it's certainly possible for some Bugzilla administrators to say, hey, we want - we're just going to make this easy for ourselves.  Everybody with a Mozilla - say, take the case of Mozilla - Mozilla.org domain email address just automatically has privileges to see bug reports for submitted zero-day, known-to-us vulnerabilities that are obviously not available to the public.



So the point is that Bugzilla is going to have administrative privileges that allow some people to see submissions that are non-public.  It turns out that it - so Bugzilla can be configured to give those privileges by email domain.  And the problem is, when you create a Bugzilla account, it does no email verification.  So anyone could create in this example...



LEO:  Oh, that's nice.



STEVE:  ...yeah, a Mozilla.org email address and instantly have...



LEO:  It's a bug.



STEVE:  ...admin privileges.



LEO:  Okay, that is a bug.



STEVE:  It's not a good thing.



LEO:  That's stupid.  That's easy fixed, easy to fix, though.



STEVE:  Always been there.  Apparently, like from the beginning, it's just it never did email loop verification.  And maybe the people who understood that weren't worried because it isn't the default condition to give blanket permission by email domain, but it is an option.  And some people apparently have used that.  And if those companies were using Bugzilla in that way, the fact that there's no email account verification means obviously that, if sensitive bugs were being submitted, people you didn't intend to have see them could access them.  So that's what that story is about.



I wanted to note, I tweeted, I think it was yesterday Amazon sent me a note that they had shipped my copy of "Edge of Tomorrow," which was fabulous.  Just Tom Cruise has been doing a bunch of great sci-fi movies.  I loved "Oblivion" from summer before last.



LEO:  Wait a minute.  Shipped it?  You didn't just watch it on demand or stream it?  You got a physical disk?



STEVE:  Oh, no.  I like - remember?  Okay.  Leo, I'm just barely using Twitter.



LEO:  Were you waiting by the mailbox with bated breath?  My disk is here, my disk is here.



STEVE:  I've seen the movie.  I loved the movie.  And so I'm looking forward...



LEO:  Oh, you wanted to own it, yeah.



STEVE:  Yeah, exactly.  I do, I like to own the bits of, like, the physical - like I said, I'm still a little bit old school.



LEO:  You don't plan moving anytime soon, so...



STEVE:  No, no.  Exactly.  So I'm looking forward to seeing it again.  I just wanted to give our listeners a heads-up.  Many people responded to my tweets in agreement.  IMDB gave it an 8 out of 10.  Rotten Tomatoes gave it a 90% with an audience score of 91%.  It's just a great - unless you really have a problem with Tom Cruise is the only reason I could imagine that you wouldn't just love it.  So I wanted to let our sci-fi listeners...



LEO:  I'm not crazy about him, but it sounds like he's pretty good in this.



STEVE:  He really is.  Actually, he did, as an actor, he did a great job.  At the beginning of the movie he's like this PR flack, and he realizes, okay, I guess I'd better start shooting things.  Anyway, it was sort of time travel and wonderful stuff.  And, oh, and are you a "Homeland" watcher, Leo?



LEO:  Love "Homeland."  I didn't, now, don't - no spoilers because I haven't watched the season premiere yet.



STEVE:  Oh, my lord, Season 4 began on Sunday.  And, oh, it looks like it's going to be - I've been exchanging texts with Jenny because she's equally into "Homeland."  And I think the series has really hit its stride.  You have to allocate an hour and 45 minutes because it's a two-episode premiere for Season 4.  But, wow, it just really looks good.



LEO:  Good.



STEVE:  And in keeping with the Q&A spirit of the podcast, I ran across a question from Martin in Frankfurt, Germany, wondering how much use he might be able to get out of a troubled drive after using SpinRite.  And I thought I would use his question and answer that for everyone.  He said:  "Hello, Steve.  I have a question about how safe it is to still use a drive after it was SpinRited."  And he said, "Yay, official new word since the last Security Now! podcast."  I guess someone said SpinRited or SpinRitten.  Anyway, you can make up your own word.  "And SpinRite has found sectors that are not recoverable."



And that's what makes this question interesting.  He said:  "In such an instance, does SpinRite tell the drive to map out those bad sectors so that they will never be used again?  Is it therefore safe to still use the drive and the remaining good portion?  Or should one consider not using the drive at all anymore since it shows rather severe damage?  I guess it all depends on the overall age and usage of the drive and how important the data you want to put on the drive is to you.  But just from a purely technical point of view, would SpinRite move those bad apples out of the way for you?  As always, thanks for your great wisdom and advice."



Okay.  So here's - that's interesting because what happens is a drive will never relocate a sector that it is unable to at least finally read successfully.  So when SpinRite is doing recovery, it is trying all sorts of tricks, as I've talked about in the past, to get just one last successful read of the sector because oftentimes what's happened is that the error is just a little too long for the error correction to be applicable.  So if we can just shorten that by a bit or two, then the ECC can correct the sector, the drive apparently internally breathes a huge sigh of relief and is then willing to relocate the sector.  That is, it says, wow, you know, here's your data.  I'm putting a good sector back in here.



LEO:  Whew.



STEVE:  But it will never do that unless it's able to read it correctly.  So what SpinRite will finally do, if it exhausts itself and is completely convinced that no force on Earth will ever be able to read this entire sector again, is SpinRite will settle for the uncorrectable data on the theory that oftentimes that's still way better than getting none.  You might lose, for example, 12 bits where the drive could have corrected 11, so like two bytes, or maybe three depending upon how they straddle the byte boundaries.  But you get the other 512.  And for example, if that's a direct resector, suddenly you go from nothing downstream of that point in the file system being accessible, to probably everything else being accessible.  So massive win in some instances.



But then SpinRite will rewrite the sector.  And then reading it subsequently allows the drive to then relocate it and take it out of service.  So again, there's, like, a lot more going on that most people appreciate, which is part of the reason that SpinRite achieves the magic that it often does.  There's a lot going on behind the scenes.  So that's the story.  I would say, if you've got big red uncorrectable U's, which is what shows up on the SpinRite map, that's a drive which is really doing everything it can to tell you, yeah, you know, don't use me anymore.



LEO:  Mm-hmm.



STEVE:  What you would have to do really is, if you had to use it safely, would be to use a file backup, after running SpinRite on it to get off all the data that you can.  Use a file backup to move the files - again, this is if you have to use the drive for some reason.  Like you're on a desert island and...



LEO:  That's it.  There's only one drive.



STEVE:  There's no Fry's and no Amazon delivery.  That's it.  You have to use this drive.  You're a remote descendent of Robinson Crusoe.  So move all the files somewhere else, I don't know where you would put them if there's no other drive, but put them somewhere.  Then you would have to do a full file system format so that the file system, that is the OS, could itself discover those bad sectors and mark those out of the file system so nothing ever tried to use them again.  Then put everything back.



But again, one thing to ask yourself is why are those sectors absolutely unreadable?  Did the drive get dropped?  Did it get bumped while they were being written?  Because that's a possibility, where the drive's okay, but the head was made to wobble when it was writing them, and so that's one of the things that of course SpinRite does is it rewrites the sector and then checks to see whether it was just a miswrite or if there's actually a defect there, in which case the drive can see it and swap it out to safety.  So again, little more going on behind the scenes than is always obvious.



LEO:  Very interesting.  We've got questions.  You've got answers.  Our listener-driven potpourri #198 starts with Simon in Melbourne, Australia.  We're going to stay in the commonwealth for the moment.  He reminds us that HTTPS everywhere has a kind of a negative side effect:  Just a quick note for the show.  A while ago you suggested TWiT use SSL.  While I agree with you that HTTPS everywhere is a good idea, it does leave caching proxy servers such as those used in universities and some ISPs useless, resulting in more bandwidth for TWiT.tv and others.  That's actually, well, okay.  I'll keep going, and then I can talk about this.



STEVE:  Yup, yup.



LEO:  In a non-SSL download, one student in a classroom would download a podcast, then 29 other students would download again, but these subsequent downloads would be sourced from the caching proxy either at the ISP or university gateway level; whereas, if SSL were implemented at TWiT.tv, all 30 students would be hitting the server individually, and no caching would be available.  Oh, he's right about that.  I'm sure you're aware of this, just wanted to bring it up.  Great show, by the way.  That's right; isn't it?



STEVE:  Yeah.  Well, except that you're using a CDN, and these days I'm surprised by, when I look at links from even small sites have independent content delivery networks that are, like, sourcing even relatively small documents and things.  So, and typically CDNs will also be supporting HTTPS, or have that available as an option.  But he does make a point that I think is a good one.



For example, I remember well when I was implementing ShieldsUP! that I needed, I explicitly was establishing an HTTPS connection to avoid ISP caching proxies, in order to get a connection to the user, in order to obtain their true IP address.  Because, for example, Cox Cable here in Southern California, they run a caching proxy.  ISPs do that because, well, for two reasons.  If there is content out on the Internet which is being pulled by their customers multiple times, like say all of the little images and twitches and buttons and stuff on Amazon's site, that stuff appears on multiple pages all over their site.



So the idea is that the first of the ISP's customers who visits that page, their queries go through that caching proxy.  It essentially holds their request.  It issues the request on their behalf, obtains that resource and caches it, and then returns the results.  The beauty of that is then all of the other  customers of that ISP, when they make the request, the proxy is able to intercept it and reply locally.  It's the locality of the cache that ends up meaning that it's a huge speed increase for the ISP's customers because they're having, you know, basically it's like a huge portion of the Amazon remote network has moved right over onto their LAN, right onto their ISP network, by caching those resources.



And then the other reason the ISP uses it is that, on some level, the ISP is paying somebody for its own bandwidth, that is, the ISP's use of Internet bandwidth.  And so if they cache within their network, then, for example, in Simon's example, one blob of podcast gets transferred into their cache, and then 29 other transfers are avoided by serving it from the cache.  So not only does it lower the load on the ISP, it lowers the ISP's network transit, also.  Which on some level they've got contracts for and they're being billed for and everything, as we've been talking about.



Now, HTTPS, as Simon says, short-circuits all of that because the whole concept presupposes a non-authenticated connection.  That is, the user's browser thinks it's actually connecting, in our example, to Amazon.  It's not.  That's why it's called a "transparent proxy."  There's no actual proxy protocol negotiation.  It's transparent.  The connection appears to be made to Amazon.  It's actually being intercepted by that caching proxy which is then making a separate connection to Amazon.  And as we know, that can only happen, you can only get a transparent interception, I mean, really it's a man in the middle.  It's not a man-in-the-middle attack, it's a man-in-the-middle proxy cache.  But it's still in the middle.  And that's what HTTPS prevents because it's going to verify the certificate of Amazon when it terminates that connection, and the ISP's proxy is unable to do that.



So anyway, it's worth - we're going to talk - there's a couple more questions that have been raised about this as a consequence of the topics we've been covering on the podcast recently, some interesting consequences of, like, switching the world over to all HTTPS.  And one of them is that the benefit that was available to ISPs and their customers does get lost, all of the assets that have to come from that source.



LEO:  I can live with that, though.  I mean, that's, you know.



STEVE:  Doesn't hurt me.



LEO:  We don't mind.  Your pages are small.



STEVE:  I haven't seen - yup.



LEO:  Yeah.  Jamie Eastland, Marlborough, Massachusetts notes that users may be not always able to count on pleading the Fifth.  This must be something from last week.  Well, yeah:  In your discussion with Father Robert last week, you noted that people cannot be compelled to divulge passwords, unlike physical keys.  I only wish that was true.



The Massachusetts Supreme Court recently ruled that defendants can be compelled to provide passwords under certain conditions, such as when doing so would provide the prosecution with little or no information.  Okay.  In this case the defendant had already admitted ownership of the computers.  He had knowledge of the password.  Knowledge of the password can be used to assert ownership of the computer, but in this case the ownership was already admitted.  So the court assigned no value to the information encrypted on the hard drive and rationalized that the defendant could be compelled to produce the key.



Seems like a shaky logical construct, he writes, but that's the rule in the commonwealth at this time.  That might be overturned at the federal level, I have to say.  Keep up the wonderful work.  I've been a listener and a SpinRite owner since year two of the podcast.  My commute is an hour each way, so while I wish you produced more than 90 minutes each week - don't egg him on, please - I'm just as happy that there isn't enough news to warrant more frequent podcasts.  That's an interesting story, actually.



STEVE:  It is weird.  And I dug in a little bit, just like saying, what is going on?  And I'm more puzzled having done that than I was just sharing what we have with our listeners.  So...



LEO:  I think what you were referring to was the well-known - this came up when Touch ID first came out, the well-known legal fact that in fact a physical thing like forcing you to use your fingerprint to unlock your phone is legal.



STEVE:  Yes.



LEO:  If you have a warrant.  But you can't force somebody to divulge the contents of their brain.



STEVE:  Right.  The idea is it is under the Fifth Amendment it's considered self-incriminating to require someone to basically testify, it's considered testimonial information against your own interests, which we're protected from with the Fifth Amendment.  And we've talked on this podcast about this several times.  This is sort of it's common belief that that is the case.  And it was definitely the case that a court in Massachusetts said, eh, we don't think so.  I mean, the Supreme Court in Massachusetts said that, which is a little worrying.  And as you say, Leo, I wonder, if this were taken to the U.S. Supreme Court, what would happen.  Like if that would stand.



But I read more about it, and it really did seem like the logic was bizarre.  It was we already believe that we know everything that we're going to find out from you decrypting the contents of your hard drive.  So therefore we can compel you to do so.  Well, it's like, wait a minute.  If you're convinced you already know it, and I don't want to share it, then how does that make any sense?



LEO:  Presumably if they uncover something they didn't know, it's inadmissible.  I don't know.



STEVE:  Yeah.  It was strange.  Thought it was just worth mentioning because we were assuming that we had protection, and maybe not.



LEO:  Right.  Chris in Sacratomato [sic], California is trying to help law enforcement:  While I was patching several servers at my company for the Shellshock bug, I decided to set up a few loggers to see what sort of commands people were trying to send to our servers.  I found several people were trying to use curl or wget to download malicious code.  In some cases - and what he's saying, we should explain, is that they would log into the server, then run curl or wget to put malicious code on the server.  In some cases I downloaded the code to see what it did, and I found scripts designed to connect a computer to a botnet and perform TCP and UDP flooding when given the appropriate command through IRC.



My question is, is there somewhere I can send these programs to help stop these people?  The programs contain IP addresses of the IRC servers for the botnet, so the right person could potentially just go shut down these servers.  I looked online and found an FBI cybercrime page.  But when I called the field office they said, eh, we don't care.  Eh, you can have it.  We don't care.



STEVE:  I love this question because, first of all, I love Chris's team spirit.



LEO:  Good for him, yeah.



STEVE:  But, yeah.  But the fact is, and I'm very sympathetic to this, law enforcement is so overwhelmed, especially at this moment with Shellshock, I mean, the fact is all server logs are all full of this.  And so it's like saying, you know, in a middle of a monsoon, hey, look, I have a glass of water.  It's like, look, you know, just put your hand out.  Yeah.  So the problem is the only way the FBI would get involved would be not preemptively like this, but it would be if a company was able to demonstrate damages.  And I once knew, there was a dollar amount, I think like $10,000 of damages.  So there's an amount of money you have to be able to demonstrate you have been cost by the malicious actions of somebody else.  And then they create a case, and then someone's assigned to it.  I mean, so it's a really long and involved process.



So unfortunately, while it would be nice if they were in the business of accepting logs from people, at this point they're seeing potentially malicious activity, but not evidence of a crime.  And so unfortunately the bar has been raised to the point now where - oh, and the other thing I remember is that they're already typically busy solving crimes of millions and tens of millions of dollars.  And so you're also ranked on the economic loss scale.  And even if you barely clear the threshold, you're still way down in the pecking order.  So unfortunately the reality of where we are today is far less ideal than we would like it to be.  But given the resource constraints, it's the way things have worked out.



LEO:  Hey, call them up and say somebody stole my iPhone, see what they do.  Nothing.



STEVE:  Yeah.



LEO:  You can file a report, sir, and we'll be glad to file the file.  Gary N. in Kalamazoo, Michigan brings up an important point:  All right, I realize I'm being a little picky here.  But just to set the record straight, you said that Ethernet should probably not be used to connect a 400-foot run.  But technically you are still using Ethernet, it's just running over a fiber optic cable.  It always drives me crazy when people call twisted-pair wiring "Ethernet cables."  Ethernet's a protocol.  It can run over coax cables, twisted-pair copper, fiber-optic cabling.  It can run over pig spit if we can figure out how to do it electrically.  It's all Ethernet.



STEVE:  Yes.



LEO:  I added the pig spit.



STEVE:  Yes.



LEO:  That's editorial on my part.



STEVE:  But it was, it was good.



LEO:  It's a good point.  It's a protocol.



STEVE:  So annoyed with myself for, like, being lazy that way because details are important, and Gary is absolutely right.  As you say, Leo, Ethernet is a protocol.  It started back in the, what, it wasn't 10, is it 10Base...



LEO:  10BaseT.



STEVE:  ...2, I think we would call it, 10BaseT.



LEO:  Or 10Base2 because "T" was twisted pair.



STEVE:  That's right, yeah.  So it was 10Base2.  And then, or, no, no, it was - wait.  10Base2, then 100Base2, and then...



LEO:  I think we used also thin - we used coax.  I didn't use thin fiber [indiscernible] coax, yeah.



STEVE:  Oh, yeah, that was all coax.  Anyway, the point is that it is inherently - and this is what Bob Metcalfe invented at Xerox PARC, where you would use - it was a shared medium technology.  Everybody would clamp on to the same coax.  And it was called, what, CS something CD.  I haven't used the acronym for so long.  Like, oh, Carrier Sense Multiple Access Collision Detection (CSMA/CD), that's what it was, the idea being that everybody would listen.  And if somebody wanted to speak to somebody else, they would wait for a pause, like when the shared cable wasn't carrying communication, and then just launch in.  Just send a packet out onto this cable using the Ethernet protocol.  And the idea was that, if there was a possibility that two people might both start talking at the same time, as often happens on the podcasts...



LEO:  We need a collision-based podcast.



STEVE:  And so you'd have collision detection which happens with, exactly with the podcast, both people talk and go, ooh.  And then they both stop, and then they wait a random amount of time and start talking again.



LEO:  They time out for random interval, yeah.



STEVE:  Exactly, and then start talking again.  And so, and that's exactly how the Ethernet protocol manages to operate on a shared medium.  And as you said, Leo, we started off with literally tapping a coax.  Then, for example, we have the twisted pair connection where we have, instead of everybody tapping on the same cable, because the twisted pair - you can't just tap into a twisted pair.  So that's a point-to-point topology electrically.  But the hub, when you have a hub and not a switch, the hub retransmits out to everybody.  What anybody sends in comes back out.  So it's essentially a point-to-point electrical connection, but it's a shared information connection.



So again, Ethernet works in the same way.  When you have a switch, there's intelligence there which is able to learn which MAC address is connected to which port of the switch.  And you can have multiple MAC addresses that the switch learns, or on different ports.  So there, that's a store-and-forward technology where a packet comes into the switch, and the switch has the ability itself to monitor the protocol on the wire and learn, by memorizing the ARP transactions happening, who's down which wire, and so it's able to forward the packet only onto the connection that's necessary.



Now, that has the advantage in a large network of allowing substantially more traffic to transit if it's dispersed traffic because the switch sort of functions like a traffic cop, sending the data only down the wires where it needs to go, rather than essentially flooding the entire network with every single sender's data across the whole network.  So again, thank you, Gary.  You're absolutely right.  I stand chastised.  I'm annoyed that I - because that's the kind of distinction I really think this podcast should be making.



LEO:  But Steve, how does Token Ring work?



STEVE:  Completely differently.



LEO:  No, no, no.  No, no, aghhhhhhhh.  Moving on.  Alex in Orange County - actually, this is a long one.  Get ready.  Brace yourself.  Because he has noticed a potentially negative side effect of switching to SSL.  Another one.



STEVE:  And Leo, you're going to care about this one.



LEO:  I do already, deeply.



STEVE:  Yup.



LEO:  Hi, Steve and Leo.  Been listening for a little over a year now, filling my commute time with the show.  Thank you for that.  I know you have brought up how there is more and more of a push for sites to switch over to TLS and SSL.  Really the push is coming from Google.  I actually switched my site, a hobby site with about 5,000 visitors a day - that's nice.



STEVE:  That's a big hobby site.



LEO:  That's a big hobby - to use TLS with, might as well, Perfect Forward Secrecy, right on, in the first quarter of this year to help keep my visitors' forum passwords secure.  They may use the same passwords elsewhere, after all.  In the last couple of months I had a couple of my direct advertisers contact me about how clicks to their site from mine have dropped drastically recently.  One of them was about to not renew their banner ad.  What I realized after the first one was they weren't getting the referrer data.  That meant that my site wasn't receiving credit for sending my visitors to them.  The visitors were going, but the packet didn't contain referrer data.



At first, I assumed it had to do with how I redirect users instead of the link going direct to the target site, and the advertiser accepted that and the stats I provided.  But after a second advertiser contacted me about the same issue, Google Analytics was not showing much traffic from my site, I decided to look into changing how my direct banner ads work with a little JavaScript to keep my ability to track stats.  I started with a simple page, one basic "a" tag with an HREF to another of my sites.  When I tested this baseline, the referrer header was missing.  WHAT???  That's how he wrote it, actually.  WHAT???



So I did some searching to discover that the trouble was that web browsers do not pass the referrer from sites that are using SSL.  Oops.  It makes total sense, if you think about it.  Browsers assume that the URL of the source may have some sensitive information that shouldn't be shared with the target site - not, of course, the case with my site.  What I also found is there is a meta tag that will tell the browsers to "pass the referrer for links on this page."  I have added that to all my pages, and suddenly even the redirect method I was using for my banner ads was now passing referrers of the original click source.  Bravo.



Anyway, I realized that many others probably don't know about this side effect of switching to SSL.  I've  worked in security for a decade, and I wasn't aware of it, not were a couple of peers in the industry I asked about it.  If the topic of having people switch their sites over to SSL comes up again, it might help out a few of your listeners who choose to do so and might have a negative impact from this little side effect.  Thanks for reading.  Thanks for providing the show.  Been a big fan of Leo since the early Screen Savers days.  Your neighbor in Orange County, California, Alex.



STEVE:  So, okay.  Things are a little more complicated than Alex indicates, but he's essentially correct.  It's been part of HTTP from at least the 1.1 spec, in the RFC.  And the RFC states that a web client like our browser should not include the referrer field in a query made from a secure domain or a secure page, when it's on a secure page, to an unsecure domain.



So it's the security crossing that is the concern.  And the argument, as Alex suggests, is that it's certainly possible that somebody is using HTTPS, and because they're using HTTPS on their own site, they feel comfortable passing security-sensitive information in their URLs.  I mean, that's still a bad idea because you just don't want to do that.  All kinds of things cache that.  And, I mean, even your browser will keep a list of pages you've visited recently.  And while it may only be for you, that's still sitting in your computer.  And putting things like usernames and passwords in the URL has been deprecated now for quite a while from a security standpoint.  So it's a bad idea.



But back at HTTP 1.1 they were saying, look, maybe somebody is doing that.  Which you could argue they could do securely over HTTPS because that's not going to be sent in the clear.  So if they were on a page that had that sensitive information in its URL, if that was part of the page's address that, like, that brought the user to that page of a site, and that user clicked on, for example, an ad link that was going to some other domain that was not secure, then strip out the referrer header.



Well, the problem, of course, the way the industry has evolved is it's the referrer headers that tell advertising sites where the ad was clicked on.  That's the way the advertising servers are able to credit people's sites who carry ads with clickthroughs to the ads and generate revenue.  So if the links we're clicking on are HTTP links - so the first way to solve the problem is for the ads themselves to be served over HTTPS.  Then, even though they're a different domain that's secure, at least they're both secure.  In which case the browsers will leave the referrer information there.



But the more robust solution was an addition made in HTML 5.  And it's a tag that, if you know that your URLs are clean, that is, that no URL on your site is going to be leaking sensitive information, you don't care if that URL is known to anybody else, then you can add a meta tag and, like, stick it in your include file for the headers on your site, and bang, now suddenly all of your sites have it.  The meta tag is meta and then name=referrer, with two R's and then ER, so I guess that's three R's total.



LEO:  Are you sure it's three R's?



STEVE:  There's a famous typo.



LEO:  Isn't it misspelled?



STEVE:  It's misspelled in the header, but not in the meta tag.



LEO:  Not in the meta tag, okay.



STEVE:  Yes, because they made a famous misspelling in the spec.



LEO:  One R, R-E-F-E-R-E-R, yeah.



STEVE:  Yeah.  Okay.  So and then the content is one of four values.  So you can say "meta name=referrer" in quotes, and then content equals either never, which is a way to tell the browser that your URLs are sensitive, and you never want them sent out in the user's queries originated from one of your pages.  Or you can say - you can use the keyword "origin," which for example might be you run a search engine and want people to know that the traffic came from you, but not the query tag.  So there the browser will strip off after the - at the end of the URL before the question mark and the so-called "query tail," that part gets removed.  So only the page ID, but nothing afterwards will be added.  Or you can use the tag "default," in which case you get this behavior, where it tries to be smart, where it'll add the URL if it's HTTPS that you're going to, but not if it's HTTP.  Or you can say "always."



And so if you know that you don't have sensitive information in your URLs, and you do want to make sure that clickthroughs to nonsecure sites receive the referrer information, so that you get credit, then you would want to say "always."  And that modifies the behavior of compliant browsers.  Today, Google Chrome and Safari both support this meta referrer addition up in the header.  Firefox doesn't yet, but it's in progress.  And IE doesn't at all.  So very useful information.  Thank you, Alex, for reminding us of that.



LEO:  All right.  Continuing on, Steve, more questions from our fabulous crew.  By the way, you can leave questions at Steve's website, GRC.com/feedback.  This comes to us from Chris Avelleyra in Fort Dodge, Indiana.  He's worried that MAC address randomization might be a problem.  Now, you talked, I bet, last week about Apple's bogus MAC address randomization.



STEVE:  Yes, exactly.  Yup.



LEO:  He says, in fact, he's glad you talked about it, or the lack thereof as the case may be, last week:  I have a question.  I was actually dreading the feature for the following reasons:  I use MAC filtering on my wireless network, so I was concerned that my phone would never automatically connect when I was home and I would have to turn that feature off on my router - I'm trying to learn as much as I can from your podcasts, thank you for the awesome free service - so I'm not clear if MAC filtering is actually real security.  Hey, but I figured every little obstacle would at least prevent the babysitter from logging in, even if she miraculously found my hidden network and guessed the impossible passcode.



Is MAC filtering really a viable, valuable security feature?  If so, well, what happens if you get your wish and iOS truly comes up with a different MAC address every time I try to connect to my home network, or any other network with MAC filtering where my device is allowed, such as a BYOD-enabled work place?  As crazy as it sounds, I might actually want the ability to turn off the randomizer feature.  I'm probably one of the few that really doesn't care if I'm being tracked.  I'm pretty boring, got nothing to hide.  Your insights appreciated, as always.  Chris.



STEVE:  Okay.  So in the first place, there's nothing wrong with MAC address filtering.  But it's a little bit like locking the door and hanging the key next to it.  Because anyone who is going to hack you, who wants to get onto your network, will be looking at a packet sniffer.  And they may realize pretty quickly, when they're getting no response at all from your router, that there's probably a MAC address filter.  All they have to then do is see any other device on your network which is getting a response from the router, and use that MAC address.



LEO:  Spoof it.  Spoof it.



STEVE:  The problem is the MAC address is not part of the encryption.  It's part of the transport.  And transport is necessarily outside of encryption because that's the protocol.  So the problem is, anybody who's looking will see MAC addresses that are valid and passing through the filter, and they can use it.  So, yes.  First, so the first part of the question is, eh, you know, it's not bad to have it if you're someone who likes twiddling with technology and with router configuration.  And of course this means that every time you add another device, you've got to go through permitting it.



LEO:  Now, that's the problem.  It's a pain.



STEVE:  Yes, it ends up being a lot more to maintain.



LEO:  He's also doing, it sounds like, SSID hiding, which is equally worthless.



STEVE:  Yeah.  Yeah.  So the second part is that the randomization, if and when they actually do make it useful, should not be a problem because the phone knows, if it's passively sort of just like probing and looking at WiFi ports, you know, WiFi hotspots, or if it is at your home, and in the past it has connected to yours, and it knows you and yours, and in that case when it's actually making a connection it always uses its proper real fixed MAC address.  So I'm very sure that filtering won't cause the iPhone to have problems.



But also, for what it's worth, Chris, eh, it's not clear that filtering is really buying you as much security as it is sort of annoyance, exactly as Leo says.  Every time you want to bring up a new device on your router, you've got to go figure out its MAC address and add that to the table.  And anybody who is looking at what's going on in the air can see all the MAC addresses that are being permitted.



LEO:  And SSIDs, by the way.



STEVE:  Yeah.



LEO:  Patrick, Laramie, Wyoming.  He has a question about Ethernet MAC addresses in general:  Steve, why doesn't every device use a completely random MAC address?  Why even bother to have a fixed, unique MAC address?  It doesn't make any sense.  Each MAC address is 48 bits, which means if you generate a MAC address randomly, you have a large but non-infinite chance that you'll generate two identical MAC addresses.  It's one in a large number.  You think I'm going to read that?



STEVE:  2^48.  2^48.



LEO:  Oh, yeah, that's not so bad.  It's 281,474,976,710,656.  If you care.



STEVE:  Yes.



LEO:  However, MAC address collision is detectable.  That means that in the case that two devices join the same network with the same MAC address, a collision would be detected, and one or both of them would just generate another completely random MAC address.  The statistical probability that both devices continue to generate the same random MAC address rapidly and aggressively approaches zero.  Problem solved.



Why aren't we doing this?  Is there any reason whatsoever that a device needs a globally unique identifier at the MAC address level?  I cannot see one at all.



STEVE:  You know, it's just historical.



LEO:  No, but also it's - you don't want to have that kind of computation necessary on a dumb device, a cheap, dumb device.  Why do that?



STEVE:  Well, and that's just it.  When Ethernet, the protocol Ethernet, was created, remember those network adapters cost thousands of dollars.  It was several thousand dollars to put one computer on the Ethernet.  And this was - it was discrete components.  And as we've talked about this before, the way the MAC address is segmented is that the first 24 bits, the first half, the left half, is a number given to the manufacturer of Ethernet protocol adapters.  And then the right half they control.  That's their own serial number of adapters within their manufacturing number.



So it was deliberately - and that was sort of a clever approach that Metcalfe came up with to specifically be able to give everything a fixed address and have zero probability of collision.  Today, in this day and age, we toss around the idea of, oh, detect a collision and make up a new address because we could do that trivially with the technology we have now.  But back when this standard was created, that would have cost money.  I mean, it was just like enough that it wasn't even - didn't even begin to be worthwhile.



I actually agree that, in this day and age, it really no longer makes sense, that having a random MAC address would be workable and feasible and cost nothing.  It's not totally true that it's easily - that a collision is easily detected.  You will detect a collision, but it's not in the - it doesn't have the robustness of, for example, packet collision on a shared medium Ethernet wire, where the system is designed for that.  The Ethernet assumes non-collision MAC addresses.  And, I mean, it makes it very unhappy when there is a collision.  All kinds of thing sort of stutter and lock up and stop communicating.  And while that could probably be changed, it's like, well, we have a standard, and nothing's going to happen to change that.  But for what it's worth, as sort of a thought problem, I think it's entirely feasible, if things had sort of come out differently.



LEO:  There's some value to having static MAC addresses, I think.



STEVE:  Yeah.  And it's not going to not...



LEO:  I mean, people are worried about the privacy issue.  But I think there's some value to it.  Howard Matthews in Birmingham, which is still in the still United Kingdom.  He was worried about Scotland, I think.  He's wondering whether higher HDD capacities intrinsically mean faster throughput.  Listening to your discussion about sector interleave got me thinking.  Always dangerous.  I know access times on hard drives are limited by the fact that the heads have to move to the right track.  But once there, the higher the data density, the faster the throughput; right?  So these new 8TB drives ought to be faster in use, let's say, than a 1 or 2TB drive because they've got higher data density; right?  Right?  Right?



STEVE:  That is actually correct.  There are three ways you can increase the density.  You can create the linear bit density, which is the number of bits around the circumference of individual tracks.  You can increase the track density, which is the inter-track spacing.  You lower that, and you get more tracks per inch.  And of course you can add the number of platters.  A platter is going to have two surfaces, so if you have more platters, you have more surfaces.  Only one of those three things, the actual linear bit density, directly relates to data throughput.



But I remember looking carefully at this when I was working on 6.1, and I'll be of course coming back to it as soon as SQRL is behind me, because I was curious.  Are we, like, where are we in approaching the six - now I'm trying to remember what the nomenclature was.  I know there's a three and a six in the SATA spec.  And I guess it's maybe - is it 6MB?



LEO:  Gigabits.  It's gigabits.



STEVE:  Yeah, okay.  So drives are still way slower than that.  So we have headroom before we start saturating the interface between the drive and the motherboard when we're running at absolutely full speed.  Which I was glad for because we seen to keep increasing the density.  And of course now that we've switched to helium-filled drives, that reduces the flying height.  That allows the heads to come closer.  And if the heads are closer, they essentially have more resolution.



And so that'll be the next thing that increases density is lower, closer flying heads because there's a helium bearing rather than an air bearing.  And that also turns out that air was creating a lot of friction.  Helium is lower friction, and that allows the discs to spin faster, as well.  So we just keep pushing these things in ways that are sort of amazing.  But it is the case, yes, higher density means, like as a general principle, means higher throughput because certainly one of the ways they're getting more density is packing more bits per inch around the circumference.  



LEO:  We used to say, remember the days of Stacker?



STEVE:  Yeah.



LEO:  We used to say, oh, well, Stacker offsets the extra overhead of compressing the data by making throughput faster because the data - I don't think that makes any sense, but that's what we said.



STEVE:  We were looking for ways to speed these things up.



LEO:  We just were trying to justify it.  Steve confused Mary the IT Girl in Zephyr Cove, Lake Tahoe about the strength of public keys.  Shame on you, Steve. 



STEVE:  Oh, well.



LEO:  You recently said that Elliptic Curve Cryptography is both stronger and faster than RSA, with far fewer bits in the key.  I'm having difficulty with that concept.  If brute force is the only known attack, how can fewer bits, combined with a faster algorithm, provide more strength?  Hmmm?



STEVE:  Huh.  So I understand.  I mean, that makes sense, Mary, that that's confusing because we're talking about different technologies.  In symmetric encryption, where there is a symmetric key, which is unknown, the way you crack that, given a cipher which doesn't admit any clues, is brute force.  And so it's 2^n, where "n" is the number of bits, and there's that many possible keys.  And assuming a random key and a brute force at random, it's going to take on average half of 2^n, or 2^n-1, guesses in order to - because all you can do is guess at the key.



That is not the way we crack asymmetric, that is to say, public key encryption.  With public key encryption, for example, we have a very different problem.  We've got, in the case of, for example, RSA, we have two prime numbers.  And multiplying them is easy.  Factoring the result when we don't know what the two prime sources were is hard.  And so that's the secret in classic RSA crypto is that we have a problem where - typically in crypto it's called a "trapdoor."  It's a one-way function.  It's trivial to multiply those.



But then when you look at the product, it turns out - so, for example, you don't brute-force that.  You perform a prime factorization of the product of primes, hunting through a vast possible space for the two numbers, both prime, that were multiplied to create that product.  And that's a really hard problem.  In elliptic curve crypto, we essentially have a discrete logarithm problem on a specific curve.  That is, there's a mathematical curve that is described, and then it exists in what's called a "finite field," meaning that essentially we do a modulus, and we only keep the remainder of the values that we're computing within this field.  And when you don't have the whole value, you only have sort of a hint of it, that's a very hard problem.



But again, it's not something you brute force.  There are various ways that cryptographers have of attacking this from characteristics of the encryption, but it's not just sitting there and saying, oh, I've got this many bits, so let's start guessing.  So the confusion arises from the fact that, in one case, brute-forcing is done with symmetric ciphers, and the way you crack asymmetric ciphers is completely a function of the nature of that cipher.



And so what I was talking about with ECC is that, relative to RSA, is that because ECC is harder, that is, we can take problems with very few bits and, for example, like multiply 17 and 13, and then easily figure out what the prime factorization of their product is.  Because the numbers are so small, we can do it easily.  We could take a similarly small domain elliptic curve problem and, given things the same size, the nature of the elliptic curve problem is much more difficult than the nature of factorization at the same size.  And what that means is we can use much smaller numbers with ECC to get the equivalent difficulty.  And the fact that we're using small numbers means that when we're encrypting things, that's much faster.



So, for example, when web servers are wanting to use ECC to encrypt connections, they can do that with much less overhead than if they were using traditional RSA encryption, which because the keys are bigger, to do encryption, it just takes more processing in order to do it.  So that's the whole tune-up on the relative difficulty of cracking different keys in the three different types of crypto.



LEO:  I hope you're happy, Mary the IT Girl.  I just hope you're happy.  Now we move on to our final question, from Birmingham in the United Kingdom, a terrific TNO question from Mark:  Steve, I love the show, long-time listener, proud owner of SpinRite, Password Haystack preacher, Vitamin D taker, SQRL evangelist, blah blah blah.  I wonder if he wears a bearskin hat?  But first-time question proposer.  Steve, the company I work for, like many others, are often looking at outsourcing systems, and I'm intrigued to know more about Trust No One, TNO.  I understand the concept of TNO, but I'm not sure I can apply it when auditing the security of outsourced services.



I understand that some of the telltale signs are if the outsourced service can do a password recovery.  Is this true, and does it apply to recovery methods where you're not supplied with your original password, but are provided with a re-activation link?  What else are the giveaways, the tells?  And what direct questions would you ask vendors?  How can we cut through the sales spiel and determine whether services are actually TNO or whether these suppliers also hold the keys to our data?  If you get 'round to answering this question, it would be greatly appreciated.  If not, I will not think any less of you because the work you do for the show is great.  Much appreciated, the very polite Mark.



STEVE:  So this is a great question.  You know, we've never had it posed before.  I like the question.



LEO:  TNO Tells.



STEVE:  So here would be the test.  You would pretend to be Nervous Nellie, wanting to store your data in the cloud or with this purveyor.  And you would say to them, innocently, with them not knowing that you were a listen of the Security Now! podcast for years...



LEO:  No, because that's a real tell, yeah.



STEVE:  You'd say, okay, we're going to store our stuff with you.  What if we lose everything?  What if we...



LEO:  I like it.  What would you do?  How would you help us?



STEVE:  Yes.  How do we recover if the person that knows the password goes into a coma or is unavailable, and we have to access the data?  How can you help us?  If they can, they are not secure.



LEO:  Right.



STEVE:  They are not TNO.  The idea is, if it's possible for them to help you get your data back without you providing anything, then they can get it back with or without you by definition.  And they could be giving your data to anybody who asked for it, under whatever terms and conditions.  So that's the key.  What you want to hear is them warning you.  You want red flashing neon banners on their site saying, look, we'll store this for you.  But you are entirely responsible for not losing control and keeping control of the access keys.  You want them telling you, and believe me, they will tell you because they don't want the liability, if they can't recover it for you, they're going to make sure you know it's on you.



And if you want TNO, that's who you want.  You want somebody who says, look, just be sure you understand the responsibility you're taking on here.  We can't help you.  We'll store your bits.  But that's all they are to us is pseudorandom noise.  It's on you to be able to decrypt them again.  So if they instead say, oh, well, we have very good security, military grade, in fact, we actually - we have alien technology.



LEO:  Navy Seals.  Oh, okay.  And Navy Seals.



STEVE:  Yeah, Navy Seals.  No, the Navy Seals...



LEO:  Alien Seals.



STEVE:  No, no.  The Navy Seals negotiated with the aliens because you don't want just anybody to do your alien negotiations.  So the Navy Seals did the alien negotiation to get their technology; and, thanks to that, we can recover your data if you lose everything, including all your access control.  In that case, no TNO.



LEO:  It's like that Washington Post article that said, oh, the solution to law enforcement's needs and our needs for privacy...



STEVE:  Oh, the golden key.  The golden magical key.



LEO:  ...is some magical, golden key that's held by unicorns.



STEVE:  Oh, yeah.  Now, it's not a backdoor.  We all agree...



LEO:  No.  No.



STEVE:  ...that there should not be a backdoor.  But if Apple and Google could just come up with a golden key, then, you know, we won't call it a backdoor.  It's the golden key.



LEO:  It's the golden key.



STEVE:  Yeah, mm-hmm.



LEO:  Yeah.



STEVE:  That would be nice.



LEO:  Steve Gibson, GRC.com.  You go there.  You will find many wonderful things, including SpinRite, the world's finest hard drive maintenance and recovery utility; Steve's freebies - all the information you could ever want about SQRL, Vitamin D, Perfect Paper Passwords, Password Haystacks, everything's free except for SpinRite.  SpinRite pays for it all.



STEVE:  Yup.



LEO:  And it's a good place to go if you have questions.  Not via email.  Steve doesn't look at email.  Just go the feedback form, which is at GRC.com/feedback.  He also has 16Kb audio versions of the show.  No one else has that.  He has locked in the market.  He has a monopoly on 16Kb audio for this show.



STEVE:  Yes, it's increasingly less important.  But Elaine really likes it, although she's got a new satellite link.  Apparently she's able to download things much faster, yeah.



LEO:  Elaine takes that 16Kb audio, listens intently, and turns it into a typed transcript of the show, which we...



STEVE:  Often sends me notes in the middle of the night saying, what did this mean?



LEO:  How do you spell that?



STEVE:  I listened to this three times.  Sometimes I go - I'll listen to it, too.  I have no idea what I just might have been saying.



LEO:  Redacted.  No, there's nothing redacted in her transcripts.  But that's all at GRC.com.  We have high-quality audio and video also at our site, TWiT.tv/sn.  If you wish to subscribe, there are many, many podcast apps that will do the job because Security Now! is one of the oldest podcasts in the world and so has, as a result, kind of wormed its way into all the different podcast apps.



STEVE:  Now, when we're talking about Elaine doing the transcribing, and she's transcribing that we're talking about her doing the transcribing, isn't there, like, some sort of an infinite loop Mbius strip thing that happens?  Like when you aim the camera at the monitor, and it goes down into infinity?



LEO:  Yeah, it's the snake eating its own tail.



STEVE:  Yeah, yeah.



LEO:  We do this show 11:00 a.m. - how was that, changing times, by the way?  Did that work out all right last week?



STEVE:  Oh, yeah.  Absolutely.



LEO:  We're back to our regular time, though, 11:00 a.m. - I'm sorry, 1:00 p.m. Pacific time, every Tuesday, right after MacBreak Weekly.  That's 4:00 p.m. Eastern, 2000 UTC.  You can watch at TWiT.tv.  And let's see, what else?  I think that's pretty much everything.



STEVE:  Yeah, I'm completely bemused by Windows 10.  The good news is apparently I don't have to worry about it for, like, until the spring sometime.



LEO:  You know there's a big - and I'm surprised you didn't talk about this, but I'm going to.  There's a big furor over it because in the license agreement for this beta software, not even beta...



STEVE:  This technical preview, yes.



LEO:  They say we have the right to, not only watch everything you do, but we have a keystroke logger to monitor your keystrokes.  That's normal.  That's telemetry.  Instrumentation, sometimes they call it, that is commonly used for debugging purposes.



STEVE:  Especially when you might type something, and it collapses.



LEO:  Right.



STEVE:  It's like, well, it'd be nice to know what you typed.



LEO:  I'm going to take a wild guess here and say they probably won't put it in the release version of Windows 10.  Now, that would be a problem.



STEVE:  Especially now that it's gotten as much press and attention as it has.



LEO:  But, and then people say, oh, well, here's how you disable it.  Don't disable it.  You're making an agreement with Microsoft, if you want to use a technical preview, to help them.  This is about beta testing.



STEVE:  Right.



LEO:  That's what happens.  You can't - you don't get to say, well, I'll beta test it, but you can't know anything I'm doing.  That's not how it works.  That's part of the agreement.  You know I'm an old-timer now when I have to explain.



STEVE:  And besides, you know, Windows 10, at this point, apparently it's got a ways to go.  Paul was saying they're going to be putting all kinds of more stuff in it.  It's like, okay, what you have right now is a shell.



LEO:  Yeah.



STEVE:  You know, it's like...



LEO:  And try it, fine.  But understand that you are now a beta tester, and there are rights and obligations that go along with that.  And that does not include the right to turn off the logger.



STEVE:  Or the crash reporting technology.



LEO:  Yeah, like that.



STEVE:  Which is the reason, the whole reason it's out there.  They're spreading it around in order to make it crash so that they can go, oh, look.



LEO:  Right.  You're helping them.



STEVE:  Why did that happen, yes.



LEO:  And if you don't like it, guess what, you don't have to install it.  That's even easier.



STEVE:  Leo, you do have to, you know, they will give you your money back which you didn't pay.



LEO:  Right.  It's like when people complain about our shows.  I'll be glad to give you a full refund.



STEVE:  Absolutely.



LEO:  Steve, thank you so much.  Always a pleasure.  Lots of fun.  We'll see you next week on Security Now!.



STEVE:  Thanks, my friend.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#477

DATE:		October 14, 2014

TITLE:		Payment Tokenization

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-477.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with another interesting week of security events, including the rumor of a pending SSLv3 flaw and a new Windows zero-day exploit, Steve and Leo examine the next evolution in online payment technology which replaces traditional credit card numbers with "Payment Tokens."



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and he's going to analyze how Apple Pay, or at least how he thinks, what we've deduced about how Apple Pay works, how that's going to change payments in general, and how secure is it.  It's all coming up right now on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 477, recorded October 14th, 2014:  Payment Tokenization.



It's time for Security Now!, the show that covers your security and privacy online with that guy right there.  His name, Steve Gibson, a name you must remember because he is your best bet on the Internet.  I just made a slogan for you.  Hi, Steve.



STEVE GIBSON:  The best bet on the Internet.  Well, okay.



LEO:  He's protecting us, my friends, protecting us.



STEVE:  I'm the only bet you have, and I'm here, and I'm keeping an eye on things.



LEO:  Yes, sir.



STEVE:  So my original working title for today's podcast, I was going to have a little fun and call it "Apple Pray," P-R-A-Y, because they would be praying for it to happen, as opposed to P-R-E-Y, where they would be preyed upon, or other people would be prey.  I thought, okay, Apple Pray, that's kind of fun.



LEO:  I like it.



STEVE:  And I was also initially sort of skeptical, like we commented when the 5 came out, the iPhone 5, that it was missing NFC, and that seemed like a mistake.  And then when they did the second round of 5 with the "s," it's like, wait, still no NFC?  Boy, this seems like a bigger mistake.  Now, finally, with the 6, we have NFC.  But it seems like a heavy lift to where your requirement for Apple Pay is a new iPhone and adoption at the other end of NFC terminals.



But the more I looked into this, I mean, I've spent my spare time this last week digging into what, like the whole back story here.  And I realized this is actually much less about Apple than Apple would like, much less about Apple than all of the technical press seems to think.  I mean, that's, you know, Apple's been like the focus.  Actually it's called Apple Pay, so that makes sense.  But as I looked into it, I realized the good news for, for example, all Android owners, of which there are many more than Apple, and all of whom already have NFC-enabled phones, is that the role Apple has played, and, I mean, and has, like last month and this month, because we're expecting maybe that this is going to get activated in three days, right, on Thursday, maybe with the iPad announcement, and that may be when this actually happens, that Apple ends up being the prime mover.



I mean, there have been efforts at this that have sort of limped along and not quite achieved critical mass.  There are players who thought they could go their own way and have, like, created pieces of this that we'll be talking about in this podcast today, that never achieved critical mass.  And so we all ultimately, I think, owe Apple our thanks for finally getting around to deciding it's time for this.



LEO:  Kind of nudging it along.



STEVE:  Well, yeah.  And it's the...



LEO:  I think it was, you know what, it gave it critical mass.



STEVE:  Yes.



LEO:  And all in position, it was ready, and Apple just kind of pushed it over the edge.



STEVE:  Also, as I looked around, I have a better sense for how much Apple did and what they didn't.  And they did a lot.  But they didn't by any means create this.  Their specification is based on something that began 12 years ago.  And anyway, so I renamed the podcast.  The podcast's name ended being "Payment Tokenization."



LEO:  Well, that's catchy.



STEVE:  It's, well, it's also fitting for this podcast.



LEO:  Trust Steve not to worry about SEO or any of that, you know.  Apple Pray, now, that'd catch some downloads.  Payment Tokenization, that's Security Now!.  And if you listen to this show, that's what you're looking for, frankly.



STEVE:  Well, and the full working title is "Payment Tokenization, or Why Indirection Is a Good Thing."



LEO:  Ah, all right.  I get where you're coming from, dude.  And I think this is a good topic.  You know, Apple will certainly talk about it day after tomorrow.  There was a leaked training memo from Walgreens saying they were going to implement Saturday.  I think the other thing to point out is that Apple timed it because they knew that Congress had mandated and Visa and MasterCard had agreed that we would move to new payment systems next year, chip-and-pin.  And so the old swipe and signature cards...



STEVE:  Swipe and pray.



LEO:  Swipe and pray.  That's the real praying.  Those would become obsolete next year, and most merchants would have to, would be incented to, strongly...



STEVE:  Upgrade terminals anyway.



LEO:  ...upgrade to touch-and-pay terminals to go along with their new chip-and-pin terminals.  So, you know, it's all in one.  So I think Apple is really benefiting as much from that as anything else.  But hey, who cares?  This is going to be good, I think.  We'll find out.  In just a second Steve will explain the security around it and whether you can trust it.  All right, Steve, let's launch into it.  You've got security news, I imagine.



STEVE:  Oh, we always do that.  Okay.  This is Patch Tuesday.  And this is sort of a special Patch Tuesday because a coordinated release of information about a major zero-day exploit, which is patched with today's Tuesday patches, has all been put together.  A security research firm, iSight Partners, identified some time ago something that they're calling the "Sandworm Team."  There are five teams of attackers.  This is my new attempt to use the word "attacker" rather than "hacker."



LEO:  I like that.  That's good.



STEVE:  Yeah, it sits well with me.  I think that's the right thing to do.  They've identified, in Russia, five different Russian groups.  And they see them in teams because they seem to have, aside from teamwork, sort of collective styles by team.  This group uses references to "Dune," the classic sci-fi series.



LEO:  That's sandworms, that's where sandworms come from.



STEVE:  Exactly, in their command-and-control URLs.  Yeah, in their command-and-control URLs and in the various malware samples that have been found.  So it turns out that they've been involved, the Sandworm group, and thus the Sandworm zero-day exploit, has been attacks, targeted phishing attacks, against NATO, Ukrainian government organizations; Western European government organizations; energy sector firms, specifically in Poland; several Western, I'm sorry, European telecommunication firms; and an unnamed U.S. academic organization.  So explicit deliberate attacks have been traced back to this group.



And when the attacks were analyzed some time ago, the iSight Partners group, the security firm, saw the use of a then-unknown flaw which was - I got a kick out of this because it says all supported versions of Windows.  Well, it didn't exist in XP.  XP has always been safe.  It was introduced in Service Pack 2 of  Vista and has been in Windows ever since.  So from Vista Service Pack 2 on is this zero-day, which they analyzed and informed Microsoft of immediately, saying, you guys may need to fix this pretty quickly because this is being exploited right now by Russians against various groups around the world.  So today's Patch Tuesday fixes that, among the regular gaggle of - there's a bunch of .NET vulnerabilities, a collection of remote code execution things.



So, again, standard advice.  This is Patch Tuesday; update your Windows.  Though I would argue that, now that this is known, it's become known, there will be a heightened interest in using it before it gets patched, which means that patching is all the more important.  And I think I remember seeing that they were explicitly using PowerPoint presentations as the delivery vehicle.  So they were sending PowerPoint presentations to people with human factors, social engineering exploits wrapped around them to get people to open these.  And that's the way this stuff was getting in.  It was a vulnerability in the OLE, the Object Linking and Embedding package manager in Microsoft Windows and Server, as I mentioned, introduced with Vista Service Pack 2.  So it affects all versions of Windows up through 8.1 and Windows Server versions 2008 and 2012.



It is an arbitrary code execution vulnerability in something called the "packager.dll."  That's the file that has the problem, which allows the execution of INF files.  So PowerPoint was the entry vehicle that leveraged this packager, as we used to call it, OLE, Object Linking and Embedding, that was part of the evolution of Win32 as Microsoft was moving forward before .NET and all that.  So just I would say don't - either be very careful with anything that might get sent to you, and/or get Windows patched sooner rather than later.



LEO:  Any exploit, well, it's a zero-day, so there's exploits in the wild already; right?



STEVE:  Yeah.  Oh, it's been happening.  And so targeted attacks.  And they've been keeping it relatively quiet and using it while it wasn't known.  So the calculation, the calculus about how to use this changes today with - now that it's become known, there's no reason for those who know of it to keep it quiet.  And analysis of this vulnerability will allow other people to figure it out, to reverse-engineer the patch and make it more widespread.  So this goes from being hush-hush targeted, you know, we know of a vulnerability nobody else knows about, so we're going to be careful not to expose it.  Now the logic is let's use it as fast as we can before people get patched.  So during this Window from disclosure to patch, what we've seen in the past is a flood of attempted exploit.  So the more casual user is now going to be exposed to this, where before it was being used in much more undercover...



LEO:  Spearphishing.



STEVE:  Yes, exactly.  Exactly.  They were using it to penetrate specific organizations.  Nice hat, Leo.



LEO:  Thank you.



STEVE:  [Laughing]



LEO:  There's a reason why I'm wearing this panda hat.



STEVE:  I'm going to just keep focused on my notes here.



LEO:  Someone will explain it to you on Twitter, I'm sure.



STEVE:  Okay.  Speaking of foxes.



LEO:  Yes.



STEVE:  We have a new Firefox v33.  And something happened with 33 that I thought was really nice, which is that we've touched on this off and on, and I know you've talked about it on the network.  And that is the problem with arguably the best compression technology, which is H.264, being encumbered by patents.  And patents have long dogged the high-quality compression because they've always been present.  And so people have sort of had to use less, a little sort of maybe patent-murky alternatives and so forth.  Cisco has finally agreed to essentially open source and license their open H.264 codec.  And with Firefox v33 that just happened hours ago, if you go, if you've got Firefox running and go into Help > About, you'll see that you've got probably 32.02, and it'll immediately start spinning its little wheel and downloading 33.



What's interesting about this is Firefox cannot themselves bundle this open H.264 codec.  But when you load Firefox 33, it will, it itself, your instance of the Firefox browser will go get a verified build.  They figured out how to verifiably download from Cisco a codec built from the source which Cisco has put up on GitHub.  So all of this fancy glue was put together that ends up allowing Firefox to now finally support H.264, you know, arguably the codec everyone wants to support, not, for example, I think it was forced to use VP8, which was the one that sort of had - it kind of came through, what, Adobe and Flash and...



LEO:  VP8 was a Google - wasn't it Google that...



STEVE:  Yeah, that's right.



LEO:  They wanted an unencumbered video codec they were looking for, yeah.



STEVE:  Right, right.



LEO:  And then of course MP4 and the others, owned by somebody.



STEVE:  Yeah.  And now we have H.264, which is available in Firefox.



LEO:  But that's owned by the MPEG Motion Picture Group, that's the problem, you know.  And they've said we'll never charge for that, except we don't know because Microsoft and Apple and all the others are big players in there.  So that's why Google has to do this.  It's a big, you know, you're stepping into a big political fracas that's been going on for some time.



STEVE:  So the good news is Firefox has it now.



LEO:  Yes.



STEVE:  For free.



LEO:  Yes.



STEVE:  And when you load Firefox, it'll go to Cisco and get the codec.



LEO:  Right.



STEVE:  So also...



LEO:  That should be a hint right there that there's a problem, but go ahead.



STEVE:  Yeah.  So faster, snappier searches in Firefox 33.  They did something with JavaScript strings that made a huge difference.  They were recognizing that large text apps like Gmail was taking an awful lot of space when you loaded a whole bunch of JavaScript strings.  And they also noticed that most of the strings, even though they were taking up two bytes because they were unicode, they were strings that would fit in a byte.  And so what this change did, and this is first reflected in Firefox 33, is they're now using 8-bit characters where they can, rather than 16 bits.  And in some testing, for example, they loaded Gmail in Firefox, and in Firefox 32 it took 11MB on this one browser tab to contain Gmail; in Firefox 33, 5.5.  So it cut it in half.  Which you'd expect from a character representation going from 16-bit characters to 8-bit characters. So this is neat for users of heavy JavaScript string apps like Gmail.  So a nice improvement in Firefox 33.



And then they've beefed up session restore.  So I guess there were some ways that Firefox could collapse or crash or your Windows could die or various things could happen where Session Restore would not be there for you.  And it looks like, I mean, they're very bullish about that now in 33.  It looks like they've got that nailed.  And then a bunch of other little things like CSS3 stuff.  Custom counter styles are now supported.  There's some experimental work.  A 4x4 matrix is represented natively, which speeds up 2D and 3D operations for matrix management and multiplication and manipulation and so forth.



So just, you know, it's funny because, as I wrote down 33, I thought, boy, you know, it wasn't long ago we were at v3, and then we moved after a couple years to 4.  And then of course they went on to this whole, okay, we're going to accelerate our versioning and not just move so slowly, which has been a nice change.  And, you know, Firefox continues to stay current.  It and Chrome I think are probably the two browsers of choice now.



Now, all we have is a rumor of something wrong with SSLv3, which is not going to be announced until around noon tomorrow.  So this is Tuesday the 14th of October.  Around noon on Wednesday October 15th the release of information which is known to those who are apparently busily patching SSLv3 right now.  We just don't know what this is.  I picked up something in the grapevine about a version regression problem, like maybe there's a way to cause it to use security suites that you'd rather it didn't use, that kind of thing.  Or maybe it's a TLS problem where there's a way to get TLS to fall back to 3, and then you lose some of the features of TLS that v3 of SSL didn't support.  And it might be, you know, not a big deal.  We just don't know.



I wanted to mention it because I'll certainly be on the lookout for this tomorrow.  I'll tweet what is known, if it's important.  I'm happy to jump on with Sarah for the second round of Tech News in the afternoon if you guys want me to figure out what this means, maybe just say, okay, it's nothing.



LEO:  I'll pass it along, yeah.



STEVE:  Yeah, or maybe it's something.  So at this point we're sort of in this odd place where the news is out that something is going to be announced tomorrow that those who are responsible are right now patching in advance of everyone finding out.  And again, it may be a small thing.  My sense is it's - the phrase that I like is "tempest in a teapot," that it's like not that big a deal.  But, you know, we'll have to wait and see.  So I just wanted to give people a heads-up that there maybe some news.  Oftentimes it seems that things happen on Wednesday, right after the podcast.  It's like Shellshock was a Wednesday event.  It's like, oh, no, we've got to wait seven days.



LEO:  Steve, you just call, we'll get you on this.  We'll figure it out.  Just let me know, yeah.



STEVE:  I also did pick up on another - it's funny, having spent our time talking about supercapacitors some years ago, people now think of this podcast as - I guess their sense is they can send me news of, okay, what does this mean about energy storage, and I'm interested enough in it that I'll figure out what it means, and then I'll tell everybody.



So what's interesting about this is this is a news item that was posted on Physics.org site about sort of where we are is are we going to stay with batteries, or are we going to do something bizarre and new like supercapacitors.  And batteries have the advantage of a huge supply chain in place; lots of electrochemistry understanding. There's already like a big industry in place.  And so if we do something completely new, there's a big tooling time, you know, for like tooling up to implement something.  If we're able to make what is a relatively small change to an existing electrochemistry, then that has the potential to actually happen, which is good because that's when - when the battery gets into our phone is when we care.



So what we have here is that, a relatively small change from the guy that did lithium ion 34 years ago, who's still at it.  And this is changing the traditional lithium ion graphite electrode, the anode in the lithium ion cell, to a gel suspension of a titanium dioxide nanotube.  And nano stuff happens in batteries now because what you need is surface area.  The key is, in order to prevent batteries from dying because the surface area gets corroded and corrupted, and the limitation on charging rate is also a service area deal, the more area you have, the more current you can push into the battery without causing damage to the battery.  And so nano stuff seems to be where we are.  So these nanotubes are, as you can imagine, being a tube, high surface area things, in this case made of titanium dioxide.



The result of this is they have batteries in the lab which are fundamentally lithium ion chemistry, that is, lithium ion electrochemistry, which is well understood, and for which, like, all of this existing manufacturing system already exists, which can be charged to 70% of full capacity in two minutes as opposed to many hours; lasts 10,000 recharge cycles, which is to say has a 20-year life; and is basically an electrochemistry already in place.  So patents are being granted.  Licensees are signing up.  And this could be - this is something, it feels like something that we could see a year from now where the next generation of our portable devices, for example, iPhones with nonremovable batteries, could be charging in minutes rather than hours, and where battery lifetime of a nonremovable battery is no longer an issue.



And of course the electric vehicle market is panting for this sort of thing.  You need the capacity to deliver a tremendous amount of current in a short time.  But this could start to make the equivalent of electric gas stations feasible.  If you can get 70% capacity in two minutes, well, we spend two minutes putting liquid gas, you know, gasoline in our tanks right now.  So the problem is, you know, the typical home doesn't have the ability to deliver that kind of current in that short a time.  So but something like an electric filling station could.  So anyway, we'll see.  But so thank you for those listeners who sent this to me.  I got it from a bunch of people because they said, oh, you know, what does this look like?  And I said it looks good.



Finally, there's been some odd news about Dropbox over the last week, about did they get hacked, was Dropbox hacked.  Pastebin has been the recipient of some several hundreds of login credentials which have been verified.  Before Dropbox neutered them, people were downloading them from Pastebin and logging in successfully to other people's Dropbox accounts.  Which reminds me.  Before I forget about it, I ran across something that I guess started off as a title in a recent security conference that Ars Technica picked up on, and then I saw it there and tweeted it.  I just loved it.  And it's a perfect meme for the Security Now! podcast.  Rather than the Internet of Things, which is the terminology we typically use, for the Security Now! podcast it's the Internet of Other People's Things.



LEO:  [Laughing] I like it.



STEVE:  Which I think is perfect.



LEO:  I don't know if Microsoft would like it, but I like it.



STEVE:  So the Pastebin poster, the guy who's been putting these hundreds of login credentials up on Pastebin, claims that 6,937,081 account credentials have been leaked.  And the use of a number like that is a little convincing.  It's like, oh, you know.  You'd expect an actual number, rather than, oh, almost seven million.  Okay, well, no, 6,937,081.  That many.  So maybe this is a come-on.  We're not really sure what this is because they've sort of posted a few hundred.  Then the attackers are asking for more money.  They're asking for money in return for the release of additional credential data.



LEO:  [Muttering]



STEVE:  I know.  Meanwhile, Dropbox has reset the passwords of all the credentials that have been posted.  And in the latest news, Dropbox responds:  "Dropbox has not been hacked."  They said, quote:  "These usernames and passwords were unfortunately stolen from other services and used in attempts to log on to Dropbox accounts.  We had previously detected these attacks, and the vast majority of the passwords posted have been expired for some time now.  All other remaining passwords have been expired, as well."



So I don't know what the story is.  To me, this maybe looks like a come-on by the people who posted these, saying, look, here are some credentials that work.  So imagine that they in fact got a much smaller number - or say that they took an existing large breach, because there have been large breaches on sort of an ongoing basis.  They attempted to use those to log into Dropbox; found a bunch of people who unfortunately reused their password on the leaked accounts, their leaked credentials, and on Dropbox; gathered those together, posted them on Pastebin, saying not only do we have these hundred, or hundreds, few hundreds, which is probably all they actually have, but we have 6,937,081 more.  Pay us some money, and we'll release those.  Which in fact they may not have.  To me it sounds like they probably don't.



So I think that's the actual, you know, piecing together from what fragmentary information we have, that sort of fits the facts.  So we'll see if anything more comes of this.  But if we're to believe Dropbox, and I think we have to because they made a formal statement, I just don't think there's a major breach of seven million Dropbox accounts.  They're saying no, I mean, they're saying we know what happened.  And that's all.  Which to me makes sense.



And I did want to share a fun note that I ran across.  This was just, okay, this was sort of a blast from the past - you'll get a kick out of this, Leo - and it also incorporates a bit of a SpinRite testimonial from Matthew Power, who is a SpinRite customer.  And he wrote to our support email, saying, he said:  "I'm a very satisfied owner of the SpinRite product.  Since my purchase, SpinRite has brought back THREE [all caps] unmountable drives," exclamation point.  He writes:  "I firmly believe in this product.  Because of SpinRite, people bring me their PCs when the other guys can't get them to boot."



Then he says:  "I see that it is distributed in FreeDOS, which is awesome.  I love SpinRite's DOS shell look."  He says:  "How did you do that?"



LEO:  It's not a look.  It's real.



STEVE:  Uh, exactly.  He says:  "I would love to write a small game with that DOS shell look and feel."



LEO:  Um, okay.



STEVE:  "Maybe run in FreeDOS, as well.  But I have never been able to figure out how to get that look.  Are there any of your free examples I should be looking at?"



LEO:  Aw, cute.



STEVE:  "Or maybe you know of a site I should check out?"



LEO:  He's talking about your ASCII graphics; right?



STEVE:  Well, yeah, he's talking about the fact that it is running in DOS.  It's a DOS app.



LEO:  And you have the DynaStat stuff, but that's all ASCII.



STEVE:  Yes, like my...



LEO:  You're just drawing in ASCII.



STEVE:  Yeah, like, you know, graphs and charts and all that.  And he says, he says:  "Remember when MS" - and then he has a link to Edit.com - "had the orange-block mouse cursor?  That's the look I want.  I have never read anywhere where someone knows how to do that.  And yet SpinRite has it, minus the mouse.  Any help?  Thank you.  Matt."  So I just got a kick out of that.



LEO:  One way to do it, use DOS.



STEVE:  For what it's worth, yes.  He says successfully recovered unbootable systems for people, three unmountable drives, and other data recovery work.  So thanks for sharing that, and a reminder to our listeners that SpinRite works.  And Matthew, if you're listening, yeah, I mean, this is the real deal.  This is SpinRite running in DOS.  Now, 6.1 will remain there; 6.2, where I'm going to see how much more I can do for USB, will stay the same.  But I'm planning to finally leave that environment for SpinRite 7.  I'm going to - I'm not going to put myself under a time constraint for SpinRite 7.



Basically I'm writing 6.1 and 6.2 to buy myself time so that, I mean, basically I don't think 7 will ever be, nothing will ever be able to be faster than the next version of SpinRite.  I'm going all out for performance to meet the needs of contemporary drives that just keep getting larger and larger, so that you'll be able to use SpinRite overnight on a three or four terabyte drive and have it done in the morning.  That's the goal.  7.0 will be all kinds of features that people now want, like simultaneous operation across all the drives they have.  There's no reason I can't do that except none of the existing infrastructure in SpinRite supports that.  Or drive cloning and file system awareness and all these, you know, like the next generation of things that it would be fun to do.  I enjoy developing SpinRite.



So the 6 series, these next things are there to tide me over while I start from scratch.  I'm going to start over.  I found the kit that I want to use.  I'm still going to be natively booting my own system, that is, not hosted on an OS, but doing my own, but with a GUI interface and a mouse and a contemporary UI and a sort of a new foundation that will then, in the same way that a multi-windowed interface does, allow me to grow the product in the future; whereas I'm sort of stuck with, I mean, nice as the DOS shell look is, the user interface is limited.  And functioning in a DOS-based environment, I've sort of reached the limit of what I can do.  So that's where I'm headed in the future.



LEO:  Well, for those who wish to give that great graphical user interface look with DOS and ASCII prompts, there is a library for Linux called Curses - you could write to it with Python or Ruby or anything else, or Bash shell - that'll let you do exactly that.  And it's a library.  I bet you you wrote a library with graphics primitives in assembler.  Steve does his own libraries.  He doesn't use anybody else's.  But for those who don't have access to Steve's assembly language libraries for x86, Curses, C-U-R-S-E-S.



STEVE:  You know what I did, I prototyped - there was a DOS-based tool that Dan Bricklin created.  It was called Demo, Dan Bricklin's Demo.  And basically you moved the cursor around, and you could draw line art and mark blocks and move things around.  And so I - and this has really, this has always been my development style.  I did the same thing with SQRL, for example.  People will remember I completely designed the user interface, and then I wired up behind it.  And I did the same thing with SpinRite.  I designed the UI because I'm UI-centric.  That's what the user sees.  So I think of the product from a standpoint of how it's going to be used.  And oftentimes that gets me in trouble because I'll be overly aggressive.  I'll say, oh, this is what I want it to do.  And then when it comes time to doing it, it's like, oh, this is going to be hard.  But now I'm committed because I know how I want it to look.  Now I just have to make it go.  So, yeah, that's the approach I take.  And it was with that beautiful screen editor that Dan Bricklin wrote.



LEO:  Yeah, and then it probably just output arrays of ASCII numbers that you would then just blast onto the screen, I would imagine.



STEVE:  I wish I could say I did.  Actually I wrote raw native code to implement each page.  But I did write a...



LEO:  Now move over once and put ASCII 374.  Now move over again once and put ASCII 374.  Like that?



STEVE:  Well, I had blocks of text.  I had strings.  And there was a lot of...



LEO:  And you could make - I've done this, I mean, I used to write stuff like this all the time.  You just make an array that contains all - and then you iterate over the array, and it's very quick.



STEVE:  Yes, correct.



LEO:  Very easy.  I'm sure you did that.



STEVE:  I did that.



LEO:  Yeah.  [Whispering]



STEVE:  Okay.  So as I mentioned at the top of the show, I began digging into the back story, essentially, behind Apple's Pay technology, wanting to bring an understanding of it to our listeners for the podcast.  And what I quickly ran into is something called the EMVCo, E-M-V-C-O, as in company, which is an LLC, a limited liability corporation, formed back in 2002, originally by Europay, MasterCard, and Visa, thus EMV, EMVCo.  Then JCB, which was originally the Japan Credit Bureau, joined two years later in '04.  Then American Express joined five years later, in '09.  And then most recently China's UnionPay joined last year.  And so now there are six main entities, each sharing a one-sixth interest in this EMVCo:  China UnionPay, Visa, MasterCard, American Express, Discover, and JCB.



And the charter for EMVCo has been to agree upon standards for moving credit processing forward.  And the major concept is tokenization.  It's the buzzword we heard during the Apple Pay presentation.  But as I guess Apple tends to do, they gave us sort of the feeling that this was all theirs.  Apple, without question, did a lot of work because the spec which exists really should be called a "meta specification."  It describes the players in the dance, but not the details of, at the low level, of how they communicate.



So, and even today that's still somewhat obscure.  There's this notion of - the term is, shoot, I'm blanking on the - oh, the term is "cryptogram."  And it's like, okay, cryptogram.  And so I'm seeing the word used, but nowhere am I seeing a clear description of what it is.  So at least in the meta specification, it's just sort of like, okay, a man behind the curtain, it's there, but we don't talk about what that is in detail here because we're too busy talking about the committee meetings that we had and who does what.



But here's the concept.  The problem with breaches of security is credit cards escape.  Credit cards are being given to the merchant.  Credit cards are being given to, you know, when you pay for your meal at a restaurant.  Credit cards are being put into websites when you purchase things.  And the term is PAN, Primary Account Number.  And so a PAN, P-A-N, is the official term for the user's actual account number, what is currently the only number we have, the account number, which is our credit card.  And of course it's accompanied with expiration and the CVV, the card verification code, the little three- or four-digit thing on the back that you often have to use which is explicitly not on the mag stripe so that it can't be lost if the mag stripe is captured.  So this payment token, what the payment token is, is a stand-in for the PAN, the P-A-N, what we're used to as typically a 16-digit; but it turns out it can vary from 13 to 19 digits, so it could be longer than 16.  I've never encountered a 19-digit one, but they can be.



So this is - so the first thing to know is that this payment token looks like a credit card number.  It is processed like a credit card number.  And in fact it even obeys the so-called Luhn, L-U-H-N code.  That's that deal that helps catch digit transposition, where all credit card numbers, to be valid, there's a sum of nines.  That is, you add the digits up, and essentially you always end up, I remember what the algorithm was, I implemented it for GRC's eCommerce system myself, but anyway, you can look it up.  The idea is that it sort of has - credit card numbers have a built-in checksum.



So the key takeaway here is that what we're being given with a payment token is a pseudo credit card number.  And that's the key.  It's not some base64 thing.  It's not some crypto string.  It's not ASCII.  It's not, you know, it is a credit card number.  And it was done this way because, as it moves through most of the system, there's no difference.  No one can tell the difference.  So, for example - oh, and as best I can tell, I saw one reference to the possibility that it was a per-use token, but largely I think that's not the case.



LEO:  I think that's what Apple said it was.  



STEVE:  And I don't think it is.  In fact, I don't even think it is in the Apple case.  I know, for example, that there is an instance, there's another use where they call them "card-on-file merchants."  And, for example, Amazon is a card-on-file merchant where - meaning that they have their customers' cards on file and so that we're able to log in, reauthenticate, and click the Buy It Now button and, bang, our credit card is charged.



LEO:  So Apple, in other words, Apple hasn't documented this, really.



STEVE:  Correct.



LEO:  Okay.



STEVE:  Correct.  And the documentation that I have seen, and I should say that I've watched, I've sat through really boring webinars of executives who were, I mean, like First Data has one, and there's links in the show notes to the First Data - there's a page there, Leo.  You scroll to the bottom.  There's a 60-minute webinar where the slides don't change nearly often enough.  And people who don't actually seem to know what they're talking about are talking about things nevertheless.



LEO:  No.



STEVE:  And so their terminology, I kind of cringe because it's like, oh, gosh, that's not - that can't be right.  But I'm trying to, like, get the truth out of this.  And but so my belief is - and so there may be a one-time something that is apparently...



LEO:  What Apple said, because I was there...



STEVE:  Okay.



LEO:  ...listening carefully.



STEVE:  Yup, I was listening, too, but go ahead.



LEO:  I believe, I'll go back and check, is that there was a one-time-use token or a one-time-use number, not the credit card number.



STEVE:  Correct.



LEO:  Which would be the token, presumably, and another PIN that's associated with the Touch ID or something else.  But it was a two - it was two factors, or two things.  And I'm pretty sure Apple said one-time use.  But maybe they didn't mean on both.  Maybe the token is not one-time.



STEVE:  So, yes.  So before I forget, because I've been meaning to say...



LEO:  Because maybe Tim Cook doesn't know.



STEVE:  He may have been part of the webinar.  And, like, no, I mean, he wasn't.  This was all First Data people.  But they were in the lab.  One of the guys has used the Apple Pay system 20 times.  He's giddy over the user experience.  And so the way this works is when - okay.  I'm sort of out of sequence here.  Way back in the chain of action, so we have a - say that we're in a retail establishment, and there's a touch pay terminal.



So you've got the purchaser with their iPhone.  You've got the merchant whom you're visiting.  They have, essentially, a provider that they have a relationship with.  And this is a company like First Data.  They're like a credit clearinghouse.  Nova is one.  And for example, that's the relationship I have with GRC's eCommerce system because, as we know, I wrote my own, did all my own eCommerce system from scratch back before I did SpinRite 6.  And so I have a relationship with one of these clearinghouses, direct.  And I don't remember if it's Nova, but like First Data is one and so forth.  So it's not directly with Visa or MasterCard or Discover, but it's one stage removed.  It's with a credit processing, like merchant services company.  And then they tie into the credit card processing network where Visa and MasterCard and American Express and so forth reside.



So there's this pipeline that the credit card goes through.  And what's happened is there's been one more player stuck in this chain on the other side of that payment clearinghouse, in front of Visa, MasterCard, American Express.  And the terminology is a Token Service Provider, TSP, a token service provider.  The token service provider is responsible for maintaining something called the Token Vault.  And the token vault is where the relationship between the actual PAN, the Primary Account Number, which is the credit card number, and the token are maintained.  The token is mostly a random number.  So that's key.  It is not cryptographically derived from the credit card because, if that key ever got loose, then all of the relationships would be vulnerable.



LEO:  You've read this document from Apple, right, that says:  "When you add a credit or debit card with Apple Pay, the actual card numbers are not stored on the device nor on Apple servers.  Instead a unique device account number is assigned" - is this the token? - "encrypted and securely stored in a secure element on your phone.  Each transaction is authorized with a one-time unique number using your device account number."  That doesn't change, obviously.  And instead of using the security code from the back of your card, Apple Pay creates a dynamic security code.  So it sounds like, not only is the credit card number not involved, but it sounds like it's using a one-time number each time.



STEVE:  No.



LEO:  It's not?



STEVE:  No.  What's also in your phone is one of these tokens.  Because as I understand it - and again, unfortunately what we don't yet have is real clarity.  But from the people I painfully listened to, it was clear that the phone actually contains a 16-digit static token.



LEO:  That's the identifier for the phone.



STEVE:  No.



LEO:  No?



STEVE:  That is the - it's the token.  And so here's the process.  And again, I'm subject to the fact that there's still not complete clarity.  When this association is created - so, for example, a user, an iPhone user scans a new card, right, because we know that they're able to do that.  They take a picture of their credit card.



LEO:  Yeah.



STEVE:  The card number is extracted.  The card number is - and there's something called a BIN, B-I-N, which is like the ranges of card numbers.  It turns out that within the 16 digits - for example, people may have noticed, and I don't remember now, but like all cards beginning with 5 are MasterCard.  All cards beginning with 4 are Visa.  All cards beginning with, like, 6 or something are American Express.  Or there's some - so there's a system like that.



LEO:  You can validate these card numbers, obviously; it happens all the time on the web.



STEVE:  But the point is that's actually - the card numbers contain routing information.  So there's this notion of routing.  There's a routing database.  And so the user scans the card.  From this routing information, that number goes to the actual issuing entity, Visa, MasterCard, or whomever.  Now, they are token service providers.  I know that.  So they offer this new service.  But there's also third-party token service providers.



LEO:  Could Apple be one?



STEVE:  I don't think so.  I was looking carefully to see about that.



LEO:  So this is, look it, this is - Apple's unequivocal.  When you add a card to Passbook, its number is never stored or shared on your device or Apple servers.  I mean, that's unequivocal.



STEVE:  I think that's true.  And so here's the point, is that what happens is the credit card number helps the system find the issuer.  Then they request from a token service provider a token.



LEO:  Ah.



STEVE:  And that's where this mapping gets made.



LEO:  Because they have to know whose card it is.



STEVE:  Correct.



LEO:  There has to be a mapping.



STEVE:  And so what looks like a credit card number, but is not, the token is associated with that user's actual - that PAN, which is called the Primary Account Number, which is the credit card number, and that 16-digit number comes back.  The bank also provides the artwork, which is why what we see looks gorgeous.  And the last four digits of the PAN, which is actually the credit card number, that is kept.  So what the user sees is this beautiful-looking credit card art which came from the issuer, from Chase or from MasterCard or whomever.  And they see the last four digits of their actual credit card number, and that's what's used on receipts and so forth, so that they can figure out which card they used to buy something and that.  But that's all that's there.  So their credit card number is not present.  But a stand-in for their credit card number is present.  And so that's what this whole payment tokenization is.



Now, Apple could very well be doing more than that; that is, there could be some additional hocus pocus.  I've heard mention of encryption.  And so what I've said so far, nothing is about encryption.  So the beauty of the system I've just described is it was a tiny change to the existing infrastructure.  Only in this multiparty system, which involves the movement of what looks like, what is credit card numbers.



The idea is that, because we have a routing system that knows how to route based on a credit card number, then we're able to add another entity.  We're able to add this thing called a "token service provider" that provides indirection.  That's where I talk about indirection.  They maintain the so-called "token vault," which remembers the association between the randomly assigned, what looks like a credit card number but is now just a token, and the actual credit card number.  And they own a block of these credit card numbers so that they're routed, so that these pseudo credit card numbers are routed through them, and that's where the mapping occurs.



So the beauty is that the merchant thinks they're taking - and even the merchant terminal thinks it's receiving a credit card number.  And from some people it is.  From some people, they'll still be swiping their credit card.  But Apple Pay users will be presenting a pseudo credit card number which runs through the system through the same process, except because it's a different range of numbers it gets switched over to this token service provider, where it's turned into, at the last stage, it's turned into the actual credit card number as it goes to the final routing stage.  And the beauty of this whole system is your actual credit card number is never exposed.



So, for example, card-on-file organizations like Amazon - oh, and that's the other thing.  There could be and probably will be multiple mappings between pseudo credit card numbers and your one real credit card.  So, and those mappings could be and probably would be offered by, maintained by different token service providers because they would just be happening, you know, like Amazon could choose to use a different token service provider.  And Amazon would decide, we no longer want the responsibility of maintaining actual credit card numbers.  So we're going to swap them for tokens.  And so Amazon says, using a backend API, works with their token service provider and exchanges all of their users' credit cards, actual credit card numbers, with tokens.  And then the whole system continues to work.



Amazon then no longer - actually, one of the things that happens is they no longer need to worry about the full level of compliance because they're not actually - they're no longer storing and needing to encrypt users' financial data.  They have this level of indirection.  And what this means is, because you have an N-way to one mapping, is if breaches and losses of information occur, it's instantaneous to cancel a given organization's mapping.  So if, for example, RSA got hacked, if RSA was tokenized, that is, they were only maintaining tokens rather than actual credit card information on file, they could immediately cancel the tokens, and they would no longer be usable, except there's one other piece of this.  And that is there's this notion, a new notion of domains.



Right now we are in a domainless environment with credit cards, which means that a credit card number is honored no matter where it comes from.  Now, of course credit card companies' security tries to help us out.  We've talked about how like I can't buy gas with one of my cards because it just raises the alarms whenever I do.  And there's also been situations where someone has flown across the country, and then tried to rent a car, and it was denied because they used their card that morning to put gas in their car or to park at the airport, and then suddenly they appear across the country.  And again, security systems go crazy because it's like, wait a minute, there's 3,000 miles' separation between two uses of the same card in six hours.  And so that seems questionable.



Now what happens is Amazon's use of tokens would be tied to Amazon.  So no one could use the token that Amazon received from their token service provider except Amazon.  So this is a whole 'nother layer of security we've never had before.  Similarly, the token that would be issued to Apple, or actually issued to an iPhone user, but it would be known to be an Apple iPhone token, it could never be used as a credit card number by anyone else.  So this is another aspect of this.  And again, this is not Apple's invention.  All of this existed.  And Apple will probably - probably deserves credit as being the entity that finally got this off the ground.



I originally encountered, when I was looking at this, sort of this mythology which has numbers that I think makes it real, that Apple has been aiming at this for some time, that they began work in earnest at the beginning of this year, in January of 2014; that Visa had a thousand people on the project; JPMorgan Chase had more than 300; that it was done under a cloak of super secrecy.  No bank knew of any other's involvement explicitly, but they had to know that Apple was going to be involving as many players as possible.  So it is absolutely the case that Apple will probably end up earning and deserving the credit for being enough of a big player to finally get the system off the ground.  Lord knows it has lots of buzz.



But the good news is that there are an awful lot of Android phones out there that have had NFC capability a lot longer than the Apple iPhone 6.  And given the proper technology at the handset, all of this is available.  So one of the things that became very clear was that, while Apple Pay - the trademarked Apple Pay specifics is Apple and proprietary, and they have some patents.  The system in general is not of Apple's creation.  Everything I described with token service providers and the system of routing and credit card numbers standing in for others, that's all existed before this.  It just it never really happened.  And exactly as you were saying, I think before we began recording, Leo, since chip-and-pin has been mandated to happen next year, and existing terminals will have to be upgraded, now they'll be upgraded with NFC receivers and this touch pay technology.



LEO:  And we all win then; right?



STEVE:  Yes, yes, we all do.



LEO:  Does the Android, the Wallet, Google Wallet, touch and pay, work kind of the same way?  I mean, are they all similar?



STEVE:  Well, the question is the hardware support.  One of the other aspects of this, I mean, there are many cool things.  It's very cool that there's this notion of a domain, the domain validity, where the token was issued, who the token was issued to, and where it is then valid.  Because that means you're not actually using your credit card, you're using your token within a restricted domain.  So that token isn't useful, for example, outside the iPhone.



Well, one of the other new features is, it's a 00 to 99 scale of how confident we are in what they call the "user to token binding," that is, what's the security at the user end?  And one of the things that Apple did - again, I don't always think they do this deliberately.  I think they sort of luck into some of these things.  But I've heard you mention for the last several weeks, Leo, many times on the network you've referred to how good the Touch ID system is on the iPhone.



LEO:  It works very reliably, yeah.



STEVE:  And, boy, I wanted to jump in there and say yes.  I no longer - I used to have mine covered up on my iPhone 5s.  Of course I famously had the typo keyboard, and so I had no access to it.  Now I'm back with the 6.  It has never failed me once.  I did chuckle a little bit watching it training more than the iPhone 5s did.



LEO:  Yeah, yeah.



STEVE:  They learned their lesson.  They needed to give it more samples upfront to get it trained up.  But it just works perfectly.  And so I think with that and with this notion of the Secure Enclave, sometimes referred to as the Secure Element, the idea that you have a coprocessor that is read-only, that is, you can ask it to do crypto work for you, you can say, like, encrypt something for me, or hash something for me.  But it uses a key that it generates internally which it never exports.  There is no API, no way to get that exported.  You can only have it do the work on your behalf and then provide the results, which is really good security.  And that's - it's intimately involved in processing the data from the Touch ID processor in the phone.



And so the point is that Apple is able to assert and substantiate in this rating system in a very high degree of confidence, that is, of security.  And what that lets them do is negotiate a lower cost for transaction through the payment system.  Because, for example, traditionally, there was just a binary.  It was called CNP, Card Not Present, or Card Present.  And card-not-present transactions had a higher cost to them, higher transaction processing fees, because they were regarded as less secure because who knows why the card's not present?  But, you know, it could have been stolen, and so it's not present; whereas - as opposed to a card-present transaction, where you're doing a card swipe.  A physical card swipe means that it's just likely - it's much more likely that it is the user, no, that the user is actually holding the card than some sort of electronic hack happened over the Internet, and that we're doing a card-non-present transaction.



So, for example, all of the SpinRite purchases that I process through our clearinghouse are card-non-present transactions.  And so I pay a higher fee to have those transactions performed than Apple is paying for theirs because they've established a higher level of security, verifiable security for their transactions.



LEO:  Well, I'm looking forward, we'll find out more Thursday, presumably.  I hope Apple will publish more details.  They did put out a security document, didn't they, today?  Somebody said they did.



STEVE:  Oh, okay.  I've not seen it.  And so to sort of explain this, there is something more than I have not found documentation on.  There is something called - it's based on the Visa spec called 3-D Secure.  And that's this cryptogram.  And it's not clear whether it's a hash or whether it's encryption or what.  But one of the things we need is we need the existing system to be able to function with something that is not the user's credit card number.  And that's where this whole token service provider that has issued blocks of tokens from which it randomly creates these associations to the user's actual credit card number.  And then this thing looks like a credit card number and moves through.



So it could be that there is a challenge response mechanism.  There could be additional crypto.  There's something called a cryptogram that we'll get clarification on, and I'll certainly explain what that is as soon as we know for sure what it is.  But in any event, Apple invented some of the glue.  They did not invent this underlying technology, which is good news because it means that - and there was another piece of news that I meant to include, that Samsung, like within the last few weeks, Samsung announced something like this.  And so they may be riding on the coattails and the fact that now that Apple's sort of got these specs up and running, other people are going to be able to do this, too.



So the good news is, I mean, I was a little worried.  If it was only iPhone 6 and people who had compatible terminals, this was going to be a little rough getting off the ground, I thought.  In fact, I saw in one of these webinars they were saying that there's a - that Apple says iPhones have a three-year, typical three-year cycle life, that is, the typical iPhone user is updating every three years.  So they were seeing and preparing for a three-year curve, adoption curve, which in Visa and MasterCard life is probably acceptable.  It's like, okay, yeah, three years, that's fine.  Everyone will be up to speed in three years.  Everyone, within three years, everyone will have an iPhone 6 or 7 or 8, and those will all be NFC-capable and Apple Pay-capable, and off we go.



So the good news is I think that Android users very soon will end up having essentially a touch pay compatible solution, subject to the technology in the phone offering the security that is needed.  And that is scalable.  The APIs now have the notion of what is the security environment at the transaction point.  And that is reflected throughout the entire transaction.



LEO:  So you mentioned at the beginning of the show that perhaps tomorrow there'd be some information about OpenSSL.



STEVE:  Yes.



LEO:  And about 1:00 o'clock, right when we started the show, this was posted on the InfoSec Diary.  There is, there has been an OpenBSD patch which perhaps triggers or gives you some information about what that SSL bug is.  The bug affects SSL3, is critical.  So far there hasn't been any release.  We're waiting for that from OpenSSL.org.  But this is the OpenBSD patch.  And according to InfoSec, Johannes Ullrich writing...



STEVE:  Yup, he's good.



LEO:  This looks like memory corruption/use after free vulnerabilities being patched.



STEVE:  Ooh, that's not good.



LEO:  So give you something, a little homework for tonight, Steve.



STEVE:  Cool.



LEO:  Hey, Steve Gibson, he does this every week, can you believe it?  Unbelievable.  Every Wednesday, or I'm sorry, Tuesday, around about 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2000 UTC, we start talking about security.  And if you don't hear it, you might miss something important.  So make sure you listen every week.  You can watch live, listen live.  But if you want on-demand versions after the fact, we have a whole panoply of choices.  Steve has 16Kb audio at his website, GRC.com.  Also very nicely written transcripts that you can peruse, listen along, or just read them by themselves.  That's probably the smallest form.  Not as much fun as watching; but hey, you know, to each his own.  That's GRC.com.



You'll also find SpinRite there, Steve's bread and butter, the world's finest hard drive maintenance and recovery utility.  Many freebies.  It's also where you should go if you have a question or a comment that you'd like to get to Steve.  He has a feedback form there, GRC.com/feedback.  Doesn't accept email.  You could tweet him.  Sometimes we'll use tweets.  But that's the best place to go, GRC.com/feedback.  You'll also find lots of great freebies, information about SQRL, Vitamin D, carbless diets, everything.  It's all there.  It's just it's like Dr. Bronner's soap bottle.  It's just everything you'd want in one place, GRC.com.  You can also get higher quality audio and video versions of the show at our website, TWiT.tv/sn.  And it's, you know, it's like one of the oldest podcasts in the world.  So - it is.  It is.



STEVE:  Yeah.



LEO:  Eight or nine years we've been in the making.



STEVE:  Yeah.  Other podcasts have come and gone, and we're still going strong.



LEO:  A lot of them.



STEVE:  Yeah.



LEO:  I kind of, you know, I remember when I was mad at Kevin Rose because he did Diggnation because it competed with TWiT.  And, well, that's gone.  And then I was mad at John C. Dvorak because he did Cranky Geeks, and it competed with TWiT.  And, well, that's gone.  So basically we've just outlasted everyone.



STEVE:  Well, and our listeners have.



LEO:  And you have, too, at home, yes.



STEVE:  Yeah.



LEO:  So anyway, you can get it.  There's a TWiT app on every platform, including Roku.  You could watch live.  You can watch after the fact.  There's all sorts of ways to do it.  I don't think it's too tough.  Just Google "Security Now!" and you'll find it.  Thanks, Steve.  We will be back next week.  And we'll probably be doing questions and answers.



STEVE:  Yup.



LEO:  But who knows.



STEVE:  Oh, I think we probably will.



LEO:  Depending on the news.



STEVE:  Yeah.



LEO:  All right.  We'll talk to you next week.



STEVE:  Okay, my friend.  Thanks.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#478

DATE:		October 21, 2014

TITLE:		Poodle Bites

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-478.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a few interesting events from the past week, Steve and Leo take a deep dive into the details of the Internet's latest security "catastrophe" which has been named "Poodle."  Steve first carefully explains the trouble, then debunks it completely, showing why the vulnerability should be fixed but will probably never be exploited.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  You've probably heard about the "frufarah," the folderol, the fracas around this new exploit called Poodle.  Steve says it's just a load of mutton.  The latest on Poodle and all the security news, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 478, recorded October 21st, 2014:  Poodle Bites.



It's time for Security Now!, the show where we cover your security, your privacy online.  We talk about hacks, exploits, attackers, the new word Steve's going to use for bad guys on the 'Net.



STEVE GIBSON:  Yup.



LEO:  Steve Gibson's here.  That's the Steve I'm talking about, of GRC.com, the creator of SpinRite and also a father of spyware.  Not that he made it, he discovered it and created the first antispyware tools.  It's good to see you once again, Steve.  Ten years we've been doing this show.  Almost.



STEVE:  Feels like just the other day you were suggesting this. And I thought, what?  I don't think we have enough to talk about.  In fact...



LEO:  Second show we did on the TWiT network.



STEVE:  We have so much to talk about we don't even get to our regularly scheduled stuff anymore.  It's like, this week was supposed to be a Q&A to follow up on last week's discussion of the tokenizing purchasing system.  And one of my little notes here is just to mention that, of course, Apple Pay went live yesterday.  And in fact my phone, I went over, and it was saying, hey, you can update to 8.1 at any time.  And I thought, well, okay, I'll do it now.  So it's over there doing that.



But what happened was we talked - I mentioned sort of tangentially last week that there were rumors of something that was going to be disclosed, I think I said noon Pacific time on Wednesday, that was, like, synchronized with some particular time in Europe, I don't remember what or why.  But it didn't last that long.  It was just too big.  And so it leaked out later in the day on Tuesday.  And that's the so-called and annoyingly named "Poodle" exploit.  You know, 2014, looking back on it, I hope we're able to look back on it...



LEO:  What a bad year, huh?  God.



STEVE:  It's been a rough year.  Yeah, boy.  Heartbleed, and what was the one we just had?  I'm blanking on it.  Shellshock.  Heartbleed and Shellshock, and now we have Poodle.



LEO:  Oy oy oy.



STEVE:  I'm excited about this podcast because this is a really interesting problem which pulls a lot of the different things that we've discussed over the years together.  People who have not managed to survive with us over the years or, that is, who haven't been here that long, will still be able to follow along.  But what I realized when I was first researching it last week, was that it was nonsense.  It's like, whoa, okay, wait a minute.  It turns out that there is a problem, but nobody would ever attack you that way.  So, and by the end of the podcast, everyone will understand what I mean by that because it's really not that complicated.  But it's got lots of interesting moving parts and details which is the kind of stuff we like to do here. So I think everyone is going to enjoy the next hour and a half or so.  And there really wasn't, other than that, that much news.  But we'll get to that and then dig into Poodle Puddles.



LEO:  All right, Steve.



STEVE:  Okay.  So, like I said, not a lot of news this week.  We did have, I just sort of wanted to mention because a lot of people tweeted it, unfortunately we've got the FBI guy, James Comey, who is much in the news lately, now grumbling at his first official speaking engagement at the Brookings Institution in Washington.  And this is like his first major policy speech, even though he's been at the FBI for 13 months.  I guess someone said, "Come talk to us."  And so he's complaining, not surprisingly, because we've been hearing grumbles of this for the last few weeks, about the encryption, the enhanced encryption in Apple and Google products and now, as expected,  beginning to make noises about maybe it's time for a legislative "fix," in quotes.



LEO:  Oh, oh, a backdoor.



STEVE:  Exactly.  And of course our listeners will know that I felt this happening a couple years ago, which is why I stopped working on CryptoLink, was because it just felt to me like the way the country was going there was going to be some legislation, or if nothing else we were going to go through a painful period.  And we're not in it yet.  We're approaching it.  The Huffington Post covered this, and I liked their reporting of it.  They said that Comey said he understood the, quote - and I love this, this is like poll tested - "the 'justifiable surprise' many Americans felt after former National Security Agency contractor Edward Snowden's disclosures about mass government surveillance."  Yes, we were justifiably surprised, Leo.



But he said, the Huffington Post said he contends "that recent shifts by companies like Apple and Google to make data stored on cell phones inaccessible to law enforcement" have gone too far.  Comey said, quote:  "Perhaps it's time to suggest that the post-Snowden pendulum has swung too far in one direction" - okay, now, I would argue it's still on its upswing, away from center, where it had been.  And he said:  "...in a direction of fear and mistrust.  Justice, he said, may be denied because of a locked phone or an encrypted hard drive."  And when I saw that I got a little chill.  It's like whoa, ho, okay, what, what?  An encrypted hard drive, uh-huh.



So Comey said that the FBI was seeing, quote, "more and more cases," unquote, in which law enforcement officials believe there was significant evidence on a laptop or phone which they couldn't access - so we are talking about hard drive encryption, too - due to encryption.  It's not clear, however, that any of the cases he specifically referenced, and apparently he talked about a murder in Louisiana and a hit-and-run homicide in California, that they could not have been solved with a traditional warrant to cellular service providers.



And then, happily, Matthew Green, our assistant crypto professor at Johns Hopkins who's been much active recently, he was approached by the Huffington Post for his reaction to this, and he said:  "Law enforcement has access to more data than they've ever had.  As a society we're just finally trying to get back to a point where it's a little more in line with what law enforcement would have been able to get back in the '80s," you know, meaning that we have to have some sense of balance here.



And then on background the Huffington Post finished by saying:  "Snowden's revelations have provided a crisis abroad for major U.S. tech companies, which could lose billions as foreign customers leery of American software and devices compromised by the NSA turn to other providers.  Comey said that he was, quote, 'not trying to jump on the companies,' like Apple and Google, that implemented encryption systems closed off to law enforcement and that he believed they were, quote, 'responding to a marketing imperative.'"



So anyway, it's just, okay, I mean, back when the whole Snowden revelations occurred, one of the things we said on this podcast was that this was going to happen, that math is fundamentally unbreakable.  We have unbreakable math.  And the fact that we've been maybe somewhat lackadaisical in deploying it or enforcing it doesn't mean that it's not available to us.  And it really hasn't taken long at all.  What, a year?  Because I think it was just about a year ago.  And look at, you know, the terrain from the protection of the consumer's privacy today looks very different than it did a year ago.



And all of us would argue, I mean, I heard you on MacBreak Weekly covering the China government hacking story, where they were basically using a weak browser to get man-in-the-middle interception of their citizens' access to iCloud and using it to capture their usernames and passwords in order to decrypt their data.  And so it's not anti-law enforcement.  I mean, I understand from the FBI position that's their bias and the way they see it.  But it's truly as much protection against foreign governments and attackers as it is against law enforcement.  I mean, it is just privacy that the math makes possible.



So anyway, we were talking before we recorded...



LEO:  Yes, [indiscernible].



STEVE:  Yes,  you and I both received envelopes from Yubico, our friend Stina Ehrensvrd at Yubico.  My Twitter feed went crazy starting around midnight last night.  Google posted on their blog, and Yubico sent out coordinated news and also provided you and me both with two of their latest toys.  Yeah, you've got the little blue one right there, and then there's a little tiny one called the Neo-n.



Okay.  So Stina and the Yubico engineers have been working with - of course we know that they have a longtime past affiliation with Google because it's one of the reasons that Stina moved Yubico from Sweden over to the peninsula was so she could be here in Silicon Valley in the hotbed of all this.  And of course Google is a major player here.  So she's been working with them, and she's also - I think I read that she's on the board of directors now of the so-called FIDO Alliance.  And the FIDO Alliance is some hundred-plus companies that are all gathered together to try to arrive at an open standard for sort of next-generation Internet authentication.  All of their work is device-based, that is, like the Yubico YubiKey.



And I guess I would characterize it as like sort of heavyweight.  I mean, it is a - there's two specifications in FIDO, and U2F is the lightweight, sort of possible to actually implement specification, as opposed to - I don't even remember what the acronym for the other one is.  But that one is so complex that only one company I'm aware of has got it working, and they're the company that helped to write the spec.  And, you know, they like to sell stuff.  And so it's more in their interest to keep it complicated and license their software than it is to make it open and easy.



And by comparison, because people will say, well, how does FIDO compare to the work I've been doing for the last year on SQRL, SQRL is like super lightweight.  You can explain it quickly and easily and implement it quickly and easily.  It can use hardware, but it doesn't, it's not tied to hardware, where the FIDO stuff always will be.  So there's certainly room for more than one solution in the industry, and we'll see how all this pans out.



But so what Yubico has now is the most inexpensive solution they've ever offered.  That blue key - the blue pill - the blue key you are holding, Leo, is only $18 on Amazon.  And if you're a Prime Member, shipping is free, so it's $18.  And that will not do all of the things we've talked about before with Yubico.  That is, it's not a one-time password, touch the thing and it emits a string of sequentially encrypted one-time password tokens.



LEO:  Because it looks exactly the same as those.



STEVE:  It does.



LEO:  It's going to be hard not to confuse them.



STEVE:  It's pretty much, well, and the blue color, that's how you know, is it's blue.  But it's also much less expensive than their prior technology.  But all it does is the FIDO U2F, which currently is supported by Google and Chrome, but being an open standard can spread if it's going to.  So, and knowing Stina, it'll be spreading.



LEO:  Yeah, see, because here's the old YubiKey.



STEVE:  Yup.



LEO:  It's black.  It does have a little key on it.



STEVE:  As long as you have a color monitor, or eyes, or I guess color eyes...



LEO:  But they also put a little key on the button so that you know it's a little different.



STEVE:  That's true, yeah, so you can - if you can't tell the difference.  So that one's inexpensive and does U2F.  Their newest product is the - oh, and that's called the Security Key.  Google uses the term.  I didn't see Yubico mentioned anywhere on Google's page, which I thought was a little bit - I don't know.



LEO:  Are they the only company doing it?



STEVE:  No, actually.  I think I noticed there was one other...



LEO:  Yubico, they say in the letter they're on the whatever, the panel, the board, the...



STEVE:  Yeah, yeah, exactly.  Anyway, so there's the - I think it's the Neo and the Neo-n are the two other new technologies.  The NEO is 50 bucks, and the Neo-n is 60.  And the Neo-n, the "n" of the Neo-n stands for NFC.  So that gives you near field communications technology.  And both of those are these cute little almost square things that are just sort of like just the plug part of a USB, sort of like you took the YubiKey and snapped it off like where it inserts.  Anyway, those are both available.  And they do, not only the new FIDO U2F, but all the other traditional Yubico protocols - one-time password, something called JavaCard which is another standard, and a couple other standards.



So they're very much standards-based.  And where necessary, Stina goes and creates new standards, like she has with basically the bifurcation of FIDO into U2F, which it's actually possible to use, and the other thing that's not off the ground yet because it's like the Spruce Goose of authentication.  So anyway, if you just go to Yubico, Y-U-B-I-C-O, dotcom, which is what I did this morning, and click on Products, it takes you to a nice grid where you can see the lineup of the various hardware offerings, the suggested retail pricing, and then what protocols each one supports and so forth.  So the good - yeah, then click on Products up there in the menu.



LEO:  I did.  These are - this is where you go.



STEVE:  Oh, but scroll down.  Oh, I'm sorry, on Product, then Hardware.



LEO:  See?  Yeah, that's where I am.



STEVE:  There it is.  Okay.



LEO:  Ah, here we go.



STEVE:  Perfect.  Very nice.



LEO:  Somebody said Neo-n does not have NFC, just Neo.



STEVE:  Uh-oh, wait.  Really?



LEO:  Well, if you trust the chatroom.



STEVE:  Okay.  Well...



LEO:  I'm looking at this, and I don't see NFC on the Neo-n, just on the Neo.



STEVE:  Oh, it does - so it does show it on the - that's weird.  So the Neo is less expensive than the Neo-n.  I don't know, I guess I don't understand that.  Anyway, that's why I recommended people go there, because the grid is comprehensive.



LEO:  I think the only one that has NFC is the Neo.  The Neo-n does not.



STEVE:  Okay.  Maybe that's what the "n" stands for, "not."  No NFC.



LEO:  No NFC, not NFC, yeah.



STEVE:  Anyway, that's pretty much all of our news for the week.  I did want to just sort of - I noted over the last couple weeks that I was getting many more sets of four yabba-dabba-dos.  And I had noted over the summer that that seemed to have sort of disappeared.  And of course the difference is an individual license for SpinRite generates a single yabba-dabba-do when a purchaser obtains a license.



And the way we operate is that corporations can get a license for all of the machines in a single physical site, like whatever, regardless of how large the site is, by having four licenses.  And that just seemed, when I was coming up with the policy, a much simpler way of organizing things because I thought someone might want to try it and see if it works, and then they would have bought a license for one.  So then if they wanted a site license, you have to have some sort of a site license for people who already owned one, or refund their purchase and then issue them a site license, and it just seemed like a mess.  And so I liked the idea of just having X number of regular licenses.



And then it also kind of was really cool with upgrades because if we then had a paid-for upgrade, then they could upgrade their site license by upgrading their individual licenses.  Anyway, just so the idea is that when I hear four yabba-dabba-dos, somebody purchased a four-license site license.  And for whatever reason, in the last couple weeks, there have been, like, they've come back.



So I just wanted to thank people because - actually one of my favorites is when I hear three because that means that someone got one, they checked it out, and then they said, okay, we want to - this thing works.  We want to use it sitewide.  And then they bought three more in order to have a total of four licenses and then have permission to run it on all of their machines within a facility.  So anyway, thank you.  I really appreciate that.  That keeps the wheels turning here over at GRC and lets me do everything else I do.



LEO:  Did you - I guess you explained why yabba-dabba-do and all of that.  We don't hear it anymore, right, because you turn it off during the show.  Every once in a while it will be on by accident.



STEVE:  Yeah.  I mute it because it's a little distracting.  But it was just - what I have is I have a system that sort of monitors the GRC servers.  It's sort of like my custom version of the advertiser you just introduced us to.



LEO:  PagerDuty.



STEVE:  PagerDuty.



LEO:  PagerDuty.



STEVE:  So, and for example, there was a time when we were under denial-of-service attacks, more or less annoyingly frequently.  And so I built a sort of a real-time bandwidth monitor and server monitor that watches all of the things, the processes and servers in our offsite facility at Level 3.  And among other things, it - and it's very cool.  It uses UDP.  It's all custom stuff that I built.  And so I'm behind multiple layers of NAT, and so nothing can get in here.  But UDP, as we know, is able to return up the path that it exited.



So my system here sends out a UDP query every second or two, actually I think it's every two seconds.  It sends out a UDP query just asking for an update.  And that maps through all of the security that surrounds the Fortress of Solitude and Research so that the server, when it receives a query, or the system at GRC, when it receives a query, it assembles a current state and then returns a UDP reply, which UDP doesn't really expect one.  It's just the idea is it might get one.  But the NAT routers have like been opened by the outgoing query.  And so the servers send back a "here's where everything stands" reply.



One of the things in there is the total of SpinRite sales.  And so at this end I look to see if there's been any change.  And if there is, I divide that by the cost of SpinRite, which tells me how many licenses sold, and I emit that many yabba-dabba-do WAV files.



LEO:  So it's modulus SpinRite cost.



STEVE:  It's modulus SpinRite licenses, yes.



LEO:  Oh, I love it.  I think we assume that everybody who listens over the years has learned this.  But, you know, people still come in the chatroom and say, "What are those lights blinking over Steve's left shoulder?"  So we have to assume that there are people here who are not...



STEVE:  What's Fred Flintstone doing in the background?



LEO:  ...hip to the lore of the Fortress of Solitude.



STEVE:  Yeah, exactly.



LEO:  Yeah.



STEVE:  We're going to go from not very technical and what's your Zodiac sign to "Fasten your technical seatbelts."



LEO:  Uh-oh.



STEVE:  But I think everyone's going to enjoy this.  Okay.  So once again the industry suffered another shock.  Much like Heartbleed and - why can't I remember the name? - Shellshock.



LEO:  Shellshock.  You're blanking it out.



STEVE:  I am.  So this was - okay.  And the headlines all were hyperventilating, and people were making sure on Twitter that I had seen this, and I knew what was going on.  And the scary headline title is that there's a new problem with secure connections involving a means of making browsers and servers use SSL v3, and then leveraging a vulnerability in that in order to crack the security of SSL v3.



So immediately, sites popped up on the 'Net to allow people to check whether remote websites had responded to this Poodle problem.  And SSL Labs, of course, quickly added a test to allow anyone to check.  I started getting people saying, [gasp], "Oh, Steve, GRC is vulnerable."  And it's like, okay, everybody.  First of all, GRC is not vulnerable.  Never has been a problem.  I'll explain that at the end of the podcast, why this is not, I mean, independent of this, why it's not a concern for the way I implemented things.



But so here's the story.  Here is exactly what's going on and why, despite all of this, and the fact that none of that is wrong, it's actually not a problem.  The fact, well, I don't want to step on myself, so I'll take us through this.  So what's going on?  As we know, SSL has had problems through time.  It was originally created by well-meaning smart guys at Netscape in order to create a secure link between browsers and servers so that we could do things like have usernames and passwords and cookies that were not in the clear, because before that everything was in the clear.  It was like email is pretty much today.  Just there, there go the bytes.  If you're sniffing the wire, you can see them go by.



So SSL of course started off at 1.0 and has been incrementing sort of slowly and in various amounts over time as problems have been found and fixed.  And we finally got up to the point where we were ready to go to 3.0, and someone decided, let's change the name.  And it's like, oh, really?  Okay, fine.  And that decision never comes off very well.  And in fact that's been a problem because we have SSL v3.0, and then TLS v1.0.  But TLS v1.0 is newer than SSL v3.0.  So not only did we change the name, but we reset the version number.  And so that confuses people.



But then we've moved with TLS.  SSL was Secure Socket Layer, that's what the acronym SSL stands for, because in UNIX world, UNIX thinks in terms of communication sockets.  That's the name of the abstraction for communicating between two endpoints on the Internet.  You create a socket, and then you connect to another socket on a different machine, and then they talk to each other.  So Secure Socket Layer is SSL.  TLS is Transport Layer Security.  So we have a new acronym for the same thing, just a newer version of the same thing.



LEO:  This could all be part of our new show on the TWiT Network, Acronym Olympics.



STEVE:  Acronym Soup.



LEO:  Yes.  Really we should do that.  It'd be a good thing to do, like just give people acronyms and say, "Can you define this?"  Because it's crazy.



STEVE:  You know, I'll bet it would be possible to do an entire podcast where you simply bring...



LEO:  No English?



STEVE:  ...bring acronyms together with small conjunctions where the RC4 and the CBC of the SSL and the TLS...



LEO:  You could.



STEVE:  ...and so forth, yeah.



LEO:  You could, definitely.



STEVE:  So, and actually having listened to Andy Ihnatko on MacBreak Weekly talk about how he wants to use NASA portable audio...



LEO:  As his ringtone, as his ringtone.



STEVE:  It's like, have you ever heard of anything more geeky?  I mean...



LEO:  I think he's the king.



STEVE:  That's my point exactly, yes.



LEO:  The king of the geeks.



STEVE:  Yes.  Yow.



LEO:  Yow.



STEVE:  So, okay.  So TLS is where we are now.  And we went, of course, we started at 1.0, 1.1.  We're now at 1.2.  So there's always a problem as we are moving standards forward with systems that aren't advancing.  And it's, like, not good not to advance, but it's the reality.  So it turned out, when we moved forward to TLS, and clients, that is, users with Windows, Linux, and Mac, and smartphones and so forth, had clients that were initiating state-of-the-art, modern, recently updated, refreshed connections.  They would connect to a server and say, "Hi there.  I know about TLS 1.1."  Because 1.2 is really very much newer.  So probably 1.1.  Maybe, well, certainly 1.2 now.  And there were some servers that said, "Huh?"  And hung up.



Again, if everything worked smoothly, there's supposed to be like a version protocol handshake.  And we've discussed how SSL negotiates.  The idea is that both ends of a connection advertise the highest level of the protocol that they're aware of, and they agree on the highest level they both speak.  So that happens on a monotonic scale in terms of versioning.  But then the client may have a different set of ciphers that it knows about.  So it sends a list of all the ones it knows about to the server.  And then the server browses through those and chooses, in some order, hopefully from strongest to least strong, the ones that it knows about, that it has in common.  And then they agree.



So, and that's a neat theory.  But it has been subject in the past to so-called "protocol downgrade attacks," various ways, I mean, again, bad guys are clever.  And as we know, they only get cleverer.  So we need to protect ourselves against a bad guy coming in, well, I mean, a classic one in the early days, there was actually a null cipher that was in the set of ciphers because the original engineers of SSL said, hey, you know, what if something - if you're trying to connect to a skate key or something, I mean, that has no crypto whatsoever?  So maybe we should allow that.  And so you could actually say, I would like to talk to you over SSL, but I don't have any ciphers.  And the other end would say, oh, shoot.  Well, okay.  And so you'd have an SSL communication with no encryption, which really sort of defeated the whole purpose.



LEO:  Just SL.  There's "S" in the SL.



STEVE:  Exactly.



LEO:  Secure, but not - insecure, ISL.



STEVE:  No, just the socket.



LEO:  Just a socket layer, yeah.



STEVE:  Socket layer, but no secure socket layer.  So, okay.  So when we realized, we the industry, that there were lame servers that were confused if we even mentioned TLS - we'd say "TLS," and they'd just hang up.  It's like, ooh, okay, I guess not.  So browsers learned to, if they got hung up on when they offered TLS, to try SSL.  And if they knew about TLS, they certainly knew about SSL3 because that was the end of the line of the SSL acronym.  So they'd say, how about SSL3?  And at least it was SSL.  So then the server would go, oh, okay, yeah, fine.  What have you got?  And we'd go from there.



So the problem with that is that that opens us to a version downgrade.  That is, if - and this is an "if" we'll be coming back to several times.  If an attacker managed to get into the connection, the classic man in the middle - now, in this case, it's not just an eavesdropping connection, that is, not a passive man in the middle who can monitor, like we now know the NSA likes to do.  This is an active man in the middle which is, again, it's another escalation in attack requirement where somehow the victim's client traffic is passing through the attacker, who is able to change it.



And in the initial packets, which are going back and forth during this negotiation, there have been weaknesses in the past which TLS further strengthens.  But in this case all the attacker has to do is force an error, which is trivial.  It's hard, actually, you've got to balance checksums and do all kinds of things, not to have an error.  But all the attacker does is lead the browser to believe that they are trying to connect to one of these lame servers.  And so the client will go, oh, I guess no TLS here.  Fine, we'll use SSL3.



So the stage-setting portion of this is that we are, today, are subject to this protocol downgrade where a bad guy convinces the browser that the server can't do TLS.  So now we do SSL3.  And so the first part of this is that we're forced onto SSL3 from an active man-in-the-middle attack.  Now we have SSL3 problems which we had deliberately gotten away from, moving to TLS.  And SSL3 has a choice of basically two ciphers.  It can use RC4 or CBC.  And we've talked about both in the past.  I'll give a quick review.



RC4 is a really lovely stream cipher from RSA.  The problem is that, when we looked at it more closely, we discovered that the way it starts up is not secure.  RC4, it's lovely because it's just elegant.  I love it for its simplicity.  You have two tables of 256 bytes.  So, like, basically two vectors.  Or, no, I'm sorry, one vector.  It's two pointers.  One vector, one table of 256 one-byte entries, and two pointers into the table.  And basically, when you give it the key, it scrambles the initial starting conditions into something which is based on the key.  And then, as you run the cipher, it continues to basically swap bytes in the table and, at the same time, emit pseudorandom data.  And you could almost imagine how, if the table wasn't really scrambled up well, then the bytes coming out wouldn't be that random.



And that's precisely the problem.  If the designers had just warmed it up more, if they'd, like, run it for 256 extra bytes, then the table would have always been sufficiently scrambled that it wouldn't have been a problem.  But the weakness turned out to be that the first data being emitted by the RC4 cipher, which is then XORed with the user's plaintext to create ciphertext, it wasn't as random as we needed.  And in fact, even more recently, detailed additional analysis showed that it's worse than we thought.  So RC4 is out.  No one likes it anymore.  We hope no one's using it anymore.  Not only was it used, of course, famously in SSL, but even more famously in the original WiFi protocol, WEP, which is where we really saw it collapse.



Okay.  So the better cipher, although not without its own problems, is CBC, which is an acronym for Cipher Block Chaining.  CBC takes the data in blocks of bytes where the size of the block is the size of the cipher's block.  So let me just say to remind people that RC4 is a stream cipher, meaning that it emits a stream of bytes which are unpredictable, and so you XOR those bytes with your data to get your data encrypted.  And then on the other end you give it the same key.  It generates the same stream of pseudorandom key-based bytes, which are unpredictable.  You XOR those with the ciphertext, and out pops the original plaintext.  So very neat and elegant.



There are problems with a simple XOR cipher, though, such as you absolutely have to make sure you never use the same stream twice because then the whole thing falls apart in interesting ways that we have talked about in prior podcasts.  By comparison, cipher block chaining uses a block cipher like AES, the Rijndael cipher that we're using now, which is 128-bit block.



The Rijndael cipher, and if anyone isn't familiar with it we did a beautiful podcast on it [SN-033] on AES some years ago when Rijndael had been chosen as the Advanced Encryption Standard (AES) cipher for the industry, and that was an NIST-based competition that looked at all the various candidates and said, okay, we like this for - it meets all of our criteria better than any other cipher, so we're choosing it.  That one takes 128 bits, or 16 eight-bit bytes at a time, and converts those, sort of maps them to a different 128 bits, under the influence of a key.  So the key uniquely determines the mapping between the 2^128 possible input bit combinations into a uniquely different 2^128 output.



The problem with CBC is that it is a block cipher, which is to say it only operates in these 16-byte blocks; whereas RC4 you could say, eh, my data is 55 bytes long.  Give me 55 random bytes, which I will XOR with my 55 bytes of plaintext, and out comes 55 bytes of ciphertext.  The problem with block ciphers is they work only in multiples of the encryption block size, which is in this case 16 bytes.  So if you have any data you're wanting to transmit or encrypt which is not an even multiple of 16, you have to round it up with a process called "padding."  You pad the balance out to an even block size multiple so that you can then run it through this block-at-a-time process.



Okay.  So another problem with encryption is that we not only need to encrypt, but we need to authenticate, something we've often talked about, is we need to make this tamperproof.  And Moxie Marlinspike is famously quoted saying:  "If you have to perform any cryptographic operation before verifying the MAC" - the MAC is the so-called Message Authentication Code.  "If you have to perform any cryptographic operation before verifying the MAC on a message you've received, it will somehow inevitably lead to doom."  Which is to say that, when you receive a message, absolutely the only safe thing to do is check to see if it's been tampered with.  Don't do anything else.  First verify that the message is authentic using the Message Authentication Code, the MAC.



Unfortunately, the guys who designed SSL got it backwards.  SSL authenticates, then encrypts when it's sending.  Which means that we have to reverse the process when we're decrypting, meaning that when we get the message, we have to, because it was authenticated, then encrypted, we have to decrypt, then authenticate.  So that breaks this rule of never doing anything other than check for tampering.  We decrypt, then we do the tamper checking in SSL protocol.  And that's a critical downfall in the original design, and it's the way the BEAST attack happened that we discussed a few years back.



And this is essentially a variation on BEAST.  Once we've been able to downgrade the communication from TLS to SSL v3, due to the fact that we decrypt, then we authenticate, it is possible for someone in the middle, in a man-in-the-middle position, very much the way that it happens with BEAST, to probe the communications, to probe the decryption.  The padding at the end of the message is checked separately at decryption because padding is a process of encrypting.  You have to pad, then you encrypt; which means you decrypt, and then you check the padding.  So, and the padding is always by definition from - it's the last block of the cipher is the pad content.



And the way the CBC cipher works, when you're decrypting something that was encrypted with CBC, the second to the last block of ciphertext, that is, the text to be decrypted, is XORed with the last block of plaintext.  So, and it's sort of an unfortunate characteristic of cipher block chaining.  But what that means is that, if an attacker can mess with the second to the last block of ciphertext, they can, that is, by flipping bits in the second to the last block of ciphertext, they can induce bit flips in the last block of plaintext.



What that does is it gives an attacker control over the tail end of the message and allows them to essentially probe the plaintext because what happens is, after the decryption occurs, the padding is checked.  And if the padding is wrong, it'll generate a padding error before it generates a message authentication failure.  And that allows the attacker to essentially probe the plaintext by looking at the errors being returned by the server.



Now, this takes a long time.  This, for example, takes 256, on average - wait, is 128 or 256?  In what I was reading, the analysis kept saying 256.  It seemed to me they ought to be able to get lucky, and it ought to be an average of 128.  So maybe it was a maximum of 256 and an average of 128, which is half the number of possibilities of eight bits.  So they probe one byte at a time in order to obtain the information about the plaintext, then go to the next byte.  So first of all, many of the reports said that it would require several hundred probes.  In fact, several hundred probes gets you one byte of information.  So it's actually several thousand probes in order to get you a chunk of bytes, like a cookie, for example.



Now, okay.  So what are we trying to get here?  Let's step back from this for a second.  The bad guy, the attacker in the middle, would love to, for example, get the session cookie.  Remember that once the user logs in, provides their credentials when they log in, they maintain a persistent session with the remote server because every time their browser, so long as they're logged in, makes additional queries to the remote server, it provides the cookie, saying - reminding the server for every single query, this is who I am, this is who I am, this is me coming back, and here I am again, and here I am.  So that's the session cookie.  And the lengths vary.  Typically they're huge, like long mothers.



So it's going to take many sets of multiple hundreds of probes stepping through in order to extract the cookie.  Now, where do these probes come from?  Well, the probes have to originate from the browser.  That is, the man in the middle, this is all opaque to the attacker who has poised himself in the middle.  They're seeing gibberish go by.  And so because they have an intimate knowledge, because they've forced a downgrade to SSL v3, they know what protocol has been negotiated, but they don't have access to the encryption keys.  That was securely negotiated by SSL3.



So they're being forced to futz with the data going from the client to the server, making changes, introducing errors.  Which means part of this attack requires malicious code in the browser to initiate these thousands of queries.  So one of the reasons the bar is so high on this is that, not only do you have to have an attacker who's positioned themselves in the middle, but the page which is generating these queries has to be running malicious code in the context of the site that you're attacking.  Because, remember, we also have the whole same domain protection that prevents script from obtaining information about any other domain.  It's only able to receive information to look at the domain information for the domain from which the script, its same origin, from which the script originated.



So somehow the attacker not only has to get themselves in the middle, but they have to inject malicious code into the user's browser.  And that causes the browser to be initiating all of these hundreds of queries.  And the attacker has to have some sort of a dialogue, establish a dialogue so that it's able to tell the clients, the malware running in the client, okay, got that byte.  Now what has to happen is the client needs to pad the query by putting some additional stuff in the header to force the cookie to change its byte alignment because the attack requires - the attack operates on the boundary of successive blocks of decryption.  So, first of all, this is very complicated.  And it requires active participation by malicious code in the browser.



Okay.  So let's assume that somehow all of this happens, that an attacker is able to arrange to make that happen.  They have to get themselves in line.  They have to be able to modify traffic.  They have to be able to inject somehow into a session that they've - it's never clear how they can inject anything into the browser.  I mean, this is a secure page.  And all they're able to do with thousands of queries which they've induced the browser to generate, and they're breaking the queries as they zoom by in order to cause the server to generate - in order to send back padding errors that allow the attacker to eventually determine a single byte, then tell the browser, okay, got that one, shift everything down, now I'm going to work on getting the next one.  So it's never been made clear how that malicious script gets running in the browser, but that's another requirement for this.



So the bar for pulling this off requires all of that to be in place.  So I'm going to, after Leo tells us about our final sponsor of the podcast, explain what the official fix is, why GRC doesn't care, and why this entire thing is completely bogus, and not just because it's hard to do, because it's ridiculous.



Okay.  So, first of all, the recommendations in the industry which flew around last week with great gasps and breathless instructions and websites popping up to warn people if somebody still supported SSL 3.0, was either to, well, disable CBC.  Except, what, then you're going to fall back to RC4?  That doesn't work.  So it's disable SSL3 completely.  That was the only remediation anyone had.  I hope people are a little skeptical now that anyone could actually pull this off.  It's not even clear to me how it could actually be done.  But in a minute I'll tell you why no one ever will.



The official fix is very clever.  And that is that, remember how I said, during the negotiation of the protocol, the client provides a list of the ciphers that it supports - that's called the "cipher suite," the suite of ciphers that it knows about -  sends it up to the server.  Server looks over them and picks hopefully a good one that they share, and then that's what they use.



Well, there have been other things in the past that have sort of "overloaded," as the term is in programming, overloaded that with additional meaning.  And there is a pseudo cipher suite called TLS Fallback SCSV, stands for TLS Fallback Signaling Cipher Suite Value.  And it's included in the list of ciphers which the client knows about.  But it doesn't represent a cipher.  It represents an assertion that it knows about TLS because only if it knows about TLS would it know to include it in the list.



And so this is very clever because, if an attacker tried to perform the downgrade attack by faulting that initial handshake, the client would, believing that it had no choice, drop back to SSL3.  But it would still include the TLS Fallback SCSV value.  The server that's also aware of TLS would have seen an, oh, would not have received that initial handshake because the man in the middle grabbed it, blocked it, and returned an error.  So what the server sees is an SSL3 request that includes in the cipher suite negotiation the TLS Fallback SCSV value.  Which is to say, specifically to detect this.  And the server says no.  That tells the server that the client is asking for an SSL3 connection while knowing about TLS.  A client should ask for a TLS connection if it's including the TLS Fallback among its cipher suite values.



So it's a beautiful prevention for this kind of protocol downgrade.  Unfortunately, it's new.  And that means the right solution for this problem is for the endpoints to upgrade to support this.  OpenSSL immediately added support.  If you update to whatever your platform is, if you're a Linux or a UNIX, and you update your system to the latest OpenSSL, it now knows about this.  Now, it's got to be supported at each end.  So we need the servers to update, too.  I imagine next month Microsoft will have a patch for all of their supported servers and platforms, because you can also receive connections on a non-server, to add TLS Fallback SCSV support.  That's the right answer.  That completely solves the problem.



Now, GRC is not vulnerable because I don't use cookies.  In fact, I don't use any state in my ciphers.  I've mentioned this before, but even my eCommerce system operates in a cookie-free fashion.  After the user has provided some information, that's encrypted in a blob for which only GRC has the key and provided back to the user with their next page.  And then when they submit that, the blob is returned.  So at no point does GRC ever have any state information.  No one has to log into GRC.  There is no notion of logging into GRC.  We do have cookies, but that's only for background R&D, to sort of look at statistics of how cookies are being handled by different browsers.  We use it for nothing.



So for anyone who is worried that GRC is still supporting SSL3, yes, I am, and I intend to continue doing so.  I will certainly update the server next month or whenever Microsoft produces the fallback support.  But it's really not necessary because, at least for GRC, there's no danger in falling back to 3.0 because, in the first place, I don't think anybody is ever going to perpetrate this attack, just for reasons of it being so difficult.



But here's the final point.  Not only is it incredibly difficult, it's completely bogus because the absolute requirement to pull this off is that the attacker somehow get malicious code in the client running in the context of the site that is under attack so that queries are being issued to that site, and that it then do these thousands of queries in order to provide the opportunity for the attacker to break the end of the queries in order to generate the padding failures.  Okay?  And that's ridiculous.



If anybody could get script running in the user's browser, even without any fault in the protocol, in SSL, even under TLS 1.2, the latest one, a client could easily use side channel leakage in order to communicate with somebody passively, not even an active attacker, a passive listener on the connection.  The client knows what its cookies are, for example.  That's something you can easily read in JavaScript is your HTTPS server-side authentication or your various cookies.



So the client could simply issue, essentially send out in binary, for example, binary encode the cookie in a sequence of short and long queries:  short query, short query, long, long, short, long, long, short, short, short, long, short, long.  Somebody monitoring just looks at the length of the outgoing query, which is the client, the malicious client they stuck in the user's browser, essentially like using Morse code to communicate the sensitive data out over the wire.  And so a passive attacker can use what is essentially a side channel attack in order to obtain that information.  And that works on any protocol.  It doesn't require any vulnerability.  And it's vastly simpler than this ridiculous thing that's going to get closed up here in a month or two.



So anyway, when I looked closely at what it took to actually pull this off, it looks like what they did was, I mean, they truly did find a problem.  And, yes, there's a problem with the protocol.  That should get fixed.  We always want to fix our protocols.  So any weaknesses should get fixed.  I'm sure this will be.  It's already fixed in OpenSSL.  The other server platforms I'm sure will be pushing out support for TLS Fallback shortly.  So this problem will go away.



But to me it looks like they took a theoretical vulnerability and then reverse-engineered an attack which is so difficult to pull off, if you could arrange, if you could set the situation up that makes that attack possible, then you're already able to do something far more easily and far more damaging against which there's no protection whatsoever, a side channel attack using query length in order for the browser to communicate out to a passive listener.  So there you go.  And Leo is now smoothly shaven.



LEO:  Do I - yes, I am.  And go ahead, kiss that there.  Do you - if I run cookies on a browser, is it worth worrying?  I mean, you're invulnerable because you don't use cookies.  It's just too hard to do this, even if you do use cookies.



STEVE:  Yes.  It's a theoretical attack.  Nobody has ever been attacked by it.  I don't think anybody ever will.  I mean, I just - it's not at all clear how it could ever actually be set up.  We know some pieces, but the requirement to run malicious script in the browser, that's the deal breaker because, if you could run malicious script in the browser...



LEO:  You could do a lot of other stuff, too.



STEVE:  All bets, yes, all bets are off.  You don't need a downgrade attack.  You could do this over TLS 1.2.  It's ridiculous.



LEO:  Yeah.  That's the key here.



STEVE:  So it's like, okay, thank you very much.  Everybody, you know...



LEO:  In the words of Frank Zappa, I think we have - oh, I don't have any audio.  Darn it.  I was going to play a little bit of a Frank Zappa song in which he says "the poodle bites."



STEVE:  Ah.



LEO:  Steve Gibson is at GRC.com.  That's where he gets his mojo and his yabba-dabba-dos.  So be sure you go on over there.



STEVE:  And thank you to our listeners, yes.



LEO:  Yes, buy some SpinRite and make his day.  And Fred Flintstone's day.  You can also, while you're there, find so many other great things, all free.  The only one he charges for is SpinRite.  You've got the Perfect Paper Passwords.  You've got Password Haystacks.  You've got information about SQRL and test implementations and a whole forum on that.  And you have a place where you can ask questions.  And there's always questions for Steve.  You could tweet him because he's @SGgrc on the Twitter.  But you can also go to GRC.com/feedback and leave your questions there.  Do you think - I know this was scheduled to be a Q&A.



STEVE:  Well, let's try for one next week.



LEO:  With any luck we'll have...



STEVE:  As long as the sky doesn't fall, yes, I will suck up our  mailbag from this week and last week, and we'll have a great Q&A next week.



LEO:  Although I'm having to think that maybe this YubiKey may end up, FIDO may end up being part of the show, as well.  But, you know, we have room for that.



STEVE:  Yeah.  And if people ask me a question, then that's a perfect segue.



LEO:  There you go.  Hint, hint.



STEVE:  Yeah.



LEO:  Of course you can also go there to get 16Kb audio versions, the smallest version offered, as well as nicely written transcripts.



STEVE:  Handwritten.



LEO:  Handwritten by a human being.  Steve pays Elaine to do those.



STEVE:  No bots over here.  We do not have Siri at this end, unh-unh.



LEO:  We also have full-quality audio and video at our site, TWiT.tv/sn. And wherever finer podcasts are aggregated, you're sure to find it because it is one of the oldest shows on the 'Net nowadays.



STEVE:  We're surviving everybody else.



LEO:  Yes, we are.



STEVE:  We're like the cockroach of the Internet.



LEO:  Steve, what fun.  Thank you so much for helping us don our propeller caps.  We'll see you next week.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#479

DATE:		October 28, 2014

TITLE:		Listener Feedback #199

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-479.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a lot to talk about.  The Apple Pay currency kerfuffle, more Poodle news, and, yes, lots of questions, lots of answers.  It's a Q&A episode of Security Now!, next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 479, recorded Tuesday, October 28th, 2014:  Your questions, Steve's answers, #199.



It's time for Security Now!, the show where we cover your security, now.  And privacy and, you know, anything that's on Steve's mind.  Steve Gibson is here.  He is the man in charge, not only of Security Now!, but the Gibson Research Corporation.  His website, GRC.com, that's him.  You know, because of the perspective, Steve, of the camera, your hands look massive.  The world's largest hands.



STEVE GIBSON:  I saw a preview of Letterman, and I think Jim Carrey's going to be on, and it looks like he's wearing monster feet.  And of course I think he probably is.  First I thought it was exactly that, that he had a wide-angle lens...



LEO:  Perspective issue, yeah.



STEVE:  Yeah.  But I think he's actually wearing, like, large rubber feet.



LEO:  You never know exactly what's going on with Jim Carrey.



STEVE:  That's true.  So...



LEO:  Hello, Steve.  How are you today?



STEVE:  We're finally getting to do a Q&A.



LEO:  Yay.



STEVE:  We were not overrun by news.  We have some interesting news.  And in fact I'm going to make you go back through the CurrentC issue again, which you just covered on MacBreak, because I think our listeners will find that whole issue interesting.  Maybe we'll do it a little less extensively than you just did.



LEO:  And we're always interested in your nuts-and-bolts take on this kind of stuff, the deep stuff.



STEVE:  Then it turns out that, in the news, although actually not news, or not new, are some very worrisome to many people cookies, like supercookies, which Verizon and AT&T at least have been found to be adding to their mobile users' network traffic.  Then, like bizarre coincidence, RC4, the cipher I was talking about last week that I have always been so enamored of because, for how simple it is, it's just amazingly good, it got an upgrade.  And so I want to talk about that briefly.  And then we've got a Q&A.  So actually I couldn't whittle it down to 10.  We ended up with 11 comments and thoughts and notes from our cust- from our customers.  From our listeners.



LEO:  They are our customers.



STEVE:  Yes.  They're our advertisers' customers, our sponsors' customers, and our listeners.  Yeah.  So we're going to have some fun here for the next hour and a half or so.



LEO:  Steve Gibson...



STEVE:  It's posted.



LEO:  ...has posted this.  He has done the duty.  Done the deed.  So as always, let's start with the week's security news.



STEVE:  So let's talk about the sort of distressing number of retailers who have decided to eschew Apple Pay in favor of their own sort of non-Apple-based solution called CurrentC, which I guess is actually - it's MCX.com is the site.



LEO:  Right.  This is a Walmart product, but these guys have signed up for three years.  And I think they're contractually obligated not to offer Apple Pay.



STEVE:  Ooh.  Now, I would be surprised if that was legal for them to say, like, we agree not to do...



LEO:  Well, that's interesting.



STEVE:  I guess it could be exclusive.  But that sounds like an antitrust sort of deal, where, like, it's hard to imagine that any of them couldn't decide to also...



LEO:  Well, I wonder if these guys, I mean, it's Chili's, it's 7-Eleven, it's Sears, it's Dick's Sporting Goods, it's, you know, there's a huge number of big companies.  K-Mart.



STEVE:  And this is, as I understand it, CurrentC is not a credit card system.



LEO:  That's the point.



STEVE:  It's a debit card system.



LEO:  That's the point.  They didn't want to...



STEVE:  A lot of people need to put stuff on credit.



LEO:  Right.  Well, you could still use a credit card.  This is a system designed to, well, it's not a tap-and-pay system.  You actually get a QR code you have to scan with your phone. 



STEVE:  Yeah.



LEO:  So it's a real - it's a - by the way, major security issues.  I don't know if you've heard this.  But a similar system was tried in China and abandoned.  The Chinese government forced them to abandon it because of security concerns.  For instance, everybody could see that QR code.  Right?  All I need to do is snap a picture of it.  And I can, I mean, there's all sorts of issues with this.



STEVE:  And if we know anything, if we've learned anything from this podcast over the last nearly 10 years, it's that this stuff is difficult to do correctly.  And we don't know anything about, at this point, about the detailed background operation of this, who designed it, where it came from, what the protocols are, what kind of problems it's going to have.  So anyway, just sort of interesting that I guess, if we understand the background of this, these merchants decided that they didn't want to offer credit-based sales where Visa and MasterCard and so forth took their couple percentage points of payment and decided to sort of go their own way.



LEO:  They also want the personal information, which even with a credit card you get some, but you don't get all.  In this case, the contract you sign, you agree to when you download and install the currency app, says they can have even things like your phone's unique identifier, your health information, your Social Security number.  So let's hope they have good security on their end because they've got everything.



STEVE:  This is going to be great material for the podcast.  We're going to - it's like this is wonderful.  It's like...



LEO:  I think it's a nonstarter.  Nobody's going to use this.  It's just dumb.



STEVE:  Well, the fact that you have to download an app is a bit of a barrier because people will just go in, and they just, you know, they want their aspirin or whatever from the drugstore.  They don't want - it's like, what, I have to have an app?  Here's two bucks.  I'm done.



LEO:  We haven't seen the whole thing.  There will be, I'm sure, just as there is - this is very much like a loyalty card.  So there will be incentives.



STEVE:  Ah, right.



LEO:  They'll say "Save $12 if you use CurrentC."



STEVE:  Or it's free aspirin if you, you know, yeah.



LEO:  I mean, there's no way somebody would use this without incentives.  So they're going to have to give you some sort of incentives.



STEVE:  Right.  Right.  Okay.  So the distressing news that has been all the buzz the last few days is it has come to light that Verizon and - and I have verified both Verizon and AT&T are inserting a persistent, unblockable tracking header into their customers' outbound traffic.  Someone put up a site, and I could not do it because this only works over non-SSL.  So SSL, of course, or a VPN, is the way to block this.  And GRC is locked now to SSL because I've got all of the browsers knowing to only connect to GRC.com securely.  But it's less...



LEO:  That may explain why - because I did my Verizon iPhone, and I tried, I went through that site, and I didn't get an ID.  It said "No ID."  But maybe because I - I don't know.



STEVE:  Did you have WiFi on?



LEO:  Yeah, probably.



STEVE:  Ah, and I did, too.  So this morning at breakfast...



LEO:  It'd have to be through Verizon, obviously.



STEVE:  Yes.  And I have - this morning at breakfast I had both my iPhone and my iPad with me.  And the iPad is still grandfathered into the original unlimited bandwidth AT&T plan, so it's the only reason I'm still over on AT&T, although actually now with Verizon being increasingly egregious, I'm there, too, on my iPhone.  So anyway, the site is LessonsLearned.org/sniff - L-E-S-S-O-N-S-L-E-A-R-N-E-D dot org slash S-N-I-F-F.  And I'm not sure how long the page is going to be there.  The guy who put it up said, you know, this may only be here for a few days.  But neither device showed the so-called UIDH header.  When I then turned WiFi off, so that both were going through the cellular carrier, both showed this UIDH.  I'm looking at mine, Mzc5njg5MTI blah blah blah blah.  I mean, it's a long, base64-encoded binary blob.



Now, the way this works is interesting.  We have anecdotal reports that it changes weekly, but it's definitely sticky across multiple days because many people have said, oh, yeah, I checked yesterday and the day before and today, and it's always the same.  So at some point it changes.  But the idea is that every single query that is passing from your device out through the carrier, Verizon and AT&T are both doing this, which is not secured, that is, which is in the clear.  So non-HTTPS browsing, where the transaction is not encrypted, gets this header added to it, courtesy of the ISP.  So every recipient of a query by your device, which means the site you're visiting, but also remember all of the other resources that that page causes your browser to fetch from, like, advertisers, they all receive this cookie, this thing that is persistent, I mean, like very sticky.  It isn't itself immediately useful to them.  They, get this, pay Verizon for information about you...



LEO:  Oh, no.



STEVE:  ...by giving Verizon this token which has sticky but sort of semi-persistent meaning.



LEO:  Oh, no.



STEVE:  Verizon looks it up and then returns information about you in return for money.  So this is Verizon monetizing what they know about you, which of course is everything.  You're the account holder.  And so advertisers are able to exchange money for information.  So Verizon is directly monetizing their relationship with you via this identifying tag.  Now, it also is a tracking tag.  I mean, it turns out there's part of this you can opt out of.  Apparently you can go to Verizon, log in there.  There's some way to turn off their monetization, which is on by default.  But that doesn't turn off the tag.  So you're still tagged.



And if nothing else, this is a way, for example, of bridging across cleaning of your cookies or like if you delete your cookies, but this tag is undeletable because it's not coming from your browser.  It's inserted into the traffic as it leaves the Verizon ISP out onto the broader Internet.  So if somebody had given you a cookie and associated it with this tag, and then you deleted your cookies in order to shake these people off, well, they'd see the same tag they had and be able to reassociate you with a new cookie.



So, you know, it's annoying, and there's no way to turn it off.  You're able to opt into some additional program which is even worse, or opt out of the monetization, which by default you're opted into unless you turn it off.  But otherwise, this is, you know, Verizon deciding we're going to monetize our customers.  And both my iPad, which is on AT&T, and my iPhone, which is on Verizon, are both doing this.  And this site, very conveniently, lets you see this:  LessonsLearned.org/sniff.



LEO:  Verizon announced they were going to do this three years ago.  Here's a CNN article quoting the CTO for Verizon.  It says:  "David Small raised the point 4G will allow users to do even more with their cell phones and other wireless devices, which means carriers will be gathering more consumer data than ever before via their networks.  'All that data about all the facets of users' lives, that's got value,' Small said.  'And that's a revenue opportunity for us.'"  They don't even hide it.



STEVE:  They call it "Precision ID," by the way.  That's their name for this.



LEO:  So this was how they planned to monetize 4G and LTE.



STEVE:  And this has been going on for a couple years. 



LEO:  Yeah.



STEVE:  It just isn't, you know, it hasn't really come to everyone's attention before.  And I think now, post-Snowden, and everyone's way more sensitized to this than we were a couple years ago.  So anyway, this is a simple way to see that it is happening.  Apparently there have been people who've reported that they're not seeing it.  It could be that they've got WiFi on, and they're using their local WiFi.  Our phones and pads and mobile devices will preferentially use that traffic rather than the cellular traffic, if it has a choice.  So I did have to turn mine off in order to see this.  And when I did, I saw my long wacky cookie.  You know.  So it's like, okay, well, I mean, at least we know.  At least we're...



LEO:  At the same conference, the Sprint guy said, "There's a fine line between monetization and consumer trust."  So Sprint showed some sensitivity.  But I do wonder if Verizon's - I doubt they're the only one doing this.



STEVE:  No, we know that AT&T is.



LEO:  Oh, they are, okay.



STEVE:  I've seen my cookie also.



LEO:  So it's not like you can flee Verizon, and it will all be okay.



STEVE:  Correct.  And reports are that T-Mobile is not currently doing it, but I stress the word "currently" because Verizon and AT&T, if nothing else, have paved the way.  So...



LEO:  Well, but T-Mobile, if they're smart, you know, their whole thing because they're No. 4, they try harder, is to provide an alternative to the big guys.  And if they're smart, they'll say, "We don't do it, we'll never do it, you can trust us," something like that.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  Yeah, yeah.  So last week I was talking about how much I like the RC4 cipher.  This was in the context of comparing it to cipher block chaining, which is a lot more complex.  And I sort of refreshed everyone's memory of what RC4 was.  And Bruce Schneier blogged about a paper that was made public at a conference by RC4's original parent, Ron Rivest, and one of his - a guy that he works with, Jacob Schuldt.  And they made a tiny tweak to RC4 to essentially bring it to state-of-the-art strength.



Bruce wrote:  "Last week, Ron" - oh, last week, sorry - "Ron Rivest gave a talk at MIT about Spritz" - which is the name of this updated spritzed RC4 - "a new stream cipher by him and Jacob Schuldt.  It's basically a redesign of RC4, given current cryptographic tools and knowledge."  So, and I think RC4 is, like, 25 years old, so this is a big jump forward.



Bruce wrote:  "RC4" - and I love it because he feels about it the way I do.  He said:  "...is an example of what I think of as a too-good-to-be-true cipher.  It looks so simple.  It is so simple.  In classic cryptographic terms, it's a single-rotor machine.  It's a single self-modifying rotor, but it modifies itself very slowly."  And remember how I described it, as a 256-byte vector, so an array, a linear vector of 256 bytes which can each hold one of 256 values.  You initially fill it up with just zero through 255, and then the key is used to perform swaps so this vector always has one of each value in it, but in a scrambled up order.  And then you have two pointers into that which you move around over time and continually perform swaps.  So that's what Bruce means when he says it's this rotor, as he's describing this vector, is having two terms exchanged over time.



So he says:  "Even so, it is very hard to cryptanalyze."  Now, he's still talking about the original 25-year-old RC4.  "Even though the single rotor leaks information about its internal state" - which is normally a no-no - he says, "with every output byte, its self-modifying structure always seems to stay ahead of analysis.  But RC4 has been around for over 25 years, and the best attacks are at the edge of practicality."  Meaning that even now, and this is why I've continued to stay enamored of it as I've talked about, you know, it's still strong.  He says:  "When I talk about what sorts of secret cryptographic advances the NSA might have, a practical RC4 attack is one of the possibilities."  Because they're becoming uncomfortable with it.



So "Spritz," Bruce writes, "is Rivest and Schuldt's redesign of RC4.  It retains all of the problems that RC4 had.  It's built on a 256-element array of bytes, making it less than ideal for modern 32-bit and 64-bit CPUs.  It's not very fast."  And he says:  "It's 50% slower than RC4, which was already much slower than algorithms like AES and Threefish," which of course is Bruce's own.  He says:  "It has a long key setup, but it's a very clever design."  So when he says that Spritz has the problems that RC4 has, what he means is in the context of today's ultra beefy processors, where we've got three levels of monster caches, and we're able to process 64 bits in a single chunk, a wide block cipher like Rijndael, like, you know, the AES cipher, that fits the architecture of current machines.  So they're able to chew through 128-bit, 16-byte-at-a-time ciphers very quickly.  And in fact, you know, the latest Intel processors have special AES instructions to further improve the performance.



But in the show notes here, I show the entire algorithm of RC4 and the entire algorithm of Spritz.  And basically it's like a couple of assignment statements.  You know, i = i + 1 is the first one for RC4.  And they changed that to i = i + w in Spritz, or that could be any odd number, but they typically leave it at one.  And then the second one is j = j + S[i], meaning that you take the - S is that linear vector.  So you take the i'th element of that S and add it to j.  That's like the second instruction.  Then you swap S[i] and S[j].  And then z, which is the output, you get from taking S[i] plus S[j] and using that as a pointer to pick a value from S.  And that's your output.  That's the entire algorithm of RC4.  And Spritz only adds one line to that.



So, for example, while, yes, it's sticking it on a modern monster processor that dims the lights when you turn it on and is pumping heat out of the back, while that doesn't make sense, putting this in, for example, a medical pacemaker that you're implanting in your chest, where you want a really good cipher that takes no power, that's where this thing makes sense.  Or in fact I saw somebody in the comments on Bruce's blog posting commented that this would be beautiful in JavaScript because anybody could write this.  I mean, like there's no debugging.  There's no arrays.



I've implemented AES myself a couple times in assembler, and even in C.  It's daunting.  I mean, you've got to be very careful.  It's huge.  And yes, you get good performance because it maps onto today's processors.  But this you could - if anyone, for example, wanted a solid cipher that they, as a hobby, could write in a few lines of JavaScript, I'd use Spritz at this point because it gets the job done.  So anyway, I just thought that was very cool, that they added one other assignment statement basically to an incredibly simple algorithm and restrengthened it up to useful, state-of-the-art level.  Very cool.



And Leo, I've been watching you talk about the iPad Air 2.  Mine came, I guess it was, what was it, Friday.  And I watched you do your "close your eyes," you did it with Sarah yesterday, and everyone guesses the wrong one because it's not actually very much lighter.



LEO:  How many, is it grams?  It's not much.



STEVE:  No.  I like it.  I just - it does, to me, I can feel it being thinner.  But your other comment you were dead on the money with.  I'm seeing the battery not last nearly as long.



LEO:  Yeah, see, that's disappointing.  It's a 15% smaller battery.



STEVE:  Yeah.  And while, yes, it's way more...



LEO:  It's more efficient.



STEVE:  ...powerful in terms of, well, remember, yes, more efficient because it's like double the processing speed and, like, what is it, six times more graphics performance.  So, like, it's an engineering marvel.  But frankly, as you have said, do you need - for what I'm doing, I'm checking email and Twitter and reading PDFs on it.  I'm not playing 3D immersive games on my iPad.  And I may seriously bring it back into the house.  I got it because I could use a third one in my - the way I have my world set up, one lives out in the car.  And so I like the idea of having a Touch ID-enabled pad that travels around outside with me.  In case it ever got loose, it would be locked up.  But I'm thinking I'm going to go back to my original iPad Air that has a longer battery life because it is when it's mobile that I care about it being, you know, the battery lasting a long time.



LEO:  And you probably don't do any hardcore processor-intensive stuff.



STEVE:  No, I don't.  I just use it as sort of a reference device.  And it's, as you said, I mean, I like it.  It's a beautiful piece of engineering.



LEO:  Oh, yeah, yeah.



STEVE:  But, yeah, I'm disappointed, actually, that they sort of skimmied down on the battery because...



LEO:  Because there's nobody saying I want it thinner.  It's not like, you know, oh, there's the drum beat, oh, it's got to be thinner.  And I think almost everybody says, yeah, more battery life would be good.  So I don't, yeah, I don't really understand it.



STEVE:  Well, and we got - it got Touch ID, as did the mini.  So that's nice.  So it's like, oh, okay.  And I do agree with Rene's comment.  The screen is just gorgeous.  It has like a - there is like an interesting sort of blue tint, an antireflective coating blue.  I noticed that because I had a panel of LEDs here.  And if I look at them reflected in the iPad screen, they pick up a blue tint.



LEO:  Oh, that's interesting.  Oh, that's interesting.



STEVE:  Yeah.  But and also the colors seem more saturated.  I mean, it is a stunning LCD display.  But I think the conclusion I've seen you reach on your other podcasts, which is, if you already have an iPad Air, eh, no need to feel like, oh, now your old one is obsolete; it's certainly not.



LEO:  Yeah.  And if you have an old, old one, you know, maybe, if things - it's expensive.



STEVE:  Oh, yeah, if you've got one of the old humpback...



LEO:  Yeah.  If you've got an old humpback, you'll definitely know the difference.



STEVE:  Absolutely.  No doubt.



LEO:  Even a 3 you'd notice a big difference.



STEVE:  So I'm trying to think - oh, this is what it was.  I got an interesting note from a Steve Ellison in Bradford, Pennsylvania.  I got a kick out of this.  He called them "SpinRited neologisms abound."  And he said:  "Steve, longtime listener here.  In listening to the discussions about the new term "SpinRited," I wanted to put forth our tech group's take on the term, et al."  He said:  "Working as a technical analyst at a regional campus of a large U.S. university," and he specifically kept himself anonymous for whatever reason, he said, "when we get a spare moment, we like to pontificate on such topics as, 'What should a drive that has successfully passed SpinRite be called?'  'What should a drive that has been fixed by SpinRite be called?'  'What should a drive that fails even after the magic of SpinRite be called?'  So we propose that a drive that has been through a SpinRite operation with nothing bad found should be referred to as having been 'spun.'"



LEO:  Okay.  Okay.  Yeah.



STEVE:  "Penultimately, a drive that is fixed by a SpinRite operation should be referred to as having been SpinRighted," R-I-G-H-T.



LEO:  Right, good.  Like it.



STEVE:  It's been made right, R-I-G-H-T-E-D.



LEO:  Been made right by SpinRite, yes.  Yes.



STEVE:  Last...



LEO:  I think I know where we're going if it doesn't.  Go ahead.



STEVE:  "Last, but in no way the least, a drive that fails even after SpinRite should be referred to as being 'SpinRotten.'"



LEO:  Oh ho, I love it.



STEVE:  So he says:  "Just our - mine, my brother with whom I work, and our work-study students - two cents on some neologisms that should be added to the jargon of the tech mainstream."



LEO:  Oh, lord.  They have way too much time.



STEVE:  Spun, SpinRighted, and it is now SpinRotten.  Yeah.



LEO:  Yup.



STEVE:  Thank you very much, Steve.



LEO:  Eleven questions await us, my friends.  Our question from Kevin in North Carolina concerns random MAC addresses:  Hi, he says.  Hi.



STEVE:  My name is Kevin.



LEO:  Hi.  My name is Kevin, and I am a short-time listener.  I've been listening for the past few months since a friend mentioned your show.  The show is great.  I watched The Screen Savers, so listening to Leo is like running into an old friend.  Don't run into me too hard, will ya?  You mentioned on the last Security Now! that random MAC addresses would not cause any problems, and they provide little value.  I don't think so, Steve.  I think hard-coded MAC addresses are extremely valuable to the enterprise.  Asset management software like HP Asset Management is dependent on MAC addresses to uniquely identify hardware.  Things like Wake on Lan require that you can uniquely identify a computer on a big old network.  Just wanted to include that bit of information for discussion.  See, Steve was saying who cares about MAC address, unique MAC addresses, it's not that important.



STEVE:  Well, okay.  So kinda.  And I guess maybe this is just some clarification is needed because we were talking about - and I didn't make it clear, so my fault - a particular instance of WiFi MAC addresses only in a certain circumstance.  So this was, as we now know, it's actually less useful than we were hoping it was.  This was Apple announcing that, with iOS 8, when you did not have an association with a WiFi connection, when you're walking around in the mall and various retailers are offering free WiFi, rather than your phone in that mode only, essentially broadcasting the phone's Ethernet MAC address, it uses something random.



But for connections and for anything of greater persistence, I mean, like real, real use of your connection, then it absolutely and always falls back to the device's true MAC address.  And in fact, as we learned, it falls back all too often.  Whenever it wakes up to check email, it stops using a random address.  And unless it's really in a deep slumber, unfortunately, the MAC address is not randomized.  But I completely, I just wanted to say I completely agree with Kevin that having that unique tag is valuable.  It's also the case that firewalls lock onto it.  You're able to, although it's not super useful, as we discussed, you're able to block use of routers and things based on MAC addresses.



So it's not valuable for security purposes because it's easily spoofed, but it's one more piece of information that is useful.  And by all means, you know, regular networking equipment in enterprise is certainly not randomizing its MAC address.  It's a static address.  It is typically possible to override that in software, but otherwise I completely agree with Kevin's point.



LEO:  Yeah, and actually, you know, I don't know if they still do it, but I remember the cable companies used to log your MAC address for your cable modem.  And if you changed your cable modem, they'd have to kind of reset it somehow.



STEVE:  Yes.  I think what I remember is, in fact even recently, I think you need to, like, leave yourself offline for some time.



LEO:  Right, pull the power, yeah.



STEVE:  Exactly, and let them sort of forgive you for changing your MAC address.  And that's one, it was always one of the reasons why having a router between you and your cable company was convenient, even if you only had one computer behind it, or you were, like, plugging and unplugging and changing computers.  The cable company would always see the router's MAC address and not the merry-go-round of MAC addresses that the router was having to contend with.



LEO:  Yeah.  And of course having an iPhone with a rotating MAC address wouldn't impact in that in any way.  But just the point being that MAC addresses are used sometimes.



STEVE:  Yeah.



LEO:  Steve in Columbus, Ohio encountered a, wow, $4.80 annual SSL certificate.  He says:  I've been helping a web designer install SSL certificates.  And I don't have much experience with them, but we've been able to work them out together.  Why she asks me, and not tech support from where she bought them, I don't know.



STEVE:  I think actually he answers his own question because, you know...



LEO:  $4.80 is why.



STEVE:  Yeah, you're not going to get much support.



LEO:  Anyway, in the rare instances I need a cert, I use DigiCert after your recommendations.  But when I told her about them, she said, "Oh, no, I'm getting my certs from CheapSSLSecurity.com."  What could possibly be wrong with that?  It's only $4.80 a year.  Steve, how are these so cheap?  Are they just repackaging the free StartSSL certs and putting a small charge on each?  I'm not switching from DigiCert because I trust them, and they have great customer service.  But why the vastly different price?  DigiCert's, what, 140 bucks, versus $4.80?  How can they do it so cheap?



STEVE:  Okay.  So you need to go to the site, Leo, CheapSSLSecurity.com.  Well, I mean, I poked around there this morning when I saw Steve's note.  These are not people I had seen before.  And...



LEO:  Nice clipart on the front, though.  I always like that.



STEVE:  Yeah, she's smiling.  She's happy with her SSL cert.



LEO:  She doesn't know what she's pointing at.



STEVE:  And what did she pay, $4?



LEO:  $4.80 a year.



STEVE:  Yeah.  So the only thing I can figure...



LEO:  It's a Komodo certificate, though.  I mean, that's a good company.



STEVE:  Well, Komodo or, well, that one is Komodo.  Then they have RapidSSL and GeoTrust.



LEO:  Yeah, but they go up.



STEVE:  Now, brand, yes, brand name certs like Symantec, who bought VeriSign, GeoTrust, you know, those are more pricey.  I was glad to see that, if you wanted EV certs, they said that would not be instantaneous.



LEO:  That would be a bad thing.



STEVE:  Yeah.  They tell you that that might take a week, whereas the other one is just moments away.



LEO:  Ooh.



STEVE:  So I think what they must have is a resale relationship, or maybe like some relation, some connection into the back ends of these other companies, and they're just - they're trying to do bulk certificate sales.  I think this is a good thing because, although you may not get the kind of support that you would want, depending upon how technically savvy you are, we were wanting the web to move more towards SSL.  We've just talked about how the only way to avoid the Verizon and AT&T persistent tracking monetizing cookie is over secure connections.  And to the degree that it's possible for a site to secure itself for 44 bucks - I think for some reason $44 a year is one of the offers that I saw there.  It's like, okay, that starts being a lot more feasible.  And actually one of the ways you get that price is by committing to five years.



LEO:  Ah.



STEVE:  So I think it's like - and there's like a dropdown where it's one, two, three, four, or five years.  And we know that the more secure certificates have deliberately shorter lifetimes hooked to them.  So an EV, I think, is a maximum of two years, so you're not going to get as great a discount.  And there are, they have, like, thousand-dollar-plus certificates there.  So they've got the range of them, but they also - they do have them, apparently.  If you want five years' worth, you can get a good price.



LEO:  I think in a way the question should be why are they so expensive.



STEVE:  Yes, exactly.  Because remember, you're right, they're just selling, like, nothing.  They're just selling bits.



LEO:  It's air.  It's bits.



STEVE:  Yeah, it is.



LEO:  I mean, support, you mentioned support.  That is certainly a significant cost.  On a regular cert they have to verify; right?  That's got to cost something.



STEVE:  Yeah, they do.  But, you know, I mean, and so, yeah, right.  I mean, we've had phone calls.  There's an automated process.  There's a manual process.  There is somebody actually, in the case of my EV certs, they did, they looked up Dunn & Bradstreet numbers and verified, like from other sources, the physical address of the organization.  So they really did -  it's why it can take a week.  It can take multiple days...



LEO:  Right.  But that's an EV.



STEVE:  ...in order to qualify, yeah, at that higher end.  So I just think this sort of demonstrates what is still an immature market, that this is changing, and now there is an increasing interest in sites moving to security.  Things like the Verizon super cookie and the increasing interest in having secure connections puts more pressure on sites to add security.  And I'm glad that it's becoming affordable, that there are some affordable choices.  Like Steve in Columbus, I'm not leaving DigiCert.  I'm really happy with, I mean, I want a high-end, high-reputation certificate by GRC.  But not everybody needs that.  Sometimes all you want is just some privacy, and you don't have to have ultra robust verification of your identity.  Just having your domain protected, you know, and those are just called "domain protection certificates" that are so inexpensive.



LEO:  $4.80 inexpensive.  But don't call them for tech support.



STEVE:  Yeah.  They may not call you back.



LEO:  Yeah.  Phil Brick in the Bronx - what a great name.  Hi, Phil Brick here, from the Bronx.  He wonders how to get started with SSL:  I'm not an IT person, nor do we have an IT staff, so I'm filling that position.  We are a company with 10 PCs.  I'd like to increase our level of security.  We have Chrome.  I'd like to add the "S" feature to the site communications.  HTTPS,  he's talking about.  I can't find anyone yet that can tell me who to contact or how to go about achieving that level of security, or even if it makes sense.  Who can I contact for this?  Thank you.  And I guess - can we say his email, his web domain?



STEVE:  I don't know why not.  His email address came from JCJProduce.com.



LEO:  Ooh, it looks good.



STEVE:  I know.



LEO:  I'll take some leafy vegetables.



STEVE:  Yeah.  It's a very nice site.  Clearly somebody - it's JavaScript based because of course I didn't have my JavaScript enabled at first, and so it scrolled off down into oblivion.  So I thought, oh, let me try turning JavaScript on.  And then it all came up and did nice Flash animation or JavaScript or whatever it's doing.  So Phil, if you're listening to this, and I assume you are, that server, that site exists somewhere.  Someone is hosting that for you.  And they certainly know how to help you do this.  So, I mean, so it sounds like someone set this up for this company, JCJ Produce.  It looks like a neat company, like a nice little operation.  And these people are sending you a bill.  So somebody in bookkeeping is receiving a bill.  And so you can contact them and say, hey, we need one of those $4.80 SSL certificates from the question we just discussed before because that's perfect for you guys.  You don't need - I mean, I looked.  There's absolutely no...



LEO:  They're not selling on the site.



STEVE:  Nothing.  They cannot accept information.



LEO:  It's a brochure.



STEVE:  Yeah.  So I would say on one hand you really don't need security.  But if you'd like to add the "S," then I'm sure it wouldn't be difficult to do that.  Wherever that site lives, whoever's sending you a bill every month for your hosting, they know how to do that.  So contact them and say, hey, we want the "S."



LEO:  Yeah.  It's the host that has to do it, not the customer.



STEVE:  Yeah.  Correct.



LEO:  Greg in CONUS - wonder what that is?



STEVE:  Wherever that is.  That's what he wrote.  I thought, what is a CONUS?  Where is CONUS?



LEO:  Something United States.  It sounds like POTUS, you know, it sounds like he might work, you know...



STEVE:  He might be jumping the fence?



LEO:  He might be somewhere, yeah.  He wonders why no one uses DNSSEC:  Isn't it a good thing, Steve?  I installed a Firefox extension called DNSSEC Validator.  It's been several weeks.  I haven't come across a single website that's using DNSSEC.  I thought it was a benefit, like HTTPS.  Surely sites that talk security, for instance SSL Labs, or needs security, for instance banks, should be using it; shouldn't they?



STEVE:  I thought this was a great question because it brings us back to the trend that we see over and over and over, which is people just don't want to change anything unless they really have to.



LEO:  But DNS doesn't come from a client website, it comes from a DNS server; right?  I mean...



STEVE:  Well, it is the case that when your browser looks up the domain, that it would be getting records which could be securely signed.  That is, so what this extension is doing is it's looking to see whether the answer returned from a DNS query is signed.  Is it signed so that, for example, it absolutely cannot be spoofed?  And nobody's really bothering to do that.  I mean, we have all the technology.  It just - it's one of these painful things where it requires - in fact, in the news, maybe, what, a year ago, the root servers finally got signed.  So they are now signed.  And you had to have the signed root in order for the second-level domain servers to be signed because it all has to sort of flow from the root.  But it just isn't a problem.



We've talked about, and I don't remember now what the topic was, but there are really cool things that we could use DNS for, if it was more secure.  I mean, if it was, well, for example, certificate - in fact, now I do remember what it was.  It was certs.  For example, rather than you trusting the certificate chain, if we had DNS security, individual sites could have their DNS essentially verify the certificates that their server is offering, rather than going through the whole certificate hierarchy deal.  And that, I mean, that changes the whole model so that things like a breach with a root certificate provider are not a problem, or trusting all of the roots.



I ran across a story this morning that just sort of didn't make the cut, about how the Chinese government is now trusted by Apple and Microsoft, and people saying, well, okay, so this is a problem because we've been talking about how they've been intercepting the private communications of their own citizens.  And if the Chinese government, not even the Hong Kong Post Office, but it's like China NIC, is a trusted CA, they're able to issue certificates for any web domain in the world.  I mean, they could issue a certificate for - I would choose Google except Google's Chrome is doing its own pinning.  So they can't get away with that.  But most other sites that are not pinned, you know, GRC is also pinned.  But most are not.  And so that's a problem.



So the idea is that, if we had real security on DNS, which is just a matter of deploying it, it's all the technology is there.  It's just not deployed.  And even, like, the latest OSes, they're DNSSEC aware.  But it's just the sites in the middle that just like, well, okay, we really don't need it, so we haven't done it.  And at some point there will be some driving force.  Or perhaps when it's turned on by default, when you set things up, and it's easy to do, then they'll just sort of drift into use.  But as Greg notes, nobody's bothering right now.



LEO:  By the way, the chatroom tells me that CONUS, C-O-N-U-S, is a commonly used military designation for the Continental United States.



STEVE:  Ah.  So he's hiding somewhere on the dirt somewhere.



LEO:  In plain sight, yeah.



STEVE:  Yes.



LEO:  Karl in Chicago's next.  He wonders whether those Poodle attacks maybe are a little easier than we said last week:  In doing additional research on Poodle, I've come across this claim several times.  This is a quote taken directly from ImperialViolet.  We knew they'd weigh in:  "An attacker can run JavaScript in any origin in a browser and cause the browser to make requests with cookies to any other origin."  Am I missing something stupidly obvious?  I thought preventing cross-site requests was the whole point of JavaScript's same-origin policy.  If so, then how is this possible?  If it's true, well, it does seem to significantly lower the bar for being able to pull off a successful attack because I thought the malicious JavaScript needed to have same-origin privileges and could thus only be injected when connected to the site being attacked.  Thanks for a great show.  Karl.



STEVE:  So Karl is completely correct.  And when I read that, I thought, what?  And so I went over to Adam Langley's ImperialViolet blog, and I...



LEO:  He's the Googler that you knew would respond.



STEVE:  Yeah.  And I searched for "can run JavaScript" or "in any origin" or some little substring.  And, bang, there it is, and it's completely in context, not taken out of context.  That's what he's saying, and it's completely wrong and irresponsible.  I'm just, it's like, oh, come on, Adam.  I mean, this is upsetting and confusing people.  And it's not true.  It turns out that a Chrome extension, if the extension is explicitly given permission to act cross-domain, and there's like a wildcard domain construction that allows, for example, you to use *.google.com so that Google could have their own assets cross-domain, like cross-subdomain, then in that case it's possible.  And then there is also a W3C extension which is sort of working its way through standardization where, if servers explicitly give permission to the browser for cross-domain privileges, then it's possible.



So essentially what we're seeing here is that the same-origin policy is absolute.  And the restriction that that imposes is chafing a little bit on people like Google that are wanting more scripting freedom.  They're wanting to do increasingly aggressive and arguably amazing things in a browser container.  And so the same-origin policy is restricting what they can do, as it was designed to do.  And as it restricts the Poodle attack.  And so for him to just say an attacker can run JavaScript in any origin in a browser and cause that browser to make requests to any other origin, well, it's not true.



LEO:  It's prevented by all implementations of JavaScript, including Chrome.



STEVE:  Yes.  Unless the environment has explicitly softened that restriction.  And it only does so knowingly, and to only other specific domains, because this is so dangerous.  I mean, it's the same-origin policy, it's only that that makes any of this, what we're doing with scripting today, in any way safe.  So it's like, wow, okay.  Anyway, so Karl, that explains it.  You're not missing something stupidly obvious.  You're correct in your thinking that blocking cross-site scripting requests is the whole point of JavaScript's same-origin policy.  And it's only when the server, or in the case of Chrome, a Chrome extension has deliberately put rules in that weakens that, that it is possible.  And so it's unfortunate that Adam is trying to make this look worse than it really is.



LEO:  I wonder what his motivation is in that.



STEVE:  I don't know.  He's, you know.  He's on a roll.



LEO:  Yeah.  Josh Gardner in San Antonio, Texas wonders what we're all waiting for:  With SSL 3.0, why are we still supporting 18-year-old technology?  I mean, sure, I get it for compatibility reasons.  But really?  At this point, shouldn't we move on?  I mean, SSL 3.0 was introduced in 1996.  That's 18 years ago.  TLS 1.0 in '99, 15 years ago.  TLS 1.1 in 2006, eight years ago.  At this point, shouldn't we be moving on?  Seems like a bad idea to put a current technology at risk to support 15-year-old security for devices that frankly are unlikely being used at all.



STEVE:  And the problem is, as we have found, it turns out these things are still in use.  And even more...



LEO:  By XP.



STEVE:  Yeah, exactly.  When Mozilla tried to turn that off, they got bit, and suddenly 10% of their downloads disappeared.  So it's like, ouch, turn that back on again.  So, unfortunately, I think this is only going to get worse with time.  The good news is, as we know, SSL 3.0 isn't that badly broken.  But it is things like Poodle that create some pressure that finally induce people to start turning it off.  But as these protocols get baked in the cake, as they say, you know, like people's microwaves, and their light bulbs - and the Internet of Things is going to have, already does have some of this stuff in it.  And then the companies that made those go out of business, or they stop supporting them.  And now you're stuck with something that's arguably vulnerable, that will never be updated.



So, I mean, it seems like we're in this mode where we're seeing this protocol spread over time.  We're fixing things and creating new technologies, yet getting them adopted is, I mean really is difficult.  The only thing I could imagine would be if there were some mechanism whereby they, like, forcibly expired.  Notice that that's what certificates do.  And on the other hand, notice the trouble that it causes because every so often we'll see, like, oh my god, Twitter's cert expired.  They're off the 'Net.  I mean, because people get caught out by those sorts of forcible expirations.  So when we have forcible expirations, that causes problems, too.  We could argue that maybe that's the lesser of the two evils.  It's just sort of not clear.



So this is just sort of, I think, unfortunately innate to where we are.  And a perfect example of, for example, we were talking about DNSSEC, which is having a hard time getting adopted because it's just, like, well, DNS is working without it, so I guess maybe we'll do it when we have to, when something makes us.  Just like finally abandoning this, as Josh says, 18-year-old technology, SSL 3.0.



LEO:  Guillaume Auclair in Sherbrooke, Quebec, Canada shouted in the subject line:  OPEN VPN LEAKAGE!  Warning, warning.  Danger, Will Robinson.  Sorry, Steve.  I had to catch your attention.  I'm a long-time listener and follower, blah blah blah.  I've been using proXPN for quite some time now, and I thought I was protected against my ISP's snooping.  But I have a dedicated Linux box on my network, and its sole purpose is to be a VPN proxy.  That Linux box connects to proXPN and has some IPtables rules to allow it to only get to the outside world through the VPNed "tun0" tunneling interface.  And on the other hand, that Linux accepts requests from the local network, all this behind an Astaro UTM - wow, this guy, wonder what he's doing? - which has rules to only allow that Linux to reach proXPN and proXPN only.



Now, I thought I was preventing my ISP from watching what I was doing because, from what I thought I knew, my packets were wrapped inside a packet that was addressed to proXPN, and then only proXPN was really seeing what my packet was after decrypting it.  I know someone who is an architect in IT for a big bank here in Canada, and he assured me the content of the packet was encrypted, but not the header, so that OpenVPN is in fact leaking some header information, thus exposing to my ISP some information about what I'm doing.  Is that true?



STEVE:  No.



LEO:  Oh.



STEVE:  The good news is I know absolutely positively because I'm using OpenVPN, and I dug all the way in.  And, for example, one of the things that you need to do is that OpenVPN tunneling interface needs to advertise a smaller packet size for its use over UDP so that the packets coming from the origin system are small enough to be enclosed within a UDP packet which is the container.  So maybe the IT architect guy at the big bank in Canada just is like - maybe it's just like some confusion of terminology.  It is certainly the case that all packets have headers.  But an analysis of the packets, that is, going from that system to proXPN, all it's going to show is packets going from that system to proXPN.  The content is inside the payload, which is absolutely encrypted.  Everything, the entire packet is encrypted.  So it's leaking zero information about the packet's original pre-encryption, pre-tunneled data.



And actually he's got a really neat setup.  So he's using proXPN as a static VPN so that, like, he's not like having to connect and disconnect.  It's his home network has a persistent OpenVPN connection to proXPN.  So all of his traffic is always running through that VPN out on to the Internet.  And his ISP is absolutely 100% blind to what he's doing.



LEO:  That's awesome.



STEVE:  Really very cool stuff.



LEO:  Nice job.  And he has an Astaro UTM in there and everything.



STEVE:  Yup, yup.



LEO:  Leo Laporte, Steve Gibson.  On we go.  Question number - I had it right here.  Eight, eight.



STEVE:  Ari.



LEO:  Ari in South Africa.  He has observed that the FIDO U2F YubiKey is very different:  Steve, there seems to be a big difference between the old YubiKey, covered in a prior episode [SN-143], and the new blue YubiKey.  Seemingly contradictory quotes from their website read, quote one:  "The key pairs are generated on the device, in the secure element, but the key pairs are not stored on the Security Key.  Instead, the key pair, public key and encrypted private key, are stored by each relying party/service that initiated the registration."  Quote two:  "The secrets contained in the Security Key belong to the end-user exclusively and are never transferred, copied or stored by a service provider or any other application provider."  What is going on, Steve?



STEVE:  So those are both technically true.  And this is one of the weird things about FIDO, is FIDO, unlike my solution, SQRL, FIDO generates random key pairs for every association that you make with the so-called relying party, like the remote website.  So the problem is that requires storage to have a growing number of key pairs.  But there is no storage, or not lots of storage, in a lean little device like the YubiKey.  So the solution they came up with is kind of counterintuitive.  And that is, have the relying party, that is, that remote server, who you are authenticating with, also hold the authenticating information.  It's like, what?



LEO:  Well, that's what you do with a password, too; I mean, you know?



STEVE:  Well, but, yeah, but that's the problem is, I mean, one of the nicest things about my SQRL solution is you give the server no secrets to keep.  In this case, you're giving the server the things that you need in order to prove your identity to it.  And the way they do it is, during this, and it requires a back-and-forth interchange, what doesn't leave the YubiKey, which has no ability to leave, and I should sort of broaden this a little bit to say a FIDO U2F device, of which the YubiKey is the best known example, is a secret key which is used to encrypt the private key.  So in order to authenticate - and we'll cover this, we'll do a FIDO U2F podcast at some point, in order to cover this.  And I read all this once, and some of it's drained out of my brain because there's only so much room.



LEO:  Pretty full already, yeah.



STEVE:  Yeah.  So the FIDO protocol requests the private key to be sent back into the YubiKey, and the YubiKey uses its secret  key to decrypt the private key which it's received back from the website.  That then allows it to assert its identity by signing something like a nonce that the site has provided which it then does.  And it returns that to the site, which is then able to verify that with the public key.  So, I mean, it's clever in that it allows to have a zero storage hardware token which only needs to store one master key, which it never lets go of.  And then you're able to have the storage essentially offloaded to all the different sites where you have created identities.  The way that differs, for example, from SQRL is that does allow you to break, like individually break identity associations rather than having them all governed by a single static key which SQRL uses, although the tradeoff is that they all have to - essentially you're giving them your private key to hold for you.  You encrypt it, and then you decrypt it as you need to identify yourself.



So technically the way to read these paragraphs is that what's never leaving the key is the key that's used to encrypt the private data that is leaving the key, but nobody can access that because the key that was used to encrypt it never leaves the key.  Anyway, it's, yeah, a little more complicated.



LEO:  So it's kind of almost like symmetric key.  Well, but I guess it isn't because only you know your key.



STEVE:  Yeah, it is, it's a symmetric key in the YubiKey which is used to encrypt the asymmetric private key which you then export to the remote website who holds onto it.



LEO:  Right.  Okay.



STEVE:  Yeah.  And actually Question #9 is closely related, as we'll see.



LEO:  Well, it comes to us from Charles Jurczak in Collinsville, Illinois, and he's wondering about Yubico's new FIDO Security Key.  He simply wrote:  I have one and use it.  Please tell us how it works.  How do it work?



STEVE:  So, Charles, you just got the short version of how it works.  And I don't think I left out any super important details.  But I realize this was, I mean, this is a topic for a podcast because there's lots of subtleties.  So we will definitely, I mean, FIDO U2F is beginning to happen now.  It exists with the YubiKey and Google at this point.  And as it gains traction and gets used in other places, we'll certainly cover it because it's important technology, much as we've talked about single and multiple factor authentication and time-based tokens and one-time passwords and all that stuff.  So we will definitely do that.



LEO:  Question 10 comes from Steve in Austin, Texas.  He wonders, I don't know, are you cutting Apple too much slack?  Hi, Steve.  I notice you hold back on upgrading Windows versions for a long time, but you update your iOS device almost as soon as a new version comes out.  Your stated reasoning for holding off on the new Windows versions is they need to prove their security first.  Doesn't that apply to iOS?  Just curious.



STEVE:  I think that's a very valid challenge, actually.  One thing I think that keeps me from updating to newer versions of Windows is that it's way more painful than it is to update iOS.  Updating iOS is just a matter of saying, okay, I want to update.  And in fact, as I understand it, that's one of the new touted advantages of Windows 10 is we're finally supposed to be able to update it sort of inline, rather than scrapping all of what we have.  I mean, I guess, what, theoretically you're able to install a new version of Windows over the old one?  But oh, my goodness, I've never done that.  I take the opportunity, since I do it so seldom, to start over again, and that lets me flush away all of the software that I installed once and forgot about and really never use on a daily basis, sort of a spring cleaning every couple years.



But at the same time, look what just happened with iOS 8 and bricking iPhones when we went to 8.0.1.  I'm very glad that that news - that I wasn't immediately jumping on that and then bricking my phone and having to wait for 8.0.2 to come along and save me.  So anyway, I guess, you know, I think I treat my iOS devices a little more like an appliance; and my Windows system, I mean, it really is my heart and soul.  This is my environment.  And I really curate it much more carefully than I do my phone and my pads.



LEO:  Our last question comes to us from Diana Bockhahn in Port Orange, Florida:  I have a classic iPod - by the way, they stopped making those, Diana, so hold onto it.  It sounds like it's on its way out - click, spin, high to low pitch, click, spin [Leo mimics faulty iPod drive].  Apple doesn't - oh, she knows this.  Apple does not sell the classic anymore, and I have a massive amount of music and video on this thing.  It holds 160GB.  Will SpinRite work on an iPod too?  This classic HDD may not allow me to play my Monster Ballads in between podcasts for much longer.  Steve, I thank you for the hard work you put into everything.  Love the show.  You and Leo - Batman and Robin - well together.



STEVE:  Okay.  So the answer is yes.  We've talked in podcasts years ago about SpinRite's ability to repair the hard drives in the iPods, the early iPods.  That's what you're hearing, that click, spin, high-low pitch and everything, right.



LEO:  It's trying to read a sector?



STEVE:  Yeah.  Now, Diana, you do need a wizard because it's not a matter of plugging SpinRite into the iPod or running it.  You need a wizard who's able to open that iPod and then essentially plug that hard drive into a PC on which he or she, the wizard or wizardess, runs SpinRite.  So in fact there was a great story we talked about, some guy fixed a friend's iPod, and then the word got out.  Oh, no, everybody - I guess he'd been collecting iPods, everyone's dead iPods they were bringing to him.  And then when - he fixed someone that absolutely had to have some data off of it.  And then he started running SpinRite on all of the other iPods and fixing all of them.  And even the solid-state ones that had died, SpinRite brought back to life, which is one of our earlier SSD recovery stories.  And then he was, like, not sure if he wanted to give them back to people or what.



LEO:  That's right, I remember that, yeah.



STEVE:  Yeah.  So it absolutely can work.  But you need to decide, I guess, if it's worth it because it's not a matter of just plugging it in.  You need to - because there's not enough access.  SpinRite needs very low-level access in order to get at the guts.  Sounds like it's on its last legs, though, or its last spins.  And what was the term, it will soon become SpinRotten.



LEO:  SpinRotten.



STEVE:  If you don't make it SpinRighted pretty soon.  So I wouldn't wait long because it's in trouble.  And maybe, assuming that it can still dock into iTunes, it might be time to update to a newer iPod.  And 160GB, is that more than the iPods have now, Leo?



LEO:  Oh, yeah, much.



STEVE:  Wow.



LEO:  The iPad goes up to 128.



STEVE:  Oh, you're right.



LEO:  And iPhone.  So 160, but it's a physical disk.  And in fact Tim Cook said why they don't make them anymore is because they can't get the parts.  I think it was a Hitachi they were using, or Toshiba.  No, somebody said Toshiba.



STEVE:  Wow.  Crazy little drive.



LEO:  Yeah, there were those - remember when IBM came out with them?  They were the size of compact flash?



STEVE:  Oh, the 1.8, yes, 1.8-inch, yup.  Very cool.



LEO:  No one makes them anymore, so.  Well, Steve, no one makes you anymore.  They broke the mold when they cranked out Mr. G, and that's why we are thrilled to have him each and every week talk about security on this very program.  We do the show at 1:00 p.m. Pacific, 4:00 p.m. Eastern.  Now, we've got to tell you we're going to switch out of summertime next week.  We fall back.  So that doesn't change - and every time I say this, I hear people in the chatroom going, no, you're wrong, Leo, but I'm right.  It doesn't change the time from our point of view.  We're still at 1:00 p.m. Pacific, 4:00 p.m. Eastern.  But it does change our UTC time.  So I just - I mention this because we're now minus eight, or will be minus eight, not minus seven.



STEVE:  The sun will be in a different location.



LEO:  Yeah.  We're actually moving.  UTC never moves.  But because of it...



STEVE:  Correct.



LEO:  ...we will now be at 2100 UTC.  So do the calculations to your local time.



STEVE:  We get to sleep an extra hour; right?  So we'll be in an extra great mood for the podcast.



LEO:  Fall back, yeah, so we get an extra hour. That's nice.



STEVE:  Yeah.



LEO:  So we'll see you next week, though.  We'd love it if you come by and join us live.  If not...



STEVE:  And it's on Election Day, isn't it.



LEO:  It is?



STEVE:  Next Tuesday.



LEO:  November 4th.



STEVE:  Yeah.



LEO:  Well, everybody vote before you listen.



STEVE:  I've already mailed mine in.



LEO:  Good man.  I've got my ballot, but I haven't mailed it yet.  It's a tough one in California.  We've got a lot of initiatives.  And of course dueling television ads like crazy.



STEVE:  Oh, goodness, yes.



LEO:  Out of control.  Do come back and watch live.  But if you can't, on-demand audio and video available.  Now, Steve has some interesting, unusual formats at his website, GRC.com, including a 16Kb audio version, which sounds like hell, frankly.



STEVE:  The assembly language version.



LEO:  Very small.  The transcripts, however, are quite elegant, and that's because a human named Elaine writes those.  He has both of them, along with SpinRite, the world's finest hard drive maintenance and recovery utility and all the good stuff that he does for free, the pro bono work, including SQRL, all at GRC.com.  Now, for next feedback episode, which is two episodes hence, should all go well on the Internet, the good lord willing and the creeks don't rise, we'll be - you can ask your question now at GRC.com/feedback.  He does not accept email.  You could tweet him, though, @SGgrc.  He's been known to include a tweet or two from time to time.



STEVE:  And I did forget to mention Simon Zerafa, who was responsible for cluing me into the RC4 update, Spritz, that cipher.  I had it in my notes here, a shout-out to Simon, who tweets all the time.  He's a relentless tweeter and keeps me - he makes sure I don't lose track of things.  So I appreciate that, Simon.



LEO:  Relentless tweeter.  Thank you so much, Steve.  Thank you, everybody, for being here.  And we will see you next time on Security Now!.  Bye-bye.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#480

DATE:		November 4, 2014

TITLE:		Listener Feedback #200

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-480.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll review the latest security news and then get down to work with eight questions from our audience.  Steve's answers, your questions, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 480, recorded November 4th, 2014:  Your questions, Steve's answers, #200.



It's time for Security Now!, the show where we talk about security.  Now.



STEVE GIBSON:  Yeah, yeah.



LEO:  Yeah.  That's Steve Gibson there, that guy there.  That's the guy in charge there of the show.  He is at GRC.com, Gibson Research Corporation.  He's created - which sounds like a big giant conglomerate.



STEVE:  Conglomerate, yeah.



LEO:  It's really just Steve.



STEVE:  Yeah.



LEO:  A few other people.  Creates the world's best hard drive  maintenance and recovery utility, however.  You might know it as SpinRite.



STEVE:  SpinRite.



LEO:  SpinRite.  Lots of free stuff there.  And every week for the last almost 10 years now we have been getting together on various days, Tuesdays these days, to talk about security.



STEVE:  Yeah.  And we did a Q&A last week, but we've been skipping Q&As because there's just been so many catastrophes in the security world.  And so I thought, let's pull some more questions.  Also there was a bunch of news I wanted to talk about.  And having a heavy news podcast sort of squeezes out time from getting into any serious propellerhead stuff.  And I just thought, yeah, let's do another Q&A.  So...



LEO:  I love the Q&A.  And I know our audience does.  So that's fine.



STEVE:  Yeah.  And I like it because it gives our listeners a chance to have their voices heard.  Like the guy whose question we took last week about random MAC addresses, we misunderstood what he meant.  And so sort of a chance to come back and fix that.  So I wanted to talk about a couple things.  First of all, I have to say, I just love your banter with Sarah.  Sarah, I don't know what it is.  It's you're so comfortable with each other.



LEO:  We've known each other for even longer than I've known you.



STEVE:  It really is special.  It is just, you know, she is at the top of her game.  She is quick and sharp and easy on the eyes.  And actually it was the one before last where you were doing the Christmas music, but just crazy stuff.  And even yesterday I just - I really look forward to iPad Today for the pre-show stuff.  And in fact it's interesting because later, I guess a couple days ago, you capturing the whole stream because it was the pre-show stuff with you and Sarah that was just - it was wonderful.



LEO:  Now, this wasn't on a podcast.  That was you were watching live.  Or you were watching a rerun.



STEVE:  I was watching live.  No, but someone reran that.



LEO:  Oh, yeah.  We put that in reruns.  We try to put that in reruns.



STEVE:  Oh, and it is just wonderful.



LEO:  Aw, Steve, thank you.  I appreciate it.



STEVE:  It just really shows how comfortable you guys are with each other.  It's like you are different in a way because you're just so...



LEO:  Well, she's so cute, I'm kind of giddy.



STEVE:  She is.  And you're super comfortable together.  Anyway, it's just - it's a great side.  So...



LEO:  I've always had such a crush on Sarah.  I'm just mad for her.



STEVE:  And I was - well, who wouldn't?





LEO:  And so I guess that shows; right?



STEVE:  I mean, she's got it going on.  But...



LEO:  Yeah, we're such good friends, and we've known each other for so long.  And you know what, we never ruined our relationship by being in a relationship.  So I think that was a good thing, too.  Yeah, at this point now it's a very easy friendship.  So thank you.  I appreciate that.  Because gosh knows I love doing that show with her.  I really do.  It's so much fun.



STEVE:  Well, it's just - it's a romp.



LEO:  A romp.



STEVE:  And sadly, there's no link...



LEO:  A madcap romp.



STEVE:  Sadly, there's no link that I know of where anyone could listen to that pre-show banter from week before last.  It just popped onto your feed again.  And I was so glad to see it because, frankly, once you started, it was like sort of more, okay, down to business now.  And it's that pre-show stuff that, you know, and you and I often have that, which is why, as I said, this time I was biting my tongue about a couple things I wanted to talk to you about to make sure it got into the podcast rather than just stuff we were rambling on about beforehand.



LEO:  I'm a little torn because one of the things - this all has - this is a complicated story, and I don't want to waste your time.  But it has to do with the evolution of TWiT because, as you know, it was originally just audio podcasts.  And all you could ever listen to was the produced final product because we didn't...



STEVE:  Right.



LEO:  But then once we started putting up cameras, and it originally was just simple spy cams, you could watch more than just the show.  You can watch us produce the show.  And I think that's really what TWiT Live, the live version, really always is and has been is you're not - we're not - and I think sometimes people don't understand this.  It's not like - we're not trying to do a TV station that, you know, show show show show.  You're watching us produce programs for later download.  But then I also feel like the live thing is good.  And we want people to watch live if we can get them to, even though we have yet to figure out a good way to count live viewers for advertising purposes.  So from a financial point of view it's a kooky thing.  But I just think it's important because it's the easiest way to watch.



STEVE:  Yes, the stream has so much extra stuff.



LEO:  Right.  And that's intentional.



STEVE:  So we're recording now.  Everybody is hearing this.  So for what it's worth, you know, and I just - when I'm coding, and I'm not doing, like, I'm not writing because I can't have, as I've talked about, for me the distinction between a linguistic process and a nonlinguistic process, I'll just turn on to see what's going on.  And I get all this extra stuff from live.twit.tv which is not in the podcasts.  And a lot of it's just really worthwhile.



LEO:  Thank you.  I mean, that's kind of the design.  I don't know why, but I just feel like live is exciting and interesting and more fun.  And so we encourage people to watch live.  And of course live is the only way you can interact with the shows; right?  If you're not watching live, you can't exactly interact with us.



STEVE:  Right, right.  And I just think it's organic.  I mean, that's - it's you.  It's reality.  It's what's going on there.  And while you do have regimented, scheduled things, because you have to have that or everyone would just sit around playing...



LEO:  Kind of sort of regimented.



STEVE:  ...with spaghetti all day.



LEO:  But there is this concept called "Leo time."  



STEVE:  Yeah, I just - it just - I just think it's great.  And so I would encourage people, if they have the opportunity, to just watch the feed sometimes.  Sort of consider that there's more than these snipped out, edited, tuned, produced, I mean, and I'm as much into the, okay, here's all my show notes, here's all the Q&A, I mean, there's a whole bunch of production that goes into Security Now! every week, which is one of the reasons I think that, for those people who want that, we have that.  But watching what goes on, the antics before and after, that's different than the podcasts, but I really enjoy it.  So I just wanted to make sure people knew there was something more available, and just to sort of turn the stream on sometime and see what's going on because...



LEO:  Thank you, Steve.  I'm very flattered, thank you.



STEVE:  ...there's often really good stuff.



LEO:  We do our best.



STEVE:  So I keep listening to you talking about the Apple Watch.  And I just wanted to chime in, off topic as it is.  But, you know, we're techies and so forth.  I completely think that all of this stuff is way early.  And the analogy I draw, because there is one that you and I have lived through, is the laptop.  The laptop took a long time to actually get practical, to the point where it's in many cases now people's only computer, or it's their preferred platform.  But, I mean, we went through three-hour battery life.



LEO:  That's right, I forgot, yeah.



STEVE:  And, you know, laptops with wheels, and laptops with really dim screens that were 80 characters by 16 lines.  I mean, and a floppy drive where it was like, well, how do I get my data into there?  Oh, you put it on a floppy and then you stick it in this little slot.  It's like, no, no, no, no.  And so, I mean, and we endured this, we early adopters, for years.  I was a Toshiba loyalist, and so I sort of followed Toshiba through.  And, I mean, with lifetime measured in minutes, battery life in minutes rather than in days, and really bad screens, and no peripherals or I/O, small storage, I mean, they were really poor cousins of what we had on the desktop.  And it took, it really took the evolution of technology, which we went through, to enable the machines we have today.



And so I completely agree.  I look at these watches, and I just - they have no interest for me at all.  I wear a wristwatch.  I'm a wristwatch wearer.  And occasionally I glance at it to see what time it is.  And I don't have to shake it, or talk to it, or push any buttons, or beg it or pray or charge or do anything.  It goes for years on some battery that I go back to the jewelers, and they change it because it's got a mechanical movement in it, and so I don't want to get any, you know, they're able to  do it in a dust-free environment.  But, I mean, it is abso- well, in fact I did have to deal with it on Sunday because I had to change it by an hour.  And it's polite enough that I can just twist the crown, and the hour hand jumps by hour increments.  So even going, you know, daylight savings times plus and minus isn't increasing my chance of having a heart attack on Monday or Tuesday following...



LEO:  You heard us talk about that.



STEVE:  Uh-huh.



LEO:  Ten percent higher chance of a heart attack.



STEVE:  Amazing.



LEO:  I know.



STEVE:  Amazing.  So anyway, I wanted to interject my two cents' worth in about all of this watch business.  Which, again, I don't think it's bad, but I'm not going to get any of those arrows in my back.  I'm going to wait because maybe someday it'll evolve to a point where we have a watch that just, I mean, it uses so little power that it's got a solar strap which just absorbs light from the ambient and keeps itself going, and then it updates an eInk display so you don't have to mess with it.  I mean, who knows.  But I just, you know, it's just fun to see where we start versus where we are.  I mean, I have a refrigerator full of Tungsten Palms that I thought, oh, this is the one.  I don't want to ever...



LEO:  I do mention that a bit, and I hope you don't mind that I use you as an example.



STEVE:  No.  Yeah, you know, sometimes you get it right.  And you guys were talking about on MacBreak Weekly the absolute ultimate calculator app in the world.  That PCalc...



LEO:  Oh, you like that, huh?



STEVE:  Oh, my god.  It is - and, oh, on the iPhone 6 it is a joy.  It is my go-to calculator.  And so I was watching the drama of, not that I use it in widget mode, it just sort of never occurs to me, but I was curious to see that it was there.  And I have seen it in widget mode.  But it was fun to get Rene's extra rich information into the background of that because I care about the app and the author and its success.  And in fact I've edited mine.  You just - you hold a button down, and it's just very much like shifting the icons around on your iOS device.  You can then drag and you can move the buttons around.  And I'm using exponentiation because I'm doing scientific stuff enough that I've reordered, I've sort of changed the design a little bit.  And anyway, it is a wonderful application.



LEO:  There's an example of something you already have, you don't really need, and yet if it adds that much value - do you use it, I bet you use it in RPN mode, don't you.



STEVE:  Absolutely.



LEO:  Oh, god.  You're such a geek.



STEVE:  What would you do with an equal sign?  Yeah.  And, I mean, here are my two RPNs...



LEO:  Oh, look, you've got your HPs, yeah.



STEVE:  Those are my two RPN HPs.  A 16, which does hex, decimal, and binary and so forth.  And then the scientific one.  And these are not in the refrigerator, but I do have quite an inventory of them because...



LEO:  Those are the 12Cs, you said?



STEVE:  We've got 16C, of course, 16 is the programmer's calculator.  And it's got extra things like masking and rotation and all that, setting bit and clearing bits, and they're all programmable.  And then the 15C is the scientific.  And it's just, you know, what you want, you want a device where, as we've talked about often in different contexts, where much like the telephone, the user interface fades, and you're not conscious of it.  It's not in the way.  It just helps you get your job done.  When you're on the phone, you're not thinking about holding a handset and talking into a microphone.  You reach through it into the mind of the person you're speaking with.  And so the UI becomes transparent.  And for me, these calculators, once you get comfortable with them, that's the way they are.  And PCalc on iOS, oh, I mean, it's a reason to have a phone is just to have...



LEO:  Wow.



STEVE:  ...for people who calculate.



LEO:  So it's like an HP 16C on your phone, basically.



STEVE:  Yes.



LEO:  Ah.



STEVE:  With a bunch of really nice extra features.  You can drag the display to the left and go to previous displays.  You can pull it down in order to shrink the keyboard and create more space for the screen.  And, oh, it's skinnable.  And he's got, like, I don't know how many dozens of skins.  And I've just chosen one that I think is best.  But people have, you know, opinions vary.  I think there's now probably a Windows 10 or 8 or whatever it is, the new flat theme skin.  But anyway, I just really, really like that.



LEO:  I'm going to install it right now on your recommendation.



STEVE:  Oh, Leo, it's just, I mean, if you're not someone who calculates, then obviously...



LEO:  I'm not.  But I want a good calculator.



STEVE:  It is THE calculator.  Really, it's just nailed it.



LEO:  Last time I used a calculator.  Well, occasionally I'll use it in the radio show, mostly for bandwidth calculations.  I wish there were like a bandwidth calculator.  But the last time I can remember that I wanted a calculator on my phone, I was visiting a friend in court.  He's a litigator.  And it was a recess, and he had to quickly figure out what the damages he should ask for should be.  And he's, "Quick, give me your phone."  And he calculated it on - I thought, okay, I would think you'd think about that a head of time, but - he won the case, by the way.



STEVE:  Well, and the cool thing is it's not like you have to carry a second calculator.  Or, that is, you have a phone and a calculator.  Back in the day we used to carry, we geeks, a calculator because we didn't have phones that could do double-duty.  But here you always have a really top-end calculator with you, whether you're carrying your pad or your iPhone.  And I'm sure there are good calculators over on the Android platform.



LEO:  Oh, yeah.  You know what, actually I use Google a lot because you can do calculations with Google Search.  And you can actually do fairly complex calculations with Google Search.



STEVE:  I use it for monetary conversion and for units conversion sometimes.  You just sort of ask it the question, and it says, oh, here you go.



LEO:  But you can do weird things like - in fact, I should try this with bandwidth, like how many hours would it take to download a 500MB file with a 3MB connection or something like that.  And it's smart that way.  It's kind of like Wolfram Alpha.  That's where you go if you've really got some serious stuff.  That's like having Mathematica at your fingertips.



STEVE:  Okay.  So I have an important correction to make at the top of the show.



LEO:  Uh-oh, yeah.



STEVE:  To a mistake I made last week.  We're going to talk about CurrentC; an interesting new entry into Tempest Broadcasting.  Tempest, of course, is the famous technology for extracting information from just the operation of a computer.  A Mac OS X privilege elevation that was recently uncovered, but I don't think is a big deal.  TextSecure gets an audit.  The EFF finishes a comprehensive evaluation of messaging app security.  Another ruling on fingerprints and passwords and our rights.  And a nice little piece about state-of-the-art TVs, and a Q&A.  So a bunch of great stuff to talk about.



Okay, so Department of Corrections.  In answering the question that one of our listeners asked when he was talking about same-origin policy, I got sort of sidetracked by the correctness of his supposition, which is no excuse because I didn't give him the correct answer.  And I missed the point of Adam Langley's note on his page when he said that any web page is able to access any other domain.  Well, of course it is.  The same-origin policy, what it does is it prevents anything in one origin from accessing information in another origin, which is completely irrelevant to Poodle.



The point is it's not the script in the browser that needs cross-origin access because the attacker is outside.  And so it's absolutely the case that script in a browser can cause queries to any other domain it wants.  I mean, that's what a web page is.  I often talk about how web pages are now composed of crap coming from 40 different servers, 40 different domains.  So an external attacker is going to see the traffic from all of that, even if the page itself has no access to the content of those other domains.  It doesn't need to.  Poodle doesn't need it to because the attacker is on the outside.



And so it's like, this hit me during breakfast the following morning.  It was Wednesday morning, and I was just, I don't know, I just was sitting there sipping coffee, I thought, oh, my lord.  And I immediately tweeted, from where I was, I said, "Realized that I missed the point Adam Langley was making about Poodle.  JavaScript cannot get internal access to other domains."  Next tweet:  "But JavaScript can cause the browser to make queries to other domains, and that's all we need since the attacker is outside to observe."  And then the third tweet:  "I'll correct my confusion at the top of next week's podcast.  In the meantime, that point I made was wrong."  So I wanted to...



LEO:  Wow.  Well, that's big of you.



STEVE:  Well, it's correct.  So I don't like to make mistakes.  Everyone knows I try hard not to.  But when they happen, they happen.  So the only thing we can do is fix them.  So that's fixed.



Okay.  CurrentC.  And I know you've been talking about it.  This happened Wednesday morning, immediately after last Tuesday's podcast, as so many things seem to.  They happen the day after the podcast, so we have to go a whole week before we can talk about it.  And it turns out that it was certainly a black eye.  And in looking at it more closely, it's also sort of not as big a deal as it was easily sort of made to be.  It turns out that it was apparently a security breach at the email provider that the Merchant Customer Exchange, MCX, uses.



LEO:  Well, but...



STEVE:  I know.  Certainly, I mean, I'm not making an excuse for them.



LEO:  They gave it to a third party.  So...



STEVE:  Yeah.  So not secure.



LEO:  Not secure.



STEVE:  Yeah.



LEO:  And the third party wasn't secure.  So it doesn't matter who it came from.  If they lost it, they lost it.



STEVE:  So for people who don't know already, the day after last week's podcast where we were talking about this, CurrentC had what you'd have to consider a major breach because the email addresses of all of their demo users and early testers leaked from their email provider.  Dekkers Davidson is the CEO of MCX.  And so he tried to downplay this.  But there were a couple interesting nuggets that were worth - and that actually I saw as positive, just in terms of our interaction, of the world's interaction with him, because he did confirm that there is an exclusivity relationship for retailers who use MCX.  That is, they are not also, as part of their agreement, not also able to use Apple Pay today.  But two things he also said:  There are no fines associated with exiting the consortium.



LEO:  Yeah, see, that's interesting.  So you could drop out.



STEVE:  Yes.



LEO:  But can you do MCX plus Apple Pay?



STEVE:  And he said that's not being ruled out in the future.



LEO:  Yeah, bet it's not.



STEVE:  That's the second point, yes, yeah.



LEO:  This is a backpedal because really the whole point of MCX was them both keeping your personal information to themselves, and Apple doesn't give them personal information, and disintermediating the credit card companies so they didn't have to pay the percent to them.  And both things would happen with Apple Pay.  So I think this is backpedaling.



STEVE:  Yeah, which is fine.



LEO:  Yeah, backpedal away.  Go, go, go.



STEVE:  Let's backpedal to turn that stuff on because we want to use Apple Pay.



LEO:  Yeah.



STEVE:  However you do it, however long it takes.  But the good news is that retailers can decide, if Apple Pay continues to happen, because as we know, what was it, more than a million credit card activations in the first three days.  So Apple was out touting their initial launch success.  And we'll just have to see how it goes.  Clearly, if it succeeds, and if any retailer - Rite Aid, of course, who famously turned theirs off - if they realize people are going to Walgreens specifically because, you know, in protest, they're going to say, "Uh, sorry, MCX, we need to enable our customers to use what they want, and you didn't get your thing off the ground in time."  So it's interesting because MCX actually began two years ago, back in 2012.  And it's just sort of been limping along and didn't really happen.  And, I mean, even now it's not happening until 2015, sometime next year.  So it's like, they may have missed the boat.  We'll see.



Okay.  Air Hopper.  Many people picked up on this news, which is interesting.  This was the result of a group of researchers who presented a paper at what's called MALCON, which has only been around relatively briefly, at the IEEE 9th International Conference on Malicious and Unwanted Software.  I thought that was nice.  That's sort of a nice title:  The International Conference on Malicious and Unwanted Software.  So it's not necessarily evil, but it's unwanted.  And so we're going to call it - that's under the umbrella.



Anyway, so what these guys demonstrated was not Tempest as much as sort of a toned-down version.  Now, Leo, you've been around as long as I have.  I remember putting an AM radio, sitting it on top of an IBM 1401 sort of small mainframe, it certainly wasn't a minicomputer, basically it could add, but it also wasn't very powerful, and playing Christmas music by feeding in punch cards...



LEO:  You did this?



STEVE:  ...that caused, oh, yeah, that caused loops to run at...



LEO:  [Making odd noises]



STEVE:  Oh, it was awful.



LEO:  I can't believe you did this.



STEVE:  Oh, yeah.



LEO:  You're hysterical.



STEVE:  And then years later I worked for a company called Minicomputer Technology, where not surprisingly we had minicomputers.  And we did the same thing, just because, you know, the days were long back then.  And again, you would tune a radio in between stations, and it would pick up all kinds of noise from the operation of this machine that it was sitting above because these machines all used core memory.  And core used pulses of current through wires to flip the magnetization of ring magnets into clockwise and counterclockwise directions.  So that required a substantial pulse of current.



Well, that pulse of current that generated a local magnetic field also broadcasted electromagnetically, powerfully.  So much so, in fact, that in my PDP-8 mini computers that I have, they consumed one of their precious card slots with nothing but a copper grid between the core memory region that you sort of stick toward the back of the back plane, and all the processing and I/O, because the core memory was generating so much electromagnetic noise from its functioning that it could flip bits in the neighboring electronics if you didn't have essentially what was sort of a Faraday screen, an electromagnetic screen.  And card slots were precious, but they gave one up just to have this barrier between the core memory and the rest of the computing electronics.



So the point is that, although - well, and everyone has looked at modern-day machines and noticed that, to varying degrees, these things are clearly noisy inside, and the manufacturers attempt to quiet them down, to keep those emanations from getting out by doing all kinds of things, you know, you'll have clearly conductive copper fingers that reach out and touch the lid as you close it in order to create an electrically conductive closed cage that prevents leakage.  And people have seen those lumps on their cables, which are specifically there to absorb sharp edges in the transition of the current because edges - nature doesn't like edges, as we've talked about.  And those broadcast unless you snub them by essentially running them through a big piece of iron that absorbs that transient.



So it turns out that today's computers are comparatively quiet, except that screens are not.  Screens, by their nature, have to be sort of out there exposed.  And they create an opportunity for broadcast.  So what this team of researchers showed was, if you could - and this is why this is not like a super danger. Remember that the way Tempest worked, the idea was you could surreptitiously receive from a CRT enough emanation from it that you could decode the image it was displaying, that is, the technology of the CRT was such that, if you could aim like a parabolic dish from a distance through a window at this CRT, or even like the back of it, you could suck in all that data and process it and figure out what it was displaying.  So modern LCDs don't operate in the same fashion, don't operate at the same voltages at all.



So what these guys showed - but my point was that you needed no preparation.  Well, these guys showed, if you could prepare, what could you do?  Meaning that, if you managed to infect - so you have to first infect the computer.  And it then has malware - thus the MALCON Conference - it has malware running in it which is able to use the video subsystem to surreptitiously get an FM transmission out of the machine into a nearby recording FM radio.  So you need a smartphone that is able to also receive FM, that is, as in broadcast FM, because that's about the frequency range they're able to put out.  And that smartphone has to know where to be tuned.  It's got to be tuned to the malware, essentially.  It's got to be within one to seven meters, so it's not long range.  And it's able to - it's not super high bandwidth.  It's only able to get about 60 bytes per second transmitted through this channel.



So it was an interesting capabilities display.  As we know, these things only ever get better.  They typically don't get worse.  So we could imagine successive refinement.  In any kind of a proof-of-concept, these guys are just demonstrating that their first idea works.  If you really needed to get down to it, it's very much like a modem.  Remember that modems used to be happy to get 300 baud through a phone line.  Now I can't believe the amount of data we get over copper.



LEO:  Analog.



STEVE:  Basically dirty copper twisted, yeah, analog twisted pair.  It's unbelievable.  So one could imagine successive refinements of this concept, the idea of something, rather than just being a passive leaker of information, if you put something malicious in the computer that was able to select what it wanted to send and arrange to use the existing channels to do so, it probably could.  On the other hand, this is one of those things where there's probably easier ways.  Oh, and the point was this was called AirHopper because this would be for air-gapped computers.  That was the point they were making was, yes, if it was on the Internet, or any 'Net, then thank you very much for the connection to the world.  I'm not going to be limited to 60 bytes per second or seven-meter range.  I can talk to Moscow directly.



So, but in this case, if the thing is off by itself in a basement and not connected, and you think you're being really clever, well, if something bad got in there, then it turns out these guys demonstrated you could leak information at a low rate and in close proximity, just through the video channel, just video noise that you're able to control.  So a really interesting sort of a proof-of-concept.



There was concern about a Mac OS X privilege elevation exploit.  I saw a couple people refer to it as zero-day.  It's like, well, okay, except that it's a local privilege elevation.  Apple knows about it.  They'll be patching it.  And what it allows is it allows a bad guy who knows what to do - and this was not revealed.  It was demonstrated at a recent conference.  But the person who discovered it did not reveal what it was.  He's waiting until after it's fixed.  Then he'll tell us what it was. So he's being responsible.  So in that sense it's not a zero-day because it's not in the wild.  Nobody, as far as we know, has figured out how to do this.



What it allows you to do is to enable an admin account, which is the normal default user account on a Mac, to obtain root privilege which you normally don't have access to.  You normally need extra magic in order to get that.  And so the workaround, I mean, if you were really worried about this, and I don't know that anyone needs to be, but again, it's a function of the environment of your Mac, if you're the only one using your Mac by yourself in your house, then I think you're probably fine.  This is not a remote network takeover sort of thing.  But if you had a super high-value Mac in an environment where many people had access to it, and you're waiting until January, which is the earliest that we expect Apple to be able to address this, then maybe you want to go to some extra measures.



It turns out you can create another standard admin account, and then you can reach over back into the original one and remove admin privileges from it and then make that the normal default user account so you've neutered that.  And that's a workable, temporary measure, if you consider this a problem, until Apple fixes it.  But so consider all of that.  It may not be even worth bothering about because it's not in the wild.  As far as we know, nobody else knows how to do it.  You do need physical access to the machine.  And we already know that pretty much any time we have physical access, the jig is up anyway.



LEO:  But you don't have to know the admin password to do this.



STEVE:  Correct.  Basically it's an admin password bypass.



LEO:  Right.  We wouldn't want that.



STEVE:  TextSecure, that is Moxie Marlinspike's creation.  And it has an interesting past.  As I recall, didn't it get purchased by Twitter, and then they open-sourced it and released it, and now it's been audited.  And so the news here is...



LEO:  Oh, good.  Oh, good.



STEVE:  Yes, that it and Cryptocat are the two open-source solutions which have been audited and complete their across-the-board green stars.  The EFF just published a secure messaging scorecard.  And in fact the first page of the podcast notes this week I have a sort of a small screen cap of that.  But TextSecure passed the audit with one - these guys really dug deep.  And it is a very complex protocol.  I mean, it is, like, whoa, eye-crossingly complex.  But they found something that they named the "unknown key share attack" and found mitigations for it, shared it with the developers of TextSecure, who are already on fixing it.



So just a snippet from the paper's abstract.  They wrote:  "In this paper, we present the first complete description of TextSecure's complex cryptographic protocol and are the first to provide a thorough security analysis of TextSecure.  Among other findings, we present an unknown key-share attack on the protocol, along with a mitigation strategy, which has been acknowledged by TextSecure's developers.  Furthermore, we formally prove that, if our mitigation is applied, TextSecure's push messaging can indeed achieve the goals of authenticity and confidentiality."



So those are the two things you want.  TextSecure succeeds with a formal, mathematical cryptographic-strength proof.  So I'm sure TextSecure will shortly get revved to close this one opportunity for the so-called "unknown key-share attack," which I didn't even look at because it's going to be gone before we can get to it.  And so we've got a really useful proof of security for TextSecure.



LEO:  I'm installing it right now.  How about RedPhone?  That's also from the same company, from Moxie Marlinspike.



STEVE:  Yes. 



LEO:  That's their secure phone solution.



STEVE:  Yup, also very good.  So I mentioned EFF's scorecard.  You may want to click the link and just bring this up on the screen while I'm talking.



LEO:  I love this thing, by the way.  They just put this out; right?



STEVE:  Yes.  Yes, just now.  So they analyzed basically all of the instant messaging solutions under seven criteria:  whether the message is encrypted in transit; whether it's encrypted from its provider; whether the contact identity, that is, the other end is verifiable; does it offer forward secrecy, which we know means if the keys are compromised in the future, are messages in the past vulnerable; is the implementation code open for independent review; does it have a proper security architecture; and has it been independently audited.  Under all of those criteria, for all of the popular instant messaging solutions, only two are green for yes, get checkmarks as opposed to slashes for all seven.  And that's, as I mentioned before, Cryptocat and TextSecure.



LEO:  They do say RedPhone is also all seven, as is Silent Phone and Silent Text.



STEVE:  Yes.



LEO:  So that's good.  So we can use RedPhone, too.  You know, I thought RedPhone's kind of silly because you have to have RedPhone on both ends.  But what will happen is you make a regular call using RedPhone, and the other end will still work, but they'll get a popup that says, if you'd like to have a secure phone call with this person, install RedPhone.



STEVE:  Nice.



LEO:  I love that.



STEVE:  Nice.



LEO:  So that means it kind of works across the board, gives you this as a straightforward option.  I'm going to install both of these.  That's great.



STEVE:  Yup, yup.  Those are the ones.  There's also a ProPublica.org has a sort of a different - it's a little more interactive.  You're able to bring up the columns and then sort the columns by qualification, like to bring all the ones that have been audited up to the top, or all of the ones that provide good authentication up to the top.  So you're able to - it's the expanded chart that you found there at the EFF site.



LEO:  Right, right, that's nice.



STEVE:  So, very nice.



LEO:  Thank you, EFF.



STEVE:  Also in good news, we have one more judge.  We're still sort of feeling our way through this question of fingerprint versus password.  And a Virginia Circuit Court judge ruled last Thursday the way we wanted them to, which is that a person does not need to provide a passcode to unlock their phone for the police.  We've pretty much already lost the battle of the fingerprint.  That seems to be pretty much gone.  But at least the issue of what you know cannot be extracted.  That's still considered testimony, which is protected under the Fifth Amendment to the - in the U.S., I should say, to the U.S. Constitution.



So a couple quote snippets here:  "Giving police a fingerprint" - and this is from the judge's comments.  "Giving police a fingerprint is akin to providing a DNA or handwriting sample or an actual key, all which the law permits.  A passcode, though, requires the defendant to divulge knowledge, which the law protects."  And then, lastly:  "A communication is testimonial only when it reveals the contents of your mind.  We cannot invoke the privilege against self-incrimination to prevent the government from collecting biometrics like fingerprints, DNA samples, or voice exemplars because the courts have decided that this evidence doesn't reveal anything you know.  It's not therefore testimonial."



So the takeaway is, convenient as Touch ID is, if you're ever in a situation where you may be losing access to your phone, or you want control over access, then you want to turn it - you want to do a hard turnoff of the phone.  Or remember that Touch ID resets after 48 hours of non-use.



LEO:  Right, right, right.



STEVE:  And it's typically trivial to get your attorney to create a two-hour delay.  That's only two hours.



LEO:  Two days.



STEVE:  Two days.  A two-day delay.  So just file some paperwork or whatever.  And that's like, oh, wait a minute, you know, we require an extension or whatever.  And 48 hours goes by, and then even your fingerprint won't unlock.  And of course, if you wanted to be - if you were in an environment where you thought it was worthwhile, then don't register your thumb, register a more obscure finger because, after four mistakes, it locks and then requires you to enter your passcode, which, boy, you know, the court just cannot compel you to divulge.  So, I mean, that's not a concern I have, but I know that there are listeners who really like to keep a moat around their belt and suspenders.



So this is where we stand at the moment.  And again, I think the more affirmation we have of the fact that you cannot be compelled to reveal a password, the better, because it is testimony against.  Oh, and it was interesting, too, because in this case - it was weird.  I remember as I was reading the case, it was somebody - there was something with a girlfriend.  I think he assaulted his girlfriend.  And the police wondered if maybe there might be a video of that on his phone.  And it's like, what?  Who's going to videotape themselves doing that in the first place?  And I know that there is some issue in the law of how much, like, a fishing expedition.  If they're like, well, we'd like to go look at the phone, it's like, well, of course you would.  But, sorry, unless you have some reason...



LEO:  You need probable cause.  You have to have probable cause.



STEVE:  Yes, exactly, probable cause.



LEO:  And, you know, there's a case, a big case right now in California, as I'm sure you know, CHP officers have been taking people's, attractive young women's phones and looking for nude pictures and then sending them around.



STEVE:  What?



LEO:  Oh, you didn't see that.



STEVE:  No.  I must be watching the wrong channels.



LEO:  Well, it's...



STEVE:  Wow.



LEO:  But, I mean, the point being...



STEVE:  Why would they do that?  That's just so...



LEO:  It's so wrong.



STEVE:  Yeah.



LEO:  But that's the point is that, while there are constitutional protections and legal protections, when you're in the hands of law enforcement, sometimes it's scary and threatening.  And if a police officer says, "May I look at your phone," people often, despite their legal protection, might say yes.



STEVE:  They're intimidated, yeah.



LEO:  They're intimidated.



STEVE:  They don't realize they're not going to get themselves in more trouble by saying no.  And so, yeah.  Wow.



LEO:  So, yeah.  I mean, I think that's shameful and really, by the way, he was charged and fired, but...



STEVE:  Good.  Okay.  So I just liked this piece.  This is a little fluffy, but this was Michael Prince, who contributed this short observation to Salon.  He's counsel in the Liberty and National Security Program at the Brennan Center for Justice at the NYU School of Law.  So he understands what's going on.  And so what he posted, just the beginning of his piece in Salon, he said:  "I just bought" - oh, and the reason I brought this up is many people tweeted this to me because they were like, oh, my lord.  It's like, well, good observation.  He says:  "I just bought a new TV.  The old one had a good run, but after the volume got stuck on 63, I decided it was time to replace it.  I'm now the owner of a new 'smart' TV..."



LEO:  Ooh.



STEVE:  Yeah, "...which promises to deliver streaming multimedia content, games, apps, social media, and Internet browsing.  Oh, and some TV also.  The only problem is that I'm now afraid to turn it on."  Actually, you may not even need to turn it on.  "You would be, too, if you read through the 46-page privacy policy.  The amount of data this thing collects is staggering.  It logs where, when, how, and for how long you use the TV.  It sets tracking cookies and beacons designed to detect" - quote from the 46 pages - "'when you have viewed particular content or read a particular email message.'  It records, quote, 'the apps you use, the websites you visit, and how you interact with content,' unquote.  It ignores do-not-track requests as a considered matter of policy.



"It also has a built-in camera with facial recognition.  The purpose is to provide gesture control for the TV and enable you to log into a personalized account using your face.  On the upside, the images are saved on the TV instead of uploaded to a corporate server.  On the downside, the Internet connection makes the whole TV vulnerable to hackers who have demonstrated the ability to take complete control of the machine.



"More troubling is the microphone.  The TV boasts a voice recognition feature that allows viewers to control the screen with voice commands.  But the service comes with a rather ominous warning:  'Please be aware that if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party.'  Got that?  Don't say personal or sensitive stuff in front of your TV.  You may not be watching, but the telescreen is listening."  So it's like, oh, boy.  Maybe it is time for us to read the privacy policies.  I'm just so happy that I have a stupid, 13-year-old car.  This thing, it's 2001, and I like it because it does...



LEO:  TV.



STEVE:  No, car.



LEO:  Car.



STEVE:  I'm driving a 2001 car and very happy because it's got low mileage, 100,000 miles, and I take good care of it, it's still running just beautifully, and I don't want any brains in my car.  I just want it to take me somewhere.



LEO:  My TV does all of that.  I couldn't - who cares.



STEVE:  I know.



LEO:  Nobody's listening.



STEVE:  I know.  Until they are.



LEO:  Well, maybe they are.  Who knows.



STEVE:  We have a listener of ours asked me to mention, he called himself, well, his Twitter handle is @therealjampers, J-A-M-P-E-R-S.  I put the link in the show notes for anyone who's interested:  github.com/therealjampers/spritzjs.  He's done a very nice sort of reference JavaScript implementation of the new Spritz cipher that we talked about.  This is the recently released updated version of RC4, which really begs for simple implementations because - yup, there it is on the screen.  And very nice.



If you scroll down and click on the Spritz.js link, right there at the top, near the top in that little link zone, you can see his implementation, which is very straightforward.  He's done some neat things, like he kept the variable names in his source identical to those in the paper.  So it sort of represents a live running implementation of the cipher that follows the description.  So if anyone was interested in messing around with that and perhaps contributing, he'd love to have, for example, sample test vectors for the cipher and so forth.  By all means, go over to that on GitHub.



LEO:  He credits you with the inspiration, along with Bruce Schneier.



STEVE:  Oh, cool.



LEO:  You're in the source code, man.



STEVE:  And, well, he is a listener of the podcast.  And I tweeted two links to a neat-looking sci-fi trailer.  One of them was taken down due to copyright constraints by its publisher, so only one has survived as of this morning when I put the links - I was pulling the links over and checking them.  But anyway, it's due out not too far in the future, April 2015.  Out of habit, I tweeted 2014 and had to correct that.  It's called "Ex Machina," E-X space M-A-C-H-I-N-A.  So you could google that.  It's on IMDB, and it's on YouTube.  And, ooh, it looks like some tasty sci-fi.



So apparently it's a - you get from the trailer that some young jock has acquired or taken over a major technical corporation, and he's looking through the books, and he sees that there's some project, sort of off the books, run by some genius who's been disappeared.  And so he takes a helicopter flight over the river and through the woods out into this way remote, one-person-occupied R&D facility and discovers what this person has been working on.  So it looks really, really tasty.  So I'll just give everyone a heads-up, anyone who likes sci-fi, "Ex Machina."  Go find it on YouTube.  You'll be glad you clicked the link.  And then you'll be waiting five months impatiently for it.



And it's been quite a while since I shared one of our traditional SpinRite testimonials with our listeners.  I've been talking about the technology and various, sort of conversationally, various aspects of it.  But one was sent this morning at 2:03 a.m., which I guess is probably in the middle of Chris Day's day, but it's from Chris Day in Princes Risborough in Buckinghamshire in the U.K., with the title "SpinRite recovers a Samsung SSD 840 EVO from the Performance Restoration Software."  And I didn't quite understand that.  But it turns out that performance restoration software is Samsung's software to restore performance, which broke the drive.



So anyway, he said:  "Hi, Steve.  I've been a SpinRite owner for several years now and have used your excellent product from time to time on my systems and servers at home.  I recently heard about the problems with the Samsung EVO SSDs slowing down on your - oh, on your brilliant Security Now! podcast with Leo."



LEO:  It was a trim issue.  They weren't properly implementing trim.



STEVE:  Right.  And he said:  "I'm a CISSP and learned all I needed to know about crypto, hashing, et cetera, et cetera, to pass the CISSP exam just from listening to your podcast over the last 10 years.  As my laptop has a Samsung SSD 840 EVO, and Samsung have recently released the Performance Restoration Software to resolve the slowdown issues, I decided to apply the update to my system.  What harm could it do?"



LEO:  [Laughs]



STEVE:  I downloaded and ran the software, following all the instructions, apart from the backup, as all my data is synchronized with my server, and I have a base-build image of a patched Win 7 OS and core programs as I rebuild my laptop every six months or so."  Good for you, Chris.  You're doing it.



"So everything went smoothly.  The drive firmware was updated, the laptop rebooted, and the Performance Restoration Software went to work rewriting every sector on the drive and completed successfully.  I left the computer, and the next day when I came to start work the laptop wouldn't boot into Windows."



LEO:  [Groan]



STEVE:  Oopsie.



LEO:  [Groan]



STEVE:  "I ran through several cycles of rebooting to make sure, and not even recovery mode would work.  Nothing.  So I grabbed my copy of SpinRite and ran a Level 2 scan on my Windows drive.  Thirty minutes later, SpinRite completed, and its completion screen proclaimed all was well and nothing amiss.  I rebooted the laptop and, as expected, it fired right up into Windows perfectly.



"Now, I can't give you a great sob story of how my life's work was on the machine without any backups, and how SpinRite saved my children from destitution.  But I can attest to the efficacy of the product and tell you and your listeners that it's the best $89 I ever spent."



LEO:  Yay.



STEVE:  "Regards, Chris Day - MBA, BSc with Honors, CISSP, MCSE, CITP, and MBCS."



LEO:  OverAchiever.com.



STEVE:  And XYZ.  Longtime Security Now! listener and first-time contributor.



LEO:  That's great.



STEVE:  And Chris, thank you very much for sharing your success.



LEO:  I love it.  All right, Steverino.  Got questions for you.  And I know you have answers.



STEVE:  And I knew we'd be long, so I chose eight rather than our regular 10.



LEO:  Easy, easy.



STEVE:  Yeah, it'll be fine.



LEO:  Steve, are you ready?  Do you feel - you've got your thinking cap on?



STEVE:  I've had some more coffee, so yes.



LEO:  During that break.



STEVE:  I've been sipping.



LEO:  Paul from Burlington kicks us off with our Q&A, our "listener-driven potpourri," as you are wont to call it.  He's been thinking about these persistent cookies from Verizon, and I guess now we know AT&T's also doing it.  He writes:  Steve and Leo, I thought during the Q&A, if you want to block the cell service provider cookies, well, use proXPN because proXPN is the only people that ever see the cell provider tags.  The remainder of your browsing traffic will be within the encrypted payload.  Of course you could always just use WiFi or, better yet, both - proXPN over WiFi.  Is that true?



STEVE:  Well, yeah, except that this spoke of a little bit of a confusion that I wanted to take the opportunity to correct because I saw that a number of people had it.  What Verizon and AT&T are doing is they're adding - and this is actually why techno purists like me and so many others are annoyed is they're actually modifying the traffic.  They're seeing a query in the clear, not encrypted, going out of one of their subscribers.  And they're adding their own header to our headers.  And it's just, I mean, the idea that they're doing it just, you know, that they're making a change to our headers.  It would almost be like they themselves monitoring the cookies that our browser is sending.  I mean, who knows that they're not?  They could be.  But in this case they're adding their own cookie because, if the traffic is unencrypted, they can do that.  And that's the key.



LEO:  Yeah.



STEVE:  It doesn't matter how you encrypt it.  You could encrypt it with proXPN or just HTTPS.  They're unable to do this completely during any encrypted transaction, whether it's tunneling encryption that completely bypasses them or, you know, HTTP is a tunneling protocol.  Technically it brings up a standard TCP connection and then negotiates with a handshake the keying and authentication that'll be used to verify the endpoint, that you're talking to the server you expect.  And then nothing you're doing in there is available to the outside.  So these guys are completely blind to any form of encryption.  So where Paul sort of misunderstood what was going on was he said that only proXPN could see the service provider cookies.



Well, in fact there are no service provider cookies.  Either they're able to alter the actual headers in the query to embed their cookie, or not.  And if not, then they're adulterating your traffic in no way at all.  They're making no change at all.  So any kind of encryption that you imply.  Yes, a VPN means that secure or nonsecure traffic is protected.  Or if you can arrange for all the sites you go to that you care about, and more of the major sites every day are encrypted, then that's protection, too.  So it ends up only being those sites that don't have persistent security where there's really any problem represented.  And we're seeing more and more sites bringing up HTTPS all the time, which is good.



LEO:  Yeah.  Greg, writing from an undisclosed location, wonders about big data center security:  Steve and Leo, longtime listener and all of that, since the very beginning.  The podcast usually covers down-in-the-weeds technical stuff.  But I've been curious about a larger strategic security topic:  How on earth do medium and large websites stay online despite all of the constant zero-day exploits out there and the complex software running behind most web servers?  I wonder that myself sometimes.



There are always some vulnerabilities we don't know about.  So wouldn't it make sense for attackers to use those on high-profile targets like Google or CNN?  Obviously these sites have a lot of redundancy built in, full-time security staff.  But why don't we see more frequent defacing or takedowns of high-profile sites?  What measures do businesses put in place to remain online?  That's kind of the more interesting question.



STEVE:  Yeah.  And I thought it was a great question.  And at one point, as you were reading that, I was thinking, yes, on a wing and a prayer.  But really it's the case that we now understand how to do this.  I would argue that in the beginning we were still, "we" as an industry kind of collectively, we're still learning about things like cross-site scripting vulnerabilities and cross-site referral exploits and, lord help us, SQL exposures.  And so there were a lot of mistakes being made.  And hopefully we saw other people getting bit by those and then fixed the same things we were doing before we got bit by them.



So it's definitely the case, as Greg mentions, that these large sites are very complex.  But it isn't impossible technology to get right.  It's just hard.  So the fact that they've got a full-time IT staff, and that they scrutinize everything that they do, and that they have an architecture designed for security, that is designed with security in mind.  It's no longer the case that you can take a system out of the box and set it up and, without any regard for security, go on the 'Net, make this thing globally available with all kinds of bells and whistles and have no problems.  You're going to have problems.



And I remember the time, back like 10 years ago, or actually a little bit more, when I was implementing my own eCommerce system from scratch.  There were shopping cart applications you could get.  That's the last thing I was going to do because they were all proprietary.  They were closed source.  And we kept seeing them having egregious problems.  Well, we don't see that so much anymore.  So those lessons have been learned.  We understand now to a much greater degree how incredibly careful we have to be if we're going to put this content on the 'Net.



And it's still the case that the smaller, less conscientious sites are having problems because they have unprofessional people who are sort of using the default setup.  They've got SQL Server running and with exposed ports because, oh, it's convenient, or that was the default settings.  And where they're not bolted down, they're still getting low-profile attacks.  But the big boys really, by really focusing on what the vulnerabilities are, today I think we've learned how to make them secure.  We didn't understand that to the degree we do 10 years ago, but we're moving forward, thankfully.



LEO:  Yeah, I could talk about this on and on and on.



STEVE:  Yeah.



LEO:  Because we have, you know, there's a lot we have to do.



STEVE:  Well, and you guys have used things like Drupal, where there have been security problems, not in your code, but in the packages that you were importing.



LEO:  Right.  And there just was a big one in Drupal itself.



STEVE:  Yeah, that's why it came to mind, yeah.



LEO:  So it's somewhat similar, though, in thrust and idea, to the way a normal user keeps themselves secure.



STEVE:  Right.



LEO:  You keep updated.  You keep up on what's going on.  It's just that there's a lot more software, and you have a public face.  So there is a place people can bang on you.  At home your public face is your router, and it's stupid.  But we have a server as a public-facing entity.



STEVE:  And I think in the typical web experience you also have a more heterogeneous environment.  That is to say that many websites are assembled from pieces to fit the need.



LEO:  Right.



STEVE:  And so many companies' needs are different.  So no two are exactly the same.  And so there can be unsuspected interactions between them to create opportunities for exploitation that exist here but not there.  So it's not easy.  And you're right, Leo, it's something that it's important to do, and it's worth doing.  And look at the value that we now get from our sites.  It's just, you know, it's the way the world works.



LEO:  Yeah.  But it's doable.  It's not as hard as - and as you say, we've learned a lot.  From Pedro Tarrinho in Porto, Portugal - oh, I like this.  Let's just go there to answer this in person.  Steve, my name is Pedro - and I know I'm saying it wrong, Pedro - Tarrinho, from Portugal. I'm a new viewer and listener and enjoying the podcast very much.  Regarding the comparison on digital certs, besides the support level, there's another big difference.  To my knowledge there are three kinds of certs:  the DV, Domain Validation; the OV, Organization Validation; and the EV, Extended Validation.  The DV will only validate the domain and can be done automatically and quickly.  The OV will do the previous analysis, additionally verify the domain is registered to a company, and that the request comes from an authorized individual at that company.  The EV, well, that's an exhaustive analysis which includes the previous ones, plus further verifies the identity of the company making the request.  Keep up the good work.  Regards, Pedro.



STEVE:  I really appreciated this.  I don't think I've stressed enough that this is the way certificates break down.  I know I've talked about Extended Validation from a technology standpoint extensively.  But I was glad for Pedro's addition here because we were talking about the cheap certificates and, like, scratching our heads, like wait, how can this be, whatever it was, $4.80 a year or something.  Well, it is only for Domain Validation.  That is, essentially all they're asserting is that the certificate for the domain is for the domain.  And so it's sort of the default level of establishing a secure connection with a remote server.  But we've also said oftentimes that's all you need.  I mean, increasingly, it's useful to know that you're really connected to an authoritative source.



So PayPal and eBay and GRC and other properties will be protected by an Extended Validation domain, broadcasting the fact that all of this research that Pedro enumerated did go into and goes into continuously every two years, because that's as long as those certs can live, to assert absolutely what's known about the entity that was issued this certificate, which the server you've just connected to has provided to you.  But for blog posting and protecting low-level properties, where you just want privacy, there's absolutely nothing wrong with the so-called Domain Validation certificate, where the only thing it's asserting is that this is a certificate for this domain.  So good luck.



And so they're not very expensive.  And we would like them not to be very expensive because we'd like to promote the use of HTTPS everywhere and as much as possible.  They can have longer lives, so they're less inconvenient.  And all they're asserting is this is a certificate for that domain.  And that's all we're saying.  So I really - I'm glad Pedro mentioned this because I have not gone into enough that there really is this spectrum from minimal assertion to maximal assertion.  And what you pay for is the work on the other end of standing behind those.



LEO:  Yeah.  Question 4 from Troy K. in Kansas.  He says he's wondering about Secure Erase and Enhanced Secure Erase:  I use Secure Erase to clear SSDs.  The following site discusses the difference between Secure and Enhanced Secure Erase, it's partedmagic.com.  I admit I'm confused by how this would work on a spindle drive, but it makes sense on a solid-state drive.  A verbose report can be generated at the end of the process.  I've had the media tested.  Data has not been recovered from these drives.  There appears to be some documentation available.  But you know what, we get this question a lot.  It is worth revisiting the topic because you are the king of hard drives.



STEVE:  Well, and I'm going to - I wanted to say - he asks is there any chance we will revisit the topic.  And I still have my own drive-erasing utility on the burner for work or for creation after I'm through with the SpinRite series.



LEO:  Oh, good.



STEVE:  Well, the SpinRite 6 series, and before I start on 7.  I have a trademark on the name Beyond Recall for years.  So this is something I've always thought made sense.  So rather than attempting to address it now, I'm going to wait until I am deep in the weeds, developing something that will be able to claim absolute mastery over erasure.  And at that point we will know all about it.



LEO:  But there are specific challenges to solid-state that don't exist with spindle drives because of the wear leveling; right?



STEVE:  Well, kind of, except that the physical media has sector relocation.  And it's different than wear leveling.  Wear leveling is being done on the fly all the time in order to, as it sounds like, level the wear on an area.  What's been found is that access patterns across a large chunk of mass storage is extremely non-uniform.  You've got a swap file, typically.  You have a temporary file directory.  You have even the directory tree itself.  That so-called metadata sits in specific sectors and clusters on the drive.  And during the course of use, many of those are being rewritten to a much greater degree than, for example, the original OS files that are only being read.  They're almost never being rewritten.  Or files, you know, like applications that you install, and they're only being read and never written.



But as we know, these solid-state drives fatigue because the way they work is by deliberately stressing their insulation.  By forcing electrons through an insulating layer and stranding them to create an electrostatic charge, we are able to store a bit.  And the act of pushing electrons through the insulation fatigues, it breaks down that insulation over time.  And so reading is - it doesn't require moving electrons.  It requires only sensing them.  But writing requires that we either pump or pull electrons through that insulating barrier, and so that fatigues the drive.  What that means is that excessively writing in one area will physically fatigue certain locations.



So understanding this, this sort of a meta architecture was developed where unused areas, the actual contents of unused areas would get replaced with the contents of heavily used areas.  That is, so that even though, from the outside, we always appear to be writing on the same physical sectors, the same sector numbers, there's a translation layer which says, oh, now at the moment we've moved that data over here because it was being written a lot.  So now it's over here, so intercept any read and write requests to this range and send it over to that range.



And so this process is going on all the time.  What that means is that it may be that some areas of the drive have older data that has stopped being written to in favor of wear leveling which is writing to a different area.  Yet forensically, if you were to penetrate that translation, that meta translation layer, and access all of the physical drive, you could find data that you thought you had erased, but you'd erased it through the translation layer, which wouldn't have given you access to this briefly out of service, previously written area.



So what secure erase does is essentially says, okay, we're deliberately shutting down meta translation.  We're going to do a true physical access to the actual media and, one last time, or maybe not, if you want to keep using the drive, but we're going to absolutely wipe it all so that no one can get to it again.  And so this is similar to the secure erase function on hard drives because hard drives take sectors out of service which the drive no longer trusts.  It may still be readable.  It's just that the error correction required started to freak the drive out.  It's like, oh, this is requiring near my maximum amount of correction, or retries in order to read it at all.  This is getting flaky.  I'm going to stop using it.



But it leaves the data there because it's in a hurry, sort of someone's waiting for their data, and so it just says, okay, stop using it, we're going to copy - now, we did successfully recover the data from that sector.  We're going to put it over here.  And future references go here, not there.  But the data's still sitting there.  So again, the different types of erase penetrate these translations in different ways and to different degrees.  But it turns out it's not simple.  It's not just a matter of saying, oh, format, which we learned long ago when Peter Norton famously taught us that format does almost nothing because, if you can have an unformat command, you know you didn't really achieve much.



LEO:  Hey, you know that drive you formatted?  Can you stop that?



STEVE:  It'd be like unerase.  Oh, I want to issue the unerase command.



LEO:  Right.



STEVE:  Except, wait a minute, if you can do that, then...



LEO:  It ain't erased.



STEVE:  ...we've got a problem, yeah.



LEO:  Yeah.  Curtis in Phoenix wonders about credit card payments with SQRL.  SQRL is, of course, Steve's amazing magical website authentication protocol that he's...



STEVE:  To be demonstrated momentarily, actually.



LEO:  Oh.  That's exciting.



STEVE:  Yeah.  We're about to have it - it's about to be running.



LEO:  That's exciting.  Can't wait for that.



STEVE:  Yup.



LEO:  I envision scanning a QR code displayed on a payment terminal by my phone, he says.  Using Target as an example, I set up an account at Target.com with my CC info and my SQRL ID.  When I'm in the Target store, the terminal displays the QR code.  I scan that with my phone.  And then the magic happens, by telling Target who I am, authenticating, and then using that credit card information that Target already has on file.



Now, granted, they'd still hold a database of credit card information that could be stolen, but I would think those databases are more secure than the pay terminals.  These options would make it just that much harder for an attacker to gain information.  Another option would be to transmit the credit card info or some ID like Apple Pay uses in the - I've got the hiccups, sorry about that - in the SQRL conversation between my phone and Target's servers.  That way they wouldn't even have to store the credit card number.  What do you think, Stevie?



STEVE:  Okay, so I'll talk while you get some water or drink upside down or...



LEO:  I'm going to drink upside down.



STEVE:  I think, you know, I did hear that a spoonful of sugar, that's the one.



LEO:  That's the actual remedy.



STEVE:  Yes.



LEO:  Not an old wives' tale, but scientifically proven.



STEVE:  Knocks them right out.



LEO:  To calm the spasming diaphragm.



STEVE:  Yeah.  Interesting, yeah.  Okay.  So, Curtis, yes.  It's true that exactly what he suggested would work.  SQRL is, from my standpoint - and people are starting to ask about FIDO and does FIDO make SQRL obsolete, or where does it sit and so forth.  The thing that I like about SQRL, that I still like about SQRL, is its incredible simplicity.  What it is in its heart is a very simple, using state-of-the-art but easily explainable crypto, authentication system.  It avoids the problem with replay attacks.  The problem with a credit card is replay.  A credit card attack is a replay attack.  Someone gets your credit card, and they use it again.  They replay the number that they got.  So, and username and password, replay.  They capture your username and password, and they replay it.  They use it again.



So what SQRL does is it just - it's like the smallest thing you could do to solve that problem, which is you have a secret, and the server generates a random challenge, which you sign using your secret, and you send back to the server your signature of its random challenge.  And the challenge is always random.  So we solved the replay attack.  The server is never going to, or never going to predictably offer that same challenge again.  And only if you're really you do you know, do you have the secret that allows you to sign that random challenge.  So when that goes back to the server, it checks the signature, and it says, oh, yeah, someone just signed this correctly.  That must be him because nobody else can.  And it's that simple.



So what Curtis described is how you would use a generic authentication system - and that's what SQRL is, it's a generic simple authentication system, but it's cryptographically secure - how you would use it for credit cards.  And so while it's, yes, that would work, my feeling is, well, but then so does MCX and Apple Pay.  And so if alternatives didn't already exist that people were already going to be using, and if we sort of like needed SQRL for that, then, yeah, it could certainly work that way.  But I'll be surprised if that happens.  On the other hand, websites in general is still my target because they still haven't got a universal simple comprehensive solution to replace usernames and passwords.  And SQRL does that very easily.  So I think there it makes sense.



It could absolutely, I mean, I know - the reason I spent some time on this is that there's all kinds of applications for authentication.  Maybe we will see this simple protocol that I've developed for SQRL used elsewhere.  And I know people are going to be saying, hey, about this and how about that?  It's like, yeah, it can do anything where you have a random challenge, and you are able to assert you're you by signing that challenge and sending it back.  It's able to do that.



So what enables this that we have now is smartphones or clients in our machines.  Once upon a time, all we had, you know, we didn't have those, so we had to use username and password, something that we could memorize that didn't change.  And of course we now know that's dangerous in all kinds of ways.  So the good news is the world has moved forward.  It's easy to run clients in our computers or our smartphones that are active and have the computational power to answer a cryptographic challenge.  And so that's really all SQRL is.  I mean, it's pretty simple.



LEO:  Does it eat nuts?  I'm sorry.



STEVE:  It can do that, too.



LEO:  I'm having some right now.



STEVE:  It can solve your hiccups.



LEO:  Mm-hmm.  I'm eating a little sugar.  It worked.  Bubba Mustafa, or is it Bubba?  Bubba Mustafa - I'm sorry, I'm sure it's his real name, and I shouldn't be laughing - wonders about long-term data storage.



STEVE:  It's a beautiful fun name.



LEO:  Bubba Mustafa.  Man, if my name were Bubba Mustafa, I would be so happy.



STEVE:  I love it.  I love it.



LEO:  Steve, I heard you talking about data decay.  What are our options, say for a true 10-year retention?  Do archival-quality CDs and DVDs live up to the sales pitch?  The CD version seems just to be the original gold CDRs when CDRs first came out.  I have to admit, for regular CDRs I have had the aluminum coating just delaminate and peel right off.  Thanks.  Still haven't needed to use my SpinRite, but I'm happy to know it's there for the inevitable.



STEVE:  So this is really a good question.  And I'm finding myself wondering if maybe the cloud isn't, like redundant cloud provider storage isn't a solution, sort of making it somebody else's problem, essentially, and maybe adding some redundancy.  The problem is, I mean, we talk about time capsules and the fact, for example, that many people would have a hard time today reading a floppy.  I mean, and that's a 3.5-inch floppy.  What about a big one?  I think I've got one around here somewhere.  Actually I have a bunch.  I've got 5.25s and 8-inch floppies.  Now, someone says, okay, I have an 8-inch diskette with data on it that I need.  What are they going to do?  In fact, I saw somebody on one of your podcasts, you'll probably remember it, Leo, in the last month or two or something.  He was having a business maintaining drives that would be able to pull obscure data formats off of media.



LEO:  It was on the radio show.



STEVE:  Oh, okay.



LEO:  Yeah.  So this is a - and we talk about this a lot on the radio show.  I think this is something people are kind of interested in.  And I always say, you know, nothing will last forever, yeah.  Not even paper.  Carve it into stone because that's the stuff that's lasted thousands of years.  We know that CDs and DVDs not only delaminate, but they can get, in humid climates, they can rust.  You're holding up a QR code.  What is that?



STEVE:  I'm holding up what my SQRL client puts out.  And because it is something that I absolutely know - I can't seem to get it centered - but there is an ASCII version of a SQRL identity.



LEO:  That's what the QR code says.



STEVE:  Yes.  And so you could either scan it with the QR code, but if you were even absent a camera, I don't know how that would happen, but...



LEO:  Type it in.



STEVE:  Type it in.  It's not that long.  It'll tell you if it's right or wrong, and then you go from there.  So, I'm sorry, but, yeah.



LEO:  I agree with you on the cloud thing because really the issue, once it's bits, we've kind of solved some of the problems because it's infinitely copyable and perfectly copyable.  So there's no copy degradation.  And that's a big issue with print, with handwritten stuff and so forth.



STEVE:  Oh, those monks, they did amazing work, didn't they?



LEO:  Yeah, but still errors would creep in, transcription errors.



STEVE:  Yeah, sometimes there were little embellishments and, you know, I mean, they were bored.  If you were a monk, you'd have a hard time, too.  It's like, this is such boring text.



LEO:  So once you've got bits, kind of you've done a big thing, but now we have to keep it on media that doesn't obsolete.  And you mention floppies, but ZIP disks, ORB drives, Bernoulli drives.



STEVE:  Got them all.



LEO:  Winchester media, all of those things, they seemed like they'd be good enough.  But a few years, and they're gone.  So I like your cloud idea because what you're really doing is you're transferring the issue over to the cloud provider.  Sure, it's on some format that will be obsolete probably sooner than later, in a decade or two.



STEVE:  But they'll migrate it.



LEO:  But they are now going to migrate.  As long as they stay in business, they're going to migrate.  So, I mean, and that's what you could do.  Keep it on a hard drive, and then every few years rewrite it.  Keep it on several hard drives.  Of the physical media we have available to us now, what do you think is the most robust?



STEVE:  Optical.  Everybody agrees that, even though it seems sort of counterintuitive, the recording technology - now, again, it is the case that we've seen problems with disks delaminating and the aluminum layer oxidizing and that being a problem.  But that's why they use these gold disks and so-called "archival quality."  I've seen studies done that said archival-grade CDs and DVDs truly have a hundred-year life.  That is, you can record on them.  You've got to keep them in the dark because a little bit of light coming in will accrue, essentially, sort of like film, slowly fogging over time, if you allow any light to get to it.  So you've got to store them in absolute dark in a sealed, moisture-controlled, dark container.



But everything that - all the tests I've seen where they've deliberately aged these things, if you need your own media, that's what I would do.  I wouldn't trust a drive, frankly, because, I mean, they've got bearings.  And it's a high-tech device.  And they last for, what, maybe three or four years?  And then it's like, oh, well, I need another.  I mean, unfortunately, their capacities are growing so much, and our need for storage is growing so much, that we're constantly moving upwards in drive size.



LEO:  Yeah, and the best thing would be multiple forms of media; right?  I mean, this is the...



STEVE:  Yeah.



LEO:  So don't trust any one.  I mean, not merely optical, but optical and hard drive, or maybe Blu-ray and DVD, I mean, just multiple choices; right?



STEVE:  Yeah.  And you ought to also consider maybe, if you had - if you were writing to CDs and DVDs, store the drive you used along with them.  Put them into the time capsule because the chances are, depending upon what the future holds, you'll have the drive that was able to read them once.  And then your job is an electrical interfacing one to the drive, rather than, oh, my lord, how do I get the optical tracks off this thing?



LEO:  Right.



STEVE:  So that's an easier problem.  Also, you'll notice that I mentioned redundant cloud usage.  Was it Bitcasa that just announced they were shutting down, and everyone's storage was being lost.



LEO:  Bye-bye.  Yeah.



STEVE:  Yeah.



LEO:  So more than one cloud server - service.



STEVE:  Right, right.



LEO:  And keep an eye on their businesses.



STEVE:  Or use Amazon or Google or Microsoft.  Use a major league provider that has, instead of Bitcasa, which is like, okay, well, you may like them, but obviously they decided they were changing their mind about what they were going to do.



LEO:  Amazon has this Glacier solution.



STEVE:  Yes.



LEO:  Which is inexpensive.  And it's very cheap because it's slow to restore.  It might take a day to get your data.  But who cares?



STEVE:  Yeah.  It's actually offline storage.  So they're filling up something, whether it's drives, or they might even be using those really cool, like, tape spool technology, where they fill them up, and then it's like it's actually not accessible electronically in real-time.  Somebody or something, a robot arm or a person, has to go get it and plug it in, in order to access it.  So, yeah.  I really think there's a - the problem of destroying data is a big one.  But the problem of really keeping it archivally available is interestingly big, too, actually because we don't really think about it much.  It's not a problem everybody has, but some people have that problem.  And there isn't really anyone really addressing it.



LEO:  When we sent V'ger out into space, we put a gold disk in it because gold - not because gold is so pretty and valuable, but because it doesn't corrode.



STEVE:  Right.



LEO:  And it has, I presume it's not analog, maybe it is, an analog recording.  I guess, yeah, it probably is because probably any relatively advanced civilization could figure out what to do with that.



STEVE:  Yeah, they did a bunch of neat things.  They did things like the size of the raster scan on the image was two prime numbers.  So there was only one way to decode this into a rectangular...



LEO:  So that's going to get really big brains thinking about how would we communicate with a completely alien intelligence?  And oh, by the way, it's got to survive millions and millions of light years in space.



STEVE:  Yeah.  And they know nothing about us, and they look at this gold disk and go, hmm.  Well, let's see.  This looks like a spiral.  Well.



LEO:  And then they eat it.



STEVE:  Oh, it looks good.



LEO:  Cookies.



STEVE:  Because, exactly...



LEO:  Love that gold.



STEVE:  They're creatures that live on gold, and it's like, ooh.



LEO:  Good gold.



STEVE:  Or they immediately melt it down and resell it.



LEO:  Right.  Pretty.



STEVE:  Yeah.



LEO:  Yeah, it is an analog track, apparently.  I think analog makes the most sense.  Although ones and zeroes, binary is pretty well understood.  I think you could deduce that there's information in the switching back and forth of ones and zeroes.  Maybe not.  It's not decimal.  That would definitely be anthropocentric.



STEVE:  Yes.



LEO:  Fascinating, though, isn't it?



STEVE:  Yeah, it really is.



LEO:  Kevin in North Carolina wanted to clarify.  Oh, this is from last time.



STEVE:  You know, when those meteors land on Earth, Leo, we just think they're rocks.  Little do we know.



LEO:  Oh, look.



STEVE:  Look at that rock.  And we stick it in a glass case.  It turns out that's a desperate attempt at communication, and we've completely missed the point.



LEO:  You know, that actually seems reasonable, frankly.  What would be the chances that we would recognize the communication?



STEVE:  Yeah, it's like, look, what's this rock?



LEO:  Yeah.  Kevin in North Carolina wanted to - because we answered his - so he says:  Short-time listener Kevin here again.  Thank you for addressing my previous question regarding random MAC addresses. I don't mean to be a pest, but I wanted to clarify.  I wasn't referencing the Apple randomization while searching for WiFi.  Oh, because we had been talking about that recently. 



STEVE:  Right.



LEO:  My feedback was in regards to another question that came up previously about MAC addresses in general.  The other listener asked:  Why doesn't every device use random MAC addresses?  Why even bother having a fixed, unique MAC address? It doesn't make any sense.  So that's back to four episodes ago that we answered that one [SN-476].



STEVE:  Yup.



LEO:  As was discussed then, it's feasible to have randomly created and assigned addresses.  But there is a value in a fixed unique address because it identifies, for instance, the manufacturer.  That's the first few digits.  So that's what he was asking about.  Anyway, thank you, Kevin, for the clarification.  I don't think we have to say much about it.



STEVE:  No.  I'll just add that, back then, when we originated Ethernet, bits were expensive.  They were slow, and they were expensive.  And so it made - so to have a random MAC address you'd have to have many more bits and somehow assign them randomly.  And that just didn't make as much sense as chopping it up into two halves and making one be the manufacturer and one be this manufacturer's serial number.  It was a clever scheme that has survived even to this day.  So anyway, Kevin, yeah, thank you for the clarification.



LEO:  Finally, our last question comes from Ottawa.  Peter Sysak has been catching up all the way since Episode 1.



STEVE:  Whoo.



LEO:  First of all, I want to say that I love Security Now! and TWiT.  I only discovered your show a few months ago.  And after listening to a few new episodes I decided, you know what, I need to start from the beginning.  Holy cow.  Holy cow.  So for the last few months I've been trying to work my way through everything since Episode 1.  I can't tell you how daunting a task that is, but I find there's always something useful.  As such, I haven't been able to bring myself to skip too many episodes.  I really wish I had discovered this show years ago.  In a way, it's really interesting to listen to the old shows today and hear you guys go on and on about all the stuff that was happening a decade ago.  A decade ago.



STEVE:  Our own time capsule.



LEO:  Yikes.  Obviously, there are a ton of things that are long forgotten today.  But it's also funny how some things just never change.  With that, I wanted to ask you a question about an episode I just listened to, namely Episode 81 in which you discussed the Google report on hard drive reliability.  Forgive me if you've done something like this more recently, but I - 81?  You mean 400 episodes ago?  Eh, that's recent.  I was wondering - 400 episodes ago.  We do 50 a year.  All right.  I was wondering if there's any way you could touch on that topic again, but speaking to today's hard drives.



Is SMART still as dumb as it was then?  Yes.  I'm personally running a FreeNAS server with a RAID-Z configuration consisting of several 2TB drives.  I'm relying on SMART tests to warn me about impending disk failures so I can go buy a new one in time.  But now that I listened to Episode 81, it's kind of shattered my sense of comfort with that setup.



As a secondary question, does SpinRite do anything with SSDs?  I never knew about SpinRite until I knew about the show, and basically everything I have today runs an SSD.  Really?  His 2TB drives are SSDs?  Whew.  No.  Thanks for the great work you guys do.  I'm slowly catching up.  I'm now, ladies and gentlemen, on Episode 82.  Wow.



STEVE:  So Peter, here's my advice about catching up.  Don't be in a hurry.  Don't worry, I mean, first of all, the information - we're archivists.  I've got a lot of mileage left on me, and I intend to have all of these 10 years online for the foreseeable future.  So unless you're 95, you're going to have time.  So I would say don't be daunted by it.  Don't press yourself.  Also try not to skip them because there really is often surprisingly good stuff every so often in these things.  So unfortunately I can't vouch for them all.  But I think generally people never feel like they've just had a really dud Security Now! podcast.  So take your time.



SMART is all you've got, so it's better than nothing.  But as Leo added, it is still dumb.  The problem is...



LEO:  It hasn't gotten any smarter since then.



STEVE:  No.



LEO:  Let's put it that way, yeah.



STEVE:  The reason SpinRite and SMART work so well together is that SMART can't tell you anything about the drive that it doesn't experience.  And as we were just talking about how lopsided access patterns typically are in drives, where a very small area of the drive is in heavy use, it's the fact that SpinRite goes out and covers the entire drive while monitoring the feedback from SMART that makes the two of them together smart.  Now, SMART will warn you, on the fly, if it's seeing a problem in advance of a collapse.  But it has to experience that for that warning to be useful.  So that's really where SpinRite comes in handy.  SMART's better than nothing.



And having a RAID architecture which is able to periodically query SMART, because it's not an announcement protocol, it is a query-response protocol.  You've got to ask the drive how its SMART subsystem is feeling right now in order to get a response.  SpinRite polls SMART on the fly and displays and analyzes the information that it gets from the SMART subsystem in order to determine what's going on.  Your RAID system is also polling periodically to check on the health of the drives as they're reporting it.  The problem is they don't know about areas that they're not accessing dynamically.



And what's really interesting is that SpinRite works the drive hard, and we see the SMART health being depressed by SpinRite.  And then over time, it recovers because, I mean, and that represents some problems on the drive that are of a severity you can judge based on how far depressed the drive reports its health to be.  But the point is it has to be doing work in order to judge the health of its ability to read.  And I'll just close by saying that in the testimonial in this podcast you just heard, assuming that you're still listening to the current ones and not...



LEO:  He'll hear it in a couple of years, anyway.



STEVE:  You'll hear it when you catch up.



LEO:  Yeah.  Hello from 2014 to those of you in 2018.



STEVE:  Exactly.  The testimonial was about this guy using SpinRite to recover an SSD that the SSD's own manufacturer broke when it was trying to fix it.  So, yes, SpinRite absolutely does repair SSDs.  And we've actually - you'll find, as you catch up, many other testimonials from SSD users, which is actually one of the reasons that I decided to get interested in a future beyond SpinRite 6, which I call 7, because even though magnetic media may stop spinning, it looks like the solid-state stuff still needs us.



LEO:  Nice.  My friend, we've come to the end of your question-and-answer session.



STEVE:  Right on time.



LEO:  Right on time.  On time and on budget.



STEVE:  And with no hiccups.



LEO:  And with no hiccups.



STEVE:  Of any nature.



LEO:  Well, I had little hiccups.  Little bit of a hiccup.  Thank you, my friend.  Steve's so great.  I love doing this show, and it's 10 years, it seems like nothing.



STEVE:  It does.  And so it's funny, you talk about Episode 81, it's like, wow, I remember that Google drive reliability report.



LEO:  Oh, yeah.



STEVE:  And that doesn't seem that long ago.



LEO:  No.



STEVE:  But I guess it was.



LEO:  Goes fast.



STEVE:  Yeah.



LEO:  We love doing this show.  And Steve will be back next week doing it again.  We do it Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That would be...



STEVE:  Is it now...



LEO:  2200 UTC.



STEVE:  Okay.



LEO:  I add - no, no.  Oh.  I had a really good...



STEVE:  Isn't there a minus seven?  I thought it was minus seven or minus eight.  But that would have been...



LEO:  2100.  It's minus eight.



STEVE:  Oh,  okay.



LEO:  Was minus seven, but now we've reverted to daylight - not in daylight time, regular time.



STEVE:  Whatever it is.



LEO:  Non-summertime.  Standard.  Standard time.  So it's now 2100 UTC.  You know, I have a method now because it's eight.  It's I add eight.  So 12 plus eight is 20.  So I just add 20 to whatever time you start, so it's 2100 UTC.



STEVE:  Nice.



LEO:  See?  I thought about this.



STEVE:  That works.



LEO:  If you can't watch live because you can't figure out what time it is, don't worry.  On-demand versions always available.  Steve's got a great little tiny 16Kb version, sounds like it came from 1928, but it's small.  You could also get transcripts which are even smaller.  He has handwritten human readable transcripts at his site, GRC.com.  You also can find SpinRite, world's best hard drive maintenance and recovery utility, now for SSDs. You can also find all sorts of projects he's working on.  And those are all pro bono, so free, free, free.  So Perfect Paper Passwords, Password Haystacks, of course SQRL.  You could find about Vitamin D.  You could find about ketogenic diets.  You could - there's all sorts of stuff there.  It's kind of like the Dr. Bronner's Soap bottle of websites.  Except the type is bigger.  You know Dr. Bronner's Soap?



STEVE:  I heard of it, yeah.



LEO:  Yeah.  You should get some.  It's nice.  Peppermint.  Very smelly.  It smells good.  Smelly good.  Very good smelly.



STEVE:  Thus the fact that they're still in business.



LEO:  Yeah.  There's actually a documentary on Netflix about Dr. Bronner because he passed away a while ago.



STEVE:  Ah.



LEO:  But the kids...



STEVE:  The soap lives on.



LEO:  The kids are still - I think it's in your neck of the woods.  You could go to the Dr. Bronner's Soap factory, which is basically a big tub with a little bit of lye...



STEVE:  People staring at it, waiting for it to dry out.



LEO:  Yeah, yup, yup, yup.  What else?  Oh, we've got high-quality audio and video at our site, TWiT.tv/sn, Security Now!.



STEVE:  And your own archive.



LEO:  Oh, yeah, we've got every show going back.  We're redesigning the website, and one of the things I know everybody wants is a one-button download of everything.  It's for your show only.  Nobody's asked about any other show.  But for your show, everybody wants all of them.  So, yeah, that's a big checkmark for the new website.



STEVE:  Oh.



LEO:  Oh, yeah.



STEVE:  Oh, nice.



LEO:  Hey, I listen.  You think I'm not listening?



STEVE:  Very nice.



LEO:  But I'm listening.  I'm knitting.  I'm making socks.



STEVE:  I get it all the time.  I get it all the time.



LEO:  Yeah.  No, I know.



STEVE:  And hiccupping.



LEO:  We also have, you know, all those apps, great third-party developers who've made apps for every platform including Roku.  And so you can look for the TWiT app on your favorite platform.  You'll probably find it.  Windows Phone, iOS, Android, Roku, that kind of stuff, Samsung TVs.  And then there's iTunes and all the other places you might subscribe to a podcast.  We're there, too.  Because, you know, with a show that's been around for 10 years, there really is, I mean, it's like we win because everybody else gave up.



STEVE:  Yup.



LEO:  A long time ago.



STEVE:  They and Dr. Bronner.



LEO:  We're like V'ger.  We just keep going.  Keep going and going and going.  All right.



STEVE:  Okay.



LEO:  You should read, by the way, a little plug, just I'm in the middle of it right now, but it's good, "Whiskey Tango Foxtrot."



STEVE:  Oh, okay.  I've heard you mention it.



LEO:  It's a novel.  And it's about privacy.  And we won't know that immediately because at first it just seems like unrelated stories about people.  But it's all knitted together about halfway through.  And it ends up being - it's sci-fi.  It ends up being a massive global conspiracy to invade our privacy, not by government, but by private industry.



STEVE:  No.  They wouldn't do that.



LEO:  They would never do that.



STEVE:  No.  Monetization.



LEO:  It's really - it's really good.  It's funny, and it's fun, and I think you'll like it.



STEVE:  Oh, neat.



LEO:  It's a cautionary tale.



STEVE:  Yeah.



LEO:  WTF, "Whiskey Tango Foxtrot."



STEVE:  [Laughs]



LEO:  Oh, now it comes home.  Yeah, now you know what I'm...



STEVE:  I get it.  I don't know what's slowing me up.  I'm a little slow.



LEO:  Now you know.  Yeah.  That makes it easy to remember.



STEVE:  Yeah.



LEO:  Hey, thanks, Steve.  We'll see you next - actually, stick around.  Did you get the Voyage, the Kindle Voyage?



STEVE:  Oh, no.  It's pre-ordered.  Jenny and I get ours on the 17th because I just didn't know about it in time.  But I've heard you guys talking about it.



LEO:  My review's coming up on Before You Buy, next.



STEVE:  Oh, good.  I will absolutely switch over to the live feed and watch because I guess from what I understand the type is so crisp, it just completely changes the experience.  And not having the screen - well, I don't mean to encroach your...



LEO:  It's fast.  No, no, no, it's good.  No, you can look.  You see the page turn is so much better now than it was.



STEVE:  Oh, nice.  I love the squeezing on the margins.



LEO:  Yeah.  This is natural.



STEVE:  I like that better than having to touch the screen.



LEO:  This is so natural, isn't it?



STEVE:  Oh, nice.



LEO:  Yeah.  Well, I'm going to give it a definite - you know, it's expensive is the only negative.  It's 200 bucks.



STEVE:  Yeah.  Mine and Jenny's is on the way.  I ordered them the moment I found out about it.  And I guess I must just be - they must be backlogged.



LEO:  Yeah.  I'm sure they are.



STEVE:  Wow, nice.



LEO:  Nicely - they did a nice job with this.  And I got the Amazon weirdo case.  I don't - the Origami.  I don't understand it.  It's too complicated for me.  Does something here, I'm sure.



STEVE:  Oh, you're able to, like, create a stand out of it.



LEO:  Yeah, it makes a stand.  It's weird.  Anyway, thank you, Steverino.



STEVE:  Okay, buddy.  Talk to you next week.



LEO:  We'll see you next time.



STEVE:  Bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#481

DATE:		November 11, 2014

TITLE:		Certificate Transparency

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-481.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events, focusing on this month's crucially important Microsoft MEGA Patch Tuesday updates which, if exploited, will allow for wholesale remote client and server code execution and takeover.  They then take a first pass look at the new "Certificate Transparency" standard and initiative being launched by Google and currently supported by DigiCert and others.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a big show for you.  His planned topic, transparency around certificates, an interesting way to find out if the certificates your site is using are real, if they're from your site, and what other certificates might be out there from somebody pretending to be your site.  We'll also talk about Microsoft's Patch Tuesday.  This may have gone unnoticed, but one of the patches may be one of the worst vulnerabilities ever.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 481, recorded November 11th, 2014:  Certificate Transparency.



It's time for Security Now!, the show that covers your security and privacy online with the guy, the man, the Explainer in Chief, Mr. Steven "Tiberius" Gibson.  Hello, Steven.  Good to see you.



STEVE GIBSON:  Hey, Leo.



LEO:  I'm going to say this right upfront because they ask this every time in the chatroom.  What are those blinky lights over your left shoulder?



STEVE:  Okay.  Those are clones of the very first minicomputer, one of the very first minicomputers I ever programmed.  The venerable DEC, the Digital Equipment Corporation, PDP-8.



LEO:  Yeah.



STEVE:  And some years ago, the very end of life of that minicomputer, which itself was like a sort of a small refrigerator-size thing, I mean, the original one was just - not even integrated circuits.  This predated the availability of ICs.  So this was the so-called "discrete" components, transistors, resistors, and capacitors, mostly transistors and resistors.  There wasn't much need for capacitors back then, in the signal path, anyway.  And so it's a 12-bit minicomputer that has three bits for the operation code, meaning that sort of nominally eight different instructions, except that the math has more power in the individual bits than the rest of the instructions.



So at the very end of life they made a chip.  They put the entire minicomputer into a single chip.  And some guy found some of those available, like on the surplus market - and I've got mail coming in here, distracting me, there - and made a kit that a number of people built.  And of course one wasn't enough for me.  I had to have three.  So there's three PDP-8s.



Oh, and I forgot to say that what the blinking lights are is the whole point of the old-style minicomputers was that they had front panels.  They had so-called lights and switches, blinking lights and switches, sometimes known as the "blinkin' lights panels."  So I wrote some software to show that off, that is, because this is the way computers back then looked like when they were actually doing something was that they sort of had a sort of a sporadic changing.  They weren't just like blinking, like randomly in a constant pattern.  And so I attempted to write some software that made them look like they were actually busy.  So nothing's actually happening back there at all.  But it's fun.



LEO:  What's the clock speed on those?



STEVE:  Boy.  Ah.  I should know that.  That's...



LEO:  It's not very fast. 



STEVE:  But, yeah.



LEO:  But you can't compare it to a kind of a standard microprocessor, either.



STEVE:  Oh, lord, no.  I know that some of the cycle times on the core memory, because that's what they used, was like 1200 microseconds, so 1.2 milliseconds.  And a millisecond would be a thousand instructions per second.  So that's right around - because there were also some cycle times of 800 microseconds, which would be a little faster than a millisecond.  So right around the average, right around the neighborhood of a thousand instructions per second.  So when - and these, for example, did not have any hardware multiply or division.  And multiplication and division are famously and sort of paradoxically difficult things.  I mean, they're time-consuming to do.  They're iterative.  And essentially you take, in the case of, for example, a 12-bit computer, if you multiply two 12-bit values, you get a 24-bit result.  So the act of multiplying involves lots of shifting and bit testing and summing.  And you need to do double-precision math where you have to take the carry from the output of the first half and then move it into the second half.



The point is that just doing something simple, like we would think of simple, like a multiply, which contemporary chips just all do instantly, you know, they've got dedicated hardware where you just give it the two numbers, and it says here's your answer, that takes a long time.  And when every single one of those processes is a thousandth of a second, before long you've used up a second, just to do something simple.



So those, I mean, what I miss about those days is you had very little memory.  4K words, 4,000 words was sort of like the starting point.  And since it was 12 bits, that is 4K.  You know, 10 bits is 1K.  So 12 bits is 4K.  So then, I mean, so that was the normal, default amount of memory is 4K words.  And they had a BASIC interpreter running, you know, interpreting the BASIC language in 4K.  Well, I wish somebody would say to me, "Steve, it's really important for us to have one," because I would just love to do that.  But no one's asking for that anymore.



LEO:  Apparently not.



STEVE:  No.



LEO:  Why not?  You'd think they'd be...



STEVE:  That's just my strange nature.  The best I could do now is program everything in assembly language which, yeah, which everybody already thinks is a little...



LEO:  You're already a crackpot.  Don't push it any farther.



STEVE:  I'm out there.



LEO:  I didn't mean to sidetrack you.  But about every eight episodes you should probably just mention that.



STEVE:  Yes, perfect.  Give me a reminder when we need to just explain what all that is back there going on.



LEO:  And a couple of times during the 10-year tenure of the show - I like that, the 10-year tenure - you have mentioned that these kits are available and - because the guy has to silk screen them in a batch and blah blah blah.  But so currently not available, these PDP-8 clones.



STEVE:  Right.  They have come and gone.  Sometimes you'll see somebody parting with one on eBay, you know, with a tear in his eye.  And, I mean, and I have some of the original PDP-8s and 11s and, like, reel-to-reel - they had a beautiful little tape drive called DECtape, which used cute little reels.  And it used a mylar technology where it was mylar on both sides containing the magnetic material, rather than traditional tape that was the oxide on one side of the mylar.  And those have not stood up well over time, whereas DECtape has.  Anyway, someday my plan is to bring all that stuff back to life.  I just, you know, if no one's going to ask me to do it now, I'll give myself the project when I'm 70.



LEO:  We do have quite a bit to talk about today.  You're going to do what you call a propeller hat episode.



STEVE:  Yeah.  There's - when I - I settled down to think, okay, what do I want to talk about this week?  And I didn't want to do another Q&A because we've had two in a row.  It was a relatively quiet security period during the last week.



I do want to talk about something really fun that happened for me.  I snuck off to Las Vegas and presented SQRL for the very first presentation of its life ever, at a security summit in Las Vegas, and encountered the lead architect of SQRL's main competition, the FIDO project that we've talked about.



LEO:  Oh, you talked to them.  Oh, good.



STEVE:  And blew his mind.



LEO:  Oh, boy.  Good.  Even better.



STEVE:  It really, really made the whole thing way worthwhile for me. 



LEO:  Awesome.



STEVE:  Oh, I really enjoyed - and the conference was hosted by DigiCert.  But anyway, I'll talk about that in a second.  The topic for today is something that's been in the air for a little over a year.  And this is another of Google's many initiatives, you know, largely which - most of which I support.  I mean, as we know, I chafe a little bit when they decide that some of the things they want to do, or I don't feel like they're being completely forthcoming, you know, the CRLSet controversy of course comes to mind.  And then I was a little annoyed at them arbitrarily pushing forward all of the expiration of SHA-1 certs just because they wanted to.  But there are other things, like we talked about SPDY.  They're working on protocols to smooth and enhance and speed up our experience using the web.  And obviously they have a huge commitment to that themselves.



Today's topic is something known as Certificate Transparency.  And there's a website, certificate-transparency.org, which is like the formal place where this lives.  There's an RFC 69 - I can't remember what it is.  I have it written down.  We'll get to it later.  But the point is this is Google's initiative, which is underway.  There is, as I said, there's an RFC submitted last July, July of 2013, to augment and fix the problems with the current certificate hierarchy.  The whole certificate authority trust, you know, root trust problem that we talk about all the time.



So there are, to really get into the implementation, I haven't figured out how to explain it in an audio podcast without lots of diagrams.  But to give everyone a sense of it, that we can do.  And that's really enough for now because I'm not sure if it's going to happen.  I mean, to listen to Google, they're going to make it happen because they're going to require it for EV certs starting early next year, like I read February of 2015, which is not long from now.



But anyway, so that's today's topic.  We'll talk about that.  And we have to talk about this is the Second Tuesday of the Month.  And as I was saying to Leo before he hit the Record button just now, I was just sort of rummaging around through the Patch Tuesday, and the third one just poked me in the eye.  It's like, oh, my goodness.  I'll be making a trip to my datacenter this afternoon.



LEO:  Whoa.



STEVE:  Like, wow.  And so will every single person running a web server with IIS.  And even Windows users who are not having servers exposed have to do this.  So we've got a big Patch Tuesday.  We've got, oh, and a surprising event in the Net Neutrality struggle occurred yesterday that I'll chat with Leo about.  I want to talk a little bit about my trip to Las Vegas and what happened.  And an important Belkin firmware router update.  So another great podcast, I think.



LEO:  Can't wait.  All right.  We're going to put you back to work, Steve.  You've got your eye drops in.  You're ready to go.  I saw that.



STEVE:  Yeah.  It's just they were a little bit dry, and I thought, oh, a little eye drops.



LEO:  Yeah.  Well, it's a good time to do that.



STEVE:  Now they're a little wet.



LEO:  Well, you're back from Vegas, and there's nothing drier.  I'm going to tell you, I go to Vegas, and I come back with a sore throat every single time.



STEVE:  Oh, my goodness.  I know, I was chapped.



LEO:  Yeah.  Chapped.  Chapped, I tell you.  So let's do the security news first, and then we'll go on with the certificate transparency stuff.



STEVE:  Yeah, of course.  So, okay.  So it is Patch Tuesday, the Second Tuesday of the Month.  And as I said, I was - oh, and we already knew that it was going to be large.  Microsoft sends out sort of a, I don't know why, but sort of a get-ready email a week before.  They're don't tell you what you're getting ready for, but just sort of an overview of, it's like, here it comes, don't forget, Tuesday.  So we knew a few days ago that this was going to be a biggie.



And it is, I mean, just independent of severity, in terms of quantity, this leaves nobody wanting.  Sixteen individual patch bundles where we often have three.  This time 16.  And in scanning through the CVE list, I counted 33 known vulnerabilities that were encompassed within these 16 bundles.  Except then I looked, and the one for IE - of course there's always one for IE - it alone had 17 privately reported vulnerabilities that it was fixing.  So then I'm thinking, okay, maybe I didn't count correctly, but - because it seems like that would lead us to more than 33.  But, you know, typically the bundles all handle multiple vulnerabilities rather than just one.  But, you know, this one IE bundle had 17, so.



Anyway, so the third one down was MS14-066.  And it's like, okay.  And I'm reading what it says.  "This security update resolves a privately reported vulnerability in the Microsoft Secure Channel" - Schannel is their acronym for it, or abbreviation, Schannel - "security package in Windows."  And it's worth noting that Schannel is in all Windows forever.  I mean, it was an original component of NT.  It's where all of the security stuff resides.  So all of the SSL, TLS, certificate handling, all of that's in Schannel.  I've programmed it many times, for example, all of that certificate stuff, the certificate fingerprinting stuff that I did on GRC's server, that's all Schannel code and so forth.



And the point is, it's in both the client and the server.  It's in Windows 7 and 8 and, okay, there is no 9, but 10.  And also in, you know, XP, in old XP machines, in Server 2003, 2008, 2012 and so forth.  So it's everywhere.  It is an intrinsic component of Windows.  So, "This security update resolves a privately reported vulnerability in the Microsoft Secure Channel (Schannel) security package in Windows.  The vulnerability could allow remote code execution, if an attacker sends specially crafted packets to a Windows server."



So first of all, it's like, whoa, what?  I mean, all Windows servers on the 'Net, by definition, have ports exposed.  That's how you get to them.  So there's no hiding for a Windows server.  It's out there.  That's what it has to be.  Then, you know, and we've talked about vulnerabilities, Microsoft's whole vulnerability architecture through the years.  So they had the Exploitability Index.  And sometimes these things are like, well, yeah, if you stood on - if somehow you could stand on your right foot, raised upon your big toe, during a full moon, and spin slowly counterclockwise while chanting, then - oh, and threw a ping pong ball through a small hoop 10 yards away, you'd have a chance of exploiting it.  Not here.  This is the worst exploitability they offer, Index 1, which they call "more likely to be exploited."



Then we've also talked about how they always have sort of these cheesy mitigating factors where, oh, a bad guy would need to lure you to a website, and you'd have to have scripting enabled and click on something and then agree to down - blah blah blah blah.  Okay.  Mitigating factors for this, quote, "Microsoft has not identified any mitigating factors for this vulnerability."  In other words, there's nothing you can do.



LEO:  That sounds good.  It's bad.  There are no mitigating factors.  Oh, that's good.  No, that's bad.



STEVE:  Yeah.  You know, like, for example, we'll often talk about how, oh, go into the registry, and you can turn, you know, add this setting to disable this obscure thing that you don't actually need and nobody actually uses, but it's on all the time anyway, so you can turn it off and then forget about it, and you're fine.  No.  There's nothing...



LEO:  Oh, that's not good.



STEVE:  ...like nothing that we know of that you can do to mitigate this.  And then they also have workarounds where, like, well, you can turn this off, and then turn - blah blah blah, et cetera.  Against, workarounds:  "Microsoft has not identified any workarounds for this vulnerability."  So what this says is that, I mean, and what I'm a little surprised about is, since I saw this, this morning, I'm seeing Twitter begin to catch up.  People are looking through this, as I did, and going, whoa, hold on, what?  Because unfortunately this doesn't have a fancy name.  This isn't Shellshock or Humpty-Dumpty or anything.  No one gave it a cutesy name.  But this is like, to understand this, from what this looks like, this is as bad as it gets for a Microsoft, like for a major Internet server vulnerability just sitting out here.



LEO:  I'm kind of surprised that they're not making a bigger deal out of this.



STEVE:  Well, they don't want to.  Oh, and the other thing that I loved was that they do make a point of saying, oh, and we've added four shiny new TLS cipher suites.  So it's like, oh.  Well, thanks.  But you've also made potentially every Windows server on the Internet is, like, going to be vulnerable as soon as the bad guys figure out what it is, what magic packet you can send to every Windows server on the 'Net today to take it over remotely.  So they have an FAQ, and they say...



LEO:  That's terrible.  Okay, so, okay.  So I understand that what they're thinking is, well, look, this isn't in the wild because this was privately found.



STEVE:  Correct, privately reported, yes.



LEO:  What we would like to do is get everybody patched as quietly as possible.



STEVE:  Yes.



LEO:  And then we'll mention it.



STEVE:  Just slip it in and get it in.  Maybe nobody will notice.  Maybe they'll say, oh, look, we have four new TLS cipher suites.  Isn't that nice.  Oh, and it's fixing some little problem over here.



LEO:  Pay no attention to the little problem over there.  Cipher suites.



STEVE:  So under their FAQ they ask themselves the question, because they really have no choice:  What might an attacker use the vulnerability to do?  Answer:  An attacker who successfully exploited this vulnerability could run arbitrary code on a target server.  How could an attacker exploit this vulnerability?  An attacker could attempt to exploit this vulnerability by sending specially crafted packets to a Windows server.  Oh, but would anyone ever think to do that?



LEO:  Why would anyone?  Why?



STEVE:  What systems are primarily at risk from the vulnerability?  Then they said:  Server and workstation systems that are running an affected version of Schannel are primarily at risk.  Okay.  Wait a minute.  There are no server and workstation systems that are not running an affected version of Schannel at this time.



LEO:  So, okay.  Let me just capsulize this.  There is a vulnerability that affects all versions of Windows Server.  It's IIS; right?



STEVE:  All versions of Windows.



LEO:  Of Windows.



STEVE:  Yes.  Both workstations and servers.



LEO:  So every version out there of Windows.



STEVE:  Yes.



LEO:  The vulnerability can be triggered by a remote attack, sending misconfigured packets.



STEVE:  Correct.



LEO:  Of course that means that the system has to be online.  But all servers obviously are.



STEVE:  Right.



LEO:  Could it be sent over port 80?



STEVE:  No.  It's Schannel.  It is in the secure suite.  So it's got to be - it's some sort of a TLS or SSL deliberate malformed communication.



LEO:  Could an IIS server that's not running TLS, doesn't have an SSL cert, still be vulnerable?



STEVE:  Probably not.  My guess is that what they have probably - somebody found a buffer overrun in Microsoft's HTTPS, in their SSL/TLS protocol.  It's that bad.



LEO:  So if I - just so everybody understands, if I'm running Windows behind a NAT server, if I'm not running Windows bare to the Internet, and I'm not running SSL or TLS of some kind, I'm not vulnerable.



STEVE:  No.  Here's the problem.



LEO:  Oh.



STEVE:  Where they said "What systems are primarily at risk," and they said "Server and workstation systems that are running an affected version of Schannel."  What may be possible is that any end user who connects to an HTTPS server, in doing that, if that server knew about this and was malicious, it might still bite you.



LEO:  So a server that is running IIS...



STEVE:  No, no, no, a server running - any secure server.



LEO:  No, but you can compromise it this way easily, that secure server.



STEVE:  Yes.



LEO:  And then it could go on to compromise anybody connecting to it via SSL. 



STEVE:  Or even worse.  Once this gets out in the wild, once the hackers know what this is, any web server that end users connect to over a secure channel could reverse attack the end user.



LEO:  But it would have to be compromised.



STEVE:  Well, no, or malicious, yeah.



LEO:  But let's say I'm a company, I'm a company, big company, running Outlook web server so people can use their Outlook mail on the web.



STEVE:  Yeah, okay, good.



LEO:  My server, my server gets compromised because I'm running IIS, and I am out in the public.  That compromise could then put malicious code on there that would infect every single person who logged into the Outlook webmail.



STEVE:  Correct.



LEO:  One after the other, boom boom boom.



STEVE:  Yes.  Or you could also be Jimmy's Evil Blog.



LEO:  Right.



STEVE:  That, like, or Jimmy's Secure and Evil Blog, offering TLS connections for people who want to read the blog, and it's actually infecting the workstation of everyone who visits.



LEO:  So the first thing as a hacker I would do is go after VPNs.  I'd go after...



STEVE:  Yes.  Well, yes.  Like servers are clearly the pot of gold because they've got...



LEO:  But they have to be running IIS or Windows.  They have to be running on a Windows machine.



STEVE:  Correct.



LEO:  An Apache-based server, which is still a majority, fortunately.  These are not vulnerable.



STEVE:  Yes.  And Nginx, they're all going to be safe, too.  So you're fine.



LEO:  Yeah, we're Nginx, absolutely, and Apache, yeah.



STEVE:  Yup, yup.  So it's only the...



LEO:  But if you're running - but you're not, by the way, because you're running Windows Server.



STEVE:  Right.  And so is eBay, and so is Amazon.  Or, no, no, no, not Amazon.  eBay is.  I think PayPal is.  I mean, there are major sites which are on IIS platforms.  I don't know what the percentage is now, but I'm thinking, what, maybe...



LEO:  Ten, 20, 30?



STEVE:  ...20 or 30?



LEO:  Yeah.



STEVE:  Yeah.



LEO:  It's not the majority, but it's a significant portion.



STEVE:  Yeah, and everyone knows who they are because the server identifies itself in protocol...



LEO:  Right.  If you go anywhere that says ASP or, you know...



STEVE:  Yup.



LEO:  ...active server pages, that's it.  So they can be compromised.  They of course can be compromised to this particular attack, and then they'll pass it along to all other Windows machines.  But once you compromise a server, you might as well just put the whole kit and caboodle on there.



STEVE:  Well, yes.  And what, I mean, depending upon the site that someone manages to penetrate, I mean, we haven't had an exposed server protocol vulnerability, well, except, you know, I mean, well, okay.  Heartbleed was that.  But that was like, as we know, a low statistical likelihood of compromise.



LEO:  And there was a mitigation.  You could just turn off SSL.  I mean SSH.



STEVE:  Correct.



LEO:  And then you're fine.



STEVE:  Right.



LEO:  There's no mitigation for this, you're saying.  You can't switch off a service.



STEVE:  Right.  This is probably in the underlying Schannel library core.  It's when your secure server accepts a connection over port 443, SSL/TLS, there's something that a bad guy can do to, like, send a huge mother lode packet in containing their own code, and that server will execute their code.  I mean, it's like the worst thing that can happen.  And it doesn't sound like...



LEO:  Are we not doing a disservice by publicizing this?  I mean, shouldn't we just all keep this quiet until Microsoft can patch everything?



STEVE:  Well, the good news is, I mean, I have to tell our listeners that anybody, certainly we have, we know we have listeners who are running...



LEO:  If you read the document, you're going to know.



STEVE:  Yeah, we know - yes, exactly.  Anyone who reads this is going to have their eyes bug out when they come to the third thing on the list.  And all, we certainly have listeners who are running, who are in corporations running IIS servers.



LEO:  And they should know.



STEVE:  So they need to know right now.  You know, the moment I disconnect I'm making a little road trip over to my datacenter because I haven't been over there for a long time, and it's time to do a little maintenance.  But, yeah, I'm not leaving this thing hanging for a minute.



LEO:  This is 2992611.



STEVE:  Yes.  The MS14-066.



LEO:  And it's as bad as it gets.



STEVE:  It is as bad as it gets for a remotely exploitable, hanging out there, flapping in the breeze, open port, pot of gold.  Because what hackers want is servers.  They want servers.  And, but end users need to pay attention, too, because it may very well be that, by connecting to a malicious server, you could expose your workstation, and that's not good, either.



LEO:  What is it, on a server, is there a Windows Update just like there is on the desktop client?



STEVE:  Yeah, exactly the same procedure.  Well, I mean, my annoyance with Microsoft is these are really all the same thing.  You know, Server 2003 is Windows 7.  Windows 2008 is Vista.  2012 is - I got that backwards.  But anyway, yes.  I mean, the server platform exactly corresponds to a workstation platform.  They just configure it differently.  They just, you know, same foundation, same code, same everything.  So there it is.  Vulnerability in Schannel could allow remote code executions.



LEO:  We have not seen any exploits in the wild as of yet.



STEVE:  Right.  This just, you know, when they publish the code you know - it's not like this is not going to get attention.  The bad guys are going to be tearing this thing apart.  We can hope that Microsoft did what they could to obfuscate the change they made, like rearranging the code so it's much more difficult to figure out what changed.  But they always do that.  And we've seen now the pattern.  We know that patches are reverse-engineered to find out what got changed.  So certainly no one should rely on the idea that this is not in the wild yet.  It's just a matter of days now.  And I imagine we're going to - we'll be talking about this for the next few weeks, that something's going to happen here.



LEO:  They don't mention XP in this list because they're no longer supporting it.



STEVE:  Right.  But I'm sure it's vulnerable.



LEO:  Well, if Server 2003 is vulnerable, I think that means that XP is vulnerable.



STEVE:  Goes all the way back, yeah.



LEO:  So this might...



STEVE:  I think XP; I think 2003.  I think it was Windows 2000 and XP.  I don't remember how they were paired.  Because there was a Server 2000.  I think that was with XP.



LEO:  Okay.



STEVE:  Because, see, the fact that Server 2003 is supported...



LEO:  Well, it's still updated.  It's not XP.  Even if it's...



STEVE:  I think that corresponds...



LEO:  Even if the core of it was XP, it's still supported directly.



STEVE:  Right.



LEO:  Nevertheless, I imagine...



STEVE:  I think that 2003 and Vista were paired.



LEO:  Maybe that's it, okay.



STEVE:  I think those were the two.  And '08 and 7, and then 2012, Server 2012 and Windows 8.  So anyway, so amid this gloom it is significant that we got four, I mean, the silver lining is we did get four shiny new TLS cipher suites, and they are nice.  Two of them use RSA for key agreement.  Two of them use Diffie-Hellman.  So we know that that gives us - it's DHE, Ephemeral Diffie-Hellman.  We've talked about that.  That gives us perfect forward secrecy.  So we have two new, of the four, two give us perfect forward secrecy, which is now what everyone wants.  And they are GCM.  They're Galois Counter Mode ciphers.



Remember GCM, actually that's the same cryptographic mode that I ended up choosing for SQRL.  It's a hybrid authenticated encryption which does both encryption and authentication at the same time, rather than needing to separately encrypt and authenticate.  And as we talked about recently, SSL got it backwards, where unfortunately the authentication happens first, and then the encryption occurs, which means that - and actually it should have been the other way around because that means you decrypt, then you authenticate, and that exposes SSL to all kinds of vulnerabilities.



So anyway, this is four new cipher suites which I'll also be bringing up this afternoon because they're just beautiful.  And very secure, SHA-256 and 384 for the hashes.  So I'm glad to have them.  So this is a nice update.  Unfortunately, it's fixing a real problem that is going to force reboots of all these Windows machines after - oh, and it does require a reboot, by the way.  You're not getting away without because this is core code in the kernel.



LEO:  Yeah, wow. 



STEVE:  And in addition to that...



LEO:  So XP is - Server 2003 is XP.  2000 is 2000 Pro.  So just to get that...



STEVE:  Oh, good.  So they did, they are going back and fixing 2003?



LEO:  2003 they are fixing.  But they have been fixing.



STEVE:  Right.  Oh, and they'll fix XP as long as you say that you use that embedded thing, hack.  So...



LEO:  Right.  They're still doing that?



STEVE:  Yeah.  So XP, I'm still getting updates on XP because I said, oh, yeah, I'm embedded.



LEO:  And you will want this update.  Not that most people run server on a plain XP machine.  But maybe they do.



STEVE:  No, but remember, clients are vulnerable, too.



LEO:  Clients are vulnerable, too.  So if you surf to a compromised machine, then you will be compromised.



STEVE:  Right, exactly, yeah.  You have to go to a compromised machine, but nobody wants to do that.



LEO:  Right.



STEVE:  In addition, we had, I mean, this is like almost, it's almost an anticlimax, 17 vulnerabilities fixed in IE.  XML Code Services were patched.  Microsoft Office had three privately reported vulnerabilities fixed.  There's also a problem which we don't often see in TCP/IP.  If a bad guy got, somehow got code running on your machine, this is not something that you have to worry about a lot, but they said in TCP/IP IOCTL processing:  "This security update resolves a publically reported" - oh, publicly reported, so that raises the bar, that means that everybody knows about it - "vulnerability in TCP/IP that occurs during the input/output control."  That's the OCTL processing.  "This vulnerability could allow elevation of privilege if an attacker logs onto a system and runs a specially crafted application."



And again, it's like, okay, how is that going to happen?  That's not something you need to worry about.  "An attacker who successfully exploited this vulnerability could run arbitrary code in the context of another process."  Well, that's not good.  "If this process runs with administrator privileges, an attacker could then install programs; view, change, or delete data; or create new accounts with full user rights."  So this is one of those things where it's difficult to see how they would gain that foothold.  But if they did, then all hell breaks loose.



But still, the requirements for this are such that we're not running around with our pants on fire the way we are for this server, this first vulnerability we talked about, MS14-066.  But Windows Audio Service also is being fixed.  .NET framework, SharePoint Foundation, Remote Desktop Protocol, IIS has a restriction feature bypass, Active Directory Federation Services, even the Japanese IME, the Input Method Editor had a vulnerability fixed.  And not to be forgotten is the Windows kernel mode driver has some problem where, if a specially crafted TrueType font file was put out on a Windows share, and a bad guy got you to enumerate it, he could take you over.



So, I mean, this thing is just - it's got something for everybody.  But one really, really important update that everyone needs to handle immediately, like when you stop listening to this.



LEO:  Nice.  Okay.



STEVE:  So yesterday Obama, President Obama, to address him formally, I guess, announced that he's going to ask the FCC to reclassify ISPs as telecommunications carriers under something known as Title II.  And this of course has rekindled the whole debate.  Your producer, Jason, asked me for Brett Glass's email address yesterday, since Brett, as we know, we had Brett on the podcast to talk about this [SN-457], sort of has the ISP's viewpoint of...



LEO:  Yes, an ISP's viewpoint.  If we got Dane Jasper of Sonic, that might be another viewpoint.



STEVE:  Yeah.



LEO:  But I know Brett feels very strongly.  So we thought we'd get him on TWiT.



STEVE:  Good.



LEO:  And we're trying to get Nilay Patel to debate him, which would be fiery.



STEVE:  And this would be Sunday?  Is this going to be Sunday next week?



LEO:  Yes.  So Brett has confirmed.  We will have Brett on.  And maybe we'll get Dane Jasper, if we can't get Nilay.  But I want to get both sides of this because I think there are two sides.  The Title II regulation is a fairly hardcore regulation.  It regulates them as a public utility.



STEVE:  Right.



LEO:  And a lot of ISPs do not think that's a good idea.



STEVE:  Right.



LEO:  A lot of the debate is, well, who do you want to regulate the Internet?  Do you want the U.S. government to regulate the Internet?  That seems like a bad idea.  But certainly these guys aren't going to regulate themselves.  So this is a tough, tough challenge.



STEVE:  It is.  I mean, I'm, as an independent serial entrepreneur who's created and operated small companies for my entire life, I want as much freedom as I can have.  But I do recognize that the free enterprise capitalistic system has a flaw.  There is a tendency, and we see it happen, for large companies to use their inherent power to become larger still.  That is, and what that does is it creates an unstable system.  From an engineering standpoint, negative feedback is something that creates homeostasis, where as something begins to drift off, if you have feedback that corrects it, then that's good.  That tends to create a stable system.



The problem is that capitalism is inherently, in a free market, is inherently unstable.  It doesn't tend to self-correct.  Large companies tend to get larger because of network effects, as it's known in economics.  And so much as I dislike the idea of "government," in quotes, regulating, I recognize the need for some control.  And I'm unhappy with the idea that there is actually no choice, I have no choice in my source of bandwidth.  And it turns out most Americans don't.  Most of us are, first of all, unhappy with our bandwidth provider, and have absolutely no useful market choice.



LEO:  And of course I'm sure Brett will point this out, the reason you have no choice is because the government intervened in the first place...



STEVE:  Yeah.



LEO:  ...to create monopolies for cable and DSL.



STEVE:  Yeah.



LEO:  So it's a mess.  And I think...



STEVE:  It is.



LEO:  I don't know what the answer is.  You know, President Obama campaigned on the promise of supporting Net Neutrality.  He has been kind of weak, particularly in appointing Tom Wheeler, who many feel is just too compromised.



STEVE:  A lobbyist for the cable industry.



LEO:  Yeah.  And he's the chairman...



STEVE:  Or an ex-lobbyist.



LEO:  ...of the FCC.  However, I have to say Mr. Wheeler has been coming up with some pretty good ideas and creative ideas for trying to solve this conundrum.  He has not just said, oh, trust the cable companies, they'll be find.  So he's trying to do - it seems like he's trying to do his best.  But we were waiting for something from the president, and this is exactly the, I think, most Internet advocates, this is exactly what they wanted to hear.  I have misgivings, though, and I think any reasonable person does.



STEVE:  Remember, too, that, as I understand it - and, I mean, I'm not obsessing about this.  I haven't been following it super closely.  But as I understand it, the FCC did impose some regulations.  And Verizon sued.



LEO:  That's right.



STEVE:  And the Supreme Court agreed that the FCC did not have the authority to regulate ISPs in that fashion.  So basically this is a response to that.  By reclassifying ISPs as common carriers, now there's no question that they fall under the FCC's regulation.



LEO:  Yeah.  This was the roadmap the court gave the FCC.  They said, look, you don't have the - either you get Congress to mandate this - because Congress is ultimately the body that tells the FCC what it can and cannot do.  Either you get Congress to give you these powers, or you're going to have to go some other route like Title II.



STEVE:  Right.



LEO:  And we'll see.  Title II, as Brett has pointed out, has regulations that would be considered onerous for any Internet service provider because...



STEVE:  Well, and it's old.



LEO:  It's aimed at Ma Bell.  It's aimed at...



STEVE:  Right.  It's old, and it's antiquated, and a lot of it doesn't make sense.  But it's the only thing we've got at the moment.



LEO:  It'll be very interesting.  And we're going to have a great debate on Sunday.



STEVE:  Wonderful.



LEO:  I'm looking forward to it, yeah.



STEVE:  Okay.  So I quietly departed for Las Vegas on Thursday.  I never, just as sort of general security protocol, I never preannounce when I'm going to be away because that just seems, you know, unwise.  But I always talk about trips when I come back.  And I was asked in the summer, I think in August, by DigiCert, my certificate provider, with whom everyone knows I am super happy.  And of course I've worked, during the whole CRLSet thing - they participate in the certificate authority organizing committee and groups.  And they had asked if I wanted to do a blog posting or a submission there.  And I said, no, I pretty much said my piece.



But anyway, when they were holding a security summit, their 2014 security summit with all of their major customers and other interested parties, they said, "Hey, Steve, would you like to speak?"  And I said, "Well, the only thing I really have to talk about is the project that I've been working on for, then, about nine months.  And that's SQRL."  And they said, "We'd love to have you talk about SQRL."  And I said, "Well, then, I'll happily show up."



So on Friday I gave a presentation to the entire conference, basically a 45-minute front-to-back talk, a presentation about SQRL, how it works, what it does, the whole thing.  And I don't know - there was a camera in the back recording it.  And, I mean, I just - I've been so busy since I got back I haven't had a chance, but I will shoot a note off saying, hey, you know, is that presentation available?  Because I did a very nice, 45-minute, I left nothing out, covered everything.  It's the nicest formal presentation I've put together so far.  So maybe I can get a copy of it.



But afterwards, in the first break after my presentation, there were a number of people who were interested came up, and we were chatting.  And one of them was Brad Hill, who I had never met.  But I certainly knew his name because his name is all over all of the FIDO docs.  FIDO is the big sort of historically moving slowly, sort of glacially forward authentication alternative.



LEO:  This is the one that Yubico key supports is FIDO; right?



STEVE:  Well, they support...



LEO:  FIDO 2.



STEVE:  Well, yeah.  There's two specs.  There's UAF, which is the full one, the Universal Authentication Framework.  And then what Stina sort of - she sort of peeled off the part that she wanted, frankly.



LEO:  Ah, okay.



STEVE:  And that's called U2F, Universal 2 Factor.  And that's what she did with Google and what we talked about a few weeks ago was that announcement.  And so it's sort of FIDO Junior.  And it operates very differently.  But it borrows some of the technology.  Anyway, what really delighted me was that Brad Hill, who is a very nice guy, who was at PayPal during all of this - PayPal made him available to the FIDO project.  So he was like one of the lead architects of FIDO.  He's now very recently switched over to Facebook.  So he's now a security engineer, his business card says, at Facebook.  He said that what he just saw was the most well-thought-out authentication system he has ever seen, in what I presented.



LEO:  SQRL.



STEVE:  In SQRL.



LEO:  Awesome.



STEVE:  And it was funny because there's one, you know, the key concept behind SQRL, the thing that hit me that morning, just about a year ago, I think it was in November of 2013 [SN-424], and this just, you know, I'd been reading through elliptic curve crypto and looking at Dan Bernstein's stuff.  And there's a place on Dan's page where he's talking about his ED 25519, the 25519 elliptic curve, where in sort of an old Q&A he says, you know, how do you create a private key?  And then his answer is you don't.



And that's what's so special about the crypto that I chose is that anything can be the private key.  And that's the fundamental basis for SQRL because that "anything" is when you take the user's master key and use it to key a hash of the domain name.  Then the result of that is the private key.  And that's what's so cool because, for example, what FIDO does, and this is unfortunately what Stina's solution is, is they choose keys at random.  And but so now you've got a random private key and the matching public key and nowhere to store it.  So what they do is they encrypt it and give it to the server to store.  So you're authenticating to the server, but the first thing you have to do is ask it back for the private key it's been holding for you.  And then you decrypt it and use that to sign the nonce that it gives you to prove that you have the private key that it just gave you.  So it's like, okay.



Anyway, so the point of this is that I sort of gloss over that.  Obviously in a short presentation I don't have time to dip into everything.  So I have a diagram that I showed that is like, it's the diagram on the first page of the SQRL pages at GRC, where I show that process, where you take the master key and hash it with the domain name.  That's the private key.  Then you run it through an API call to produce the public key.  And then you also use the private key to sign the URL.  And the public key is your identity token, and the signature is your proof that you have the private key.  And I just sort of - and then I move on.



And so Brad was looking at that and, you know, really knows crypto, but wasn't aware of this particular property of the Bernstein 25519 elliptic curve.  So he came up to me, when we were talking about this, and he said, you know, he said, remember that famous - oh, actually he told me, he says, you know, you really need to change your presentation because you just sort of skipped over that step.  And he said, remember that famous joke where Einstein or someone is on a chalkboard, and they're working out a proof of a theorem, and they get stuck, they paint themselves into a logical corner, and so in the series of equations there's like a little puff of smoke, and it says, "And then a miracle happens."



And so his point was that he recognized, because he understands this stuff, that apparently something was missing.  But it's this particular choice of crypto that solves that problem, and that's the magic of SQRL.  And of course now he understands that.  And so then he was having to - he was digesting that, realizing that I'd just obsoleted the way FIDO worked because it was a kluge, and SQRL wasn't.



LEO:  Ooh.



STEVE:  So anyway, it was a great...



LEO:  How did he react to that?



STEVE:  Well, I didn't rub his face in it.  But, you know...



LEO:  Did he kind of understand that?



STEVE:  Oh, yeah, he definitely understood it.  He said to me, I mean, he said, "That means there's no need to have the server store the private key on behalf of the user anymore."  I said, "Right."



LEO:  Right.  And he said, oh.



STEVE:  Yeah, we don't - I don't have to - we don't do that with SQRL.



LEO:  Oh.



STEVE:  It's much better, actually.



LEO:  Interesting.  Wow.



STEVE:  So, yeah.  Anyway, but he's a super nice guy.  And I think he was glad for the meeting, and I certainly was because...



LEO:  Good, good, good, yeah.



STEVE:  ...somebody who really knows this stuff was able to watch the presentation and then say, "This is the most well-designed authentication system I've ever seen."  And this is the guy who just spent five years doing that.  So, wow.



LEO:  Well, I hope people pay attention to that.



STEVE:  Ah, well, we'll - it's going to succeed if it should.  I hope it does.  So I have one last security thing.  And this is important.  For everyone who has a Belkin N750 dual band router, I mention this, it's this specific router, but it's been around for three years.  It went on the market in 2011.  So it's Belkin's N750 dual band router.  There is a very easily exploited vulnerability that allows an attacker to gain root on the router through exploiting the guest network, which there's a problem with.  The guest network has a web page, has a little web server where you authenticate, and a specially crafted POST - verb, you know, HTTP has GET and POST for submitting only a URL query or that plus a block of data.  And POST is typically used, for example, for submitting the contents of forms.  If you maliciously format the POST submission, you can access the telnet server and get access to the telnet, basically the command prompt with full root access on the router.



LEO:  Oh, crap.



STEVE:  So they have a firmware update.  The firmware that everyone currently has ends in 1.10.16m as in Michael.  What you want is 1.10.17, sorry, 1.10.17m as in Michael.  So just a heads-up.  I'm sure within the sound of my voice, with our whatever we have, about a hundred thousand listeners, there are people with Belkin N750 dual band routers.  As a workaround, you can immediately shut down the guest mode, if you want, if you're concerned.  But this allows wardriving to really be...



LEO:  Wardriving, yeah.



STEVE:  ...wardriving.  It really means war.



LEO:  Wow.



STEVE:  Yeah.  So, and in the show notes I have a link to the guys that found it and a very simple proof of concept.  I mean, it's just - it's trivial to implement.  Oh, and I forgot to mention, it's been put into Metasploit.  So, and it's an automated remote takeover module in Metasploit, so also very available.  So anybody with this Belkin N750, update your firmware.  Get .17m from Belkin.



LEO:  You know, and we don't say this enough because so many of these router manufacturers never update their firmware.



STEVE:  Yeah, they're just not good about it.



LEO:  Well, it's such a commodity device, they...



STEVE:  Yes, you're right.  It's - you're right.



LEO:  So thank you, Belkin, for fixing it.



STEVE:  Yeah, you're right.  I'm glad you said that, Leo.  That's a very good point.  It's easy for us, and, I mean, we just sort of take it for granted.  But you're right.  Consumers - there's probably not a lot of demand because consumers typically see it as like a set-it-and-forget box.



LEO:  It's a box, yeah.



STEVE:  Yeah.



LEO:  So, yeah.  I mean, and there's not a lot of incentive.  I'm sure there's no money in fixing it.



STEVE:  No.



LEO:  But they really should fix it.  So, good.



STEVE:  I was exchanging tweets with somebody last week, and I don't remember now what the topic was, but it was related to security.  And he said some - I guess in the tweet, in his tweet he said that, oh, by the say, SpinRite just came to the rescue for me.  And he sent me a link to his blog post from last month, so a couple weeks ago, October 2014.  And the topic was, his subject was "Universal fix for Windows KSOD."  And I thought, what?  We know about the BSOD, the Blue Screen of Death.  I thought, what's a KSOD?



So he said:  "Ever had your Windows installation inexplicably die, leaving your computer unusable without a fix?  I have - more times than I'd like to count.  The last time this happened was yesterday when Windows 7 would only boot into a black screen with a movable cursor, also known as the blacK [with a capital K] Screen of Death."  So, you know, "B" was already taken for Blue Screen of Death, so he used the "K" at the end of black, so KSOD for blacK Screen of Death.  He said:  "It was a serious case, considering none of the safe modes or repair function in the Windows boot options would work.  Each option would universally end in either a KSOD [as he calls it] or the classic BSOD after hanging on [and then he has] aswRvrt.sys during safe boot.  After exhaustively eliminating all possible 'regular' fixes that were available on the Internet, I decided it was time for the big guns:  Steve Gibson's SpinRite."



He said:  "Prior to trying SpinRite, I first tried Kaspersky's Rescue Disc 10, which was entirely useless for my case.  After booting from the rescue USB dongle, I would always get a 'Missing Operating System' error in the boot screen."  So it sounds like Kaspersky was needing a little more there than was present.  And of course SpinRite needs nothing.  It operates, it brings its own little OS along with it.  So anyway, he said:  "Not reassuring.  I have long been a fan of Steve Gibson's Security Now! podcast, which is why I knew of the tool.  I knew the tool would be one of the few things that might do the trick, so I gave it a shot.



"After about an hour running SpinRite 6, and a few reboots later, my Windows 7 installation was working perfectly, as if nothing had ever happened.  SpinRite saved the day."  And then there's a bunch of stuff that I'm skipping over because then he said TL;DR at the end:  "SpinRite saved my machine from a perpetual and otherwise unbeatable KSOD scenario.  And my guess is that, if you are having KSOD problems, then SpinRite is one of the few things that might help you, too."  So I don't have his name, unfortunately, in front of me, but thank you.  I'm sure he's listening to this right now.  So I appreciated our Twitter exchange, and thanks for sharing the link.



LEO:  Yup.



STEVE:  And there it is.



LEO:  Universal Fix.



STEVE:  It's a very, very cool screenshot...



LEO:  And there's the DynaStat system.



STEVE:  ...showing the DynaStat.



LEO:  Yeah.  Nontrivial to get a DynaStat screenshot because you're running DOS.



STEVE:  Exactly.



LEO:  I don't know how you'd get that.  That's funny.  That's awesome.  Very nice.  So he didn't even send this to you.  This was just - you saw the blog post.



STEVE:  Yeah, well, he sent me the link.



LEO:  Oh, he did.



STEVE:  And so that, yeah, so I was able to find it that way.



LEO:  Great.  And it's Reposter.net.  Let us continue on with Mr. Gibson and a little bit of certificate transparency.



STEVE:  Okay.  So everyone knows who's been following the podcast for any period of time how the current certificate authority-anchored system operates.  The idea is that certificate authorities verify the identity to differing degrees of entities, individuals, companies, organizations of any kind, who want to have a - want to assert their identity on the Internet.  So the idea is that they prove who they are to the certificate authority.  They provide their server's public key to the CA, the certificate authority.  The certificate authority signs that public key and gives it back to them.



Then, whenever someone connects to them, they send the client, the user's web browser typically, this signed public key.  The public key itself is the key to them establishing a secure connection with each other because their private key, the matching private key, never leaves their control.  And them having the private key that matches the public key that they've just provided is the way a secure tunnel is bootstrapped such that nobody listening in the middle can intercept.  And the fact that it's signed by the certificate, this public key, which is what's going to be used for communication, the fact that it's signed means that somebody else, a third party, whom the client trusts to have performed due diligence, is asserting, yes, this is really Amazon or Facebook or eBay or PayPal or GRC or whomever you're establishing a secure connection with.  So that's the model.



Now, we've talked about the many ways this fails.  Good as it is, there are problems with it.  For example, we're trusting, I mean, hundreds, many, like four or 500 different authorities with this performance of due diligence.  And the problem is, whereas all of GRC's certificates are only signed by my chosen certificate authority, DigiCert, it is entirely possible for, and I'll just pick on them because they're my typical whipping boy, it's entirely possible for the Hong Kong Post Office to sign a fraudulent certificate asserting that it is GRC.  And if the Hong Kong Post Office, which is a CA, a certificate authority, is trusted by the user's browser, then a different website can impersonate GRC, if they're also able to get DNS to cooperate because somebody's web browser has to believe they're going to GRC, but be given the wrong IP address or be intercepted and rerouted to a fraudulent server that's offering a certificate signed by an untrustworthy certificate authority.



So that's one of the problems.  Then of course there's - so that's like the malicious CA problem.  But then there's the compromised certificate authority.  And remember we talked about years ago the famous DigiNotar problem.  DigiNotar was a - were they - I think they were a Dutch certificate authority that had a breach, had hundreds of certificates created somehow in their system.  Somebody got in and was able to get all kinds of certs signed.  They knew about it and didn't tell anybody, hoping that they could get away with it.



Well, the fact that they found out about it and kept quiet ended them.  They were bankrupt a few months later because it's one thing, you know, anyone can make a mistake.  But if you're a CA, you have got to immediately acknowledge when you find out there's a problem, and take responsibility for it.  And the fact that they didn't meant that no one could ever and would ever trust them again.  All the browsers immediately suspended their support.  And if you don't have browsers trusting you, remember, this whole thing is that the browser verifies the certificate by trusting the signer of it.  And if the browsers retract their trust of the certificate authority, that certificate authority is out of business.  No one, I mean, they can't assert their reputation, even if they haven't completely wrecked their reputation.  So there's that problem.



And then so we have the malicious CA.  We've got the compromised CA.  And then just the mistake where, like, there was another instance more recently where a certificate authority had issued a certificate that had CA rights.  That is, normally the intermediate certificates are themselves unable to be a certificate authority.  But that's just a bit flag in the privileges, in the characteristics of the certificate.  And one CA did issue an infinitely powerful certificate that was able to sign any certs of any kind.  And so that mistake was corrected.



So the point is that there are a number of things, a number of ways that this existing hierarchy with certificates can break.  And because of Google's size, they are almost always at least among the websites that are compromised.  That is, they're discovering bogus certificates that they didn't issue that other people issued.  And, I mean, one of the things that is nice about Chrome, the Google browser, is that they've built technology in where Chrome knows much more about the - because Chrome is from Google, Chrome knows about the validity of Google's own certificates and immediately sends up all kinds of warnings if a certificate that appears to be valid for Google.com or any of Google's properties is used on the Chrome browser that's actually not from Google.  So they're in a special place, having both making certificates and their own browser that can be aware of all the certificates that should be considered legitimate.  But none of the rest of us have our own browsers that everybody's using, so that doesn't work for us.



Still, Google has spiders, bots, which are out rummaging around the Internet.  That's what they do.  They're basically going to all websites and servers, following links, sucking down and indexing the entire Internet.  And so it occurred to them at some point, it's like, hey, you know, every time we connect to a server following a secure link, and that's happening historically more and more, we get the certificate.  That's what happens.  The first stage of establishing a secure connection is the secure server sends the client, that in this case is a Google bot, the certificate.



So they began to think, you know, why don't we start collecting these, all of these certs?  Because, I mean, these are all the certs on the Internet, all the certificates.  And when you think about it, that doesn't exist anywhere.  There's no central repository of all the certificates.  But imagine if there were.  Imagine if every certificate issued existed in some kind of database that could be queried.  I would love to query it.  Hey, what are the GRC.com certificates?  Let me have them.  Because, boy, don't I want to know if there are any that I don't know about.  And in fact everybody wants to know that.



LEO:  It couldn't be used to validate because some might be bogus.



STEVE:  Ah, well.  And so, yes.  So the first phase of this was this notion of collecting them all.  And, well, okay.  So we used Google's bots to create this database.  And then Google started saying, okay, what we want is - somehow they sort of made this conversion to this idea of, okay, we will put all the certificates in that we encounter.  Now, we'd like to be able to allow people to query the database for properties that they care about and find out if, you know, what certs we have encountered that are there.  We'd also like to encourage certificate authorities to submit certificates that they're in the process of issuing.



And so this is sort of - it's going to kind of have to bootstrap itself.  But the idea would be that ultimately this database would run in parallel to the existing CA verification.  First of all - and they call it a log, they call it the Certificate Transparency Log.  It's not a log in the traditional sense, as I'll explain in a second.  They called it a log because, like a log, a correct log, it has what they call an "append-only property."  That is, by its design, all you can ever do is append to it.  So it's a chronology of all the certificates that have been found so far.  And the structure of it is such that it can only be appended to.  And it has a series of security properties in its design that allow it - that don't require it to be trusted.



And this is where it starts to get a little mind-bending from a security standpoint.  But the idea would be that, if it exists, and its design is correct - and I should say it does exist, and the design is correct, so these are sort of - I'm sort of trying to lay down a framework for understanding this.  And it could be trusted - and again, that problem has been solved, and I'll get to that in a second.  Then web browser clients could rely on it as an additional source of information, that is, people who owned domain properties could check the log to verify that only the properties, the domain properties that they own are present, that is, there are no fake versions of their certificates.  And if they found them, then they would go through the normal process for remediating.  They would notify all browser vendors, and tell the CA who issued that cert that this was bogus, and get them to revoke it, and tell the browsers to revoke it and so forth.



So the idea is that you, first of all, to get this thing bootstrapped, browsers will only trust certificates that they receive from servers if those certificates are members of the certificate transparency database.  And, okay, so that's a requirement, that is, the certificate must be in the database in order for the browser to trust it.  And then the database must be queryable by the owners of the certificates to allow bad certificates to be found because only if the certificate, only if a bad certificate is in the database will a browser trust it.



So what's useful about this is that, by creating a sort of a repository of all certificates - we don't have that now.  Right now the browser receives a certificate from the web server and checks the chain of trust back, the validity of the chain of trust back to someone, some single certificate authority that signed it.  But that does allow, within a controlled environment, like in Iran, just to pick on someone, for them to control a CA, and for them to issue certificates for Google.com, for example, which appear to be valid, only because the chain of trust is local.  It's never being, you know, having a bright light shined on it.  It's never being exposed to the light of day.  It's the protocol doesn't have global scope.  This system gives certificates global visibility which Google calls "certificate transparency."



So, okay.  Now, how does this work?  One way, the way to start visualizing this, the first way to think about it, which is not the way it's actually structured, but we have to start somewhere, is as a chain, a linear chain of hashes of certificates.  So you start with the first certificate.  And you take the SHA-256 hash.  Now you take the second certificate.  You append the hash of the first one to it, and you hash them.  Now you have a second hash, which you append to the third certificate and hash them.  And now you have a third hash, which you append to the fourth certificate and hash them.  And you have the fifth hash, and so on.



So what you have is a chain of hashes of certificates which creates a dependency chain.  That is, when you get done hashing all the certificates, you know, one by one in this chain, if you think about it, due to the way hashes work, the resulting single hash is a value which you only get if every certificate - you only get as a result of hashing all of the certificates sequentially.  And now, moving forward from there, any new certificates that come along, it's easy to evolve this, that is, from a given starting point of having all that work done in the past.  You hash any new certificates sequentially, adding them to the front of the chain, and the resulting final hash is the head of this chain.



And so essentially, thanks to this magic cryptographic processing of the way hashing works, you have a - essentially you're able to state the proof that all, every single previous certificate has been seen if you get this final value.  And incrementally, what this means is that, that is, it's provable that you had this append-only property because any particular version of this log, and this log is this chain of hashes, is the full proper superset of any previous version, that is, because you can always look at the - any previous version is entirely representable just by the final hash that was its head.  And you append to it by hashing additional certificates.



Now, if that was the actual model, this would not be very practical and very cumbersome.  So it turns out that instead of a linear chain, we can use a tree.  And if we use a tree structure, suddenly this thing becomes incredibly cool.  There's a data structure known as a Merkle, M-E-R-K-L-E, a Merkle hash tree.  And a Merkle hash tree is exactly what I described, but using a binary tree structure rather than a linear hash chain.



So, and I've never, I don't think I've really ever talked about trees.  One of the things I have always planned to do on the podcast was do a fundamental data structures series of podcasts to talk, you know, because we've done other fundamental things like CPUs and the Internet and other stuff.  And I thought data structures, the fundamental underpinnings of data structures would be really great.  But the world's just gone crazy with security problems, and we've never - we have very little chance to talk about that kind of stuff.



But a binary tree is if you took two things, like two hashes of certificates, and hashed them together, and then took two other hashes of certificates and hashed them together, then you took those two hashes that you'd done and hashed them together into a top one.  So you can sort of see how there's a top node which splits into two, and it splits into two, and so on.  So it turns out that - okay.  And what I just described, that is a Merkle hash tree.  All it is, is a series of joinings from the bottom up of two hashes into a third, or to make a third, and then somewhere else you take two hashes to make a third, and then you hash those together to make a fourth and so on.



So this binary tree has the very cool property that, and this is where it's difficult, I mean, I'm already sort of into where it's difficult to do this on an audio podcast without any audiovisual tools.  But the idea is that where the size of the log grew as a linear function, if it was just that first linear example, if you do a - if you use a binary tree, it grows with the log of the number of certificates.  That is, it grows incredibly more slowly.  So that, for example, if you double the size or you double the number of certificates that are in the tree, the tree is able to grow only one - it only requires one additional level of growth.  So it is a far more efficient means for storing these hashes.



And if anyone's curious, look up "Merkle hash trees" because essentially what this means is that every certificate that has ever been found - and I should explain, these logs exist now.  There are about seven or eight of them that are being maintained.  Google has about four.  DigiCert, my certificate authority, was working with Google on this early on.  They're running one.  And there are a couple other people who are.  And it is Google's intention, last I saw, to in Chrome, starting in just a few months, in February 2015, to require certificates to be present and proven in this certificate transparency log to have EV status.  So this is another thing Google is doing to work on dramatically strengthening the certificate authority system.



And it's easy to get lost in the weeds here because it turns out that there are, when you have this tree structure,  you can demonstrate that very few nodes need to be known in order to provide a proof that a given certificate is present in the tree.  And that's the key.  If we had this single linear list of chained hashes to prove that a single given certificate was in the tree, we would have to have the hash in front of it, that is, the hash that was there before it was added, and its hash and all the certificates since, to prove that the value we end up with is the value at the end of the chain.



But by breaking this down into a binary tree, the number of hashes that we need is just a handful because the binary tree structure is so efficient that it is very economical to provide a proof that any given certificate in the world has been represented in this tree.  And that's what's so cool about this is the proof is very efficient and very lean.  And that allows all the certs to be dumped in.  And what will be happening in the future is that certificate authorities will be submitting, voluntarily submitting their certificates to this certificate transparency log, which is in this tree structure, in order to essentially preannounce their certificate as being in the world.  And so we'll no longer have a situation where a certificate authority can go rogue and have its rogue-issued certificates blindly accepted by browsers and having us maybe discover that that exists.  Once this system is in place and running and enforced, within a matter of hours, typically, any maliciously issued certificates will be found.



So that's the ambitious project that Google embarked on about a year ago, RFC 6962, if anyone's interested.  And in the little abstract, first paragraph, it says:  "This document," that is the certificate transparency document, "describes an experimental protocol for publicly logging the existence of TLS certificates as they are issued or observed, in a manner that allows anyone to audit certificate authority activity and notice the issuance of suspect certificates, as well as to audit the certificate logs themselves.  The intent is that eventually clients would refuse to honor certificates that do not appear in a log, effectively forcing certificate authorities to add all issued certificates to the logs."  So, ambitious, but it may happen.  And a very, you know, a substantial and significant addition to the Internet's security infrastructure.



LEO:  Interesting.



STEVE:  Yeah.



LEO:  All right.  Thanks for...



STEVE:  Certificate transparency.



LEO:  Transparency.  And by which we don't mean disappearing, we just mean transparency about the provenance.



STEVE:  Visibility, yes, visibility.



LEO:  Yeah, visibility.



STEVE:  Yeah, exactly, making it all, making what's happening transparent to everyone.



LEO:  Don't know what this means, but the chatroom just pointed out that Open Whisper Systems has just tweeted that RedPhone was removed from the Play store today.  The tweet says we don't know why, but we've reached out to Google Support for more information.  That was one of the security products created by Open Whisper Systems, along with the TextSecure text messenger that we had recommended.



STEVE:  Right, right.  And I should mention that these Merkle hash trees, they're in LimeWire and Bitcoin and Gnutella.  I mean, the Merkle hash tree itself is not an invention of Google.  It's a very handy way for managing peer-to-peer filesharing, in order to verify that sets of files that have been received are valid by taking their hashes and then receiving a chunk of the tree and by evolving these trees over time.  The Merkle hash tree itself is a really interesting data structure in fundamental computer science.  It was invented back in 1975, I think.  And it has been around and used for many different purposes ever since.



LEO:  Interesting, yeah.  Steve is at GRC.com.  That's where you'll find SpinRite, the world's finest hard drive maintenance and recovery utility.  We highly recommend it.  While you're there, though, you might want to check out some of the freebies Steve offers at GRC.com, including this show.  16Kb audio is there of the show.  That's the smallest audio file we offer.  Plus the full text transcript written by Elaine Farris.  Thank you, Elaine.  And all sorts of other stuff, including information, more information about his SQRL protocol.  If you want to get involved in that, there's forums.  There's a lot going on.



If we do a Q&A next week, your questions will come to Steve in one of two ways.  He does tweet replies, so @SGgrc is his handle.  And you can also use his website.  That's probably the best way.



STEVE:  Yeah.



LEO:  GRC.com/feedback, and your feedback will be received by Steve that way.  We have full quality audio and video of the show at our own site, TWiT.tv/sn.  We also make sure that it's available everywhere you get your finer podcasts.  If you want to watch live, you can do so at TWiT.tv every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC at TWiT.tv.  Thank you, Steve.



STEVE:  Okay, my friend.  I will be watching Brett Glass talk about Net Neutrality on this coming Sunday.  And we'll orient for a Q&A next week.



LEO:  And while we don't ever reveal Steve's itinerary, I do think he might be heading over to Level 3 at some point later today.



STEVE:  Yes, everybody.  Update your Windows systems.  I'll be doing that.  You'll notice that GRC disappears from the 'Net briefly here in about an hour or so.



LEO:  Briefly while it reboots.  Thanks, Steve.  We'll see you next time...



STEVE:  Bye.



LEO:  ...on Security Now!.  Bye-bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#482

DATE:		November 18, 2014

TITLE:		Listener Feedback #201

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-482.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  A Microsoft Update to last week's Microsoft Update in the news.  We'll also talk about dirtboxes.  They're flying over you all the time.  And Steve will answer some questions, as well, including a stone DVD.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 482, recorded November 18th, 2014:  Your questions, Steve's answers, #201.



It's time for Security Now!, the show that covers your security and privacy online.  And there could be no better host for this show than Mr. G, Steven Gibson.  He is the man in charge at the Gibson Research Corporation, GRC.com, and also creator of many useful tools, including SpinRite, the world's finest hard drive maintenance and recovery utility.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you.  This is a Q&A, after last week's coverage of certificate transparency.  And in fact we may be doing another show on certificate stuff next week as a consequence of some just-breaking news this morning, an announcement from the EFF, Mozilla, and the University of Michigan about the EFF's initiative to make certificates, web browsing certificates, web server certificates, the kind we're always talking about, both free and safe to issue and somehow kind of auto-renewing.  So there's a new protocol called ACME we'll be talking about.  And then also, boy, Microsoft is having a rough go of it for their patches in November.  One dropped today that they'd held back...



LEO:  Uh-oh, an out-of-band update?  Wow.



STEVE:  Yeah.  They revised one that was - the most important one last week turned out to have problems with it.  There's an update to Firefox with a cool new feature that I like.  I wanted to chat with you about the so-called "flying dirtboxes," which...



LEO:  I'm an expert in flying dirtboxes.



STEVE:  Yes, I heard you on TWiT.  I think that's great.



LEO:  That one's peeved me off a little bit, so I'm...



STEVE:  Yeah, well, rightly so, and many other people.  You could imagine the ACLU is having, you know, is on oxygen.



LEO:  Yeah.



STEVE:  Also an update on the cellular provider supercookies, some information, some news about WhatsApp, BitTorrent Sync, and this is a Q&A.  So since we had so much stuff to talk - oh, also some interesting miscellanea stuff.  I wanted to chat with you a little bit about "Interstellar."



LEO:  Oh, you saw it, eh?  Ah.



STEVE:  Yeah.  Also an upcoming movie or production about Alan Turing's life...



LEO:  Yes.



STEVE:  ...that looks really good.



LEO:  I talked to somebody who saw who says its amazing.



STEVE:  Oh, I'm so glad.  And then we have a Q&A.  But so much going on there that I just found five questions, so a half-size, a half-pint Q&A, which I think will pretty much round out a good podcast.



LEO:  Excellent.



STEVE:  So lots and lots of stuff today.



LEO:  Holy camoly.  Oh, my.  I was hearing radio sound in all of this, and I realized what it is.  It's my Pono Player has decided all of a sudden to start playing "Psycho killer qu'est-ce que c'est?"



STEVE:  Hey, so we briefly mentioned it last week.  What do you think?  You've had it for a week now.



LEO:  You know, I'm going to review it on Before You Buy.  That's why I have it in the studio.



STEVE:  Oh, okay, cool.  I'll keep watching out for it.



LEO:  Well, I'll give you the thumbnail.



STEVE:  Cool.



LEO:  I want to support it because I really want to support the notion that you can buy high-res, studio-quality recordings of your favorite music.  And in order for that to work we have to develop an ecosystem of people who are willing to buy it.  And it's always going to be a specialty.  Although I have to say the PonoMusic Store, HDtracks, Bowers & Wilkins has a Society of Sound.  They all sell albums for, you know, 17, 18 bucks.



STEVE:  And so these are the same albums we're familiar with.  They've gone back to...



LEO:  They're effectively studio masters.



STEVE:  Right, so they've gone back to them and said, okay, wait a minute, we want the raw original data before you ran it through your compression.  And that's what they offer.



LEO:  Yeah.  And most - sometimes you'll get stuff with compression on it, both digital and audio.  But what you're getting with this stuff is FLAC files, so they're losslessly compressed.  And then the bitrate is, you know, it varies.  I mean, sometimes it's just, on some of these systems, it's just CD quality, 44.1 by 16 bits.  But most of them are at least 24 bits.  And then some of them are 96K.  Some of the are 192K.



STEVE:  Ooh.



LEO:  Yeah. 



STEVE:  In big files, big files.



LEO:  They're big files.  I doubt you'd hear the difference.  But nowadays with big hard drives, you know, who cares?



STEVE:  Yeah, it's a very good point.  The whole MP3 thing was designed back in a really lean storage and bandwidth environment.



LEO:  And bandwidth, right.  So, and I think we'll look back on this MP3 era as kind of just an unfortunate blip.  I'm hoping.  Anyway, but in order for this all to work, besides being able to buy the tracks, you need something that will play back the tracks.  For instance, Apple and iTunes will not play back high-res tracks.  They'll play back a certain degree, but not all the way.  But you can get DACs, Digital-to-Analog Converters, that will do 192/24.  And you can get very high-quality digital-to-analog converts, DACs.  And so my Onkyo AV receiver, for instance, has an excellent TI DAC that does 192/24.  So I can listen on my stereo.  I can actually put it on a USB key, put these high-res tracks, pop it in the stereo, and listen on good headphones or on my good speakers.  And you know what, maybe it's psychology, I don't know.  I think it sounds a lot better. The soundstage is larger.  There's more detail.  There's more open...



STEVE:  I would think it would be brighter, yeah, cleaner.



LEO:  Yeah, the high ends are brighter.  But you know what, even the bass is more precise.  It's not as [making sound].  You feel like it's more detailed.  And then so but the question is, you know, an iPod won't play it back.  So Neil Young created this Pono, P-O-N-O, Player, PonoMusic.com, to basically be a high-res iPod.  But as you can see, I mean, it's kind of bigger than an iPod.  It's a triangle.  In fact, you could put it on your desk, and you could have your name on it, and it would be just about the size...



STEVE:  Your name tag.



LEO:  Yeah, your desk name tag.  This one is - I got it on Kickstarter because it was a Kickstarter project.  So I have the Neil Young Limited Edition.  This is 251 out of 500.  But that was just because I was an early adopter.  You still can - you can buy them now, they're in their second manufacturing phase and won't be available for a month or two.  Four hundred bucks.  But they've put, they say, and I think they're right, a very good DAC in here, plus a good headphone amp because you...



STEVE:  I'm sure they did because when they first announced it I immediately went to the specs for the DAC that they were using because I had not looked at ultra high resolution DACs for a long time.  And there's a lot there.  I mean, there's a black art to merging the digital world and the analog world at that level of resolution because, when you're talking 24 bits, I mean, those bits are really small down at the least significant end.  And there's a lot of digital noise flying around.  So, I mean, it's an amazing piece of just technology to be able to convert 24 bits of digital data to analog with that kind of precision.  It's really interesting from an engineering standpoint.



LEO:  Well, and you know a lot about this because I know you worked in audio as a student.  And this is one of the things that you are kind of pretty up on.



STEVE:  Yeah.



LEO:  The problem is, and a lot of people say this, oh, it's all psychological.  You know, it's the "golden ears" thing.  And you think you're getting better quality, so it's going to be better, sound better to you and all of that.  And I can't vouch for that one way or the other, you know.



STEVE:  There's always been an audiophile component to people who enjoy music, people who really want good speakers and good amplifiers, I mean, just who enjoy that.  And so I think it's cool that there's an audiophile offering within otherwise this white-ear-buds-on-the-bus crowd.



LEO:  Well, but that's the other thing.  Because now, okay, so now you're got this.  Now you've got to either get - this has both headphone and line out.  So now you either have to get really, really good headphones - 400 bucks for this, that's nothing compared to the headphones - or you have to hook it up to your stereo via analog in.  And if your stereo doesn't have a good DAC, well, this could be in a way giving you a good DAC.  But you want great speakers or great headphones to even approximate it.  But assuming you have that, and you have the ears, I might be - we might be too old to really - I think I hear a difference.  I think I really hear a difference, but...



STEVE:  I would just call it the last half a percent.  And if you're someone who wants to push to get the last half a percent, then, hey, great.



LEO:  Right.  It was interesting...



STEVE:  So it's not going to be a huge market, but it'll be a market.



LEO:  Scott Wilkinson, our home theater geek, on his AVS Forum, you know he's the editor over there, did a blind A/B comparison.  He posted four files, two of them CD quality, two of them high-res, all FLAC.  And he invited his readers to download them and tell him which were which.  And he found an interesting result, which actually to me confirms that you can tell the difference if you're paying attention.  And he also asked, what equipment are you listening?  The readers that didn't have equipment that could handle higher resolution music, 50/50.



STEVE:  Ah, wow.



LEO:  It was almost exactly 50/50.  The statistical odds for guessing.



STEVE:  Expectation, yes, right.



LEO:  Yeah, for guessing.  Of the listeners who had equipment that could play back higher res files, 80 percent accurately picked the high-res files.  That to me said that's more than statistical.  That to me says that you can tell the difference.  Maybe somebody 57 years old can't tell the difference, but somebody can tell the difference.  And it makes me happy just to buy the music in as high a quality as I can.  And it's not that much more expensive.



STEVE:  And you've got storage space now.



LEO:  And I can store it.  The whole collection, which is about 20 albums, because I'm not buying everything, just my favorite things, 60GB.  That's not a lot.  Now, that was a lot when a hard drive was 2GB.



STEVE:  Oh, my god.  Yeah.  Well, I remember, you know, the MFM drives were 20MB.  So, yeah.  We were doing everything we could so squeeze music down at that level.



LEO:  But 60GB now, you know what, I put it on my Dropbox, I put it on my Transporter because I want - you don't want to lose these.  It's you can't, you know, that's it, they're gone.  And I put it on my Pono.  This has 128GB storage capacity.  So, easy.  And classical music sounds beautiful.  But really my favorite albums are mostly rock.  And, boy, they sound great.  When they're not digitally recorded, a lot of albums - when did they start using PCM recording?  In the '80s?  '90s?  So those you're going to get the original, you know, quality is going to be the same as the original PCM recordings, whatever they recorded at.  If it's tapes...



STEVE:  Oh.



LEO:  So, for instance, I have Bob Dylan, "Blood on the Tracks," one of my favorite albums, recorded on tape.  But the tape is analog.  So they master them still at a high bitrate, hoping to capture all the analog data.  So it still, it seems to me, would be better, coming off the analog master in a high-quality system to a high-bitrate recording, is going to be better than what you've got on a CD.  Right?



STEVE:  Yeah.  Yeah, although, I mean, analog systems are notoriously troublesome, too.  You've got, I mean, remember wow and flutter, which are, like, real things.  And then hiss, you do have a signal-to-noise ratio on tape that people like Dolby made their fortunes trying to overcome.  So what's really the best would be high-end, high-bandwidth, digital sampling that's then stored digitally and then returned to you digitally.  And then let's hope that you can transduce that back into analog that your ears are able to accept.  We don't yet have our digital interface.



LEO:  Or if they did it on tape, but the tape was going around really, really, really, really, really fast.



STEVE:  Well, and in fact that was one of the things they did was they ran the tape at a high speed in order to increase the signal-to-noise ratio.



LEO:  I have a recording which was clearly analog of "The Rite of Spring."  It's Leonard Bernstein and I guess the New York Philharmonic.  And the dynamic range on Stravinsky's "Rite of Spring" is huge.  It starts with one oboe or some woodwind.  And you can hear the air in the room.  You can hear the musicians rustling.  You can hear...



STEVE:  Like the flutter in the...



LEO:  You're in the room.  And as far as hiss goes, you hear no hiss on any of these recordings.  There's maybe a little hiss on the Stravinsky.  But not much.  But mostly what you're hearing is the susurration of human respiration.



STEVE:  Yeah, like being there.



LEO:  Anyway, this is a security podcast, but I know you're really interested in this stuff, so I think it's worth - and yes, the Pono does a great job.  But really it's such a big topic.  It's not just the Pono, it's about getting good speakers, good headphones and all the rest.



STEVE:  Right, right.  Okay.  So to our topic, Microsoft having a really rough November.  We spoke last week, which was Patch Tuesday, the Second Tuesday of November, about them dropping basically a mega, and I called it a "red-alert" set of updates because what was the third one in order, the MS14-066. That one, I mean, it's funny because my impression I've since been reading echoed elsewhere was that they just sort of slipped it out there and didn't say much.  And when I'm just scanning the details of it for the podcast, it's like, what?  And as I said, I had to make a trip over to my physical servers at Level 3 in order to make sure they got through the process of updating this because this one was not one I could allow stand.



I should mention that I don't patch my servers every month because I have a very specifically designed constrained environment.  And a lot of stuff that affects other people, like SQL Server, I don't have any SQL Server.  I don't have any .NET stuff exposed or Active Server Pages or any of that.  So I'm able to, and I do, rather than just doing a wholesale update, I actually look at each individual aspect of the patches, and I go, eh, I don't really - and in fact I had not, there wasn't one since May of this year.  When I looked, the last time I had installed patches, Windows Update told me and my logs told me, was early in May of 2014.  That was when there was one that I thought, okay, this one I can't ignore.  This one needs to get put in.  And so at that point I caught the system up, I caught my machines up, brought them current.  But they've been idling since.  I never reboot them.  They never crash.  They just run.  But this one, the 066 was a biggie.



However, a couple days after Tuesday came the news that they had botched something about those four new cipher suites that they added.  Our listeners will remember that last week it's not only are they fixing some sort of a horrible vulnerability that we didn't know that much about, except they just said this is a horrible vulnerability, there's no workarounds, there's no mitigations.  Fix this.  And both for servers and for workstations.  And remember that they also added, which is unusual for Microsoft, to add functionality during a patch.  Normally they do that later in the month.  But for whatever reason, this included four new TLS cipher suites.  And they were good ones.  They were Diffie-Hellman, which we like.  They were SHA-256 and 384, so good, strong SHA-2 family hashes.  I mean, you want those.



Turns out they were broken.  And so people who did follow Microsoft's advice and implorings about getting their systems updated then began having random lockups and server crashes and huge problems because there were problems with the cipher suites.  So the advice then came out a couple days later, uh, delete these from your registry and reboot your machine.  The good news was, since I had already overridden the choice of cipher suites to deliberately select the ones that I wanted, that overrode any automatic inclusion of the new bad ones, so I didn't have any trouble.



But today, in addition to dropping another update which they had held back last week, so we have another, another completely different.  And everyone is running around again saying this is really important, update today.  That is, they did an out-of-band, essentially, although technically they just held it back because they apparently weren't ready for it, or it wasn't tested enough or whatever last week.  So in addition to that, and this is important, because this is not automatic, so everybody who's got IIS servers, I'm talking to you.  You need to manually now redownload the MS14-066 patch and reapply it.  They have reissued it as Version 2, and so I will be doing that at the end, after this podcast is through, since all of this just came in this morning as I was prepping things, and I haven't had a chance to.  Besides, I'm always twitchy about rebooting the server, and so I wouldn't want to do it here before the podcast.



So, but anyway, anyone who applied 066 last week, and everyone should have, it's not so crucial for workstations.  But you might want to do it anyway.  You need to go to the page MS14-066 and get it again manually, download it, and then reapply it.  And so everybody who's using IIS in a web server role exposed to the Internet should do that.  This fixes whatever it was they broke in those four cipher suites.



LEO:  I imagine they'll push it at some point, but they're not pushing it now.



STEVE:  They're not pushing it now.  That's a good question, Leo.  I wonder, maybe they're just a little gun shy after having messed it up last week.



LEO:  Yeah, yeah.



STEVE:  So, yeah, but you're right, they really ought to repush it, and maybe they will.



LEO:  Oh, I'm sure they will.  But, yeah.



STEVE:  Next month.



LEO:  Yeah.



STEVE:  And the bad guys and the good guys, okay, a range of hat colors from white through gray into black are in fact pounding on what it was that Microsoft changed.  I have seen disassemblies posted online of the patch.  The people of various hat colors have found the change that Microsoft made, and they are managing to get Windows servers to crash by fuzzing the TLS handshake.  So this is always the first stage of developing an exploit.



So, and what is a concern is, and I didn't mention this last week, and I should have, this is clearly wormable.  So we haven't seen something like this since Code Red and Nimda and Blaster worms, which were huge events on the Internet.  This is of that scale because an unwitting server that supports secure connections could, once this evolves from crashing servers to running explicit code on servers, and that'll be next week's news, then it becomes something where the hackers are going to, you know, first they'll probably play around with trying to get into servers, depending on how much they're able to do through this exploit.  But then they're going to want to just do a worm.  And so that servers that are exploited start searching for other servers.  And that was immediately where you went to last week, Leo, and you were correct about that, about the idea of, you know, of compromised servers then compromising others.



LEO:  Yeah, we know that's how they work because - yeah.



STEVE:  Or their users, yeah.



LEO:  Yeah, compromising a server doesn't get you as much as compromising everybody.



STEVE:  Yeah.



LEO:  Is it almost always the case that, if you can crash, you can do a buffer overflow and crash an OS or crash a system, that you're going to likely be able to figure out a way to then go to the next step and compromise them?



STEVE:  I don't know that we could say definitively one way or the other.  It's certainly possible for there to be crash-only problems.  Microsoft calls those "denial of service" vulnerabilities.



LEO:  Right, right.



STEVE:  And we hear about those all the time.  You know, half of the Microsoft patches that we're receiving are not remote code execution, they're so-called denial of service.  And we're used to thinking in terms of the bandwidth flood-style DOS attack.  But when Microsoft uses the term, what they mean is you crash the service, thus denying the service that you crashed.  So a lot of these are just, well, we could make the code path crash, but we weren't, by the nature of it, we weren't able to give it a payload.  And so we just don't know.  We won't know, you know, maybe this won't go any further.  But we know that people are looking at it really hard.  I mean, they're tearing this code apart, figuring out exactly what the code path is.  And then they're certainly going to see whether, given what they learn, can they arrange to get a buffer executed.  That's, of course, that's the keys to the kingdom.  So that's where we...



LEO:  Amazing.  Just amazing.



STEVE:  Yeah.  Really cool stuff.



LEO:  Yup.



STEVE:  Okay, now, I got news a couple days ago from Firefox that it wanted to restart.  And so I always check to see what's going on.  I got updated to 33.1.  And then this morning for the podcast I went to About Help, or, oh, no, Help About.  And it said, oh, look, I've got something more.  So they found and they did a little patch on 33.1, and now we're at 33.1.1.  Here's the cool thing they added that I really think is neat.  They call it "Forget."  And it's a new means of enhancing privacy.  The traditional approaches are the so-called "incognito" browsing, where you open a window or a tab or an instance preemptively, with expectation that you are going to be doing something you don't want the system to record for whatever reason.  That's been the traditional approach.  Firefox v33.1 adds a Forget button that allows you - and I call it their Regret button.



LEO:  Or the Day After button.



STEVE:  Exactly, that allows you to cause Firefox to expunge from its memory the previous five minutes, two hours, or day, or 24 hours.  And so when 33.1 comes back up, it gives you a little song and dance to talk about its new features.  And one of the things you can say is, oh, yes, I would like to have the Forget button added to my toolbar.  You can still always access it through the menus, of course.  But it just - and it's a little sort of a spinny backwards arrow.  And I just thought that was really neat.



LEO:  That's such a brilliant idea.  I don't know why nobody's thought of that.  I mean, every browser has an incognito mode now.  But the idea that you may not know you want to be incognito till after you visit that site; right?



STEVE:  Exactly. 



LEO:  Whoops.



STEVE:  Which is why I think this is so clever.



LEO:  It's very good.



STEVE:  The reason is, from an implementation standpoint, it is much trickier.  Essentially you're having to do some sort of journaling or logging.  You have, like, time passing.  And so you need to go back and rewind your state to an earlier time.  That's, from an implementation standpoint, that's a lot trickier than setting up an environment that you know you're going to flush so that none of its updates are recorded permanently.  So this is a little, I mean, from an implementation standpoint, I appreciate that they're able to do this.  It's like, oh, that's very cool, but also a very handy feature.  So at this point Firefox now has it.



LEO:  Have we ever talked about - and this would be a great subject for a later date - just what is forgotten and what is not forgotten in an incognito mode?



STEVE:  Yeah, good point.



LEO:  Because obviously forgetting is only going to - is going to have limitations.  For instance, when you enter an incognito mode, I presume - well, maybe not, actually.  Your IP address would have to be sent to the site; wouldn't it?  Or you wouldn't have a conversation.



STEVE:  Yeah, so, you're right.  So the idea is it would be like cookies that got set or caching of things that your browser received during that time.  The things that are normally sticky don't stick.  They're kept in RAM.  They're never written to disk.  And they are, when implemented correctly, proactively overwritten before the memory that they were occupying is released back to the operating system.  But incognito is not necessarily anonymous.  So the things the browser is sending out in its query headers are probably still identifying.  But you're right, it would be worth digging in and seeing whether browsers sanitize their queries in some fashion because that would be another form of anonymizing which is really different than forgetting on your local system.



LEO:  Yeah.  And frankly, if that's the case, it's not something you could do retroactively.  You can't retroactively sanitize a conversation.



STEVE:  Correct, yes.



LEO:  And so somebody's pointing out this is really not so very different from clear browser history or clear cookies.  It's just time, you could specify the amount of time that you're clearing.



STEVE:  Right, right.  Yes.  And I'm sure we've all been in the position of where we have sometimes, because we needed to, or sometimes inadvertently, we've overcleared our history.  Like if you clear your third-party cookies, baby, well, okay, all of the semi-static things that know you, no longer know you.  So you're logging in everywhere again because you've said don't, you know, I want to just scrub all of my sessions.



LEO:  That's a pain when you do that.



STEVE:  It is.  It is.  Exactly.  And that's the point is that, if you knew that you only needed to go back, you know, that five minutes would repair whatever you had mistakenly done, then it's like, oh, good, I'll just take five minutes, please, because I'd like to keep everything else I've been doing all morning.



Also they built in, sort of making it very easy to use, the DuckDuckGo anonymous searching website as one of their available offered searches.  So that's the second thing that was added is it just - it's built in, making it very easy for someone to choose non-tracking searching as an option on the Internet.  So I thought that was nice.  Speaking of what's not nice, flying dirtboxes.



LEO:  Mm-hmm.  Even the name should tell you something.  You have a nice little graph or a graphic here.



STEVE:  Yeah.  The front page, I always try to put something relevant to the podcast topics on the first page, the bottom half of the first page of the show notes.  And this is from - this is the graphic, I don't know, maybe it was The Wall Street Journal.  They broke the story, but they're behind a paywall that I couldn't get past.  So everyone was looking at CNN's coverage of this from The Wall Street Journal behind the paywall.  But it got picked up and widely covered because it upset people.  The story, okay, we've talked in the last few months about the so-called "fake cell towers."  And we really need, like, cell - we need a better term than "cell tower" because there's nothing that's a tower about it, as I explained before.  The idea is...



LEO:  It looks more like a palm tree in some cases.



STEVE:  Yeah.  Well, and what it really is, is a briefcase, so...



LEO:  In this case.  Well, they've had this, what was it, the Stinger?



STEVE:  Yes.  And that was my point, is we talked about those, for example, maybe in Las Vegas, in casinos, or law enforcement.  We know of municipalities all over the country that have these devices which are, essentially, they are fake cell systems.



LEO:  Sites.  Sites.



STEVE:  Yeah, sites.  Unfortunately, "cell tower" is really the only term we have.  But I remember, when you and I were talking about this before, the question was, you know, could you, if you traveled, could one of these handoff to a real cell tower?  And it was no, because the way real cell towers hand off among each other is they're able to just switch the conversation from their feed to the other tower's feed and make a seamless transition.  In fact, that was really, when we used the term "cellular," that's what cellular means, is this really cool concept of a grid, and it's actually a hexagon ideally, of overlapping cells where each cell only has a short range and only needs to transact conversations within its radius.



And then as someone driving, in the classic example, drives out of that cell's coverage range, they're already in an adjoining cell's coverage.  And by looking at the relative signal strength, the outgoing cell can see that it's beginning to lose this guy.  And so it's able to query the adjacent cells and say, hey, who sees this guy?  And one of the cell towers says, hey, I do.  And so the other cell tower says, okay, you take over.  And so that switch occurs without the user, without anyone in the conversation ever knowing.  That's cellular communications.  And so you're able to drive from San Francisco to San Diego, potentially, I mean, it doesn't really work, but...



LEO:  You know, I had no idea that that's how it worked.  I thought somehow the phone was involved, like, oh, I see a better tower.  So it's actually the towers that are communicating with one another and doing the handoff themselves.  How interesting.



STEVE:  And negotiating, yeah, and negotiating that traffic.  And so, and they get all kinds of interesting information.  For example, I don't know if we talked about it on this show.  There was some guy who was driving somewhere in the Midwest on his commute with a very powerful cell jammer, thinking he was doing some civic good by preventing other motorists in his environment from having any conversations on their cell phones because you're not supposed to talk...



LEO:  Oh, good.



STEVE:  I know.  And he was...



LEO:  That's horrible.



STEVE:  It was horrible.  And it went on for, like, several years.  And he was, like, blocking all emergency services and other stuff because it was just some horribly overpowered, just blanket of like the cone of silence driving down the freeway.  Well, the cell carriers all noticed this pattern that repeated at commute time, the same location, the same place every time each day during the week, not on the weekends.  And they caught him because they were able to associate this moving zone of destruction through the cell system and finally figured out, okay, that guy passes by the same - oh, there it is.



LEO:  For two years.  This is the definition of dick behavior, ladies and gentlemen.  Holy cow.  He's going to face a $48,000 fine, by the way.



STEVE:  Yeah, a ton of fines because it is absolutely illegal to do this.  And so the point is that there's monitoring of all this going on, and the cellular system gets feedback.  And so what they saw was this weird dead zone traveling down the geographical territory that was the freeway, and finally put two and two together.



LEO:  Here's the story from The Verge.  I'm loving this.  By the way, it wasn't Verizon, AT&T, or Spring that caught him.  It was Metro PCS.  Apparently Verizon doesn't care.  Ah, we see cells drop all the time.



STEVE:  We've got your money.



LEO:  Reception was flat-lining along the same point of I-4 in Florida twice each day.  The FCC used, quote, "sophisticated interference detection techniques."  I've seen the trucks.  There are only - there's five or six of them.  There are not a huge number.  But they have these great trucks that can go out.



STEVE:  Really cool Yagi antenna.



LEO:  Yeah, yeah, and track the stuff down.  And officers, they found this guy in his Toyota Highlander.  When officers finally pulled him over, it didn't take long to confirm their suspicions.  As they approached his car, officers immediately noticed their radios lost all contact with dispatch.  Jammers, the FCC says, are illegal under any circumstances and can result in jail time.



STEVE:  Yup.



LEO:  Wow.



STEVE:  Yup.  So that was - we were talking about fixed or law enforcement-based sort of suitcase things, and how they use these when people don't know they're there.  Basically these things are pretending to be cell towers.  They get your phone to connect to them for whatever law enforcement purposes they are alleging.  What The Wall Street Journal discovered and has been picked up is that there are also small aircraft flying overhead with the same technology.  In the articles covering this, it's like, "Fake airborne 'cell towers,'" in quotes, "dragnet and inspect all phones below."  So you can imagine the American Civil Liberties Union is unhappy.



LEO:  Oh, yeah, Chris Soghoian, who's their CTO, Sal Soghoian's brother, said this is appalling.  He says, "I can't imagine even that if a judge approved this, he even understood the incredibly widespread nature."  I mean, you're gathering as many as hundreds of thousands of phones in this dragnet.



STEVE:  Yes.  Yes, you are causing every cell phone within its range on the ground to preferentially connect to this fake flying cell tower.  And law enforcement says that they're doing it to catch bad guys.



LEO:  How is this different from the guy in Florida?  Because aren't they breaking the cell phone when they do this?



STEVE:  That's a very good question, whether "can you hear me now, can you hear me now..."



LEO:  No.  It's a jammer.  I'm sorry, I'm talking to a dirtbox.



STEVE:  There's a government dirtbox flying overhead, yeah.



LEO:  Nineteen airports in the United States.  These are Cessnas.  They're small planes.  And they say it covers - 90% of the U.S. population is covered by these flights.



STEVE:  Wow.



LEO:  They say they gather - what would they get?  They would get the unique identifier for each phone.



STEVE:  Yeah, generically we would say they get the metadata, which is they say they're not messing with the conversation.  We know that the boxes we were discussing before are, I mean, they're pretending to be cell towers.  The decryption...



LEO:  There's no phone calls going through them, though; right?  I mean, it's not - as we've said before with these Stingers, you're not going to continue to have operation.



STEVE:  No, but you are, but they are monitoring the conversations of the cell phones that they're intercepting.



LEO:  You will get five bars briefly.  Look over your head.  If you're getting five bars, and you see a Cessna, you're being gathered.



STEVE:  Yeah.  I have a great connection to the spy tool.



LEO:  But as you pointed out, they couldn't do a handoff because they're not really in communication with the cell networks.  So your call's going to be interrupted at some point.



STEVE:  Yeah.  The problem is very little is known about this.  The government clams up.  And the only problem I have is the secrecy.  If this weren't secret, then it's like, okay, justify your existence.



LEO:  No, no.  It's not - it's a fishing expedition.  They say, just as the NSA does, no, no, if you're not a suspect, we, quote, "let go" of the information.  But you've got to imagine they're harvesting it and storing it in that giant facility in Utah, just as the NSA does.  They collect everything.  They say, look, we're not going to look at it if you're not a suspect.  But if you ever became a suspect, you could be pretty sure...



STEVE:  Right, retroactively.



LEO:  ...they would say, oh, we know where he was.



STEVE:  Yeah.  We would like to know where these people were.  CNN contacted the Department of Justice for comment.  An official at the DoJ would not confirm or deny the use of flying spoof cell towers.  He said, "Any discussion would let criminals and foreign governments, quote, 'determine our capabilities and limitations.'"  Which, you know, is just like, well, you can't make us talk, so we're not going to.



LEO:  And of course because this is metadata, you don't need a warrant.



STEVE:  Right.



LEO:  And this is where really we've got to get the courts up to date because metadata is valuable.  It does have - is identifiable, ultimately, and has a huge privacy implication.  It's not just, oh, metadata.  And so this is like a pen register search.  This is like when they go to the portals run by the phone companies and say, "Hey, where was Leo on Friday?"



STEVE:  You, I mean, we've discussed this of course in the context of Snowden and all of that.  But you can easily make the case that metadata is a far richer source of information for research and plumbing, even than knowing what the person's yammering about, about their dry-cleaning and whether they need to remember to get cat food or what.  I mean, who you talk to and when, your six degrees of separation, that's really vital information.



LEO:  Well, we know it is because they want it because it helps them track terrorists.  So we know it's valuable.



STEVE:  And we know that people knock on, you know, that the government knocks on people's doors, saying, hey, you're a friend of so-and-so.  Tell us about him.



LEO:  Yeah.  Yeah.  That's just what you're going to get.  Isn't that nice.



STEVE:  Yeah, yeah.  So, okay.  AT&T got some props, I guess is the current jargon.



LEO:  That's how the kids say it, yeah.



STEVE:  Yeah.  For ending their supercookie injection "testing," in air quotes.  On the other hand, in digging into this story further, I'm less impressed.  Essentially, so first of all, this is the Verizon and AT&T supercookie, which their equipment is injecting into their subscribers' query headers.  I detected it on both my AT&T and Verizon WiFi accounts.  So I saw it myself.  As soon as I switched off WiFi, which was preferentially handling my broadband, my Internet connection, then immediately I started to see their injection of these X-UIDH and other query headers, which contain a serial number which is about me.  It is associated by my account with the carrier and makes for a tracking supercookie.



We know that it's actually being used, I mean, the concern when we first talked about it was that it was overly strong, that is, unfortunately, the nature of what they're doing to inject something that's unshakeable, can't be deleted, can't be incognito-ized or regret-erized or anything.  I mean, this thing is stuck into your query after you've lost control of the traffic.  The concern was that third parties could also use it because all they had to care about was that it was static. 



Well, now we have evidence of that.  In the developer notes for one of Twitter's acquisitions last year, a company called MoPub, which bills itself as the world's largest mobile ad exchange, it explicitly uses Verizon's tag, the supercookie, to track and target cell phone users for ads pursuant to instructions on the software developers' page.  I have a link in the show notes where you can scan through.  And in fact I tweeted this link because, as I was scanning through it, just to verify that it was there, there is so much else there, it's just chilling.  It's like, okay, I mean, the ad, the guys that want to track us get a ton of stuff.  And so again, the Verizon and AT&T supercookie are among what they get.



Unfortunately, AT&T's suspension looks to be just temporary.  I mean, they desperately want this.  So they're calling what they were doing a "test," which they have ended, and sort of rolled out an end to it, although at no point are they saying they learned a lesson.  Maybe they ended it as a function of some backlash, although even that's not clear because they're still talking, even now, in discussions of this being over, talking about, well, creating a code that changes every 24 hours.  And of course we've talked about the idea of changing the code, how if there's any other information that allows bridging between changes, then changing the code doesn't help.



But if nothing else, there has been a certain - certainly there's been a bunch of backlash, and the companies are going to have to address the privacy concerns.  Remember, this has been going on for years, and it just only recently really came to the fore.  So at least it's a good thing that it did.



Just this morning, on November 18th, the EFF has announced an interesting initiative called "Let's Encrypt."  They have the domain name LetsEncrypt.org.  And next summer, so summer of 2015, they will be launching, the EFF, along with Mozilla and the University of Michigan and Cisco is involved and a couple other large companies, but I think primarily the EFF and Mozilla, and I think...



LEO:  This is so great.



STEVE:  Yes.  It is a free certificate authority whose mission is, as the title implies, Let's Encrypt, to get the rest of the Internet encrypted by creating a facility which can issue free certificates.  Now, more needs to be seen about how this is going to work.  And in fact I think very soon I'm going to cover the protocol.  There's a protocol that's been developed called ACME, and I guess we would pronounce it ACME.



LEO:  Yeah, of course I would, yeah.  So they're automating this, so that the cost of an extended cert, for instance, you can't make that free.  But this will be automated.



STEVE:  Correct.  So ACME stands for Automated Certificate Management Environment.



LEO:  Got it.  Cool.



STEVE:  And what little is known so far, and only little because all this happened this morning, and I'm busy prepping for the podcast and pulling all of this together, GitHub has the protocol.  So there's a JSON over HTTPS protocol.  JSON of course is JavaScript Object Notation, which is the approach that sort of has won the war of XML and other approaches for sending data back and forth, the idea being that somehow this is a protocol between the server and the certificate authority.  So presumably, and I'm just making this up at this point, the certificate authority queries the server in some fashion for something.  And there's a conversation that involves this protocol, this ACME protocol, which allows the certificate authority to confirm the identity to some level of certainty, enough so that it's able to issue a certificate.



And another part of this initiative that the EFF makes very clear is they talk about how it can take a couple hours for an IT person to bring up security on a web server that doesn't have it, just because it's never been made easy.  You've got to dig into man pages and look through sort of strange cryptic command line stuff and generate a certificate and send it to the CA and get the result and fix it in, you know, set it in.  And then you've got to bind it to ports and open ports and blah blah blah.



Anyway, the point is part of this is automating all of that, too, so that, for whatever server families they support with this, their goal is to make this one click.  That is, you download something, and you run it.  And if you're running Apache, it knows about Apache config files and configuring and the ACME protocol.  It downloads what it needs.  It installs things.  It edits the config files.  There's a complete log of everything done, all configuration changes made, so that you're able to back out.  Or you're able, first of all, to audit them and then back out of any or change any that you don't like.  It then contacts the CA, this whatever certificate authority this will be that will be established by summer of next year.  And the CA, through this interaction, gets enough confidence with DNS lookups - oh, and apparently they will be also using Google's Certificate Transparency logging system to further heighten their confidence in their ability to issue certs, which is good, for example.  I don't want anybody else to be able to get a GRC.com cert.



So we absolutely need protection against mis-issuance, and enough attention needs to be given to that.  But that's, presumably, that's what the protocol will do.  So it won't be able to issue, for example, extended validation certificates.  And that's good.  We want those still to mean something.  We want those to mean that extended validation actually did occur.  But the goal here is to, over time, make security ubiquitous.  And the way to do that is make it free and make it easy.  And his initiative, this Let's Encrypt initiative, the goal is to do both.  So I'll know everything about it next time we talk about it because it looks like a perfect topic.



LEO:  That's great.  And you know, kudos to EFF and Mozilla and Akamai and Cisco and IdenTrust because, frankly, Google should be on that list because Google prompted this whole thing with the change in how Chrome deals with certs.  Right?  I mean, they kind of forced this HTTPS everywhere.  Why aren't they doing this or involved in this?  Google, put a little money into this, would you?  Give us some 20% time here.



STEVE:  They certainly are doing the right thing with certificate transparency, along with DigiCert, who's the only other commercial or the only other CA right now that is running a certificate transparency facility because DigiCert's been working with Google from the beginning on this.  But Google is providing the stuff from their end.



The other thing that is interesting, and this was mentioned along with this announcement, and that is the notion of short-duration certificates.  Remember that what we have now, because the issuing system is so burdensome, you know, it's annoying to have to go through all of this every two years or three years.  I mean, even that period of time, it's like, oh, my god, I've got to go figure out that again.  I mean, it's just long enough that you've completely forgotten how to do it, and then you have to figure it out again.  So...



LEO:  That's a clever design.



STEVE:  So the alternative, if you think about it, is, rather than having long-life certificates, which you may need to revoke, like, early in their long life so that you kill them off for the balance of their otherwise valid period, imagine instead issuing short-life certificates.  If you were to issue certificates that only were valid for a few days, then you never need to revoke them.  You just stop issuing them, and they expire.



So another interesting approach here is the concept of let's not worry about revoking certificates that have years of life left.  Let's only issue certificates that never live more than a few days.  But if we're going to do that, we have to make the process automated.  We need to have exactly something like this, some way for the server, in the same way that right now servers can reach out to the certificate authority and ask for updated OCSP status, if you were to implement an OCSP must-staple rule in order to say, here is a reassertion from the certificate authority that this certificate is still good.  I mean, clearly this is a kluge.



So an alternative is that the cert lasts only a few days.  And the server daily goes and gets an updated certificate.  And it's only allowed to do that, clearly, if the certificate is still valid.  So it's a different model.  And this looks like a really interesting step in that direction.  So I'm with you 100%, Leo, this is a great-looking initiative.



LEO:  Yeah, yeah.  Excellent.



STEVE:  And I would argue there's still a position for extended validation certificates, or certificates that are asserting to a much stronger degree the identity.  So all this is doing, this is saying this domain is associated, in DNS, this domain name is being served by this server.  That's the assertion being made.  So that's a distinction we need to make.  That is, nowhere is EFF in this system, the Let's Encrypt technology, nowhere are they making an assertion about the entity that owns the domain.  They're making an assertion about the domain name to IP and server mapping.  That's what they're doing.  So, and they're automating that and making it free.  So that's valuable.  But I want green in my URL, and I want the browser to be able to make the assertion, this is Gibson Research Corporation, and someone, a certificate authority, went to the trouble of, like, phoning us, talking to us, checking our D&B records, verifying addresses and...



LEO:  Flying a dirtbox over you.



STEVE:  There's a real organization here.  That's the role now for tomorrow's certificate authority in this new automated free certificate world.  But not everyone needs that.  Blogs don't need it.  Small sites don't need it.  But they'd like to have security.  They'd like to have encryption.  They'd like to have privacy of their communications.  And note that none of this Verizon and AT&T supercookie stuff works if you've got HTTPS.  That blocks it all.



LEO:  Isn't that good news.  Yeah, we want to be, we want to do - in fact, DigiCert gave us some certs.  We just haven't, because it's a lot of work apparently, installed them.  But of course we want to be able to offer HTTPS.  But if somebody poses as TWiT, there's not a lot of harm there.  I mean, it's not like we do eCommerce.  But it'd be nice to have a cert.



STEVE:  Right, right.  And I'm absolutely sure that there will be technology in place.  When they refer to using certificate transparency and some other online facilities for verifying, somebody else would have a big difficulty issuing themselves a TWiT.tv cert because you're already - you exist.  Your certificate is there.  So any - I'm sure this system will be making those, will have those checks and balances to prevent mis-issuance.



LEO:  And by the way, I donate monthly, I have a monthly subscription to EFF, and I encourage everybody to do so.  They just are so - they're doing God's work.  EFF.org to support them.  And, yeah, I literally have an automatic monthly donation because it's just such a good - and I want to sustain it, you know.



STEVE:  Yeah.  So WhatsApp was in the news.  They were, of course, acquired early this year, early in 2014, I think around February, for $19 billion. 



LEO:  Twenty-two.  When you calculated the inflated Facebook stock, it went up to 22.  Twenty-two.  



STEVE:  Yup, by Facebook, in a cash and stock offer.  They recently integrated Open Whisper Systems' "TextSecure" into WhatsApp for Android.



LEO:  So awesome.



STEVE:  Which is really cool.  And it's enabled by default.  So TextSecure we were just speaking about because an independent audit of it, which was possible because it's open source, concluded that, with a little tweak, fixing something that was found, and the TextSecure guys already were on it by the time this news was out, it passed with flying colors, with that one exception, and that's being fixed.  So WhatsApp, of course, has 600 million users worldwide.  WhatsApp for Android has this.  We're not quite sure when iOS integration will be happening.  But we presume it will be.



The question I had, of course, is, okay, wait a minute, how does authentication happen?  We know that there is a good secure handshake, that that's easy to do.  It's easy to - the technology cryptographically for negotiating keys on the fly exists.  But if you don't have authentication, then you're subject, you're subjected to potential man-in-the-middle attacks.



So I did a little digging because I hadn't looked at TextSecure closely.  As for the security, that is, the privacy of their messaging, they say:  "TextSecure automatically detects" - and this is TextSecure in the WhatsApp app for Android - "automatically detects when a message is received from another TextSecure user" - which will mean another WhatsApp user - "and prompts you to initiate a secure session.  If you choose to initiate the secure session, a key exchange will ensue, and a lock icon will be displayed in the title bar of the conversation view, as well as on the Send button itself."  So there's visuals showing you that this is now secure.  "A lock icon will also be displayed next to each encrypted message received, in order to confirm that it was transmitted securely," that is, that your dialogue remains secure.  But that still doesn't answer the question of authentication, which is crucial.



Next they said, under Verifying Keys:  "It is prudent to verify the identity key of a conversation's recipient, in order to ensure that no man-in-the-middle attack has occurred."  Because, again, you can know that the dialogue is encrypted.  But unless you can verify the key you are encrypting with or encrypting to is actually owned by the person you believe you're having the conversation with, then somebody else could have imposed themselves in between.  Yes, you've got privacy, except you've included a third party, which is certainly not your intention.  So "...in order to ensure that no man-in-the-middle attack has occurred.  From the menu in a conversation, select Secure Session Options.  And then under there is Verify Recipient Identity.  This will present you with an option to manually verify the recipient key's fingerprint, or to verify it by QR code scanning.  If you're physically located in the same space as the recipient, you can select QR code scanning to quickly verify each other's fingerprints."



LEO:  This is like Threema.



STEVE:  Yes.  And this is the only way to do it.  This is why, I mean, this is why Threema, what I liked about Threema was they got it.  They put authentication right up out in front.  That was the focus.  And but TextSecure has done it, too.  "If you're remotely located, you can manually read the fingerprints to each other over the phone."  So that's an out-of-band - both of those are either optical or some other means, acoustic in this case, out-of-band verification.  But that you need to do.



It says:  "Once you verify that the recipient's identity is correct, this information is saved and used to automatically authenticate future secure sessions with that recipient."  So anyway, so they've nailed it.  And so this technology is in WhatsApp for Android, probably coming soon to iOS.  And it's worth just once either showing each other's WhatsApp's QR code, crossing that identity.  And the fingerprint is just a hash of the key.  And so you could just read it over the phone or fax it or send it to their email.  I mean, you'd like the channel to be as secure as you think is necessary.  The idea being, though, that you just once need to make sure that you've actually got the other person's, the true other end's key.  Once that's done, it's stored locally, and it verifies all further communications.



So it's very nice, if this is going mainstream.  And one that happens, see, my problem with iMessage is they've sacrificed all of this in the name of convenience.  But in the process we do not have a system that cannot be eavesdropped on.  What TextSecure is giving us in WhatsApp is that, a conversation that we absolutely know cannot be eavesdropped on because we're given the responsibility of managing the keys.  It's the fact that Apple does it for us that is the Achilles heel in iMessage.  Which is not to say that they're decrypting conversations.  They're not, as far as we know.  But we know they can.



LEO:  And if it were a demand from federal law enforcement, they'd have to, and they might not be able to tell you they are.



STEVE:  Well, you know that it would be...



LEO:  Now, WhatsApp is not open source.  So how do we verify that the implementation within WhatsApp is secure?



STEVE:  Yeah, I think at that point you just increase the thickness of your tinfoil.



LEO:  So you can't be sure.



STEVE:  Yeah.



LEO:  You know, the problem with any of these solutions, Threema or TextSecure, is you have to get your friends to use it.



STEVE:  That's a good point.



LEO:  And WhatsApp is so widely used.



STEVE:  Yes.  That is the benefit is 600 million worldwide now.  And, yes.  And so it's way easier to overcome that with WhatsApp than it is with Threema.



LEO:  And I think you're seeing the benefit of the Facebook acquisition here because we know that Facebook and Apple and Microsoft and Google hate it that the NSA is demanding information from them.  They all have transparency reports in which they're saying we want to tell you, but we can't, what people are being asked to do.  But this way they secure it.



STEVE:  Yeah, right, these companies are suing the federal government for permission to talk.



LEO:  Right.  So I think you could probably safely assume that this is why Facebook's doing this, and they're making darn well sure that they don't have access to the keys because, if they did, then they'd have to hand over the data, and they don't want to.



STEVE:  They don't want to.  Exactly.  Now, okay.  I'm not going to go off half-cocked the way the rest of the industry has because there's some concern over BitTorrent Sync's security and privacy.  It's just been raised.  Everyone is running around suddenly saying, oh, my god, we shouldn't be trusting BitTorrent Sync.  BitTorrent has themselves, in their own marketing side, claimed that Sync is performing eight times faster than Google Drive, 11 times faster than OneDrive, and 16 times faster than Dropbox.  So that's their push.  Of course, it's super popular among people who are using it because it is, it's using the BitTorrent protocol, which is strong and mature.  It allows you basically to keep a whole bunch of different devices all synchronized.  And if one goes down, other ones are able to provide the data.  The problem is that some hackers, I have to make sure I say this right because the original term, of course, is cogito ergo sum.



LEO:  I think, therefore I am.



STEVE:  Right.  And so these guys are Hackito Ergo Sum.



LEO:  I hack, therefore I am.  Ren Descartes is spinning in his grave, yes.



STEVE:  So they're claiming that there are...



LEO:  Hackito...



STEVE:  I know.  They're claiming that there are, quote, "probable vulnerabilities in the client," only because they've made it crash.  So we know that crashing is not the same as takeover, but it's not a good sign - "and that the protocol can leak potentially sensitive hash and client IP data."  Well, okay, it's not content.  It's hash.  And anyway, so we're, again, this just happened.  I'll follow this, and I'm sure my Twitter followers will make sure I see any updates to this.  I think it's way premature to worry.  I know that BitTorrent is working now on a full rebuttal and response, which wasn't available at podcast time.  So, and I'm tied into them.  I'm on their PR list.  All I want is a protocol documentation.  Instead I just get PR nonsense from them, from their PR people.  But it's like, okay, fine, at least I know what they're saying.  And of course BitTorrent adamantly disagrees with that characterization, so.



LEO:  Well, just open, just give us the code.



STEVE:  I know.



LEO:  Here's something the chatroom just told me about called Syncthing that is open source, same idea.



STEVE:  Yup.



LEO:  And it has implementations for Windows, Linux, Mac, BSD, and Solaris.  And it's open.  So, I mean, if it uses - I don't know if it uses BitTorrent protocols.  Those are widely known.



STEVE:  Yes.  Yeah, and there was - we talked about it on the podcast.  There was a reverse-engineering effort of the BT Sync protocol.  And I think that effort panned out.  And I think they figured out everything that was being done because it wasn't a huge change from the original BitTorrent protocol.  They just had - they added a layer for doing interdevice, peer-to-peer syncing of files.



LEO:  And Syncthing works kind of similarly to BitTorrent Sync.  You just give people your ID number, and they can sync with you.



STEVE:  Nice.



LEO:  Yeah.  I'll have to try that.  This looks kind of cool.



STEVE:  So, miscellaneous gizmos, miscellaneous things.



LEO:  All right.



STEVE:  So, as expected, Sunday's TWiT discussion...



LEO:  Oh, thank you for helping us with that, by the way.



STEVE:  ...of Net Neutrality was great.  I thought that was...



LEO:  We used your buddy, Brett Glass, who's been on this show.



STEVE:  Yeah.  And I thought - and your Sonic guy, I thought that the dialogue...



LEO:  Isn't he great?



STEVE:  ...between Brett and the Sonic guy, the Sonic.net guy...



LEO:  Dane Jasper, the founder of Sonic.net, yeah.



STEVE:  Really, really useful.  And I don't think anyone reached a conclusion.  I don't think there is one.  But for a sane, level-tempered, just really thought-provoking dialogue, I wanted to make sure that our listeners remembered that the first hour of TWiT last Sunday was that.  It was, I thought, really interesting discussion.



LEO:  Thank you.  I appreciate that.  Yeah.  We were trying to, you know, shed more light than heat.  And unfortunately, this is one of those things that, if you don't kind of come down on the right side, you hear from people.  But we thought it was more important that people hear all of the pros and cons on each side so that they can make up their mind.  And...



STEVE:  Yeah, the problem is it's complicated.



LEO:  It isn't easy.



STEVE:  Yeah, it is a complicated - and where we are today is a mess.



LEO:  Right.



STEVE:  And so, like, how do we get from the mess we're in today to something that makes sense?  And, I mean, I completely agree with Brett, for example, saying that Title II is the wrong thing.  But, unfortunately, it's all we've got.  And so the idea of reclassiflying - reflying - reclassifying ISPs as common carriers and thereby subjecting them to all of Title II, you know, ISPs look at Title II and go, wow, this is awful.  This was written in the Stone Age compared to where we are.  So, and as you guys said, one of the many suggestions, I think this was yours, was, well, can we get legislators to start over, do something correct?  And the problem is, wow, what a heavy lift that is.



LEO:  Yeah.  I don't think that's going to happen, either.  You should listen.  I think you'll have an opinion.  And then this is just the beginning of what we all need to go through, some homework to figure out what's the best solution.



STEVE:  Yeah, I would argue no conclusion is reachable.  Yet being informed, you know, you can't ever have too much information.



LEO:  Right.



STEVE:  And that first hour of TWiT was really this really useful discussion and information.



LEO:  TWiT 484.  Listen, if you have it.



STEVE:  And I forgot to mention, last week I was going to mention that TWiT in the previous week, Dvorak said he thought Security Now! was your best podcast.



LEO:  Yeah, he loves you.



STEVE:  It's like, holy - what?



LEO:  I was amazed that he listens.



STEVE:  Yeah.  Like, yeah, he seems impatient.  But hello, John.  Thanks.  Okay.  Interstellar.



LEO:  Yes.



STEVE:  This is going to seem so, so geeky.  I mean, I don't - I'm normally not this geeky, I think.  I don't sort of have a self-identity of being this geeky.  But here was my problem.  If they just - and this doesn't really give it away, so there's no spoilers here because it's no need to go into that.  If they just called it a "spatial anomaly," then I would be fine with that.  But they call it a "black hole."  And then it did not behave in any way like a black hole.  And that annoyed me.  So...



LEO:  Well, what specific - okay.



STEVE:  So, for example, information can't come out past the event horizon of a black hole.



LEO:  Well, that was silly, yeah.  But that's why they had to go in.  No, that's - but really, no, Conan O'Brien said it best.  He said people are worried about scientific inaccuracies in a black hole, but it doesn't bother them that Matthew McConaughey is an astrophysicist?



STEVE:  Yeah.



LEO:  It's a movie.  Now, I have to point out that the Nolans wrote this based on the writings of Kip Thorne, who is an astrophysicist and a black hole expert.  Kip was there the whole time they made the movie and did the calculations.



STEVE:  On valium.



LEO:  Well, even he says that the visualizations that the filmmakers make gave him some insight into this spinning black hole that he never would have had otherwise.  It was very valuable for him.  You know, the Bad Astronomer, Phil Plait, said this whole thing of a planet being on the edge of a black hole is impossible.



STEVE:  That, too.  That was annoying.



LEO:  Well, then he took it back.  He said, "I'm sorry, this is a very special kind of anomaly.  It's a spinning black hole."



STEVE:  It's a Hollywood anomaly.



LEO:  Well, no, Kip Thorne, I think, well...



STEVE:  Oh, a spinning black hole, okay.



LEO:  There are such things, apparently.  And the physics of it and the calculations...



STEVE:  That is true.



LEO:  ...are very, very complex.



STEVE:  As matter condenses, you can get a lot of centrifugal spin, yes.



LEO:  Rotation, yeah.  And Phil said the calculations on spinning black holes are - if you think calculations of black holes are complicated, these are more so.  And he said, I apologize, I was wrong, the planet on the edge of the black hole could exist, and the time anomaly they describe in the movie is possible.



STEVE:  Okay.  Because of relativity, which is your catchall.  Okay.  Here's the problem, though.  And that is gravitational gradient.  You cannot, in your spacesuit, fall into a black hole.



LEO:  I know.



STEVE:  You are shredded at the molecular level.



LEO:  I know.



STEVE:  Gravitational gradient, as they say, will get you every time.  And so in Star Trek I don't have a problem if they make up absolute nonsense and call it, like, possible.  My problem is, if they take something that we know a lot about, we know a lot about the behavior of a black hole, and then just ignore it all.  So, however, I thought it was a great movie.  I mean, it was fun.  It was great special effects.  And after about half an hour Jenny nudged me, and she said, "This is different than I thought it was going to be."  Because of course we spend a lot of time on the farm.



LEO:  It's very emotional.  There's a lot of good stuff.



STEVE:  Yeah.  Yeah.



LEO:  Yeah, I thought it was a great movie.  I think it will be considered a classic like "2001."  By the way...



STEVE:  Oh, no.



LEO:  Oh, yeah.  You watch.



STEVE:  Really?



LEO:  Ten years from now let's talk.  And we know we'll be doing the show 10 years from now.



STEVE:  Betcha.  Nothing's going to stop it.  We're in a black hole.



LEO:  AMC has announced that they are going to offer unlimited tickets for people who would like to see this movie an unlimited number of times.  If you've already gone to an AMC...



STEVE:  One was more than enough.



LEO:  You really will feel like seven years have gone by.



STEVE:  I could not sit through that again.



LEO:  They said for 15 bucks, if you're already seen it once, you can by unlimited tickets, see it as many times as you want.



STEVE:  See, that's a safe bet for them.



LEO:  Did you notice it was really loud?  This is what Scott Wilkinson was talking about on Saturday.



STEVE:  I was very aware of the power of the soundtrack and that it really, if you didn't have that, you'd be like, okay, now, what are they doing now?



LEO:  Yeah, right.  What is he doing?



STEVE:  Are we supposed to care about this?



LEO:  What is that?



STEVE:  Is this dramatic or not?  I really can't tell.



LEO:  Hundred dB plus.  In fact, I think he measured it.  He brought a sound meter.  Talk about geeky.



STEVE:  Of course he did.



LEO:  I think he measured, he said, 117 dB at one point.



STEVE:  Wow.



LEO:  Yeah.



STEVE:  So I don't want to put anybody off of seeing it.



LEO:  So did you like it?



STEVE:  I was really - yeah.



LEO:  A little bit.  You liked it a little bit.  You wouldn't go see it again.



STEVE:  No, I couldn't.  It was two hours and 40 minutes.  It was a long movie.  And just kind of, I don't know.  It was a little too pop for me.  I guess that's the way I would put it.



LEO:  You wanted more science.



STEVE:  Nice how everything wrapped up; and it's like, okay, well, we don't have any loose ends.  And of course there is the fundamental problem, and I don't want to - I can't really say  more because I refuse to do a spoiler.  But there's the big causality problem of you can't get that until you already have it, and then - so it's like, okay.



LEO:  It's a movie, Steve.



STEVE:  All right.



LEO:  You've got to have some, you know.  Did you like "Back to the Future"?



STEVE:  Loved it.



LEO:  He saves his life by going back and making sure his parents meet.



STEVE:  Yeah, I guess that's a problem.



LEO:  Remember, he has a photograph, and he starts to disappear?



STEVE:  Yeah, but he had a hoverboard.



LEO:  Oh, the hoverboard made it all right.



STEVE:  Actually, I don't think that was that one.  That was one of the...



LEO:  It was the second one?  Yeah.



STEVE:  "Back to the Future Again."  Okay, so...



LEO:  There is a movie, though, that you do want to see.



STEVE:  Yes, yes, yes, yes.  Comes out Friday after Thanksgiving, November 28th.  And it is - I saw an interview - what was it on?  I saw an interview somewhere of several of the actors who star in the movie.  It's called "The Imitation Game."  And in fact the website is TheImitationGameMovie.com.  And I think you can get the preview there.  It's very dramatic-looking, with lots of stuff going on on the web page.  But anyway, it's the history or the story of Alan Turing and Bletchley Park and their decryption of the German Enigma machine ciphers, and how vital it was and all of that.  But apparently strong on being a tribute to Alan Turing.  So...



LEO:  Yeah, we have a viewer who saw it and said it's great, and a heart wrencher.  So how do I get this site started here?  I just - do I click?  Do I rearrange?  Seems like there's stuff going on.



STEVE:  I had scripting off, of course.



LEO:  Oh, then it worked.



STEVE:  It kind of limped along and did stuff, but clearly a lot of attention was paid to it.



LEO:  There's some real scripting going on here.  Wow.  Wow, all right.  Well, I'm not going to be able to see the trailer unless I solve this crypto game, apparently.



STEVE:  I would imagine, if you just put "The Imitation Game" into Google, IMDB probably has it with a lot less nonsense going on.



LEO:  Well, now I've got to solve it.  All right, go on.  You know what I'll be doing for the next hour.



STEVE:  One of the main actors, not ones interviewed, but one who was not sympathetic, I was looking at him, it's like, why do I know him so well?  I mean, we already know him.  But it was like, why do I know him so well?  It's like, ooh, he's the evil father king on "Game of Thrones."



LEO:  Oh.



STEVE:  And so they brought him out to play...



LEO:  He's a good actor, yeah.



STEVE:  Yeah, he really is, yeah.  So, looks like it's going to be great.  And keeping in with our Q&A theme, I thought I would answer a listener's, because I encountered this reading the mailbag, answer a listener's question about full disk encryption with SpinRite and SSDs.  That had never come up before.  Greg wrote, he said, "My routine before I do" - and I should mention before he's apparently a Linux guy.



"My routine before I do full disk encryption is to SpinRite" - to turn it into a verb - "the hard disk drive at Level 5" - so a full-strength deep SpinRite - "the idea being to expose as much of the disk as possible before overwriting it with pseudorandom data.  Following this, I installed the encryption container using Linux's dm-crypt and LUKS, L-U-K-S.  Considering the wear that SSDs incur from Level 5 SpinRite, do you think this is a good idea to do on SSDs prior to overwriting them?  For security, the SSD has to be overwritten prior to putting the encryption on.  So the wear incurred is necessary.  But does my use of Level 5 before overwriting make sense to you from a security perspective, or do you recommend I just use Level 2 for SSDs that I want to encrypt?"



My feeling is there Level 5 is what you want.  Because once upon a time when error correction was relatively weak on hard drives, and drives were a lot slower, or a lot smaller, SpinRite wrote a whole bunch of patterns.  Its strongest pattern testing did a whole bunch of stuff.  Now, because error correction, as density has increased, out of necessity the ability to do on-the-fly error correct has been strengthened dramatically.  And of course chip density is higher.  That supports much stronger algorithms for correct.  The chips are much faster, and so they're able to do more on the fly and so forth.  So as all of that scaled up, and drive size scaled up, SpinRite's - the surface analysis and testing that SpinRite had to do was scaled down in proportion.  So now what SpinRite does is only two writes.  It reads what's there, inverts it and writes that, reads that, inverts it again, and writes it back.  So that's just two writes.



LEO:  And that doesn't make a wrong.



STEVE:  Actually, because it's inverting, it puts them right back where they came from.



LEO:  There you go.



STEVE:  Exactly.  And then you're going to run encryption which is going to go across the entire thing again.  So if you did nothing, if you did no writing, then you'd write everything once.  If you use Level 5 on SpinRite, you're writing everything three times.  And compared to the writing that you're going to be doing for the rest of the drive's life, that's nothing.  So, and it does make sense, I think, to run SpinRite over an SSD to help the SSD immediately find any areas that it might want to swap out at that point.



Now, one thing that you didn't mention, and that everyone should think about, is after you put encryption on the drive, you really then want to reset trim because both running SpinRite on an SSD, where SpinRite is doing any writing, or doing whole drive encryption, will saturate the drive's trim bits.  Remember the trim is an extra facility in SSDs to dramatically speed it up, where it operates sort of at the physical level of the SSD to inform, to sort of remember whether anything useful has ever been written there.  And if you run SpinRite on an empty drive, you've written nothing useful.  So you absolutely want to run a trim-clearing utility after that.  And without giving away too much, that'll be an option in the future, at my end.



But if you then encrypt the SSD, you're writing all the sectors again.  So what you need is you need to be able to run some sort of trim-clearing utility on the post-encrypted SSD to get it to relax, essentially, to tell it that, even though a lot of writing has been going on, we don't care about any of that because then you're going to put the file system on the drive.  And that's going to be doing the first actual writing that we care about.  So I would look into post-encryption trim-clearing on SSDs.  I'll be able to do post-SpinRite trim clearing, but that wouldn't help you in this case because you're then going to write the entire drive one more time.



LEO:  All right.  And we'll leave it as an exercise to the listener to figure out how to do that.



STEVE:  There are lots of utilities for doing that.



LEO:  Why is this at the end of your show notes?



STEVE:  That's at the end of the show notes.  If you zoom in...



LEO:  It's a picture of a CD.



STEVE:  It's actually a very special DVD called an M-DISC.



LEO:  What is an M-DISC?



STEVE:  And it's made by Hitachi, and with an interesting name, which I was able to pronounce.



LEO:  Millenniata.



STEVE:  Millenniata.  I love that.  This refers to one of - I'm glad you asked the question, by the way, Leo.  This refers to one of our five questions.  This is a 1,000-year archival storage.



LEO:  Millenniata.



STEVE:  Literally written - are you sitting down on your ball?  I think you are.



LEO:  I am.



STEVE:  Literally written in stone.



LEO:  What?



STEVE:  It doesn't use dies.  It uses inorganic material, basically stone.  It melts the stone.



LEO:  Wow.



STEVE:  And so it inscribes 4.7GB in stone.



LEO:  Yeah, I like it.



STEVE:  Yeah.



LEO:  Wow.  We'll talk about that because our question-and-answer section has arrived.



STEVE:  Yes.,



LEO:  Yes.  And we will start with Question Numero Uno.  Let me just take the Millenniata out of the way.  It's kind of a big - I blew it up.  It's real big now, and I can't see the questions anymore.



Advait in India wants to know about going to your servers at Level 3.  Steve, on the past episode, you said you had to physically go to your servers to update them for the Schannel bug.  We now know you're going to have to do that again, apparently.  But so why do you need to go to them?  Can't you just do it remotely?  That's a good question.  I thought you could pretty much do all Windows Server maintenance remotely, including power cycling, if you have the right equipment.  Don't most co-los allow for remote power cycling?  I know ours does.  Just curious.  Thanks, love the show, happy SpinRite owner, et cetera.  Advait.



STEVE:  So I just wanted - I thought this was an interesting question.  I had several other people ask, like, wait a minute, you know, why are you going there?  And the only reason is I have been so well trained by Murphy.  I am a disciple of Murphy.  And this was, as I mentioned, since I'm not rebooting them all the time, like in this case it's been six months since I have had to touch them.  And that meant that I'd be doing a lot of patch catch-up.  And we've all had the experience of doing a big update and rebooting our system and the screen stays black.  And for GRC, I just - I didn't want to be here at home, clicking things, pressing buttons, waiting for the server to come back up, and have it not.  So I wanted to be there where I was physically present and could deal with anything that might happen.  And as it was I made fresh images and did some other, you know, just sort of cleanup stuff.  And, you know, I just never visit.



So it was nice to sort of check in, and it feels good to sort of see that everything's the way I left it.  And I think, frankly, this little update, I probably won't bother making a trip, since I just did a week ago.  I will make sure that I've got a current set of images and backups.  But this one I will do remotely.  So, and I have power control equipment, and I can do power cycling and all that stuff remotely.  But this seems like, well, you know, it's been six months.  It's worth a trip.  And as it happens, everything went just swimmingly.



LEO:  Oh, good.  Oh, good.



STEVE:  Yeah.



LEO:  Charles Victorian, great name, in Houston, Texas, has some SQRL implementation help questions:  Steve, long-time listener, blah blah blah, all episodes, blah blah blah, Security Now! University graduate, et cetera.  You and Leo rock, blah blah blah.  He actually wrote all of that, by the way, folks.  I'm not making it up.



In pondering SQRL, I was wondering/hoping for three important things:  Would you please help with the creation of tools or libraries or simple instructions, et cetera, so that web developers not on the rocket surgery level can easily implement your strategy for login?  Dumbing it down may be important for this to catch on like wildfire.  Two, would you please create a sample login page on your website which would allow people using your SQRL reference implementation, or any other really, to have a known working location to experiment with logging in via SQRL?  Three, would you please make an iOS SQRL client yourself so that we know it's as TNO as possible?  I, and perhaps many others, apply the TNOBS principle - Trust No One But Steve.  We'd pay for that app.  Not trying to be mean to other iOS devs, but they haven't earned your white hat reputation yet.  I'm just sayin'.  Thanks for all your hard work to both you and Leo.



STEVE:  Okay.  So a couple things.  Other developers - so the first point was what about dumbing it down or making it easy to implement.  There will be drop-in packages for all the major web server-side stuff, Drupal and PHP libraries and all of that.  That's all in the works and underway.  And there are some that are even up and running at this point.  So it won't be necessary for anyone to write this stuff from scratch, though once this is all absolutely finalized, I absolutely will have some simple, like, flow charts of what API call you issue when.  Other people who are involved in the GRC newsgroups have asked for the same thing.



As for a sample login page, yes, absolutely.  There's actually - it's already there, although it doesn't quite do much.  I'm using it myself as I'm finishing the final phases of this.  GRC.com/sqrl/demo.htm will present you with a valid SQRL QR code right now.  And once you have the client, you can either click on it if it's, well, in fact you would in your browser click on it.  And Leo, if you refresh that, every time you refresh it you'll see that you get a different - actually yours is blanking the whole page, so it's less easy to see.  In Firefox it just changes the QR code, just goes blink.



LEO:  It's because everybody has gone to your page.



STEVE:  Ah.  That's right.  Sorry about that.  Anyway, so that will allow you to log in and create, like, a fake SQRL account and also, like, show you when you last logged in, how many you've logged in, when you've changed your identity, a whole bunch of other metrics and so forth.  And then there will be another place, it'll be sqrl/dump.htm, that doesn't yet exist, where all of the crypto stuff will be made visible so that developers will be able to verify that their crypto exchange is the same thing that GRC is seeing.  And that stuff is easy to do.  I just haven't gotten around to it.  But essentially a pseudo login facility where you create SQRL accounts, that's actually the database on the backend is already there.  I just haven't brought it out to the web service yet.



And as for iOS, no.  I'm going to be going immediately back to SpinRite 6.1 and returning to the development of that.  I don't know of an iOS developer except that Ralf had mentioned - Ralf is the person who has done the Android client implementation that is up and running and works for Android, that people can download.  If you have an Android device you can get SQRL for it right now, although Ralf has not finalized it until I finalize mine.  And there have been some protocol tweaks.  And he did reference, months ago, doing one for iOS.  I'll be happy to work closely with any iOS developers to, like, have it get my seal of approval.  But that's the most I can do.



I just - I can't take any more time away from SpinRite.  Maybe after 6.1 is behind me.  We'll sort of see where things go.  I also don't want to spend any time if it never gets off the ground because that would be sad.  But on the other hand, it will help to have an iOS implementation for it to get off the ground.  So maybe I could say that the first iOS SQRL implementations won't be the last, and we'll just have to play it by ear.



LEO:  Question 3 comes from Edmonton, Alberta, Canada.  James is the one who told us about the stone DVDs, the Millenniata, the M-DISC.  Now, I've got to point out, good for a thousand years; but, yeah, a thousand years from now, who're you going to sue if it's not?  Oh, man, it's not good for a thousand years.



STEVE:  So it's a couple years old.  It's called the M-DISC, just letter "M" and then DIS - now, I write "K," but I don't know if it's "K" or "C."  Sometimes discs are with a "C."  So, and it was Mitsubishi that had acquired the rights and was going to produce the medium and the drives.  I don't think this thing uses standard DVD writers.  So I think you need - because, I mean, it is, apparently it is stone, so it's going to use like a stronger laser.



LEO:  I would hope it would use standard readers, however.



STEVE:  I don't know either way, actually.



LEO:  That would be an issue because a thousand years from now, if it's a nonstandard reader, chances of getting one are slim.



STEVE:  Very good point.  A thousand, you know, that thousand years is a long time, Leo.



LEO:  Even 10 years from now, the chance of getting a reader might be slim.



STEVE:  So we had been talking about archiving.  And several people, one who is a member of the archives, it's like archivist association, talked about the stone DVD and the M-DISC.  So this is the real deal.  If you're somebody who wants to or has an interest in storing in allotments of 4.7GB, that is, a single-sided DVD - wait, that's Blu-ray density because a DVD - isn't a DVD...



LEO:  No, that's DVD.  Blu-ray is more.  It says, apparently it does say readable on current DVD and Blu-ray drives.  So you can read it.  You just can't write it without a special writer.



STEVE:  That absolutely makes sense.



LEO:  You need a chisel and a hammer.



STEVE:  So they've kept the format identical to standard DVD, yeah.  Blu-ray, of course, is in the 40 and 50GB range.



LEO:  Yeah.  And a single-sided is 4.7.



STEVE:  Right.



LEO:  DVD, yeah.  They apparently do make them in Blu-ray sizes.  Probably want that.



STEVE:  No kidding, wow.



LEO:  Probably would want that.  Question No. 4, Dave in Southampton, United Kingdom, wonders about data recovery on destroyed hard disks:  Steve, in a team meeting, a sad and unfortunate story of a soldier in Afghanistan being killed by an IED was told.  The story was used to highlight a security problem with hard disks because, although the laptop he was carrying and the hard disk it contained were both destroyed, the data on the laptop was important and was retrieved by taking the disk apart and scanning it somehow to get some of the data back.  The story was told to us to highlight the issue, even after destroying hard disks simply by drilling a hole through them or taking them apart and cutting them to pieces with tin snips, this may not completely destroy the data that's on them.



Now, I accept it's possible to get the data back from a disk that's been destroyed in this manner, although I will fall off my chair if you can tell me you will do it with SpinRite.  How hard is it to actually do, assuming the disk was not encrypted?  What type of equipment would be needed to achieve such a task?  How long could it possibly take?  My current contention, until you tell me otherwise, is that it is extremely difficult to do, requires extremely expensive equipment and people.  Let's assume that he is an attacker, he may not get that data that's of any use to him.



If I'm correct on this, then I assume that an attacker who would have the resources to do this would also have the resources to place an insider in an organization because that would be a lot easier.  What do you think?  Many thanks.  Regards, Dave. P.S.:  If this answer is heard on Security Now!, please do not give my surname in case someone from my team also listens, and I get accused of rocking the proverbial boat again.  But you can give my location.



STEVE:  So, okay.  The only way to get data back at today's recording densities is to somehow put a disk that can still spin and aerodynamically support a flying head over its surface.



LEO:  In other words, isn't bent.



STEVE:  Right.  And it hasn't had tin snips, or hasn't had a pattern of holes drilled through it, all of which would destroy the ability of a head to fly.  Older generation drives may have had simpler recovery being feasible.  You could actually - there used to be a solution you could actually rub on an old-style oxide disk and then look at it through like a microscope and read the bits.  You could actually see the bits because this fluid was affected by the magnetic domains stored on the oxide.  But today's densities make that absolutely impossible.  So if the story is not apocryphal, I mean, if it's actually true that following an IED explosion - and it wasn't clear whether the bad side got the disk, recovered the laptop and disk.  It sounded like maybe our guys got it and were somehow able to recover it.



LEO:  The whole thing's made up.  Come on.  You know it's not a true story.



STEVE:  Anyway, the answer would be you could, I mean, if you really needed to recover it, you would take the drive apart and mount those platters in the same make and model of another drive and then maybe have a chance.



LEO:  And we've talked about this before.  It would be possible, I mean, this is governmental level decryption.  It's not...



STEVE:  It is really, yeah, it would be - oh, no, it's absolutely NSA...



LEO:  It's not the mob.



STEVE:  No.  No, no, no.  It's NSA labs absolutely need to recover the data level.  But again, our technology - we talk about this all the time.  Hard drive storage is so fragile that it barely works on a good day.  So subjecting a drive to any kind of physical trauma, forget about it.  I mean, especially tin snips and drilling holes with drills.  It really does end - end of life.



LEO:  It's hypothetical.  It's hypothetically possible that you could read somehow the magnetic field on the disk if you had extraordinarily sensitive equipment and then somehow hypothetically assemble it.  You know, we've heard people do kind of outrageous things like reassemble shredder pages.



STEVE:  Well, and, yes.  But, see, there you have the benefit of them being physical things.



LEO:  Right, you can look at them.



STEVE:  Because anyone who actually knows what happens between the user submitting 110011 and what's written will really appreciate there's four different stages of translation.  And one of them is called "whitening," where its goal is to average the number of transitions per linear extent in order to keep the write amplifier from being too much biased in one direction or the other.  So my point is that even the magnetic image on the drive is only distantly related to the data that was originally written.  And only all of the electronics and data recovery in the read path of the drive that wrote it even knows how to translate the magnetic information back to the usable user data.  So even if you had, if you could even get the actual magnetic patterns, that's not the data that was written on the drive.  You have to go back through the read process.  And how do you do that?



LEO:  Right.  Yeah, yeah.  Not to worry.



STEVE:  Not to worry.



LEO:  Final question from Charles - is it the final question?  Actually I didn't check.



STEVE:  Yeah.



LEO:  Yeah.  Charles in the U.K., we're talking about brute-force encryption:  There's one thing with brute-force attacks against encryption that always left me perplexed.  How do you know you succeeded?  How do you know the results of decrypting with a key is a success if you don't know what to expect?



STEVE:  You know, this is a great question, and it comes up all the time.  And normally we run out of space.  And I thought, okay, Question No. 5, since we've got so much to talk about at the top of the show, and as it turns out our timing was about right.  Okay.  Let's look at two examples.  The only way to answer the question is to actually drop it into the real world.  Two examples:  The first is - and two relevant examples.  The first is communications.  With an SSL/TLS connection, and the issue is brute-force determination of the key, how do we know?



Well, as we mentioned recently, unfortunately, SSL got the order of authentication and encryption wrong.  They got it backwards, the original designers, the well-meaning guys at Netscape.  They said we're going to take the user's data.  We're then going to authenticate the data, that is, run an HMAC over it or whatever, and have the authentication added to the end.  Then we're going to encrypt it.  That's unfortunately wrong.  As we discussed then, the well-understood now in contemporary crypto knowledge is you always encrypt, then you authenticate, because the process of decryption requires a reversal of steps.  So that means, if you encrypt, then authenticate, which is correct, but unfortunately not what SSL does, then that means the first thing you do when you need to decrypt is to authenticate, then decrypt.



But with SSL, it's backwards, which means that the last thing done is encryption, which means the first thing we do is decryption.  And that means that we can always test to see whether our decryption was correct because we then verify authentication.  And so SSL, by doing it in that order, the only good side, I mean, there's other bad aspects to it, but in this case we can do a trial decryption and then a trial authentication.  And if the key is wrong, we will have decrypted the wrong data, which will not authenticate.  And so in the case of communications flow, we're able to verify by checking the authentication.



The second real-world example, completely different, is stolen passwords, which we're talking about with websites all the time.  Somebody gets a database of password information belonging to some website.  Now, what do they have?  They have the hashes of the users' passwords.  So what they're looking at, what they have is the result of the input password being hashed through whatever algorithm the site uses, which they presumably know because that's typically part of what they're able to figure out in order to crack this.



So the goal is - they've stolen the password database.  They want to determine the input passphrase that, when run through the hashing algorithm, whatever it is, how many iterations of algorithm it might be, how much strengthening it has and so forth, they want to determine the input passphrase that results in the hash that they have in the database.  So they're not actually decrypting that hash in the database.  Rather, they're successively - you can think of it as encrypting or enhashing.  They're successively hashing guesses to see if they get the same result.



The reason is, if they get the same result, then they have figured out almost certainly the user's password, or at least a password that results in the same hash, which then allows them to go to that website and log in as that user.  And if the user has been unwise and reused that same password elsewhere, and they have any other information about the user that they also stole, like their email address, name and so forth, maybe they can use that same information to log into other websites to impersonate the user.



So those are two examples.  In one case, the authentication, which is part of the integrity guarantee of communications, it can be used to verify the decryption, that the guess is correct.  And in the instance of a password database being stolen, you're not really decrypting what the database had, but rather you're doing the same thing the server did when the user enters their password to get a result.  You know the result, so now you just make a lot of guesses until you get the same result.  And that's how it works in the real world.



LEO:  Excellent.  Or you just, as somebody in the chatroom said, you shout, "I have the message," versus "I have the message z4391x!qtty."  Right?  Usually it's pretty obvious.  Hey, Mr. G, that concludes this edition of the fabulous Security Now! podcast.  Each and every week we meet and talk about the latest issues in security.  Next week, do you know yet?  Or is it going to be a surprise?



STEVE:  Don't know.  I'm really curious about this ACME protocol which the EFF is using.  And to what degree, you know, how much they're doing, I want to see how much is there.  So if there's enough there, we might talk about that.  Otherwise, I've got a long list of stuff to get to.  So I'll pick something.



LEO:  As always.  You can find Steve on the Internet at GRC.com.  That's his home on the web.  He also has a lot of stuff there you might want, including SpinRite, the world's finest hard drive maintenance and recovery utility, and all the freebies like crazy he gives away.  You'll also find 16Kb audio of the show, and transcripts written by Elaine Farris, so they're very easy to read and a good thing to read along while you're listening.  Steve's on the Twitter @SGgrc.  Questions to Steve can be forwarded to him from GRC.com/feedback.  We have full quality versions of the show, audio and video, available at our site, TWiT.tv/sn, on YouTube.com/securitynow, and wherever finer podcasts are aggregated for later distribution through the Internet network of networks.  Mr. G?



STEVE:  As Brett reminded us, it's actually not owned by anyone. It's an Internet of networks.



LEO:  It's an Internet of networks.  A 'Net of networks.



STEVE:  Okay.  Leo, always a pleasure.  I will be back with you next week.



LEO:  Thank you, sir.



STEVE:  See you.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/ 



SERIES:		Security Now! 

EPISODE:	#483 

DATE:		November 25, 2014 

TITLE:		Let's Encrypt 

SPEAKERS:	Steve Gibson & Leo Laporte 

SOURCE FILE:	http://media.GRC.com/sn/SN-483.mp3 

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm  



DESCRIPTION:  This week Leo and I cover two major stories:  the discovery of a frighteningly capable and sophisticated espionage malware known as "Regin," and deeper coverage of the forthcoming "Let's Encrypt" free and automated web server certificate issuing and management system.  And, as always, we also cover a bunch of interesting smaller issues. 



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here with really two big topics:  A new massive malware threat that looks to be written by some government somewhere in Virginia, it's called "Regin," we'll talk about that and kind of the miraculous construction of it; and then Steve will take a look at the new effort from the Electronic Frontier Foundation to encourage encryption on every website, Let's Encrypt.  Security Now! is up next. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 483, recorded November 25th, 2014:  Let's Encrypt. 



It's time for Security Now!, the show where we cover your security and privacy online with this cat here, the Explainer in Chief, Mr. Steven "Tiberius" Gibson, who is coming up for New Year's, I hear. 



STEVE GIBSON:  I am.  And early enough to hang out. 



LEO:  We're going to have a host dinner. 



STEVE:  Correct, on the 29th. 



LEO:  Will you be here for that? 



STEVE:  Yes, Jenny and I both. 



LEO:  I think we've got 20 or more people.  And what we've done is we've booked the oldest roadhouse in the area, the Washoe House, which used to be a roadhouse in the 1860s where the stagecoach would stop. 



STEVE:  Huh. 



LEO:  They haven't really updated it since. 



STEVE:  So we'll be picking splinters out of our butts afterwards? 



LEO:  Yeah, it's - we thought, you know... 



STEVE:  Don't slide.  Don't slide. 



LEO:  Right, exactly.  We thought, oh - Lisa and I went back and forth.  We really wanted to have a host dinner.  And because a lot of people are coming for New Year's Eve and so forth, and we just thought it'd be really fun to have all the hosts together.  And since many of you are coming from out of town, initially we were just going to go to one of our many fine restaurants here, but that could be anywhere.  So we thought, what could we get that's really - that says Petaluma? 



STEVE:  And you found it. 



LEO:  And this says Petaluma.  But it's good. 



STEVE:  They have plumbing. 



LEO:  They have plumbing, but you can hitch your horse right up to the front there.  It's actually, it's really a great place.  And they have great steaks.  I know you like steaks.  We're going to get some Cab for you.  I don't know what Jenny's going to eat, but we're going to get... 



STEVE:  And what's it called again the place, just The Roadhouse? 



LEO:  It's the Washoe, W-A-S-H-O-E, Washoe House.  And they've had in the past, you know, it's haunted, they say.  So every Halloween Eve one of the local radio stations spends the night there, looking for ghosts.  It's fun.  I think you're going to like it. 



STEVE:  Cool. 



LEO:  Yeah.  And IDoTech says dollars bill on the ceiling.  That's right.  How did you know that, IDoTech?  That's exactly right. 



STEVE:  He does more than tech. 



LEO:  Apparently he's been to the Washoe House.  Or else he's looking at the website.  It is really an amazing place. 



STEVE:  So today we've got two topics.  We didn't have much news.  And frankly, I studied, I read the entire Let's Encrypt spec, front to back, and I've got it.  I understand all about it.  Then I started doing my homework on one of the things I wanted to talk about, which is the - we think it's called "Regin," and I'll tell you why I think so - new amazing malware which has been defined.  And it just sort of absorbed my entire morning.  The deeper I got into it, it's like, oh, my goodness. 



LEO:  The folks at Symantec who discovered it said it was the most sophisticated malware they'd ever seen. 



STEVE:  Well, if any of the people or team who developed it are listening to this podcast, nice going. 



LEO:  And would that person who is listening to this podcast be anywhere in Northern Virginia? 



STEVE:  Yeah, I think they probably have a large stake of data territory.  So we're going to talk about that first because technically it's sort of our show notes.  And the main topic of the show is Let's Encrypt.  And not much else happened.  We've had several crazy busy weeks previously, so that's fine.  We're going to do deep dives into these two topics.  And there is a little bit of miscellaneous stuff because I did see "Citizenfour."  I want to talk to you about that and some other stuff. 



LEO:  Oh.  Oh, good. 



STEVE:  So we've got another great podcast here. 



LEO:  I'm excited.  Let's get down to the tech news, or the security news. 



STEVE:  Yeah.  Okay.  So the bottom of the first page of the show notes is Symantec's diagram of the way this Regin installs itself, which you might want to put up on the screen just to show people who are watching the video.  Just the first few paragraphs of Symantec's analysis gives you a sense for what they feel about this.  They said:  "In the world of malware threats, only a few rare examples can truly be considered groundbreaking and almost peerless.  What we have seen in Regin is just such a class of malware. 



"Regin is an extremely complex piece of software that can be customized with a wide range of different capabilities which can be deployed depending on the target.  It is built on a framework" - actually, in my notes, after digging into it, it's an OS within an OS.  It's that sophisticated.  It brings its own encrypted virtual file system along.  It's like nothing we've seen before.  So anyway, they said:  "It is built on a framework that is designed to sustain long-term intelligence-gathering operations by remaining under the radar.  It goes to extraordinary lengths to conceal itself and its activities on compromised computers.  Its stealth combines many of the most advanced techniques we have ever seen in use. 



"The main purpose of Regin is intelligence gathering, and it has been implicated in data collection operations against government organizations, infrastructure operators, businesses, academics, and private individuals.  The level of sophistication and complexity of Regin suggests that the development of this threat could have taken well-resourced teams of developers many months or years to develop and maintain. 



"Regin is a multi-staged, modular threat, meaning that it has a number of components, each depending upon others, to perform attack operations.  This modular approach gives flexibility to the threat operators as they can load custom features tailored to individual targets when required.  Some custom payloads" - which we'll discuss in a minute - "are very advanced and exhibit a high degree of expertise in specialist sectors.  The modular design also makes analysis of the threat very difficult, as all components must be available in order to fully understand it." 



Okay.  So here's what we have.  We have a fundamentally different class, an entirely different class of malware.  I mean, this is what books are written about, like sci-fi espionage books.  I mean, it sort of gives me, as a developer, goose bumps because it is clearly the work of somebody, as Symantec wrote, with extensive resources.  For example, one of the add-on modules is able to infiltrate and intercept GSM cellular admin traffic, parse it, and exfiltrate it. 



Also in their report Symantec shows some pie charts or where this thing has been found.  Leo, the PDF, the second link in the second page of the show notes is to a PDF.  And I think like about the third page of the PDF, if I remember, has two different pie charts.  The first one shows the geographic distribution of where this thing has been located, or I'm sorry, the second one is geographic distribution.  More than a quarter of instances have been found in Russia; the second most prevalent location was Saudi Arabia; and then other specific geographical regions, working their way down.  So this is not... 



LEO:  And by the way, not the U.S.. and not the U.K. 



STEVE:  Right.  Zero.  So... 



LEO:  Just a coincidence. 



STEVE:  ...this is not opportunistic infection.  This is clearly explicitly targeted.  I mean, if we think of Stuxnet, Stuxnet is the only sort of similar thing we've discussed where something the size of nation states had focused intent and implemented their focused intent through software and through cyber espionage to achieve that goal.  In the case of Stuxnet, though, it wasn't a general-purpose platform.  It had characteristics of that; but all of it was about, we now know, arranging to get a specifically capable malware package installed on air-gapped machines that were controlling the refinement centrifuges in Iran. 



So this is different in that it is fundamentally structured to be a general-purpose espionage tool.  I mean, what's been discovered is what probably the NSA has spent huge resources creating and hiding.  One of the ways this thing, I mean, it does many things that have not been seen before.  For example, they presume there must be an executable "dropper," as it's typically called.  That's the module that is dropped onto the machine.  It has to be executable because, without any prior knowledge, the machine just has to run it.  But even now, they've never found it.  So they don't - they've never found a sample of it because it is designed not to need to persist.  The various pieces of this live in both the registry, where they're encrypted binary blobs, encrypted with a custom variant of the RC5 cipher, which again, when you think about it, that's very clever because RC5 is very simple. 



And so it's a perfect cipher to choose if you could choose among anything.  It uses a 64-bit block, which makes sense also because what they're going to be encrypting and decrypting are virtual sectors of their own encrypted virtual file system, which actually has a very FAT-like structure, a FAT file system internally.  And so those sectors will always be multiples of 64 so you don't have block padding problems and so forth.  So, and it uses a 64-bit block and 20 iterations of a customized version of RC5.  So again, none of this is off the shelf.  This was designed for a purpose.  So what happens is... 



LEO:  How did Symantec find out about this?  And it's been around, they say, for years, like five or six years. 



STEVE:  Well, yeah.  So, and that's another creepy thing.  They encountered what they think is Version 2 in 2013.  So sometime last year they encountered it.  But when they found it, there were some similarities with other patterns they have long been collecting, which allowed them to then go back in time since they've been gathering stuff.  And they realized it's been around - and, I mean, I'm getting goose bumps - it's been around, never before detected, as early as 2008. 



LEO:  Wow. 



STEVE:  And maybe earlier.  So the farthest back they found, once they saw and recognized something in what they're calling v2, then pattern analysis was able to roll back in their logs as far as 2008 and say, whoa, we didn't know what this was then, but we now recognize it from similarities, and we'll call that Version 1 just because we have to call it something.  And in fact it's that which caused them to bump what they had just found in 2013 to v2.  They don't know there weren't intermediate things.  But one thing that's interesting is that in 2011 it was removed.  It was, in one moment, it disappeared across the entire Internet. 



LEO:  So it also has a self-destruct capability. 



STEVE:  Yes.  And where they found remaining little bits is where something was broken that prevented its deliberate extraction.  A machine had been, like, taken off the 'Net and never connected to the 'Net, and they found fragments of it there, where it wasn't able to - it couldn't receive the "remove yourself" instructions.  So something happened in 2011 that caused the controllers to suck it back in, essentially, to deliberately extract it... 



LEO:  Amazing. 



STEVE:  ...from all the little nooks and crannies.  Oh, I mean, this, it just is science fiction.  This is just wonderful. 



LEO:  Yeah, wow. 



STEVE:  And then it came back.  In 2013 it returned, and those pie charts are where it is now, where Symantec has discovered it.  And what's really interesting is the one, the other pie chart, not the geographical distribution, but there is a chart by sort of like application domain.  For example, it is very modular, and there's a wide range of modules which have been found.  For example, one of them infiltrates hotel reservation records and exfiltrates who is in what hotel when, almost as if to figure out, again, this is - I spent some time with Padre yesterday on This Week in Enterprise Tech, talking about this.  And I drew the analogy of how, with cell phones, we've talked about how powerful cell phone metadata is because, even though you may not have the conversations, you may never get access to the conversations, the idea of knitting together who is talking to whom when, if you can build that connectivity graph, that's hugely powerful. 



Well, similarly, if you're operating on a nation-state level, you care about what other actors in other countries are moving around the globe, where there's - there's also an airline reservations infiltration package.  So where people are flying and where they're staying, especially if you want to then send an ops team in to get the adjoining hotel room and set up listening equipment.  I mean, this is what we found, essentially, is like... 



LEO:  So it sounds like, based on the locations this has been uncovered in, and the industries, that it is a highly targeted attack.  It doesn't spread as a virus would normally spread. 



STEVE:  Correct. 



LEO:  It would have to be infected.  In fact, Symantec says they don't even have a copy of the dropper, the thing that starts the process. 



STEVE:  Correct.  And in fact they - nor do they have any good sense for what the infection vector is.  In one machine, one infected machine's log that they happened to find, they found a log that implied that an unknown vulnerability in Yahoo's Instant Messenger was used as the means for getting this into that particular machine.  But that's, like, all they know.  There's no, like, readily discoverable means for this thing getting in.  So again... 



LEO:  It seems likely that there's a variety of vectors, though; right?  They wouldn't just be Yahoo! Messenger.  They would email. 



STEVE:  Correct. 



LEO:  They'd do spearphishing.  There's, you know, USB keys.  There's a variety of ways. 



STEVE:  But those examples are all too common, Leo.  My guess is that they are using undetected vulnerabilities. 



LEO:  That would make sense because an email would leave a trace. 



STEVE:  Right. 



LEO:  A USB key would be detectable and traceable. 



STEVE:  This thing is way too stealthy.  Those things that we're normally talking about, that's your common hacker stuff.  These guys are operating on an entirely different level where, I mean, you know, we've heard that Microsoft tells the NSA about problems in Windows before they're published.  Right?  I mean, we know that, that the government receives early notification of vulnerabilities in Windows.  And note that this is only Windows.  This is entirely Windows-specific.  This has nothing to do with Mac or Linux, period.  This is a Windows-targeted technology.  Okay, so... 



LEO:  And it makes sense that it would be not merely defensive, for defensive reasons Microsoft would tell the government.  There might be an offensive reason they'd like to know this ahead of time. 



STEVE:  They would love... 



LEO:  By the way, 2008 you'd make it for Windows.  Maybe in 2014 you'd cross some other platforms, maybe get it in an Android, where there are far more installations; right?  We don't know. 



STEVE:  Right, right.  And where Android is inherently a location-based system.  You have a mobile device where - and if you can infiltrate somebody's Android phone - it's funny, well, no, I won't go down that rat hole.  But I'm aware of an instance where a conference was held where there were Chinese delegations, and Australians had their Android phones infiltrated during that conference, was like, oh, wow.  I mean, in Australia, not in China.  So they bring their own ops people with them. 



LEO:  So what's really interesting is that the dropper is the only unencrypted part of this.  It then decrypts blobs and adds capabilities. 



STEVE:  What it does, yes, in several stages.  So all of the payload material which the dropper probably downloads once it - so the dropper comes in unencrypted.  So something gets itself into the machine.  It probably fetches pre-encrypted blobs which it tucks into unusual places.  The registry is a place where you've got flags and switches and parameters; right?  But it is a flexible tree-structured database.  Well, I mean, and you can store binary data in the registry.  So they take components of this system and stick them in the registry, just store them, not, I mean, like abusing what the registry was meant for.  But it's already big, and it's big and complex, and nobody tends to look in there.  And besides, this is encrypted.  So the dropper tucks things into registry keys. 



And in Symantec's document - anyone who's interested in this should take the time to just - you can just google "Regin," R-E-G-I-N.  Or it's the second link in my show notes, and I just tweeted the link to the show notes.  And of course you can get them from GRC - to take a look.  Because there are... 



LEO:  It's amazing.  It's just incredible. 



STEVE:  Yeah.  There are details I'm skipping.  But, for example, Symantec enumerates the key, the registry keys which, if present, are probably an indication of this infection.  And their own software, of course, Symantec's own security scanning stuff is now fully up to date and up to speed, as you would expect on this, and protecting their own customers from... 



LEO:  But what are they looking for?  If they don't have the dropper, they're not looking for the dropper, they're looking for the thing that the dropper puts on the system. 



STEVE:  Correct.  And so they know which keys it uses in order to... 



LEO:  Got it, they're looking for the reg keys, got it.  Of course, yeah. 



STEVE:  Right.  The other thing it does is NTFS is a much more flexible file system than we normally see.  For example, you can use a colon in a filename to create another stream.  In the same sense that a stream is the file that is at that name, if you put a :1 after a filename, and you can, it creates an entirely separate stream which you normally never see.  Well, there's also something known as "extended attributes" with NTFS.  And they can be big.  And so this is another place this dropper stores encrypted pieces of Regin, is in NTFS file attributes.  And finally, it also stores blobs, encrypted blobs, in the slack at the end of the drive, after the last partition. 



LEO:  Wow. 



STEVE:  For historical reasons, partitions are always a multiple of a cylinder size.  And cylinders, which have now become an abstraction, a cylinder is the number of heads times the number of sectors per head, is the old terminology for a cylinder on a hard drive.  Well, heads are now typically 254, and sectors are 63 because that's the maximum number of sectors you can have.  So 254 times 63 is the cylinder, sort of the virtual cylinder size that you will have today.  And that's a lot of sectors.  But no drive cares about being a certain exact multiple of that.  The drives are just whatever they happen to be.  But the partition has to end on an even multiple of that, which means up from zero to that many sectors may, because that would not be quite a full cylinder, there's that much possible slack at the end of the drive. 



SpinRite, for example, knows that, and deliberately goes out and does its job out there.  So for what it's worth, SpinRite is helping to recover this, if it ever had a read problem.  That is, SpinRite's aware of this slack space and also does its work out there.  But nothing is normally used out there because it's extra file system.  It's outside the file system.  This thing can also put components out there.  That's another - it's one of the three places:  registry, NTFS attributes, and file system slack at the very, very far extent of the drive.  And all of that is encrypted. 



So what then happens is the dropper also puts some registry entries, which cause the installation of a kernel driver, which is the Stage 2, if you call dropper - I think they call dropper Stage 0, actually.  So that's Stage 1 that gets loaded at boot time.  Then it decrypts Stage 2, and all of this content is coming - none of this lives in the file system.  None of this is where you would normally scan for it or see it.  It's all tucked away, all custom encrypted.  And then that Stage 2 loads Stage 3.  It decrypts.  Then it finally gets going and interesting with Stage 4.  Oh, and one of those earlier stages also installs rootkit hooks, which prevents any, as they called it, code attributes - there was a better word that they used.  Not vestiges.  I have it in my notes somewhere.  Anyway... 



LEO:  Vestigital? 



STEVE:  You know, debris. 



LEO:  Leftovers. 



STEVE:  There's no way, because this is rootkit technology, there's no way, once Stage 1 has executed, to sense that there's any of this code running in the system. 



LEO:  Wow.  Wow, wow, wow. 



STEVE:  So it does all the low-level rootkit hooks to go to stealth itself.  So, finally, it gets into the framework functions.  And they call it a framework because it is essentially a series of general-purpose modules that function like operating system functions that are available to be called by other custom modules.  So, for example, Regin contains its own compression and decompression, essentially API calls; it has them for encryption and decryption; what they call the EVFS, the Encrypted Virtual File System; its own container manager; log management; loaders; network operations; then command-and-control by TCP, by UDP, and some sort of a C&C oversight processor. 



The payloads which this thing brings include the ability to sniff low-level network traffic; to exfiltrate data through a whole range of communication channels, not only TCP and UDP, but also ICMP.  So when it looks like it's sending a ping, the ping's payload is a compressed and encrypted payload going out looking like an innocent, hey, I'm an ICMP ping.  If you receive this, send back an echo.  But it's certainly not that.  But neither is it anything you can recognize. 



And they even go so far, Leo, as to use HTTP with encrypted cookie values.  So you'll see, I mean, so somebody, a network engineer, trained, could be looking at a Wireshark packet capture of a standard web query where he sees in the headers a set cookie header with an innocent-looking name, and it uses common names, and the value looks like gibberish.  Well, values already, innocent values are gibberish.  You know, they're just nonces.  They're often, you know, we're used to sort of just kind of going, okay, yeah, whatever. 



But in fact, if your system is infected with this, this is your password keystrokes being exfiltrated after they were compressed and encrypted in the value of an HTTP header cookie, and you don't know it because they all kind of look the same.  So this is able to gather information about your computer, running processes, installed applications, all of that stuff.  It's got keystroke logging to steal passwords.  It's able to crawl through the file system and detect and recover previously deleted files and exfiltrate those, if it wants them. 



LEO:  Oh, how useful is that?  Maybe I'd buy a copy. 



STEVE:  It's also able to... 



LEO:  You put SpinRite in the thing, you've got something. 



STEVE:  ...capture your screen and to take over your mouse and execute mouse point-and-click activities.  And then... 





LEO:  Execute. 



STEVE:  Yes. 



LEO:  Not merely monitor, but do it. 



STEVE:  Yes, take over your mouse and move it around and click things that it needs to do, probably when the web cam that's monitoring you sees that your back is turned.  So in terms of when they talk about the specific expertise required, the best example is that they found a payload which has probably been inserted into foreign nations' cellular network base stations because they found something that is able to sniff and gather the admin traffic from cellular base station controllers.  So, again, to do that you need to have really application-specific knowledge.  There's also IIS server web traffic monitoring agent and a parser for Exchange databases.  So they get this thing into a machine that has Exchange installed, and then they have their own parser of the database to go through and extract things.  So, you know, just amazing. 



So we know that, well, we know that it is highly complex, that it is general purpose.  It's been around for at least six years, since 2008.  It had a period of time there was no activity during 2012.  So it was deliberately, not just shut down, not just went to sleep, but it was extracted.  It was pulled back across the Internet at some time in 2011 and then reappeared in 2013, altered.  It was changed.  So Symantec does see changes from the earlier samples that they were then able to detect after they found the newer ones.  They knew what to look for, which is how they knew that it existed back then.  So it is in v2 now and, I mean, and active.  It was found, you know, these charts are from discovering it on the Internet, actively in use, right now. 



LEO:  And it's credible; right?  I mean, Symantec - has anybody confirmed the sighting, or is it all - yeah. 



STEVE:  Yes, actually Kaspersky has it.  Samples are now being posted to Pastebin.  Our friend Simon Zerafa just this morning was tweeting me links to more and more of these bits and pieces showing up. 



LEO:  And of course I've seen speculation that it's either the NSA or GCHQ, the British NSA.  I mean, it's, I think, telling that neither Britain nor the U.S. have any incidences of infection. 



STEVE:  And Padre had the tidbit that he had found, which I didn't see, but I certainly know that he found it, that it was originally authored in English. 



LEO:  Ah. 



STEVE:  You can typically tell what the language of authorship is in these things.  And, yes, so English was the language that the developer spoke.  Yikes. 



LEO:  Well, I mean, it's not, you know, to be honest, you're not surprised; are you? 



STEVE:  But isn't it cool?  I mean, I just think, I mean, it's one thing to say... 



LEO:  It's straight out of "Homeland."  Right?  I mean... 



STEVE:  It is.  It's one thing to say, yeah, they probably have something. 



LEO:  You can see Saul pulling the strings. 



STEVE:  We found it. 



LEO:  Yeah. 



STEVE:  Yeah, actually Saul's not pulling anything.  Have you been watching "Homeland"? 



LEO:  No, don't spoil - you know what?  I'm, okay, I'm a little miffed.  Not at you.  But I'm watching Showtime because I love "Homeland," and I haven't... 



STEVE:  Oh my god, Leo. 



LEO:  ...started the new season.  And, yeah, well, but their promos are showing stuff. 



STEVE:  Oh, you're right. 



LEO:  And it pisses me off because I didn't know anything.  All right.  I'm one of them whiney spoiler people now.  But... 



STEVE:  Well, no, I... 



LEO:  They don't have to - their promos have to - they're saying, "You won't believe what's happening."  And I guess I'm going to have to start watching from the beginning because clearly everything's going to be revealed before it's over. 



STEVE:  Ooh.  It's so good. 



LEO:  But don't you, I mean, I think at this point you... 



STEVE:  Actually, you have two weeks because they're now in hiatus. 



LEO:  It's season finale? 



STEVE:  No, no, they're on hiatus.  They left it at an amazing cliffhanger on Sunday.  So now would be a great time to catch up.  You've got the holidays and everything.  It's like, oh.  But Leo, believe me, it's so good. 



LEO:  I loved the first two seasons.  I think it's a great show. 



STEVE:  Wait.  Whoa.  So you didn't see the third season? 



LEO:  Wait a minute.  Maybe I did. 



STEVE:  I think we're in 4 now. 



LEO:  We're in 4, okay, yeah.  Yeah, yeah, they dragged out that first plot for three seasons, that's right.  Now they have a new story. 



STEVE:  Oh, it's good.  It's good. 



LEO:  Okay.  But I'm telling you, if you're following the NSA revelations by Snowden, if you're even - if you're watching shows like "Homeland," this is not - of course the U.S. spy agencies, we've certainly got the people with the brains to write something like this.  It's exactly what you'd want to do.  If you were going to - if you, Steve Gibson, were going to sit down and write a program, some malware that would be useful in espionage, this is exactly how you would - it'd be hard to track, hard to trace. 



STEVE:  As I was reading through this, I had already planned when I was preparing the show to directly address the creators and say, "Nice going." 



LEO:  And I don't think these people are... 



STEVE:  I mean, this is what I would create. 



LEO:  It's not your garden - I mean, obviously it's a state doing this. 



STEVE:  Yes. 



LEO:  But even the people writing it are not your garden-variety hackers.  They're not attackers.  They're probably Ph.D. graduate-level computer scientists because they're doing all the - I'm sure it's, I mean, we haven't seen the code, but I'm sure it's nicely coded.  It's written well.  It's got lots of comments.  And I really like the idea of, look, if you're going to make something that's not traceable, you take advantage of exploits.  You don't do spearphishing attacks because an exploit can be done silently, without anybody knowing anything.  You can get in there.  You can leave the - and then the brilliant thing, the dropper... 



STEVE:  Yes, it self-destructs. 



LEO:  It self-destructs, and these... 



STEVE:  And there's no evidence of how it got in. 



LEO:  Yeah.  I mean, it's exactly what you would do if you were thinking about this.  And I'm sure Mark Russinovich probably wrote it in one of his novels.  This is exactly what you would do. 



STEVE:  Yeah.  And you have something which - the other very telling thing is that it was clearly designed for long-term penetration, that is, this is a huge investment. 



LEO:  Right. 



STEVE:  So they didn't want it to be discovered.  They're not happy right now that Symantec has just, you know, is publishing keys. 



LEO:  Maybe, maybe not. 



STEVE:  Yeah?  Well, they may already be on to, you know, Version 3. 



LEO:  I'm sure they've moved on.  The 2008, my god, we're much better than this. 



STEVE:  Version 3.0. 



LEO:  That's the old one.  That's the Casio Smartwatch.  We've gotten much farther than that.  I'm sure they have.  And, you know, if they've really done their job right, Symantec will never know about what they're using today.  But of course the thing that always scares me is that these are powerful weapons that could easily be misused, whether by somebody in government or somebody not in government who just gets a hold of it, and could very easily be misused.  And it shows you why really, if you're concerned about privacy, forget about it.  I mean, you check into a hotel, they know.  You use your phone, they know. You get on an airplane, they know.  Right? 



STEVE:  Yeah.  Yeah. 



LEO:  Do you want take a break here?  Would this be a good time to do it? 



STEVE:  Good, yeah. 



LEO:  Yeah.  Why not? 



STEVE:  We have a little errata, some miscellaneous stuff, and then we'll get into... 



LEO:  Crypto. 



STEVE:  ...Let's Encrypt. 



LEO:  Have good reason to encrypt. 



STEVE:  Amen. 



LEO:  Although... 



STEVE:  That won't help you. 



LEO:  Doesn't matter. 



STEVE:  No. 



LEO:  Once you're owned, you're owned.  It doesn't really matter if you encrypt. 



STEVE:  They're happy to have their outgoing ICMP encrypted.  Eh, thank you very much. 



LEO:  They'll encrypt. 



STEVE:  It keeps anybody else from getting it. 



LEO:  Yeah.  But if you think about it, I mean, we're spending all this time using PGP on our email and stuff.  If they've got something on your machine, you can do whatever you want.  They can read your keystrokes. 



STEVE:  Yeah, well, they have Windows on our machines. 



LEO:  They're looking at you.  Hi.  I'm waving back.  Hi. 



STEVE:  I was chatting with a reporter from Wired magazine yesterday about TrueCrypt, and I made the comment that, you know, there was some story that went by, and I didn't catch it, that indicated that BitLocker's strength may have been recently reduced.  I don't remember what that was.  But I made the point that, you know, we just basically accept whatever we're being sent every month from Microsoft, assuming that it's helping us.  Well, that's a big assumption. 



LEO:  Yeah.  But again, it doesn't matter because, if you can see it and you can read it on your computer, and they have spearphished you, they can see it and read it, too.  You can use SSL and use PGP and use BitLocker, it doesn't matter because, as long as you can read it, they can read it.  Oh, well.  All these people, you know, because this is - this is what gets me is people are so, oh, you know, I'm so worried, I'm going to be very careful and never use Google.  Google?  What are you worried about Google for?  Why do you care about Google?  They don't need to put anything in Google's service.  They just put it in your computer.  I got an email about a Kickstarter project that you might be interested in. 



STEVE:  Oh. 



LEO:  We know your love of coffee.  Do you like French press coffee? 



STEVE:  I've had it, yeah.  It's good, yeah.  I mean, basically because it means it's going to be fresh, and it's not sitting around on a burner. 



LEO:  Yeah.  Yeah.  This guy, it's called the ESPRO, or Espro Press.  He's already raised $83,000 on his Kickstarter.  Oh, I guess it's over.  I thought he had more time on it.  But this looks really good.  I'm going to get you one.  This will be your holiday gift.  The idea is it's like a travel French press. 



STEVE:  Wow. 



LEO:  Yeah, that you carry with you.  And then it has two-stage micro filter and all of this stuff.  And then - it makes about four cups of coffee, and then it's in a vacuum insulated container.  So it just... 



STEVE:  Very nice, so it keeps it warm. 



LEO:  Isn't that good?  You just - it's like your thermos has a French press built into it. 



STEVE:  Yeah. 



LEO:  Did you ever get that cup?  The thermal cup? 



STEVE:  No.  But, boy, they're communicating a lot.  Their roof blew off of their work shed, and then they.... 



LEO:  [Whining sounds] 



STEVE:  I know, I know.  It's like, I'm still hoping. 



LEO:  You know you're in trouble when you start getting a lot of messages from a Kickstarter project. 



STEVE:  Yeah, well, and, I mean, I understand.  By its nature, these are generally non-professionals. 



LEO:  They've never made a product, right. 



STEVE:  Yes.  And I've made a bunch, and I understand.  So it's like, yeah, okay, you know?  Yeah, the Temperfect Mug. 



LEO:  They had almost 5,000 backers.  They raised more than a quarter of a million dollars. 



STEVE:  Yeah, we'll hope.  I mean, I'm still getting email, so, you know... 



LEO:  It's been there since January 1st. 



STEVE:  When there's email - yeah. 



LEO:  You talked me into buying this.  I'm holding you... 



STEVE:  Yeah, that was - it was a big, it was a heavy lift to get you to click, yes. 



LEO:  [Laughing]  Steve says, "Temperfect mug," I'll take it. 



STEVE:  Okay.  How many phones do you have within the span of your two arms at this moment? 



LEO:  Oh, one... 



STEVE:  And I didn't talk you into any of those. 



LEO:  ...two, three, four.  But this is an unusual day. 



STEVE:  Oh, uh-huh. 



LEO:  I actually have five phones with me right now. 



STEVE:  Yeah, okay. 



LEO:  This one's a Chinese clone of the iPhone... 



STEVE:  Oh, I saw that.  You were showing it to someone on a different podcast.  I was amazed. 



LEO:  I have to be careful because there's some Apple engineers in this studio right now.  So I have to be careful. 



STEVE:  Uh-oh.  Well, maybe they can get some tips. 



LEO:  I should give it to them to bring back to the mothership. 



STEVE:  Oh, I'm sure they've seen that. 



LEO:  Yeah.  Oh, they have them all.  They have a museum of these things. 



STEVE:  Jobs is literally rolling over in his grave. 



LEO:  No, he's not, no. 



STEVE:  Well, no. 



LEO:  But that's a nice fake. 



STEVE:  Look, yeah, I know.  And you said way cheaper than the thousands of... 



LEO:  $111.  $111.  But you know why?  It's running Android.  So you don't have to feel threatened. 



STEVE:  Yeah. 



LEO:  They're laughing.  They're laughing.  They don't care. 



STEVE:  They're not threatened. 



LEO:  They're not threatened.  Anyway, continue on. 



STEVE:  So I got what kind of constitutes a piece of errata from Peter McDonald.  I only know that because it's PeterMcDonald.co.uk.  So he's enough into this stuff that he's got his own domain name. 



LEO:  Whoo. 



STEVE:  On his own name, which is very cool.  Anyway, he wrote:  "I think you made a mistake when describing the Schannel issue."  And this is referring to Episode 481.  "You mentioned that sites running Apache and Nginx would be safe.  However. surely this is not correct if they are running on Windows.  Granted, if they are using Apache or Nginx on Linux, they would be safe."  And he's absolutely right. 



So I just wanted to thank you, Peter, for the clarification.  Of course, I was sort of conflating Apache-ness and Nginx with Linux, ignoring the fact that, if those two services or either of those server platforms were running on Windows, then they would be running atop the Windows Schannel and then suffer from the security issue that we all ran around and patched ourselves for very quickly.  So good clarification, Peter, thank you. 



I saw "Citizenfour" last week. 



LEO:  Is that a movie?  What is that?  I don't - that doesn't ring a bell. 



STEVE:  You haven't seen it? 



LEO:  I didn't even hear about it.  What is it? 



STEVE:  Oh, my goodness.  Okay.  It is... 



LEO:  Oh, it's the Snowden movie. 



STEVE:  Yes, yes, yes, yes, yes. 



LEO:  Ah. 



STEVE:  Really worthwhile.  So if listeners are interested in the Edward Snowden story, essentially what this tells, it's in documentary format, and it's that the guys that Snowden was contacting had the foresight to have a camera rolling from the beginning.  So this tells the entire story, sort of behind the scenes, a lot that we've never seen and heard before.  And it was really interesting.  I thought it was absolutely worthwhile.  So I just wanted to say - I had assumed that you had seen it because... 



LEO:  No spoilers.  Does he get caught?  I'm just kidding.  I'm just kidding. 



STEVE:  I know.  So we sort of see everything behind the scenes, including the interview - we see them setting up for the interview that we did see. 



LEO:  So this is a documentary.  I mean, that's not an actor.  That's not Edward Norton playing Edward Snowden.  That's Edward Snowden. 



STEVE:  Yeah.  Oh, yeah.  So this is - you get to see much more of him and some insight into his thinking.  And, I mean, it is the interviews by Laura and Glenn Greenwald of Edward, where they're, like, you see them, the dawning of their appreciation for the immensity of what he has done.  I mean, and you see Glenn's, like, looking through the documents, and his jaw dropping open, and then him asking Edward if this is really what this appears to be and so forth. 



So here's my takeaway, though.  As I was coming out of the theater, I realized I had an appreciation that I didn't have before and that I don't think you have.  Okay.  So one of the things that I have noticed is, sort of as I become more politically aware, is that an inherent characteristic of democracy, by its definition of majority voting, majority rule, is it's easy for a majority to vote away rights of any minority.  So, for example, gay marriage is an example.  Gay people are a minority.  It's easy for a majority that doesn't care to say, eh, yeah, we'd just as soon you couldn't get married.  Or a bunch of white guys sitting around deciding that they don't think a woman's right to choose what she does is important, so we're going to arrange for that to be minimized.  Or, on the flipside, people who don't care about guns restricting the rights of those who do. 



So my point is that this is inherent in a democracy, that the interests of a minority should be, I mean, they deserve respect, I think.  And it's easy to forget that.  Well, I'm not a person who has a particular need for privacy.  I mean, my text messages are basically, you know, little sweet nothings to Jenny and when I'm going to meet up with my friends for various meals.  And my email is supremely boring.  I really don't care.  And I pretty much know you sort of feel the same.  But the appreciation that I got somehow from watching this movie was that I need to respect the fact that there are other people not like me; that people can want privacy, have a right to it for its own sake; and that this argument that we hear, oh, well, if you have nothing to hide, then why do you care, if you're not doing anything wrong and you have nothing to hide, why do you care, well, that's wrong.  I mean, that's a fundamental mistake. 



And certainly we know that there are people who have a legitimate need for communications secrecy.  We know that there are, I mean, that we can easily relate to, people who are working for human rights in oppressive, non-democratic governments, for example, or in corporations where there's extreme espionage pressure against their secrets, they have an absolutely legitimate right to keep those secrets protected.  So anyway, I felt a much stronger sense of understanding that privacy is absolutely, I mean, I feel more like I understand the EFF's position, which to me sometimes seems over the top.  It doesn't so much anymore.  So I thought that was - I'm glad I saw it, and I'm glad I have a better sense for that. 



LEO:  It's also, and I think this is a really important thing, is that when - you may not have anything to hide.  But if a government wants to put together a case against you, and they have access to information... 



STEVE:  Retrospectively. 



LEO:  ...it's not hard, it's not hard to fabricate a case against somebody who is an enemy of the state.  Remember that for a long time Martin Luther King was viewed as an enemy of the state, and J. Edgar Hoover collected lots of information about him, and there's a massive dossier.  I mean, this is not - this is in our recent history.  So you may have nothing to hide, you think, but that doesn't mean that you're invulnerable to this kind of government pursuit.  And so that's another big issue. 



STEVE:  And I've been in business all my life.  And there have been situations where there's been contractual conflicts, when I've been deposed by an attorney who wanted to, from my perspective, misconstrue the past.  And it's a weird feeling facing somebody with a stenographer who's asking questions with a clear intent to bend the truth.  And you find yourself, I mean, you know, I know what happened.  And yet I'm on the defense for some reason.  Like how did that happen, that I'm having to defend no wrongdoing at all?  But that's the nature of the world. 



LEO:  I can see a scenario where, to be honest, the NSA decides that you are a threat to national security because you reveal information about their methodologies and says, you know, we've really got to get that Gibson and anybody else, Brian Krebs, we've got to get these guys out of the public eye.  Maybe a short stint at Guantanamo would help with that.  I mean, you know, we're lucky because I think we do, we still live in a free state, and we can express ourselves, and we are somewhat protected.  But you want to watch that slippery slope. 



STEVE:  Yeah.  One other little bit of miscellany, and this was just - this is more whimsical than anything.  A Utah legislator has put forth a bill, which is working its way through the Utah legislature, to cut off the supply of the NSA's water... 



LEO:  Oh, we're definitely putting that guy in Guantanamo. 



STEVE:  ...to their super secret new installation. 



LEO:  What? 



STEVE:  I'm not kidding you. 



LEO:  That's one way to go after them. 



STEVE:  Oh, my goodness.  Apparently in one month they used - and I had it in the notes, and it must not have made it into the PDF.  So if you can pull up that Ars Technica story... 



LEO:  I will, yeah. 



STEVE:  ...that I linked to because I had pulled more out.  So, okay.  So earlier this year... 



LEO:  6.2 million gallons of water in a month. 



STEVE:  Yes.  The Salt Lake City Tribune published data showing that since July 2013 the facility used 6.2 million gallons of water in one month. 



LEO:  They have a $29,000 a month water bill.  Water bill. 



STEVE:  And in October of 2013 The Wall Street Journal reported that they had experienced 10 electrical meltdowns in the past 13 months for unknown reasons. 



LEO:  Wow.  So the water is for cooling; right? 



STEVE:  Yeah.  The water - but we couldn't figure out why their water usage varied so much.  And it turns out that they're having some sort of horrible electrical problems there.  So they're just unable to keep it cool or to keep it up.  There have been, like, huge meltdowns and fires of unknown nature. 



LEO:  The facility draws 65 megawatts of power. 



STEVE:  Enough to run a town of 20,000 people. 



LEO:  I have a lot of hard drives. 



STEVE:  Oh, baby, yeah. 



LEO:  The town that they're in, Bluffdale, is 8,000 people. 



STEVE:  Yeah.  And so, yeah, so basically all the electricity goes off to the left.  It's like... 



LEO:  So does this guy, like... 



STEVE:  I don't really understand what his deal is.  I didn't go... 



LEO:  There's a bill.  He's put a bill in front of the Utah State Legislature. 



STEVE:  Yes.  Legislation.  The idea is that the bill prevents interstate or operating with federal agencies that are collecting consumer data.  And so that sounds innocuous, but that means that providing them with water would constitute interacting with them or supporting federal data collection pursuant to this bill.  And so, oops, sorry, we've got to turn off your water because we can't work with you. 



LEO:  This is the website of the assemblyman who has proposed the bill, Marc Roberts.  Right on the front there it says, "Life, liberty, and property do not exist because men have made laws.  On the contrary, it was the fact that life, liberty, and property existed beforehand that caused men to make laws in the first place."  I think it's a bad French translation.  And then he's standing there raising his hands to the clouds.  Interesting. 



STEVE:  Hmm, yeah.  Anyway, I just thought that was a bit whimsical and fun.  I did get a nice note from an Andreas Gogstad - I'm hoping I said that right - in Sandefjord, Norway.  Anyway, sorry, Andreas, if I mangled those.  Just yesterday he wrote, on the 24th, he said:  "A user came in with a totally" - I don't know how, so it came in, he must have some sort of a facility - "with a totally unreadable hard drive on a private PC." 



He says:  "I took the opportunity to purchase SpinRite as payment for the recovery job after hearing about it many times on your podcast.  I ran a Level 2 scan despite warnings from SpinRite about an 'invalid partition for drive size,' since there wasn't much else to do, and an LBA setting wasn't an option in the BIOS.  I was then able to mount the drive on a Linux machine, which I did in Read Only mode for safety, and recover the photos this client needed for her building permit application.  Could you explain the partition message, and what the best solution in those cases would be?" 



And so, first of all, thank you, Andreas, for sharing your successful recovery of - apparently this was very important information on, as he said, a totally unreadable hard drive.  SpinRite fixed it, brought it back to life, made it readable again.  SpinRite is very cautious in its operation.  And so what it does is it looks at what the BIOS is telling it about the drive, compares it to what the partition table is telling it about the drive, and looks at what the drive is telling it about itself.  And if those things don't mesh up, it will say, uh, you know, something seems wrong here. 



What happened was he had moved the drive from one machine to the other, so it was then being seen by a different BIOS.  And so that was where this matchup problem came.  The warning is just to be, like, make sure you want to do this.  And it's normally safe to push through it.  That will completely go away in 6.1 because we're no longer using the BIOS, and we don't care what the BIOS thinks.  So that will be one of the nice things happening with the next release of SpinRite.  But until then, it's just a function of a mismatch caused by moving the drive to a different motherboard with a different BIOS.  SpinRite says, uh, we can proceed, but just want to let you know there's some reason that things are confused.  And as we see, it works anyway. 



LEO:  You're like the Honey Badger of file recovery tools.  We don't care what the BIOS thinks.  SpinRite don't have to care. 



STEVE:  Exactly. 



LEO:  Steve Gibson.  Leo Laporte.  What is the EFF program called?  They have a good name for it. 



STEVE:  It's called Let's Encrypt. 



LEO:  That's a good name.  I thought there was something else, but maybe not.  All right. 



STEVE:  So the idea is, and the reason the EFF is a principal actor here, along with Mozilla and Cisco and Akamai and IdenTrust and some guys at the University of Michigan, is that we're always talking about the idea that more of the Internet should be encrypted.  But there are several barriers, practical barriers to that being done.  And it's a matter of tradeoff.  I mean, I'm using HTTPS at GRC, and have been forever, originally because that was the way for ShieldsUP! to get the correct IP of the user.  When users who wanted to check their ports were behind an ISP with a caching proxy, GRC would see the web queries coming from the proxy.  So if I tested those ports, I'd be testing the ports of the proxy server, not the user. 



But by establishing an SSL connection, since the proxy can't proxy a secure tunnel, exactly as you were describing with proXPN, I would then see the queries coming from the actual users' IP.  So there was really no other purpose I had for security.  And then I later, years later, added eCommerce, and so I did need to be able to do secure forms to allow our SpinRite customers to be able to put their credit card information in securely.  And then, of course, just because being a hundred percent secure, actually it was shortly after the whole HTTPS Everywhere effort, where it was possible to tell browsers never to not accept - wait, never - to only accept... 



LEO:  Yeah, never to not accept.  That's good.  A double negative, but okay. 



STEVE:  To only accept secure connections.  I said, okay, fine, let's - I want to do that.  So now GRC is completely secure.  But you could argue that a blog has no - okay.  If it's really free and easy to have security, yeah. 



LEO:  Why not? 



STEVE:  Why not?  But if it, first of all, if there's lots of hoops you have to jump over to configure the server, and if you have to pay hundreds of dollars a year, then that's crazy.  Or even if they're cheap certificates, and you can get them for four or five, it's still, like, well, okay, what about when they expire and suddenly people are sending me email saying that they're coming to my server and they're getting warnings?  It's like, the point is, if there's really a low need, a low level of need, then just all of the annoyance of doing it keeps it from happening.  So the EFF, along with these other companies, are saying, how can we make this dead simple?  How can we make this one click? 



LEO:  There's more friction, too, not merely the cost, but just the annoyance and difficulty of installing it.  We have some nice certs from DigiCert, but we haven't installed them yet because it's a nontrivial thing to do.  It's work. 



STEVE:  It takes, yes, it takes learning something about your server that is - it's funny because the example that I use is that, with certs dying very two or three years, that's just long enough for me to have forgotten how to do it all.  And then I have to go, okay, you know, it's time, scratch my head and figure it out again.  So these guys have arranged to automate, the Let's Encrypt initiative automates this process. 



LEO:  Yay. 



STEVE:  They put - yes.  And I've now read the entire specification front to back, 36-page RFC, and they've nailed it.  They absolutely got it right.  But it is crucial to understand what it is that you get for free.  It is absolutely the case that you get for free what many certificate authorities are now charging for.  So in that sense it is absolutely true competition for what all certificate authorities are currently making some money selling.  It is not at all competitive with what all certificate authorities should be charging money for, meaning that it is - okay. 



And so what that is:  Remember that there are broadly three categories of certificate.  There's the so-called domain validation certificate, a DV, which its only assertion is that the certificate is bound to this domain, that is, the certificate is just a certificate for the domain.  It doesn't assert anything about the ownership of the domain.  So the certificate will make a claim about the ownership.  So even a domain validation certificate, it'll have a common name and an organization associated with it.  It's important to understand that this doesn't validate that, that is, a domain validation cert is really, it's just saying - it's like the minimum required to establish an SSL/TLS connection to a remote website. 



The next level up fixes, sort of at the weakest level, the fact that the domain validation isn't really making an assertion about the organization.  That type of certificate is called an OV, an organization validation.  The problem is that there's no visible indication of which is which.  And so one of the things that I do wish we had, and I don't know how we could get it in practical terms, is three levels of indication in the web browser where we currently only have two.  We currently have either EV, which is the Cadillac, the Extended Validation certificate, or not EV.  And in the grouping of not EV is both DV and OV.  That is, essentially nothing but the validation of the domain name and really not the organization, or the organization validation, which would be nice to somehow be able to assert because that requires - that's not what this system does. 



The whole Let's Encrypt thing is automated, and it is free specifically because it can be, because you're able to cryptographically validate the domain control with full automation.  You cannot validate organization, that there's a corporate entity, without involving people.  And so that won't and can't be free.  That's what you need the CA for.  Or, going further, if you want Extended Validation and an indication in the URL, the green coloration or glow or whatever it is, depending upon what browser you're using, then that takes extra work.  Okay. 



So we need to understand that all this is is that weakest form of validation.  And CAs are probably going to lose that business to the degree and as this takes hold.  And, frankly, that's a big business because Extended Validation certs are still the minority.  But this is sort of inevitable because they actually weren't doing much to get any money for just doing a domain validation.  I mean, so little, in fact, that it could be completely automated with the so-called ACME protocol, A-C-M-E... 



LEO:  That's it.  That's the name I was looking - that's the funny name. 



STEVE:  Yes, Automated Certificate something.  Oh, Certificate Management Environment.  So you could tell that the acronym came first, and they had to reverse-engineer... 



LEO:  They call those retronyms, yeah, yeah. 



STEVE:  Retronyms, yeah.  It's like, okay.  We know what you meant.  So, okay.  So how does this work?  There is an agent, some software which will be written by some pro Let's Encrypt people for the various platforms.  I'm sure that Linux will have the first one.  And the example on the EFF site and their video is of a Linux install where basically two command lines act to get something, to get the package from the repository, and then install.  And this thing runs. 



The idea is that it contains the knowledge of how to configure the server if it had a certificate.  It has the knowledge of how to ask the OpenSSL crypto library to generate a certificate.  You have to ask, there's an interactive session where you tell it a few things, like what domain name you want and your organization name and the other things that certs typically have, you know, like geographic location and so forth.  Then it has the ability to query the Let's Encrypt CA. 



So part of this service is a new certificate authority that will only be issuing, probably, domain validation certs through this automated protocol.  Oh, and it has to be preconfigured with the URL of the CA.  So that would be bound into this package.  And of course the domain name of whatever it is wouldn't be changing often.  So that's not a problem.  So it generates a Certificate Signing Request, a CSR, which is the normal process we all go through when we're creating a certificate.  And that certificate signing request involves the generation of a public key pair.  The server holds onto the private key.  That's its crown jewels.  It never lets that go.  But the public key is part of the certificate signing request, which it then is, when appropriate, it sends it to the Let's Encrypt CA. 



But first what happens is it needs to prove that it has valid control of the domain that it wants to get the certificate which it has just created that it needs to get signed.  That is, we don't want some random person generating a certificate for GRC.com and submitting it through this automated protocol to have it signed because then they would have a cert for GRC.com.  I don't want them to have that.  They would still have to jump through some hoops to use it because GRC's IP is in DNS, and so people looking for GRC.com come to my IP, not this bogus entity's IP.  So more needs to be done, but still we know we don't want them to get a cert for that. 



So the protocol has three main purposes.  One is to validate that you have control of the domain you are wanting activity for.  And that activity would be issuing certificates and revoking certificates and renewing certificates, you know, fundamental certificate operations.  So there are two ways that you can prove, through this automated protocol, through the ACME protocol, that you prove you have control of the domain.  The first is that you place content which the CA provides on your web server, which is then made publicly available, and the CA obtains it.  So there's a well-defined, simple, JSON-based, you know, JavaScript Object Notation, JSON-based protocol where the user, the client of this ACME protocol says I want to work with a new domain name.  I want you, CA, to ultimately issue me a certificate for this domain name.  So let's do that. 



So the protocol, the ACME protocol at the client side generates another completely separate public key pair and, again, holds onto the private key and sends the public key to the certificate authority over the ACME protocol, along with a domain name that it wants to associate, essentially.  So the CA has a public key and a domain name that the client says it has a right to have certificates issued for.  The certificate authority challenges it then with a session ID and a cryptographic nonce, so that none of this can be repeated, and a list of challenges, a list of ways it can prove control of the domain.  Currently there are two. 



But the protocol is meant to be open and extensible.  And in fact it can technically be used for other things than just managing a domain name, though that's all it's defined for currently.  So this challenge comes back to the client running the ACME protocol.  And the client can choose which of the things it wants to do.  One of the things it could want to do is to accept the challenge to put some content, which is just a bunch of Base64, so ASCII-encoded random gibberish, on a certain path in terms of the directory path of the website on the server.  The path always begins with ./well-known/acme-challenge/ and then a path which the CA has provided.  And again, that's a hex-encoded bunch of random stuff.  Hex so that it is valid for a path name. 



And so the CA says, essentially is saying in this challenge, here's a blob that I want you to place at this blob location.  Let me know when it's there and ready.  So in accepting the challenge, this client establishes, takes the data from the certificate authority, arranges to have it appear in public on that path at .well-known/acme-challenge/ and then a gibberish path, and then says, okay, I accept the challenge.  I'm ready to go.  The CA then makes a public query at the domain name that they're negotiating over at that well-known/acme-challenge/gibberish page and then obtains what's there, which should be the random gibberish that it gave the client. 



And so in completing that loop, involving looking up the domain name, getting the IP address, making a query, essentially what that tells it is, with provable security, that the entity that the CA is in communication with is able to affect and influence web pages at that domain.  So it has control of the domain.  And so in my example of some bad guy trying to get a certificate issued for GRC.com, they'd have no way of influencing my server, of arranging to get a page to appear on a whim on a certain location down my own public server space. 



So what the successful accomplishment does is to bind the public key, which was generated just for this, to the domain name at the CA.  So that, once done, establishes that the entity has control of the domain.  Subsequently, things like issuing certificates for that domain require that they be signed by the matching private key, which never leaves the client.  And all subsequent operations are signed with the private key that matches the public key which has been bound to this domain name forevermore. 



One of the cool things that the system does at that point, once there is an association that's been made at the CA, is it ups the ante for all future attempts to make a binding to that domain name, which is, when I read that in the spec, it's like, oh, nicely done.  Because that's what you want.  The idea is the first person to use this Let's Encrypt system to issue a certificate establishes this relationship.  And in doing so, nobody else can establish a relationship for that domain name without being able to prove they're the same entity that originally did it.  So that's another application for the matching private key. 



But then there's also something known as a recovery code, which the CA sends back as part of this initial binding protocol, which should be, can be stored separately.  The idea is to - and it's actually very much like SQRL's rescue code.  It's offline, and it's a "get out of jail free" card if you screw something up, if your hard drive crashes, if you lose all of your cryptographic stuff.  If the worst happens, how can you - and because we've upped the ante on making these associations, how do you say no, no, no, it's really me?  Please, I need you to issue me a replacement certificate because I've lost mine, but it really is me. 



Well, this recovery code is, again, long and random.  And only the person who originally made that association would be able to do it.  And what's cool is all the recovery code does is forgive the binding.  That is, essentially it says, okay, you still are going to have to reprove again that you still have control over the domain the way you originally proved it, but we're going to let you do that.  So very nice aspect of the protocol. 



And one other very neat thing that I saw there was when you vet - so the next aspect is you then issue a certificate.  So the client takes the certificate signing request that it made.  And it negotiates a transaction with the CA saying, okay, I've got a CSR, Certificate Signing Request.  I need you to sign it.  And it signs that request with its private key, which it uses for proving that it is the rightful requester for activities in this domain, sends that to the CA.  The CA looks through the various fields in the certificate to make sure that they're all valid.  For example, it would be possible for you to request things that you shouldn't request, like the right to sign other certificates.  It's like, oh, no, no, no, can't do that.  So it'll strip out things that you're not able to do.  And then, when everything looks right, it will sign that and return the certificate to the client as part of this negotiated transaction. 



One of the other things it returns, which is what I was going to say I thought was another really nice aspect of this, is a URL of a simple GET query which the server, the client running in the user's server, can use to get a renewed certificate any time it wants.  The idea would be it would still have to fit within whatever time horizon constraints the overall certificate has.  But, for example, you could use this to issue short-life certificates.  If you wanted to experiment, for example, with a protocol that we've discussed before, where instead of a long-life certificate with the need to revoke, you instead arrange to issue short-life certificates and don't worry about revoking them because they're going to expire in a couple days. 



So the system is a platform for experimenting with that.  And they've already incorporated one of the components you would need into the protocol, which is a way for the server, daily, to simply say give me a certificate, a refresh of my existing certificate.  You can't change any of the parameters.  You can't change the keys or features or anything.  But you could say give me a certificate that's good for four days.  And that's done with a simple GET request.  And the reply to that GET request is another signed certificate good for some length of time.  And this makes that very simple.  So clearly, if the world is going to be switching to short-lived certificates, we need a clean, simple, fast way to reliably get them periodically.  And this is already built in. 



The way I explained of putting content on a page is one of the two currently defined means of proving you have control of the domain.  The other one is a use of SNIs, Server Name Indication.  That's the technology where a single server that supports SNI is able to, at a single IP, support different hostnames.  And SNI is used to disambiguate which certificate should be returned to the client who is requesting an SSL connection.  The idea there is that you could use this system for non-web-based applications.  Clearly the first application is a web-based application because you need to put a web page up at somewhere publicly available at a random gibberish page name in order to obtain the content and verify ownership.  But you can use SSL and TLS for non-web things. 



And so using server name indication, the client chooses that as a means of proof in the protocol and creates a self-signed certificate where a random gibberish domain name is appearing in the certificate, along with the domain that they're asking for control over.  And so they respond to the challenge that way.  And then, again, the CA makes a request at this random gibberish machine name dot domain name dot whatever, and verifies that it's able to establish a server name indication enhanced TLS connection that way, and there again proving that the client has control of the domain.  And at that point then the association is established that allows certificates to be issued and revoked and so forth. 



So anyway, it's truly elegant.  It's simple, won't be difficult to implement.  None of this is hard.  The spec is all open.  The plan is to bring up a CA that operates this protocol in second quarter of 2015, so in the late spring, early summertime this should happen.  And I forgot to mention that once the client obtains the signed certificate, since it is then - it contains sort of the little mini expert system that knows how to configure the various web servers on the server platform.  It does that.  It puts the certificate where it's supposed to go, and the configuration files to bring up HTTPS on the server, and you're done.  So what the user sees is they run this, or install this. 



Oh, and I should also mention that clearly it won't be long before this is built in.  Why wouldn't Apache build this into the server, so you don't even have to add an add-on module?  It's like, yeah, once the system exists, just have it there.  So you'd have to be able to get it for installations that wanted to add it.  But the idea is that the operator of the domain either starts this process or loads it and starts it, answers some simple questions about the domain name they want to secure, their organization and where they're located and so forth, the standard things that go into the certificate.  They press a button, and then hum a short tune, and then up pops a dialogue saying, okay, you're now operating a secure server on that domain.  Everything else is done for them.  And it can be made transparent because the lowest level of authentication, just asserting that I have control of this domain, that's all automated.  And I just think this thing is 100% cool.  I'll be very surprised if it doesn't take off.  I think it's clearly going to. 



LEO:  I like your idea of Apache just building it in. 



STEVE:  Yeah. 



LEO:  Wouldn't that be cool. 



STEVE:  Yeah.  I'm sure it'll happen.  It's like, hey, just, you know, I mean, it might even end up being defaulted on.  It's like instead of you having to go and do it, part of installing is, hey, you know, unless you tell us you don't want to, we're going to bring up security on this newly setup server.  So tell us a few things, and we'll go get the cert for you.  I mean, why not? 



LEO:  Why not?  Let's just do it.  Yeah, I can see a day when everything's encrypted.  Why not?  Exactly. 



STEVE:  Yeah.  Exactly.  In fact, that's be a great... 



LEO:  Why not?  Why didn't it?  Why didn't it? 



STEVE:  That'd be a great name for the service. 



LEO:  Why Not? 



STEVE:  Why Not?  Yeah. 



LEO:  I seem to remember, was it Tim Berners-Lee, I'm trying to think, it's one of the early web pioneers.  Oh, no, no.  It was when we interviewed Vint Cerf, who of course is considered by many the Father of the Internet.  And I asked him why built-in end-to-end encryption wasn't part of the original spec, because it could have been.  He said, well, actually what I asked him was, "Would you have done anything differently?"  And what he said is, "I would have built in end-to-end encryption."  But we didn't at the time... 



STEVE:  Any idea. 



LEO:  Any idea, think it would be needed.  No one envisioned what has happened.  And I think also there was overhead in those days, those slower machines.  There was some overhead. 



STEVE:  Yes.  Remember that ping excited them. 



LEO:  Yeah.  They were still... 



STEVE:  That was like, oh, my god, I got an echo from my ping. 



LEO:  They were still happy with fingering. 



STEVE:  Exactly. 



LEO:  So we've come a long way, baby. 



STEVE:  Yeah.  And, I mean, the crypto world, as you said, there was overhead associated with it.  But also remember there was all that export nonsense.  I mean, our government... 



LEO:  That's right.  It was illegal.  Yeah. 



STEVE:  Crypto was a munition. 



LEO:  Right. 



STEVE:  It was categorized as a weapon. 



LEO:  Yeah. 



STEVE:  So, yeah. 



LEO:  Well, here we are.  We're going to retrofit the Internet for the modern world.  And this is a big start.  This is great. 



STEVE:  Yes, it's a really great piece of work.  And if this does, I mean, I will still pay the going rate, happily, because I want, I mean, because a lot of... 



LEO:  You want EV certs; right?  You want the green. 



STEVE:  Well, yes.  And you know, when you think about it, the prevalence of free domain validation certs, it almost makes the better certs more valuable because it will be clear, it'll sort of filter out into the ether that, oh, yeah, there's a lot of encryption, but all it's doing is encrypting your data.  Because the assertion strength of the organizational association will fall because it'll be understood that all this is doing, I mean, this is just sort of an automated thing.  And so, yeah, it's encrypted.  But we don't - but what that asserts in terms of the company you're talking to, that ends up getting - that ends up being weakened by this because you're not having a human-to-human contact interaction the way we do today.  And so that actually makes the ones you pay for more valuable because they're able to make that stronger assertion. 



LEO:  Yeah, I agree. 



STEVE:  Yeah.  And so... 



LEO:  It's good all around. 



STEVE:  I'll happily pay for my green EV status because I want it to be known that, yeah, this is actually Gibson Research Corporation, and that a human has verified in order to put that stamp on the certificate.  And I'm happy to pay for that.  And a lot of people will be. 



LEO:  Yes, indeed.  Well, you know what, a lot of people are willing to pay for Security Now!, but we don't charge them.  So there.  We do Security Now! every week at this time, Tuesday afternoons, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2000, I'm sorry, 2100 UTC.  And you could come and watch live.  We like that.  But you don't have to.  You can always get it on-demand after the fact.  Steve has the 16Kb versions of the show.  I wanted to say megabit, but no, kilobit versions of the show.  They're barely audible.  It sounds like Steve's coming to us from 1924.  But that's... 



[Crosstalk in muffled voices] 



LEO:  But you can also read transcriptions which actually have the highest fidelity of anything we do. 



STEVE:  And Leo, for what it's worth, the low-quality ones are very popular.  Thousands a week get downloaded. 



LEO:  Really. 



STEVE:  Per episode, yes. 



LEO:  Interesting.  Huh.  Well, I guess somebody wants them.  You know, if you have bandwidth caps or that kind of thing, or you just don't care how crappy it sounds, there you go. 



STEVE:  That's right.  There you go. 



LEO:  Well, more than 70, to be fair, more than 70,000 people download the high-quality audio and video versions. 



STEVE:  Yup, yup. 



LEO:  So, you know.  I mean, it's a percentage of your - more than 1%.  You can get also SpinRite at GRC.com.  That's Steve's fabulous hard drive maintenance and recovery utility.  Everybody should have it.  If you have a hard drive, you need SpinRite.  And lots of freebies that he just gives away out of the goodness of his heart.  And that's where you'll go if you have a question because I guess next week, the Internet willing, we'll have - if the creeks don't rise - we'll have a question-and-answer session.  That would be... 



STEVE:  You know, everybody's going to be in a turkey coma, even the bad guys and the attackers.  So we'll probably have a very quiet week. 



LEO:  The tryptophan. 



STEVE:  That's it. 



LEO:  You know what, Steve, it's a U.S.-only holiday.  I think that the Canadian hackers are going to work overtime. 



STEVE:  I heard that Thanksgiving had spread.  Is that not the case? 



LEO:  Thanksgiving, I think, is American.  Where else would it go?  It's the Pilgrims landing. 



STEVE:  I did hear, I heard that something had... 



LEO:  And then Squanto brought corn.  And they celebrated... 



STEVE:  Quanto? 



LEO:  Yeah, Squanto.  You've heard of him.  Squanto. 



STEVE:  Okay. 



LEO:  See, you don't come from New England.  In New England you learn these things.  You go, you visit the Rock.  They call it Plymouth Rock, where the first toe from the Plymouth Pilgrims set foot. 



STEVE:  Landed. 



LEO:  Yeah.  And then you learn all about Squanto.  You can go to Plymouth Plantation, where people dressed up like Pilgrims who pretend they've never heard of matches.  It's fun.  You try to trick them.  And then you have your Squanto.  He brought corn.  He brought sweet potatoes.  And because they were celebrating surviving, you know, their first year in the... 



STEVE:  Yeah, there was a bunch of ground-kissing, probably. 



LEO:  Probably. 



STEVE:  Yeah. 



LEO:  But I don't see any other reason - now, they have Thanksgiving in Canada, but they do it in October because they're - I don't know why, because they do it... 



STEVE:  Canadian. 



LEO:  They don't have Pilgrims.  They're Canadian.  But I can't see France celebrating Squanto bringing corn to the Pilgrims.  It just doesn't seem like... 



STEVE:  Maybe it was Franois.   



LEO:  Franois. 



STEVE:  Something, could it have been Halloween?  I don't think it was Christmas.  I just... 



LEO:  Halloween has spread.  Halloween has spread.  That's what you're thinking of. 



STEVE:  Oh, that's what I'm thinking of, then. 



LEO:  Everybody celebrates Halloween now.  Absolutely. 



STEVE:  Well, okay. 



LEO:  Who doesn't like to put on a sexy costume and scare the kids?  That's fun. 



STEVE:  They didn't have Squanto. 



LEO:  They don't have no Squanto. 



STEVE:  Okay. 



LEO:  They don't know Squanto.  I don't know what happened to me.  I'm sorry.  I apologize.  I lost my... 



STEVE:  This is all bonus time that... 



LEO:  Bonus. 



STEVE:  Yes. 



LEO:  Because vacation is coming up. 



STEVE:  Most of the audience has already hit stop. 



LEO:  I hope to god you're right. 



STEVE:  There's no other genius coming.  No jewels of wisdom at this point. 



LEO:  Have a wonderful... 



STEVE:  We're all - we're both punch drunk. 



LEO:  We're punch drunk.  Have a wonderful... 



STEVE:  And Elaine is thinking, why am I still transcribing this nonsense? 



LEO:  Yes, you can stop typing now, Elaine.  It's okay.  Especially that last thing.  Cut that out.  So are you going somewhere?  You going to see Mom for Thanksgiving?  Or what are you doing? 



STEVE:  Actually did.  Jenny and I made a pre-Thanksgiving trip up. 



LEO:  Oh, that's nice. 



STEVE:  A couple weeks ago.  And I'm so happy not to be traveling during the next couple days.  And Thanksgiving is Jenny's No. 1 holiday, Squanto notwithstanding.  And she has... 



LEO:  Well, because what's not to love about Thanksgiving?  You sit around, you eat a nice meal, you watch some football, it's a great time.  No pressure. 



STEVE:  That's like the one she really cares about.  So she throws a big party.  All of her friends come over. 



LEO:  Oh, fun. 



STEVE:  And, yeah.  So I get to be there for that because we've already done family. 



LEO:  Good. 



STEVE:  Yeah. 



LEO:  Wonderful.  Well, have a great Thanksgiving.  And we'll be back here next Tuesday at our normal time. 



STEVE:  Will do.  And yourself, as well... 



LEO:  Thank you. 



STEVE:  ...and all of our Squanto-loving American listeners. 



LEO:  I'm going to celebrate Thanksgiving by decapitating the Seattle Seahawks at the '49ers game. 



STEVE:  Oh, you've become Mr. Sport.  When did this happen? 



LEO:  Not really.  I couldn't care less.  But my girlfriend makes me go. 



STEVE:  Oh, okay.  That's - okay. 



LEO:  Let's be honest here. 



STEVE:  I was going to say, I've known you for years, Leo, and suddenly you're talking about sports like I've never heard... 



LEO:  I don't know what I'm saying.  I don't care.  Look at my attractive sweater.  That's... 



STEVE:  Well, now, that is - that's very nice. 



LEO:  The NFL has a whole ugly Christmas sweater shop for every team.  And this is actually the Philadelphia Eagles.  I'm not - I don't have the San Francisco '49ers one.  That makes it even more ugly.  So have a wonderful time.  We'll be back next Tuesday. 



STEVE:  Will do. 



LEO:  Everybody stay safe.  Don't let the Stuxnet or the Flame or the Regin infect your system.  We'll see you next time. 



STEVE:  Bye, Leo. 



LEO:  Bye. 



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/. 



 






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#484

DATE:		December 2, 2014

TITLE:		Listener Feedback #202

SPEAKERS:	Steve Gibson & Mike Elgan

SOURCE FILE:	http://media.GRC.com/sn/SN-484.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Mike and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  Steve updates us on the latest Firefox, plus the trouble with iOS v8, and Steve answers your questions.  It's Q&A #202.  Stick around.  Security Now! is next.



MIKE ELGAN:  This is Security Now! with Steve Gibson, Episode 484, recorded December 2nd, 2014:  Your questions, Steve's answers, #202.



It's time for Security Now! with Steve Gibson, the show where we cover privacy, security, and so much more, including coffee.  And we'll be totally talking about coffee here today at some point.  How you doing, Steve?



STEVE GIBSON:  Hey, well, everybody knows you are not the voice of Leo.



MIKE:  You're kidding.



STEVE:  So, Mike, it's great to be with you this week.  We'll do a Q&A, and everything'll be just fine.



MIKE:  I'll believe it when I see it.  I hope I don't wreck the show.  Leo's off today, and I'm stepping in.  I always listen to this show, so it's really great to actually host the show with you, and this is just going to be awesome.  So why don't we just launch into the show.



STEVE:  Well, so we have a Q&A this week.  We don't have a ton of news.  I want to talk about some new features in the just-released v34 of Firefox.  And to sort of tease next week's "deep dive" episode, I thought I was going to talk about the research into de-anonymizing Tor.  And I've decided we'll call that one "De-Tor."  But it ended up being so interesting and cool that I thought, okay, this is worth a whole podcast.  So that'll be next week.  Then we have a bunch of, I mean, nothing really happened in the last week, although we've had a couple of very busy weeks before that.  So we have a bunch of interesting miscellaneous stuff, and it's a Q&A episode, #202.  So we've got 10 interesting and some thought-provoking questions from our listeners that we're going to cover.



MIKE:  Fantastic.  I can't wait to hear it.



STEVE:  And it's sort of odd in our - I try to put some sort of a picture on the front page of the show notes every week.  And Jenny sent me a picture of the Newf sisters, the twins that she has.  She and her daughter each have one, named Paris and Beluga.  And I didn't realize it until she commented that they both have their front paws crossed, which was the impetus for taking the picture.  Apparently this is something that Newfoundlands do.  Jenny is a serial Newfoundland owner.  And so they took the picture because both dogs, both pups were sitting there with their right paws crossed over their left.  I mean, this wasn't staged, this was just candid.



But we have a sponsor, who we don't have this week, but Leo introduced them last week, BarkBox.  And one was sent to me, which I then dropped off with Jen, and the pups got a big kick out of it.  So we will talk, I will share Jenny's reaction and theirs, actually, when we next have BarkBox as a sponsor.  But that explains why there's a couple dogs on the front page of the show notes, whereas normally we have schematics of networking diagrams and boxes interconnected to stuff, or bar charts showing scary infection rates across the globe.  Now we've got Newfs staring at the camera saying, "Can we eat that?"  Anyway, so...



MIKE:  And crossing their paws.  It's amazing.



STEVE:  And crossing their paws, as apparently Newfs are wont to do.  So we're going to talk, next week's topic will be De-Tor.  And I'll just say that the reason it's worth talking about is that stats have been generated by a researcher who believes that anyone who sufficiently wanted to could deanonymize more than 80%, I think the number that I remember was 84%, of supposedly anonymized Tor traffic, using some features of Cisco routers.  And that's a high enough number.  It's not like maybe they could get lucky.  But that's a big number.  And we do know, if nothing else, post-Snowden revelations, that organizations like the NSA really do, really would want to be able to provide deanonymizing service for Tor.  So definitely worth talking about next week.  And we'll do one of our wind-up-your-propeller-cap episodes.



MIKE:  Nice.



STEVE:  Yeah.  So we just got a new drop of Firefox, v34.  The biggest thing you see, which had been covered, I think it was mentioned maybe a couple weeks ago, is that Firefox for the first time is no longer using Google as their default search engine.  If you're upgrading from Firefox, it doesn't boot you out, but it introduces and sort of suggests that let's all switch to Yahoo!.  Well, okay.  Now, I have no experience with Yahoo!.  But I'm not switching.  I'm staying with Google.  So as I understand it, Google has been a sponsor of Mozilla for, like, for a long time.  Do you know what's behind this, Mike?  Is this the ascendance of Chrome as, like, competition?  Has Google pulled their sponsorship of Firefox?  Do you know any more?



MIKE:  Well, I have a feeling that Yahoo! paid dearly for this.  And the other thing that's interesting about it is the length of the contract.  I think this was a five-year contract, where I think the old Google contract was a three-year contract.  I think it's pretty standard for money to change hands for these things.  But I just think that Yahoo! is desperate and hungry.



STEVE:  Well, and we do see more Yahoo! stuff in the news, so I think you're right, I think they're clearly pushing wherever they can to make some inroads.  And so the default search engine changes.  But if you're already at Google, you're not kicked out.  They've expanded search features.  Oh, I ought to mention also that for Belarusian, Kazakhstan, and Russian locales the search engine is changed to Yandex, Y-A-N-D-E-X, as opposed to Yahoo!.  So it's not a global change.  They have improved the search bar.  They've also got now a real-time chat client called "Hello" is built into Firefox.  So that's part of the standard build now.  It's also possible in 34 to easily switch themes and personas directly in the customizing mode.  Oh, and they're now noticing that, if you're using Wikipedia search, it defaults to HTTPS.  So it sort of upgrades your search privacy for you when you are searching in the U.S. Wikipedia.



They have an early implementation of HTTP/2, which is based on SPDY, that we talked about a long time ago.  SPDY was the sort of experimental, next-generation HTTP alternative that Google was experimenting with, has been for years.  And also ALPN support is there.  That's the Application Layer Protocol Negotiation that allows application layer security to be negotiated by connection.  So anyway, so this is just sort of early standards stuff moving forward that Mozilla is staying right up with.  And they also said that you can now recover from a locked Firefox process in the, quote, "Firefox is already running" dialogue under Windows.  Firefox is my browser, I live in it, and I've never encountered that.  So I don't know when that happens.  But if it does, you can now recover from it.



Oh, and interestingly, they have disabled SSLv3 in the Firefox client.  So Firefox will no longer support v3 of SSL.  It will be at formally TLS now, 1.0, 1.1, and 1.2.  And that's of course because we've had recent problems with the security of SSLv3.  So, neat that they're doing that.  And I imagine, Mike, that Windows will ultimately - Microsoft with IE will get around to that at some point, which is a good thing to do.



MIKE:  Probably take them a while, though.



STEVE:  Exactly.  Precisely.  It won't be anytime soon.  And just sort of on the developer side, lots of motion forward on the HTML5 standard, mostly in the web crypto area.  I saw just a ton of new web crypto APIs that have support.  And I think that's good, overall.



So that's really all the news we have.  I hear Leo and Sarah talking about iOS v8.  And I've been meaning to say for a while that the iOS 8 bugs are just driving me crazy.  I mean, it's sad that - I don't know, are you an iOS or an Android person?



MIKE:  I'm on iOS now.  I moved from Android to the iPhone 6 Plus, and so I'm back on iOS.  And, yeah, it's kind of surprising, isn't it.



STEVE:  It really is.  I mean, Jobs would just be, well, I mean, heads would be rolling, if this was going on at Apple with Steve still at the helm.  All kinds of obscure things.  A lot of them seem to be keyboard related.  I'm a big fan of Swype and SwiftKey.  That's just a win on those touchscreens.  But I'm seeing, like, new, creative ways that they are finding to fail.  Just this morning I could see, like, just the upper maybe 25% of the keyboard skewed off to the side.  It was like, okay, what the heck?  And but even non-keyboard things.  The calendar app had the December month, like, ghosted three times in some sort of a rendering error.  And just all kinds of obscure things.  It is not only surprising, but it's disappointing because we depend upon this, and we'd like to have a reliable appliance.  So anyway, I listen to Leo and Sarah sometimes saying, "What is going on?"  And I just want to say, yeah, believe me, you guys are not alone.  Everybody is seeing it.



MIKE:  Yup.



STEVE:  And there was an interesting article in The Washington Post.  I'm also hearing Leo, and as it was, Leo and Sarah were talking yesterday.  You know, Leo is no fan of Twitter.  You probably have heard him, Mike, talking about just what a catastrophe he feels it is.  Anne Applebaum wrote a nice piece that I'm linking to in the show notes, that I wanted to just point our listeners to, just the first couple paragraphs to give our listeners a sense for it.  Anne writes:  "If you are reading this article on the Internet, stop afterward and think about it."  Okay, so she's saying read the article.  Think about it.  "Then scroll to the bottom and read the commentary.  If there isn't any, try a website that allows comments, preferably one that is political.  Then recheck your views."  And so what she's saying is read what's posted and wait, assess it, make up your own mind.  Then read the comments and see what you now think.



She says:  "Chances are your thinking will have changed, especially if you have read a series of insulting, negative, or mocking remarks, as so often you will.  Once upon a time, it seemed as if the Internet would be a place of civilized and open debate; now, unedited forums often deteriorate to insult exchanges.  Like it or not, this matters.  Multiple experiments have shown that perceptions of an article, its writer, or its subject can be profoundly shaped by anonymous online commentary, especially if it is harsh.  One group of researchers found that rude comments" - quote, and this is from the research - "'not only polarized readers, but they often changed a participant's interpretation of the news story itself.'  A digital analyst at Atlantic Media also discovered that people who read negative comments were more likely to judge that an article was of low quality and, regardless of the content, to doubt the truth of what it stated."



Anyway, I just think this is a fascinating aspect of what's going on with the Internet now that absolutely relates to Leo's current angst with Twitter.  And I've experienced it.  There are, for example, about SQRL, there are some people who didn't understand what I had created and put up some early blog postings that are critical of it, which are fine, if people would understand the context for that.  And one of the problems is that I guess people who don't have a firm sense of their own ability to make up their mind sort of inherently defer to others.  And so people will read, as Anne notes, criticism and get hugely swayed.  And I end up finding myself having to defend against somebody with no credentials at all who's raised some concerns that actually aren't problems at all, I mean, the person is completely wrong, but it scares people.  And we see this happening all over the Internet, in all kinds of instances.



So anyway, that's just the front of a really thought-provoking piece that, if people are interested in the subject, I really would commend them to take a look at.  And she wonders toward the end whether anonymity is, for all of its benefits and the power and enabling that it creates on the Internet, if that's not part of the problem.  And I wonder - and certainly I would never suggest that people lose the right to be anonymous if they choose.  But sort of in the same way that Twitter, to use the example, has the option to verify the identity of Twitter accounts - you know, Leo has the little checkmark.  He's a verified identity.  People have told me I should do that.  I just haven't gotten around to it.  But maybe that's the solution is to allow people to have an authenticated identity if they choose, or to be anonymous, oddly named creatures if they don't.  But anyway, I thought that this was just an interesting piece that came across.  What do you think about the whole thing?



MIKE:  It is, yeah, it is interesting.  And I've had multiple conversations with Leo about this.  And my own view is that I think that anonymity is okay as long as the communications medium you're using enables the person who starts the conversation to delete any comment below that conversation and then block that person from being able to come in later on.  There are some social networks that allow that and others that don't.  Twitter is where a lot of the problems exist, simply because on Twitter you have no such power.  Any tweet, whether it's a response to an initial tweet or not, is equal to every other tweet, for the most part.  So, for example, let's say you posted something on Twitter about SQRL, and then a bunch of people commented on it.  And let's say somebody was saying all kinds of things that weren't true, and they were being just deliberately malicious or whatever the case may be.  And on Twitter there's literally nothing you can do about it.  Everyone involved in that conversation who's paying attention will see their comments and your rebuttals as equal, and you can block them if you want.  But if you block them, you're simply putting your own head in the sand, and those comments are going on without any control on your part.



STEVE:  Right, right.



MIKE:  Whereas on other social networks, you can go in there and literally delete the comments.  And so the conversation that you started, you have sort of stewardship of that conversation, and...



STEVE:  You're still able to curate it, yeah.



MIKE:  Exactly.  And I think that's one part of the solution.  I don't mean to be super anti-Twitter because Twitter is great in so many ways.  And of course we tech journalists love Twitter almost universally.  But there's a structural issue about Twitter that leads to this kind of misinformation.  It's probably the worst place there is online to have a conversation.



STEVE:  It's funny, I was speaking of, you know, you were talking about journalists.  I heard, or I was watching some interviews of some young, hip, Internet-enabled journalists a couple days ago.  And these were, like, on the East Coast, but they were involved in the financial markets.  And these were like the people who sleep with their iPhone, like, holding it so they'll be awakened by it vibrating.  I mean, they're just so connected to the 'Net.  And I'm thinking, okay, that's a little too much.



But they both said that the first thing they do when they wake up is check Twitter and, like, specific feeds because they need, they're literally - they're  anxious about the fact that they've been unconscious for six hours, god help them, and as fast as possible they need to come up to speed, due to the nature of their jobs, on what happened during the six hours that their body forced them to be unconscious.  And I just thought, okay, well, yeah, I don't want your job.  But so, yeah, it's irreplaceable, as you said.  But the absolute nature of the fact that it's just such a wild zone also creates a problem.



MIKE:  Yup.  It's a troll's paradise.



STEVE:  Yeah.  I like the idea of being able to curate a conversation you start.  Of course, the flipside is you really need to be a mature curator because you're also able to go too far and curate a dialogue so that it looks like you're walking on water.  If people are raising issues which are good ones, if you don't have the strength to allow useful debate, rather than just trolling, then this notion of you having control of the dialogue can be taken too far.  I did note, and Anne talks about this, there are confirmed reports of paid organizations deliberately spamming competitors' blogs and feeds, like each political party, for example, in an environment where there are multiple parties, hiring organizations to plant negative information in their competitors' or their opponents' social environment for exactly this fact.  Unfortunately, negative stuff has a strong, a high level of traction.



MIKE:  Yeah, it certainly does.  And it's for exactly the reason they're talking about in this article.  This sort of astroturfing works, and that's why political parties do it.  And also China does it, and Russia does it, too.  In fact, there was a story in the news over the weekend, The New York Times Book Review Podcast was talking, interviewing the author of a book about Putin and the Putin kleptocracy, I don't recall the name of the book ["Putin's Kleptocracy" by Karen Dawisha], but it was a new book that was coming out.  And she was saying that she was shocked that the so-called "50-Ruble Army," which is what they call it, it's basically named after the "50-Cent Army" of China, which is where they pay commenters to promote the Kremlin and oppose its critics on message boards all over the world, they were silent.  She was saying that they didn't jump in and talk about this.



I posted a little thing on Google Plus about the fact that she mentioned that the 50-Ruble Army wasn't there. And guess what, the 50-Ruble Army came rushing in and just polluted the comments with just crazy talk, exactly as she described it.  She was asked to describe what sorts of things, what sort of techniques the 50-Ruble Army uses to sort of block out rational conversation, and that's exactly what happened on my own message board.  So that was kind of funny.  But, yeah, this is the tragic thing.  It works.  And over time, more and more organizations, governments, parties, companies are discovering that they can influence public opinion through this kind of fake grassroots commentary.



STEVE:  Wow.  Well, yeah, GRC maintains a bunch of old-school NNTP newsgroups.  And it's just - it's an amazingly valuable resource.  And years ago you could post to the newsgroups through a web interface.  And during the time when I was stirring up some controversy over my railing against Microsoft for having the raw socket interface left in, which was going from Windows 2000 Server, it was going to then become Windows XP.  And I begged Microsoft not to leave the raw sockets API in a consumer operating system.  Fine to have it in a server.  Don't put it into a consumer operating system because raw sockets on the application level gives too much attack power.  And it wasn't until Service Pack 2 that they finally understood what I was saying.  Actually, the MS Blast Worm that attacked them used XP's raw sockets to blast them with an attack that they couldn't defend against.  Fortunately, it was aimed at the wrong URL, so they were able to duck that.



But the point is my taking that position was controversial; and the newsgroups, GRC's newsgroups were just overwhelmed with just junk, I mean, just garbage posts, people who weren't informed, who were just on the bandwagon, enjoying making noise.  And it was somebody else who'd been a longstanding participant who noticed from the headers that it was the web interface that was the source of all of this, not people who had taken the time to set up a formal NNTP newsreader.



And so I shut down, I made the web interface read-only, and the problem just went away.  Because people were happy to just sort of drive by and drop junk into the forums, but nobody took the time to actually set up a newsreader, and that's been the way it's been ever since.  And we just, as a consequence, through that little bit of a bar, little bit of a barrier to entry, we have a paradise of, like, really useful technical discussion on an ongoing basis.  So I think part of the problem is it's just so easy to put this stuff up.  And you have the advantage of anonymity.  Which, again, I wouldn't want to take from anybody.  But as we've been saying, it does, it can get, unfortunately, abused.



We talked, oh, I don't know when it was, maybe six months ago about an interesting movie that a friend of the podcast, Jonathan Schiefer, had produced called "Algorithm."  And I wanted to let our listeners know, and I will remind everyone next week also, that on Sunday, this coming Sunday morning, well, midnight, so like 12:01 a.m. Pacific time, Jonathan is going to take the movie on YouTube public.  The URL is in the show notes for anyone who wants it.  I'll tweet it on Sunday after it is public because I've already confused some people who tried to go there, and it says "This is private" at the moment.  But it's a - yeah, right, you get the little unhappy confused face if you go to the link.  But it's a really interesting, technically accurate, sort of privately produced movie that Jon crowdfunded in order to produce.  So as soon as it is public, I will tweet it, and I'll remind everybody next Tuesday.  But if you're anxious to get it before then, you could do so by grabbing the URL from the show notes and checking it out on Sunday [https://t.co/ks1gOLZTu0].



Okay, now, this is completely off topic.  And I was anticipating that I'd be talking to Leo about this.  I don't know if - do you know anything about Abe and Oddworld?



MIKE:  No, I don't.



STEVE:  Okay.  Well, Leo and I have spoken about Abe and Abe's Oddworld and Oddworld Inhabitants for a decade or more.  It was a really unique videogame project which launched in 1994, a group of computer animation and special effects people up in San Luis Obispo, led by a guy named Lorne Lanning and Sherry McKenna.  They were considering - they were sort of an offshoot of Hollywood, doing projects for Hollywood.  And Lorne and Sherry were seeing each other socially.  Lorne wasn't around when Sherry was hanging out in his living room, and on his coffee table she saw a sheaf of papers, sort of looked like a screenplay, that Lorne had put together, that he'd never mentioned to her.  So she starts reading this.  And when he came back she said, "What's this?"  And he said, "Oh, it was just sort of some ideas I was working on, maybe for a movie."  And she looked at him, and she said, "No, this is our videogame."



And I'm talking about this because it's coming back.  It was on the early consoles.  And every time another installment would come out - there was Abe's Oddworld, Oddworld Exoddus, or Abe's Exoddus, I think.  Then the idea was there was going to be a quintology.  I think they did only three or four titles.  And I'm not a videogame guy.  I mean, I've really no interest in the whole first-person shooter genre, except from a video technology standpoint.  I've been fascinated by looking at the way the technology has evolved.



What was unique about this, and the reason they did something, was that it was sort of green.  This little character, who was literally a floor polisher, worked in - this is all on an alien planet - worked at Rupture Farms, which was a meatpacking facility.  And this sort of takes you through his attempt to free all of his coworkers.  It is a puzzle mode game as opposed to a fast reflex, fast action sort of game.  And I'm just a sucker for puzzle mode stuff.



And even though I remember the reviews just were wild about it, they called it a - it came out in a time when we were sort of done with what's called the "horizontal scrollers," where you just sort of scroll horizontally and stuff happens.  And this was one, except that it was so well done, the graphics and animation, I mean, and the background music, you just felt like you were in this environment.  Leo was completely enthralled.  He and his son used to play it all the time.  I would lose a couple weeks of my life every time a new title came out from these guys because that's all I would do was just sit down and say, okay, I have to just take a timeout.  I don't ever go on vacation, so this is my vacation.



So what Leo and Sarah talked about yesterday is there is a new title available using a character which they created toward the end called "The Stranger."  This is available on iOS.  So they were showing it on iPad Today yesterday, called Oddworld:  Stranger's Wrath.  And it is coming soon to Android.  But anyone who has a PS4, because it's the only platform their remake of the original Abe's Oddworld is available for, if you're interested, check out Abe's Oddworld.  The game is called "New 'n' Tasty," currently only on the PS4.  They are going to be backporting it to the 3 and the PlayStation, the Mac, the PC, and the Xbox One.  But it's not available on those platforms yet.  And just to give you a sense for it, Escapist gave it a 5 out of 5, Eurogamer a 9 out of 10, Gadget Show a 5 out of 5, PS Nation a 9 out of 10, Meristation a 9 out of 10, Nowgamer a 9 out of 10, and IGN an 8.5 out of 10.  I mean, so I can't wait till they get this thing on additional platforms.



And I know this is not a podcast about games.  But for what it's worth, if you are a person who likes sort of the puzzle genre, you can play some of the videos on their site.  It's Oddworld Inhabitants is the formal publisher.  You'll immediately get a sense for what they've done.  It is really charming.  And the other thing is that it was always inherently nonviolent.  And that's why Leo liked it so much and enjoyed sharing it with Henry is that this was about doing good and sort of ecology and, I mean, it's still interesting.



But they were under pressure to do a first-person shooter because that's what everyone was wanting, even though they were very successful with their puzzle platforms.  So this Stranger character shot weird little animals that did the - instead of like a grenade blowing up, it would be some little fur ball that was mostly teeth, and it would buzz around on the bad guys whenever it shot them.  So even then they tried to tone it down and keep it from being your typical first-person shooter game.  So anyway, I just, for what it's worth, I recommend all of their content without reservation.  And I'll have fun talking to Leo about it when he's back with me.



MIKE:  Well, it sounds really cool.  I'm going to have to check it out.  I just am completely unfamiliar.  I'm not a gamer, either.  I just have maybe one or two games that I play every now and then.  But this sounds really great.  I love what you're talking about, how it's like sort of the opposite of Grand Theft Auto.



STEVE:  Yes.



MIKE:  You know, it's constructive and interesting rather than just blowing people away.  And, yeah, sounds really fascinating.



STEVE:  Yeah.  Well, it has heart.  I mean, first of all, these guys are talented graphic artists and designers.  So a huge amount of just emotive content in the game.  I mean, it's just - I just can't recommend it highly enough.  So if I've managed to tease anybody, go check out Oddworld Inhabitants.  I was just delighted that they're still around, and they're producing content.  It is really unique and really special.  In fact, Leo played a video.  If anyone's curious, you could get yesterday's, that would be December 1's iPad Today because there is a video at the beginning of the game that Leo played that gives you a great sense for just how good this is.  And again, for younger kids and for us old people, too.



MIKE:  Sounds awesome.



STEVE:  So I encountered, when going through the mailbag today, a note which was - it's one of the kinds of things that we hear about SpinRite from time to time that surprises people.  And that's because it's not always clear when a hard drive is having trouble.  So this was from a guy - well, I guess a guy.  I'm sorry if you're not.  All I have for a name is M-A-R-B-L-A, so MarBla or something.



MIKE:  MarBla.



STEVE:  In Poland.  Anyway, his email was titled "SpinRite Saved Chromium Browsers."  So he wrote:  "Hi, Mr. G.  Recently I had some serious issues with the browsers that work with the Chromium engine, Google Chrome and Opera."  He said:  "Pages did not want to load, not possible to load settings page, et cetera.  I tried multiple times to uninstall and install the software again, scanned my computer with many antivirus and antimalware software, but nothing I tried helped.  I was forced to use Firefox, [and he says] not my favorite, on this particular machine.  But finally I received a strange message from Windows operating system that my hard drive needs attention as there are a lot of errors."  And he says:  "Probably some input from the SMART system?  So I launched SpinRite at Level 2.  After a few hours it showed three red 'U' marks, and the system restarted.  And, yes, Chromium browsers now all work perfectly again.  So sometimes you can't expect what can actually help in your software problem.  Thanks, and greetings for you and Leo."  And MarBla, thank you for sharing your success with SpinRite.



MIKE:  Who'd a thought.  It fixes Chromium.  That's awesome.



STEVE:  Yeah.  Indeed.



MIKE:  Well, Steve, we've got some questions here.  Why don't we just launch in?  I'll ask you the questions; you answer them.  Because if you ask the questions and I answer them, people are going to get some bad answers.  So let's do this right.



STEVE:  That sounds like a plan.



MIKE:  All right.  So let's start with Yves Nadeau.  I'm probably messing up the pronunciation there.  Hi, Steve Gibson.  I got a domain-level SSL for my blog for 98 cents a year on Cyber Monday.  It works so far, but how do I prioritize it over regular HTTP?



STEVE:  Well, I saw this, and I thought this was a really great question because we've been talking recently about the EFF's pending project, due out in the second quarter of 2015, to for the first time ever make domain-level, that is, Domain Validation, DV certificates, available for free by coming up with a clever means of automating the process that allows a server to assert its ownership over a domain name and thus qualify to get certificate protection to basically allow it, in the same way that it would be having an HTTP conversation, to have an HTTPS conversation.  When you think about it, I mean, if it's already able to control an HTTP connection, that is, to demonstrate that it's the server there, then why not just allow it to secure essentially the connections to the same domain that it was creating over nonsecure.  So I just love the idea.



So in this case he's got a very inexpensive cert, and everyone in the second quarter of 2015 will be able to get them for free.  But the problem is, once you get the certificate, then your server can respond to https:// and whatever.  But it's doubtless also still going to respond to HTTP.  So he's saying, okay, I've got the security now.  How do I get it used?



And so there are a couple things you can do.  It is definitely possible to, depending upon what server platform you're using - IIS, Apache, Nginx, whatever - to talk to the server administrators.  Now, he says he has a blog, so I'm assuming that somebody else is running, who knows where, it might be with WordPress, for example.  But taking that as an example, there is a WordPress plugin which you can add to your WordPress installation which will automatically convert the HTTP links to HTTPS.  So there's that.  You can also, in the config file for the server, you can redirect any browser that attempts to connect to any URL on your blog from HTTP to HTTPS.  It's called an HTTP redirect.  So those sorts of things you could achieve by contacting the administrator and saying, "Hey, is this a feature that you can offer my blog?"



The alternative way is just to start using HTTPS for everything.  If there's, for example, if you're able to edit past blog posts, just go through and change all references to http:// and your domain and blog, change it to HTTPS.  You'll want to make sure that all of the explicit HTTP references on the page to your domain are changed.  Otherwise you'll start getting those mixed-content warnings, where a secure page also contains unsecured other bits and pieces, pictures and scripts and so forth.  So you'll want to make sure you move the whole thing over.  And you can easily test it to make sure that you're not having a mixed content problem.



So really the best thing to do is just start using HTTPS ubiquitously.  Use it everywhere.  When you post links to your blog, post them as HTTPS.  When you tweet links, tweet them as HTTPS.  Google will pick that up and switch itself over, and so it'll start showing your links preferentially using HTTPS.  So you can sort of do it casually, just by using it.  Or, if you want to go further, you can enforce it at the server side so that the server turns any nonsecured query, basically sends back a response to the client saying, oh, this has moved permanently to, and then it gives it the same URL, just adding an "S" after the HTTP, in which case the client reissues the query over on the secure side.  And actually, if you do that, Google is very smart about that.  It'll notice that links it had are being now redirected permanently, and it'll go back and fix them in its index.  So I think a lot of people are going to be wanting to do this about six months from now, which is going to be great.



MIKE:  Wow.  Cool.  All right.



STEVE:  Yeah.



MIKE:  Question #2:  Jim in Philadelphia is suffering under corporate SSL interception:  Hi, Steve and Leo.  I'm a longtime listener, and I look forward to hearing the show each and every week.  Recently, with the help of Steve's HTTPS Fingerprints service, I discovered that my company is doing SSL interception of both our HTTP and HTTPS traffic.  While I wasn't completely surprised to discover this, I was surprised that it was effective across the board.  My banking information, my credit card data, my medical claims were all being decrypted, scanned, and analyzed before leaving our network.  I understand the reasons for a company to put this process in place, but surely there must be boundaries?  I feel like this is a lawsuit waiting to happen.



If my understanding is correct, setting up a VPN would not help because they would just play man in the middle with that connection, as well.  Is there a way around this, or should I just resign myself to never visiting these sites from my work computer?  Thanks, and keep up the great work.  Jim.



STEVE:  Okay.  So I'm seeing more and more people, I don't know if people are - I think it's probably the awareness that we've created by talking about this problem on the podcast and then giving people a quick means to check using the HTTPS fingerprinting service at GRC.  What that does is GRC shows you the serial numbers of certificates out on the Internet that the GRC server sees, and then a user inside of a corporate network compares those to the certificates they're seeing, and they should be the same.  If they're not, then there's a very strong chance that essentially a sanctioned man-in-the-middle attack or - like I don't really want to use the word "attack" because it's not an attack.  But still, a man-in-the-middle interception is happening.



Okay.  So a VPN, if it worked, would almost certainly solve the problem, Jim.  This is the firewall that your corporation is using is intercepting HTTP traffic and generating certificates for the sites you visit on the fly.  Doubtless your machine accepted in the past a certificate from the firewall which essentially gives it permission to sign on behalf of, well, of anyone it wants to, essentially, which is what makes this a little concerning and frightening.  But it's not able to do this with a VPN connection.  The problem is that it may - that same technology is very likely, unless it's explicitly permitted, blocking VPN connections.  The good news is many VPN services have like a free trial offer, so you could certainly easily experiment with running a VPN connection.



The way VPNs work is that, all of the commercial ones, you receive a certificate which your VPN client has, and that certificate has been signed by the server.  But it is not using the regular public, public key crypto system.  It's using it, I mean, it's using public key technology, but not the infrastructure, not the whole certificate authority hierarchy.  So you get the benefit of very good end-to-end authentication because you're using essentially private certificates.  But that means that it cannot be intercepted by regular SSL traffic interception.  So it may be that the corporation is blocking VPNs as part of their overall security architecture.  But if they're not, then you could absolutely use a VPN in order to essentially create your own tunnel through their firewall, bypassing all of this interception and getting out onto the Internet, where then you would be - you'd then be able to use HTTPS through the VPN tunnel and get really good security that nobody was intercepting.



MIKE:  All right.  Question #3.  Rob Blair in Toronto noticed that Mozilla removed the force OCSP mode.  And he says:  Hi, Steve and Leo.  I'm running Firefox 33.1.1, and I just noticed that in my security settings I no longer have an option for how I want to use OCSP.  It used to offer don't check, optional, and force.  Now there's only a checkbox for whether to use it or not.  Yikes.  Any idea when or why this change was made?  Thanks.



STEVE:  Okay.  So I looked, and I was already up to v34 that I was just talking about at the top of the show.  And sure enough, it's gone from the UI.  He was using 33.1.1, which was the last prior version.  I didn't notice when it went away.  And we saw this happening with Chrome.  Now we're seeing something similar.  Essentially, I think that they're trying to simplify the user's experience.  The good news is the feature itself is not gone.  When we spent all of this time a few months back talking about the whole OCSP certificate revocation issue, many people who are Firefox users turned that on and reported - okay.  And so what that was doing is that was enforcing OCSP so that Firefox would only function if it affirmatively was able to verify that the certificate was still valid.  Nobody - okay, I can't say nobody.  But, like, .01, to make up a number, like almost nobody ever had a problem.  I'm running it.  I've got, I mean, as I said, I live in Firefox.  No problem at all.



So the thing to do is go to the famous smorgasbord settings page in Firefox.  In the URL bar you put about:config.  Instead of https:, you put about:, and then config, C-O-N-F-I-G.  You'll end up with more settings than you have ever seen or imagined anything could have.  So the good news is there's a search bar.  Put in "OCSP," and that reduces it, I'm looking at mine, to one, two, three, four, five, six items.  And the last one there is "ocsp.required," and I see that it's still set for "true."  So because mine, in my UI, was - really, you're going to want to put in at the top there, in the search bar, put in "OCSP," and it'll just whittle that craziness down.  There it is.  Bang.  So I had left my Firefox with that enabled.  Even though they removed it from the UI, they did not turn it off.  So good for them.  So there's "enabled," and there's "required" is the last two items there.  And I've got mine still set for "true" in both cases.



So they are honoring it.  And anybody who still wants to enforce it, if it was enforced by the UI checkbox before, then it has continued to be.  And if you never got around to doing that, but you want to, unfortunately they've no longer made it easy.  It's not in the UI, but it is in this crazy about:config page, where you're easily able to set that to true, and it'll be sticky.  So, Rob, it's still there.  And you're still protected; and I am, too.  So thanks for bringing that up.  I'm glad to know that Mozilla didn't turn it off for people who had it on when they removed it from the user interface.



MIKE:  Fantastic.  All right, Steve.  We have Question #4 from Chris Haas in La Crosse, Wisconsin, who's wondering about the far future of CA expiration dates.  He writes:  Hi, Steve and Leo.  I really love watching the show and listening to Steve going into deep dives on subjects most people don't talk about until it's too late.  I recently opened up my local Windows certificate manager - that's certmgr.msc - and was surprised to see how many trusted root CAs that have what I consider to be insanely far future expiration dates.  GoDaddy and AOL - AOL! -  for instance, expire in 2037, and AOL's was created in 2002.  I get the "if it works today it should also work tomorrow" principle, but this is excessive.  I know that they can be revoked, but still someone had to consciously say, "Hey, don't worry.  Unless you hear something otherwise, just blindly trust us for the next quarter of a century."  And someone at Microsoft said, "Yeah, we'll only patch Windows 8 for the next seven years, but that sounds like a good idea."  Is this not much of an issue?



STEVE:  Okay.  So really that's a great point.  The way to think about this, I think, is sort of as a hierarchy of levels of protection of certificates.  So the root CAs are assumed to have extremely good security.  We've covered instances where they have unfortunately failed to demonstrate that.  But the presumption is they're like security anchors.  They've got really good security.  They've got the keys to the kingdom really well protected.  And for that reason they're willing to - essentially they issued themselves certificates with this far expiration date.  You can understand the motivation for doing so because it's somewhat burdensome to get their certificate into every platform that needs to trust the certificates they sign.



Now, probably we're seeing more of an historical, sort of an historical bias because, in this day and age, OS versions are changing.  We've got on-the-fly updates.  The whole connectivity means that in fact it would be not a huge deal for CAs to have shorter-lived certificates that they themselves were replacing in all of the systems that need to trust them.  But that's not the way the world is.  The world still has really long-life certificates.  The danger is that their private key would get compromised.  And, I mean, that's really the secret that they're keeping is the private key associated with the public key, which is part of the signature of their certificate.



So what's happened is, and this is maybe about 10 years ago, it used to be that the CAs were signing certificates with their root, and everyone got a little concerned because essentially that meant that their private key, that thing that is there, they absolutely have to keep secret because, if they don't keep it secret, every browser will remove their certificate, and every certificate, every customer certificate they've signed with that would be invalidated, creating a disaster.



So the danger was that that master secret that absolutely cannot be allowed to escape, that is being used every time they sign a certificate, meaning it has to come out to play.  So the philosophy of, like, how to protect themselves changed, and they created intermediate certificates.  So that today, for example, you don't see the end certificate of the server signed directly with the root.  Instead, you'll see it signed with an intermediate certificate, and that will have a much shorter expiration.



When I saw the question I thought, I wonder what Mozilla is doing?  So I went over, I did https://www.mozilla.org.  Up came an EV certificate.  I clicked the link.  I saw that Mozilla gets their certificate from my favorite provider, DigiCert.  And sure enough, the root certificate is 2037, and there is an intermediate that expires 10 years sooner than that, the idea being that, now that the root has signed the intermediate, and that intermediate has certificate signing authority, then the root can be literally stuck in a vault so that it never, they never are endangering their root, the root's private key from escaping.  It only has to sign the intermediate certificate once, where that certificate has itself certificate signing privileges.  Then they lock the root away, never to need it until they need to renew their intermediate certificate.  So that gives them much more safety.  The only thing that then could escape would be the intermediate certificate.  And while that would not be good, it's way better because then none of the browsers would need to disavow the root certificate.  They would just need to get another server certificate signed with a new intermediate certificate.



So anyway, that's the story.  The roots do have long life, under the presumption that the security of the CA is going to be extremely good.  And the incentive is for it to be extremely good because literally the entire business model of the CA is banking on it.  We discussed, I think it was DigiNotar, years ago.  They were found to be signing fraudulent certificates.  They're now bankrupt.  They were bankrupt instantly because of their conduct in the handling of that leak.  So no certificate authority wants to allow that to happen.  The use of this sort of three-stage chain allows them the ability both to have an anchor which lives effectively forever, but at the same time not put it at risk by sort of moving to an intermediate certificate that they are able to - that has a shorter life because they only need to resign that with the master every decade or so.



MIKE:  Hmm.  All right.



STEVE:  Really cool system.



MIKE:  Very, yeah.  All right.  Question #5, Joshua in Michigan wonders how a student should safely report a vulnerability.  He writes:  Hello, Steve.  I'm a huge fan of the show.  I started taking classes in computer science when I was in the eighth grade, and I can say you've been a big part of my inspiration and interest in computer science and security.



I'm contacting you because I found a security flaw in an online class that I am taking.  I'm still a high school student, but I'm taking an online Spanish class, so I have time to dual enroll and take computer science classes at my local university.  In my computer science class we've been working with web development, and I was curious as to what software my class was built on.  So as I was inspecting the source, I saw a CSV file.  It was named a random number, so I was curious and downloaded the file.  It was under the overview directory, so I thought it might be an outline of my assignments for the semester.  But the file actually contains the grades for every student in my class.  Wow.  



Obviously, this is a security flaw, and I know I should report it.  The biggest concern is how I should go about reporting it.  I've read about too many white hats who've gotten in trouble for responsibly reporting vulnerabilities.  I'm still in the class right now, and I don't want it to affect my enrollment.  If they dropped me from the class, I don't know how it would affect my grades, and I don't know how I'd be able to make it up.



What do you think is the best way for me to go about reporting this?  I looked on their website, and I couldn't find a logical place to report it, either.  I want to make sure the issue is dealt with, so I don't just want to send it to their general sales query email.  I really appreciate you looking into this.  I know you're very busy, but I'm both conflicted and concerned about how to approach this, and I need some help.  Thank you.  Joshua.



STEVE:  I thought that was really interesting.



MIKE:  Yeah.



STEVE:  And, first of all, Joshua's completely correct.  I should mention that he used his full first and last name, and I removed his last name because there's a lot of Joshuas in Michigan, and there's no need to narrow him down.





Okay.  So he's found a problem, and he's completely right that, unfortunately, as he knows from this podcast, we're often reporting on unfortunately misinformed or poorly informed bureaucrats who blame the messenger, shoot the messenger, when they absolutely should not do so.  Here's what I would recommend, and I spent a little time thinking about this.  First of all, I think you have to go old-school.  You don't want to do anything in email or PDF or electronic because it's just - it leaves a trail.  So I would create a short note that explains the problem, with enough technical detail that whoever is in charge of this will understand what it was you found and how to fix it.  I would also print a copy of the CSV file.  That is to say, part of this note wants to get their attention.  And if they see a printout of all the grades of the students in the class, that'll get their attention.



However, do not print it on any printer that you own, especially a laser printer, because unfortunately we know that printers are - the term is "watermarking."  They actually don't use water, they use yellow dots if they're color laser printers.  And they actually salt pages with yellow dots to identify the printer that has printed it.  So I would say maybe create a PDF or just a Word doc or whatever, whatever format you're comfortable with, and take it to a printing facility and pay cash, just to have, you know, like a Jiffy Quick or a FedEx printer or I can't think of the really famous one.  We've always had one on the West Coast.  Kinko's is the name I was trying to think of.



Anyway, so get this printed on paper, fold it up, stick it in an envelope, and old-school address it to somebody who is in authority, and send it to them.  I think that's the best thing you can do.  It will be anonymous.  There will be no electronic trail that can be traced back to you.  They will get the information.  They will believe what you've told them because right there will be a printout of the CSV.  And I think that stands the greatest chance for getting this thing fixed and for keeping you completely free of any ridiculous claims of being a bad guy.



MIKE:  And it's kind of a sad fact that an honest person trying to do the right thing has to be very careful and cover their tracks, as if they were doing something wrong, when in fact quite the opposite is the case.



STEVE:  Yeah, it really is.  And, I mean, we see this over and over.  People really get themselves in trouble, just from trying to say, look, I'm just trying to help you.



MIKE:  Yeah.  All right, well, Question #6.  An anonymous listener in Sweden shares his chilling true story:  Hi, Steve and Leo.  Blah blah blah, loving and using my SpinRite corporate license every week at work.  A small story reminding why you should backup every day:  When I got to work this Monday, a support request came from my boss that had noted that he did not have any folders left in Outlook, only the standard folders, and all mail had moved to the inbox and marked as unread.  After some investigation I noted, for a change, the trouble was not with his hard drive, so I couldn't just use SpinRite to save us again.  The reason that all mail had moved was that someone had broken in through the RDP, the Remote Desktop Protocol, and encrypted every Office document and all Outlook files during the weekend, then left a ransom note - over 600 of them, one in every folder.



So when Outlook started and did not find its standard PSD database file, it created a new one and re-downloaded all mail from the POP server.  Thus, they are all "unread."  And wouldn't you know it, the backup of my boss's machine had stopped silently a long time ago, and no one noticed.  So we have saved the encrypted files in case a time comes when the encryption can be broken, but we don't have much hope for that.  The moral of the story is have SpinRite for recovery, and verify your backups for when it's NOT the hard drive that crashes.



STEVE:  Yeah, I thought this was interesting.  I just wanted to give our listeners a heads-up about this form of attack.  If this was in 600 different folders, it sounds like this is some sort of an automated tool which is cracking through RDP.  If I'd had more time this morning, I would have dug into RDP protocol because I do remember not long ago, in the last few months, there was a patch that fixed that, that fixed a problem.  It must then be that someone got into their network or that RDP was exposed.  It runs on a well-known port, and it's not something you really want to have available out on the public Internet.



So, I mean, it's like the old days when servers used to have services running and all their ports exposed, just by default, and people were blocking the ones they didn't want to have access to, or they didn't want to have anyone outside on the Internet to have access to.  And we inverted that so that we're only allowing access to the ones we do want people to have.  For someone to be able to get from the outside to his boss's remote desktop protocol port is frightening in itself.  So for what it's worth, I'm sure there was a patch in the not too distant past that probably fixed what this attacker found, was probably scanning for on the Internet, found and then leveraged.  So make sure you don't have RDP exposed.  It's too dangerous.



And, yeah, and do verify that backups are actually happening.  You know, we do hear stories about this from time to time where a backup system silently stops doing its work, you know, who knows why?  The medium fills up, or it's generating errors to an email address that has changed, and no one told the backup server to update its reporting email.  One reason or another, it doesn't happen.  And then something collapses that absolutely was depending on there being a backup.  So, yikes.



MIKE:  Well, Steve, here comes the Wild One:  Jim M. in Northern Virginia provides us with the source of the name "Regin."  Am I saying that right, Steve?  Is it Regin?



STEVE:  You know, we didn't know.  I was assuming it was because I was guessing it stood for Registry Installer because that's the technology.  Now we know what it stands for.  You're about to tell us.



MIKE:  Okay.



STEVE:  And technically, I guess, if we were Norse, we would know how to pronounce it.



MIKE:  And we are not, and so don't.  Let's go with Regin.  And so, Steve, in case you haven't seen, in Norse mythology Regin is a cunning dwarf who raises the hero Sigurd as his own son - I'm going to get all this wrong, I guarantee it - as his own son in order to use him as an instrument of revenge against Regin's deceitful brother, Fafnir.  Having become a dragon after stealing the family's hoard of gold, Fafnir is killed by Sigurd, who then goes on to kill Regin when he learns that his adopted father used him to avenge his brother's crime.  Now the old Norse dwarf has a second life as a newly discovered, highly advanced piece of malware, techspeak for software used to damage or infiltrate computers.



STEVE:  So anyway, Jim provides a link to a blog at ForeignPolicy.com where it explains this.  And so, yeah, we were fumbling around with the name last week, not knowing what to use.  Now, if anyone knows, at least we know where it came from.



[blog.foreignpolicy.com/posts/2014/11/24/this_malware_may_have_gotten_the_nsa_caught_with_its_hand_in_the_cookie_jar]



I did want to mention that there's still no confirmation, but there's very, very strong rumor which has not been confirmed that, as we suspected, that the NSA and also the U.K. intelligence services were probably using this.  More disturbing is - and again, no firm confirmation - but that the AV companies have been aware of this for years and assumed it was Western state espionage malware and kept quiet about it.  Which, if true, would be disturbing because it would say that they understood that this malware existed, that nobody wanted it in their machine, but they were essentially being complicit with the spooks who had developed and deployed this and weren't pointing at it because that would of course render it useless.  So again, no confirmation of any of that, so we just have to call that gossip.  And I don't like to do gossip, but I think it's necessary to share what the rumor mill is churning.



MIKE:  Yes.  And again, if you know the pronunciation, please help us out.  We need it on Tech News Today, as well.  We don't know what to call this thing.  It's a Norse dwarf.  We've got to call it something.



Joseph Laba in West Bloomfield, Michigan wondered about CryptoLink:  Hi Steve.  Just wondering, with the cessation of TrueCrypt support, is there any chance that CryptoLink might be revived?  I'm somewhat familiar with its history and why it was shelved, but haven't the successes of TrueCrypt, LastPass, and other TNO systems demonstrated that it's feasible to do it without sacrificing any principles or convictions?  Thanks.  Long-time listener and SpinRite owner, Joe.



STEVE:  Okay.  So just to recap, CryptoLink is a project I spent a good deal of time, actually, a couple years ago, spec'ing out and designing.  The idea behind CryptoLink was that it was Trust No One and had a whole bunch of features which to me seemed like any VPN ought to have them, but none of them do, which would ultimately mean that you would always be able to succeed in establishing a connection.  And there were just a whole bunch of other neat things about it.  The plan at the time was that I would invest a huge amount of time creating another commercial product for GRC to go along with SpinRite.



Then I saw the handwriting on the wall of what's happening with our intelligence agencies.  And it felt to me like we were approaching a time when Trust No One irreversible encryption solutions could actually become illegal.  And in fact there was a story just today, and I can't remember the context of it.  It was there's an old 18th-century law, something about writs, which courts have just started to use, that is, the federal government is starting to use a writ or to have judges issue them as a new way of forcing companies to decrypt phones, like forcing Apple to decrypt their iPhone and so forth.



Clearly, we're reaching a tipping point where we're going to find out what individual privacy rights are.  Apple famously with iOS 8 has deliberately designed a system that they are asserting they are unable to decrypt.  And the NSA lead, the new head of the NSA has unfortunately said that Apple is marketing their technology to pedophiles and organized crime and so forth.  I mean, way over the top rhetoric, but that's what this has come to.



So here's where I stand.  I'm busy finishing SQRL.  Then I am busy finishing SpinRite 6.1 and 6.2, which will add support for USB features and push SpinRite a little bit further.  I want to get 6.1 out without delaying it for the work I want to do for 6.2.  At that point we'll see where we stand.  I don't think I will ever do CryptoLink as a commercial product.  But if I always plan for it to be freeware, then I won't mind if I just have to, I mean, I don't know where I would stand.  I guess, if I'm not selling it, if I just put it out into the world, then it's freeware, and people can use it, and we'll just have to see.  Maybe we will have something definitive by then where we decide that it is going to be safe for companies to create encryption which is unbreakable.  Right now, I think that's still up in the air.  And so where I am with CryptoLink is up in the air because the only way I would do it, if it was unbreakable.  There'd just be no point in doing a brand new VPN - well, I just wouldn't do it if I had to make it - if I had to put a backdoor in for anyone.



MIKE:  All right.  Well, Question #9, Russell Gadd in the U.K. offers a terrific tip about determining what computer or tablet to buy:  Steve, one of the lurkers in your newsgroups, Neil Hutton, is a techie who fixes people's PCs.  He has created an excellent website advising ordinary folks what to buy to avoid malware - PCs, tablets, et cetera - mainly avoiding Windows.  It would merit a mention on Security Now!.



STEVE:  Okay.  So I went there, and I am very impressed.  The URL is HowToReplaceYourPC.com.  And I want to commend this, maybe not to our listeners because they probably already know, but to their family members.  Unfortunately, we just missed Thanksgiving, because this would have been a perfect time for you to print this on everyone's napkins when your family convened.  But we do have Christmas coming up:  HowToReplaceYourPC.com.  I am very impressed.  I like the style.  I like the design.  It's funny because it's organized correctly.  There's as much there for digging as deeply as you want.  He says he's going to - his job is dealing with people's PCs of all makes and models that are broken.  And he says, okay, if you absolutely don't have any time to spend, get a MacBook Air.  Period.  But if you don't - and so if you're unwilling to go any further for advice, do that.  But you may not find that it fits as well as what you could learn about if you dig a little deeper at this site.



So anyway, as I said, I'm very impressed:  HowToReplaceYourPC.com.  This is for all of the relatives and friends and family who ask us these questions.  Just tell them, go here, and you'll be able to help yourself, because I think this guy, Neil Hutton, has done just a beautiful job.



MIKE:  Wonderful.  Now, a quick bit of advice.  He mentioned that, if you don't know what else to say, just go for the MacBook Air.  Wouldn't you think that, for avoiding problems, a Chromebook would even be better than a MacBook Air?



STEVE:  Yeah, I didn't have enough time to spend on his site because I just, again, encountered this during my read through my mailbag this morning, preparing the notes for the podcast.  I agree with you, and I'll bet you he even says that.  The question would be that people would probably maybe run into things it won't do.  And so the advantage of the MacBook Air is, of course, you're - okay.  First, nothing does everything to the degree that Windows does.  But at the same time, nothing is more dangerous than Windows.  For example, the malware, Regin or whatever it's called that we were just talking about.  That's Windows-only malware.  So if you have a Mac, Regin can't get you.  And most of the malware that is out in the world is Windows.



So I think there's like a set of stages where you back away from being able to do absolutely everything you could ever want, but also having absolutely maximum exposure to malware.  You step back a notch to the Mac.  There are going to be some things that you'll run across that are Windows-only.  The good news is much more things now are also available on the Mac, or probably a version or a solution that does the same thing for the Mac.  And the level of danger you have is backed off.



But, for example, and I'll bet you he covers this, if, as you certainly know this, Mike, if all your grandmother is doing is baking cookies and surfing the 'Net and doing email, and she uses Gmail, yeah, a Chromebook would be absolutely, first of all, much less expensive, and sufficient.  So, and I think that's what this site does.  The idea is it carefully matches your needs so you're not spending more money than you need to, you're not buying capability that is going to be unused and will only end up getting you in trouble.



MIKE:  All right.  Sounds like a great, great site.  Can't wait to check it out myself.  Last question.  Bryce Klippenstein in Calgary, Alberta, Canada wonders about the Security Now! show notes.  He writes:  I have noticed that the links to the show notes almost always seem to go to a blank wiki page.  Are the show notes only posted for some episodes, or is there somewhere else I should be looking for the show notes?  Thanks.



STEVE:  Okay.  So I don't know what, well, okay, I do know what it is.  It's that I've been referring much more heavily during the podcast to links in the show notes.  The show notes are what I'm looking at right now; and, Mike, what you're looking at; what Leo is always looking at.  They're always at GRC.  However, the podcast that TWiT publishes has up until now just linked to a blank wiki page, which hasn't been what we should have been doing.  I just sent email because I must have encountered, like, one out of every two pieces of email in the mailbag were people saying "Where are the show notes?  You keep talking about the show notes, but I click on it, and it's a blank wiki page."  So I've just asked the producers to start using the GRC URL in the podcast feed.  So from this podcast, 484 on, hopefully they will do that.



If it turns out that you still get the TWiT.tv link, GRC always has them.  I tweet them at the beginning of the show.  They always exist because it's what we run this podcast from.  And the entire history of them is on GRC.  So if you go to GRC.com/sn, that's the Security Now! page.  So the first icon is the high-bandwidth audio.  Second icon is the audio I recompress for Elaine at quarter the bitrate, at 16Kb.  The third icon is the show notes.  That's a PDF with all of the stuff and clickable links.  So you can always find them there.  But I bet you now that having finally thought to bring this to the attention of the fabulous producers over there in TWiT Land, the link to GRC's notes will now be in the podcast feed.  So Bryce, thanks for mentioning it.  Everybody else who asked the same question, I saw you all, and it finally got me to ask TWiT to fix this.  So I think we're going to be okay now.



MIKE:  Fantastic.  Well, Steve, how do you end the show?  Do we have any final comments?  Any other sort of...



STEVE:  We just tell people that you can find the podcast in their podcast feeds, that they're at TWiT.tv/sn, that I have - oh, that also Elaine transcribes them, so text versions for those who want to read along are at GRC.com/sn.  And the 16Kb quarter-size ones for those who are, as Leo puts it, bandwidth impaired, are also available at GRC.com.  And that next week we're going to be doing a deep dive, unless, I mean, the world could - the sky could fall.  Hopefully the bad guys are taking the holidays off, so maybe nothing bad will happen in the meantime.  Assuming that nothing comes in to intervene, we're going to do a deep dive next week into the technology that has been developed and confirmed for deanonymizing Tor users who are specifically using Tor because it's an anonymizing service.  And we're probably going to call the podcast "De-Tor."



MIKE:  That's fantastic.  And of course Steve and Leo do Security Now! at 1:00 p.m. Pacific, 4:00 p.m. Eastern, 2000 UTC, every Tuesday, right here on the TWiT network.  Don't miss it.  Steve, thank you for tolerating my amateurish hosting, co-hosting of the show.  It's been a real...



STEVE:  Yeah, you did a great job.  And thank you for filling in.



MIKE:  Well, thank you so much, Steve.  And again, I can't wait for that next week's issue.  I'm really, really curious about that.  It's really one of the most fascinating stories of the year, in my opinion.  So I'm looking forward to that.  So thanks again, everyone, for tuning in.  And you can tune in for Security Now! again next week on Tuesday.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#485

DATE:		December 9, 2014

TITLE:		Expensive Lessons

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-485.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events, including the Turla advanced persistent threat for backdoor for Linux.  We then look closely at the very expensive consequences of the lax security measures employed by Target - and their massive late 2013 point-of-sale terminal breach - and Sony's whole-corporation network internal data dump and disclosure.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  There's lots of security news, including a Linux exploit you're going to want to know about.  And then we'll get into the Sony hack.  My goodness, the detail.  We still don't know who did it or why, but Steve has some thoughts, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 485, recorded December 9th, 2014:  Expensive Lessons at Sony.



It's time for Security Now!, the show that covers your security, now.  What?  Huh?  And - good name, eh?



STEVE GIBSON:  Or soon.



LEO:  Or soon.  In this case we're going to look back a little bit.  But Steve Gibson is here.  He is our Explainer in Chief, the man at GRC.com, creator of the world's first antispyware tool and in fact kind of the discoverer of spyware in many respects.  He's also the author of SpinRite.  Hi, Steve.



STEVE:  Hey, Leo.  Great to be with you.  I had promised our listeners we were going to do a deep-dive episode.  But I've seen so much email and Twitter traffic from people saying how are you not talking about Sony, that I'm like, we can't not talk about Sony.  And I want to do more than just say, oh, it was bad, because that sort of misses the depth of the badness.



LEO:  How bad it was.



STEVE:  Oh, my lord.  I have, and I want to share, just I want to scan through the analysis of the files which have been released to date, which themselves is a small piece of the total 12-plus terabytes of data.  And this is a situation where the guys who took it are having problems finding the diamonds in the rough because there's just too much.  And so they've done things like - and the press has been confused because the press, you know, well, they're the press, you know, and we're about technology.  So it's clear from what we're seeing that they've done things like scan for the word "password" in the filenames and then pulled all of the files from all of the employee workstations that had the word "password" in them and aggregated them and released them.



LEO:  Actually, I do think that that was done by the bad guys.



STEVE:  That's what I said, yeah.



LEO:  Yeah, yeah.  The bad guys put out a Pastebin that they gave to the press, not to the public, but gave to the press.  And they highlighted, like they put in a folder all the stuff they thought was really egregious.



STEVE:  Right.  And so the problem is it's like they're being flooded with the wealth of what they have.  And so every few days they've been releasing another 20GB or so.  I mean, it varies depending upon what.  So I want to talk about that.  But then of course we have to talk about Sony's background and what could be done to prevent this.  And there are some other little techie nuggets that have come out that I think are, like, just whimsical and hard to believe about this.



But the episode is titled - oh, anyway, so the point is, as we do, I want to cover the issue of Tor not being nearly anonymous as we had hoped and as many people wished it was.  There was a very nice academic paper that came out that explained actually what a poor job it does.  If anyone really applies their intention, it can be largely deanonymized.  And of course we know that there are entities now out on the Internet with lots of funding that certainly have intention to deanonymize people on the Internet.  So we will get to that when the news allows us to.



But I titled this podcast "Expensive Lessons" because I want to talk about two things in our main, you know, after we cover the more newsy stuff.  And that is also some news that has arisen about Target, where it was like one year ago that they suffered that, what is it, 40 million of their customers' credits cards escaped, and 110 email addresses and other personal information.  And of course we've got our regular news of stuff that happened during the week.



So we're going to talk about POODLE, which is an attack, of course, we recently discussed, which turns out is biting us yet again.  That was the one that caused us to run away from SSLv3.  Turns out that switching that off doesn't completely solve the problem.  It can still affect some implementations of TLS.  There is something we've discovered, an advanced persistent threat backdoor on Linux for the first time, which - or prominently for the first time.  Judge Posner, whom we've talked about through the years, who's a pretty well respected U.S. District, I think he's Seventh Circuit Court judge...



LEO:  Yeah, yeah.



STEVE:  ...said some scary things.  And Cory Doctorow was just wonderful in response.  And we have some miscellaneous stuff, and then we'll get into talking about Target and Sony.



LEO:  I want to say Posner was the judge in the Microsoft case; wasn't he?



STEVE:  For some reason his name is so...



LEO:  His name is so familiar.



STEVE:  So familiar, yeah.



LEO:  Yeah.  But I can't place it.  But,  yeah.



STEVE:  So it turns out that the POODLE attack is not completely mitigated as we had hoped by the frantic disabling of SSLv3. Just to remind our listeners, because we've covered so much territory on this because there's so much going on, the problem - the POODLE attack was the result of the fact that the SSL standard defined the two operations which must be performed, that is, authenticating the data and encrypting the data backwards.  In SSL, they authenticate first and then encrypt, which means that, when you are undoing that, when you're wanting to turn the information back into plaintext, you reverse that process.  You decrypt first, then you authenticate.  Had it been done in the proper direction, the proper sequence, the first thing you would do is authenticate.  And if you were trying to play any games, that would fail, and it would just be over.  This whole exploit would never have happened.



But because you're decrypting first - and what POODLE uses is block ciphers.  Unfortunately, the stream ciphers like RC4 have been pretty much discredited.  No one thinks they're sufficiently secure, a stream cipher meaning that you're able to encrypt individual bits at a time.  In a block cipher, because the underlying crypto system itself takes a block of some number of bits, typically 128, so that's 16 bytes, it takes 16 bytes at a time and, under the influence of a key, translates that entire set of 128 bits to a different 128 bits.  Well, that means that you always have to give it multiples of 128 bits or 16 bytes.  But if the data you're wanting to encrypt doesn't fall on an exact even multiple, then you have to come up with some way to pad that data out to an even multiple in order to encrypt it.



So therein lies the problem is that SSL never specified what the padding had to be.  It just said "padding" because the argument was, well, it doesn't matter because it's just superfluous anyway.  So do whatever you want to.  And some various schemes were created for creating the padding.  Well, it's that laxness in the specification that some clever researchers figured out how to exploit.



So this wasn't happening in the wild, but it was discovered and went public that it was possible, meaning that people then could do it.  And the attack would be you get some code in your browser that would make something like 4,096 queries.  And that would give you a byte of header data, which is still a lot of work to do, but it's feasible.  So, as our listeners will remember, we scrambled around throughout the industry and removed SSL3.  This latest update of Firefox that we described and we discussed last week, I think it's v34, completely removes SSL.  Chrome has deprecated it and is, a version or two from now, they've said they were going to remove it.  Okay, so people are turning it off all over the place.



What just came out is that as many as 10% of the Internet sites, tending to be the major ones for a reason I'll explain in a second, have remained vulnerable.  And the reason is that there are still, even when you turn off SSLv3, that means you're always going to be requiring TLS v1.0, 1.1, or 1.2, which is the three versions of TLS we have so far.  And that, the TLS does rigidly specify what the padding data must be.  It turns out that, probably due to the history, that is, TLS was - probably the code actually used to implement an implementation of, create an implementation of TLS was inherited from SSL because it's almost the same.  It's just additions and tweaks here and there, and version numbers in the header and so forth.



It turns out that many instances of TLS do not check for the adherence to the specification of TLS that specifies exactly what the padding must be.  The fact that they can no longer be played with by a hacker neuters the ability for POODLE to work, unless the stack that you're trying to probe doesn't check on the server side.  It turns out that, right now, today, 10% of the Internet sites don't check.  And they tend to be the larger ones because they are those sites which are behind sort of big iron load balancers which themselves terminate the SSL or TLS connections.



So there's a company called F5 that makes one of the more popular frontends, so the idea being that behind this box are a whole bunch of servers.  And this is the first box you come to when your fiber optic comes off the backbone through a router to this thing.  So it's all your traffic.  But it actually has your SSL certificate or TLS certificate, your website's security certificate, and it's got SSL/TLS security acceleration hardware, good random number generators, everything it should have except its code, its TLS code didn't get changed when we rifled through the whole industry.  It may have had SSL3 disabled in it.  But it turns out that, because it's an appliance, it didn't get the same OS updates as everybody else.



And I don't mean to pick on F5.  There's also one called A10 which is a different manufacturer and company, same problem.  Neither of them are checking, when they receive incoming traffic under the TLS protocol, for the padding adhering to the TLS specification.  So POODLE still works against them.  The companies have been notified.  F5 already has an update, which I'm sure they're pushing out to their customers quickly.  So anyway, that's - it hit the news because it just came out.  I see in fact Adam Langley blogged about it 12/8, which is yesterday.  So that's just happened.  Again, probably not, you know, it's not the end of the world.  The instances where this is a problem are being found, and it looks like it's a few major instances where they're not OS-based TLS stacks, but rather turnkey hardware frontend stuff.



The other piece of interesting news is - it's called Turla, T-U-R-L-A.  I couldn't ever find where the name came from.  Everyone just sort of started using it.  It is an advanced persistent threat, an APT, targeting Linux in an interesting backdoor technology that I'll get to in a second.  It turns out that it's part of another state-sponsored major espionage malware suite, but it doesn't look like it's our state this time.  It looks like it's Russia.  We know that the programmers work nine-to-five hours, which sort of - and that's from timestamps in the various modules of code that have been found.  Nothing seems to happen on the weekends.  They're home playing with the kids.  And they seem to be in UTC+4 is the time zone that they're in.



Instances of, okay, I've jumped over the part where I should say that it is at least six years old.  Pieces of the Windows version - because this has always, up until now, been a Windows-only malware.  So the presumption is a Linux backdoor module was added to extend its breadth as an add-on to this advanced persistent threat that's been around for at least six years.  It was being called - Kaspersky and Symantec had it on their radar for a while.  And it was being called Uroburos?



LEO:  Uroburos.



STEVE:  Uroburos.



LEO:  Uroburos is the snake that eats its own tail.



STEVE:  Yes.  And in fact also known as the Snake.  And people who can't pronounce strange words...



LEO:  It's a strange word.



STEVE:  ...prefer calling it Snake.



LEO:  Yeah.



STEVE:  So this thing has been Windows 16 and 32-bit - I'm sorry, 32 and 64 bits only.  It was spotted 32 times in the Ukraine since 2010, 11 times in Lithuania, four times in the U.K., and then a handful of times in the U.S., Belgium, Georgia, Romania, Hungary, and Italy.  So sort of more of a Western and Western-aligned feel than, for example, the other major state-sponsored discoveries that we've been talking about, which seem more like they're from us aimed in the other direction.  This stuff sort of looks like it's coming at us.



LEO:  Well, you saw that not only the Russians but the Koreans have this elite core of military - the North Koreans, military hackers.



STEVE:  A huge number.  Wasn't it, like, 1,500 of them?



LEO:  1,800 in the Section 121 group.  And they're well maintained, trained from youth.  So every - I would bet every state has at least some elite core of hackers.



STEVE:  When we look at what this stuff can do, I mean, we did a full coverage of it two weeks ago, it is frightening.  I mean, it's, like, it's no longer science fiction, although, I mean, it feels like we're talking about science fiction.  But what we're talking about is, as we have said, and of course we will be talking about this when we discuss Sony here in a minute, security is alarmingly porous.  And the more pressure you put on the attack surface, the more opportunity you can find to get in.  In this case, the Windows components, which have traditionally been used, have used several known zero-day exploits to get in.  They've also attempted to get in using long-since-patched exploits for Windows.



But also this system sets up a very - an extreme array of watering hole attacks.  So they set up fake websites where they have, for example, videos that they lure their targets to through phishing mail that say, oh, you don't have the latest version of Flash.  Click here to update your version of Flash.  And of course what you're actually doing is downloading the malware into your machine.  So these are highly, you know, very much like the state-sponsored attacks.  This thing is meant to be super stealth, to stay under the radar for a long period of time, and to be aimed at specific targets in order to get into their networks.



So what happened is just in the last couple days, a couple samples of some Linux code were posted to the malware testing sites.  And that tripped some of the alarms of the companies that have been monitoring this stuff for a while.  What was found was a new Linux offshoot of this.  So for six years it's been Windows-only.  Now, this is based on, and this is what this Turla name, T-U-R-L-A, is referring to, based on actually a 14-year-old open source Linux malware, cd00r, which was then extended and modified.  But in looking closely at it, they've seen pieces that are very familiar and old.  So this stuff has been reused and recycled.



It is big because it is static.  It's compiled from C and C++.  It's an ELF executable with the symbols stripped from it to make it a little less easy to reverse-engineer.  But whereas most code is - it's called "dynamically linked."  Famously, Windows is DLLs, dynamically linked libraries - the idea being that you can assume a bunch of things that you need will be present on the system where you're running.  And, if not, you can tell the person running the system, please update your GNU C library, or we need to have OpenSSL or libpcap installed.  Well, in this case, this thing needs those modules, but it can't ask the victim to install them, so they're statically linked into it, making this thing 800-plus K in size.  So it's a big blob that gets into your system.



What's interesting about this is it does use an older version of OpenSSL that is bound into it, v0.9.6, which is actually quite old because 0.9.8 has been current for a long time over in the 0.9 track.  And it uses the libpcap network capture library in order to monitor the traffic on the victim's computer.  Significantly, though, it does not require elevated privileges to run, which is unlike many of these things, where it's got to be run as root or admin in order to get the hooks that it needs in.  In this case, a non-privileged user who runs this by mistake, who's, like, tricked into clicking on something to download this, is all the privilege this thing needs.  No root needed.  And it has some stealth capabilities.  It disappears from the system, even though it's still running, so it won't show up when someone looks to see what processes they've got running.



And the way it works is interesting, and it gives us some clue as to what kind of machines it would be installed in.  It monitors all incoming network traffic using its pcap interface in order to see what's coming in.  If it sees a particular pattern of bytes in the header of a TCP packet - and, for example, in the case of the TCP packet, it's a specific ACK number.  We've talked about the TCP protocol years gone by.  The ACK is a 32-bit value which essentially acknowledges, thus the word, or the abbreviation "ACK," it acknowledges the highest numbered byte that has been received from the sender so far over the TCP connection.  And so it will tend to jump by the number of bytes in sets of packets that it receives at a time.  It doesn't respond to every single one.  And packets typically have, what, 1,500 bytes or so.  So it's going to be jumping through this 32-byte number space.



But if a specific TCP packet arrives with essentially what is - it's called a "magic cookie value," a key, or a UDP packet with - similarly, UDP doesn't have an acknowledgment, but it does have other stuff in the header.  So if there's a match on either specific TCP or UDP data, this thing - oh, and it's using a raw socket in order to be able to monitor everything coming in.  This thing creates a standard communications socket and opens an outbound connection to the IP address from which that special magic packet was received and connects it to a terminal session and awaits commands.  So it is a stealth Linux persistent backdoor which - and what this tells us is, this means that it's not going to be useful on some Linux machine on an Intranet or in the back room somewhere.  It's going to have to be a machine like a server which is Internet-facing such that public packets are able to get to it unmodified because, for example, if it were behind one of these F5 boxes that is doing frontend filtering, the F5 box terminates the connection.  And then, essentially working like a proxy, it opens another connection.



So that's a perfect example of something that would prevent the raw incoming data from actually reaching the server.  But so it has to have access to the public-facing Internet.  And when then the bad guys know that they've managed to get this - they've infiltrated some organization, a company, a government, offices, wherever they're trying to get in, and that organization has some sort of public-facing server.  It could be email, for example.  It could be web.  It just doesn't really matter that much.  They then, when they want to execute whatever, basically whatever commands they want to on that machine, they just - they send it a magic packet containing this data.  And then they will note that, within a second, an incoming connection from that victim IP is asking to open a connection.  They accept that connection, and they're looking at a command window to that machine in that organization.  And this has been found operating in the wild.



LEO:  Oh, it's a zero-day.



STEVE:  Well, it's not itself a vulnerability.  It appears to be an extension to this existing advanced persistent threat malware, which itself is about six years old, but we've only just run across this.



LEO:  Yeah, guess you can't call it a zero-day if it's six years old.



STEVE:  Well, it's a new component of this whole attack platform.  And what we're seeing in these advanced persistent threats is they obtain a foothold or a beachhead in the victim network; and, over time, they'll browse around.  They'll see what's in your network.  And it may well be that they get in via Windows through an exploit, through a phishing attack where they get an employee to go to a fraudulent website because it's something that they've already determined the employee would want to do, lure them there.  The employee downloads something in Windows.  But then once they're - and so that gives them their Windows position.



But then they look around and go, oh, look, this organization has Linux servers, like Linux-based web servers.  So then they will use their Windows-based foothold to download this Linux malware and then install that through the Intranet into the Linux server.  And that gives them another access into this corporation through the public server.  And it might be something, for example, that people are less likely to check.  They might have a Linux server in the closet where they're not backing it up frantically, or it's not having antivirus stuff scanned on it the way their Windows-based user workstations are.  So it gives them a very potentially potent additional foothold into the organization.



So our friend, whose name is so familiar to us both, Judge Richard Posner....



LEO:  Oh, I should have looked it up, yeah, yeah.



STEVE:  ...with the Seventh Circuit Court.  He was speaking at, just recently, I think it was last Thursday, at the Georgetown Law Cybercrime Conference.  And among other things he said:  "It should be illegal to make phones the government cannot search."



LEO:  [Frustrated sound]



STEVE:  I know.  I know.  He said also, if the NSA wants to vacuum...



LEO:  What is the legal justification for that?  I'd really like to know.



STEVE:  I know.  "If the NSA wants to vacuum all the trillions of bits of information that are crawling through the electronic worldwide networks, I think that's fine," he said.



LEO:  Yeah, why not?



STEVE:  And he went on to say, and this is the one that really got me, in fact Cory Doctorow was like, I mean, I'm sure he had to recover.  Posner said:  "Privacy is mainly about trying to improve your" - okay, this is Judge Posner, Seventh Circuit Court.  "Privacy is mainly about trying to improve your social and business opportunities by concealing the sorts of bad activities that would cause other people not to want to deal with you."



LEO:  Oh, that's an interesting statement.  I mean, this guy's an intellectual.  So he's thinking about stuff.  He has said weird things before, including that he thinks that regulation of the buying and selling of children is a bad idea, that the free market should allow - so he's known for being outspoken.  But I think a lot of this is kind of intellectual exercise.  I hope.



STEVE:  Ah, well, maybe that was the, I mean, Cory did not take this lying down.  There's a link here, a BoingBoing.net link in the show notes.  And, by the way, I'm now including the link to the show notes with my communication every week to your guys, Leo, so that they can put that in the podcast feed so that everyone's able to get it more easily.



LEO:  Yeah.  The show site, which is TWiT.tv/sn, each episode should have these links.



STEVE:  Right.  And from now on they will.  Anyway, Cory wrote:  "Posner conflates secrecy with privacy, another nonsense."  He says, Cory says:  "Your parents did something un-secret to make you, but I'm willing to bet that Posner doesn't want his own non-secret, baby-making activity to be recorded and viewed by strangers."



LEO:  There you go.  He might, though.  You don't know.



STEVE:  Secrecy versus privacy.



LEO:  He was - the reason we connected him with the Microsoft case, he was the private mediator brought in, agreed to by both the Department of Justice and Microsoft, at the end of that case.



STEVE:  Ah, okay.  Okay.



LEO:  So he was the guy who was kind of responsible for enforcing the antitrust judgment.



STEVE:  Right.  Makes sense.



LEO:  You know, he's an interesting fellow.



STEVE:  Yeah.  I was sorry you were not with me last week because the previous...



LEO:  So was I.  And by the way, thanks to Mike for filling in.  I really appreciate it, yeah.



STEVE:  Yes, yeah.  The previous day you and Sarah had a great time talking about one of the things you and I have near and dear to our heart, which is Oddworld.



LEO:  Ah.  You love Oddworld, too?



STEVE:  Yes.  Yes.



LEO:  You don't play videogames anymore, do you?



STEVE:  Actually, no.  And I really even didn't then.  But that special series was so amazing that my company knew that pretty much once a year, when a new Abe or Munch title would come out, I'd be gone for a couple weeks.  They just - that's like, okay, well, we'll see Steve when he's done because...



LEO:  Love them.  Love them.



STEVE:  Oh, my goodness.  And so, and I listened to you talking about how you and Henry used to play it.



LEO:  Yeah.



STEVE:  And I did, last week, even though Mike was like, huh?  What?  Odd what?



LEO:  Oddworld?  Abe's Oddysee?  What are you talking about?



STEVE:  "Mike, I was planning to have Leo, but I'll just wing it without you."  But, so, yeah.  So what I learned is that what they've done is there is a new remake of the original 2.5D scroller called New 'n' Tasty.  And this is thanks to you and Sarah talking about it because I was just curious, and I went back to Oddworld Inhabitants, where I hadn't been for years, because - and I completely agree with you.  Trying to play Stranger's Wrath on a pad without really good controls would be just difficult.  I guess, you know, kids do it somehow.  But anyway, I won't drag our listeners through it all again because I discussed it at length last week.  But I did want to mention to you, since you're a fellow Abe lover, that New 'n' Tasty is out on the PS4, with the other platforms coming soon.



LEO:  Yeah.



STEVE:  So they will be making it available across the board.



LEO:  I think the thing we liked about this, certainly I liked about it, was that it was just different.  And so many videogames are the same that something that's unique...



STEVE:  Yeah, not only different, but clever.  I mean, to have - for Abe, who is a floor polisher, to be working at Rupture Farms...



LEO:  There's a sense of humor, isn't there.  Yeah.



STEVE:  Yeah, there really was.



LEO:  Now I might buy a PlayStation 4 just to play this.  Although they say they're coming out on other platforms soon, too.



STEVE:  Yes.  It will be out on all the various platforms.



LEO:  Yeah.  So the occasion for this was that Stranger's Wrath was reissued on the iPad.  And I think it looks the same.  It looks like the same game.



STEVE:  I think it is.  And Stranger's Wrath, I explained last week that the history of this is that Lorne Lanning and his girlfriend Sherry [McKenna], I can't remember her last name, she happened to be, like, waiting for him to get home or something, hanging out in his living room, and on the coffee table she discovered a manuscript for a movie of this, that is, with Abe and Rupture Farms and all this, that Lorne had just been sort of playing with.  And so she reads through it while she's waiting for him to get home.  And then she's like, when he walks in the door, she's like, oh, my god.  And she said, "Do you know what this is?"  And he said, "Yeah, a manuscript I was sort of toying with."  And she says, "No, this is our videogame."  Because they were in San Luis Obispo.  They were doing special effects and creative stuff, sort of as a satellite of Hollywood, as a producer of that stuff, wanting to develop some property of their own.



And so that launched them into, this concept launched them into videogames.  And they didn't want to do a first-person shooter.  They didn't want people dying and blood splattering and all that.  And so, I mean, the worst that happens with Abe is that really evil creatures that you have no sympathy for whatsoever get ground up.  But, you know...



LEO:  You know, it's somewhat similar to the sense of humor of "Hitchhiker's Guide."  And maybe that's why we like it.



STEVE:  Yes, yeah.



LEO:  It's kind of a clever twist.



STEVE:  Yeah.  Anyway, so I did recommend it.  I commended it to our listeners.  If you've got kids, oh, in fact, one of the things that Stranger's Wrath represented I was sort of sad to see that they didn't maintain.  They were originally going to do a quintology.  And Stranger's Wrath was sort of them succumbing to the first-person shooter pressure.



LEO:  Yeah.  Right.



STEVE:  And so they didn't shoot bombs, but they shot little furry creatures that were all teeth.  So you'd, like, shoot it behind a wall, it would grab onto someone's butt, and they'd come running out from behind the wall, and then it would take them down.  So anyway, fun stuff.



I did get - I saw as I was going through my stuff this morning a question from a Markus Sommer in Germany, who asked a question I see often, that I have answered before, but I just wanted to - since it's still being asked.  He said:  "Dear Steve, I've been a Security Now! listener for about six months, but I never bought a copy of SpinRite since I thought it to be a pure recovery tool."  Oh, and that's why he probably hadn't heard it before, because he's only been listening for six months.  He said:  "However, you recently mentioned that it is in fact a preventive maintenance tool, not just recovery, so I was thinking about getting a copy.



"But there's a problem.  Due to privacy concerns" - to which unfortunately Posner is not sympathetic - "I'm using full-disk encryption, TrueCrypt, on all of my hard drives.  Since this will effectively prevent SpinRite from seeing the data structure on the hard disk drive, I assume that it will not work on my hard drives.  Will I need to always decrypt the hard drive, then run SpinRite on it, then reencrypt it again?  Or is there a way to work around this annoyance?  Or might there be one in the next version of SpinRite," blah blah blah.



LEO:  You are clearly, clearly new to this podcast, my friend.



STEVE:  "Love the podcast, and I'm already waiting for the next part of 'How the Internet Works.'"  So, Markus, good news, run it absolutely as it is.  You have a valid hard disk, regular partitions.  They contain noise, but SpinRite doesn't care.  The drive doesn't care what noise it's reading, and neither does SpinRite.  It's all about helping and assuring that the drive will be able to read the noise or data, whatever that's there in the sectors.  So yes, by all means, it runs with no problem on fully encrypted, full disk-encrypted drives.



LEO:  Indeed it do.  All right.  Back to work, Steve.



STEVE:  Okay.  So briefly, just to - this ran across my Twitter feed last week, and I thought, ooh, that's going to change a few things.  We talked extensively one year ago, it was November through December that Target suffered that major breach.  Boy, it's been a year, Leo.  Time is really flying.



LEO:  And what a cruddy year it's been.  Breach after breach.



STEVE:  Ah, it's been a busy one.  So to refresh, 40 million Target customer credit cards were compromised, meaning that 40 million of them had to report to their credit card company, or their credit card company informed them your card may be vulnerable, we're going to replace it.  Which is really expensive.  I think I saw the number $800 million.  Maybe it was $400 million.  It was a lot of money that that breach was believed to cost the credit card companies.  And in addition, as many as a 110 million people may have had their personal information such as email addresses and phone numbers stolen. 



Well, not surprisingly, that resulted in a landslide of lawsuits filed against Target.  And at the time there was some concern that Target should have known.  And therein lies the reason why they're probably in trouble, because a strong case can be made that Target was negligent in ignoring warnings that they were receiving.



Of all of the landslide of lawsuits, they were consolidated into just two:  one lawsuit for consumers; one lawsuit for all the banks.  So they all got together and said, okay, we're going to consolidate our complaint into a single suit.  Target's lawyer argued, as they always have before, and as all other retailers always had, that they're under no contractual obligation, and that they have no obligation to the banks specifically because a third-party firm handles all of their credit and debit card payments.  And so the Target attorney asked for the suit to be dismissed.



So the big news is a St. Paul, Minnesota judge, and I saw his name here somewhere - oh, Paul Magnuson.  He ruled that Target's behavior "played a key role in allowing the harm to occur."  He said:  "Imposing a duty on Target in this case will aid Minnesota's policy of punishing companies that do not secure consumers' credit and debit card information."  Even though "the third-party hackers' activities are what caused the harm, Target played a key role in allowing the harm to occur."



So this ruling is one of the first court decisions to clarify the legal confusion between retailers and banks and who's responsible in these data breaches because, in the past, as we know, banks have often been left with the financial burden of a hacking and responsible themselves for replacing the stolen cards.  Oh, and here's where I had - I knew it was in my note here.  The cost of replacing stolen cards from Target's breach alone is roughly $400 million.



So in my notes I wrote the Target ruling makes clear that banks have a right to go after merchants if they can provide evidence that the merchant may have been negligent in securing its systems.  And at the time of its breach last year, Target had installed a $1.6 million advanced breach detection technology from the company FireEye.  And we talked about it at the time.  According to several people who were briefed on its internal investigation, who spoke under the condition of anonymity, the technology, this FireEye technology did sound alarms that Target ignored until the hackers had already made off with credit card and debit card information for those 40 million customers and the personal information of 110 [million] others.  So this doesn't mean that the game is over yet.  This just means that the judge has said, nah, we're not going to let you dismiss this, Target.  We're going to go to trial.



LEO:  Good.



STEVE:  And see how this proceeds.



LEO:  Actually, I shouldn't - we shouldn't vote on this because it's really between the banks and Target.  But one of the reasons this stuff persists is because...



STEVE:  They're indemnified.



LEO:  Yeah, they're indemnified.  We're indemnified, too.  Retailers are indemnified...



STEVE:  We're indemnified.



LEO:  And users are indemnified.  The banks just absorb it all.  I'm not in favor of the banks in any particular way, but this isn't ever going to get solved unless the people who are really responsible for the flaw have to fix it.



STEVE:  Right, right.  Now, I did see an interesting piece from one of the SANS Institute editors, who read this a little differently.  He said:  "If the case is being made that, because Target had knowledge and ignored it, let's hope that the lesson that comes away is not to have knowledge."  Because of course that is the...



LEO:  Got it, right, be ignorant.



STEVE:  Exactly.  We're not installing any detection software...



LEO:  That's true.  That's a good point.



STEVE:  ...because Target got hung because they knew and ignored it.  And someone could easily feel that acting on this is too big a burden.  Speaking of...



LEO:  It is my understanding that the new law, the new chip-and-pin law, which goes into effect in the United States in October, we're going to replace our swipe-and-sign cards with chip-and-pin, puts the onus, or it puts the liability on whoever had the weakest technology.



STEVE:  That's what I remember reading also, yeah.



LEO:  And that's obviously something the banks got in that law; right?  But it does encourage - that's a good way to handle it because that encourages all the partners to have the best, most secure technology.



STEVE:  And it really does solve the problem because how many times have we said here that the problem with security is the weakest link is what gets attacked.



LEO:  Right, right.



STEVE:  Well, so speaking of responsibility and not taking any action, even before this last couple weeks of revelations, how many breaches of Sony have we talked about in the past?  I mean, the PlayStation has had breaches.  I mean, Sony has historically had really poor security.  And you would have to then hold them even more responsible for the depth of this catastrophe that they are now suffering.  And it can only be called a catastrophe.  We don't know yet for sure what the origin is, that is, whether - there are rumors that this is North Korea because of Kim Jong Un's unhappiness with the, what is it, "By Invitation" is the movie which is going to be coming out?  Unfortunately...



LEO:  "The Interview."  "The Interview."



STEVE:  "The Interview."  "The Interview."  Exactly.  But oddly, as a consequence of this, we know that the two main stars are each receiving $6.5 million because all the details of their contracts...



LEO:  And James Franco gets $6,000 to drive himself to work.



STEVE:  Yeah.



LEO:  I like that.  There is a certain gossipy element to all of this, and I don't know if we should foster it.



STEVE:  Oh, that's what makes it so juicy.  Oh, yeah, we have to, Leo.  So, and Lizzy Caplan, I was a little disappointed, she's only getting $100,000 for her part.



LEO:  What?  A show.



STEVE:  No, for the movie.



LEO:  Oh, in the movie.



STEVE:  Yeah.



LEO:  Oh, she should get as much money as Sony has.



STEVE:  Well, yeah.  Now we know exactly what that is, too.



LEO:  A hundred thousand?



STEVE:  I know.



LEO:  She's a super - she obviously did the deal before "Masters of Sex."



STEVE:  Probably did.



LEO:  Yeah.



STEVE:  Yeah.  And, boy, she's - anyway, you and I both like her a lot.



LEO:  I hope she's getting a lot of money for "Masters of Sex."



STEVE:  I bet she is.  And, what...



LEO:  From now on she's going to make plenty of money.



STEVE:  Yeah, yeah.



LEO:  But, you know, the question is, what is Korea's involvement in this?  That's the interesting...



STEVE:  Well, and, yeah, okay.



LEO:  We don't know, do we?



STEVE:  So one of the reasons I didn't talk about it last week or the week before is that, first of all, this is going to be  providing juice for a year.  I mean, the problem is the bad guys are having a ball trickling this out.  And they've got so much content to disclose that there's no hurry.  And I wanted to get a sense for it, too.  So one of the things we have established is that a group whose initials are GOP, who goes by the Guardians of Peace, are clearly the source.  We don't know much about them.  We know that their English is not great.  At one point, when they were disclosing something to the press, they said:  "We've got great damage by Sony Pictures.  The compensation for it, monetary compensation we want."  Actually, they sound like Yoda.



LEO:  [As Yoda] "Monetary compensation we want."



STEVE:  "Pay the damage, or Sony Pictures will be bombarded as a whole.  You know us very well.  We never wait long.  You'd better behave wisely.  From God's Apostles" - A-P-S-T-L-S.  So, and similar messages like that in broken English and with words - there was also something that tried - it apparently pretended to be actually posted in Korean, but it looked like a machine translation was used to get it because actual Korean speakers said, no, the words are all, like, Yoda-ized.



So, okay.  So here's - to say that it's bad, I think, misses the point.  So I want to quickly just sort of scan through the contents of the data that has befallen the public from Sony's caverns so far because it gives - it's important, I think.  As I was going through this, I was thinking, oh, my god, oh, my god.  I mean, because it just, I mean, this actually did happen.



So on November 25th was the - and we now know that some small set of Sony's executives, two or three days before this, received an extortion email saying, pay up, or we're going to disclose a lot of information.  And they ignored the email.  No response came back to the Guardians of Peace.  So November 25th, via a Pastebin link, torrent files were hosted on four sites in 26 parts as 25 1GB files, and then the sixth one, the fragment, was 894MB.  They were also uploaded to filesharing giants Mega and Rapidgator, but the managers of those sites pulled them down.  Those files contained information on 4,000 past and present Sony employees.  And following this, a brief email dialogue that Risk Based Security, one of the many researchers following this, had with the GOP, the Guardians of Peace, stated that - the GOP stated that they had over 12TB of data, obtained from Sony's servers and workstations.



The next day, on the 26th, torrent links were published to Torrent Trackers containing the unreleased movies "Fury," which actually has now been released, but then three other ones:  "Annie," due for release on the 19th of December; "Mr. Turner," due for release on the 19th of December; and "To Write Love on Her Arms," the title of a movie due for release on March 15, I'm sorry, March of 2015.  And based on several torrent tracking sites, those three movies have been downloaded over 100,000 times.  So they are loose on the Internet.



Monday before last, on December 1st, NBC News reported that the FBI was investigating the breach.  Also the FBI sent out a flash alert a few days after that to a number of other high-profile companies, basically warning them to, like, watch their networks closely.  One of the things we do know about the malware, and I'll talk about it in more detail in a second, is that it is able to jump through Windows shares, from one machine to another, through an Intranet.  And this clearly helps to explain the depth of what was lost inside of Sony.



LEO:  There's been so many stories about this.  But I also saw that they thought it might have been an inside job because there were Sony logins to certain servers and so forth, so that maybe they were able to get that malware even deeper than they would have been with a spearphishing attack because they had some help from the inside.



STEVE:  Yeah, again, all we can do at this point is speculate.



LEO:  Right.  The FBI's not saying anything.



STEVE:  My sense is that this was ongoing for some time.  I know that, for example, the malware was written for Sony.  That is, in the malware were the names of 50 different Sony servers.  So it knew what to look for.  On the other hand, once you get in, if you can stay stealthed, you can poke around within a network.  And clearly, in order for there to be this much data - 12TB.  The other thing, Leo, that just cracks me up, and I've got this, later on I was going to talk about it, but Sony's own servers are providing the seeds for the torrents of their own data.  So BitTorrent clients have been loaded on Sony servers.  Then they're offering the torrents from Sony's own servers.



LEO:  Wow.  Oh, that - that's insult to injury.  Holy cow.



STEVE:  So December 1st, another 24.87GB of data was leaked.  Now, get a load of these numbers:  33,880 files in 4,864 folders, containing, just scanning through the data, 47,426 unique names with Social Security numbers.  15,232 Social Security numbers belonged to current or former Sony employees, 3,253 Social Security numbers appearing more than a hundred times throughout the files.  And just among all this data, an example of employee data that was found is one file was in a directory structure - \HR\Benefits\Mayo Health\Mayo XEROX assessment feed - containing 402 Social Security numbers, internal email addresses, plaintext passwords, and employee names.  So all of this confidential internal employee number and an additional 3,000 or more Social Security numbers, names, contact details, phone numbers, dates of birth, email addresses, employee benefits, workers' compensation details, retirement and termination plans, employees' previous work histories, executive salaries, medical plans, dental plans, their gender, their employee IDs, sales reports, copies of passport information and receipts for travel.  It's just - oh, and account information to order customer jewelry from Tiffany & Co. via email.  That was Monday before last.



LEO:  Steve Gibson.



STEVE:  Okay.  So I don't mean to belabor this, but some of these, I mean, our listeners will appreciate the horror of the fact that all of the security certificates for the servers at Sony, the file containing the security certificates has now been escaped to the public.  Last Wednesday was a bigger blob.  Oh, no, I'm sorry, smaller, because we're talking gigabytes, 1.8GB.



LEO:  Oh, is that all?



STEVE:  The plaintext credential, the login credentials, about 500 of them, for all of Sony's servers and internal machines, IP addresses and data, with the security certificates, the users and services that those certificates are tied to.  121 FTP plaintext credentials, including the main Sony Pictures FTP server login.  Just a huge number of password files which appear to be individual files, personal files, that Sony employees had on their own workstations, which they named "passwords," where they managed their own lists of passwords.



So it's not clear whether the malware attacked the backups of their workstations, which seems certainly possible, that is, all of this distributed workstation data is part of what was lost.  I mean, it pretty much looks like everything was lost.  So it may have been the workstations were being backed up to the servers, and the servers were sucked dry.  But we also know that malware did get out onto the individual workstations because many of them had that weird skeleton screensaver that came up and scared everybody a couple weeks ago.  And then there was also some drive wiping that was occurring.  Data was removed, and then the drives were wiped behind them.



And I'm just going to scan through here for some other tidbits.  Oh, on the 5th, last Friday, 100GB of compressed data which was titled the "Financial Data of Sony Pictures" - 22 individual files, making up three larger files, containing a set of newly released data.  So in File 1, 30,916 individual files in just shy of 3,000 folders, making up 16.4GB of compressed data comprising...



LEO:  That's a lot of compressed data.



STEVE:  Bank statements, bank account information including wire transfer swift codes.  The financial year reports, financial year forecasts, budget reports, overhead reports, receipt and transaction account statements of computer hardware, vehicles, car accessories going back to '98.  Internal information for Sony Pictures Releasing International portal, screenshots, walkthroughs, and other usage information.



File 2 had 89,800 files in more than 10,000 folders, 88.6GB compressed, had accounting information in the format of the  Trintech, Inc., software, and then their licensing, their media, Sony's content licensing contracts with Access Digital, Amazon Europe, Amazon Japan, Clickplay Multimedia, Comcast, Eagle Eye, Gaia, Google, Media Vault, M-GO, Microsoft, PlayStation, Sena, Sony Visual Products, and too many other vendors to list, their actual licensing contracts in more than 90 files.  528 payrolls for Imageworks Canada with full staff names, contact numbers, and residential addresses.  I mean, the actual data.  All of this stuff has now been posted publicly on the Internet into torrents and in downloading sites.  And files of federal income tax returns too numerous to count.



And then the third of these three files on just last Friday was, in another archive, 113,000 files in almost 40,000 folders containing incident reports of accidents of some sort with full names, incident locations, injuries, and positions held with Sony.  Copies of employment contracts and agreements, passports, driver's license image scans, Social Security numbers and signatures.



And the last one I'm finished with is yesterday's drop, was four archives in two large files.  The first .rar was corrupted and would not unpack.  It was 3.5GB in size.  We know that it was an Outlook mail spool.  However, the second one did unpack.  And that was titled APascal1.ost.  Amy Pascal is the co-chairman of Sony Pictures Entertainment.



LEO:  Oh, she's pissed.  She's pissed now.



STEVE:  Her entire email spool, 5,000 emails.  The most recent inbox email was dated November 23rd of 2014. 



LEO:  Oh, it's recent, wow.



STEVE:  So it is completely current, and it consists of emails to Sony Employee Relations, personal invoices, personal emails, includes talk and details about upcoming movies and current and closing business deals.  So this is the private email correspondence of Sony Pictures Entertainment's co-chairman, Amy Pascal.



And they're just getting started, Leo.  They have 12TB of this data.  So this is, I mean, think about it, this is the entire internal operating data of Sony.  Everything.  I mean, payrolls, history, invoices, business plans, contracts.  You know, Sylvester Stallone's Social Security number was, like, in among that stuff.  You know, the pay stubs of all the actors that they've had on their movies.  I mean, everything.



LEO:  So we get it.  Everything.  So the question is - a couple of questions.  First of all, I have to think that Sony is not the only company that this could happen to.



STEVE:  Oh, I completely agree.



LEO:  And in fact, if you were targeted by sufficiently sophisticated hackers, there's probably few companies that would, I mean, is it possible to secure yourself against this kind of attack completely?



STEVE:  The problem is a mono culture and a mono network.  That is to say, instead of being organized as small satellite networks that inherently have some containment, it's clear that a single attack event of some sort, at some time in the past, allowed someone to establish a foothold in Sony's network.



LEO:  But you understand why it was that way.  That's the easiest way to do business.



STEVE:  Yes.



LEO:  You start siloing stuff, then it's a pain in the butt.  You can't find out this.  You can't find out that.  You can't talk to this person.  It makes sense.



STEVE:  Right, you can't get email directly from here to there.



LEO:  And we should point out it is siloed in the respect that this is just Sony Pictures Entertainment.  Sony is a much, much larger company.  This is just one division of Sony, as big as it is.  It's not like all of Sony was compromised, just SPE. 



STEVE:  Right.



LEO:  So it's siloed a little bit.  It's just not - but you're not going to, I mean, I think about, okay, I think about our business here.  Yeah, we use reasonable precautions.  Our data's on QuickBooks.  But I could easily see somebody getting into our internal networks.



STEVE:  Yeah.



LEO:  And if somebody were determined enough, they probably could do it.



STEVE:  Yeah.  I think, I mean, I'm trying to think of an analogy that works.  And, I mean, if you switch to the real world, if someone came in the front door, heavily armed, with grenades and submachine guns, they could...



LEO:  What are you going to do?



STEVE:  They could pretty much have whatever - they could have whatever they wanted.  You know?



LEO:  Right.  Well, I need to go farther than that because - and this may be the real issue.  Until the data era, security wasn't really, look, you lock your door, but anybody can get into your house.



STEVE:  We have windows.  We have windows.



LEO:  It doesn't really stop a determined attacker.  It's more of a signal.  And here's the barrier.  Don't cross this because you'll be breaking the law.  We have the law on our side.  But it doesn't - if you're willing to break the law, a locked door is not a deterrent at all.



STEVE:  No.  That's exactly right.



LEO:  And so I think as we got into the digital era that same mentality persisted.  Well, we've locked our doors.  It's illegal to break in.



STEVE:  Yeah, you know, we put a password on our WiFi, even though it was our street address, so that we would be able to remember it.



LEO:  What would be the burden of true security in a business?  Not merely financial, but structural.



STEVE:  I would argue you can't do it in a sufficiently large and sprawling network where employees, by virtue of their jobs, have to have access.  And unfortunately we are, you know, we've discussed the way firewall technology changed, where the original firewalls were open, and they blocked bad stuff coming in.  And it was after it was painfully clear that that was wrong that firewalls were closed by default and then selectively opened ports where we did want to allow traffic.



The problem is we have, even in the computer that's in front of you and is in front of me, it is not a whitelisting computer.  It is a blacklisting computer.  That is to say, by default, it will run anything we ask it to.  Now, there are whitelisting systems.  And you can get them for your computers.  The problem is they're a pain in the butt to use because you can't just download something and run it.  You've got to get permission from IT, and they say no because their job is to say no.  Their job is to prevent this from happening.



So my point is that, from the beginning, you know what I mean, from our mobile phones that are personal devices that people have in their pocket, and they walk into their organization, and they plug them in to charge them to a USB connection which is hooked into their computer.  Now their phone, which who knows what's on it, has access to the USB port of their computer.  And we know from the BadUSB exploits that it can do a lot of damage just from having access to a USB.  So convenience, the real problem is that I think the only way you could have security is to have absolute mathematical certainty-level knowledge of every single component.  And it's impossible today.



LEO:  Right.



STEVE:  It's impossible.



LEO:  I mean, we use LastPass Enterprise.  We do all the prudent things.  And I think we're just - so the only reason I bring that up is to caution people who are mocking and laughing and saying, oh, stupid Sony, as stupid as Sony is, as willing as I am to say that they have crap security, I'm not convinced that the same exact thing couldn't happen to most corporations.



STEVE:  I cannot conceive of securing Sony.  I couldn't secure them.  I could not secure them in a meaningful way.



LEO:  They could have done much better.  Putting a file on the desktop that says "passwords.txt" is a bad idea.  They could have done better.  But a determined attacker probably could get in anyway.



STEVE:  And, for example, I believe those are individual personal passwords files.  So in an organization that size there were invariably a lot of people who were like, first of all, the fact that they had a passwords file means they had lots of different passwords.  They weren't using a password manager that encrypted the data because they weren't that sophisticated. 



LEO:  We give everybody in the building here LastPass Enterprise.  And I guarantee you there are some people with a file on their desktop in this building that says "passwords.txt."



STEVE:  Yeah, and they look up what the password is for that site.  That's, I mean, so that's going to happen.



LEO:  I never mentioned this, but we had an engineering director some time back who posted all of our company passwords, SFTP, all the secure stuff, on a public web server. 



STEVE:  On purpose?



LEO:  No.  He just wasn't thinking.



STEVE:  Ooh.  Ooh.



LEO:  Yeah.  He's not - he's not with us anymore.  But that's - it's easy for that to happen is what I'm saying.



STEVE:  My point is it's almost probably impossible for it not to happen.  You know, ivory tower guys can say, oh, yeah, you know, follow best practices.  It's like, well, yes, but try to implement that across a company of 45,000 actual human beings who are not robots, who need to be able to access networks in other countries and actually do business.  The problem is these systems are just fundamentally insecure.  And the only thing I can think is that, if some kind of, as you said, stovepiping or compartmentalization were present so that, if somebody got into, I mean, so that there was a sense of not having all of the crown jewels on one big network in a set of interconnected servers that were able to see each other such that just getting a toehold allowed that to get pried into the crown jewels.



But think of what this means.  Every, I mean, the security at Sony, within this division of Sony, is completely screwed.  I mean, every single employee has to change every single one of their passwords, let alone every single server has to completely be rekeyed.  I mean, it's just devastating.  It just - it's just stunning what the impact...



LEO:  Yeah, I'd hate to be the cleanup crew here, would be just...



STEVE:  Yeah, exactly, to remediate this kind of disaster.  And then there's the reputation cost and the fact now that actors all know what each other makes, that that's now in the public.  We're going to be seeing this data dribbling out for the next year, and it's just going to be hugely damaging, unfortunately, hugely damaging to Sony.  And...



LEO:  How long was PlayStation Live offline?  Several months after their attack there.  I mean, this isn't the...



STEVE:  Yeah.



LEO:  This isn't Sony's first time to the rodeo.



STEVE:  No.  And that's - some people have observed that one wonders what lessons, if any, they learned.



LEO:  The lesson is don't get attacked.  Don't anger bad guys.  I think it's probably the same sentiments that brought down PlayStation Network are exhibited here.



STEVE:  Yeah, but, you know...



LEO:  They alienated gamers.  Don't ever alienate gamers.  Bad.



STEVE:  True.



LEO:  Oh, believe me.



STEVE:  Gamers have skills.



LEO:  They have skills.  Mad skills.



STEVE:  Yeah.



LEO:  It's such an interesting story.  And, you know, one last philosophical question, and I think a great one, from somebody in our chatroom, and I can't remember his name, somebody - sorry I didn't give you credit for this.  But he said, how is it different, looking at this data that has been leaked from Sony, how is that different than looking at the naked pictures of celebrities that were released earlier?



STEVE:  Yes, I had the same thought while I was going through this.  I was thinking, I mean, you actually have to just say no.  You just have to say that this is data that is private.  It is Sony's property.  And no one should publish this.  But, I mean, yesterday when I started doing this research, I saw one of the employment sheets for the "The Interview" where I saw the major actors' salaries on this.  And there it was, on a website.  So it is airing their dirty laundry.



And the person in the chatroom is exactly right.  I mean, this is exactly the same.  It should be - oh, and in fact one security researcher had the FBI come knocking at his door.  He was not at home.  His wife was.  And she was, like, stunned, so she didn't even remember exactly what they said.  But they were very intimidating.  And what she remembered from their conversation was "illegal downloads."  So what the FBI is now running around doing is trying to put their finger in the dike.  They are trying to find the IP addresses of everybody who's downloading from the download sites and the torrents and trying to get the files back.



LEO:  Oh, don't focus on that, FBI.  You've got more important things to do than that.  Really, that's the focus?



STEVE:  Yeah.



LEO:  Let's try to catch the people.  You can't put your finger in this dike.  That is impossible.  That's too bad that they're doing that.



STEVE:  So anyway, they are spending time that way.  Well, they've got a lot of agents in...



LEO:  They have plenty of things, plenty of time.  By the way, it was Strengths in our chatroom who proposed that about the relationship between nude photos and the Sony data.  And I think that one lesson is to maybe - it might be at this point bad mojo to have a little bit too much schadenfreude over this, that ask not for whom the bell tolls, my friend, because it could be you next.



STEVE:  Yup.  The only thing, I mean, the only thing that I think works is keeping things small, keeping things simple.  So if you had an IT person who was truly responsible for the security of a sub-network and the behavior of the employees and actually had authority, I mean, too often, I mean, IT people are complaining all the time that they get no respect; that they say, "We need to do this, we need to do this," it's like, what does that cost?  Oh, well.  It's like, "Okay, well, maybe we'll get around to that one of these days."  But from my standpoint, complexity - we've said this often on the podcast - complexity is the enemy of security.  And if you've got a gazillion employees on a common network, forget it.  It's over before it begins.  All it takes is any one of those people.



It's like the RSA, the devastating attack on RSA where one administrative assistant, and we know who she is, clicked a link, opened a PDF that contained an Excel spreadsheet, and the thing got into her machine, and now the bad guys were inside the RSA network.  They stayed stealth, and they browsed around and found, like, watched traffic happening, and they just took their time.  I mean, it is horrifying to think of something evil persistently living in your network.  But if it's sufficiently large, if the network is, I just - I don't know how you prevent it from happening.



LEO:  In some ways they're lucky that these guys went public with it.  They could have just sat there forever and used this to their advantage.  I mean, if you've compromised a network, the scarier prospect is that people didn't find out about it, and you just sat there and enjoyed.



STEVE:  And, you know, it really was stupid because they apparently, I mean, first of all, it does seem clear that English is not their first language.  And to send an extortion letter saying we have data, pay us or else, I mean, no one knows how much money was being asked for.  And, I mean, you would think, for example...



LEO:  This could also be misdirection.  If you're the North Korean government, then you might do that.



STEVE:  Could be.



LEO:  It could be - there's some rumor going around that it's actually a Sony inside job, that it was a Sony employee who had an axe to grind.  Of course the first thing you do is cover your tracks by pretending it was some hacker group.



STEVE:  Yeah.



LEO:  We just don't know.



STEVE:  And talking like Yoda.



LEO:  Yeah.  We just don't know what the story is.



STEVE:  No, we don't.



LEO:  But it's really terrifying.



STEVE:  Well, I think it's a wakeup call.  I don't know that anything can change, though, from it.  I mean, even in other boardrooms of other major companies, if the CIOs say to their COOs or CEOs, we're almost powerless to keep the same thing from happening, I mean, it's - you have to have access in order to function.  And the bad guys can trade on the same access that the good guys have to have.  It's like, I don't know how, I mean, I'd like to say there's an answer.  But all we can really do is talk about the technology.



LEO:  Right.  That's our job.  That's what we do.



STEVE:  Yeah.



LEO:  Every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC, this guy here, Steve Gibson, explains it all.  You'll find Steve at GRC.com.  Next week, good lord willing and the creeks don't rise...



STEVE:  Q&A.  Q&A.



LEO:  ...we'll have a Q&A.  And you can ask questions of Steve in two ways:  one at the website, GRC.com/feedback; the other on this Twitter feed, @SGgrc.  That also works.  Steve pays attention to that.



STEVE:  I do.



LEO:  You can go to GRC.com for a lot of other things, though.  Of course SpinRite, the world's finest hard drive maintenance and recovery utility.  All his freebies...



STEVE:  It's great on encrypted hard drives.



LEO:  Yeah, it doesn't care.  It doesn't know.



STEVE:  Nope.



LEO:  You can also find 16Kb audio versions of this show, really nicely done transcriptions by Elaine Farris, who writes it all out longhand, at GRC.com.  Now, at TWiT.tv/sn, that's our site, we have MP3 audio, high-quality audio, high-quality video.  You can also find the show on every podcatcher out there because it's one of the longest running netcasts in the world, we're very happy to say, and we continue to do it each and every week.  The bad guys are making sure to give us lots of material.



STEVE:  We're never running out.



LEO:  Thanks, Steve.  I'll see you next time.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#486

DATE:		December 16, 2014

TITLE:		Listener Feedback #203

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-486.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  More on the Sony hack, plus we'll answer questions from you, our audience.  Stay tuned, the last Security Now! before Christmas is coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 486, recorded December 16th, 2014:  Your questions, Steve's answers, #203.



Time for Security Now!, the show that protects you and your loved ones online with the Explainer in Chief his self, Steven Gibson of the Gibson Research Corporation.  Well, I should say "Happy Holidays," Steven.  Christmas is upon us.



STEVE GIBSON:  Thank you, Leo.  I guess we are at this point.  We're on the 16th of December, so we're halfway into or through December.  And, yeah.  Anyway, we all have the spirit and lights, and we're whistling Christmas tunes.  Oh.



LEO:  I was drinking eggnog this morning.



STEVE:  Before I forget, I think I had mentioned to you before, but I have been in a live theater where Patrick Stewart was doing his one-man show...



LEO:  Oh.



STEVE:  ...of "A Christmas Carol."



LEO:  Because you heard Andy Ihnatko talking about that on MacBreak Weekly earlier today.



STEVE:  Yes.



LEO:  That's his pick.  He loves the Audible book of that.



STEVE:  And I didn't know there was an Audible book of it.



LEO:  Yeah.



STEVE:  So I wanted to tell our listeners.  I waited until the camera was rolling or you were recording this or whatever it is you do.



LEO:  What is it I do?  I don't know.



STEVE:  Push buttons.



LEO:  Yes.



STEVE:  And magic happens.  To tell our listeners that, if you're fans of Patrick Stewart from, of course, "Star Trek:  Next Generation," it really is, I mean, Andy is absolutely right.  Andy told the story during MacBreak Weekly that annually he gets his - wait.  He did say cassettes.  So he can't still have a cassette player.  But...



LEO:  With Andy, it's possible.



STEVE:  Or maybe he's been doing it since the era of cassettes, when it was first made available on Audible.  Anyway, so Patrick Stewart, "A Christmas Carol," on Audible, and wow.  I mean, it was just him, sitting on a stool, and occasionally walking around a little bit.  It was fabulous.  And I'm probably going to get it myself, which means I'll finally have to get an Audible account.



LEO:  Wow.



STEVE:  Yeah.  Because it was a...



LEO:  Wow.



STEVE:  It'd be fun to have that.  It was spectacular.  So just a heads-up for our listeners who like Patrick.



We had a relatively slow week.  Got some news, of course.  There are new upcoming changes in Chrome being bandied about, we want to talk about, with Google continuing to push security.  News of a previously unknown, devastating cyber attack surfaced that had been kept quiet for 10 months, but was massive.  And then I wanted to talk a little bit, because there's been a lot of discussion, I mean, one of the things that happened, of course our show last week, we've talked about it, it was titled "Expensive Lessons."  And one of the things I did was enumerate the nature of the documents that were leaked or stolen by the hackers of Sony Entertainment.



Well, since then, of course, we're starting to see all the salacious details of the content of the email.  And so there's been a lot of interesting discussion.  I know that you guys, you had a great coverage of that whole issue on TWiT on Sunday.  And so I want to talk a little bit about the ethics of disclosing illegally obtained content, and then Sony's new questionable strategy with the press about that.  Verizon has what I would consider a ridiculous Cypher phone app that they have just...



LEO:  I knew you'd laugh when you read about that.



STEVE:  Oh, my lord.  And we've got some miscellaneous fun stuff, and of course questions from our listeners to put us on to other topics that we will be talking about.



LEO:  Oh, I'm glad.



STEVE:  So a great show.



LEO:  I'm glad you're going to - yeah.  This is all good stuff. We'll talk about this.  All right, Steve.  The news of the week.



STEVE:  So some dialogue surfaced over in the Chromium Chrome developer team area, suggesting that they want to push further with sort of the overall thrust that Google has been making to secure the Internet.  They're planning - I know you're sitting down on your ball, so it's safe to tell you this, Leo.



LEO:  Uh-oh.



STEVE:  They're planning to explicitly mark non-HTTPS connections as non-secure in some new fashion in the user's experience.



LEO:  This isn't - weren't they doing this, I mean, this isn't new, is it?



STEVE:  Yeah, no.



LEO:  No.



STEVE:  So the idea was, what we've had so far has been an indication, if you are using HTTPS, that is, like the key is not broken or the lock is closed, sort of a subtle clue.  Then we went with the extended validation certificates.  We added the green glow if you were using an EV cert.  But if you were not secure, it was just kind of normal.  What they're intending to do is like a skull-and-crossbones if you're not using TLS.  So that they're going to further, I mean, they're basically going to start warning people when you're not using a secure connection.



LEO:  Well, but that's - it isn't a lie, I mean, it is less secure.  I hope it's not a skull-and-crossbones, though.  This site is poison.  I mean, if it's kind of a non-loaded thing, I mean, isn't that what the open padlock was?



STEVE:  Yeah.  But clearly their intention, though, their intent - well, okay.  What they said was:  "We, the Chrome Security Team, propose that user agents gradually [that means browsers] gradually change their UX [the user experience] to display non-secure origins as affirmatively non-secure.  We intend to devise and begin deploying a transition plan for Chrome in 2015.  The goal of this proposal is to more clearly display to users that HTTP provides no data security.  We'd like to hear everyone's thoughts on this proposal and to discuss with the web community about how different transition plans might serve users."



And then they finish, saying:  "We all need data communication on the web to be secure, private, authenticated, untampered.  When there is no data security, the UA should explicitly display that, so users can make informed decisions about how to interact with an origin."  So they're clearly saying that they intend to display a signal of some sort that causes users to be anxious or aware in a way that they're not currently, when they're not on a secure connection or secured connection.  I mean, I noticed they were careful to say "non-secure" rather than "insecure" because the two are not synonymous.



LEO:  It's not encrypted.  I don't - I think the proof will be in the implementation.



STEVE:  Yes.



LEO:  I mean, this could be completely innocuous.  Or, if they put a big banner up that said "Don't go here," well, that wouldn't be so good.



STEVE:  Or [emulating buzzer].  That would be a bit of problem.



LEO:  They don't tell us how they're going to do this, what it's going to look like?



STEVE:  No.  And at this point this is just sort of a, this is something we think we should do.  Now, I don't participate over there.  I'm sure that some of our listeners do.  And they're inviting comments.  What I would like to see, and I would love it if someone would get this into the discussion, is something we talked about recently, and that is, while we're going to be creating additional distinctions, I think it's important to distinguish a domain validation certificate, a DV certificate, from anything higher class, like an OV, the Organization Validation cert.  Remember that the DV, with the EFF's effort, which is going to be hitting around the same timeframe, like second quarter of 2015, where that all becomes free and automated.



At the same time, it's important to understand that the assertion being made is not that you're at the company whose site you are, but only that the domain name validates against the certificate.  And that's a subtle but important distinction. So, I mean, if there's some way to, without confusing people, to say we do have EV certs special, it would be nice to have organization validation somehow showing stronger than domain, like then the free automated certs that we're going to start having around the middle of 2015.  And then of course they're going to want to do something, who knows what, maybe a yellow triangle or an exclamation point.  But, I mean, what they're going to try to do is to affirmatively say to people, your data is not secure on this connection.



LEO:  Yeah.  I mean, we'll see.



STEVE:  Yeah.



LEO:  Depends how they do it.



STEVE:  Yeah.



LEO:  Unlocked, you know, an unlocked padlock was there for years.  That's how Netscape did it.  Remember?



STEVE:  Yeah, but you had to go looking for it.



LEO:  Yeah, it was like the bottom of the...



STEVE:  Right.  And so the idea will be this will be in the URL bar.  It'll be in your face so that you're not, you know, so that you're being, I mean, their idea is to put pressure on those websites that will display that in order to induce them to go get themselves the free cert through the EFF's system.  And, I mean, I'm not saying it's a bad thing.  It's just it could be nice.



LEO:  Be ready, yeah.



STEVE:  Yeah, exactly.



LEO:  Yeah.  We'll see what they do.



STEVE:  Turns out that there was a major unreported cyber attack against - that went unreported from February 10th, when it occurred, until just a few days ago, against Sheldon Adelson and his Sands properties, the Venetian and the Palazzo.  This was on February 10th that they got hit by something that is reminiscent of the Sony attack, but different because this didn't appear to be about exfiltrating incredible amounts of information, as did happen with the Sony attack, but rather deliberately attacking to hurt Sheldon and his properties.



It's believed that this is a direct consequence of him making some very inflammatory statements a few months before that, like I think it was October of 2013.  He was on a panel in Manhattan where he came down very, like, essentially ruthlessly against Iran.  And they were able to verify that these were hackers that were traced back to Iran.  And the point was made in the analysis that independent entities don't do anything without the Iranian government knowing what they're doing.  So the sense being this had to have backing of the government.



People, our listeners and my Twitter followers, have commented that it's annoying we don't know more about the technology of the Sony attack and hack.  What's fun is a lot is known and is now available about this attack that happened on February 10th.  In fact, I wanted to aim people at the story, which was covered in BusinessWeek.  So I created a bit.ly shortcut to help people do it - bit.ly/sands-attack, all lowercase - because there's lots of information.



They found, for example, a very small script that was written in Visual Basic, of all things, was installed in the system and was implicated in this destruction.  This thing wiped out servers.  It wiped out hard drives.  It flew through the network and caused what essentially was, they're estimating, about $40 million worth of damage to the network infrastructure that the Las Vegas casinos run on.  And it also demonstrates the kind of - sort of the nature of the attack.  And when we were talking about the Sony attack last week, I talked about how what normally happens with these advanced persistent threats is that bad guys get a foothold somewhere.  They get a toe in the door.  Somewhere, in a sprawling network, there is some little mistake made.



This report explains that.  And I don't remember now the details.  It was in a completely different, geographically remote casino because Sheldon has a bunch spread all over Asia and not only Las Vegas but also around the world.  There was one casino where a small mistake was made that - oh, I remember what it was.  A brute-force attack on their VPN was detected.  And because that's relatively common, they thought, okay, well,  yeah, people are trying to crack our VPN.  And so this was a VPN into the internal network at that facility.  And somehow the bad guys found a way in, and then that was their foothold, and then they were able to use that in order to jump over to the main Las Vegas properties network and set up their major devastating attack.  So anyway, the article was interesting because it had a lot more detail about the way this was done.  And so I thought our listeners would find it interesting.



LEO:  Actually, a couple of people want to know who Shelly is.  And one of the reasons we're all very interested in this is because we all know Shelly.



STEVE:  Ah, okay, yes.



LEO:  Because he was the founder of COMDEX.



STEVE:  So Shelly is - he is the, what is it, 43rd, 44th most, like, richest person in the world.  Or maybe it's that he has $43 billion.



LEO:  He has 43 billion.  Most of that - so the story of Shelly is fascinating.  He created COMDEX.



STEVE:  Yes.



LEO:  And got out just in the nick of time.  And as far as I know, that's where he got his first billion.  He sold the trade show.  And then he built casinos in Macao.  That's where his big money came from.  But he does also on the Sands.



STEVE:  But isn't that relatively recent?  I thought those were newer than his Sands properties.



LEO:  They're pretty new.



STEVE:  Yeah.



LEO:  And that's when he really started to cash in.



STEVE:  Right.  Well, because, in fact, those are generating massive revenues for him.



LEO:  Right.  The other thing I think is salient in this, what we were talking about when we talked about the Sony thing last week, you could say, well, Sony Pictures Entertainment, they didn't really worry about security.  You can bet - these are the computers that operate the slots.  They operate the security in the casinos.  These are big, big targets for money.  So you can bet they were state-of-the-art secured, I would guess.  Wouldn't you?



STEVE:  Yes.  Well, yeah.  For example, they knew when somebody was pursuing a brute-force attack on their VPN.  So that demonstrates they were looking at bandwidth.



LEO:  They're watching it, yeah.



STEVE:  And they were looking at logs.  And the fact that they've been able to recreate the - and that's why this article is so interesting.  They were able to recreate the footprints of these attackers.  They know where they got in, when they got in, what they did, how they moved across networks.  And you only can do that if you've got really good logging in place.



LEO:  Right.



STEVE:  They obviously didn't stop them.  But they were at least able to retrospectively...



LEO:  Well, partly that's because these guys had no incentive to cover their tracks.  They aren't going to get arrested for this; right?



STEVE:  Right.  And that was another interesting point is that this article talked about the fact that what we're seeing now are cyber attacks against small pieces of U.S. infrastructure, in the case of the U.S., that don't motivate the government to respond.  That is, well, it's too bad Sony got blasted.  And it's, oh, well, too bad Shelly got hit.  But that doesn't merit a military response from the U.S. government.  And so the article drew an interesting distinction, that this was sort of - these attacks were maybe what we're going to be seeing in the future was things that sort of slipped under the radar, but were still doing substantial damage to small pieces of U.S. domestic infrastructure.



LEO:  Yeah, I mean, this was clearly targeted at Shelly.  He's very pro Israel.  He's very active, gives a lot of money.  In fact, he supported the Newt Gingrich campaign well beyond its stay fresh date.  But the interesting thing is, to me, is that here you have something that's highly secured.



STEVE:  Yes.



LEO:  And they still got in.  And that was our point last week, which is you can say all you want about what a crap job Sony did.  But I think a determined attacker with some skills and maybe a government behind them, it's going to be hard.  We are, along with this news, is news that the United States is very actively going into the grid and trying to protect all those systems on the grid, many of which are run by independent third parties who have not great practices.



STEVE:  Yup.



LEO:  That's, I mean, if you really want a cyber war, you go after infrastructure.



STEVE:  Yeah.  And I think maybe that's the point is that that's the kind of thing that could rally a military response from the U.S., if a foreign country was affirmatively found to be responsible for producing damage to the public infrastructure, as opposed to pieces of much smaller private infrastructure.



LEO:  Right.  Easier.  Easier.



STEVE:  We'll see, yeah.



LEO:  Although I've got to think there's nothing more secure than a casino.  I mean, this is the back office operation of the Sands casino.



STEVE:  You raise a really good point, and a lot of the questions that we have today are people following up from last week's discussion about the Sony breach.  But, no, your point is a hundred percent.  I mean, their security had to be topnotch.  And yet, and this was the point that I made last week because, from a standpoint of the things that interest our audience, the question is, how do you prevent what happened to Sony?



LEO:  Exactly.



STEVE:  And I rather gloomily said, "I don't think you can."



LEO:  Don't know.  I don't know.



STEVE:  And so the point is that, again, their network, despite all of the focus, as you rightly point out, that they brought to bear on security in these casinos, they still got hit really hard.  I mean, they were - the story explains they were running around pulling the network cables out of machines that hadn't yet come down because this thing was just rifling...



LEO:  Get off the 'Net.  Air gap it.



STEVE:  Yes, yeah, exactly, because drives were being wiped by this thing.



LEO:  Yeah.



STEVE:  Yikes.



LEO:  Pretty amazing.



STEVE:  So the ethics of disclosure.



LEO:  Ooh, I want to talk about this, yeah.



STEVE:  Yeah.  Bloomberg View did a really nice article yesterday, that the headline was "Keep Publishing the Sony Emails."  And from all the conversation that I've seen over the last week, and there's also been some interesting legal opinion, one of the determiners of what the press might use to decide what they say and what they deliberately withhold out of respect for the privacy rights of somebody whose information was stolen - and, for example, we were talking about comparing email content to nude photos of Hollywood people - is whether the disclosure is in the public interest.  That is, does it serve a valid public interest?



LEO:  Boy, I want to hear this logic.



STEVE:  Okay.



LEO:  Because, I mean, you can make the argument the Pentagon Papers, which were illegally obtained classified documents, it absolutely served the public interest for The New York Times to publish those.



STEVE:  And I was...



LEO:  I don't know if we can make the same argument about Amy Pascal's emails about the negotiations over "The Interview."



STEVE:  I have one.



LEO:  Okay.  I'd like to hear it.  Because I disagree.  We have intentionally stayed away from the content.



STEVE:  You haven't heard it.



LEO:  Let me hear it.



STEVE:  You haven't heard it yet.



LEO:  Let me hear it.



STEVE:  So you can't dis- okay.



LEO:  No, I didn't say I disagree with that.  But I have said up to now - and my problem is that Bloomberg and all these people have a vested interest in publishing this stuff.  It's great for business.



STEVE:  It's also good for something else.



LEO:  Okay, good.  I want to hear the public weal.



STEVE:  Okay.  So the next step from the Pentagon Papers is of course the Snowden leaks.



LEO:  Absolutely.



STEVE:  And I, again, absolutely feel, as I said the day we first reported this, that while I could never do it because oaths are oaths, I thought this was a good thing.  And a year later I remember saying, when we were sort of testing that again, can we imagine having - standing here today, not knowing what we know?  That is, hasn't that been valuable?  And of course the NSA and law enforcement would adamantly disagree that this was in the public interest.  And of course that's the point.



The direct upshot of what Snowden did, of those leaks, has been a year that we've chronicled here on the podcast of radical change in the industry's security posture.  We've suddenly seen Google go crazy, if not overboard, in pushing security.  We've got Apple advertising as a marketing feature the fact that they can no longer decrypt people's phones, where in the past they were able to respond to the letters requiring them to do so.  Google has announced that Android will be following.  We've got third-party communication apps coming out constantly.  And whereas previously our acronym on the podcast, TNO, Trust No One, was something that we and our listeners understood and cared about, suddenly now everyone cares about it.  So it really - there has been a massive benefit of public security that is a direct consequence of what Snowden showed us was going on.



So, Sony.  Sony's also certainly not happy that these details are being published.  And I have no interest in the underwear of executives.  I mean, I don't care about that.  But I'm not sure that the message would have gotten through to the degree it has were it not for these details.  That is, last week I took the time to enumerate much more clearly the kind of content.  I mean, the least disclosure is to say, oh, 12-plus terabytes.  Okay.  That doesn't mean anything to anybody.  So I understood that it was important to say, yes, but that's salary ledgers and financial reports and income projections and blah blah blah blah.  And so that I thought helped, by further enumerating and making more clear the nature of what this loss meant, helped it to hit home.



And while I have no interest, and I haven't looked at or gone seeking any of the details of the email, it's been all the buzz in the press.  And it's evoked apologies and all kinds of additional pain.  And while I wouldn't wish that pain on anyone, the sad thing is I think it's human nature that that's what it takes for people who really need to be pushed to increase the level of their security to do so.  That is, there are certainly executives now, and actually I've received email from people saying - I mean, like, prominent people - how do we get ourselves secure?  Because the nature of this, the details are unfortunately necessary in order to get people to understand what it really means.



And so I would argue that that's in the public interest.  It's in the public interest, I mean, in corporate interest, if it finally penetrates the thick skulls of the CEO and the COO that they're going to have to spend the money that the CIO has been begging for in order to implement better security because security is hard.  It's painful.  It's difficult.  And increasing it is a good thing.  So that's my argument.



LEO:  I totally disagree.



STEVE:  Okay.



LEO:   So it would be like saying, hey, you just got robbed of $100,000 by leaving your door unlocked.  So, but we're going to keep the money so that you learn the lesson that you ought to lock the door.  This is stolen material.  There's no excuse for telling people what somebody made to make a movie.  The list you gave, I have no problem with the list you gave, or I would have stopped you.  The list you gave is completely appropriate and fine.



STEVE:  Right.



LEO:  I don't think that the contents of those emails should be disclosed.  I think they're stolen goods.  I think it's as bad as showing the naked pictures.  The press would have shown the naked pictures if they thought they could have gotten away with it.  The only reason they didn't is because they were naked pictures.  This is just as good, as far as they're concerned, is going to generate just as many clicks.  And I think every argument I hear for releasing the salacious details of the Sony leak is an argument from somebody who says, "I'm going to make money on this because we're going to get lots of clicks."  I think there's - I don't see how that improves - look.  Sony knows what got stolen.  I don't think this improves their attitude.  And what you listed, I like what you listed.  I think there's nothing wrong with saying here's what they got.



STEVE:  Right.



LEO:  Without revealing the details.  And I don't think that's what we're talking about.  I think what Sony's saying is stop publishing our private emails.  Those are private.  I don't think they should be published by journalistic entities who are equating it with Snowden's revelations.  These are not Snowden's revelations.  Anyway.  You stand firm.



STEVE:  Well, yeah.  I mean, I see your point.  It's not Sony we're trying to teach a lesson to, though.  That horse has left the barn.  It's the other companies whose behavior could improve, but only if they understand what's...



LEO:  I don't think it's The Verge's job to make these other companies improve their security.  I don't think it improves the public - there's no public benefit from us knowing how much James Franco got for being in "The Interview."  I just - I don't get it.  I don't get the value.  I agree, believe me, I'm a firm defender of the fourth estate and the right of the press and the people's right to know, if it affects the people.  You can't make that argument.



STEVE:  Right.



LEO:  That any of this salacious stuff affects the people.  This is publishing it because we love reading it.  And I confess, until I really kind of thought about this, I was reading all those articles, and I even reported one tidbit, which was what James Franco got paid for driving himself to work because that's, wow, what a story.  But as I started to see more and more, I started to really feel for these people.  And these people are not the people who were responsible for the poor, lax security.



STEVE:  Correct.



LEO:  Why should, I mean, I don't understand why Seth Rogen and James Franco should have to suffer because some CIO didn't do his job.  And I don't see how it benefits any of us for them to have that information revealed.



STEVE:  Right.  Well, and Brian Krebs reported, he said:  "Over the weekend I received a nice holiday letter from lawyers representing Sony Pictures Entertainment, demanding that I cease publishing detailed stories about the company's recent hacking and delete any company data collected in the process of reporting on the breach.  While I have not been the most prolific writer about this incident to date, rest assured such threats will not deter this reporter from covering important news and facts related to the breach."



LEO:  Nor should they.



STEVE:  Right.



LEO:  I'm with him on that.



STEVE:  Right.  And so the letter that he received said SPE - and this of course is from our friend David Boies, who is the attorney who stepped into this.



LEO:  Boies, yes, yeah.



STEVE:  Yeah, Boies, said:  "SPE [Sony Pictures Entertainment] does not consent to your possession, review, copying, dissemination, publication, uploading, downloading, or making any use of the stolen information, and to request your cooperation in destroying the stolen information," said SPE lawyers.  And that's what Brian wrote.



LEO:  I wouldn't want my private emails to be revealed to benefit - who, I don't know - to make people be more secure.  I'm sure you wouldn't, either.  I've had my private emails revealed, and I don't like it.



STEVE:  No, no, it's, again, it's not - no.



LEO:  I'm against it.



STEVE:  There's no question that the degree to which this is bad for Sony affects other companies' security.



LEO:  Right.



STEVE:  That's my belief.



LEO:  But I also agree with you and Brian that a free press does not get deterred by this kind of thing.  But I would guess that Brian is not, I mean, his audience doesn't care...



STEVE:  No.



LEO:  ...about the details of what was leaked.



STEVE:  He's like our audience.  It's like ours, where we were talking about the broad...



LEO:  The security implications, yeah.



STEVE:  Security implications and a broad-stroke appreciation for what this meant from a security standpoint.



LEO:  Right.  I would also say, hey, be careful what you defend in case it comes back to haunt you.  I wonder how the editors at some of these publications would feel if the same thing happened to them.



STEVE:  Yeah.  Yeah.  Well, and that's, I mean, my point is nobody would think this is good.  But security is hard.  And it needs respect.  It needs attention.  It needs money.



LEO:  Right.  Well, I agree with you on that.  But I, gosh, if you just say all the stuff that they got, isn't that sufficient?  They have to be - you have to embarrass people for them, for others to take security seriously?  That's sad.



STEVE:  Yeah, it is sad.



LEO:  But maybe that's the state we're in.



STEVE:  So Verizon last Thursday introduced, to some fanfare, Voice Cypher, along with the encryption company who created it called Cellcrypt.  And they said this "offers business and government customers end-to-end encryption for voice calls on iOS, Android, or Blackberry devices equipped with their special app.  The encryption software provides secure communications for people speaking on devices with the app" - now, this is not me speaking, this is them, because otherwise I'd be putting air quotes around all this - "regardless of their wireless carrier, and it can also connect to an organization's secure phone system."



And then they said:  "Cellcrypt and Verizon both say that law enforcement agencies will be able to access communications that take place over Voice Cypher, so long as they're able to prove that there's a legitimate law enforcement reason for doing so."  And the vice president, the North American vice president of Cellcrypt, a guy named Seth Polansky, disputed the idea that building technology to allow wiretapping is a security risk.  He said:  "It's only creating a weakness when it's a legitimate government agency request.  Just because a government access option exists doesn't mean other companies can access it."



And then, as if that wasn't all just crazy enough, I love their slogan.  They doubled down with the slogan:  "Security when it matters most."  Which of course is exactly what it isn't because, when it matters most, the government is able to wiretap it.  So anyway, I just got a kick out of this, that they're - I think it's also not cheap.  The app is free to download, but in the announcement I remember seeing, like, $45 a month you pay for the privilege of this Verizon-backed, point-to-point voice encryption.  We already have free solutions that do this, that we've talked about on the podcast.  So it's like, well, I'm sure there will be users of it.  And it's okay.



I did forget to mention last week, and I intended to, that there was just, in miscellaneous sci-fi notes, that there was a three-night miniseries that would be airing on the Syfy channel.  The first chapter was last night.  I did tweet it yesterday beforehand, and I know that a bunch of my followers had intended to DVR it and then did.  So I was glad I remembered at least then.  I'm sure that Syfy will be reairing it.  If they're not reairing last night's tonight, you know, they tend to reair this a lot.



So it's yesterday the 15th, today the 16th, and tomorrow the 17th, called "Ascension."  And I watched the first hour of it before it got to be my bedtime, and I decided, okay, well, I maybe will finish the rest of last night's and then see.  I got a lot of feedback from people who thought it was great.  It's okay, you know, we're sort of in a sci-fi desert at the moment, or drought.  So it's sort of typical of what you get from them.  And Leo, do you know what this site, gog.com, is?



LEO:  G-O-G?



STEVE:  Gog.com.



LEO:  No.



STEVE:  A listener, Isaac Johns in Louisiana, sent us a note about Abe.  He said Abe's Oddworld has been out for PC...



LEO:  Oh, Good Old Games.  I do know about Good Old Games.  Yeah, love Good Old Games, yeah.



STEVE:  Oh, good.  So they're legitimate?



LEO:  Oh, yeah.  These are all licensed.  These are licensed.



STEVE:  Oh, good, good, good, because the Oddworld series for the PC is, like, $5 or $6.  So if you search for Oddworld, you'll find three of them - Abe's Oddysee, Abe's Exoddus, and Stranger's Wrath - downloadable for the PC.  So I did want, because we've been talking about it the last couple weeks, due to its sort of rebirth on the PS4 and on the iPad, I'm glad to know these guys are legit.  And if anyone is interested, I really, again, for six bucks, if you've got a PC, certainly I remember running it on a PC 20 years ago.  So you don't need some fancy state-of-the-art...



LEO:  It's probably a DOS game.



STEVE:  Yeah.  You don't need a fancy gaming box.  Anything will run this.



LEO:  Actually, no, it's Windows XP or better, it says.



STEVE:  Yeah, so XP, yeah.



LEO:  Yeah, yeah.  That is great.  I'm happy to hear it. 



STEVE:  I wanted to give our listeners a heads-up that that was there.  And, boy, just looking at those screenshots, Leo, just kind of like - I feel nostalgic.



LEO:  Brings back the memories.  What a great game this was, yeah.



STEVE:  So well done.



LEO:  And, you know, the whole plan, as we mentioned, was to have a whole Oddworld Universe that would go on and on.



STEVE:  Yeah.  A quintology was what was originally targeted.  What they ended up doing, Abe was the first character.  Then Munch was the second.



LEO:  Right.



STEVE:  And so they introduced Munch, who was like a weird little guy who kind of waddled around.  And then they sort of went off plan and did a second, like a sequel to Abe, because the first one was - and so, right, there's Munch's Oddysee.  And that was the second one.  Then they did Abe's Exoddus to follow Abe's Oddysee, to create the first three.



LEO:  So there are - they've kind of kept going in ways that I didn't really realize.  There's a few more of them here.



STEVE:  Yeah.



LEO:  So Munch's Oddysee HD came out for the PS3 a couple years ago.  New 'n' Tasty.



STEVE:  And that's the very new one, which is now...



LEO:  That's the one you were talking about, yeah.



STEVE:  Yup.  And that's on the PS4, and it'll be coming out with other platforms.  But basically it's a remake of the original Abe's Oddysee, which you can get for six bucks for the PC.  And especially if you've got kids, I can't think of anything, I mean, it is like, you know, PG rated.  I mean, okay, there's a grinder.  But...



LEO:  It's perfect because it's a little bit gory.



STEVE:  It's a little edgy.



LEO:  Right.



STEVE:  So your kids aren't going to think you're a wimp.  They're going to think, okay, Dad's cool, he knew about this.



LEO:  Yeah, yeah.  Like I said, I played this with Henry when he was probably nine or 10.  And he and I both have very fond memories of playing this game.  This is the last one, Stranger's Wrath, yeah.



STEVE:  Yeah, it'll run on the machine you've got in the garage.



LEO:  Yeah, but now I have to get a Windows machine.  I wonder if those HP Streams - it'd be worth buying a $200 HP Stream just to play this game.  Maybe.



STEVE:  It would.



LEO:  Maybe.



STEVE:  It would, yeah.  And while I was going through the mailbag for today's Q&A, I ran across a nice note.  I don't seem to have the guy's name here.  Normally I - oh, I think it actually was, he sent it to be anonymously.  But so it was Friday, December 12th.  The subject was SpinRite saved a server RAID array.  And this caught my attention because he came very close to the point of no return, but also is clearly operating some major facility.  He said:  "Steve, every weekday morning I do a visual" - so every weekday morning, probably when he goes in - "I do a visual inspection of our servers for any issues," he says in parens, "(scanning the server status screens and hard drive LEDs).  I'm also responsible for backups.



"One morning I was checking the previous evening's backups on one of our NAS servers," you know, network-attached storage.  "I noticed a major read/write error in the backup log, causing the backup job to fail completely.  Checking if the backup volume was mounted correctly, I immediately noticed that the volume had disappeared.  I then began scouring the system logs; and, sure enough, we had a drive failure in our RAID 5 array.  Come to find out we had another drive failure at a prior time, which makes two drive failures at this point, causing the entire array to be lost."  Because remember that a RAID 5 has - it can tolerate one drive failure because essentially it sort of runs like a checksum drive.  And so any of the remaining can reconstruct the entire RAID content.  But you only get one.  That's why I'm running RAID 6.



He said:  "These two failures slipped by me since the visual inspection on this one custom-built server fails to indicate a problem for any of the drives.  It only shows a green LED for power."  And that's a little scary because typical drive back planes now will show you like a red or sometimes yellow error light if the drive is having a problem, separate from drive activity, or in this case, drive power.  So he just - his visual scan wasn't showing that one drive had died some time ago, and now finally a second one followed it.



He said:  "Figuring out the problem took only minutes.  And looking at what the logs were telling me, my mind immediately went to a previous episode of Security Now!.  In that episode, you were discussing how a SpinRite customer was able to save his/her RAID array by removing the drive and booting it as a standalone drive connected via a separate interface.  I thought, I can do this.



So he says:  "I removed the first failed drive, connected to a laptop via a SATA to USB interface, and booted SpinRite.  I immediately heard some truly awful sounds coming from the drive.  Well, that sounds bad; and, sure enough, I could not get SpinRite or the laptop to recognize that drive at all.  Trying the second bad drive, it booted, and SpinRite saw it.  Running Level 2, I noticed that at times the drive would seem to have a hard time reading a sector.  After a few seconds, it would work through it and go on to the next sector."  Which of course is exactly the behavior that SpinRite users through the last couple decades have seen.  And that's what SpinRite does is it sits there and fixes that sector, and then we get to move on.



He says:  "I ran SpinRite until 50% completion and decided to give it a try back in the server.  Sure enough, the drive came back up, and the RAID controller gave me the okay, and the RAID volume is back up, but in degraded mode since the complete loss of the other drive.  I was able to get all of this done within one workday and had backups running again that evening with no data loss.  I've got two new drives on the way and will be replacing them and rebuilding the array as time permits.  Thank you for a great product."  And whoever you are, thank you for the great testimonial.  I really appreciate it.



LEO:  Steven "Tiberius" Gibson.  He is @SGgrc on the Twitter.  That's one way you can ask questions.  You can also go to his website, GRC.com/feedback, ask questions there.  And you have cobbled together some questions from our audience.  You ready?



STEVE:  You bet.  I was going to say that we've really developed a nice little community over on Twitter.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  It's really - it's vibrant.  And, you know, I get great tips and leads from people who want to make sure that I've seen stuff.  And I'm able to answer short questions.  And I always like, you know, I get up in the morning, and I scroll back and catch up with what has gone on while I've been unconscious.  And so, yeah, it's really been a good thing.



LEO:  Isn't that nice?  And they're global.  They're all over the world, like this.  The first question comes from Dorset in the United Kingdom.  Andrew Stevenson wonders about the POODLE TLS attack.  Steve and Leo, Ivan Ristic over - he doesn't talk like that.  Ivan Ristic - I'm doing the Dick van Dyke from "Mary Poppins."  Ivan Ristic over at SSL Labs has implemented a test for POODLE - oh, of course Ivan has - against TLS.  My question, does this attack deserve an F rating?  Do you think this attack is more damaging than POODLE against SSL3?  Also, have you seen that SSL Labs now demotes sites to a grade B if they support RC4 ciphers?  To reacquire your previous - I guess I'm wondering, I'm thinking Andrew might just happen to have a site with a B rating.  To recover your previous A+ rating for GRC.com - you mean you don't have one, Steve?



STEVE:  No.



LEO:  You'd have to remove RC4 ciphers, disable SSL3, upgrade to SHA-2 certs, install TLS_FALLBACK_SCSV downgrade attack prevention, et cetera, et cetera, et cetera.  What do you say?



STEVE:  So, okay.  So GRC used to be A+ rated at SSL Labs.



LEO:  Oh, man.



STEVE:  And we are back to a C.



LEO:  Grading a - C?



STEVE:  A C, as a consequence of a number of things.  I'm still opting for compatibility.  And the problem is that GRC is HTTPS, meaning if you even try to connect to me HTTP, the first thing the server does is bounce your browser over to S.  There's no way to access, to get in the front door without security.  And of course then I also have an HSTS, the simple transport security header with a long life which Ivan gives me good credit for.  He likes the fact that I'm doing that.  So I'm telling all browsers, remember that we're only secure.  The problem is there are still - there's still a big install base of users who I don't want to deny access unless they have the latest and greatest.  I mean, we know that they're out there.  They're unable to use SHA-256 because they don't have Service Pack 3 of XP.  They've got something older than that.



So I'm going to tolerate for, oh, I don't know how long, maybe six months into 2015, a substandard grade from SSL Labs on purpose.  There's nothing wrong with GRC's security.  I do have prevention against insecurity for eCommerce because I don't even use or require security for, like, cookies, for example, for handling our sessions, so there's nothing for POODLE to get that GRC is doing.  That said, we're sort of - there's tension that we've talked about before.  And that's my favorite word to describe this because certainly Ivan's whole point of having SSL Labs grading websites is to find problems with them.  That's his deal.  Mine is to offer a service to as many people as I can.  And meanwhile, that against the backdrop of us moving forward with standards.



So I do think it's time that I drop RC4.  And at that point I think I get to pop up to a B rating.  So I won't have the A+ that I had a few months ago, before we knew that there were these additional, at the time unseen, problems in the protocol.  I'm doing everything the same, but now we've decided, okay, this is a problem.  And so I am going to drop RC4, and I'll disable SSL.  But I'm going to hang back with SHA-1 certificates because there's nothing that anyone knows is wrong with those.  And we will see how Chrome moves forward with their push for SHA-256, which I support, and I'll switch over to those.  But I'm going to hang back.



The idea will be that, as other sites switch, that will create pain for the people who still don't, still can't do SHA-256.  They will be forced to use Chrome or to use Firefox.  They will no longer be able to use IE.  I want them to still be able to GRC.com.  So I'm going to lag on that, and then I will make a switch.  And of course, if we do find that, like, something is surprisingly wrong with SHA-1, which nobody at this point expects, then I can easily switch over to 256.



So, yeah, I'm going to tolerate - I'll bring my grade up to a B, I think, by agreeing that RC4, it's time to say goodbye to that, and SSL3.  It's now time not to allow a downgrade to SSL3.  It would be nice if Microsoft adds this TLS fallback to their offerings.  We'll see if they do that because, if they would add that to server platforms that they're still supporting, and they're still supporting my Windows Server 2008 R2, if we could get that feature in an update, then that would be a good thing, too.  That would help everybody.  But I can get rid of SSL3 without a problem.



LEO:  I think there's a little bit of...



STEVE:  Yes, there is.



LEO:  I'm a little dubious about Ivan being the arbiter of what is good and wholesome on the 'Net.  And I'm always just a little uncomfortable with recommending SSL Labs tests for that reason.  It's just one guy's opinion.



STEVE:  Well, I mean, I guess the problem is that it's hard not to give a grade.  I mean, that's just a powerful psychological thing.  And I loved having an A+ while I was A+.  I only had that for a few months, and then I fell back off of the leading edge of the cipher curve.  It would be a little nicer, I mean, he does break it all down.  So somebody who cares can look at the things that I'm doing and see, oh, look, Steve's supporting perfect forward secrecy, like with all of the ciphers anyone is using.  And way down at the bottom there's a couple RC4s because he doesn't want to lock somebody out who wants to get to his site for the purpose of using the services at GRC.  If I were to do that, nobody could ever use GRC.  And that bites a little bit.  So I'm going to lag on that.



LEO:  Sometimes the perfect is the enemy of the good.  This would be a good example of that.  Phil S. in Central New York coins the term "The Gibson Comma."  There's a Twitter account called the Oxford Comma that tweeted me, "Leo, do you support or do you not the Oxford comma?"  Hi, Steve.  Avid listen - I haven't responded yet.  Avid listener from Central New York here.  During the past few months my team and I have been patching our web servers monthly - monthly - thanks to POODLE and the Microsoft patches and so on.  We value and use your cipher suites list for our hardening procedures.  Oh, that's great.  That's on GRC.com.  You can go to bit.ly/grcciphers, with an "i."  But I discovered a missing comma - oh, dear, oh, lord - on line 24 which we've dubbed "The Gibson Comma."  Oh.  A quick fix on your end, but while you're in there can you review and update the suites as SSL Labs is capping grades to B when it sees RC4?  Many thanks.  Phil.  Did you fix the comma?



STEVE:  No.



LEO:  No.



STEVE:  No, because I wanted you to click on the link first.  So when I first saw this...



LEO:  Ha ha ha, it was a joke.  I get it.



STEVE:  No, no, no, it's real.  When I first saw this, I thought it said "The Gibson Coma."  And I thought, what?  That doesn't sound good.  I don't want to be inducing a coma in anybody.  Anyway, so you can see, like, the fourth from the end, and it happens to be, I think, one of the RC4 lines.  So what this is - yup, there.  Oh, it's at the end of the MD5.  It's missing its comma there.  So that's the Gibson Lack of Comma.  So what that is...



LEO:  You've got a new line.  I don't think you need a comma and a new line, okay?  I'm just saying.



STEVE:  Yeah.  So this is for Windows servers.  I went through and looked at all the available cipher suites and carefully hand-tuned the list in order of the one we would prefer that a client connected with first.  So it's very carefully designed for maximum forward secrecy and maximum security as we go down the list.  So it goes from strongest to weakest that are currently offered by Windows server platforms.



LEO:  I would presume the server would query in that order; right?  It would try to connect with the first one, and then the second, and then the third.



STEVE:  Well, what happens, yeah, what happens is the client, remember, in the TLS handshake, the client offers all the ones it has.  And so the server then uses the sequence that I have created, going down its list, looking for the first match with any of the ones in the client.  Thus we get the strongest negotiated security available.



And so I have been needing to go back in because, with that update a couple months ago, I think it was two months ago, I want to say it was 068 was the Microsoft update, that was the one that silently fixed a problem that had not previously been disclosed and treated us to four new cipher suites which were really new and tasty, to borrow Oddworld's title.  And so I've been wanting to merge those in.  And that would of course push, now I'll push some of the RC4 ciphers off the bottom and then pop my grade up at SSL Labs from an embarrassing C to a, well, somewhat less embarrassing B.  At least I could maybe beg my way into a good school.



LEO:  Well, yeah.  Gentleman's C is not going to work here, I think.



STEVE:  No, I don't think so.



LEO:  You need to step up your game.



STEVE:  So for anyone who's interested, as you said...



LEO:  And fix the comma.



STEVE:  ...it's bit.ly - yes.  Oh, yes, thank you for - yeah.  Bit.ly/grcciphers is the list.  But that's the old one.  If you look at it, and you see that there's a comma missing from the fourth to the last line, and there's still some RC4s, then you know you don't have the new one.  I'll be getting to that here pretty quick.



LEO:  That's why you left the comma out.  Now we know.  So people could tell if it was...



STEVE:  Yeah, we have a - it's a canary.



LEO:  A canary.



STEVE:  It's really weird, too, because Microsoft has a character limit on the length that string can be.  So I put in new lines to make it visually clear.  But to use it you have to remove the new lines and then cut and paste it into the registry.  And I think it's 2048.  And the problem is there are more useful ciphers that you'd like to have that are available, except you run out of room because they're too long.  And so it's, ugh.  And so it really is sort of a balancing act.  You've got to, like, you've only got 2,048 characters, I think that's what it was.  And so you've got to go through and go, okay, well, we don't have room for this one, but we do have room for that one.  And so you have to, like, deliberately withhold some you'd like to have in the interests of, again, of compatibility.  That's why I spent some time building this list, and people are using it with their servers.  So there.



LEO:  So there.  It's very cool.  How did you build the list?  Did you pull it from the code or...



STEVE:  In the registry help it gives you a list of all of them.  And so I copied that out.  And it also says, but warning, the string you provide can only be 2,047 characters long.  And it's like, okay, is that going to be a problem?  And so then I look, and the list is like 3K long.  So it's like, yes, that's going to be a problem.  I can't have them all.



LEO:  I love it.



STEVE:  They've got to fix that.  That's ridiculous.  I don't know what that's about.  Come on.



LEO:  Ron in Daytona Beach, Florida.  He's got a question about VPN usage and spying:  I use a VPN most of the time using proXPN, our fine sponsor.  Thank you, Ron.  Question:  When I connect, I have many choices of terminating VPN locations.  Yeah, that's one of their features.  The U.S. one gave me the best performance.  That makes sense.  It's geographically proximate.  However, I feel that when I connect to one of the U.S. ones, my traffic is still subject to spying.  Oh, no.  I'm guessing my ISP can't track me directly anymore, but the National Spy Agency is still collecting my packets.  Is this true, or am I just being overly paranoid?



STEVE:  So we see this question in various forms, and I know you get it a lot, Leo.



LEO:  Yeah.



STEVE:  I've heard listeners on your weekend show, The Tech Guy show, asking.  The question would be, do you think the NSA is specifically capturing traffic from the proXPN servers more than they're capturing traffic coming into the U.S. through the fiber optic undersea cables.  And maybe it's all of the above.  But I guarantee you that there are taps on all of the oceanic cables coming into the country because that's where terrorists are, presumably.  And their articulated responsibility is to protect us from them.  So we know they're tapping traffic coming into the country.  We also know that they're sniffing what they can get that's available within the country, unfortunately.  There's that room that we know about in L.A., or was it San Francisco, where the fiber optic tap was installed that we originally talked about a year and a half ago.



LEO:  AT&T WorldNet in San Francisco, yeah.



STEVE:  That's it.  So I don't really think that there's a difference.  What the VPN certainly does is it protects your ISP from collecting any metadata.  Metadata, of course, is even if they can't decrypt what you're doing because you're over SSL or TLS - boy, I wish they hadn't changed the name.  That just really annoys me.  I guess I just have to support the TLS.  Everybody knows what that is now.  They can't see what's in there, but they can see the IPs that you're visiting, and they can see the DNS queries that you're making.  So running through the VPN does prevent that.  It prevents any visibility into your traffic until it gets to that server.



But as for NSA difference, I really don't - can't say that I would imagine it makes a difference.  We will soon, eventually, when the world lets us, get to our podcast about the Tor Deanonymizing which is on my very short list of things to talk about, because as I mentioned it looks like it's not quite providing the protection that we were hoping under some circumstances.  But short of that, I think that the VPN offers local protection, but probably doesn't matter too much whether the NSA is checking or not.  I think they're as likely to be looking at traffic coming into the U.S. if you connect to an extraterritorial VPN server.



LEO:  Strikes me that, if people took the energy that they spent trying to protect themselves, possibly futilely, against snooping by the spy services, and instead directed that energy towards our members of Congress, saying fix this, there'd be more - that'd be a more useful use of your juice.



STEVE:  Or both.  Let's do both.



LEO:  You could do both.  But people spend so much energy on, well, is this safe?  Are they going to be able to spy on me here?  Just send a couple of messages to your member of Congress, too, as long as you're doing that.  Because that's really the only way, and maybe even that's not going to be good enough.  But that is the only route to getting this in hand.



STEVE:  Leo, I think we're heading for legislation which mandates a backdoor.



LEO:  Yeah, we do look - it does look like that.  You've got your Ron Wydens on one hand, and then you've got your backdoor guys on the other.



STEVE:  Yeah.  And, I mean, the boogieman of protecting us from the bad guys, the whole terrorism argument, and the argument, you know, I mean, we talked last week about Posner saying "I can't believe it's legal for anyone to sell a phone that can't be decrypted."  It's like, oh, goodness.  I mean, I just think we're losing this.  And I predicted a few years ago, which is why I suspended work on CryptoLink, because I thought, well, I don't want the government to come along and say, "Gibson, you've got to build a backdoor into the VPN you just spent all your time making absolutely secure."  It's like, uh, no.



LEO:  Anthony Headley, who must also be from the U.K. because that's a very British name, wondered:  Whatever happened to the SmushBox?  Hey, Steve.  Whatever happened to Mark Thompson and company's SmushBox?  In the last episode, Leo remarked the guys from ITPro were sending SMS notifications, and I was reminded of SmushBox.  Yeah, we ordered one.  I have one.  I know you do, too, Steve.  From their site I see they had a rocky start due to some faulty microSDs.  They offered to fix the issue.  That seems to have solved the issue.  Where does that stand right now, Steve?  I'm just wondering if either of you have received your boxes - yes.



STEVE:  Yup.



LEO:  Do they work?  Can't tell you because I haven't set it up.  Thanks, love the blah, blah, blah, Anthony.



STEVE:  So we've talked about it since.  And I need to distance Mark Thompson from this.  It wasn't his company.  It was some guys that he knew of, and I knew of them because I know of him.  And he thought it was a cool thing.  I mean, he thought it was a neat idea.  And you and I agreed, Leo, and we both got them.  The problem, or part of the deal was, they had a special deal with T-Mobile so that for $20 a month you could have unlimited number of messages that this SmushBox would send.



LEO:  Yeah, that was cool.



STEVE:  That was what that was about.



LEO:  And that ran out.



STEVE:  And, yes, and that's what happened was it turns out that one hand didn't know what the other was doing.  They got into some fights with T-Mobile.  And so they did send an email out to all the SmushBox owners, apologizing for the fact that they were unable ultimately to honor the original contract.



LEO:  But this will still work.  I just have to pay more.  Is that right?



STEVE:  Precisely.



LEO:  Oh, okay.



STEVE:  So, yes.  So it is a beautiful, nice, USB interface to text machine that can send out mass texts.  But it's up to the individual to create an account with T-Mobile, rather than all running it through a grandfathered blanket $20 a month forever deal.  That's what fell apart.



LEO:  So somewhere I can put a SIMM in here.



STEVE:  It's got one built in.  It's already in there.



LEO:  Okay.  So I would just call T-Mobile and say, hey, activate me, baby.



STEVE:  Yes, exactly.  And then you're able to send and receive texts with that.  And so one of these days you and I are going to figure out how that's useful.  It's a beautiful thing.



LEO:  Well, I always, you know, and we have been - as you know, we're designing a new TWiT site.  And it's kind of one of the things on our wish list, to be able to send out text notifications when a live show begins recording...



STEVE:  Oh, yes.



LEO:  ...when a show has finished recording and is now in editing, and when a show ships.



STEVE:  Special, yeah, exactly, like allow people to subscribe to a feed of real-time events.



LEO:  Right.



STEVE:  Yeah, very neat.



LEO:  Well, that we can do.  And we can easily do something that they pull.  But this is pushed.  So I don't know, I mean, it's easy to do something that's pull, that you would poll us - in fact, that's kind of how RSS works anyway.



STEVE:  Yeah, but I think texting is just so ubiquitous and so simple that - and people are able to send back, like, send back a stop if they don't want to receive that anymore and basically control it through text.  I think that's cool.  And look, you were even able to find yours.  I don't know where - mine's, like, mine's BuriedBox.  I don't know where mine...



LEO:  You know what's bad?  I can't find the documentation.  Must be on...



STEVE:  Might have been online.



LEO:  Maybe it's on the website.



STEVE:  Yeah.



LEO:  There's no documentation at all.  It is pretty, though.



STEVE:  Well, they did a beautiful job.



LEO:  Yeah.  My SmushBox.  Question 5 from Michael Peters.  He hails from Meerbusch, Germany.  Meerbusch.  He wonders about whitelisting executables:  During the recent episode of Security Now!, while you were talking about the Sony case, you mentioned whitelisting of executables as the "only real way to keep the bad guys out."  Indeed, I see this as the last chance left to get more security into a larger company network.  For our company and our network, no user except the IT people should be able to launch any kind of program that hasn't been approved by the IT staff.  Boy, that seems obvious.



STEVE:  Yeah.



LEO:  Unfortunately, we never took the time to give Windows AppLocker a try, and I'm wondering whether such a scenario could be realistic, or am I missing something?  Love your show, although it frightens me more and more.  Steve is really great; Leo, too.  Besides, it's helping me improve my English.  Well, your English is perfect.  Kind regards, Michael from Germany.  We have an AppLocker license.  When we bought the new Dell machines for our editors, six of them, Russell talked me into - he said we should get AppLocker, too.  I said, deal.  So, but I don't think we've turned it on yet.  But we haven't - the machines are just getting implemented now.  So what is that?



STEVE:  So AppLocker is a feature that was introduced into Windows 7.  And as we know, I will ultimately be moving from XP to 7, kicking and screaming, at some point.  I mean, I have 7 everywhere else, just not on my main system because it's such a pain.  I mean, I have to, like, start over.  I have this incredibly mature, perfect workstation with everything installed.  And just the idea of starting over is daunting.  And there's never time.  I've got to, like, say, okay, well, after SQRL and after SpinRite 6.1, then maybe I'll make the switch.  But the point is that it's built into Windows 7, and it's continued to thrive, and it's in Windows 8, as well.  And it is a built-in - it's not - there's, like, I think it's in Ultimate and, you know, they've got all these different SKUs now.  I don't think it's in Home or even Pro, but it is in Ultimate.  And I'm going to deploy it from day one because...



LEO:  It's a little weird to do it on a home system.  I mean, in a business you can say, hey, you can use Office and our line of business stuff, but you can't use any other apps.  That's a reasonable thing for a business to do.  But at home, don't you want to just do what you want to do?



STEVE:  Well, but it's me; you know?  And what I was going to say was...



[Crosstalk]



LEO:  ...locker?



STEVE:  No.  So AppLocker is an application whitelister.



LEO:  Right.



STEVE:  So only the specific apps which have been whitelisted are allowed to execute.



LEO:  And a malware can't pose as one of those apps; right?



STEVE:  Precisely.



LEO:  Is there a hash or something?



STEVE:  Yes, yes.



LEO:  Okay.



STEVE:  So, and remember back in the day of ZoneAlarm there was the question of whether - because ZoneAlarm was a whitelisting firewall.  It would pop up and say, such-and-such wants to access the Internet.  And you'd say - you'd look at it and go, okay, yeah.  And then the question was whether malware could say that it's Internet Explorer, you know, IExplore.exe, and sneak by.  But it wasn't just a filename match, it was a match on the signature of the app itself.  So it caught that.  So that's what's built into Windows 7 and 8.  And I just - I want to try it.



One of the things that I do is I have some sounds associated with different events in Windows.  And one of the events in Windows is application execution.  And it's just a little snap sound.  But every so often I'm, like, working, and I hear a snap.  Which means I didn't just start something, but something started.  And I sometimes wonder what that was because that would be a quick clue that something's in my system that I'm not aware of.  So I'm going to do the experiment.  And this is the kind of the thing that's difficult to turn on later because, like, nothing will work.  Although you are able to put it in an audit mode, and that could be useful all on its own.



LEO:  Yeah.  You say, hey, audit what I'm doing right now because I know there's nothing bad on here.  Please add these things to my whitelist.



STEVE:  Right.



LEO:  Yeah.



STEVE:  Right.  And so you train it during a time when you know that your system is fresh and set up.  And then you're able to look at a log of the things it has blocked or that it has permitted and, like, tweak it over time.  It's basically, it's like an application firewall.  And I would argue maybe that's where we're going to end up.  We ended up there with data firewalls, and that may be the way that we ultimately lock our systems down.  And it's built into Windows.



LEO:  Love to get this for Macintosh.  So am I correct, because I say this on the radio show all the time - and I probably should run these things by you before I say them.  But I have been saying on the radio show, look.  To get malware, to get on your system, the bad guy has to have you run a program in some form or fashion.  The malware maybe a malformed PDF, and you run Reader, and it's got a bug.  But ultimately the way you infect systems is by executing code.



STEVE:  Correct.



LEO:  And if the bad guy can't get you to execute code, then you're safe.  And so the idea being we only can execute these set programs.  You should be safe.  Now, if one of those programs is Reader, and you get a malformed PDF, and Reader's not up to date, well, you'll still get bit.



STEVE:  Correct.  Or if you're lured to a phishing site, and they tell a nave user, oh, we'd love to show you this video that you're interested in, but you have a vulnerable or obsolete version of the video player.  Click here to update it.



LEO:  Right, right.



STEVE:  And so many people who are not podcast listeners...



LEO:  Easy, easy to fall for that.



STEVE:  Yes.



LEO:  But, now, AppLocker would stop you because the installer for this...



STEVE:  Correct.



LEO:  ...malware would be not allowed. 



STEVE:  Correct.



LEO:  Yeah.  All right.  OS X does something a little similar.  But of course, as always with Apple, it's Apple that gets to decide.  You can say I'm not going to run unsigned code on this machine, and Apple is the signatory.  So if it's not signed code, it won't run.



STEVE:  Right.  And of course we did that with Windows with device drivers.  Microsoft said we're going to up the ante on device drivers, so you've got to have the device drivers signed.  And that is a useful bar to put on applications also, say that we're not going to run applications that don't come from - theirs is, I'm blanking on it, I have a license from Microsoft.  All of my apps are signed.  Authenticode is their executable technology.  And so it's like, don't allow anything that's not Authenticode signed.  The problem is it's not impossible for bad guys to get an Authenticode cert.  And in fact one thing we did see that happened from the Sony hack is that malware was quickly signed with the Sony certificate.



LEO:  [Laughing]



STEVE:  Which was stolen from Sony.



LEO:  Oh, lordy, lordy.



STEVE:  Yup.



LEO:  So this says "allow apps."  This is in the security settings on OS X, Yosemite or later.  Allow apps downloaded from, in the most strict form, the App Store only.  So Apple has approved Apple's whitelist, in effect.  But most people, and the default is, Mac App Store or identified developers.  That really means one with a certificate that is an Apple-generated certificate.  And then this is the least secure and, by the way, not the default.  The default setting is no apps downloaded from anywhere.  So current Mac machines, really, you can only run apps, unless you've changed the settings, from the App Store, approved by Apple, or where a developer has a certificate from Apple.  I think that's pretty good.  That's Gatekeeper.



STEVE:  Well, yes.  So, yeah, so what I would do, and I know our listeners, you want to go to that middle option.  Switch it now.



LEO:  Well, that's the default, yeah.



STEVE:  That is, take it off - oh, it is, oh.



LEO:  That's the default,  yes.



STEVE:  That is the default.



LEO:  That's the default.  If you say "anywhere," they give you this big warning.



STEVE:  Oh, good.



LEO:  And furthermore, they say, in 30 days we're going to go back to the default.



STEVE:  Now, good.  Apple really has learned a lot of lessons in the last couple years.  We've seen them really tightening things up that way.  And that's fabulous.  I mean, it's like allowing Flash and then, like, disabling it again automatically.



LEO:  I know, I love it.



STEVE:  It's like, yes, that's exactly what we want.



LEO:  You can have Flash, but only for a few days.



STEVE:  Yeah.  So I was going to say, if you had that default setting, and you did run an app that was not from a well-known developer, that just gives you a chance.  You're going to get a dialogue that's going to scare you, and then you can say, oh, how much do I trust where I got this from?



LEO:  You actually have to - you have to kind of override it.  It'll say I'm not going to open this because it's not from a certified developer.  And then, if you wish to open it, you need to right-click on this app and select "Open," and then we will open it for you.  But you cannot just, you know, you don't click a button that says "Okay."  You have to kind of do something else.



STEVE:  Right.



LEO:  I think that's the right way to do it.



STEVE:  Yeah.



LEO:  Yeah.  Moving on, Question 6.  Dave Held, Redondo Beach, California.  He was floored:  I was floored by your "Oh, well, nothing can be done" response to the Sony hack.  If it's true, as you say, that computer systems simply cannot be secured against attack - and that isn't exactly what we said, but...



STEVE:  No.



LEO:  Well, don't you realize that implies the end of electronic methods in business and a massive return to paper documents and locked file cabinets?  What movie star will discuss her future roles and earnings via email?  What corporations will store their contract negotiation proposals on servers, or even use anything more complex than a typewriter to prepare them?  By the way, that's one of the upshots of this Sony hack is Sony is in fact stymied.  They are having a lot of difficulty making deals.  They are no longer using email.  They're only making phone calls.  I mean, that is how Sony's responded to this, going back to the Stone Age.



STEVE:  And I think, didn't we hear that Russia had switched to typewriters?



LEO:  Yeah.



STEVE:  For the same reason?



LEO:  Yeah.



STEVE:  Yeah.  Okay...



LEO:  So, but I don't think you were saying it's impossible.



STEVE:  No.



LEO:  Just not practical.



STEVE:  The response is a little more nuanced than that.  But, yes, exactly.  It was, in reality, could I actually claim, could I design a system that would meet Sony's requirements and be secure?  No.  You just can't.  There are...



LEO:  Could you do better than Sony?  Yes.



STEVE:  Yes.  And I talked about a number of things that could be done.  I've been, like, challenging myself in the week since I said that, kind of thinking, well, what would I do?  And something like whitelisting apps so that only IT-approved things will run on your machine.



LEO:  I like that.



STEVE:  Yes.  And then set up a virtual machine which does not have privileges on the network, but is like, you know, uses a VLAN out to the Internet so that, if somebody wants to do anything else, they can do it in this container without IT permission, but they can't access any resources within Sony.  All they can do is get to the Internet.  So if they want to run QuickBooks or whatever, or run an unapproved browser or some network-connected software, they can.  But it won't run on their machine, it'll only run in the virtual machine.  And the only thing the virtual machine can see is the Internet.  It cannot see the rest of their machine or anything else.



So that's the kind of thing that, once you implement it, people kind of grumble.  It's like, well, they didn't have this at my old job.  And it's like, well, no.  We've got security at this place.  So, I mean, there are things you could do.  Also, it really does seem like their network was just one mass of interconnectivity.  And siloing networks, which is some lack of convenience, but it does mean that one entry point doesn't get you to the entire corporate crown jewels everywhere.  So anyway, I did want to clarify in case anyone else felt that.  And I did see some tweets to that effect.  It was like, "What, Gibson can't do it?"



It's like, it's not possible because you have, first of all, a huge number of systems in which we are actually finding vulnerabilities constantly.  And you've got the human factor.  The human factor is why you have a company, I mean, of people.  And they're going to do dumb things.  There just isn't any way to prevent that.  There is a way to lock them down.  And something like whitelisting apps on their machine that is connected and then giving them freedom in a virtual machine that is not part of the Sony network, that would be an interesting thing to explore.



LEO:  Well, and we've talked about AppLocker.  I mean, that's something you can do.  There are things you can do.



STEVE:  Yup.  Yup.



LEO:  But I think that that was kind of my point with the hack of the Sands casino, where presumably they did everything anybody knew how to do.  I can't imagine they weren't following best practices.



STEVE:  You know, I'll bet that after that they're doing more.



LEO:  Yes.  Yeah.



STEVE:  So doesn't...



LEO:  There's always more.



STEVE:  Yeah.  So doesn't that tell us that they weren't doing everything that they could do?  Because there's no question that they're doing more now.  And if Sony ever does recover, we know there will be changes there.



LEO:  Yeah.  You hear it pouring rain here?  I don't know if you can...



STEVE:  I do.  I was thinking, where is the - who left the faucet on?



LEO:  Yeah.  Somebody's popping corn or something.



STEVE:  Wow.



LEO:  Mark Jones, Midland, Michigan.  He encountered some unsettling verification questions:  Steve and Leo, love the show, look forward to it every week.  When trying to schedule a FedEx delivery, I was asked to create an account.  I've seen this, and I can explain what's going on.  But I was shocked when a verification page confronted me with multiple choice questions about past addresses, last digits of my driver's license, names of others at my address, type of car registered to me.  I was then even more shocked when it said that I had the answers wrong.  It then asked me a different set of equally curious questions.



At first I was shocked that FedEx could know any of these things.  Next, I felt like I was providing data about myself that otherwise would be unknown.  Others on the web have indicated FedEx is relying on credit reports.  I decided I don't need a FedEx account.  No question here, just an alert at another unsettling turn of events.  Leo might be right, the privacy battle is lost.  No.  There's good news.  This isn't as bad as it looks.



STEVE:  Just I love the idea of encountering a security question, and it's like, what was the name of your first childhood sweetheart, and you type in "Julie."



LEO:  Nope.  No.



STEVE:  And it says, "No.  Have you forgot about Sarah?"



LEO:  That would be scary.  This isn't quite that bad.  He's right.  It comes from credit bureau information.  I don't even think FedEx ever sees this.  I've seen this, I've been exposed to this many times.



STEVE:  So it's trying to, without knowing anything about you, trying to verify your identity...



LEO:  You are who you say you are.



STEVE:  ...and who you are claiming to be.



LEO:  Right.



STEVE:  Ah, interesting.



LEO:  So it's an interesting puzzle; right?  You want to authenticate somebody, but you don't have any previous conversation with them.



STEVE:  Right.



LEO:  So there's no password.  There's no secret questions.  It's like secret questions, but you don't - so the only thing you can do is you go to one of the three reporting credit bureaus, and they provide you with these questions based on information that's in your credit report.



STEVE:  Ah.



LEO:  I don't know what FedEx is doing, but the ones I have used, I'm pretty sure the way it works, these guys aren't seeing it.  The intermediary's not seeing it.  This is directly coming from as an interaction with Experian or TransUnion.



STEVE:  Come to think of it, I've seen...



LEO:  You've seen this.



STEVE:  Yeah, I've encountered that, too.



LEO:  You have.



STEVE:  And there have been, like, some strange addresses for me.  It's like, wait a minute.



LEO:  Yeah, they'll give you four - so what they'll do is they'll give you four addresses.



STEVE:  Right, right.



LEO:  Three of which are bogus, one of which - and it often is not the full address, but it's did you ever live at Page Road?  And they'll give you four addresses.  And you pick the one that you did live there.



STEVE:  Right.



LEO:  And that's direct from your credit report because of course all of that stuff is stored on your credit report.



STEVE:  Right.  So they're matching up your real world identity with your cyber identity.



LEO:  And they're not gathering new information at all.  It's like secret questions, but you just haven't prearranged the answers.



STEVE:  Right.



LEO:  So I don't - unless you can think of a - I guess one issue would be if the third party were intermediating.  So if FedEx saw the questions, got the answers, and then - if it made the quiz based on downloading your credit report, well, but they have access to your credit report if you're applying for credit.  You have to give them access to your credit report in some cases, at which point they know all that anyway.  If you've ever given any company your Social Security number, that's because they use it to access your credit report.



STEVE:  Right.



LEO:  Date of birth - name, date of birth, and Social is enough to get your credit report.  So I don't, yeah, I don't think it's an issue.  But you have to be the judge, of course.  I think it's just - it's solving an interesting question.  How do you authenticate somebody you've never met?



STEVE:  Yeah.  How do you match their real-world true identity with their cyber personality?



LEO:  Yeah, and the only way you could do that is with a third party that did know something.



STEVE:  Yup.



LEO:  Mike Vore, Columbia, Maryland, wonders about Sony exfiltration.  I love that name, that word, "exfiltration."  I've been wondering, how could that much data be taken offsite without the NOC noticing that much traffic [the network operations center]?  Even with fast fiber it takes a lot of sustained bandwidth to move that much data.  An extra megabyte or even gigabyte a day might not be noticed, but we're talking 12TB.  That's either high bandwidth or a long time.  What is - see, Sony of course is not telling anybody, the FBI isn't telling anybody how any of this happened.



STEVE:  I know.



LEO:  What's your speculation about how this might have happened?



STEVE:  Many people asked this question, and I just, when I encountered it, the first time I encountered it I added it to the show today because I wanted to respond to it.  I had the same thought myself when we learned how much data it was.  But then I thought, can you - we're talking Sony Pictures Entertainment.  Can you imagine how much content, how much media, how much data they must have transacting over their Internet, I mean, over their Intranet to the Internet?  And the fact is, you know, 12TB for a major corporation's network, eh, that's in the noise.  I mean, that's - and we do know that some of the data was snapshotted on November 23rd and, what, maybe a week later?  So we don't know how long they were there pulling other stuff.



We do know, for example, that they used Sony's own servers to seed some of the torrents, which is so ironic.  I just love that.  So there it's sort of like trickling out over time, and as people use it, you know, the way torrents will.  So anyway, I just think, if it was our network, our individual networks, yeah, we would notice if 12TB was trying to leave.  But, boy, a major media corporation the size of Sony, eh, I just - lord knows how much bandwidth they must have.  And, yeah, I just think it actually could.  If spread out over time, it would just probably sneak right out, just they wouldn't even know.  They wouldn't see it as a blip compared to, like, movies that they've got coming and going across their fiber connections.



LEO:  I would bet that, you know, digital movies now are distributed over the Internet as downloads.  I would bet that some of that came from Sony servers, among other things.



STEVE:  Yup.  Yup.



LEO:  I also think...



STEVE:  Well, actually we know because a bunch of movies were exfiltrated.



LEO:  Well, but those weren't projection copies.  Those were the screeners.  Kind of low quality, in fact, DVD copies that leaked out, as far as I - I have not downloaded them.  I'm told.



STEVE:  Hardly worth going to find.



LEO:  Really.  No kidding.



STEVE:  Besides, "Annie" I can live without, I think.



LEO:  I can wait till Christmas Day, thank you very much.



STEVE:  Yeah, okay.



LEO:  And then there's also the suspicion, you know, I wonder, I guess we'll never really know what really...



STEVE:  I'm hoping, I'm hoping that - because it would really be fun to get the technical readout.



LEO:  That I would have no problem revealing, that kind of information.  Even if we came by it illegally, I would absolutely reveal that information because that is something very, very valuable.  The public does have a right to know how did Sony get hacked, what happened, et cetera, et cetera.  There is some suspicion, you know, Sony got hacked and didn't want to talk about it in February.  It maybe is even part of the treasure trove that's been leaked.  There was a memo saying we're not going to alert the affected parties that we got hacked.  And that was in February.  So it wouldn't - and, by the way, there is a little bit of a nexus because that hack was some - it had something to do with Brazil, and there was a significant number of Portuguese and Brazilian documents in the trove.



STEVE:  Yes.  We talked about that last week.  And I also heard you say on The Tech Guy over the weekend, to somebody who had a virus, you correctly said there's no way to get rid of it.



LEO:  Right.



STEVE:  Once it's in there, you can never know.



LEO:  That could have been the vector, back in February.  And who knows, maybe they've been leaking data, a terabyte a week, since then.



STEVE:  I mean, there is this notion of a foothold.  You get in, and then you go quiet, and you protect yourself, and you scrounge around.



LEO:  Really interesting.  I wish we could know the truth of this.  And that I think would be very useful for prophylaxis, for future.



STEVE:  Yeah.



LEO:  Stephane Blais in Gatineau, Quebec, Canada wonders:  What if Sony was a bank?  Steve and Leo, longtime listener, big fan, yada yada.  As big as Sony's recent hack was, I can't help getting shivers when I imagine how devastating an attack like that would be if it were a bank instead of Sony.  How disruptive would that be?  And for all we know, those things are happening, too.  In last week's podcast, SN-485, you mentioned how impossibly hard it would be to secure Sony's network.  Would it not be just as hard to secure a bank from a determined attacker?  Are banks really that much ahead of the game, or are we all in denial?  I don't want to be unfair to banks, but I do have a vested interest since my bank has my money.  And I expect it's the same for you.  Thank you.



Optional yada yada extra:  On a personal note, I want to thank you both for the amazing education I'm getting from Security Now!.  I work as a security professional, and it's amazing how many times I look smart because of stuff I hear on your show.  I'm also convinced I passed my CISSP exam because of you.  Thank you both, and keep up the great work.  Stephane.



STEVE:  So I think it is without question that banks are more secure, in the same way that casinos are more secure.  And we could almost look at Sony as an example of the other end of the spectrum.  That is, if nothing else, how many attacks has Sony suffered?  How many password breaches?  I mean, Sony has been a constant victim over, you know, we've talked about multiple Sony problems over the years.  And for whatever reason, they seem to keep having them.  So it is certainly the case that lax security makes you more likely to get attacked, and that a bank by its very nature is about security and privacy and secrecy.  Sony, as sort of like the generic business operating corporate side, they're not.  They're about Donald Duck and Mickey Mouse and movies and...



LEO:  That's Disney.



STEVE:  Oh, yeah, well, okay.  Movies and actors and all that.



LEO:  They're artists.  They're artists.  They're not security professionals.



STEVE:  Perfect.  Perfect.  Yes, artists.





LEO:  Although a couple of things.  We know banks get hacked all the time and don't report it, A, they just absorb the loss.  And we know that happens every day.  It's not like the Sony hack because the Sony hack they got everything.  Although who would care if they released a bank vice president's email, really?



STEVE:  Yeah.  What is being - the loss that they're absorbing, though, is more of, like...



LEO:  Funds.



STEVE:  ...vendors losing their credit cards, who then turn to the bank and say, okay, you're going to have to replace all these cards.



LEO:  Yeah.  I think that banks also lose money.



STEVE:  Yeah.



LEO:  They lose money to hacks.  And they just cover it and move on.



STEVE:  Well, and that's a good point.  We also know that banking customers lose money.  There is all kinds of wire fraud and money transfer fraud, where somebody says, hey, all the money in my account is gone.  And we've discussed who is responsible in that event, and I erroneously said that the user, the victim was responsible.  But it turned out that there was a difference between personal and corporate accounts in terms of what was insured and what wasn't.



LEO:  And then Sheldon Adelson, who is probably as protected as most banks, got hacked.  Right?



STEVE:  Yeah.



LEO:  Chase Bank was hacked, info stolen for 83 million accounts.  That was in October.  Hackers attack, crack 10 financial firms in major assault.  That was in October, including JPMorgan.  Remember?



STEVE:  Yup.



LEO:  I mean, this stuff...



STEVE:  Yeah, it just happens all the time.



LEO:  We're just used to it.  You know what?  We're just used to it.



STEVE:  Yup.



LEO:  It's not not happening.  It isn't.  We're just used to it.  In fact, I don't think, you know, we didn't talk much about - that's where the - see, maybe they, okay, you know what?  This backs what you're saying up.  Because JPMorgan got hacked badly last - for 83 million accounts, an untold amount of money, just a couple of months ago.  And nobody talked about it that much.  Sony gets hacked, and a few stars' salaries get revealed, and it's the talk of the town for weeks.  So that does back up your argument that it's not a bad thing to reveal this because it just does raise awareness.



STEVE:  I think it's human nature.  It's got to be bad for anyone to say, oh, I really don't want that to happen to me.



LEO:  And by the way, Chase didn't want to reveal that it had been hacked.



STEVE:  No, it hurts its reputation.  And their reputation really matters.



LEO:  Yeah, yeah.  Well, Steve, I think that's it.  I don't see a Question 10.



STEVE:  Nope, we're done.



LEO:  I think once again you've aced it.  You are an A+ student in my book.  I don't care what SSL Labs says.  Thank you so much for the good work you do.  And it is, it's always - it's an education listening to Security Now!.  We do it every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC.  Do stop by and participate live.  It's great.  You can even come by the studio, if you want.  We always have somebody in this - people love you.  There's always people watching, you know, in the studio.  Email tickets@twit.tv, and we'll make sure we have a seat for you.  This, my studio, the little one, is a little constrained.  There are only really three good seats.  We could fit...



STEVE:  Well, four.



LEO:  There's a few obstructed views.



STEVE:  Yours is one of the best seats.



LEO:  I have a good seat.



STEVE:  You've got the best seat in the house.



LEO:  But there's a couple of obstructed views.  So let us know ahead of time.  You can also get on-demand versions of this show in several places.  This is one show where Steve has a copy of it, which is unusual, but Steve likes to host 16Kb audio versions and handcrafted transcriptions at his site, GRC.com.  We have the larger audio files and video, too, at TWiT.tv/sn.  And of course you can always subscribe on your favorite catcher, iTunes or Xbox or whatever it is you use to listen to podcasts.  Don't forget to go to GRC.com to get SpinRite, the world's best hard drive maintenance and recovery utility.  There's lots of freebies there, too, and you can find out more about SQRL.



Next week it's your talk from, what was that, a Vegas hacker con or something?



STEVE:  Yes, it was November 7th.  It was DigiCert's Security Summit.



LEO:  Ah, okay.



STEVE:  And I gave a really nice presentation, if I do say so myself, of sort of soup to nuts, if I may, for SQRL.  And so that'll be the Christmas Special content.



LEO:  Next week, December 23rd.  And then we will be back live on December 30th.  We can wrap up the year in hacks.



STEVE:  Yup, will do.  And I'm going to give a SQRL demo during that podcast.



LEO:  Oh, we're that - oh.



STEVE:  It's running.



LEO:  Yay.  That's exciting.



STEVE:  Yup, yup.



LEO:  So next week our holiday special.



STEVE:  It's going to - you're going to - your mouth is going to hang open.



LEO:  Can't wait.



STEVE:  You're going to say, wait a minute, that's actually - that works?  That's secure?  I'll go, yup, that's all there is to it.



LEO:  So exciting.  That's really exciting.  So that's December 30th.  Make sure you tune in for that.  Steve, I'm not going to see you till New Year's.  I know you're coming up for New Year's Eve.  That'll be fun.



STEVE:  Yeah.  I'm going to come up a few days before and join you guys in the...



LEO:  In a washed-out house.



STEVE:  ...host party and then be hanging around.



LEO:  That'll be a lot of fun.  I can't wait.



STEVE:  It will.



LEO:  Three a.m. New Year's Eve, 3:00 a.m. to 3:00 a.m. New Year's Day, 24 hours of 2015.  I'm going to stay up late.  Steve did it last time with me.  I bet he'll do it again.



STEVE:  I also signed up, I signed up for doing something in front of a green screen with you.  I'm not sure what I got myself into, but some sort of, like, I don't know.



LEO:  I think we're doing - I think we're acting out a Flintstones episode, and you're Bamm-Bamm.



STEVE:  Oh, good.



LEO:  No, I'm just kidding.  I don't know what it is.  We're doing it for a charity, though, so you should really do any, you know, you should really step up because this is all to raise money for UNICEF, the United Nations Children's Fund, which does great work all over the world, including in the Ebola-ravaged areas of Africa.  They've really been doing good stuff there.  So we thought it would be good to take - we were going to do it anyway.  Why not do it for a good cause?



STEVE:  Yeah.



LEO:  We're going to have auction items, giveaways.  It's going to be fun.



STEVE:  Neat.



LEO:  Thanks, Steve.  Have a great Christmas.  Won't see you till after the holidays.



STEVE:  Right.  Have a great week, and I'll see you week after next.



LEO:  Take care.



STEVE:  Bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#488

DATE:		December 30, 2014

TITLE:		The (In)Security of 2014

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-488.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  For our last show of 2014, we first catch up on two very busy holiday weeks of security craziness; then we step back to review the major events of this past very busy and security event-filled year.



SHOW TEASE:  It's time for Security Now!.  Hey, Steve Gibson's here in-studio with me.  It's going to make it a lot of fun as we go through all of the bad stuff that happened in 2014.  And Steve will tell us what we should do to make 2015 a better year.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 488, recorded December 30th, 2014:  The (In)Security of 2014.



It's time for Security Now!.  And this is a little disorienting to me because normally Steve Gibson...



STEVE GIBSON:  That's my hand on your shoulder.



LEO:  ...can't touch me.  But this time he can.  He's actually up visiting because we're going to do our New Year's Eve party tomorrow.



STEVE:  You betcha.



LEO:  And Steve wanted to actually - is it tomorrow?  Yeah, it's tomorrow, barely.



STEVE:  Starts for you at 4:00 a.m.?



LEO:  Starts in 12 hours, 13 hours?  Yeah.



STEVE:  Yikes.  And I'm getting up at 6:00 for breakfast.



LEO:  You're going to make breakfast?  Last year you made coffee.



STEVE:  I don't think I'm making it.  I can make coffee.  I've got coffee nailed.  Breakfast, uh, not so much.



LEO:  It's so great.  I'm trying to think.  We've only done a handful of Security Nows in-studio.  We did a couple - you've been in my office, I know, once.



STEVE:  A couple times.



LEO:  And then in Toronto we did it a few times.



STEVE:  Oh, well, that's where we began all this.



LEO:  Right.



STEVE:  Yeah.



LEO:  So when I was...



STEVE:  In hotels, remember?  When I'd be coming up, we would do a recording the night before.



LEO:  I remember doing one at the Drake Hotel in my room with - Amber was there, I think.  I was lying on the ground.  Maybe that was another time.  Maybe that wasn't Security Now!.



STEVE:  I remember wandering around Toronto.



LEO:  And once - one we did on the roof.



STEVE:  Yup.



LEO:  Of the Drake Hotel, yeah.



STEVE:  And I used to bring up the Heil mics, and we'd set up a whole little, like, mini studio.  You had a recorder.



LEO:  Did you really?  Wow.  Wow.



STEVE:  Yeah.  With an SD card.



LEO:  It's nice, it's so nice to have you in-studio.  Steve and I have known each other for probably 15 years.



STEVE:  Yeah.



LEO:  And share a love of good cabernets and an interest in security.  And each week we talk about security.  This is a live show.  We did, last week, we did an interesting - we always do a holiday special.



STEVE:  Right.



LEO:  And we used your lecture on SQRL.



STEVE:  Right, which I gave in Las Vegas on November 7th.  DigiCert hosted a security summit, their first security summit.  Which they just did a great job with, really interesting stuff.  And so our podcast watchers and listeners had a chance...



LEO:  They've known about SQRL for a while.  But this was really finally hearing the details.



STEVE:  Yes.  And I did say two weeks ago that I would be demoing it today.  Anyone who can see the screens know that I'm not demoing it today.



LEO:  Why not?



STEVE:  I actually have it running.  It is working, but not public.



LEO:  Okay.



STEVE:  Because when I - I got the implementation finished.  And I'm a big believer, which is why I generally take my time, that first impressions matter.  And there are a couple, when I saw it running, I realized, oh, there are a couple things that I'm not exactly comfortable with the way it works.  And so it's like, hey, there's no hurry.



LEO:  There is no hurry.



STEVE:  I mean, it's all I've done for a year.  This is what I've been on for a year.



LEO:  And for those who just kind of - the elevator pitch on this is it's an authentication, a website login process that does not involve passwords.



STEVE:  I think what we will show, what we will see, is it is a practical, and that's the key, I mean, it's a practical replacement for usernames and passwords.



LEO:  Love it.



STEVE:  It can live alongside them.  And in fact that's one of the things that delayed me was I initially had just - my demo was just using SQRL to log in, to sort of - I sort of, like, created a fake login-ness on GRC because nothing else on GRC logs in.  And then I thought, wait a minute, people are going to say, well, that's fine, but how's that ever going to get adopted?  So what I needed was to duplicate a normal login session that you'd have, like on Amazon, where you still have username and password, or SQRL.



LEO:  Or SQRL.



STEVE:  Yes.  And so what I've done is I reimplemented that, and I have now you can log in with username and password.  You can log in just with SQRL.  You could initially have a username and password account, like everyone does now, associate your SQRL identity with it, then remove your username so that you're able to sort of straddle over into a SQRL-only authentication.  And when you remove your username and password, then there's nothing for the website to steal.



LEO:  This is clearly an idea whose time has come.  Passwords are really frustrating.  They're driving people crazy.  They're a security flaw in some cases.  They're certainly an annoyance in all cases.  We did an interview yesterday on Triangulation with a New York Times reporter, Ian Urbina, who did a really great piece in November on the secret life of passwords and how people come up with their kind of standard password.  It was fascinating.



But one of the things he said at the end, and I think this is true, is that he hopes that our kids will not be using passwords; that this is a brief - our grandparents didn't have passwords, and our kids won't have.  But this is a brief period of time when passwords, everybody has to have passwords.  And we pretty clearly see how bad they are.



STEVE:  Well, and it's interesting, too, because it's a place where there's been no innovation.  Remember the way this all began, back on mainframes, where you'd have some Hazeltine terminal.  That's what - that's the way...



LEO:  That's how you'd log in.



STEVE:  ...you would log in.  And so then we went to UNIX, and we got networks.  And that same, you know, who-are-you-and-prove-it model, we're still with now, decades later.  So there's just been no - there's been no progress.



LEO:  Key to your success with SQRL will be getting websites to adopt it.



STEVE:  Yes.  And that's why one of the cool things about this is that there is, for a website to adopt it, it's one API call.  All you do is you need to verify the signature of - the signature that the site sent you just needs to be checked.  So, and in fact I just got email from someone who's got it completely running in Drupal, like, nailed.



LEO:  Nice, nice.



STEVE:  And there are PHP implementations.  It's now available in the Android Store, and there's one for iOS on the way.  So first off, obviously, we need clients, where...



LEO:  Ah, interesting.  So I'd have to have an app on my phone.



STEVE:  Yes, yeah.  And you can use the app on your phone to take a picture of the QR code, and then it authenticates sort of like behind the scenes.  The neat thing about this is, when you see it actually work, it's like, wait.



LEO:  That's all?



STEVE:  That's it?



LEO:  That's all I have to do?



STEVE:  I mean, I'm...



LEO:  It's like Apple Pay.  I'm done?



STEVE:  Well, exactly.  So...



LEO:  It's very similar, in fact.



STEVE:  So my belief is there are sites where there is a low tolerance for logging in, like blogging.  How many times have we read someone's blog and thought, oh, I'd like to make a comment.



LEO:  Yeah, but I don't want to have to log in.



STEVE:  Exactly.  And then they want to make you create an account.



LEO:  Right.



STEVE:  So those sites...



LEO:  Or they use social logins like Google and Facebook, and we're giving information now to Google and Facebook.



STEVE:  Right, exactly.  So this allows you to create an identity sort of on the fly with zero pressure.  And I think once people see that, they'll start saying, hey, I'd like to have that elsewhere.



LEO:  I think that's the key.  Once users adopt, then the sites are going to have to...



STEVE:  And as you said, now is the time.



LEO:  So we had a host dinner last night, which was a lot of fun.  I posted pictures on my Flickr page, Leoville, and on my Facebook.  But it was so much fun.  And of course I'm standing next to Steve as people come in.  And everybody said to you:  "So?  Did North Korea do it?"  It was the question of the night.  So, did North Korea do it?



STEVE:  Okay.  So what we're going to do, since I'm not demoing SQRL quite yet, a week or two, is I want to - and here we are at the last, next to the last day, New Year's Eve eve.  I want to do sort of a walk back through what happened in 2014 because, boy, I mean, talk about a crazy year.



LEO:  But is this the worst year for hacking?



STEVE:  I think it is.



LEO:  I think it might be.



STEVE:  I think, I mean, there's never been anything as devastating as the Sony hack that just happened here at the end.



LEO:  And the Target, and the Home Depot, and you can go on and on.



STEVE:  Yes, yeah.



LEO:  Lots of breaches this year.



STEVE:  I think, I mean...



LEO:  It was the Year of the Breach.



STEVE:  It was a bad - it was a bad year.  And what's interesting is, those of us who are as close to this as you and I are have sort of been expecting this.  It's sort of like the way viruses have been around forever, and they could have been a lot more evil than they turned out to be.  And we sort of never really understood, well, these viruses could be wiping out people's computers.



LEO:  Originally it was vandalism.



STEVE:  Right.



LEO:  It would deface a website or put a funny thing on your computer that you couldn't get rid of.  Then it became putting stuff on your computer that would make the bad guy money, things like spam reflectors or DDoS machines.



STEVE:  Or taking over your machine in order to use it as a...



LEO:  To co-opt it, to add it to a bot army.  But then with CryptoLocker, and I guess this was the year of CryptoLocker, it suddenly really did become an issue, a real expense.



STEVE:  Right.



LEO:  Because you couldn't unlock your data unless you paid them.



STEVE:  What I think we're really seeing is, as they say, the chickens coming home to roost.  These are problems that are latent in our architectures.  And, I mean, there were obscure things, like SSL bugs, and we'll talk about those here in a minute.  But there were also just larger problems, like the problem of securing something the size of Sony Entertainment.  It's just - you can't.  I said a couple weeks ago when we were talking about it, you said to me, "What would you do, Steve?" And I said, "I couldn't secure something that size that has humans involved like that."  I couldn't.  Anyway...



LEO:  That's the problem.  Humans are the problem.



STEVE:  So we're going to - so this is the Insecurity of 2014.  And then but I also want to catch up on - because it's been a busy two weeks.  We talked two weeks ago, and oh my lord, stuff has happened.  So we know that during his last press conference of the year, Barack stood up in front of the world and said that North Korea hacked Sony, and he wished that Sony had called him prior to making the decision not to air the movie.  Now, having seen the first 20 minutes, which is all I could tolerate...



LEO:  You downloaded it?  Or did you - yeah.



STEVE:  Jenny really wanted to sort of thumb her nose...



LEO:  At North Korea.



STEVE:  Yes.  And so I paid $6.



LEO:  We should - I think at this point it would be prudent to point out that buying or seeing the movie in no way is striking a blow for freedom.  But okay, go ahead.



STEVE:  No.  No.



LEO:  Just so you don't have to.



STEVE:  I'm so embarrassed now that - oh.  You'll know...



LEO:  It's that bad?



STEVE:  It is beyond bad.  I mean, it is so adolescent that, I mean, and comedy...



LEO:  You've not seen a James Franco/Seth Rogen movie before.  You haven't seen "Pineapple Express" or "This Is the End" of the world or - you've not seen these movies.



STEVE:  No.



LEO:  So you didn't really know what to expect.



STEVE:  No.



LEO:  Those of us who've seen them maybe are a little more inoculated than you were.



STEVE:  How old is your son?



LEO:  He's 20.  He loves this stuff.



STEVE:  Oh, he's way too old for this.



LEO:  It's like 12-year-old humor.



STEVE:  Oh, it is, potty humor.  I mean, and not just a minute of it, but four minutes...



LEO:  Endless minutes.



STEVE:  Endless.  It's just unbelievable.  Anyway, so the consensus among security experts is that - getting back to the topic.  We're having a ball.  This is great.  The consensus among security experts is that the evidence for North Korea being behind the hack is weak and weakening.  That is, I mean, and yes, it's hard to understand how the President of the United States could assert that the FBI has asserted to him that they have sufficient evidence to draw the conclusion - oh, but they're not going to share it all with us - if it weren't true.  But, for example...



LEO:  Well, that's the, I mean, both Bruce Schneier, and you're going to talk about Marc Rogers of CloudFlare, have kind of said what we know isn't conclusive.  But the FBI and the President also said there is information we cannot reveal, presumably signals intelligence, or maybe even pure espionage intelligence, that revealing that information would reveal the source and thereby make the source useless.  So the presumption is that for them to be so unequivocal, maybe there must - there must be something, a signals or something that's conclusive.



STEVE:  Yeah, because it would be really bad if it came out that they were...



LEO:  We happen to be able to tap into Kim Jong-un's phone or something.  Yeah, yeah.



STEVE:  Right, or - exactly.



LEO:  Which we probably are.  And he probably said, oh, wasn't that funny when we hacked Sony.  But maybe not.  And this is the thing.  We live in an era, after many attacks on credibility in the federal government, we live in an era when nobody believes the federal government.  Nobody is - maybe if Dwight Eisenhower had said, "No, trust me, we know they did it," we'd believe it.  But nowadays, nobody believes it.  It's just not enough to assert, well, we have information.  It's just like saying we know about WMDs in Iraq.  It's just not credible.



STEVE:  So Marc Rogers - oh, thanks.



LEO:  Thank you for that.  Go ahead.  We'll just edit that out.



STEVE:  Marc Rogers, knowing who's...



LEO:  This is the CloudFlare guy; right?  He's chief security researcher for CloudFlare.



STEVE:  Chief security guy for CloudFlare.  He's also head of security for Defcon.



LEO:  He runs Defcon.



STEVE:  Exactly.  So, I mean, knows his stuff.  So he points out that some of the evidence that we were given were the IP addresses that were used.  Well, it turns out they're public proxies.  Everybody uses them.  They're well-known ways of bouncing your traffic through another server in order specifically to throw someone off the scent.



LEO:  Right.  They're in the U.S.  They're in Thailand.  They're in Italy.  They're in Poland.  They're all over the world.



STEVE:  Yeah, Bolivia, Singapore.



LEO:  So the use of those is not in any way conclusive.  And in fact this does kind of make people think, well, maybe the FBI doesn't know what the hell it's talking about, that they would cite this as evidence.



STEVE:  Yeah.  I think it's just always - it's always difficult for someone to say, oh, I know it, but I can't tell you how.  You know?



LEO:  Yeah.  And the evidence that they provided was really not conclusive.



STEVE:  Right.  So Marc observed what others have observed, which is, for example, first of all, is the fact that the attackers only brought up the anti-North Korean bias of "The Interview" after the media did.



LEO:  Right.



STEVE:  It was never part of their original presentation.



LEO:  Weren't the first communications they had requests for money from Sony?



STEVE:  Yes.  Yeah.  Like the day before or two days before the first drop of data, they said pay us.  Now, it was always in fragmentary English.  I remember seeing the wording of that.  And they didn't even give a dollar amount, or at least it wasn't disclosed.  So I don't know whether in fact they did.  But it seemed like just simple extortion from somebody on the inside.



LEO:  Now, I might mention that, if you are the North Korean government, and you're going to perpetrate some cyber warfare scheme, that it would be smart to obfuscate it with oddball requests in poor English.



STEVE:  Well, yes.  And of course the flipside argument works, too.  And that is, wouldn't the hackers love the cover story of it being North Korea?  Because we're not going to attack North Korea.  Well, or if we do, we're not going to talk about how and when and what our methods are and so forth.



LEO:  It will be a proportionate response.



STEVE:  But the idea is it deflects the FBI, apparently, from the trail, given that they really believe that.  Also he noted, Marc noted, that the hackers dumped the data.  And he asks in his Daily Beast story, would a state with a keen understanding of the power of propaganda, such as North Korea has, be so willing to just throw away such a trove of information?  He said the mass dump suggests that, whoever did this, their primary motivation was to embarrass Sony Pictures.



LEO:  Mission accomplished, by the way.



STEVE:  Well, yeah.  And his theory is, again, the Occam's Razor argument.  What is the simplest explanation?  The simplest explanation is an annoyed employee at Sony, somebody who was on the inside who had this kind of access was able to put this together.



LEO:  And there is actually evidence that they had inside information.  Server names and passwords were hardcoded into the malware.  So that would be information only known by somebody inside Sony.



STEVE:  Well, or somebody - the APT, the Advanced Persistent Threat model that we're now having to grapple with is where somebody gets into your network, burrows in, and now sits and watches for some length of time.



LEO:  Right.  And in fact there's evidence that that had happened, that in March Sony was compromised.



STEVE:  Right.



LEO:  And ignored it.



STEVE:  Right, exactly, months before.  So maybe somebody was there.  Now, if you had that kind of presence in the network, they could gather data for six months.



LEO:  And write some specific code and take advantage of that information.



STEVE:  Exactly.  I mean, so...



LEO:  So that's inconclusive, as well.



STEVE:  And so I think one of the things - and we've talked about this, and we've seen me, I was late to the party to believe about Stuxnet being what it was.  I'm willing to say I don't know.  I don't have the answer.



LEO:  Okay.  But the thing that comes up when we say all this - and I agree with you.  It didn't smell right.  But I don't understand what's in it for the President and the FBI in asserting, I mean, this is, you know, for a nation to assert that another nation has attacked it over the Internet is a fairly significant thing.



STEVE:  Well, attacked one of our companies, though.



LEO:  Okay.  And a Japanese company, to boot.



STEVE:  Right.



LEO:  But that's a fairly strong thing to say.  What's in it for them?  Why would they assert that if the evidence wasn't conclusive?  What would their...



STEVE:  I think just political pressure to have an answer.  We're supposed to be able to know.



LEO:  We should know.



STEVE:  Yeah.  I mean...



LEO:  The risk, though...



STEVE:  ...imagine him standing up there and saying, well, I don't know.



LEO:  Well, or there are ways to couch it.  It wouldn't be prudent to talk about this yet where the investigation is ongoing.



STEVE:  Yeah, true.  And besides, I'm on my way to...



LEO:  And I've got to get out of here.  So thanks.  See ya.  But also the issue is, if it does, if evidence does surface that it wasn't, that's highly embarrassing.



STEVE:  Right.



LEO:  So it's a dumb thing to assert that, oh, we know it was North Korea, unless, it seems to me, that they knew it was North Korea.  So this is why I'm puzzled.  You know what's the truth?  We probably - we'll likely never know what happened.



STEVE:  I don't think we will.  And that's one of the problems with network-based attacks.  Unlike physical world attacks, where you leave some blood because you cut yourself on the jagged edge of the glass when you went through the window...



LEO:  Right, there's evidence.



STEVE:  ...or fingerprints or skin flakes or whatever, electronic attacks just don't have any of that.



LEO:  And one thing that you learn in security is that attribution is always very difficult because of these proxies, because of log erasures and things like that.



STEVE:  Yeah, and all of the things that we're used to now being standard mechanisms in movies, I mean, they're a little overdone.  "Well, they bounced around the world seven times, Captain, before they..."



LEO:  But they did.  And in fact we even know the proxies they used.



STEVE:  Yeah, yeah.



LEO:  All right.  So, and in fact, in the past when hackers have been prosecuted, almost always it's because they...



STEVE:  Talked.



LEO:  ...boasted; right?



STEVE:  Yes.



LEO:  So it seems unlike - if whoever did this is smart and just shuts up...



STEVE:  Ooh, and you don't want the hammer to come down on you.



LEO:  ...and goes away...



STEVE:  Not on this one.



LEO:  ...that we'll probably not know what happened.



STEVE:  I think we have to expect that we really won't have an answer.



LEO:  And I'm kind of saddened by the assertion from the United States government that it was North Korea because now they're incented not to release any further information.  Like, case closed, because anything they released could actually undermine their case.



STEVE:  There's another obligation now, and that is response.  Because the State Department has said, well, we're not going to tell you what we're going to do, or you really won't know when, but we will respond proportionally.  I mean, Barack did say that we're...



LEO:  I think, though, that that was more to say we're not going to bomb them.



STEVE:  Right, right.



LEO:  And he was very careful, and I think this is the right thing to do.



STEVE:  No mushroom clouds.



LEO:  Say this is not a terrorist act.



STEVE:  Right.



LEO:  Don't want to use the "T" word.



STEVE:  What he called it, he called it "vandalism."



LEO:  Vandalism.  And I think when he said "proportionate," he didn't mean we're going to respond strongly.  I think he meant to say we are not going to bomb them.



STEVE:  I hope...



LEO:  That would be disproportionate.



STEVE:  I hope this was not our denial of service attack.



LEO:  By the way, was that the response?  Because on December 22nd North Korea went offline.



STEVE:  Yeah.  Shortly after Barack's last press conference of the year, as he heads off for Christmas vacation, that Friday evening, connectivity to North Korea started getting flaky.  And it sort of slowly degraded over the course of the weekend until Monday morning it was pretty much gone.



LEO:  Right.



STEVE:  Now, if that's like a denial of service attack that the U.S. mounts...



LEO:  We could do better?



STEVE:  ...they need to call me.



LEO:  How much Internet does North Korea have?  They don't have much; right?



STEVE:  Oh, my god.



LEO:  And it all goes through China Unicom.



STEVE:  Most city blocks in New York have more IP addresses than North Korea.



LEO:  Wow.



STEVE:  Than the entire country.  North Korea has officially 1,024 IP addresses.



LEO:  That's it?



STEVE:  They have 10 bits of IP space.



LEO:  And it all goes through China.



STEVE:  Yes.  And so that's actually one argument for us not having attacked North Korea, because if that was, our attack would have been carried by China's telecom services.



LEO:  By the way, I don't think that's something we would want to do at this point.



STEVE:  Precisely.



LEO:  So it sounds like, and it does, the way - the sputtering and its getting stronger, it sounds like just some kid, script kiddie.



STEVE:  Uncoordinated, like, oh, let's get them back.



LEO:  Yeah.



STEVE:  On the other hand, even that, I mean, DDoSes these days knock gigabits...



LEO:  Trivial.  It wasn't even a good DDoS.



STEVE:  It wasn't.  It was hard to explain it.  So anyway.



LEO:  It's like - somebody in the chatroom said it's like DDoSing my apartment building.  It's not so hard to accomplish.



STEVE:  Right.  Anyway, so also there was something that went on with North Korea, and we don't know what that was, either.  But it sure was not impressive.  I saw charts of the outages, and it would kind of come and go, and then kind of go more, then come back, and then go more even.  It was just like, what?



LEO:  I get the distinct impression that the government made the announcement about North Korea right before Christmas and the holidays and is just hoping everybody will forget about it by the New Year.



STEVE:  A perfect example is, as we know, on Christmas Day, eve and day, Xbox live...



LEO:  They were brought down.



STEVE:  And PlayStation Network.



LEO:  By Lizard Squad.



STEVE:  Well, okay.



LEO:  Who the hell are they?



STEVE:  So there are serious strong networks taken off.  So if Lizard Squad aimed themselves at North Korea, there'd just be a - it'd be dust over there right now.



LEO:  There was an interview with Lizard Squad.  In fact, they showed one of the guys.



STEVE:  It's like, what are you doing?



LEO:  Again, this is how you get caught, folks.  Actually, we shouldn't say anything.  It's a good idea, you know, you should give an interview when you hack something.  Let the world know what you've done.



STEVE:  Yes, please do.  That's right.



LEO:  But in this case you saw a picture of the guy, and he said, you know, "We just did it for fun."  And he said, "You should go out and get some fresh air.  You shouldn't be playing games on Christmas anyway."



STEVE:  And then they sort of - they, like, again, sort of because they didn't really know why they were doing it, they changed their story, and they said, oh, we're trying to teach Microsoft and Sony a lesson.



LEO:  Oh, please.



STEVE:  We want them to improve their security.



LEO:  Yeah, yeah, yeah.



STEVE:  Except that a DDoS isn't about security.



LEO:  Right.



STEVE:  And I don't - I thought, well, do you not know the right word?



LEO:  Oh, it's BS.  It's just BS.



STEVE:  Yeah.  And so, and get this.



LEO:  They're script kiddies.



STEVE:  The way they finally stopped was that Kim Dotcom gave them vouchers for his Mega.



LEO:  Here, have some free storage.



STEVE:  Yeah.  And they said, oh, thank you.



LEO:  Oh, thanks.  We'll take that.



STEVE:  They tweeted, "Thank you, and we'll stop now."



LEO:  Morons.  I'm just really - they say in the interview they could take down NASDAQ if they wanted to.



STEVE:  Right.



LEO:  The over-the-counter stock exchange.



STEVE:  But that's not very interesting, yeah.



LEO:  But we just like - we're having some fun.  But that is scary, it is scary that these things, these people exist, and they have the ability to do something like that that really is so damaging to so many people.  It feels wrong.



STEVE:  And it's not going to get better.  What we have to understand is that this is old technology.  This is a SYN flood where...



LEO:  Is that how they did it?  You've been SYN flooded.



STEVE:  Oh, my goodness.



LEO:  You've actually - and this was five years ago; right?



STEVE:  Yeah.  I used to just, it's like, okay, here we go again.



LEO:  And it's hard to block.  The only way to really prevent it is add bandwidth; right?  Because you can't have a public website that ignores SYN requests.



STEVE:  Right.  You need a monster proxy like CloudFlare.



LEO:  That's what they do.



STEVE:  That's one of the services.  CloudFlare sits in front of your website and is able to terminate the connections so that a SYN comes in, and they'll send back the SYN ACK.  Your server doesn't see it until the connection is completed.



LEO:  And then passes it along.



STEVE:  Then, yes, and they're also a caching proxy.  So your site, even when there's a big load, sees only one request, and then they store it locally.



LEO:  It's very hard and not economically feasible to design a server that has enough bandwidth to handle all of these requests.



STEVE:  It's not even the server.  Because if the pipe...



LEO:  The pipe.



STEVE:  The pipe to the server, if that congests, then your server is starved.



LEO:  You don't even see these SYNs.



STEVE:  Yeah, I mean, I just had a couple T1s back then, and it was like it was trivial to knock me off the 'Net.



LEO:  So, and of course now with amplification attacks using NNTP and other technologies, it's possible for a single person to get enough bandwidth to attack even the fattest pipe.



STEVE:  True.  So any denial of service attack is a violation of the underlying protocol.  That is, no one should be sending out SYN packets over and over and over.



LEO:  Basically it's knocking on the door of the website and not caring what happens.  The website has to respond because it doesn't know if it's legitimate or not?



STEVE:  Well, and what's interesting is that there is a network somewhere that is allowing those out.



LEO:  Outbound SYNs.



STEVE:  Yes.  The egress filtering is really what we need.



LEO:  We've said this before, that if ISPs were all responsible, this wouldn't be a problem.



STEVE:  Right.  And notice that these are spoofed SYNs.  So the SYNs that are going out carry an IP address...



LEO:  That doesn't match the ISP.



STEVE:  Exactly.



LEO:  Yeah.



STEVE:  And so they could say don't allow any packets out that aren't...



LEO:  From our network.



STEVE:  ...from our network.  And it would stop it immediately.



LEO:  Yeah.



STEVE:  So I think, unfortunately, this is going to have to get bad enough that...



LEO:  Isn't it bad enough yet?



STEVE:  It's just...



LEO:  Nobody could play Xbox or PlayStation games on Christmas Day.



STEVE:  You know, the analogy that occurs to me is like the crumbling U.S. infrastructure.  We have, like, sink holes in L.A. with huge floods when a pipe breaks.  And it's like, oh, my god.  And so we fix the pipe.  And then it happens down the street.  Oh, my god.  And we fix that one.  And so no one fixes the infrastructure.  We just keep patching the problems.  And unfortunately this is like that.  It's spotty.  I don't know if it's ever going to get bad enough.



LEO:  So we talked before about the amplification attack using the time server, NNTP.



STEVE:  Yes.



LEO:  Is that what Apple patched, do you know?



STEVE:  No, they didn't.



LEO:  It was an NTP flaw.  The DHS, actually, Department of Homeland Security, put out a bulletin.



STEVE:  Yes, yes.  It was, okay, and it was bad.  And that was why, for the first time ever, Apple forced an update.



LEO:  Their auto patch.



STEVE:  Yes.  Normally...



LEO:  They put that technology in two years ago, but have yet to use it.



STEVE:  Actually, they...



LEO:  Did they use it before?



STEVE:  They used it for some malware.



LEO:  Oh, okay.



STEVE:  Some malware signatures.



LEO:  Right, I remember that, yeah.



STEVE:  They have pushed out that way, where it just does it.  You don't have to ask for it or okay it or approve it or anything because this is a remote code execution buffer overflow in a service which is running by default.



LEO:  The time protocol.



STEVE:  Oh, baby.  I mean, that string of words I just said is the worst...



LEO:  Scary.



STEVE:  Is the worst there is.



LEO:  So you're saying every Mac has an NTP daemon running at all times.



STEVE:  Yes, yes.



LEO:  And that this NTP daemon could be overflowed, which means malicious code - did they actually have a malicious code exploit?  Or is it just - it was a crash?



STEVE:  No, no.  It has not been seen in the wild.



LEO:  Okay.



STEVE:  So the people looking at the code went, "Holy crap.  We have to patch."  I mean, this was like one of those bad events.



LEO:  You find the overflow, and then the hackers start working to see how they can jump to an area of memory and...



STEVE:  And there's no doubt they're trying to do it now.



LEO:  Eventually they would be able to execute code.



STEVE:  Well, because, for example - okay.  So an NTP server, Network Time Protocol, you're able to ask it what the time is.



LEO:  Right.  That's how your clock gets set on your Mac and Windows machines.



STEVE:  Exactly.  And it's got technology where it asks like the U.S. Naval Research Center somewhere or something in Utah...



LEO:  It asks NIST or WWV in Fort Collins.



STEVE:  Exactly, Fort Collins, Colorado.  So the problem is many people offer it as a service.  They say, "Oh, I have an NTP server.  If anyone wants to know the time, why not tell them?"  Well, and that's where these reflection attacks come from is you ask, a tiny request goes in, and a big response comes out.  So you spoof the IP of the request, saying that over there he asked me.  And so the big answer...



LEO:  Yeah, Xbox Live wants to know what time it is.



STEVE:  Exactly.  The big answer goes there.  Now, here's the problem.  That server has a vulnerability.  So that if you ask with a specially crafted packet, that open, exposed, public-responding NTP daemon, you can take it over.  And it's typically running as root.  You get the privileges of the daemon, and it generally runs as root.  So this is a remote code exploit on all Network Time Protocol servers on the Internet.  All of them are vulnerable before, what did I say, 4.2.8.  So they patched it in 4.2.8.  Now, remember, though, before everyone panics, you have to be exposed to the public Internet.



LEO:  If you have a router, you're not vulnerable.



STEVE:  You're not vulnerable.  Now, on an Intranet you would still be vulnerable.  So if somebody got into your network, and you had an NTP server running like Sony, they got into Sony, and Sony had a server protected from the outside but running NTP, you could, from within the network, use it to gain root access.



LEO:  Oh, wow.  To all the machines in the network.



STEVE:  Well, to that server.



LEO:  Oh, that server, okay.



STEVE:  You could run your own code on that server.



LEO:  Got it.



STEVE:  So all of us behind home routers, even those of us who are behind firewalls that don't open a port for NTP access - I think it's port 123?  I'm just - that's really from old memory.  I don't remember now what NTP protocol is, but I think it's like...



LEO:  I can tell you.  I'm going to look it up right now.  So, for instance, here we have a network, but we're running behind Astaro Firewall.  Presumably it's going to block that kind of...



STEVE:  Presumably you're not offering time services to the Internet.



LEO:  No.



STEVE:  Why would you be?  I'm not.



LEO:  Wow.  So that patch, that's kind of cool that Apple could do that.  Do you know, has Microsoft patched it on Windows?  Is it an issue on Windows?



STEVE:  No, because this just happened.  And Microsoft is going to stick to their...



LEO:  They don't have the same mechanism, do they, for just I'm not going to ask, I'm just going to fix.



STEVE:  Good question.



LEO:  They may, and it may not be publicized.



STEVE:  I think they always ask you.  They do, like, give bonuses sometimes, like extra crypto suites.



LEO:  It's a good thing, though, for a true emergency.  The problem is sometimes these patches break things.



STEVE:  Well, and so I think the problem is that apparently Macs are publishing NTP, but Windows doesn't.



LEO:  Oh, interesting.  All right.  So it's not an issue.



STEVE:  Yeah, so Windows and, again, behind a router, you're...



LEO:  Service port is 123, the chatroom confirms.



STEVE:  Ah, 123.



LEO:  And so does the IETF.  Okay.  Fixed.



STEVE:  And you can use UDP or TCP, so either protocol.



LEO:  How much did Kim Dotcom give them in vouchers, just out of curiosity?



STEVE:  Didn't see.  But I just - I saw...



LEO:  "Here's 10 bucks of free storage.  Would you knock it off, Lizard Squad?"  Okay, okay.



STEVE:  Well, they were just flattered.  It's like, oh, okay.  And they tweeted a thank you from Lizard Squad's Twitter account.  They said, hey, we got...



LEO:  I'm not sure which is worse, that there are people out there who have such moral flaw that they don't kind of connect the suffering they're causing with the fun, the lulz they're having, or that it's even possible to do this because this stuff is so janky.  It's all bad.



STEVE:  And it's the fact that you do have anonymity, to a large degree.



LEO:  Right.



STEVE:  I mean, we know that doors and windows in our homes are not actually secure.  You could throw a brick through a window and then climb through it.  So it's the fact that you have to physically do that, and you risk being seen, and all the complications.



LEO:  Right, right.



STEVE:  That's what ups the ante for a real-world attack.  But you can literally be in your bedroom, on your computer, launching DDoS attacks...



LEO:  No risk, really.



STEVE:  ...to North Korea with your five bots.



LEO:  Or seemingly little risk, yeah.  There's also - there is a social contract.  Locking your door doesn't really prevent somebody from kicking it in or going around the back.  But it's a signal.  And it's a social contract we all kind of just adhere to.  And this is somehow missing in certain people.  Of course there is.  Of course it is.



STEVE:  Yeah.



LEO:  Now, here's some good news.  I was very pleased.  The Edward Snowden leaks continue on.  We are now in Year 2, Snowden Year 2.  And this is the good news.  There is stuff the NSA doesn't like, or at least as of 2012 couldn't break.



STEVE:  Yeah.  Der Spiegel carried a story showing some recent documents.  They analyzed them, and what we learned was interesting.  The NSA ranks the - okay.  First of all, the NSA, get this, calls encryption a "threat."



LEO:  Yes.



STEVE:  It's a threat.  It's not security.  It's a threat.  So, okay.  So they have a scale, a ranking system of how bad is the threat.  So "trivial" is obviously one.



LEO:  That means we can crack it, we can read it, it doesn't get in our way at all.



STEVE:  Well, and they give the example of monitoring a document's path through the Internet.



LEO:  No problem.  Easy peasy.



STEVE:  It's like, okay, we know that's trivial.  Okay.  Trivial is number one.  "Minor," a minor threat is like recording Facebook chat.



LEO:  Oh, that's not as easy, huh?  But minor.



STEVE:  Not so easy.  Yeah, you've got to actually get up off your chair and go push a button somewhere to do that.



LEO:  Okay.



STEVE:  Okay.  Number three, "moderate."



LEO:  Moderate.



STEVE:  A moderate threat is, for example, decrypting emails sent through Moscow's Internet mail.ru service.  So they're trying to encrypt it, but that's a moderate problem.  It doesn't slow them down.  They may have to call someone...



LEO:  Right.  Hey, Ivan, would you flip the switch over there?



STEVE:  ...like in the next building.



LEO:  Yeah.



STEVE:  Okay.  So then the last two are "major" and "catastrophic."



LEO:  Now, again, for us, catastrophic is good.



STEVE:  Yes.



LEO:  For them, it's bad.



STEVE:  It's a catastrophic threat.



LEO:  For us it's good.  That means we're secure.



STEVE:  Okay.  So a major are all the things they basically can't handle.  And like in the documents, TrueCrypt, nothing they can do about TrueCrypt.



LEO:  They can't do it.  Oh, that's good.



STEVE:  They're hoping the guy used a weak password because, as we know, that's the only way to crack TrueCrypt.  OTR, the Off The Record protocol, the real-time chat protocol, well designed, strong crypto, and unfortunately it is a major threat, Leo.



LEO:  I hoped it had been catastrophic.



STEVE:  It's a major threat.  No, no, it's catastrophic if you go through Tor and use Off The Record.



LEO:  Oh, then we're really screwed.



STEVE:  When you mix them up, when you do more than one at once, then it's a catastrophe.



LEO:  Didn't we learn that they have kind of infiltrated Tor to a great extent?



STEVE:  Well, on my list - I keep trying to get to it, but the world won't let us - is we're going to do...



LEO:  Some day we're going to talk about it.



STEVE:  We're going to do, soon, DeTor is the title I've had, and I keep pushing it down in my things I want to get to.  Because it turns out that there is - it's less anonymous than we were hoping.  That is, and we sort of suspected this.



LEO:  Because the endpoints have been co-opted, yeah.



STEVE:  We've talked about the exit nodes.  And if you analyze the traffic well enough - okay, so what the professor said was, who analyzed this, a sufficiently well-motivated entity...



LEO:  The NSA.



STEVE:  ...could deanonymize about 80% of the Tor traffic.



LEO:  Okay.  That's significant.



STEVE:  So that's not what anyone wants, yeah.



LEO:  But OTR is good.  It's interesting they mention Zoho.  I don't know why.  Zoho is a free office or web-based office solution.



STEVE:  It must have good crypto.



LEO:  That has encrypted email.



STEVE:  Oh, and I forgot to say that Skype - I hope the NSA is enjoying this podcast.



LEO:  Really, which - you're not on Skype, dude.



STEVE:  That's right.  I just realized that that joke doesn't work today.



LEO:  So Skype was which?  Trivial, minor, moderate?  Where was Skype on that scale?



STEVE:  Trivial, because...



LEO:  Trivial.  They have a backdoor.



STEVE:  Well, yes.  Microsoft engineered eavesdropping into it in February of 2011.



LEO:  Oh, thank you, Microsoft.



STEVE:  And there's an FISC, FISA something court, like request, that is just sitting there, that allows them to now break into any Skype calls they want.



LEO:  And probably, in Microsoft's defense, they probably don't have a choice; right?  If you get a FISA Court or a national security letter...



STEVE:  Although, as far as we understand, it's a blanket eavesdropping capability.  And that's what the rest of the industry is still resisting.  You know, VPNs don't have it, as far as we know.  Google is not doing it.  Apple, for example, encrypting the iPhone.  I mean, everybody else is resisting this so far.



LEO:  Who uses OTR?  Does RedPhone use that?  Threema, I think, uses it.  SecureText uses it.  Are those OTRs?



STEVE:  There was that web-based implementation of OTR.  I'm blanking on it.  It had a little bit of an implementation problem, but they fixed it.



LEO:  This is the Off The Record.



STEVE:  Cat, something Cat.



LEO:  Cryptocat.



STEVE:  Cryptocat, yeah.



LEO:  Used OTR.



STEVE:  It uses the OTR protocol.



LEO:  Okay.  So that's good.  So look for OTR.



STEVE:  Yes, it's a good protocol.



LEO:  End-to-end encryption.



STEVE:  Yeah.  And, I mean, they didn't mention Threema.  It was not - because it's not that this was an exhaustive list.  So Threema's technology is solid, too.



LEO:  Right.  So, good.  If you want to - but, now, first of all, this was 2012.  So we don't know what's happened in the intervening couple of years.



STEVE:  Right.



LEO:  But to me this felt like good news.  What about VPNs?  Completely cracked.



STEVE:  Yes.  And what we believe - now, so...



LEO:  As has SSL.



STEVE:  Well, the problem with VPNs is that we know that there are, as with Tor, there are exit nodes.  There is the VPN server that you're terminating to.  And if that's a public server...



LEO:  So you may not be able to get in the tunnel, but...



STEVE:  They could just set up camp right there.  I mean, because we know...



LEO:  We know where it's exiting, yeah.



STEVE:  ...that they're going to have access to the fiber and just tap the fiber in order to get to it.



LEO:  Does perfect forward secrecy help with TLS and SSL?



STEVE:  We believe that the problem there is - the weakness in TLS and SSL is the public key infrastructure because no one doesn't any longer believe...



LEO:  Anybody can have a CA.



STEVE:  Yes.



LEO:  And certainly the NSA has a certificate authority.



STEVE:  There's no way that the NSA isn't trusted.  I mean, yeah.  If you look through the array of certificate authorities that we have in our secure store now, hundreds of them.  And there's just no way that they can't have a certificate minted on demand that allows them to impersonate a website and set up an unseen man-in-the-middle attack.



LEO:  So the reason I interpreted this as good news is the message is they don't have a hundred percent view of what's going on.  There is some stuff that, at least as far as we know, they cannot see into.



STEVE:  Math works.



LEO:  That's what protects us, math.



STEVE:  And we have great math.  It is implementation vulnerabilities, and there are some architectures which are weak.  The architecture of the public key system is weak.  And remember, famously, we were doing the podcast when I looked at the list of...



LEO:  The Hong Kong Post Office, baby.



STEVE:  ...the certificate authorities, it's like, there used to be 12.  Now there's 400.  And we're trusting every single one of them.



LEO:  Right.



STEVE:  Yeah.  So, okay.  So what I think, and I'm sort of stepping on our conclusion here, but it fits right now, and that is the upshot of this first year of Snowden is today, as we wrap up 2014, security has gotten better.  I mean, the response to the now one-year-old Snowden leaks has been Apple saying, okay, we're going to make security a feature, and we're going to, I mean, absolutely do it.  And of course they've been criticized, by the people who consider security a threat, for, like, selling security.  And it's like, no.  I mean, they've been accused of, like, selling access to molesters and pornographers and bad people.  It's like, no.  We just want to allow people to have the security that they're expecting from the product.



And of course Google is following suit.  And, my god, you can't even count the secure messaging protocols and phone apps and all of the Internet communication security that has ramped up, seeing that as a market opportunity in the wake of Snowden's revelations that showed us how much interest there really was in dealing with the threat of encryption.



LEO:  So Steve Gibson is in-studio, which is really nice.  He came up from his Fortress of Solitude in Irvine.



STEVE:  Really does change the dynamic.



LEO:  Yeah.  I actually talk to you, for one thing.  And it's great because tomorrow is New Year's Eve, and we're going to do the big party, and you're going to be part of that.  But I think this is a good thing for our last Security Now! of 2014, to do the chronology.  The things that happened.  A look back.



STEVE:  Yeah, just sort of like, if nothing else, it's been a fun year.  But there was a lot of stuff that happened.  I mean, we have all new vocabulary:  Goto Fail, Heartbleed, BadUSB, Shellshock, POODLE, and Regin.



LEO:  Oh, this was all this year.  Oy.



STEVE:  Yeah.  I mean, it's been a busy year.  So of course, as we were coming, I guess it was late in 2013 that the P.F. Chang hack happened.  It was sort of in the Southeast.



LEO:  It was Black Friday of last year that the Target hack happened.



STEVE:  Right.



LEO:  And the P.F. Chang happened.



STEVE:  And then we got, early in 2014, we got more of a sense of scale for that.



LEO:  Yeah.  It went from, what was it, 11 million to 70 million, something like that, records revealed?



STEVE:  Yeah, I think 70 million was the number for Home Depot, and Target was 40 million.



LEO:  Forty million credit cards, but 110 million customer records.



STEVE:  Yes.



LEO:  Oy, oy, oy.



STEVE:  Yes.  And...



LEO:  There's only, what is it, 400 million people in the U.S.  That's like every adult in the U.S.



STEVE:  And it was estimated that the cost of replacing all of those disclosed cards came to about $400 million.



LEO:  Oh, wow.



STEVE:  And we did report a few weeks ago on the podcast that Posner, our old friend Judge Posner, said no, we're not going to let you throw the case out.  This is going to go to trial.  We're going to...



LEO:  Yeah.  The banks are suing Target over this and saying that they want to recover that cost.



STEVE:  Yes, on the argument that Target did have enough information to prevent it; and negligence, not some weird cyber hack, but negligence was the underlying factor here.  And so we're going to test whether that flies.



LEO:  That will be a fun trial to watch in 2015.



STEVE:  Ooh, it will, yeah.  So we have that to look forward to.  Now, early in the year, and we'll remember this because this was another fun thing we talked about, we discovered that many consumer routers had a wide-open backdoor, way up at about half of the port space.  Ports run from 1 to 65535.  And right in the middle is 65536.  Three six?



LEO:  No.



STEVE:  No, no, no, no, no.



LEO:  I memorized this.



STEVE:  32768.



LEO:  32764.



STEVE:  No, well, yeah, but eight is in the middle.



LEO:  Eight's in the middle.



STEVE:  32768.  So it was four down from the exact center of the port space was a port listening for connections.



LEO:  Wide open.



STEVE:  And if you set the hosts - remember when a web browser makes a query, one of the things it has is the hosts header that identifies what it is.



LEO:  All operating systems have this.



STEVE:  And for weird apocryphal reasons, they all say Mozilla, among other things, because that was the first browser.



LEO:  First browser, yeah.



STEVE:  And so even IE says, oh, yeah, I got some Mozilla here somewhere.  And we doubt that.  But so if you reversed the phrase of the person who apparently put this in, and I can't remember what the phrase was now, but anyway the point is you put that in the hosts header and make a web query from the outside on the Internet to that port.  It says, oh, hiya, what do you need?  What can I do for you?  And there's, like, 14 commands.



LEO:  There's commands; right?  Yeah.



STEVE:  It's like commands you can execute.  Now...



LEO:  Is this like a service port?



STEVE:  Well, the theory was that this was the way ISPs or router manufacturers or somebody, I mean, it was undocumented.  And someone just ran into it.



LEO:  Possibly it was an Intel reference code, we've seen that before, and just got duplicated.



STEVE:  We have seen that before in the - I just almost had it, and I lost it.



LEO:  Yeah, I can't remember, either.



STEVE:  It wasn't - was it Bluetooth?



LEO:  Yeah, no, it was in the - the baseband radios in cell phones had an error in code because everybody just copied, literally cut and paste, the reference code.  I think it was from Qualcomm, not Intel.



STEVE:  And it was never - you were never supposed to use it.  But it's like, well, okay, this works.



LEO:  Hey, they wrote it already.



STEVE:  Why reinvent that wheel?



LEO:  So I'm guessing that's probably why because it's not just Cisco and Linksys, which is one company.  This is also Netgear.  It was other companies.



STEVE:  I think it was - it wasn't Sercomm.  It was everybody, it was all the routers based on one manufacturer who had this.



LEO:  Oh, okay.  The chipset, probably, yeah.



STEVE:  Okay.  So that was right over Christmas and New Year's.



LEO:  You wrote a little program to test for this.  Didn't you?  There was a way to test for your router being...



STEVE:  Oh, yeah, yeah, yeah.  You can just see if it accepts a connection.  So you're able to use ShieldsUP!, for example, and just see if it accepts...



LEO:  Oh, okay.  Look at 32764.



STEVE:  Exactly.  And if it connects, it's like, whoops.



LEO:  Hello.



STEVE:  That's not good.  Okay.  So get this.  So the next thing that happened was everybody updates their firmware.  New firmware is issued by Cisco and Linksys and all of those.  And now that no longer happens.  So we assume all is good.



LEO:  Right.



STEVE:  It's not.



LEO:  What?



STEVE:  We're going to come back to that here in a minute.



LEO:  Okay.



STEVE:  Because the next thing that happens then is that on February 21st, Goto Fail...



LEO:  Oh, my gosh.  This was the worst.



STEVE:  ...enters the world's vocabulary of Internet problems, which was a tiny, like, what, well, goto fail.  It was a tiny error...



LEO:  One line.  One line.



STEVE:  ...in source code that was like - and you could even look at it.  And this is why debugging code is so tricky, is you can look at it, and it seems fine.



LEO:  It was a case statement that got bypassed.  And unfortunately the case statement was testing certificates.



STEVE:  Yes.  It was a particularly important moment in the code.



LEO:  So, and this was in iOS and OS X.



STEVE:  Yes, because they're using a common code base, which this demonstrated.  And what it meant was that signatures had never been checked.



LEO:  Been tested.  Oh, just forget that.



STEVE:  It's like, we'd like you to sign it right, but you really don't bother, you know, just change a few bits here and there.  And so this had just, like, gone unseen.  And we assume and hope that nobody was taking advantage of it.  And so Apple, remember that Apple was a little cagey on this one.  They pushed the fix out first, and then afterwards they told us.



LEO:  Finally admitted it, yeah.  But what was interesting was the notion that this might have been introduced by a bad actor intentionally.  That if you were going to...



STEVE:  Make it look like a mistake...



LEO:  Make it look like a - this is exactly what you would do.  And it's just that spot.



STEVE:  Yeah.



LEO:  Apple never talked about that.



STEVE:  No.  And if so, it was clever.  And in fact I remember a lot of people talking about that, because this came from open source originally, it ought to be possible to track down a log.



LEO:  You have a version log, a changelog.



STEVE:  A changelog, yeah.



LEO:  And you should be able to see who did it.  Never heard.



STEVE:  No.  No.



LEO:  Just quietly buried.  In fact, a lot of the stories from this year, because we have such short memories, just disappeared.  This was the year TrueCrypt bizarrely disappeared.



STEVE:  I know.



LEO:  And we still don't know what happened.



STEVE:  Two months after that, what is it, April, mid-April, like, you know...



LEO:  The TrueCrypt authors...



STEVE:  Like one morning we wake up, and the TrueCrypt website is gone, and it says you'd better not use this because it may contain security errors, and we're not going to fix it.  We're checking out.



LEO:  You had the best, I think probably the most sensible theory, which is that these guys just were fed up with the open source background noise you always get, people complaining.



STEVE:  Oh, thankless, thankless.



LEO:  Thankless job.  And not that they had found a flaw, but they just didn't want to be responsible anymore.  So they said go use BitLocker.  We'll see you later.



STEVE:  And we're going to 64-bit systems.  We're switching from...



LEO:  We don't want to keep it up to date.



STEVE:  ...master boot records to GPTs, the GUID Partition Table.  That would all have to change.  I mean, they would have had to have put in a huge amount of work.  And I think they had what they wanted.



LEO:  It was a singularly graceless retirement.



STEVE:  It was, yes.



LEO:  It wasn't very graceful.



STEVE:  Thank you very much for TrueCrypt all these years, but you could have done a better job of saying goodbye.



LEO:  Now, the good news is, and actually we still haven't heard the second part of the audit, but the audit is ongoing now, yeah?



STEVE:  Yes.



LEO:  So a third party from Johns Hopkins has raised money and is actually going through - because the code is available.  It's not open source, technically, but the code is available.



STEVE:  Right, it's "available source," as they call it.  



LEO:  So he's been going through the source, or somebody, some team has been going through the source.



STEVE:  Well, so, yeah.  The first phase was done.  And that only checked the boot technology and the getting it going part.  It was not a full-blown crypto review.  So, but no one has any reason to believe that that's a problem.  And we know for a fact, for example, because we've covered it, that the FBI is often thwarted by TrueCrypt.  The Brazilian government sent them a drive...



LEO:  In 2012 they were.



STEVE:  ...because some real estate guy had stuff on it that they were unable to get.



LEO:  Is the audit still going on?  I think so.



STEVE:  Last I heard, Matthew Green was still on top of it, and it was going to proceed.



LEO:  So soon, I hope, we'll know.  I guess this is harder than one imagines.



STEVE:  Oh, it's work, I mean, and you do need money to pay people to dig in there that much.



LEO:  Now, your advice at the time was go ahead and continue to use TrueCrypt.  In the absence of any known flaw, it's safe.  You still think that's the case.



STEVE:  I still have it on the website, and I'm offering it, and it's downloaded often.



LEO:  Well, that's another point.  You can't get it from the old source, but Steve has the last good version.  They actually released a version after that that was a damaged version, intentionally damaged version.



STEVE:  Right.  And in fact this demonstrated - I did an interview with someone not long ago where he asked me why I believed this was well planned.  And I said that that final iteration of TrueCrypt, I think 7.1a was the last official release, and they probably went to 7.2, or I don't remember how they incremented the number.  The point was they neutered its ability to encrypt drives, leaving only the ability to back it out, to finally, to permanently decrypt the drive.  But that change was massive.  You had to go through all kinds of places in the code in order to do that.  So they spent a long time preparing to say goodbye.



LEO:  Isn't that weird.



STEVE:  Even though none of us were impressed with the way they did it.



LEO:  The last I've seen, Matthew Green said he was going to finish the audit this year.  So I don't know where that stands.  We've got to call Matthew.  Because he raised 60, $70,000 to do it.  And he says...



STEVE:  It might be taking longer.  But if he's got that much money...



LEO:  He also - I'm looking at an article from Krebs on Security at that time, in May - was putting together a team to kind of take over the TrueCrypt code.  But we haven't heard anything about that, either.



STEVE:  No.  And I remember when there was someone who was in touch with one of the authors, and I saw Matthew asking that third party to ask the authors for license privileges because Matthew was respecting the fact that this wasn't technically open source.  Now, it has been forked, but those are not authorized forks because this wasn't forkable.  They were saying, "We're going to let you see our code, but it's still ours.  We're not wanting it to be used as a template."  Now, and in fact, one of the other offshoots has updated TrueCrypt a little bit, just adding a bunch of features that don't really matter.



LEO:  There's also TrueCrypt.ch, and they're creating something very oddly named CipherShed.



STEVE:  Yeah.  I think there's a VeraCrypt, also.



LEO:  Yeah.  So there are people trying to do it.  But the last post is from September, and they say we're closer to alpha, and then nothing.  You yourself had a crypto project you were about to embark on.  And then after learning about these national security letters and the demands that the U.S. federal government has made to put backdoors, you decided, "I'm not going to do this."



STEVE:  It was Posner who said - he was attending a cybercrime conference, like a month ago.  And he said, "I don't think it should be legal for cell phone manufacturers to create technology the federal government cannot access."  So I still - the jury is out, almost literally.  Actually it'll be an Act of Congress rather than a courtroom, whether Congress could simply require that commercial entities create a cryptographic backdoor.  It could happen this year.  Or, that is to say, next year.



LEO:  It seems strange that we would have a judiciary and a Congress that would have such an abiding trust in the federal government forever.  We've had such historical records of - and this country was founded based on kind of a lack of trust in federal government.



STEVE:  And set up in order to create checks and balances, of course.



LEO:  Yeah.  That makes me nervous.  When all the branches of the federal government agree, "Oh, trust us."  That makes me nervous.



STEVE:  Then we had arguably the best logo that's ever been...



LEO:  Heartbleed, baby.  I know where you're going with that one.



STEVE:  Now, and that's really - we learned a lesson.



LEO:  Usually exploits don't come with a logo.



STEVE:  If it doesn't have a logo and a catchy name, it's just hard to take it seriously.



LEO:  What was Heartbleed?  Refresh my memory.



STEVE:  Okay.  So Heartbleed was a defect that was found in the TLS protocol because there's something called a "TCP heartbeat" which allows you to sort of send a heartbeat packet to sort of keep TCP alive at the TCP protocol level.  And it turns out that there was a buffer overrun in that, that was found.  So the idea was you could send a malformed packet to a server that had heartbeats enabled.  And that's the other thing.  Nobody uses them.  Nobody needs them.  Nobody ever needed to have them enabled, but everybody did because it was enabled by default in OpenSSL.  So you could send a packet to this server, and it would send back a gift, 64K...



LEO:  Just random.



STEVE:  ...of whatever happens to be...



LEO:  Just whatever's in memory.



STEVE:  ...whatever's in memory.



LEO:  Here you go.



STEVE:  Yeah.



LEO:  We don't know.  Here's something.



STEVE:  Thanks for asking.  Thanks for asking in that strange way you just did.



LEO:  But it could include, not necessarily, but it could include things like logins and passwords unencrypted.



STEVE:  Correct.  Correct.  And so everyone ran around, like in a craze.  And then the guys at CloudFlare said, you know, this is just random crap in memory.



LEO:  Yeah, not necessarily useful, yeah.



STEVE:  We're not convinced that you're ever going to have the server's keys.



LEO:  Wasn't there an exploit, though, wasn't there a demonstration?



STEVE:  Well, they created a honeypot.  They put up a server, and they said, here's a server.  Go.  Oh, but before they did - so they fixed up, they cleaned up their whole network of, I think they use nginx.  But they were using SSL as the security protocol, as everybody does.  So they were aware of the problem.  They shut down the TLS heartbeats, which is all they had to do, just turn that off, because it shouldn't be on anyway.  No one uses them.  Then they set up a honeypot because they were not sure that it was actually, you could actually get credentials from the server.  And they said, "Here's a machine at this IP.  Prove it.  Send us a message signed by the server's private key, and then we'll believe you."  They got some.  That's when they said, oh, my god.



LEO:  This could be serious.



STEVE:  And they replaced their entire certificate infrastructure.



LEO:  Whoa.



STEVE:  Remember, hundreds of thousands of certs because the Heartbleed flaw doesn't leave a log.  This happens before logging engages.  It's right, like at the front door, if you knock funny, it just dumps out 64K of memory.  But you don't connect or do anything.  So you don't get into the logging system.  No one's logging at that level.  So they realized...



LEO:  No record of it.



STEVE:  They didn't have logs, and it was exploitable.  Anybody could have exfiltrated the private keys in their architecture.



LEO:  It turned out it wasn't login and password you had to worry about, it was certificate keys.



STEVE:  Yes, it was the server's identity, the server's private key.  And so a number of researchers, security researchers jumped on the problem, demonstrated that it was exploitable.  And then the only responsible thing for everyone to do was to rekey.  You had to.  And that's where I got all bogged down with the revocation issue, remember, because this was the whole revocation thing where Chrome's got a handful of certificates, and suddenly here's a hundred thousand have just been revoked by  CloudFlare.  Chrome can't handle that.  Chrome just doesn't bother with those.  And that's where I got into the whole CRL...



LEO:  Yeah.  Well, what is the upshot of all of this?  Has Heartbleed been fixed?  There was a new OpenSSL.



STEVE:  Yes.



LEO:  Did everybody patch?



STEVE:  It got fixed, and everybody patched, or turned off heartbeats is all you really had to do.



LEO:  You could just - a line in the config turns it on.



STEVE:  Exactly.



LEO:  But we also have this now worry that maybe many certs have been compromised.



STEVE:  Right.  And we have basically a broken revocation system.  We do not today, even now, have a revocation system which functions because...



LEO:  So I can't, as a website, say, hey, don't use that old certificate, it may be compromised.  Here's my new certificate, and that other one's not good anymore.  It doesn't work.



STEVE:  Because a bad guy, until it expires...



LEO:  Might have that certificate.



STEVE:  Until it expires.  So certificates have, what, like a two- or three-year...



LEO:  So I could pretend to be Amazon with its old compromised certificate, and there's no way for Amazon to say don't use that.



STEVE:  Right, because Amazon serves...



LEO:  Is that still the case today?



STEVE:  Yes.  Amazon is serving the new one, but the old one, if it ever got loose...



LEO:  Your browser won't know.



STEVE:  Until it expires due to its own aging.



LEO:  Right.  No word from the browser.



STEVE:  Right.



LEO:  So that's never been fixed.



STEVE:  No.  Can't fix that.



LEO:  Thanks, Chrome.  Do other browsers handle it better?



STEVE:  There is a system, the OCSP, Online Certificate - OCSP.  Online Certificate Status Protocol?  Probably.  Acronym soup.  That's a system that allows the browser to query for the real-time validity, the status of the certificate.  So that system exists.  The problem is that, if the browser doesn't hear anything, if it doesn't hear "No, it's bad," then it says, "Okay, fine."  That's the fail soft.



LEO:  It may be down.



STEVE:  Yes, exactly, maybe having a bad day.



LEO:  Slow.  I don't want to slow things down.  Let's just go on.  Let's just get...



STEVE:  Maybe you're in North Korea, and you have a good connection.  So then what we want is we want fail hard.  And you could turn that on in Firefox and then - and I have it on, and a lot of our listeners do because we were sort of curious.



LEO:  But it's not on by default.



STEVE:  No, it's not, because it could keep you from getting to sites.  And oddly enough, Google seems to be the one with the worst OCSP servers.  They're unable to affirm the validity of their certificates in a timely fashion.  And the only troubles that I see reported are people saying, "Hey, I got OCSP hard fail enabled, and I have problems with Google sometimes."



LEO:  Worse than that, Imperial Violet, who works for Google, said don't turn it on.



STEVE:  Adam Langley.



LEO:  Adam Langley said don't turn it on.



STEVE:  Oh, I know.  Adam Langley, well, you know.



LEO:  He and Steve don't get along so good.



STEVE:  And it's not getting any better as time goes on.



LEO:  And this is Larry Seltzer's article in which he defends it.  It's a really - it was a great back-and-forth.  We had a lot of fun, and Larry mentioned you.



STEVE:  Yup.



LEO:  And I don't know if the right answer has ever been deduced.



STEVE:  Okay, so the right answer, we're getting there.  The right answer is called "stapling."  Stapling has the server that is offering the certificate getting a fresh response from an OCSP server, or like the certificate authority, and stapling it - like stapling two things together, thus the word - stapling a short-term affirmation to the certificate it's issuing.  The problem is we still don't have the infrastructure for that.  I mean, again, things need to change in order to - or evolve further.  So people recognize it's a problem, and Heartbleed showed that it would be really nice if we were actually able to revoke all of the certificates on the Internet once that may have been exfiltrated due to an old vulnerability that we don't know that no one exploited.



LEO:  You're listening to Security Now!, Steve Gibson in-studio.  And we're going through all the fun and games of 2014.



STEVE:  Okay.  So we talked at the beginning of the year about the backdoor found in the routers over Christmas and New Year's.  Toward the end of April, it turns out it was still in the firmware.



LEO:  Nobody'd fixed it.



STEVE:  Well, they'd - well, okay.  They locked the front door, or the backdoor, but with a key that wasn't very strong.  So what happened, it turns out that somebody looked through the code and realized that that same host string thing was still there, and the port was still...



LEO:  Open.



STEVE:  ...being opened.  But you had to first receive like a knock at the backdoor.  You had to send a knock packet, an Ethernet packet, containing certain stuff.  And so the router would see that and go, oh, and unlock the backdoor.



LEO:  Let me let you in.



STEVE:  Exactly.  Now, that would be a concern, except that it's an Ethernet packet, not an IP packet.  Which means it has to be on the LAN.



LEO:  That's good.



STEVE:  Yes.  Because that means it's constrained to your cable...



LEO:  It's not routable.



STEVE:  It's not routable.  So it would be within your cable provider.  Now, there's a vulnerability because, on a cable topology, everybody's on...



LEO:  Your neighbors could knock.



STEVE:  Yes.  Exactly.  And so that's still in the routers.



LEO:  But they'd have to be your neighbors.



STEVE:  They would have to be on your local segment, within the same Ethernet routing space.



LEO:  Wow.  And we mentioned, and I see in your notes, it was Sercomm that made the chipset or whatever that all these different companies used.  So it was, if you had the Sercomm components, you'd be vulnerable.



STEVE:  Yup.



LEO:  BadUSB.



STEVE:  Oh, boy.  You know...



LEO:  BadUSB.  Now, before BadUSB happened, there was a guy who was a well-known security guy, I can't remember what his - was he at Black Hat or - who said, "I had a virus jump the air gap."



STEVE:  Oh, yeah, yeah, yeah.



LEO:  And everybody said, come on, you can't - nothing would do that.  He couldn't understand how this virus had jumped the air gap.



STEVE:  He couldn't get rid of it.  It kept coming back.



LEO:  He would erase everything, format the drive, and it would still jump into his BIOS or something.



STEVE:  Right.  Oh, that's what, yeah, he was thinking it was his BIOS was being infected.  And the problem is all BIOSes are so different that you couldn't have a universal BIOS virus.  It'd be like a Windows virus infecting a Mac.  It can't.



LEO:  Right, yes.  They're too different.



STEVE:  Yeah.



LEO:  Okay.



STEVE:  Just very different DNA.  So BadUSB freaked out people, I think, disproportionately.



LEO:  This was at Black Hat.



STEVE:  Yeah.



LEO:  In August.



STEVE:  And what the presenters at Black Hat demonstrated was that a manufacturer of the core of many thumb drives - so many different manufacturers of thumb drives buy from the same outfit.  That BIOS, the firmware of the USB controller, was rewriteable.



LEO:  It was not on a ROM, a read-only memory.



STEVE:  Right, correct.



LEO:  It wasn't even on a programmable read-only memory.  It was on EEPROM, an electronically erasable.



STEVE:  And remotely accessible.



LEO:  Oh, boy.



STEVE:  So you could give some commands that were kind of off the book through the USB port and send it new firmware.



LEO:  Here, USB.



STEVE:  Be different.



LEO:  And by the way, not just thumb drives, but anything connected via USB.



STEVE:  Be a keystroke logger.  Partition yourself off and have malware in a hidden region which will be injected into the computer.  Or pretend to be a keyboard and type something of our design.



LEO:  Anything that used this firmware.  So it could be an iPod, or it could be a hard drive or a thumb drive or even a keyboard, if there's enough memory.



STEVE:  Yeah.



LEO:  But you say it's not, what, it was overblown.



STEVE:  It was nice that we knew about it, but...



LEO:  Yeah.  Kind of shocking that it was possible.



STEVE:  Yeah, and I don't believe - I don't remember now whether normal driver software in the computer was able to issue the special codes needed.



LEO:  It might need some special software.



STEVE:  So it couldn't be a worm.  It couldn't jump around by itself.  You could deliberately, you know, bad guys who got access, physical access to the thumb drive could reprogram it and make it be BadUSB.  But your thumb drive couldn't get infected by being plugged into a machine...



LEO:  That had malware on it.



STEVE:  ...because it didn't have access to it.



LEO:  Right, right.  So it hasn't in fact been a big issue.



STEVE:  Yeah.



LEO:  I don't think anybody's fixed it.  It's not like...



STEVE:  No, I mean, everybody still has those thumb drives.



LEO:  Yeah, yeah.



STEVE:  Yeah.  But so it scared a lot of people.  And we looked at it closely to gauge how big the problem was.  And it was like, okay, well, nice to know.  But it's probably not going to get you.



LEO:  It's BadUSB.  Certificates.  Google did a few things this year to kind of, in their opinion, push forward security.



STEVE:  And I love the idea because what Google is seeing, and they're not wrong, is no one fixes security until the house is burning down.



LEO:  Right, right.



STEVE:  We're always waiting till the last minute.



LEO:  So they've used Chrome as a way of kind of pushing forward HTTPS Everywhere, the abandonment of the bad SHA-1 hash...



STEVE:  Yes.  Well, and then so what was controversial about that was that it was already - there was a scheduled sunset for the use of SHA-1 put in place by Microsoft, who also has substantial market power.



LEO:  With Internet Explorer, yeah.



STEVE:  2017.  That's when it was going to happen.



LEO:  Okay.  Two years.



STEVE:  2017.  And Google decided, no.



LEO:  Let's do it now.



STEVE:  Let's do it now.  Why wait?  Well, there's lots of reasons, it turns out, to wait.  Because people have other things to do.  They have schedules and so forth.



LEO:  This is something that we're going to start seeing soon, like in February, I think?



STEVE:  Yeah. 



LEO:  Your browser will see a certificate that uses this broken hash technology.



STEVE:  Okay.  It's not, though.  And that's why it's controversial.



LEO:  Oh, that's right, it's not broken, it's just...



STEVE:  It's not broken.



LEO:  Potentially computers are going to get so fast they'll be able to decrypt it.



STEVE:  Not even that.



LEO:  Not even that.



STEVE:  Not even that.  There is nothing wrong with waiting till 2017.  Microsoft wasn't wrong.  That's what upset everybody was that there's no hurry.



LEO:  It's not an existing problem.



STEVE:  Correct, it's not.



LEO:  It's kind of planning for the future when computers do become fast enough.



STEVE:  Yes.  And so that's why it was controversial was Google said we're going to start penalizing websites in 2015, two years early, if they still have an SHA-1, if their certificate is signed using SHA-1.



LEO:  And the penalty would be, what, in Chrome...



STEVE:  You'd start seeing scary things.  And they have 60% market share.  So that's bad.



LEO:  It hasn't happened yet, though.



STEVE:  It hasn't happened yet.  GRC's certificate, mine, is signed with SHA-1.



LEO:  So when we start seeing warnings...



STEVE:  No.



LEO:  No?



STEVE:  Because I have it expiring on midnight of December 31st, 2016.



LEO:  Okay.  Oh.



STEVE:  And so this is why it's so confusing, is Google is going to start scaring people if the certificate would be valid in 2017.



LEO:  So they're checking the expiration date.



STEVE:  Yes.



LEO:  And saying, okay, you use SHA-1, and you will continue to...



STEVE:  And if you don't change it, it would be valid in 2017.



LEO:  Did you change your expiration date?  Can you do that on a certificate?



STEVE:  No.  I have friends at DigiCert.



LEO:  Ah, you got new ones.  Got it.



STEVE:  I rekeyed so that I was expiring...



LEO:  Why didn't you just get a better - why didn't you just abandon SHA-1 at that point?



STEVE:  Ah.  Perfect.  Thank you.  We're a good team.



LEO:  Why didn't you do that, Steve?  Tell me.



STEVE:  It's because there are still systems out there that only know SHA-1.



LEO:  Ah, okay.



STEVE:  They cannot handle - and it happens that XP are among them.  And there's still a huge number of XP machines.  Now...



LEO:  So if people went to GRC, and you had deprecated SHA-1, and they went there, what would they see?  That this site...



STEVE:  No, it won't come up.



LEO:  It wouldn't load.



STEVE:  You can't load.  Now, many sites only switch you to secure when you log in.  GRC is HSTS.  It's, no, HTTPS Everywhere.



LEO:  HTTPS Everywhere.



STEVE:  So you can no longer use GRC without being secure.  So if I had switched to SHA-2...



LEO:  You would have left out a lot of people.



STEVE:  They couldn't get to GRC at all.



LEO:  Wow.



STEVE:  And so what this does is this allows me to continue offering GRC to everyone for the next two years, until the end, all the way through 2016, without generating any warnings even from Chrome.  And those people who are on XP will be getting warnings from everyone else.



LEO:  But as a result, your grade at SSL Labs is now a C, my friend.



STEVE:  I know.  I was A-plus.  It was brief.  It was brief.



LEO:  So this is to me a little controversial.  You've mentioned Qualys's test, and we've talked about it a lot.



STEVE:  I love it.



LEO:  And you love it.



STEVE:  And Ivan is a great guy.  He's doing a really good thing.



LEO:  One of the things Ivan did at some point was say, well, if you're using SHA-1, I'm going to downgrade you.



STEVE:  Yeah.



LEO:  And that's - is that why you got a C?



STEVE:  Oh, it's bad.  There's all kinds of things he doesn't like now.



LEO:  There's other things you do.



STEVE:  You can click on the link and get the details.



LEO:  There's other things you do.  Oh, oh.



STEVE:  Yeah, he's like...



LEO:  Oh.  You're good on certificate and protocol support, but...



STEVE:  Yeah, look at that.  I'm 100s and 90s everywhere.



LEO:  You're vulnerable to POODLE.  That caps you at a C.  You can't get better than a C.



STEVE:  No.



LEO:  You use the SHA-1.  That's a weak signature.



STEVE:  Actually, it's the rePOODle that we'll be getting to in a minute.



LEO:  Uh-huh.



STEVE:  It's because I still offer SSL 3.0, which is now a no-no.



LEO:  No-no.  And, by the way, Steve knows what to do, and he's chosen to do this for good reason, I think.



STEVE:  Yeah.



LEO:  Yeah.  You accept RC4.  And but otherwise you're okay.  Bad man.  All right.



STEVE:  Yeah.  Anyway, I need to reboot the server because I am going to turn off RC4 because we don't need it anymore.  And I'll turn off SSL3.  And I just haven't gotten there.



LEO:  But then you'll be capped at a C anyway because you still support SHA-1.  Won't you?  I don't know.



STEVE:  No, I think I can get a B.  He'll give me a B because - but I don't get my A-plus anymore.



LEO:  So Ivan and Google are punishing people who use this old...



STEVE:  Yeah.



LEO:  But let's reiterate.  It's not cracked.  It's not broken.



STEVE:  There's nothing - I wouldn't be using it if there was anything wrong with it.  There is nothing wrong with it.  And Google isn't, I mean, so what Google is doing, Microsoft was, as of 2017, going to deprecate that certificate.  They would no longer accept them after 2017.  So what Google is doing is saying, starting in a few months, if the certificate could be used in 2017, we're going to punish you now.



LEO:  We haven't seen yet what that will look like.



STEVE:  No.



LEO:  And they didn't say what it would look like.



STEVE:  And they're saying that it will do something in the user experience.  There'll be something that gives you...



LEO:  And it could be something minor.



STEVE:  Could be.



LEO:  Could be an unlocked padlock, you know.



STEVE:  Just like, you know, upside-down question mark or something.  We're not sure about this.



LEO:  We don't know.



STEVE:  We don't know what's going on.  Maybe a new color.



LEO:  And I seem to remember it's, like, soon.  It's like February or something.



STEVE:  Yeah.



LEO:  Yeah.  We're still in Q3.  We've got to keep moving here.



STEVE:  Okay, yeah.  Okay.  So Home Depot.



LEO:  Home Depot.



STEVE:  Seventy million.



LEO:  No big deal.



STEVE:  Big problem.



LEO:  People already - they already had my credit card from Target, so...



STEVE:  Oh, I'm sorry, 56 million.



LEO:  Oh, that's all, okay.



STEVE:  Although it actually affected a lot more people, I don't know why, that I know.  They were like, oh, my god, my card's been hacked.  In fact...



LEO:  Would the bank automatically send you a new card?  Or do you have to somehow do something about it?  Probably be prudent to check.



STEVE:  I don't know what they did.



LEO:  There's no, like, everyone - sometimes the people create...



STEVE:  My friend found a charge on his card that was not his and called the bank.  And they said, oh, yeah, we've been getting a lot of calls.



LEO:  Oy, oy, oy, oy, oy, oy, oy.



STEVE:  Yeah.  I'll bet you.



LEO:  And when they say, "Oh, hey, did you shop at Home Depot in the last three months?  Oh."



STEVE:  Okay.  Shellshock.



LEO:  Shellshock.



STEVE:  Another great name because, again, it's about the name:  BadUSB, POODLE.



LEO:  Although "bashdoor" is not bad.



STEVE:  That's not bad.  Bashdoor is pretty good.  So Shellshock turned out to be a mistake, also very old, that had been there in the bash interpreter for, like, ever.



LEO:  Wow.  Wow.  Wow.



STEVE:  Where it would, when you invoked bash, it would run through the environment variables that were in the system and execute commands.  And it turns out that services running on UNIX, Linux, would sometimes transfer data from the query to the environment.



LEO:  Right.



STEVE:  And so it was very clever because that meant that you could invoke the service remotely.  It would accept the connection.



LEO:  Yeah.



STEVE:  And then, like, move some of the headers from a query into the environment.



LEO:  It's for convenience, for programmers.  Then they can use this kind of temp variable.



STEVE:  So much easier that way.



LEO:  Yeah, yeah.



STEVE:  But then they would later, for their own purposes, they would use bash for some of their own work.  So by them, by the service invoking bash, bash would then go look and parse the environment and find the variables.  And so if the hacker had put bash commands in the headers, they would end up getting executed.



LEO:  Wow.



STEVE:  Shellshock.



LEO:  Yeah.



STEVE:  And there are now worms crawling around the Internet using this.  Worms were developed.



LEO:  So Apple has bash.  All Linuxes have bash.



STEVE:  Everybody's got bash.



LEO:  Were they updated by Linux and, you know...



STEVE:  Yeah.



LEO:  Did Ubuntu update?  And Apple...



STEVE:  Yeah, yeah, yeah.



LEO:  ...updated their bash.



STEVE:  Yeah.  So the response was, we're not sure why anyone is parsing commands in the environment.



LEO:  Stop it.



STEVE:  Nobody ever wanted to do that.



LEO:  Well, I think, I'm guessing, but it does happen in Perl, too, where you'll execute something, and the return statement is stored silently in a temp variable that is used, an exclamation mark or something, that you can reuse.



STEVE:  There's nothing Perl doesn't do, actually.



LEO:  Yeah.  And bash does that, too, for convenience.  So you execute a command, and you don't have to have an explicit return.  You're just going to have in some temp variable stored in the environment the return, and then you can use that in your continued code.  But now we can see the problem.



STEVE:  Yeah.



LEO:  It all happens because this stuff was written before ubiquitous Internet.



STEVE:  Exactly.  Back once upon a time, where there was you and your console, it would have been a handy feature.  And this is the sort of thing that UNIX hacks have always worked around is that sort of policy.  But exactly that.  Then we add servers, and no one remembers that bash is going to parse things.  I mean, and so, and it also really - you could argue that it required, to know that that was a problem, several different knowledge domains.



LEO:  Right.



STEVE:  An obscure feature nobody even knew bash had.



LEO:  Or even thought about how it might be misused, really, frankly.



STEVE:  Yeah, exactly, yeah.



LEO:  Somebody's saying it does have to go through CGI.



STEVE:  Oh, okay.  So...



LEO:  So that's a little bit of a protection.



STEVE:  So a CGI interpreter was a way to get in there.



LEO:  Yeah.  You'd have to be running a web server and so forth.  So, but there are botnets out there created by this, yeah.



STEVE:  Then we have POODLE, another great name.



LEO:  Okay.  This is an acronym.  I didn't know that.



STEVE:  Yes.



LEO:  What does it stand for?



STEVE:  Padding Oracle On Download Legacy Encryption.  Okay, now, that's a hard - this is one where they had the "P."



LEO:  Sounds like a retronym.



STEVE:  Exactly.  They had the "P."  Okay, what can we come up with that's like "P"?



LEO:  All right.  Padding, we got padding.



STEVE:  And Oracle, that's a common crypto term.



LEO:  But they don't mean Oracle the database company.



STEVE:  No.



LEO:  They mean like a...



STEVE:  No, a cryptographic oracle.



LEO:  Like oracle, okay.



STEVE:  Where you do something, and it gives you a response.  It replies to you.  So this was in October, only a few months ago.  Everyone's still remembering that.  And that was - this is the first bite of the POODLE.  There were two bites of the POODLE.



LEO:  Right.



STEVE:  The POODLE re-bit.  So, and the problem with POODLE was that we knew that there was a problem with probing SSL.  And everyone assumed that, by moving to TLS, we would be safe.  But the reason there's a downgrade attack is that - so we know the way SSL works is the client says, here's the list of things, the list of ciphers and protocols that I know, hands that to the server.  Server looks through them and, in its own prioritized list from best to least good, it chooses the most secure one that it knows that the client also knows.  And it says, okay, let's use this.  Well, it turns out that, if a hacker got into the conversation and eliminated the TLS offerings from the client...



LEO:  The secure choices.



STEVE:  Well, the TLS secure ones.  So what the server would only see is SSL3.  So then the server would go, wow.



LEO:  That's all you talk.



STEVE:  Dumb client.  Okay, fine.



LEO:  I haven't seen anybody like that in a while, but okay.



STEVE:  So what the client would see back...



LEO:  Instead of using public key crypto, let's use pig Latin.  And at least you understand that.



STEVE:  Yeah, exactly.  So the server thinks the client's dumb.  The client sees the server offering SSL3.  The client thinks the server's dumb.



LEO:  Otay.



STEVE:  Because they think that SSL3 is the best they can do.



LEO:  So it did require kind of a man in the middle.



STEVE:  It does.  Oh, yeah, you have to spoof that.  Now we have got - we've done a downgrade, what's called a "protocol downgrade," where, rather than having the protocol we could have, the hacker has pushed us back down to one that's vulnerable.  Now we can use a well-known attack where you send multiple probes in, and you can, over the course of about 16,000 queries, you can start guessing bytes from cookies.



LEO:  That's a lot of queries.



STEVE:  It's a lot of queries.  That's why it's like, uh...



LEO:  So you still - you're POODLE vulnerable.



STEVE:  Yes.



LEO:  You still support SSL3 on GRC.com.



STEVE:  Well, actually, yes, I support SSL3.



LEO:  And is that for XP users, as well?



STEVE:  It's not, actually.



LEO:  Who's that dumb?



STEVE:  It's just I haven't rebooted the server.



LEO:  Oh.  If you reboot, it'll go away?



STEVE:  Yeah.



LEO:  Okay.  And then you'll at least pass the POODLE test.



STEVE:  Then I get a B instead of a C.



LEO:  All right.  Can you reboot from here?



STEVE:  I don't like to reboot.



LEO:  I don't blame you.



STEVE:  No, because it's, you know, it stays up for, like, years at a time.



LEO:  You like that uptime - four years, 73 years.



STEVE:  In fact, I reboot so infrequently that I like to go there, just because if any smoke comes out of something, I mean, it's like, I don't know if it's going to, you know...



LEO:  That's why you're not doing it from here.



STEVE:  That's why I'm...



LEO:  You could do it from here, but...



STEVE:  Oh, yeah.  In fact, I did VPN in from here because I wanted to see - by the way, I forgot to say that the docs are not yet online because I've never VPNed into my Windows 2008 in the two years that I've had it.



LEO:  And it didn't work, or...



STEVE:  Well, I just never set it up.  I didn't have remote filesharing.



LEO:  I remember you coming to Toronto and using the smallest computer I have ever seen in my life...



STEVE:  The little Libretto?



LEO:  It was a Libretto, Toshiba Libretto.



STEVE:  Yeah.



LEO:  And you were VPNing into your - it was the strangest thing I've ever seen.  Do you still have that?



STEVE:  Yeah.



LEO:  Of course you do.



STEVE:  I do.



LEO:  Is it in the freezer?



STEVE:  No, that's the one that runs the Kindle on my stair climber is the little Libretto.



LEO:  Good use for that.



STEVE:  So it's a good use for it, yeah.



LEO:  You must have excellent eyes, that's all I can say.



STEVE:  No, no, no.  I have a huge screen mounted on a...



LEO:  Oh, plugged into the Libretto.



STEVE:  Yeah.  It's like, look at all the screens you have.



LEO:  Nice.



STEVE:  Yeah, exactly.  And a clicker strapped to the handles.



LEO:  Oh.



STEVE:  Yeah, so I'm able to do...



LEO:  It's like a teleprompter.



STEVE:  Exactly.  Okay.  So POODLE gets resolved by turning off SSL3, and...



LEO:  Which nobody uses.  It would be harmless to do that; right?



STEVE:  Even XP has TLS 1.0.  So I'm going to reboot any day now.  When I get home.  That gets resolved.  Then along comes Regin.



LEO:  Oh, boy.  Now, we still don't know the official pronunciation.  Symantec named it.  You first thought it was Regin because it used the registry.



STEVE:  Registry Install, yes.  But there's a video of a Norseman saying "Regin."



LEO:  Because he's the King of the Norse or something?



STEVE:  Yeah.



LEO:  Some historic character.



STEVE:  Yeah.



LEO:  All right.



STEVE:  Regin.



LEO:  Regin.



STEVE:  We know it's Regin.  Sort of like the President.



LEO:  And it was one of these - it was fascinating.  You actually were quite impressed by the technology.



STEVE:  Yeah.



LEO:  It's one of these probably state-sponsored attacks.



STEVE:  Yeah.  And this is one that we didn't - we're pretty sure this is Russian in origin.



LEO:  Oh, really.  Because I thought at the time we decided it was U.S. or Britain.



STEVE:  No, it's because Western countries are where it's been found.  So it's the Russkies that are poking at us.



LEO:  And is this the one that got into things like airline reservation terminals and hotel...



STEVE:  Yes, and like pulling metadata about people's movements and where they were staying, then determining, like, who was talking to whom.



LEO:  And it was really impressive because it had a loader.



STEVE:  Four-stage loader.  Remember, it came in and looked around, and then it said, okay, the coast is clear, and it brought in...



LEO:  Come on in.



STEVE:  ...the second stage.



LEO:  And it would decrypt these.  These are all encrypted modules.



STEVE:  They were all successively encrypted.  And the thing that was disturbing was we found out in retrospect that the antivirus companies had known...



LEO:  Something.



STEVE:  ...something for a couple years and hadn't blown the whistle because it's almost like they were complicit.  They weren't sure whose side it was on.  So they didn't want to blow it if it was on their own local government's side.  So they just kept quiet until additional information came to light, as finally did...



LEO:  So now we think it's...



STEVE:  We think it's Russian.



LEO:  ...Russian.



STEVE:  Yeah.  And this, I mean, this is the first clear evidence we have of the same kind of competence of deep espionage-grade malware that we presume the U.S. has, and so the East does, too.



LEO:  And then finally the POODLE bit again.



STEVE:  Yes.  It turns out that the fix for POODLE was turning off SSL3.  And so everyone ran around and turned it off and, except me, rebooted their servers.



LEO:  Right.



STEVE:  I'll do that soon.



LEO:  You've turned it off, but not rebooted.  All right.



STEVE:  Exactly that.  So, but the vulnerable stack was in the frontend appliances, the load-balancing appliances, of 10% of the Internet.  So someone thought to scan those, and it was there.  So I think it was F5 is one of the companies, and there's a different one, I can't remember.  We've talked about it.



LEO:  Is it much concern, though?  It sounds like it's a lot of work to get kind of a little bit of information.



STEVE:  It's a lot of work to get a little bit of information.  And, boy, some of these cookies are just crazy big now.



LEO:  Yeah.  I don't know what - so what?  You've got my cookies.



STEVE:  That's why I'm not in a hurry to reboot.  Well, and besides, I don't even rely on it.  My own eCommerce system doesn't store anything valuable in cookies.  I encrypt separately.  So it's actually, for GRC it's not a problem, except that I get a C.



LEO:  Is the biggest story of the year the Sony hack?  I think it has to be.  But despite all of this, we've just gone through the whole year, and it was an amazing year.



STEVE:  It's exhausting.  I'm exhausted.



LEO:  Yeah.  And sometimes you feel like, well, it shouldn't be the last thing that happened in the year.  That's just the one we remember best.  And yet I have to say...



STEVE:  Oh, if this happened in January...



LEO:  It would still be...



STEVE:  Yes.



LEO:  ...a big, big story.



STEVE:  I think my question is what effect will this have for IT?  We know what effect Snowden's revelations have had for the availability of security.  This last year we have to thank Edward for all of this kneejerk, I mean welcome, reaction.



LEO:  Right, right.



STEVE:  And so you have to imagine that there are boardrooms all over the country where the CEO is saying to the CIO, is this what you've been telling me we're vulnerable to?



LEO:  Yeah.



STEVE:  I don't want that to happen.  I don't want my emails getting out.  And then the CIO says, all I need is money.  Just I need budget and time.  I've got to hire some guys, and we'll bolt things down.  And, oh, by the way, you may not be able to VPN in from your yacht in the Mediterranean without using this key, this dongle that I keep trying to get you to use, but you say it's too much work.



LEO:  We immediately started talking about implementing AppLocker here for that very reason.



STEVE:  Yeah, in fact, when I go to Windows 7, I'm going to fire up AppLocker and go to experiment with the feasibility of a whitelisting system.



LEO:  See, that's the issue is a lot of stuff breaks.



STEVE:  Yes.



LEO:  Stuff unexpectedly breaks.  It's the same thing with address memory randomization.



STEVE:  ASLR, Address Space Layout Randomization, yeah.



LEO:  Yeah.  I mean, there are some things you can do, but they break unpredictably.



STEVE:  And DEP, Data Execution Prevention.



LEO:  Same thing.



STEVE:  This is why it's in there, but Microsoft only has it turned on for their stuff.



LEO:  Not on by default.



STEVE:  No.



LEO:  Yeah.  Because it's breaking things.



STEVE:  No.  And remember, too, like you were never a fan of NoScript because it kept popping things up saying bloop, bloop, bloop, bloop.



LEO:  Too annoying.



STEVE:  You're trying to execute scripts.  Are you sure?



LEO:  Right.



STEVE:  And we were always annoyed by ZoneAlarm.  Whenever you installed something, you'd get orange dialogues that are saying, whoa.  It's like, okay.



LEO:  We have some concern about AppLocker.  But it won't be implemented company-wide.  It will only be implemented on certain computers because we can't implement it company-wide.  So this is still a very hard problem to solve.  And I frankly still think that, if somebody is determined to hack you personally, if it's a spearphishing-style attack against you, it's going to be very hard to implement.



STEVE:  Yeah.  So minimizing the attack surface is always worthwhile.  And in the same way that we switched firewalls from blocking things that we knew were bad to permitting things that we trust, I really think we're going to end - this is where we're going.  We're going to end up whitelisting.  We're going to end up with an operating system where it learns the things that you permit it to run, and apps are going to be signed, and signatures are going to be checked, and we'll be permitting things, I mean, everyone will feel more comfortable if we do it that way.



LEO:  And yet I have to say, based on everything that happened this year, I feel like it's also hopeless.



STEVE:  Well, I said to you I couldn't fix Sony.  I mean, I couldn't prevent that.  As you said, I mean, with something that size, that many people who are going to click on links no matter how many times you warn them not to, it's like, oh, it's just a little link.



LEO:  The only way really to be secure is to get offline.



STEVE:  Yeah.



LEO:  Yeah?



STEVE:  Camping.



LEO:  Camping.



STEVE:  Yeah.  With no tall trees nearby.



LEO:  You know, the use of drones in national parks, which is forbidden, has been going up logarithmically.



STEVE:  They're fun.



LEO:  Geometrically.



STEVE:  They're fun.



LEO:  Everywhere drones.  I was talking to my hairdresser, she said, yeah, we were at a campsite, and this thing went bzz.  She thought it was a UFO.  Bzz.  Pauses.  Bzz.  And I said, oh, yeah, that's a drone.



STEVE:  No kidding.



LEO:  Yeah, it's everywhere.



STEVE:  Have you seen the Bebop?



LEO:  Yeah, I'm buying - I want to buy one, but...



STEVE:  That's the one.



LEO:  Yeah, but it's not out yet or...



STEVE:  I know.  It's...



LEO:  I was going to get one for Henry for Christmas so he could spy on this sorority.



STEVE:  They did a beautiful job.  Beautiful, wide-angle lens, and then they, in software...



LEO:  Isn't that clever?



STEVE:  It's brilliant.



LEO:  This is from the Parrot AR folks.



STEVE:  The Parrot guys.



LEO:  It's their newest version.



STEVE:  Yup.



LEO:  And the camera is super wide-angle.



STEVE:  It's fixed so you...



LEO:  Doesn't pivot or point.



STEVE:  Right.



LEO:  But gets everything.



STEVE:  Yes.



LEO:  And then it picks a section and corrects it.



STEVE:  Super-high resolution, and then so it does barrel distortion correction and - yup.



LEO:  We talk a lot about drones on the show.  Father Robert has a cheap drone that he's got, like, 80 of in the basement, I think.



STEVE:  Oh, they're fun.



LEO:  Yeah, this has become the drone network.



STEVE:  Yeah.



LEO:  Steve Gibson is the security guru, and this has been a great year for you.  We noticed, I've been looking, I just kind of checked download trends.  I don't pay too much attention to downloads.  But your show went up 20% last year, went up 20% this year.  There is huge interest in the topics we cover, and I suspect that 2015 will bring even more of interest.



STEVE:  Yeah.



LEO:  It's going to be an interesting - we live in interesting times.  You can find Steve at GRC.com.  That's where SpinRite - we didn't talk about SpinRite.



STEVE:  No, you're right.



LEO:  No plug for SpinRite today.  You don't have an email or anything?



STEVE:  Eh.



LEO:  It's Steve's bread and butter, so go buy it.



STEVE:  Everybody knows about it.



LEO:  Everybody should know about it.  It's the best hard drive maintenance utility.  You must have a copy.  If you don't, go to GRC.com and buy it.  Everything else there is free, including the feedback form, where if you have questions we'll be answering probably next week, security allowing.  That's GRC.com/feedback.  Steve also has 16Kb audio versions of the show there, and handwritten transcriptions by an actual human being, Elaine Farris.



STEVE:  Elaine, yup.



LEO:  And so if you like to read along - and this would be a good one to have the transcript of, I think.  That's all there at GRC.com.  Here at TWiT.tv/sn, we have audio and video, higher quality audio and full HD video if you'd like, TWiT.tv/sn.  You can also subscribe to the audio or the video on any podcatch client, iTunes and all of the above.  Plus we have our great apps, thanks to our third-party developers on all the platforms including Roku, which would be a great way to watch the show.  Thank you, Steve.  It's been a great year.  I'm so glad to have you in-studio.  It's so much fun.



STEVE:  And we're going to have fun tomorrow.



LEO:  Tomorrow, don't forget, 3:00 a.m. Pacific, 6:00 a.m. Eastern time, 1100 UTC.  We begin with the ball drop, midnight, as New Zealand ends 2015.



STEVE:  New Zealand is the first one.



LEO:  New Zealand's first.



STEVE:  Is that 4:00 a.m. our time?



LEO:  3:00 a.m.  So I come in at 2:30.



STEVE:  Whoo, baby.



LEO:  And then go on through the day for 24 hours.  There's 27 time zones, and we are very close to having somebody from every time zone.  There's just a few missing.  If you're in the Pacific Islands, TWiT.tv/nye.  Let us know so we can get you via Skype.  And we'll be saying Happy New Year all the way across.  We're doing it to raise money for UNICEF.  We're going to have musical performances.  Many of our hosts, almost of our hosts...



STEVE:  Breakfast with me at 6:00 a.m.



LEO:  ...will be here.  Steve likes to come in early, thank god, so I'm not all alone.  Those first three hours are tough.  But we've planned a lot.  And in fact, I don't know if you noticed, but we've got sawhorses out on the street.  We're taking over the street.



STEVE:  Wow.



LEO:  Going to have a carnival out there.



STEVE:  Neat.



LEO:  Crazy.



STEVE:  Neat.



LEO:  Crazy.  So I hope you'll stop by tomorrow for that.  And of course next week, and every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC.  That's when we record Security Now! with Steve Gibson.  Happy New Year.  We'll see you next year.



STEVE:  Thanks, buddy.



LEO:  Bye-bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#489

DATE:		January 6, 2015

TITLE:		Listener Feedback #204

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-489.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world "application notes" for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about the latest security news and then answer your questions.  It's a Q&A episode.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 489, recorded Tuesday, January 6, 2015:  Your questions, Steve's answers, #204.



It's time for Security Now!, the show that covers your security and privacy online with this guy right here.  He was in-studio last week, I'm sorry to say he's back in Irvine, our Security Now! host, our genial commentator, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you, as always, although from a distance.  It was really fun to be in the studio.  And in fact I try to decorate the show notes with a security-related photo.  In this case, I chose a photo that Lisa happened to capture while I was attempting the very first ride of my life of the mechanical bull, which you had set up.



LEO:  You made this face a lot, in fact, all day and night.



STEVE:  Did I.



LEO:  Yeah.  I have another one of you which I will dig up.



STEVE:  Not when Marilyn was on my lap.



LEO:  With Marilyn Monroe kissing your forehead, yes.



STEVE:  Oh, I thought I was pretty happy with her doing that.



LEO:  Yeah, you were happy.  It was a surprised happy.  Awesome.  Awesome.



STEVE:  So for those of our listeners who don't know, all of the hours of the podcast are available at TWiT.tv/specials.  And they're all enumerated there.  I thought that, well, there was a lot that was a lot of fun.  So I got a lot of great feedback from it.



LEO:  I got this pop-up just now - this is very odd - on iTunes.  Do you want to allow this computer to access information on Steve's iPhone 6 Plus?  Do you have an iPhone 6 Plus?



STEVE:  Uh, yeah.



LEO:  Is it called "Steve's iPhone 6 Plus"?



STEVE:  It is.



LEO:  You know, it's very strange, because obviously your iPhone 6 Plus is not connected to this iMac here.



STEVE:  Oh, I know what it was.  I was charging.  And I had it plugged into the red connector, which Jeff explained was for your clone iPhone, and so he had me switch it over.  And then I got the pop-up, do you want to trust this computer?  And of course I said no because I didn't want to form an affiliation.  But that's what that was.



LEO:  The computer feels rejected and is continuing to try to affiliate with you.  Isn't that strange?  I've been here since then, but this is the first time that's popped up.  You didn't leave your phone here, did you?



STEVE:  No, no.



LEO:  Okay.  So, well, anyway, thank you for coming.  I apologize, as I have been to all the hosts, for the truly awful dinner that we served you at the hosts dinner.



STEVE:  Oh, god.  I did - I'm glad you said that because I wasn't going to say anything.  But, oh, lord.



LEO:  I apologize.  I have pictures.  I have evidence that no one ate anything.  And probably wisely so.  It was a wonderful, convivial meal.



STEVE:  Yes.



LEO:  And I just apologize because we could have chosen a nicer restaurant.  We thought we'd choose something with a little local color.  I didn't know the color would be brown.



STEVE:  Yeah.



LEO:  But anyway, so I do, I apologize.



STEVE:  No, it was fun.  It was a social gathering.



LEO:  That's what it was.



STEVE:  And that was really the point.  And, I mean, who really cared?  I didn't care.  We didn't go there to, you know...



LEO:  Yeah, but I just - I figured, yeah, I figured probably you and everybody else were thinking, good lord, has TWiT gone bust?



STEVE:  But now that that's out, now that you have that out of your system, we're all glad.



LEO:  It was so much fun.  I have some great pictures, which I'll be sharing.



STEVE:  Oh, my god, it was a great time.  Absolutely a great time.



LEO:  I'll show - this is my favorite picture.  I don't know if you've seen this.  This is of you at the dinner, looking over your shoulder.



STEVE:  Oh, I didn't see that.  That's neat.



LEO:  Just a great smile.  And there's Sarah Lane behind you.  It was odd because how many times has Lisa, doing what she does so well, going for the money, how many times have we gotten - there's Denise Howell - all the hosts together?  And it's so odd to see all of you, not on Skype, but in the same room.



STEVE:  Well, and one thing that we did that I think we should do more of, and that was the one segment where I and three others, I think myself, Rene, and I can't remember, maybe Jeff?  Yeah, I think it was Jeff.  Anyway, it was the host roundtable.  And I got so much...



LEO:  Oh, that was great.



STEVE:  ...positive feedback.



LEO:  We'll do that again.  In fact, we should have done more of that because we had you all in-studio.  And I bowed out, I actually was sitting and listening, it was so good.  Randal Schwartz, who is our FLOSS Weekly host...



STEVE:  That's who it was, yup.



LEO:  Rene Ritchie from MacBreak Weekly.  Paul Thurrott from - it was Paul, right, Paul Thurrott?



STEVE:  It was either Paul - I think it was Jeff, I think Jeff Jarvis.



LEO:  Jeff Jarvis from This Week in Google and Steve Gibson from Security Now!, all talking about kind of a wide range, I think it was kind of like a quiz show.



STEVE:  Just anything.  Yeah, just anything.



LEO:  It was great.



STEVE:  Yeah.  But it went really fast, and we jumped around, and just it was just, you know, it's not the level of interaction you can normally get through Skype connections.



LEO:  Right.



STEVE:  And it was atopical.  It was just about whatever we wanted to talk about.  And I got, I mean, of all the things that happened, that was the thing that people said, wow, we should have had more of that.  So...



LEO:  I agree.  I agree.  I agree.  That was wonderful, yeah.



STEVE:  Tuning it as we go.



LEO:  I'll find out what hour that is.  Somebody's asking which episode that is because you know we put it all up on the website, on TWiT.tv/specials.  So I'll find out for you.  Go ahead.



STEVE:  So we have a Q&A this week.  We haven't - we skipped two weeks, actually I guess three, because of end-of-year stuff.  And I think I really liked, and I also got some great feedback, about the idea of the last Security Now! of the year being a previous year retrospective.  I think that'll be something we also add to our format because a lot of people liked cramming all of the craziness of 2014 into a summary.  It was like, okay, whew, we made it.  Here's what happened.



LEO:  Yes, yeah.



STEVE:  You know, because it's sort of a nice opportunity to do a review.  So that we will do.  Q&A 204, and not a ton of stuff has happened.  We're going to talk about the HSTS supercookie that has people kind of needlessly worried, but it's an interesting, from a security theory and technology standpoint, an interesting hack.  Then of course Gogo's in-flight cert spoofing has generated a bunch of buzz.  I will talk about Thunderstrike that you talked about in the previous hour on MacBreak.  A quick note about CryptoLocker's successor.  And then of course we've got 10 questions and comments and thoughts from our listeners.  So another great couple hours here.



LEO:  Marvy.  Chatroom is saying that it was Hour 4.  I can't believe it was Hour 4.



STEVE:  No, it had to be later than that.



LEO:  Yeah, I think it must have been.  No, I don't think all those people were here.  But maybe.  I don't know.  For me it's all a blur, to begin with.



STEVE:  And Leo, I've got to say, I'm impressed.  It took me 48 hours to recover.  I came home, and I slept for 15 hours.



LEO:  Yeah.  Me, too.



STEVE:  I went to sleep at 7:30 and got up at 10:30 the next day.  I just, you know, it just knocked me out.  But, boy, you really...



LEO:  Oh, I did the whole thing, obviously.  It was TWiT Live Special #212.  And there you have it.  And believe it or not, so it was like 4:00 and 5:00 in the morning.  Something, I don't know, 7:00 in the morning.



STEVE:  Well, I know that Rene and Randal both were planning to be part of the Breakfast with Steve, and we moved that forward, and so...



LEO:  I never did have breakfast, by the way.



STEVE:  No.  But you and I had a neat...



LEO:  I was counting on breakfast.  They told me there'd be breakfast.  But this was good, and I highly recommend it.  We should probably just put this out as a little bit by itself because it was so good.  But it's about, let me look here, it's about halfway, a little less than halfway through TWiT Live Special #212.  Looks like it starts about - after the trust exercise with Josh, about 15 minutes in, there you go.  It was such fun, and we opened so many bottles of champagne.



STEVE:  And by the way, I've been hearing you talk about understanding the need for body hair.  And of course that's why I wear the cap.  I was just reminded because there I have my little French cap on, as I do.  And it's because I keep my hair so short that, as you have found, it really is cold.



LEO:  It is not - hair is not an evolutionary mistake or leftover or vestigial.  It really protects your head.



STEVE:  And we know that you lose a lot of heat through your head also.



LEO:  I've been wearing a cap to bed.  A nightcap.



STEVE:  I think our brain uses, what is it, 20% of our body's total energy budget?



LEO:  There's a lot going through there, yeah, yeah.  And this is just a perfect radiator now.



STEVE:  Yeah.  Ah, it'll grow back in no time.



LEO:  Anyway, it was fun.  We raised $75,000 at final count for UNICEF, a little more than 10 of that through the auction, and about $61,000 through the...



STEVE:  Nice.  Just donations.



LEO:  Direct cash donations.  And you'll feel good about this, that 91% of the money UNICEF receives goes right to the kids.  It is one of the most efficient charities out there.  So I feel very, very good about what we did.  It was worth getting a tattoo and a haircut.  I tweeted, I woke up with such a sore butt.  What happened last night?



STEVE:  Such a good sport, Leo.  Yeah, when that happens in Vegas, then you have a problem.



LEO:  I was looking for a tiger.  There were no tigers.



STEVE:  In Petaluma.  Petaluma.



LEO:  No crazed monkeys.



STEVE:  So before I forget, I've also been listening to you talk about "The Imitation Game."



LEO:  Which I haven't - I just got the DVD.  So I'm talking through my hat, as they say.



STEVE:  Wait, wait.  Did you get "The Imitation Game" or the invitation?



LEO:  No, no.  I should explain.  As a member of the Screen Actors Guild, I get screeners for nominated movies.



STEVE:  [Gasps]



LEO:  And that's one of them.  So I got the screener.



STEVE:  What?



LEO:  I know.  It's not...



STEVE:  Wow.  Wow.



LEO:  Life's not fair.



STEVE:  Wow.



LEO:  But I haven't seen it yet.  And I want to see it.  It's the story of Alan Turing.



STEVE:  I wish I knew you, Leo.



LEO:  You know what?  They're so paranoid about piracy that you have to click a button before you can watch the movie on the DVD that says you will not lend or give this to anyone else, and you will shred the disk after you're done watching it.



STEVE:  Wow.  Okay.  So the point I wanted to make was, because I've heard you talking about the way Hollywood portrays...



LEO:  I'm nervous.



STEVE:  ...mathematicians.  And the way I would characterize the portrayal of Alan Turing is as a prima donna.  I think that's the perfect word is that - and I'm not giving anything away because you can see it in the trailer that they keep running.



LEO:  Yeah, it's obvious, yeah.



STEVE:  Where he says, well, "The code is supposed to be unbreakable.  Let me take a crack at it, and we'll find out," you know, as if he's going to be the ultimate authority for crackability of this unbreakable German cipher.  So anyway, I really liked it, although - and I have to say that his prima donna-ness, it would be nice to know who the real Alan Turing was because of course now we have this particular view of him.  But it was crucial for the plot that that be his character.  So it could well have been accentuated, exaggerated.



LEO:  Well, and that's, you know, some my critique, I haven't see it, so I will watch it, and then I'll come talk back to you next week.  First of all, all for people, the general populace, understanding who Turing was, his genius, he's the father of modern computing in many ways and was persecuted horrifically by the British government in a shameful fashion.  And I'm all for anything that tells that story.  I just - I think that, just as geeks are often misrepresented in mainstream fiction as being geeky, mathematicians are often - I'm thinking of "A Beautiful Mind" and "The Social Network."  The numbers appear through the air.  And I've read some reviews that say this is perhaps not doing him a great service.  His other achievements aren't mentioned.  Maybe it's not as, you know, this is a thriller, and so they have to make it a thriller.



STEVE:  It did induce me to figure out exactly how the Enigma machine works.



LEO:  That's fascinating; isn't it?



STEVE:  And I thought I would give our listeners an explanation of it next week.



LEO:  Would you do a show on the Enigma machine?



STEVE:  We could.  I mean, it turns out it's really...



LEO:  Oh, that would be awesome.



STEVE:  It fits into the discussions we've had before.



LEO:  It's crypto.



STEVE:  And it, well, it's...



LEO:  Mechanical crypto.



STEVE:  Yeah, I don't want to give it away, but I completely understand it, and it's not so complex that we could not explain it in an audio podcast.  So it's a great - it would be a great topic.



LEO:  I would very much like to do that.  I've seen an Enigma machine in a museum somewhere, and it was quite amazing.



STEVE:  I'll explain it next week.  That'll be our topic for next week.



LEO:  Yay.  Great.



STEVE:  So we had a Chaos Computer Convention that just occurred.  And, oh, no, that's the wrong topic.  Well, okay, I'll talk about that first.  And you did talk about this during MacBreak Weekly, the so-called "Thunderstrike" exploit.  And, yes, as you also noted, we've commented, we did over the holidays, for the holiday podcast, that you really have to have a good name for an exploit in order for it to get hooked, or for it to really get picked up.  And of course the famous one was Heartbleed, where it came fully with a website and its own logo when the Heartbleed vulnerability hit us last year.



Thunderstrike has at least a good name.  And we already anticipated the problem on this podcast because I did mention some time ago that Thunderstrike offered the same, you could almost argue too much, power that the Firewire interface does, or did, since Firewire is sort of fading.  And that is, it is a very high-performance direct connection to the system bus.  And it allows the peripheral to be a master on the bus, not just a slave.  And if the peripheral can be a master, it's able to generate both the addresses and the data.  And that means it's like another processor.  It's like something as powerful as the processor outside the case, which you're connecting through a serialized interface.  So, and even Wikipedia, they have a page called "DMA Attack" because this is a direct memory access (DMA) vulnerability that's built into the specification.  And on the Wikipedia page they say, "Examples of connections that may allow DMA in some exploitable form include FireWire, ExpressCard, Thunderbolt, PCI, and PCI Express.  And that's absolutely right.  Those are all bus-level interfaces.  Now...



LEO:  We've seen a FireWire attack; right?  I mean...



STEVE:  Yeah, yeah.  In fact, there was a famous credential key extraction through FireWire where somebody plugs a little box into your Mac when you're not looking and is able to rummage around in RAM.  I mean, they have complete access to memory.  Well, it turns out that, in the case of Thunderstrike, there is, similarly, bus-level access to the firmware.  The firmware of the Mac is just a region of memory.  And what this Thunderstrike does is leverage its access to the firmware in order, well, I mean, to the entire hardware of the machine to rewrite the firmware and then change the public key which is in the Mac, which is used to verify any additional firmware updates, so that it can't be removed.  So the good news it is hardware-level physical access required.  The bad news is, if you get infected with this, you can't get rid of it.



Now, Apple has already released some updates for a current - one of the minis and something else.  And they will absolutely, you know, they're responding to this as quickly as they can.  And there are things they can do to mitigate this because there are controls that are apparently not in place at the hardware level, where you can restrict the regions and ranges of memory access through Thunderbolt.  And so Apple's going to get better about doing that.  So I'm sure we'll see some updates to these systems, and they're already pushing them out for a few platforms.  And I'm sure they'll give us coverage because this is not good.



LEO:  Yeah.  But you do have to have physical access to the system to do it; right?



STEVE:  Yes, yes, yes, yes.  You've got to plug something in physically into the Thunderbolt connector.  And really what you're doing is you're plugging it...



LEO:  Well, like BadUSB you could actually have a corrupt device; right?  Would that be possible?



STEVE:  Sure, sure.



LEO:  So you could have a corrupt Thunderbolt drive that would then infect the computer.



STEVE:  Right.  Yeah, I saw some notions of like a crossover with NSA, saying that this is the sort of thing that some of the Snowden slides were implying that they were able to do.  And so we may be foreclosing another one of their tricks by locking this down and being more secure with what Thunderbolt is able to access.



LEO:  I'm sure there'll be more.



STEVE:  Yeah.  Okay.  So news also broke of an HSTS supercookie.  Now, okay.  HSTS is the HTTP Strict Transport Security, so HSTS.  And that's the feature which allows a website, if you first have a secure connection to it, it allows it to send you a reply header in response to your browser's query that specifically says I want you, Mr. Browser, to henceforth - and actually in this response header is a max age, which starts a timer that says, for the following number of seconds, only ever access this site over secure connections.  And what it does is it specifically - having this HSTS, the Strict Transport Security header, in the reply specifically allows the browser to autonomously upgrade any non-HTTPS, that is to say, any HTTP connections, to SSL/TLS connections until that max age expires.  And there's an option on there, "include subdomains."



So, for example, GRC has long been HSTS, Strict Transport Security.  And GRC's max age is the max allowable.  It's something like 31,536,000 seconds, which is like, you know, forever.  And so browsers all over the planet who have ever visited GRC, all have received - everyone who visits is receiving that reply.  And I'm saying don't ever even try to access over HTTP.



Now, the reason we do this is that, remember, there was an attack which was being exploited where, if a bad guy could intercept your first HTTP access, they could strip out the HTTPSes from the response and prevent your browser from upgrading its security to SSL/TLS, to secured.  And so the problem was that first access created essentially a persistent vulnerability because most users just put in the domain name.  And the browser defaults to HTTP, if you just give it that, because that's been the standard in the past.  And so all initial connections, even if the site wanted to be secure, the initial contact would be nonsecure.  That creates an exploitable window.



So what the whole Strict Transport Security effort has done is, once the browser gets you to secure, it tells the browser, remember, in its own sort of separate HSTS cache, remember for this length of time you have permission to never connect to this domain non-securely.  If any URL comes along that matches that domain, you the browser upgrade it.  And so what that does is, after a first contact where the browser receives that cookie, or it's not really a cookie, it's a response header, when the user puts in GRC.com, the browser doesn't any longer go to HTTP the first time.  It itself sees, oh, that's in my HSTS cache forever.  I'm going to automatically make my first connection secure so the bad guy is cut out of the loop from the beginning.



Now, what a clever hacker recognized - and what's interesting about this is this is not news.  This was in 2012 it first came to someone's attention that there was a way, if you could run JavaScript on the client - and so NoScript, for example, or any script blocker forecloses this automatically unless you deliberately run scripts on the site - it would be possible to probe the HSTS cache in the browser by having the JavaScript make a bunch of queries to subdomains to see whether they were upgraded or not, which is, really, it's a hack, but it's a clever hack.  So the idea was that you would go to a site that really was determined to track you.  And script running on the page that you received would issue a whole bunch of nonsecure queries out to - call it, like, a.trackme.com, b.trackme.com, c.trackme.com.  And your browser would contain a unique combination of HSTS upgrades for a pattern of the subdomains of trackme.com.



And the point is that it does create a supercookie.  And what's interesting is that, because the other privacy-enhanced modes are trying to protect their users, the incognito mode or private mode, whereas cookies may not cross that incognito or private mode boundary, HSTS information does.  So you think you're being sneaky, going into incognito mode.  But if you went to a site that was actually doing this - and by the way, this is all just sort of theoretical - then script running on a page you receive from such a site could make it blast out a whole bunch of queries and essentially get binary bits, a one or a zero, for every one of the subdomains that it tested, and then build up a composite ID which would tend to be sticky.



Now, again, because this is two years old, Chrome and Firefox and Opera have long since dealt with this.  If you erase cookies, they flush the HSTS cache.  Now, that's actually not a good thing to do because you want your HSTS cache to protect you.  That's why we have Strict Transport Security.  You'll get it back as soon as you visit sites again, but you don't get it back the first time you visit those sites.  But the problem is this is a problem that no one has a good answer for, no one has a good solution for.



And so what Chrome and Firefox and Opera have done is they said, okay, well, we'll flush this information when people erase cookies.  Safari provides no provision for this.  And on iPhone and iPad, and I don't know on the Mac for sure, but at least on the iPhone and the iPad there is absolutely no way for users to clear the HSTS information through any of the UI.  And the iCloud sync syncs HSTS information.  So if you wiped your device and then resynced it with the iCloud, you would get back this potentially sort of kind of hacker-esque flaky supercookie.



Anyway, that's what that is.  I got a lot of tweets from people saying, oh my god, you know, HSTS can be used against us.  It's like, yeah, okay.  And in fact there's a test site, RadicalResearch.co.uk, that has an example.  And when I went there, it came up blank because I've got NoScript.  And I saw that it wasn't working, and so then I permitted NoScript to run, and then it gave me a token, sort of a crypto-looking thing, about eight characters' worth or so.  And then they said, okay, now if you wander around, this thing's going to follow you wherever you go.  It's like, okay, yeah, with scripting enabled, and with this kind of flaky HSTS hack.  So that's what that's all about.  I don't know that it's anything really to worry about.  Browsers may start looking.  Browsers may take additional action.  It'll be interesting to see how this evolves, if it rises to the level of additional concern within the browser developer security community.



And then the other interesting bit of news is that a company called Gogo, which is doing in-flight Internet access, was caught by, interestingly enough, by a Google employee, minting a Google cert that they sign.  So this person was using Chrome, that won't put up with any nonsense with Google certificates because Google is really protecting themselves.  They've got certificate pinning going on in Chrome; and if there's anything in any way screwy about any Google cert, Chrome will alert you.  So she got alerted when she was doing some in-flight Internet use and tweeted that this Gogo company was essentially doing what we've talked about many times, that is, trying to perform a man-in-the-middle interception, I won't characterize it as an attack because we don't know that it is, but an interception of her secure connection to YouTube.



And what they've said is that they're trying to block access to YouTube.  But that doesn't really hold up to technical scrutiny because all of your traffic is going through their proxy.  So all they have to do is block access to YouTube.  I mean, like IP-level access.  Or they're also providing all the DNS, so they could redirect YouTube.com to an interception page that says, we're sorry, you cannot stream video through your Gogo session while you're flying through the friendly skies.



But they don't do that.  Instead they attempt to proxy the SSL, the secure connection that YouTube is attempting to establish with your browser.  And a warning comes up saying this is an untrusted certificate.  Do you want to proceed?  And so here's the concern that's been raised, and that is, we absolutely do not want to train any fraction of the world to click through those, to say, yeah, yeah, I guess I have to, I guess I'm supposed to say yes to this, the way they're supposed to say yes to license agreements and things.



So first of all, it's not clear at all why they're doing this.  I think this is just lame.  If they want to block YouTube, block it.  Don't try to intercept and decrypt.  I mean, they, like, went to some serious extremes to get into the YouTube traffic, rather than just blocking it.  So I'm skeptical of their response at all.  And Ars Technica sort of underreported this.  Dan Goodin normally does a great job.  But the Ars Technica story said:  "Gogo has been caught issuing a fake digital certificate for YouTube, a practice that in theory could allow the in-flight broadband provider to view passwords and other sensitive information exchanged between end users and the Google-owned video service."  But the fact is it's much worse than that.  The certificate is *.google.com and then presumably has some server alternative name fields to allow it to do things also like www.youtube.com.



So my point is this certificate that we saw a screenshot of because this Google employee took a screenshot and tweeted it, it's carte blanche across all Google properties.  So this is much more than just intercepting the Google-owned video service.  This is really bad.  And so the last thing we want is for people to think, oh, I guess I should accept this fraudulent certificate in order to proceed.  So anyway, it's troubling to see this happen, and I hope that there's a big backlash because we need to not have this become standard operating procedure when people are wanting to use a third party's Internet provisioning.  That just is way bad.



LEO:  Is there a nefarious reason they do it this way?  Or is it just kind of goofy?



STEVE:  It feels - I don't know.  They're saying they want to prevent people from doing YouTube streaming.



LEO:  Yeah, I understand that.



STEVE:  So block the IP.



LEO:  Right, I mean, it's easy to block YouTube.  I'm sure they block Netflix already.



STEVE:  Yeah.  So do that.  But what they're doing is they're trying to get people to accept a *.google.com certificate which they have signed.



LEO:  I mean, that's just bad practice.  I understand, but...



STEVE:  Yeah, yeah.  And so...



LEO:  But is there anything after you get off the plane?  Now are you compromised in some way?



STEVE:  If you were to statically accept that, then yes.  Then if you were accept them as a CA that has signed the Google cert, then that's a static compromise of your machine that you'd be carrying around with you.



LEO:  That is bad.



STEVE:  Yeah.



LEO:  Yeah.  Don't accept it.  But a lot of people would.  And if you weren't on Chrome, you might not even know.



STEVE:  Right.  Well, no, anything...



LEO:  You still get a warning.



STEVE:  Anything's going to pop up and say this is an untrusted certificate.  Do you want to proceed?  And that's my concern is that this is - everyone should always say no.  But if a service that you want is putting themselves on the other side of this, then we're going to start training people to say, oh, well...



LEO:  Right, right, right, you don't want that.



STEVE:  No.  And that...



LEO:  But maybe they're - are they caching YouTube content on the plane or something?  I mean, it seems like, I mean, obviously it's a long way around to do this.  So I'm trying to figure out why they did it this way.



STEVE:  Yeah.  I cannot give you - blocking is easy.  I did see the word "throttling," so I don't know what that means, like throttling YouTube?  Well, then the video's not going to work very well.  And again, you don't have to get involved in the decrypted connection.  You could throttle the encrypted connection just as well.  So, I mean, I can't - I don't want to ascribe anything nefarious, but I think they must be doing more than they say they're doing, whatever that is.  But the concern is people are going to get trained to ignore security certificate warnings, and that's not what we want.



LEO:  Right, that's not good.  Dr. Mom says she noticed this behavior months ago.  So it's probably not new.  People just found out about it.



STEVE:  Right, right.



LEO:  That's interesting.



STEVE:  So I did want to mention CryptoWall 2.0, only because it's not going away.  It's six months old, and I just haven't mentioned it.  This is the successor or the family member of the CryptoLocker society.  We of course have beaten CryptoLocker to death.  And we said at the time that there would be more of this, and CryptoWall is more of this.  It is similarly, unfortunately, well designed.  It is encrypt-your-files extortionware, where you need to pay them in order to get the key in order to decrypt your files.  And there was just an article in The New York Times, "How My Mom Got Hacked Over the Holidays."  And that just sort of reminded me, you know, this isn't gone, and it is really bad.  And so the good news is AV is really on top of this.  And so as long as you've got current antivirus, you've got the best protection we know of.  But if you're going to do a sponsor insert, Leo, about anything about backing up, this would be a great time to put that in because that's really the only thing you can do.



LEO:  I don't, unfortunately.  But you want to take a break now?  No, keep going.



STEVE:  Yeah, we'll keep going.  But anyway, I'm just saying...



LEO:  We don't have a backup sponsor; but, yes, that would be a good thing.



STEVE:  That is, we do know that Carbonite is often a sponsor on the show, so that or whatever you want to do.  But ultimately we're seeing people having their lives turned upside down.  Well, I mean, they have to pay $500, so it's not the end of the world.  But still, it teaches people a lesson.  And many infection vectors.  It's phishing.  It's malware that you may already have on your machine.  It's clicking a link.  It's opening a PDF.  It's like links to an Excel spreadsheet that's exploiting a vulnerability in Windows.  I mean, the things that people did in the past to get themselves infected can now be getting themselves infected with something that encrypts all their files, rather than just sort of says thanks for letting me borrow your computer, I want to attack people with it.  So, yikes.



Okay.  Miscellany.  A couple things.  I rebooted my server.  Leo, you and I were talking a week ago about how, you know, I - now if you go to SSL Labs and check out GRC.com, I got a better grade than I predicted I would a week ago.  I am, GRC.com is back to an "A."  So I have a nice green "A."  I do not have the "A+" that I had for a while because I'm deliberately staying with SHA-1 certificates, both to thumb my nose at Google and their effort to force everybody off of them before necessary because there's nothing anyone knows that's wrong with SHA-1 except Google wants to preempt everyone waiting until Microsoft's 2017 drop-dead day.



LEO:  You just wanted a better grade at SSL Labs.  Let's admit it.



STEVE:  Well, yeah.  No, people were saying, why are you a "C"? 



LEO:  Why are you a C"?



STEVE:  What's wrong with you?  I thought you were a security expert.  Apparently you're numb.  So we also talked about the cipher suite list.  I think it's a bit.ly link, bit.ly/grcciphers, which takes you to a text file.  And remember, Leo, that I left out a comma on one line that broke it.  So I waited until this weekend, when I fixed - I updated the list to the latest and greatest.  It's got the comma back in, and it's updated.



So what I did was I used a judicious selection of - and so that's an ordered list, from the one the server wants most to the one it wants least, carefully chosen so that it will give us Perfect Forward Secrecy.  Those are all the ephemeral Diffie-Hellman key agreement at the top.  Also the longest encryption key lengths, 256 as opposed to 128 when we can get it, and so forth.  And it's something like nine - you only have 1023 characters for the total length of that when you take the line breaks out.  And this thing is absolutely as long as it can be, fitting in the optimal selection of cipher suites for a Windows machine.



So what I've done is I've turned off SSL3 because even XP SP2 is able to use TLS 1.0.  And I still have an SHA-1 cert; but, as I mentioned last week, mine expires on midnight, in fact I will probably be with you, Leo, when that cert expires.  I, however, will have already then moved to an SHA-256 cert.  I already have that, but I'm not running it because I want to stay for a year with a certificate that SP2 users, Windows XP SP2 users will still be able to use all the services of GRC.  They will stop being able to use services of other websites that have been forced to switch to SHA-256.  But my site won't be one that makes them switch.  They'll be forced to switch to other sites, and that's my logic.



Then, by the end of 2015, anyone at that point who somehow is still not able, I mean, all you have to do is use Chrome or Firefox.  They both run fine, even on old Windows.  You just can't use IE, which is now the remaining browser that uses the built-in security suite for Windows.  So all anyone has to do is move to Firefox or Chrome, and then you're fine.  So anyway, I'm back to an "A" grade.  I will have an "A+" one year from now when I finally decide that I'm going to drop SHA-1 and switch over to SHA-256.



Also, you have talked about, and this is in Miscellany, our still waiting, we're waiting for the Kickstarter Temperfect Mug.  And on January 1st I received an update email from them saying:  "The Temperfect Kickstarter campaign was funded one year ago today, on January 1st, 2014."  So he wrote:  "I considered doing a 'year in review' update for you [because it's been a year now we've been waiting] but decided that would just be long and tedious.  In short, 2014 was the year we learned how hard it can be to work with a factory eight [and he says] or 12 time zones away, with a very different language, different ways of working, and a different concept of what a quality product is."  And so he says, "That leaves me with just the last month to review for you."  Because, as I said, I've been getting constant updates.  At least they have not gone, and they haven't given up.



And he says:  "We made a lot of progress in December, and things are starting to come together."  And then I'll just finish by saying that one note they made was they said:  "But after all the back-and-forth with the mug factory in the last months, we found ourselves with enough sample parts to assemble a few mugs ourselves.  So we did.  Logan and I put together a mug and tested it to see how its performance would compare to our computer model predictions and prototype measurements.  The performance is better than predicted, and the temperature hold time was over an hour even without vacuum insulation."



So just to review for our listeners, the cool thing about the physics of this, their concept was that hot coffee, when it first comes out of the pot, is too hot to drink.  You need to wait for it to cool down to drinkable temperature.  So their concept was to create a mug that had a great deal of what I'll call "thermal inertia."  That is, it's not just a vacuum container, but it's like a vacuum container where on the inside, that is, on the coffee side, it's lined in like a big copper ring.  It's not actually copper, but they have something, a material, a thick layer of a material that is initially cool.  And so the idea is that, when you pour this too-hot-too-drink coffee in, the heat in the too-hot-to-drink coffee is taken up by the liner and then preserved by the vacuum seal.  So what happens is the coffee temperature immediately drops to drinkable, but now it stays at that drinkable temperature far longer than it normally would.



That's the Temperfect mug.  All we have is promises.  But you and I have both - we're funders, and they haven't given up yet.  So maybe one of these days we'll get it.



LEO:  Anybody who's ever bought anything on Kickstarter realizes that Kickstarter is great, but it gives people who have no experience manufacturing...



STEVE:  That's exactly it.



LEO:  ...a pulpit to talk about it.  And they're learning on our dime.



STEVE:  Yes.  What we keep seeing is people who don't understand that making something is not as simple as it seems on the outside.  So lots of people are getting an education.  And every so often we get something cool.  You got your Pono Player.  That was Kickstarter.



LEO:  I did, that's true, yeah.



STEVE:  Yeah.



LEO:  Yeah, I've gotten almost everything I've tried to buy.



STEVE:  Yeah, I think overall the idea is very cool.  So I wanted to ask you, because I have not been keeping up, has anything interesting happened at CES?



LEO:  Yeah.  I mean, it depends what you mean by interesting.



STEVE:  Well, cool stuff that we have to have.



LEO:  We have Father Robert Ballecer down there.  We have Dick DeBartolo and Scott Wilkinson.  I'm interested...



STEVE:  So is coverage happening?  Is TWiT doing...



LEO:  Oh, yeah, yeah, yeah, we're covering it on TNT every day.  We have - have we put it up on Specials yet? - ShowStoppers and Pepcom, the little events that they do.  And, yeah, and then Home Theater Geeks will have a special from there.  And I'm kind of interested in the quantum dot backlighting that some of the manufacturers have announced.  That technology interests me.  We'll see if it makes a difference in TV.  Scott thinks it will.  Yeah, there have been some announcements.  There's a lot of announcements.  I don't know, you know...



STEVE:  Nothing really stunning stands out.



LEO:  Not yet.  But it's hard to sift.  It's like all Temperfect mugs.  It's hard to sift the stuff that's actually going to appear in the marketplace from the stuff that seems like a good idea.



STEVE:  Ah.  Right, right.  And that's a good point.  The nature of CES is that many times the manufacturers are showing prototypes to gauge reaction and to see if it - and also just to say, look what we were able to do.  Yes, we're able to do a 16K display.  We don't add any wires, and we can't get the image to it fast enough; but, still, look at that screen.



LEO:  Well, you heard, who was it, Sony that has the really, like, a TV, a big-screen TV thinner than an iPhone.



STEVE:  Ooh.



LEO:  But, you know, I don't mind if my TV is an inch thick.  I really - it doesn't really affect me.



STEVE:  No, true.  So okay.  So I did get a nice note, a holiday note from a Tim Green in Germany.  The subject was "SpinRite fixes PS3s, too."  And he said:  "Just for a change, SpinRite also fixes PlayStations.  We have a relatively old PS3 that we use mainly as a DVD and Blu-ray player and media center.  It started acting up recently, hanging on boot-up and exhibiting other strange stutters and pauses at unexpected times.  So I took out the hard drive, connected it to a PC, and let SpinRite at it on Level 2.  Just over an hour later, I put the drive back in the PS3 and booted up for a complete transformation.  Not only has it stopped hanging on startup, but it now also feels generally snappier and smoother.



"Thanks once again for the only really useful hard disk maintenance and recovery utility I have ever encountered, and also for all your insight, information, and wisdom in the show every week, which I have listened to as unfailingly as you have produced it ever since Episode 1.  All the best to you, Leo, and all of both of your loved ones for a happy and joyful Christmas break.  Thanks again.  Tim Green."



LEO:  All of both of our loved ones.



STEVE:  Thanks very much.  All of our loved ones.



LEO:  I understand what he's talking about.



STEVE:  We're all covered.



LEO:  All of both of them.



STEVE:  Yeah.



LEO:  All of many.  Dr. Mom sent me an email with a certificate from her hospital.  I should show you this.  It's kind of funny.  She was visiting GRC.com, and the hospital replaced your certificate with one of those man-in-the-middle things.



STEVE:  Oh.



LEO:  But a lot of businesses do.  This is not kind of what Gogo did, really.  But, you see, she's on ShieldsUP!.  It says GRC.com, but it also says North Shore-LIJ Health System, Roxbury, New York.  That's common, though.



STEVE:  Yup.



LEO:  Lot of businesses do that.



STEVE:  Well, yes.  And once what would normally happen is you would embed the proxy server's certificate in your browser, and then you would no longer get those messages.  The message only happens...



LEO:  The warning, right.



STEVE:  Right.  The idea being that it says, hey, the cert is signed by somebody we don't know.



LEO:  Right.  Says you're on GRC.com, but they didn't sign it.



STEVE:  Right.



LEO:  What Gogo's doing is different because they say Google signed it.  Right?



STEVE:  Yes, correct.



LEO:  That's a bridge too far.  Or something.



STEVE:  Yes.



LEO:  Is that you?  You have an alarm going off?



STEVE:  Yeah, I don't know what's going on.  Someone is doing a dance out in front of the house.



LEO:  Okay.



STEVE:  They've gone away.



LEO:  Question time.  Number one from James Allen.  He's looking for clarification on the SQRL cross-site tracking and adoption.  Steve, thanks for your efforts on the Security Now! podcast with Leo.  I'm new to security, and it has become a weekly staple of my life.  I love SQRL.  SQRL, I love you.  I just have one nagging question in the back of my head, and I wondered if you'd considered this and what your opinion is.  One of the features which is great for users is the per-site identification tokens, public keys, which are unique for each site a user visits.  This means that, unless the user volunteers to the website additional identifying information, an email address let's say, one site, as an example Audi.com, cannot match up the user's identity from another site, say Porsche.com.



This is great from a user's perspective as it gives us more control over what websites know about us.  But it seems to me it's not good for corporate groups like Volkswagen, who owns both Audi and Porsche, because they can no longer track users across their multiple services, or sneakily sell on your information to other companies - again, great for us, not so good for the people making money off of us.  This seems to me a potential reason for large and/or unscrupulous corporations not to implement SQRL.  Is this going to be a problem, to get some adoption?



STEVE:  Okay.  So of course the podcast before last was the Christmas holiday, and we played the presentation that I gave during the DigiCert Security Summit in Las Vegas.  And as a consequence, I got a lot of this, and I wanted to address the concern.  I think I overstated, without exaggerating anything, but I've confused people.  So the cool thing about SQRL is, well, one of the many, is that it does synthesize a per-user identity.  But that's all it does.  That is no different than a user synthesizing a per-site password.



So the tracking thing isn't something that SQRL prevents in any way.  And so that's what's got people confused.  Because SQRL generates a per-site identity, people think, they assume that that somehow prevents them from being tracked.  But the tracking happens, for example, at the cookie level, or the supercookie level, which is different from your identity.  So a bad identity system would be one that explicitly, where like for example you always had to have the same username and password for every site, well, then they can obviously track you by your username and password.  But people know better than that, so they often, if they want anonymity, they'll create different usernames and passwords per site.  SQRL just does that automatically.



So anyway, many people got confused by that, so I just wanted to take this opportunity to explain that it's identity that it creates uniquely.  But, for example, if you receive a cookie from Volkswagen, and then you go to the Audi site and they have an image or a tracking beacon over to the Volkswagen.com site, that cookie will follow you.  So all the tracking stuff isn't changed one way or the other.  It's just the identity which is unique per site.  And so it gives you sort of a head start, I guess, on the tracking problem.  But by no means did I want to oversell that or confuse people.



LEO:  Well, and you make an excellent point, which I hadn't really thought about.  But if I use my email as my login, which many sites encourage you to...



STEVE:  Yes.  Yes.



LEO:  I'm not going to make up a new email address for every site.  I use the same email all the time.  So that means they know who I am.



STEVE:  Right, same you.  Yes, exactly.



LEO:  If you log in.



STEVE:  Right.



LEO:  But obviously there's no point for SQRL if you don't.  Right?  I mean, that's the whole point is authentication, yeah.



STEVE:  Right.  And at least SQRL doesn't give away your identity.  At every site you visit, you just get a unique random gibberish blob, and they go, oh, okay.  Well, you going to tell us anything more about you?  And then [crosstalk].



STEVE:  Exactly.  Oh, he's back.



LEO:  It's Blob again.  Right, they don't know my email address.  And that's, to me, right there, a huge improvement.



STEVE:  Yup.



LEO:  I forgot that just by giving them the same - I always use the same email address.  Even if you didn't, maybe - but you're not going to make up a new address for every site.  That'd be...



STEVE:  It would be really burdensome, yup.



LEO:  Pat Cho, Sacramento, wonders whether it's safe to log into POODLE TLS vulnerable sites.  Steve, Fidelity is still vulnerable - ah, this is interesting to me, I use Fidelity - to the POODLE attack, according to SSL Labs.  How much risk is there for someone to log into their servers while they're vulnerable?  It doesn't seem like getting it fixed is a very high priority for Fidelity, even though they assure me they take security very securely.  Pat.  Or seriously.  Or something.



STEVE:  Yeah.  So, okay.  A server is vulnerable to POODLE if it still supports SSL v3.0.  TLS 1.0 and above isn't a problem.  And so POODLE came back in the news, our listeners will remember, because it is possible to downgrade the browser's intent to support TLS back to SSL.  And if the server also supports it, then they negotiate an SSL 3.0 connection, which then can be theoretically attacked.  So what everyone now should do is simply disable SSL 3.0.  It is that simple.



So to answer Pat's question, it's always been the case that the POODLE attack is more theoretical than real.  I mean, on a spectrum of things, we're preempting something that could be done.  But remember, to be done, you have to get malicious script from a site on your browser, and then it has to generate thousands of queries which a man in the middle alters, because the browser is unable to do it, in order to probe error messages coming back from the server about the handshake being broken.  And after thousands of queries, you are able to determine one byte from the headers that might be from a cookie that might contain information you care about, that might create a problem.



So the answer is, is this really a problem?  It's hard to imagine that it is.  But the fact that Fidelity Investments, who say they care about security, don't care enough to turn off SSLv3 when that's all it takes, that's the bigger cause for concern than that you could actually get bitten by POODLE.



LEO:  Well, they may have a lot of little old ladies using it with Windows 95 or something; right?



STEVE:  But even, well, good question.  I don't know how far back 3.0 goes.



LEO:  They know.  They know what their customers are using.  And they'd probably say, you know what, if we turn it off - it's a minimal threat.  And if we turn it off, we're going to have a big compatibility issue.  I would guess.



STEVE:  And it is true, it's why I didn't bother with it until I finally rebooted my server.  It's like, yeah, okay.  I mean, no one's ever seen an exploit in the wild.  No one's ever exploiting it.  And as I've always said, the bar is very high for actually getting bitten by POODLE.



LEO:  But once you get bitten by a POODLE, you'll never want to get bitten by a POODLE again.



STEVE:  Yeah, that's true.  Especially if it's not one of those little mini POODLEs.  If it's the full-size, a maxi POODLE, that'll bite you.



LEO:  Owie, yeah.  Steve Nagy, an "Average Joe in Tampa, Florida," self-described, muses about Sony's Security.  Hey, Steve and Leo.  Love the show.  Been listening now for about a year.  Got to tell you, the more I hear, the more I wonder if anyone is ever really secure.  My question is, what if Sony, or anyone else for that matter, had used some sort of dongle or YubiKey for critical security logins?  Would this have at least hindered system-wide exploitation?  Thanks again for a great show.  Steve.



You know who famously does this is Bloomberg.  They put terminals, Bloomberg terminals, in all sorts of places.  And the terminals are very expensive.  Investment folks, stockbrokers and stuff buy them.  And they have a key, a card key with a temporary code.  It's a cycling, one of those VeriSign-style cycling card keys that is a swipe and a code that is required to use it.  And nobody to my knowledge has ever broken into Bloomberg's terminals.  That's a valuable asset.



STEVE:  So I liked this question because the whole issue of remediation, not only recovery but lessons learnable, to the degree that this is - like the topic of the podcast a few weeks ago was expensive lessons.  So we'd like to learn something from this, rather than just, oh, my god.  And I, of course, famously said, I don't think I could secure Sony Entertainment.  Not while their network is as functional as they need it to be.  But people keep asking, what could you do, then?  I mean, what could be done?



And the thing I think, I think the takeaway lesson from the experience is that there are varying levels of integrity.  That is, many security models have this notion of, we'll call it "rings" because, for example, even the Intel chip has multiple rings.  We talk about Ring 0 and Ring 3.  There's actually a Ring 1 and Ring 2, but no one ever bothers with them because it turns out having the kernel and having not the kernel is really all we needed, but the architecture's got four levels with gradiated permission.



But that's sort of the idea, where you'd have all of your administrative assistants and your outside people and probably your VPNs and all that stuff would sort of have access at the outer ring.  And things like financial plans and the stuff that was really painful for Sony to lose, presumably you have a smaller cadre of C-level and related executives upon whom you actually could impose stricter requirements for authentication where, yes, in return for their access to the crown jewels, they're going to jump through some hoops.  And they can be expected to have a greater burden of inconvenience in return for needing to secure the more important data.  We don't have any evidence that there was any sort of hierarchical security.  But that's the architecture that can be imposed that is still practical.



Unfortunately, email is still going to probably be embarrassing, that's probably going to be out largely in the public.  But you could also have protected email servers for the inner sanctum executives that are kept in a more highly contained environment.  So I think that the security model that needs to be imposed is not one that is flat.  The evidence is Sony was operating in a flat model.  And you really can't do that.  I think moving forward, if Sony's going to restructure themselves, they need to do it in a hierarchical model where people who have more privileges have a greater burden of honoring the security of that privilege.  And that's a mode that could be implemented that would not be unduly burdensome to the organization overall.  And I think that's pretty much what you have to do to secure something of that size.



LEO:  Well, and maybe not use email.  I think a lot of organizations have moved to solutions other than email for internal communication.  Secure messaging can be completely secure; right?



STEVE:  Ah, right.  So there just isn't that persistent record of stuff that you really don't need to keep a record of.



LEO:  Right, and you may not want to for a variety of...



STEVE:  Yeah, exactly.



LEO:  But then there may also be, and I don't know what the mandate is on this, but I do know that you can't destroy email in a business.  You need to keep it for a number of years so there's a paper trail for legal reasons.  So there may be legal ramifications that also make this difficult to do.  I don't know.



STEVE:  Is it the case that you cannot destroy it?  Or if you have it, you cannot destroy it?



LEO:  Well, presumably you have it.



STEVE:  I don't keep mine.



LEO:  What was the rule?  Maybe somebody in the chatroom knows.  But I feel like you're supposed to - it's Sarbanes-Oxley, so it's not everybody.  You're not a publicly owned company.



STEVE:  Okay.  Okay.



LEO:  But Sarbanes-Oxley requires a certain amount of email need to be preserved for a certain length of time.



STEVE:  Okay, that makes sense.



LEO:  Yeah.  Sarbanes-Oxley was the rules, the law that was passed after, was it Worldcom?  No.  Some famous failure of a company lots of people lost money in because the company was basically hoaxing, messing around with its books.



STEVE:  And so then the idea would be...



LEO:  Enron, Enron, thank you.



STEVE:  Ah, okay, that makes sense.



LEO:  That's the Enron scandal.



STEVE:  So the idea would then be that a company that...



LEO:  It has to be publicly owned.



STEVE:  ...is publicly held, then is able to affirmatively respond to a subpoena to produce the email.  So if they're sued, they're going to have to say, okay, here's our stuff.



LEO:  You have to preserve it.  You can't throw it out.  Yeah.  And I don't know if Sony Pictures Entertainment was publicly held.  I'm pretty sure it is.  So I don't know.  I don't know.  Don't ask me, I'm no attorney.  Rafael Beraldo in Brazil  wonders about GRC's Windows Servers.  Hey, Steve, Rafael says, why not Linux?  Longtime listener here.  As a Linux guy, and knowing you like the BSD family, I've always wondered, why you use Microsoft's IIS to run the GRC website?  Why not run it on one of Unix's spiritual successors?  I decided to send this question after Episode 486, when you mentioned that Windows has a very small string size for supported TLS ciphers.  I'm curious to hear your thoughts.  Thanks.



STEVE:  You know, people ask.  And more than anything, it's just sort of an accident of history.  I'm a Windows developer.  I've been writing Windows client-side stuff, well, for 25 years.  That's SpinRite, and even before that, FlickerFree was my previous software, have always been on Windows.  And then I had my ChromaZone screensaver that I wrote.  Anyway, so when Microsoft was offering a server and used sort of the same OS that I was already a programmer of, I just sort of went with it.  I think if I had it all to do again, it would absolutely make sense to have used a fully open solution.



The good news is that IIS allows deep hooking, that is, the web server allows me to insert my own code in front of it and behind it.  So there's like a little core now of IIS that runs, and then the so-called GRC Net Engine is what I call it, it just sort of, like, stomps on top of it.  And so all the extra stuff that GRC does is my own code running where IIS just sort of does the low-level grunt work of serving simple queries.  But things like the DNS Spoofability Test, the Perfect Passwords, all of the server-side stuff I am writing in Windows.  So even now it's convenient for me because, as I said, I'm a developer that knows the Windows API pretty much inside and out.  So it's been practical.



But I do wish that I was on open source platform.  And again, I'm not going to go rewrite everything now for it.  But if I had to do it again, yeah, I probably would have chosen FreeBSD.  That's my platform of choice when I'm not on Windows.  And I do have a FreeBSD server running.  My DNS server at GRC is on FreeBSD.  I'm running a true NNTP server on FreeBSD Unix.  So I've got one, but I just don't do that much with it.



LEO:  Infosec Institute says IRS requires seven years, payment card one year, California Franchise Tax Board four years.  This is email retention.  DISA Security Technical Implementation Guides state one year.  Many state revenue departments three years.  HIPAA, six years.  So you may have regulations that require that you preserve email.



STEVE:  Right.



LEO:  Don't listen to these guidelines.  Ask an attorney.  Damien in Nashville has been told TrueCrypt has a backdoor:  Steve, thanks for all you do.  I'm writing today about something a security consultant told me today.  When I mentioned I use TrueCrypt volumes to secure some more sensitive items on my computer, his response is, "Oh, we're going to have to get you off TrueCrypt."  When probed about why, he said, "It was deemed insecure long ago and has been found to have a major backdoor.  I can't tell you the details; I'm under NDA.  But if you do enough googling, there have been papers presented on how to break TrueCrypt."  What?



I will admit, I haven't dug into this for more than the past few hours.  I also haven't been keeping up with the show the last couple months, so I apologize if you've already covered this.  But is TrueCrypt truly broken?  No, but I think your security consultant might be.  Is there any hard evidence that something isn't right with it?  I don't see any change in your TrueCrypt archive pages, so I'm thinking your stance is still the same as it was this summer.  Can you reassure me - or put me in my place?  Thanks for everything you do.  Your work is truly appreciated by the community.



STEVE:  So Damien, you're not being put in your place.  You're being reassured.  However, you can, as Leo suggested, put your security consultant in his place.



LEO:  I'm a security consultant.  I'm sorry, Steve, I know this stuff.



STEVE:  We've seen these clowns who sort of adopt a know-it-all attitude.



LEO:  Oh, yeah.  No, you must have seen that, yeah.



STEVE:  Yeah.  And the first thing to worry yourself is anyone who purports to be a know-it-all because none of us know it all.  One of my favorite things is to say "I don't know.  I can go find out, but I don't know."  But, yeah, there's no papers that we are aware of, or the industry is aware of, or anyone is aware of, that this guy is suggesting talks about a TrueCrypt backdoor.  We don't know that there is one.  But the only thing that is bad about TrueCrypt, arguably, is that it is now unsupported.  So it is unsupported, as far as we know flawless, software.



If you prefer to use supported stuff, well, there are forks of TrueCrypt source which people are developing, and there are entirely non-TrueCrypt things like BitLocker, and the Mac's got whole drive encryption now and so forth.  But if I were to choose something, I would choose - and if it were to work.  The other problem is that TrueCrypt will start getting long in the tooth when the platforms we start moving to are no longer TrueCrypt compatible.  So that will become a problem over time.  But today, I like TrueCrypt better than solutions from the manufacturers because, frankly, I don't trust the manufacturers; and I do trust the spirit and the intent of the guys who wrote TrueCrypt.



LEO:  Well, and there's good reason not to trust the manufacturers.  They do business in the United States, and they may have been compelled by the U.S. government to provide a backdoor.  And we would not know about it, and they would not be able to say no.



STEVE:  Nope.



LEO:  Whereas TrueCrypt, which was run by, as far as we could tell, a couple of guys from - where were they from?  Lichtenstein or somewhere?



STEVE:  Yeah.



LEO:  Yeah.  They probably were not.  And the code is published, even though it's not open source.



STEVE:  Yeah, exactly.  The code is all there for anyone to criticize.  And the initial pass of the audit found nothing, although that wasn't a deep audit of the crypto.  And that apparently is still underway.



LEO:  I look forward to that.



STEVE:  Yeah.



LEO:  That's actually probably what this security expert was thinking of.  He'd heard dimly in the back of his mind, TrueCrypt hasn't been audited or is in the process of being audited, and he just kind of translated that into "is unreliable."



STEVE:  You're giving him too much credit, Leo.



LEO:  I am, maybe.  No, no definitely, I'm under NDA [crosstalk].



STEVE:  I know that you've read through security forums where everybody knows everything, and it's like, oh, goodness.



LEO:  I have a friend who used to work with a friend who had a guy who his uncle I think was at the NSA.



STEVE:  That's right.  And he told you that Windows is totally backdoored.  That's right.



LEO:  They can see everything you do, all the time.



STEVE:  That's right.  Just give up now.  But I'm a security consultant, so pay my bills.



LEO:  Mark Goldstein in "North Virginia," and we know what that means, notes that HTTPS can be faster than HTTP.  What?  Test the thesis at this website:  httpvshttps.com.  It compares the load time of an unsecure HTTP and encrypted HTTPS versions of a webpage.  Each test loads 360 unique, non-cached images for a 2.04MB total.  And I guess, he doesn't say what the result is, that the HTTPS is faster.  How could that be, Steve?  Isn't there a lot of work being done?



STEVE:  Because - there is.  And this is a neat site, so I wanted to put it on everybody's radar.  You should try it, Leo.  Everybody should try it:  httpvshttps.com.  And thank you, Mark, for pointing us to it.  I wasn't aware of it.  The secret - oh, here it comes.



LEO:  It looks cool.



STEVE:  Yes, they did a nice job.



LEO:  Done.  Please try HTTPS.  So that was 5.837 seconds.  Now, this could be completely fake.



STEVE:  Nope, it's not.  So now change it.



LEO:  Whoa.  Eighty percent faster with HTTPS.  What?



STEVE:  Because of SPDY, Leo.



LEO:  Ah.



STEVE:  So we talked about SPDY in the past.  This is a very nice, legitimate comparison between not negotiating an SSL HTTPS connection and negotiating it, but using the SPDY protocol.  What Google did, just to refresh our listeners, is they carefully looked at just all the extra cruft that is in the original HTTP spec.  And remember that HTTPS is only a security tunnel through which HTTP runs.  SPDY is essentially just an optimized and accelerated and carefully redesigned HTTP which is the protocol for HTTP/2.0.  Right now we're at 1.1.  The HTTP/2.0 spec incorporates these improvements.



So what's interesting is that here we see that the boost that we get from taking the very creaky original HTTP protocol and updating it by really optimizing it, that boost is substantially greater than the cost of negotiating even that many connections.  Now, the test is a little bit - it tends to exaggerate the difference, specifically because the images are tiny, which means the handshake overhead is maximized.  So for, like, much larger objects that you are downloading, the query overhead, which is what SPDY speeds, the query overhead would be a much lower percentage of the overall than this page shows.  But this is, I think, a very useful test.  And so, again, I think everyone ought to give it a shot.  It's fun.  And IE, by the way, doesn't work at all because it doesn't support SPDY.  So you have to have Firefox or Chrome or - are you using Safari?



LEO:  That was Chrome.



STEVE:  Oh, okay, cool.  I don't think Safari is a SPDY client, either.



LEO:  Oh, that's interesting.  All right.  And they do suggest you run it in an incognito window over and over again.  You do get different results each time.  So that's kind of...



STEVE:  Yeah, you're going to. Well, because, I mean, it is how fast can it get all these little images.  So little glips and blitches and glurps and things in the Internet...



LEO:  Gliptches and mitches.



STEVE:  Those things.



LEO:  To continue on, more questions for Steverino.  Hey ho, Steverino.  Let's see here.  This is Question No. 7; right?



STEVE:  Seven.



LEO:  Yup.  All right.  It comes from Kevin Garman in Illinois, and his chosen domain.  Seems they had a slight problem:  Hi, guys.  Thanks for a great podcast and hard drive tool.  He's talking about SpinRite.  A heads-up to fellow listeners and a question:  I was recently excited to add SSL support to my own personal OwnCloud server.  OwnCloud is software that lets you do kind of your own cloud.  So I was going through StartSSL's process to get a free cert when they sent me an email saying I'm not eligible for a free cert because banks and financial institutions are not allowed to use their free service.  How does this apply to me?  They said it's because my domain has the word "money" in it.  Wow.  Some check.  Hey, says "money," must be a bank.  To their credit, they were prompt at replying with an explanation, but I guess - they didn't change it.  I guess I'm back to self-signed certs.  Unless I can find another source of free SSL certs, I guess I'll have to wait for Let's Encrypt.  Thanks again, Kevin.  That's too bad.



STEVE:  Wasn't that weird?  I just - that just sort of popped on.  Kevin explained it, and it's like his domain is like mymoney.net or something, or something .money.net.  And they just see that in the domain name, and that's what they key on.  It's like, whoa, what?  I mean, Bank of America doesn't have the word "money" in it.  I guess it has the word "bank" in it.



LEO:  I bet they look at "bank."  I bet they would look for other words, too.



STEVE:  Yeah, wow.



LEO:  It's funny they can't reverse that.



STEVE:  Yeah.  And so for anyone who's going to get a domain for themselves, if you want free certs...



LEO:  Don't put "money."







STEVE:  ...from StartSSL, avoid anything that sounds like a financial institution, and maybe you can get one.  Wow.



LEO:  That's interesting.



STEVE:  Isn't that, yeah.



LEO:  And they didn't overturn it.  I think they really don't want to...



STEVE:  Yeah, they just said no.



LEO:  They don't want to be held liable for people losing money because of a cert.



STEVE:  Right.



LEO:  So they're just staying away from it.  Jeff in Baton Rouge, Louisiana shares some great AppLocker experience:  I'm the IT Director for a major university athletic program, a Security Now! listener since 2012 - Yay, Jeff! - and was excited to hear you discussing AppLocker for malware protection in the podcast.  We have been using it for years with great success and are trying to spread the word about how effective it can be in an enterprise environment.  Pre-AppLocker, we were cleaning up three to five malware infections per week - per week.  He didn't say how many, oh, yeah, he does say later how many seats, 400-plus seats.  That's a lot of malware infections for 400 people - despite running a popular, up-to-date, enterprise AV program and having users operate with limited accounts.  Wow.  He has determined users.  Whitelisting executables via AppLocker has resulted in us not having a single malware infection across 400-plus Windows machines in more than four years.



The prospect of whitelisting every executable a user could legitimately need to access sounds daunting, but actually it's pretty simple, at least in a corporate environment.  Rules for digitally signed executables are the easiest because you can trust all executables by a given publisher with a single rule.  Want to allow everything that Google, Adobe, Citrix or Cisco offers?  Okay, maybe not Adobe.  Just create a publisher rule allowing anything signed by those guys, and you're done.  Path rules are easy, too; but use them sparingly, and only on locations when users don't have write NTFS permissions.  For example, allow c:\Windows and c:\Program Files, et cetera, but not c:\Users\Username) for executables.  I have a set of 14 rules which allow 99 - I want to get these rules.



STEVE:  I know.



LEO:  - 99% plus of the legitimate applications that our users need to run.  I rarely have to revisit these rules or make exceptions.  But when I do, it takes significantly less time than what I used to spend cleaning up malware.  The users rarely even know that these rules exist, and it has blocked the execution of hundreds, thousands of executable malware droppers from infiltrating our Windows machines over the years.  This is great.  And he does provide a link.



STEVE:  Yup.



LEO:  Here's my write-up on our specific implementation.  It's at community.spiceworks.com.  You could probably google "free almost perfect malware protection with GPO AppLocker" or something of the sort.



STEVE:  And the link is in the show notes, and the show notes are linked to the podcast now.  So people can find them under Question No. 8.



[http://community.spiceworks.com/how_to/show/59664-free-almost- perfect-malware-protection-with-gpo-app-locker]



LEO:  Good, good.  All that said, AppLocker is really not suitable in its current form for users in a home or small business that doesn't have Active Directory implemented and requires an Enterprise license for the Windows machines in question.  The only way I'm aware of manipulating rules is via Group Policy Objects.  If MS was to implement some sort of more user-friendly GUI for home users and small business users, it could be a useful tool; but I'm not aware of any such option at the moment.  What a great email.  And I'm going to send this link right now to Russell.



STEVE:  Yeah.  Yeah.  So I loved this.  We were talking recently - and this is what prompted Jeff, of course - we were talking about the notion in the context of Sony and how you lock down a big enterprise, the idea that maybe the only solution is going to be doing the same thing we've ended up doing with firewalls, where we've flipped the sense of a firewall from blocking the bad stuff to permitting the good stuff, and doing the same thing with applications, where we default disallow the OS to run something unless the app has been specifically whitelisted, and it's built into Windows as AppLocker.



So I really appreciated Jeff sharing his experience.  And I did want to also plant a bug in our listeners' ears, if they are aware of something, or something becomes aware that Jeff is referring to that allows for non-active directory class tweaking of AppLocker rules, then make sure that I find out about it so I can tell everyone because, as I said when I switched to Windows 7, I hope to, I plan to adapt a whitelisting approach from the beginning, and we'll see how it goes.  So, Jeff, thanks so much for sharing that, and also for providing the link to your specific implementation.



LEO:  Yeah, I just sent that along to Russell.



STEVE:  Neat.



LEO:  Because I think that's how this conversation got started.  We were talking about Sony, but about this AppLocker feature of Windows.  I think it comes with Windows Ultimate as well as Enterprise.



STEVE:  I do, too, yes.  So I think if you get - I remember looking it up and seeing, okay.



LEO:  Not Pro, but Ultimate.



STEVE:  It is available, yeah.



LEO:  And the idea of whitelisting is great.  Of course, Russell was a little concerned, I mean, we have a perfect use for it, which is our editors' machines.  There is a very limited set of applications they could or should be using on those machines.



STEVE:  Right.  Right.



LEO:  Basically Adobe Creative Cloud, and that's it.  And so locking those machines down is just prudent.  He's worried, though, and I've read people's stories saying, oh, yeah, but you turn on AppLocker, then caching doesn't work in your browser or whatever.  I mean, I'm just making up stuff.  But it's like address randomization.  It breaks things in an unexpected way because Windows is really not designed to be doing it this way.



STEVE:  Well, or it's a little bit like when we were talking about it before, it's like NoScript.  If you've got it turned on to, like, alert you...



LEO:  It's annoying.



STEVE:  You're always saying, yes, yes, yes, yes, yes, you know.



LEO:  But this is good.  If he's got it working so well, clever, you know, giving it the domain or the certificate blanket authorization, things like that.



STEVE:  Yeah.  Well, and so, for example, you could probably whitelist Adobe.com.



LEO:  Right.  We'd be done.



STEVE:  So signed executables, that are signed by Adobe, and bang.  And so when something new is added, it's automatically permitted if it's also from Adobe.



LEO:  Right.



STEVE:  So, yeah.



LEO:  And really that just blocks the malware because the malware is not signed from Adobe.



STEVE:  Exactly.



LEO:  Yeah.  I think, yeah, this is good.  Whitelisting is a great solution.  If you can do it, it's a great way to get rid of spam.  It's a great way to get rid of a lot of things.  Pete Shaw in Warner Robins, somewhere[Georgia, USA], sounds like...



STEVE:  I didn't even know.  He said "Warner Robins," and I thought, well, that sounds like Christopher Robin, but maybe it's his brother.



LEO:  Probably Australia.  That just feels Australian.  I don't know what it is.  He wondered - could be Arkansas, I don't know - wondered about Security Now! episodes:  Steve, a big fan.  Lately I've noticed episodes are not available even after a couple of days.  What gives?



STEVE:  Okay.  So I got a bunch of people.  It was totally my screw-up.  He sent this on the 18th, referring to the episode, presumably on the 16th, which I never posted.  Elaine sent me a note when I was up with you, Leo, saying, hey, you know, just thought I'd mention that that never showed up.  Then I thought that I hadn't updated the Security Now! main page, but all the little resources were there.  No, I never even did them.  So I'm embarrassed to say that, in the 10th year of the podcast, I'm still doing this manually, which sort of put me in mind of the cobbler's kids who run around barefoot, even though his customers all have shoes.  I could have so easily, at any time, automated this process.  But every week it's just like, well, okay, I've got other things to do, I'm just going to post this manually.  And so I get the dates screwed up, I get the numbers screwed up.  You know, it's like I'm human.



So anyway, I did go - we did go through, like, several weeks, mostly because I forgot, then I was out of town.  Everything's caught up.  Everything is synchronized.  Everything is correct now.  So anyway, that's what's happening, Peter, is it's just me.  So when someone notices that something's missing, just send me a tweet.  I'll probably see it, and I'll fix it.  So apologies.  But that's what happened.



LEO:  A little self-serving, but you could also come to TWiT.tv/sn, where we also post all the audio and video.



STEVE:  Yes, go look - yeah, exactly.



LEO:  You don't have to get it from Steve.  We put it up, too.



STEVE:  Right.



LEO:  Although sometimes, from time to time, things do take a while to get out or whatever, and we get the same kind of tweets.  What's great is people don't want to miss an episode, and they want it when it's available.  They want it right away.



STEVE:  Yup, yup.



LEO:  So Warner Robins, thanks to the chat room, is an Air Force base in Georgia.



STEVE:  Ah, nice.



LEO:  There you go.  Robins AFB.  So he obviously works in the Air Force.  Pete Shaw - I'm sorry, that was Pete Shaw.  This is Druce MacFarlane in Santa Cruz, California.  Not Bruce.



STEVE:  Our final question.



LEO:  Druce.  I used to work with a Bruce MacFarlane.  Wonder if he's related.



STEVE:  Well, those MacFarlane brothers, you know, their parents thought they'd have some fun with their first names.



LEO:  And their sister Spruce.  He has some perspective from the trenches:  Steve and Leo, first of all I'd like to thank you both.  I'm a longtime listener to Security Now!, and the things I have learned listening to this podcast have helped me advance my professional career.  I'm just glad you guys aren't on commission.  I was listening to your "Expensive Lessons" episode, where you expressed concern that Target and maybe even Sony had been alerted to the attacks while they occurred, and did not take action on these alerts.  In other news reports, but not on this podcast, I've heard this characterized as "gross negligence."



STEVE:  Well, and of course they're being sued, as we know.  Target is - that suit is being allowed to proceed.



LEO:  Right.  The FireEye products they use monitor all incoming network traffic and look for objects that may contain malware or Advanced Persistent Threats (APTs). In a company the size of Target, it would be expected to see 20,000 alerts a month correlating to truly malicious objects being downloaded to end-user desktops.  Whoa.  99.9% of all of these downloads will end up being harmless if the endpoint has an updated virus scanner or even a well-maintained and patched operating system.  As it is, in practice, impossible to follow up on each and every one of these alerts, many companies simply ignore downloads and wait until the endpoint starts exhibiting behavior that indicates it's infected.  Yeah.  I suggest we wait and see if it swells up.



STEVE:  [Laughs]



LEO:  Commonly, the PC starts sending command-and-control messages, and this is the point where organizations tend to take actions.  Yeah, they go to their botnet.  In fact, this is often the recommendation of the FireEye systems engineers themselves.  While it's true FireEye may have provided early warning to Target or even Sony, suggesting that Target and Sony exhibited negligence in ignoring the FireEye alert is like claiming the townspeople were guilty of negligence after the little boy warned them about the wolf.



I'm going to mention that the stories I saw say that there had not merely been a download of malware, but in fact an active incursion into their systems; that they had a hacker inside the network, and they decided, eh, whatever.  So I guess the question is what did they know, and when did they know it?



Security professionals currently suffer from a deluge - I can only imagine, though, this is good information - of what we are in the industry starting to call "trivial true positives."  You used to call it "Internet background radiation."  These are alerts that, while true, provide little relevance and only serve to tap the limited resources an organization has to spread across their entire information technology infrastructure.



As we know, Sony had five people in their security department, and three of them were administrative, were managers.  So there were only two people in that whole company.



STEVE:  Yes, two techies.



LEO:  As with all stories like this, it's always tempting to look for the easy answer, but the problem is far more nuanced than can be easily answered in a quick sound bite.  That's why I applaud Steve for his statement that he would probably not have been able to prevent a Sony-like attack.  It helps bring perspective to the problem and recognizes the difficult job performed by all the security professionals that you count as listeners.  Thank you, Druce.



STEVE:  Yeah.



LEO:  Well, that's a very good point.  I mean, it's extremely challenging.  I hope we haven't in any way implied it's anything less than extremely difficult.



STEVE:  No.  But I did love, you know, we talk about false positives.  I love the term "trivial true positives."  So they're not false positives.  They actually are true.  These are true problems.  But they'll be knocked out before they can take root by AV or a well-maintained OS.  But still, 20,000 of them coming in, the problem is the really nasty ones can get hidden in the noise.



LEO:  I should also point out that, if you were using or could use AppLocker, you wouldn't have that many malware programs downloaded.



STEVE:  That's exactly right.  I really think that AppLocker or a whitelisting solution, that's where we're going to have to go.  I mean, think about it.  Only allow things that you know are safe to run.  Then, I mean, it's a sea change.  And, yeah, it's not easy.  It's like turning off scripting unless you explicitly know you want it on.  So there is going to be a bit of a problem.  But especially in a corporate environment, where they're not supposed to be running their own stuff anyway.



LEO:  Well, that's the thing.  But then your users bitch and moan because, "But I want to run Picasa Web.  I have pictures to look at."  Or whatever.



STEVE:  Yeah.  During lunchtime.



LEO:  Right.  And you have to deal with management that says to you, no, don't worry about it.  Or we're going to cut your budget.  Or you have two active on-the-ground security professionals for a company of 10,000 people, something like that.  I think a lot of companies are going to take this more seriously.



STEVE:  Can you imagine these poor guys?  It's like, oh, my god, why do they even get up on Monday morning?



LEO:  But they have, like, three managers.  That's the worst thing.



STEVE:  Right.



LEO:  There's only two guys doing the actual work, and there's three other guys just sitting around yelling at them.



STEVE:  Yeah, exactly, saying, "Why did you let this happen?"



LEO:  Oh, god.



STEVE:  "My boss's boss's boss is all upset, so how did this happen?"



LEO:  Believe me, we have total, total sympathy for anybody who's on the front lines in this.  All I have to do is look at my web server and see how many attacks there are on SSH every day.  Hundreds, thousands, it's constant.  And to have even a tiny glimpse of what you must be dealing with.  But I do think that better policies would make your job easier; right?  Rather than saying, hey, we got some malwares downloaded 10,000 times this month, but I'm pretty sure the antivirus got it.



STEVE:  And so policies flow from the top down.  And as you said, I think this has been an expensive lesson, but it's one the whole industry can learn from.



LEO:  And by the way, I might mention that, if malware gets on your point-of-sale terminals, you probably should investigate that each and every time.



STEVE:  Yeah.



LEO:  Just a tip.  It's okay if it gets on the secretary's computer.  But the POS terminals, that's maybe a little more important.



STEVE:  Yeah.



LEO:  Steve Gibson, always fun to talk security with you.  I learn so much.  I love this show.  You make us all look like we know what we're doing.  So thank you.  Security Now! is every Tuesday at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC.  If you want to watch live, we'd love it if you do, but you don't have to because, and I want to reiterate, not only does Steve have a copy, but I have a copy.  Steve's got his 16Kb audio versions.  He's got the transcripts.  And that is the only place you can get those transcripts.



We have transcripts on many of our other shows, and I got an email from the guy who does those, the company that does them, saying, you know, "You always mention that Steve's transcripts are written by a human.  What are we, chopped liver?"  So all the transcripts for all the shows are written by humans.  I mean only to say that there is not, like, these aren't those machine-created transcriptions you might see on other podcast networks or websites.  You've seen the horrible transcriptions on YouTube.  It's not that.  These are good.  For Steve's show and all of our shows.



Go to GRC.com also, not only to get the 16Kb version and the transcripts, but go there also to get SpinRite, the world's finest hard drive maintenance and recovery utility, a fabulous, fabulous tool that everybody who has a hard drive should have.  He's got lots of free stuff.  You can go there to read about SQRL, Vitamin D, and everything in between.  You also can go there, I might add, to ask questions.  So these feedbacks that we do every other show, some are generated through Twitter - he's @SGgrc - and some are generated on the website.  None are generated through email.  So don't email him.  He doesn't even see it.  He doesn't know where it goes.  There's a black hole somewhere, it all falls in there.  If you have a question, go to GRC.com/feedback.  That's where you go.  Fill out the form, and that's a good way to get a question or a thought or a suggestion to Steve.  Or tweet him.  Honestly, he reads all those tweets.



STEVE:  And next week, how does the Enigma machine encrypt?



LEO:  Are you going to do - you've got to have some illustrations; right?



STEVE:  I do not need visuals.



LEO:  You can talk us through it.



STEVE:  I can talk us through Enigma.



LEO:  This was the amazing mechanical encryption machine that the Nazis used in World War II.  And it's a very famous story.  At Bletchley Park, that's where Alan Turing was, if you saw "The Imitation Game" you know the story, and he was able to, with some help, wasn't just him, crack the Enigma machine.  The Germans didn't know it, and it was thanks to that that we were able - we - the Brits were able to turn around a very vicious submarine warfare...



STEVE:  Actually, one of the things that the movie does a really good job of - and will you have seen it by this time next week?



LEO:  Yes.



STEVE:  Now that you have your fancy...



LEO:  My DVD?  It's not a Blu-ray.  Don't get excited.



STEVE:  All right, all right.



LEO:  It's just a DVD.



STEVE:  Anyway, one thing that they really did beautifully is understand that, having cracked it, they couldn't immediately act on the information because that would give away the fact that they had cracked it.  So many times they had to, like, really do the tough call of, like, letting people die.



LEO:  We know a ship is going to be attacked by a wolf pack in the North Atlantic, and we have to ignore it because, if we admitted it, they'd know we had Enigma.



STEVE:  And I did remember hearing the story, and I hope it wasn't apocryphal, that said, for example, that sometimes they would arrange to have a fishing boat, like, happen to be there, or a civilian plane would fly over, and the Germans would go, darn that plane, when in fact in order to create a coincidence that could then allow them as a means of having found out.  But anyway, I loved the movie.  So you and I will discuss what you think about the movie next week.



LEO:  I'm sure I'll like it.  I'm sure.



STEVE:  And that'll fit perfectly in with our description of how Enigma encrypts.



LEO:  I can't wait.  And remember, this is not digital.  This is cogs and wheels and a crank.



STEVE:  And light bulbs, light bulbs.



LEO:  Light bulbs.  I mean, it is cool.



STEVE:  Yeah.  The "W" lights up.  Ooh.  Write that down, Sherlock.



LEO:  Speaking of Sherlock, you liked Benedict Cumberbatch in the movie?  He was good, wasn't he.



STEVE:  He really was good.



LEO:  I think he's up for some awards, yeah.



STEVE:  I wouldn't be - no, it is a good movie, although he did really play up the whole prima donna thing that I found a little over the top.  But, you know...



LEO:  He didn't choose to act as if he had Asperger's, though; right?



STEVE:  No.  No, no, no.



LEO:  Because some people thought that Turing was on the spectrum, and I was worried that he might - see, this is what happens with, you know, a lot of these movies, math whizzes are looked at as, like, freaks.  Prima donna, hell, I'm a prima donna.  That's nothing.



STEVE:  I think you'll like it.



LEO:  I can't wait.  I have to watch it before Sunday.  That's the Golden Globes.



STEVE:  Good, do.



LEO:  I like to see all the movies before the awards.



STEVE:  And we'll talk about it on Tuesday.



LEO:  Good.  Thank you, Steve.



STEVE:  Along with how the machine works.



LEO:  I can't wait.  That's going to be fun.  Enigma next week.



STEVE:  Bye, Leo.



LEO:  Bye, Steve.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#490

DATE:		January 13, 2015

TITLE:		The Enigma Machine

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-490.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I first discuss a surprisingly busy week of security news; then, we take a careful walk through the history (it's not what you may think) and the detailed operation of "The Enigma Machine" which Germany used to encrypt their sensitive radio traffic during the Second World War.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll review all the big security news of the week; and, yes, there was quite a bit.  But we'll also talk about something we both loved, the movie "The Imitation Game."  We'll talk about the historical inaccuracies.  But then Steve's going to go a deep dive on how the German Enigma Machine actually worked.  It's kind of a fascinating story.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 490, recorded January 13th, 2015:  The Enigma.



It's time for Security Now!  It's a winter, a cold winter Tuesday.  But not where we are because we're in California.  Steve Gibson is here from GRC.com.  He's the guy in charge.  He's the author of SpinRite, the world's best hard drive maintenance and recovery utility.  Our security guru joins us each week to talk about security.  And this week, security from the '40s, 1940s.



STEVE GIBSON:  Yes.  Yes, we're going to - this is the Enigma Machine episode.  And, boy, the feedback I received after announcing that that's what we would do this week, last week, was really significant.  I think everyone...



LEO:  Good.  Very excited.  I'm excited.



STEVE:  ...is excited to learn how it works.  I was thinking...



LEO:  So I saw "The Imitation Game."  I said I would.



STEVE:  Oh, yeah, yeah, yeah.  Yup.



LEO:  I said I would watch it, and I loved it.  And Benedict Cumberbatch, it's going to be a tough Oscar field, but he'll get a nomination, I'm sure.  He deserves it.  He's great in this, really brings Alan Turing to life.  Now, I don't know how accurate it is; but, boy, it's got heart, it's got soul, it's a beautiful performance.  And I think, as far as I can tell, right, historically accurate.



STEVE:  A little less so than many people believe.



LEO:  Oh, okay.



STEVE:  For example, he didn't build the first Enigma decrypting machine.  The Polish cryptographers did that.  Anyway, we're going to talk about the history of Enigma before getting into the exact mechanism and mechanics of how it works.  So we will correct the historical record.  That doesn't take away at all from the fact that it is - just it's a great movie.



LEO:  Oh, yeah.



STEVE:  And I would say that it's loosely based on history.  But that doesn't diminish it as a movie at all.  I think it was just wonderful.  And I loved, for example, how sharp the MI6 guy was.  Wasn't he fun?



LEO:  Loved him.  Loved him.



STEVE:  He was perfect.  I just wanted him to be that good, and he was just that good.



LEO:  Yeah.  And I shared my concerns, and it was not from watching the movie, but from a review, I think a specific review I'd read that said, why do we always have to portray our mathematical geniuses as somehow weirdos?  And yes, Turing was a little odd.  As played by Cumberbatch, probably Asperger's, at least, right, a little bit on the spectrum.  Whether that's true or not, I don't think history reveals.



STEVE:  Although really the interesting criticism I saw was like, come on.  He doesn't understand what a joke is?  He doesn't understand he's being invited to lunch?  I mean, it was like over the top for, like, okay, how spaced out is this guy?



LEO:  And so that is the kind of criticism, is why is it that you can't be a normal person and brilliant at math because clearly there are - the vast majority of brilliant mathematicians are not weird.  They understand a joke.  And why does Hollywood kind of insist on portraying geeks in general as weirdos?  But setting that aside, what a great movie.  What a great movie, yeah.



STEVE:  Great movie.  Great movie.



LEO:  So we're going to talk Enigma.



STEVE:  We are.  We're going to - it's funny, for a while I was thinking maybe we would do two episodes.  One was how it encrypts, and the second one is how it was cracked.  But when I got deep into, and I'm talking about weeds, into how the "bombe," as they were called, these things that we saw in the movie with their spinning disks, I can explain briefly how it works.  But there is no way on a podcast to accurately convey the actual operation.  I will for the Enigma machine.  It's interesting how simple that is compared to what Turing had to design in order to decrypt it.  And that really was a work of engineering genius.



LEO:  Truly neat, yeah.



STEVE:  But we also had a bunch of news.  Oh, anyway, so my point is I'm not going to do a second episode on how the cracking machine works.



LEO:  Touch on the highlights.  Touch on the highlights.



STEVE:  We'll wrap this one up with sort of the concept of how it works.  And I think that's probably all we need anyway because how this thing, this mechanical device that was, like, clunky, was able to create a cipher this good is really an interesting story.  And again, as I realized when I brought myself up to speed, it's like, oh, I can do this in a podcast.  So we're about to see that happen.



But we also had a whole bunch of news.  We want to follow up from last week on - we talked about CryptoWall and AppLocker and SPDY, which was faster, we found out, than HTTPS, sort of the next-generation protocol.  Some news about ISPs having to have their behavior regulated under Title II of the Communications Act.  SOHO Linux router is being taken over and turned into botnets.  Windows 7 support changes starting today.  Notepad++, which is a very, like a favorite editor for everybody over on Windows, site was hacked after the Paris attacks.  Google annoys Microsoft yet again by predisclosing details of an unpatched Windows vulnerability.  U.S. CENTCOM's Twitter and YouTube accounts were hacked.  And unfortunately we're going to wrap up the week's wrap-up news by talking about the unfortunate position that our British Prime Minister David Cameron has taken.



LEO:  Oh.  Oh.  Oh.



STEVE:  So, lots to talk about.



LEO:  You know, I saw the CENTCOM hack, and I thought, oh, crud, we're not going to get to Enigma.  But I think we can touch on all of this and still do Enigma.



STEVE:  Yeah.



LEO:  All right.  We'll save the commercial.  We're going to do a nice shaving commercial.  So we'll save that for you after the SpinRite, before we get to Enigma.



STEVE:  Perfect.  Okay, so on CryptoWall a friend of the show, Christian Alexandrov, he's our friend in, I hope it's Bulgaria, who has the dentist whose...



LEO:  Oh, yeah, yeah, yeah.



STEVE:  ...dental work he has paid for by fixing the guy's computers with SpinRite.



LEO:  Right.



STEVE:  Christian has sent a number of testimonials in as he's wandered through the streets, fixing, like, the restaurants.  He was with his girlfriend, and the restaurant computer wouldn't work, so he fixed that one.  And then his dentist's computer wouldn't work, and he fixed that one.  So basically he walks around with a copy of SpinRite and gets free stuff in return for fixing everybody's computers.  Anyway, he did some experimenting with CryptoWall, which we talked about last week as the successor to CryptoLocker.  And what he discovered I wanted to share with our listeners because it is potentially good news.  And that is a non-admin account can be recovered.



So in a series of four tweets, Christian wrote:  "If system protection and system restore run on all drives, including shadow copy services, on non-admin account there is hope."  That's the first tweet.  Second tweet was:  "Under non-admin account, CryptoWall cannot see, delete, or alter any shadow copies used by system restore and system protection."  Tweet No. 3:  "Remove malware, then login as admin, use the shadow explorer utility to restore previous versions, before infection."  And finally, "Access to read, modify, or delete shadow copies requires full disk access privilege, which non-admin accounts do not have, but admin does."  So thank you, Christian.



Essentially, the short of that is, if users are running as everyone knows they should be, rather than as an administrator, as a non-admin account, if you get hit by CryptoWall, you're able to restore yourself using the shadow copy system because CryptoWall will only have the privileges of the logged-in user when you get yourself infected.  And so if you disinfect yourself, even though your files are all still scrambled, you can then restore from backup shadow copies.  So good to know for anybody to whom that happens and who was properly running as a non-admin account.



We've also been talking a couple times now about the notion of whitelisting apps.  And it turned out, I got a tweet from Nathan Lamonski, who responded after we were talking about it last week, again through Twitter, saying you do not need MS Active Directory Group Policy.  For a workgroup machine you can use the local policy editor, explained - and then he gives a link - here:  HowToGeek.com.  And the HowToGeek link, I imagine if you just put it into Google, it'll find it:  "Block users from using certain applications with AppLocker."



So we know that that's not available on all versions of Windows, but it is on Ultimate and Enterprise.  So if you've got Ultimate, even if you're in a non-enterprise environment, you don't have to have all of the encumbrance, which is really daunting, of Active Directory and everything that comes with it.  You can use just your local policy editor.  So I imagine that's what I will be doing when I move myself to Windows 7.  Oh, and I replied with thanks, and he said back, "I work IT in K12 education and use AppLocker.  Love it.  It helps with the malware situation big time."  So when it's available, I think we're going to end up in a whitelisting land as we move forward.



And I did want to mention, to just sort of close this issue, that HowToGeek.com also notes that there is something called Windows Family Safety.  And that's available in all versions of Windows.  But it's really sort of - it has this weird, literally parent/child paradigm, where you're a child using the computer.  And when a note pops up, it says, "You have to ask your parent for permission to do this."  And so it's like, it's a little unfortunate.  But apparently it's their family-friendly interface to AppLocker.



LEO:  I guess better than master/slave.  It's not intended for kids, right, it's just that's how you think of it.



STEVE:  Well, it's part of their, what do they call it, the Windows Live Essentials package.  So you download...



LEO:  So it is for parents, then.  It is a parental control.



STEVE:  Right, right, right.  Yeah, it is in that mode.  It's built into 8, but it's installable under Windows 7.  So if you don't have Ultimate, then that's a solution, too, although you do have to put up with being told that you've got to ask Daddy if you want to do something.



LEO:  Papa Sysadmin.



STEVE:  So IE and SPDY, we talked last week about how Firefox and Chrome were currently SPDY-enabled.  And someone shot me a note, noting that Internet Explorer 11 was.  And I thought, huh?  I don't quite remember that.  But it turns out it's sort of conditionally so.  It offers support - IE11 doesn't offer it in the Windows 7 version, but it does under Windows 8.1 with some problems.  Apparently, if you use Google, you get Page Not Found errors.  But then, if you reload the page, it's happy.  So I found a posting saying one fix for this is to disable SPDY in Internet Options > Advanced.  So, like, eh, okay, they don't sound like they quite have it right.  And in any event, IE will be dropping support for SPDY because it'll be adopting the HTTP/2 standard, which we'll certainly be talking about at great length as that finally begins to happen.  It's continuing to march along.  It's in the standards bodies now.



And just to remind people, SPDY - and basically, SPDY got a lot of traction.  SPDY is a win, and we owe our thanks to Google for their experiments with that because it uses a binary protocol rather than the verbose textual protocol that HTTP uses.  It allows full multiplex communications over a single connection.  Right now, because HTTP is non-multiplexed, meaning that it is a query response, query response, query response, where you can't go query query query query query and then get things back as they come, essentially a single connection is blocked by waiting for the response, which is why many browsers now open multiple simultaneous parallel connections to the same server in order to have more going on.



The problem with that is, as we've talked about in the past, opening a TCP connection is a time-consuming process.  TCP doesn't know how fast your connection is, so it does a slow start, and then it sort of waits until you start having packet loss before it backs off and, like, figures out how much bandwidth you have.  So there are lots of reasons why - oh, and it also consumes lots of resources, both at your end and at the other end, before all these connections.  So it makes way more sense if you do that just once, and you're able to just send stuff, send all your requests off and simultaneously be receiving whatever of what you asked for the server wants.  But even more than that, the server can anticipate requests and send them ahead.  So that's another big win, in addition to compression.



So lots of stuff that Google pioneered, and all of that is in the HTTP/2 specification.  And by the way, they said they're not going to do like a 2.0 because then everyone, I guess, got confused by 1.0 and 1.1 that we've been living with now.  So they're just going to do HTTP/2 as the official name for the next one.  But again, we'll deal with that in more detail when it starts to happen.



Also, I got a kick out of the way this was characterized in the press in at least a couple places.  During CES, during a one-on-one discussion with the president of the Consumer Electronics Association, that's Gary Shapiro, he was chatting with FCC Chairman Tom Wheeler.  Tom implied that Title II, which we were discussing, I guess you were on your Sunday TWiT show.



LEO:  Oh, yeah, talked about it a lot.



STEVE:  You had Brett on.



LEO:  Yeah.



STEVE:  That Title II of the Communications Act will be the basis for the new Net Neutrality rules governing the broadband industry.  And of course Title II allows the FCC to regulate telecommunications providers as common carriers.  And apparently Obama has urged the Commission to use Title II to impose Net Neutrality rules, to ban blocking and throttling and paid prioritization and so forth.  So anyway, the way the press characterized this was that Verizon's great lawsuit backfired because of course they sued and won their suit, but it looks like they won the battle but are maybe losing the war.



LEO:  I wouldn't declare victory just yet.  I think we'll see a lot more back and forth.



STEVE:  Yeah.  But still, it's good that the - I'm happy to see that the government is taking a strong position from which then we can negotiate maybe from that position down, rather than just saying, okay, well, you guys do whatever you want to, and we'll trust you.



Brian Krebs reported that the Lizard Squad - we've talked about Lizard Squad in the last couple weeks.  They came to the fore over the Christmas holidays because they brought down both Xbox Live and the Sony PlayStation network over the holidays, like claiming that they did it to show that the security was weak on those networks, when in fact what they did was blast them with a ton of bandwidth, which is a fundamental sad fact of the Internet is that links have a limited amount of bandwidth.  There are unfortunately many computers on the Internet which are not secure, which can be taken over and have historically been taken over by botnets and used to all send traffic to a single point of focus, which ends up collapsing the hardware, I mean, the routers on the way in.  As the traffic aggregates from one router to the next, finally you get to a point where either the link can no longer carry that amount of traffic, or the router can't route that many packets per second.



What Brian Krebs reported, though, was really interesting.  It turns out that Lizard Squad's botnet is largely powered by our little blue box consumer routers.  We talked also recently about...



LEO:  Right, you warned of this, yup.



STEVE:  Yup, exactly.  There are known backdoors which have not been patched.  I mean, in some cases patches are available.  In other cases, the backdoor has been modified to make it much more difficult.  You have to knock on the door essentially locally, which precludes a remote Internet attack.  But routers are not perfect.  And their public, their WAN interface is out there.  And this is a little Linux machine running in these boxes.  It turns out that they have created a worm so that compromised routers scan the 'Net for other compromised routers and are able to take them over.  And the Christmas attacks were powered by consumer routers that are running their botnet in the background.



So I imagine that listeners to this podcast probably have replaced the default firmware with Tomato or one of the alternative better packages.  Or at least they're keeping themselves current with what the manufactures provided.  But we know that there are millions of these little routers that are sitting in a dusty closet, and they're doing their job, but they're also doing more than their job.



LEO:  Well, the other problem is that router manufacturers consider these commodity devices and often don't update.  Do we know what devices were suspect?  It was huge.  It was everything; right?  It was a huge list.



STEVE:  Exactly.  It was a huge list.  It was cross-manufacturer and just a vast array of routers.



LEO:  It was, what, reference code in the chipset that everybody implemented?  Or I'm trying to remember the detail.



STEVE:  Yeah.



LEO:  But you know.  I don't need to.  Anyway, is there a fix or a way to know if you're vulnerable?



STEVE:  There really isn't, as you're not going to see it on the LAN side.  If you suspect, I mean, it's like, if you had lights on your cable modem or your fiber interface separate from the router, and they're going like crazy, but you're not doing anything, that is, your router is doing something, that would be a tipoff.  Mostly just you want to not use default usernames and passwords.  Brian noted that as a major reason that these routers have been exploited is that people just never, you know, they left the manufacturers' well-known defaults that way so it was very easy for bad guys to get into them.  So you want to change username and password.  Turn off remote management features.  Almost no one needs them, but generally they're unfortunately all too often on, enabled by default.  And keep the router's firmware current.  If there is a firmware update, there's a reason.  So as you state, none of these router manufacturers are excited about updating firmware for commodity devices.  So if something has driven them to do so, there's a reason.  So you want that firmware update.



Simon Zerafa, another friend of our show, sent me - he tweeted, and I was able to capture the screen of Notepad-plus-plus.org while it was defaced.  The only thing that was really interesting about this was that, for some reason, well, I guess to show solidarity, the Notepad++ guys did a "Je suis Charlie" version of Notepad++.  It's v6.7.4.  And you can get it from them.  And someone tweeted, Jon M, whose handle is @Liquidretro, he tweeted that he downloaded that version just coincidentally the night before, and it typed out a "Je suis Charlie" message the first time he ran it.  So anyway, as a consequence of - I guess people over on the other side were unimpressed by Notepad++'s 6.7.4 version.  And unfortunately their web server had a way in, so they suffered a defacement.  Which last I looked, I guess it is back up.  There was one point when they - it took them a while to notice it.  Then they had nothing up there except sort of a naked directory listing.  And then they got their site back up.  So, but apparently they're still offering that version for anyone who cares.



Today - in my notes I said tomorrow, but it's actually today, the 13th - Windows 7 support status changes.  Windows 7 is getting old.  Probably old enough for me to start using it.  In fact, what's happened is that, as of today, mainstream support ends, and extended support continues.  Now, the good news is we really don't need mainstream support.  Extended support is what Microsoft calls it where they keep sending out patches, which is all we really want.  And we get five more years of that.  Extended support for Windows 7 runs through January 14 of 2020, so five more years.



And so what's being lost with mainstream support is the no-charge incident support handling, warranty claims, any design changes and feature requests - not that they weren't ignoring them before, but now they're officially ignoring them.  And any nonsecurity-related hotfixes, we don't get any of that anymore.  But there's still available paid support, security updates, and of course all of the various online support resources will be kept available for another five years.  So it does sound like it's maybe about time for me to switch to 7.



Okay, now, this was fun.  We've seen this happen before, and it just happened again, which is that Microsoft is unhappy with Google over Google's pre-disclosure of a bug in Windows that Microsoft has not yet gotten around to patching.



LEO:  This is the second one; right?  This isn't the one that...



STEVE:  Yes, yes.



LEO:  Because the first one they waited 90 days.  It was not a major flaw and required physical access.  And Microsoft said, all right, we're going to patch it.  And that's kind of normal.  That's normal; right?  You wait.  You tell them, tell the company.  Ninety days later, if they don't do anything, I think there's a reasonable...



STEVE:  Yeah, I mean, so, yes.  This second flaw is similar.  It's a little more severe.  It still looks like local access only and elevation of privilege.  So you can get rights that you're not supposed to have.  Okay.  So looking at the Google page, reading about this, it also includes a proof-of-concept batch file.  So it's like, okay, everyone can do this.  And down at the bottom of the page it says:  "This bug is subject to a 90-day disclosure deadline.  If 90 days elapse without a broadly available patch, then the bug report will automatically become visible to the public."



Now, I don't - it's not clear to me whether, if a patch were available, then they wouldn't make this page available because at that point they sort of could.  It'd be benign.  But what I got a kick out of what was there was also a little bit of dialogue in the thread conversation among those who have privileged access to this.  Back on the 11th of November, so, what, two months ago, in this dialogue thread it says "Microsoft confirmed that they are on target to provide fixes for these issues in February 2015.  They asked if this would cause a problem with the 90-day deadline."  And the response was "Microsoft were informed that the 90-day deadline is fixed for all vendors and bug classes so cannot be extended.  Further, they were informed that the 90-day deadline for this issue expires on the 11th of January 2015."  Now, of course today is Patch Tuesday.  It's the 13th.  So this 90 days expired two days before Patch Tuesday.



Okay, then a month later, on the 11th of December, we see in this dialogue, in this thread, Microsoft confirmed that they anticipate to provide fixes for these issues in January of 2015.  And then, a month later, on January - oh, in my notes I have 2014, I meant 2015 - that is, two days ago, it says "Deadline exceeded - automatically derestricting."  Now, Microsoft didn't like this at all.  And there is a lengthy annoyed blog posting by the guy who's in charge of the security response center titled, "A Call for Better Coordinated Vulnerability Disclosure."  So I can, I mean, the problem with the 90 days is that, due to Microsoft's fixed 30-day calendar, that is, that Microsoft has committed to only releasing on the second Tuesday of every month, this sort of has a 60/90/120 effect, meaning that Microsoft might have had the patch ready two weeks ago but couldn't patch until today.  So if Microsoft weren't committed to only releasing on the calendar month, then they could be more responsive.  If they had it ready on the 61st day, missing the 60th day, then they'd be okay.



Anyway, so just sort of interesting to see this going on.  And here again, Google is just sticking to it, saying we think 90 days is enough.  Now, of course, Google is asynchronously updating Chrome on a continuing basis.  Google is updating all of their web apps on a continuing basis.  So they have no notion of sort of a lockstep calendar-based patch cycle.  Thus they really get 90 days.  Whereas Microsoft arguably has a bigger problem with that.



But at the same time, also in the news, is Google's abandonment of pre-v4.4 Android updates, which surprised a lot of people.  I think it's yesterday Metasploit, the hacking kit, was updated to include 11 new exploits which are effective against the default WebView-based browser in Android versions prior to 4.4, which is at the moment 61% of the Android install base, which Google has clearly stated it does not intend to fix.  Now, the whole story is a little bit more subtle than that.  So the press has gone crazy over this, about the idea that more than 60%, 61% of pre-4.4 version Android web browsers, that is, the default browser for Android, now have 11 known and hacking kit-level, turnkey, script kiddie-able exploits that Google has said, eh, no, it's old, we're not fixing those.



It turns out that, in fact, in a dialogue that the Metasploit guys, the Rapid7 guys had with Google, Google said, well, and quoting from the conversation:  "If the affected version of WebView is before 4.4" - this is Google speaking - "we generally do not develop the patches ourselves, but welcome patches which accompany the report for consideration.  Other than notifying OEMs, we will not be able to take action on any report that is affecting versions before 4.4 that are not accompanied by a patch."  Which everyone sort of thought, well, okay, but that's not the way it works.  Normally we explain the problem and give you a proof of concept to demonstrate the exploit, and then you patch it.  And so I guess Google is taking the position, well, hey, it's open source.  If you want to fix it, show us the problem, give us the patch, and then we'll consider doing something with it.  Which again is a different approach than we've seen before.  So I don't know.



LEO:  Isn't that what security people do, though, is set a deadline?  I mean, it's not unusual to notify the company and say, hey, you know.  Google cited the user's right to know, and of course the issue is always that hackers are eventually going to find it.  So is 90 days typical?



STEVE:  Well, I think the problem is the particular demographic to which a very sophisticated device is being sold.  That is, all of these old Android phones are still in use by people who don't know about alternative browsers or that they're in trouble.  And so we have, I mean, I saw the number, it's like 900-some million Android devices that now have browsers that are in use on the 'Net that are riddled with holes.  So essentially we've given innocent users very powerful Android-based smartphone devices, that are connected and now very vulnerable, that are never going to get fixed.



LEO:  I'm sorry.  I was talking about the Windows flaw.  But the Android phone might be difficult to patch.  I'm sure Google has the, I mean, Google could push a patch to the open source repository.  But remember, these phones are generally patched by the carrier, not by Google.



STEVE:  Right, right.  And so essentially the carrier - and so, I mean, we have a fundamental problem, which is, in the same way that we were talking about the manufacturers of routers, who are like, we sold it, we got your money, it's a blue plastic box, good luck to you, similarly the carriers are like, okay, you know, get a new phone.



LEO:  They don't want to update, yeah, in many cases.



STEVE:  Yeah.  So we have a problem.



LEO:  I guess Google could, now, it's just - it's in the browser; right?



STEVE:  Correct.



LEO:  So Google could, well, Google does offer an alternative browser.  The problem is getting the word out, I guess; right?



STEVE:  Right.  It's the built-in Android WebView platform that has the problem.  Google has switched now to a Chrome-based browser in Android.  And so that's what they're loving and caring for and feeding.  It's like, yeah, that stinky old browser, we're not going to deal with that.



LEO:  Well, I wouldn't assume that they don't have a patch for it.  I would just - I don't know how they get it out to the millions of people who have old versions of Android.



STEVE:  Well, and so, yeah.  So I guess the part that's...



LEO:  It sounds like you'd have to patch the whole operating system to fix this.



STEVE:  Yeah.  It's the browser built into the OS.



LEO:  Not an app update, yeah.



STEVE:  Yeah.  So, I mean, but conceptually we're now entering into an interesting, as-yet-unexplored territory where nearly a billion users have a sophisticated vulnerable phone which probably won't get fixed.



LEO:  Isn't it analogous, though, to I buy a machine, I mean, Google, I'm sure all the phones that Google sold directly, the Nexus phones, will be patched because Google patches those directly.  But it isn't...



STEVE:  Not older phones.  Not before KitKat, as I understand it.



LEO:  Oh, okay.  So if I bought a Galaxy Nexus from Samsung, there's no patch available for it.



STEVE:  Right.



LEO:  There's no way to fix it.



STEVE:  Right.  And so the Metasploit guys said, hey, here's all these things that we've just published.  And Google said, yeah, well, we don't, you know, sorry, it's too old.  We're not going to do anything about it.



LEO:  It's not as old as XP.



STEVE:  No, except that, well, no, that's a good point.  Though, again, the demographic is different.  We have...



LEO:  It's not, really.  I mean, a lot of dumb Windows users, too.  I mean, I think it's just users.



STEVE:  Yeah, somehow the idea of just people not appreciating the power that they have in a cell phone and its ability to, I mean, its fundamental ability to be compromised.  If we are to make a prediction on the podcast, it's that we'll be hearing - we'll be coming back to this topic, the idea that there are a billion unpatched vulnerable browsers in old Android-based cell phones.



LEO:  Yeah.  I don't know.  But, see, that's the thing is I don't know - this is true of Windows XP, as well.  I don't know - how far is this company responsible for fixing it?  I mean, most of these are manufactured by companies other than Google, that they used the free open source system on it.  It's like saying, I mean, it's a tough one.  I don't think it's immediately obvious what to do.



STEVE:  No, I'm not suggesting a solution.  I'm just saying we have a problem.



LEO:  Yeah.  It's a problem.  I agree, yeah.



STEVE:  Yeah.  As an industry, we're entering a new experiment here which is what happens with a billion cell phones with known vulnerabilities and exploit kits?  We're going to find out.



LEO:  Yeah.  Yikes.



STEVE:  Yeah.  In the show notes I have a screen capture of the tweet that was posted to CENTCOM's Twitter account.



LEO:  Oh, this is terrible.



STEVE:  "In the name of Allah, the Most Gracious, the Most Merciful, the CyberCaliphate continues its CyberJihad."  A little embarrassing for U.S. Central Command, to have their account hacked.  And it's worth noting, again, the press got a lot of mileage out of this.  It's worth noting that this doesn't mean anything bad about the integrity of Central Command's network.  This is Twitter that got hacked.  And Twitter's getting hacked all the time.



Now, multiple people probably have access to it.  Who knows what the back story is.  Bad password, weak password, somebody got their computer infected who was logging in, I mean, good, we just don't know.  It took them a while, though.  And then they tweeted about a day ago, U.S. Central Command is back.  They said, "We're back!  CENTCOM temporarily suspended its Twitter account after an act of cybervandalism.  Read more."  And then there's a link there in their tweet which basically says, yeah, so this wasn't us.  This was our social networks, both Twitter and YouTube.  I guess a bunch of videos were posted in CENTCOM's name to YouTube.



LEO:  I'd like to point out that both services have second-factor authentication, which obviously CENTCOM is not using.



STEVE:  Now, Leo, that's too tricky, you know, that's for experts.



LEO:  But on the other hand, you made the excellent point, which is a lot of people probably post to these social accounts, so it's very difficult to control that.



STEVE:  Right.  They wrote from Tampa, Florida in their note, they said:  "Earlier today, U.S. Central Command's Twitter and YouTube sites were compromised for approximately 30 minutes.  These sites reside on commercial, non-Defense Department servers, and both sites have been temporarily taken offline while we look into the incident further.  CENTCOM's operational military networks were not compromised, and there was no operational impact to U.S. Central Command.  CENTCOM will restore service to its Twitter and YouTube accounts as quickly as possible.  We are viewing this purely as a case of cybervandalism."  Which I guess is the term now.  That's what Obama called the Sony hack; right?



LEO:  Yes, yes.



STEVE:  He used the term "cybervandalism" in his pre-Christmas, final news conference of the year last year.  So it's cybervandalism.  Okay.  Finally, I think I'd like you to play this 60-second video into the podcast, if that's possible.



LEO:  All right.  Absolutely.  The lovely and talented David Cameron.



STEVE:  Mm-hmm.



LEO:  Let me just turn on my audio so you can see it.  It says a brain - what is this, a brain living within its means?  Let me go back to the beginning.



[Begin clip]



DAVID CAMERON:  In our country, do we want to allow a means of communication [Leo:  Oh, Britain.] between people which even in extremis, with a signed warrant from the Home Secretary personally, that we cannot read?  [Leo:  Yes.]  Now, up until now, governments of this country have said, no, we must not have such a means of communication.  That is why, in extremis, it's been possible to read someone's letter.  That is why, in extremis, it's been possible to listen in to someone's telephone call.  That is why the same applies with mobile communications.  Let me stress again, this cannot happen unless the Home Secretary personally signs a warrant.  We have a better system for safeguarding this very intrusive power than probably any other country I can think of.  But the question remains, are we going to allow a means of communication where it simply isn't possible to do that?  And my answer to that question is no, we must not.  The first duty of any government is to keep our country and our people safe.



[End clip]



LEO:  Huh.



STEVE:  So Cameron said, "We must not allow terrorists safe space to communicate with each other."  And so he's promised a "comprehensive piece of legislation" to close the "safe spaces," as he puts it, "used by suspected terrorists to communicate online with each other."



LEO:  By the way, we should point out that the British government does in fact have secure communications, and nobody's proposing there be a backdoor in that.



STEVE:  Correct.  And he said he recognized such powers were, quote, "very intrusive," but he believed that they were justified to counter the growing threat to the U.K. as long as proper legal safeguards were in place.  And essentially what he's saying is we're not going to permit encrypted communications that we are not able to eavesdrop on, meaning that Trust No One (TNO) connections like WhatsApp offers, like iMessage and FaceTime both offer, would be or could be banned under new surveillance plans.  And the press has picked it up, saying in the wake of the Paris attacks, "Prime Minister wants to ban encryption that government can't read in extreme situations."  And of course this whole notion of "in extremis" that he keeps talking about, well, that just means there's a way.  It doesn't matter, it doesn't have to be really important.  It just, you know, you either can or you can't.  So, oh, Leo.  I mean, I really - I'm worried about the future.



LEO:  I don't worry at all.  First of all...



STEVE:  Really.



LEO:  Yeah.  Here's a couple reasons.  First of all, we don't know if he's actually going to try to get this enacted into law, and you can see already there'll be a lot of opposition if he does.  Let's say he does.



STEVE:  Yes.



LEO:  Remember the U.S. government forbade strong encryption export.  Didn't stop it.  It'd be very difficult for the British government unilaterally to prevent people from using strong encryption.  I just don't think that they can do it.  It's not enforceable.  Are they going to throw everybody in jail who does?



STEVE:  They can outlaw commercial products which provide strong encryption.



LEO:  They should because those aren't really strong encryption.  And by the way, they won't outlaw those because they just go to Microsoft and others and say, hey, put a backdoor in, and it's done.  It's the open source, non-commercial software that, as usual, is going to be very hard for them to stop.



STEVE:  Okay.  I guess we're sort of talking at cross-purposes.  I mean, you know...



LEO:  Well, WhatsApp, you know, WhatsApp may be dead.  But who cares?



STEVE:  Okay, what about iMessage?



LEO:  TextSecure - who cares?



STEVE:  So iMessage will be...



LEO:  TextSecure is not going to be reengineered and will be available in Great Britain, no matter what they do.



STEVE:  Okay.  So - oh, okay.



LEO:  See what I'm saying?  So, yeah, maybe they will - maybe.  But, frankly, do you trust iMessage now?



STEVE:  Well, no.  We know that it's possible for...



LEO:  So what, then?



STEVE:  ...Apple to provide the keys; right.



LEO:  Right.  Commercial companies, we have, I think, said pretty consistently you cannot be sure that they aren't already putting in a backdoor, regardless of the law.



STEVE:  Okay.  So...



LEO:  In fact, I would submit that the U.S. law does already have this feature.  That's why you stopped doing your crypto solution, because they can write...



STEVE:  No, I anticipated that we were going to have a law come out that said...



LEO:  But we already do.  It's called the Patriot Act.  They can go to anybody and say you need to put a backdoor in this.  Already, right, in the U.S.?  Don't they?  With an NSL?



STEVE:  No.  No.  They're able to say give us what you have.  And so the companies are now saying, "We're happy to because we no longer hold the keys."  So that's what Apple says; that's what Google says.  We no longer - we have reengineered our systems over the course of 2014 so that we no longer have the keys.  So you're welcome to this blob of noise.  Good luck, because it won't help you.



LEO:  Good.  And I'm not sure I fully credit that.  So if you want to be secure, and if you're a bad guy, you don't use iMessage.



STEVE:  Right.



LEO:  You'd be nuts to use iMessage, or Messages, as they call it.  But so the real question is, okay, so the British government may do this, making explicit what's probably been going on behind the scenes all along.  But does this thwart open source solutions like TextSecure?



STEVE:  It outlaws them so that we can't...



LEO:  I would say unenforceably.



STEVE:  Right.  But still, it outlaws them.  So potentially you're then committing a crime if you employ strong encryption for your own non-terrorist activities because the government has said strong encryption is no longer legal.  You cannot communicate in a way that we're unable to intercept.  To me, that's a profound change in the world.



LEO:  Yeah, it's not good.  I'm not saying that.  But I think it's unenforceable.



STEVE:  I don't care.  It's profound.



LEO:  It's wrong.



STEVE:  I mean, you're a criminal if you employ strong encryption.  That's profound.  I mean, you know...



LEO:  Well, I'd like to see them arrest 10% of the British population.  That's the other thing.  You can make a law.  If it's widely ignored, what are you going to do?



STEVE:  Yeah, I do notice a lot of people on the freeway going faster than 55.



LEO:  There's a lot of laws in the world.



STEVE:  Or 65.



LEO:  Yeah.  If they're widely ignored, you can't arrest your population.  I would anticipate some strong civil disobedience in the U.K. if this were to be passed.  I think Cameron knows that, too.  But we'll see.  You know, maybe not.



STEVE:  Well, and the U.K. doesn't affect me because I'm in the U.S.  And I wouldn't be at all surprised.



LEO:  Because, of course, if WhatsApp is illegal in the U.K., it makes it difficult to, you know, I mean, that can spread.



STEVE:  Right.  Well, yeah, exactly.



LEO:  And somebody in the chatroom says, "What about HTTPS?"  Jeff is in London, so he has an interest in this.  Do you ban HTTPS?  Is SSL banned?  And which vendor do you go to to get the backdoor?



STEVE:  Yeah.



LEO:  I think it's hard.  I think it's very hard to make this happen.  But maybe - but you're right, we should call attention to it, yeah.



STEVE:  We'll be watching, yeah.  So I do have good news, before we start talking about Enigma.  Something that is not an enigma is SpinRite.  I got a nice note on the 8th of January from someone who signed it JS Cube.  I just know that his email was - he's in Shaw.  Shaw is his ISP in Canada.  And he said:  "Hello, GRC peeps.  This is not a query, but a testimonial.  I wanted to leave one on your site, but I couldn't find a link to do so."  That's true, we really don't have one.  He said:  "You may not care, but I'd like to leave a testimonial anyway."  And of course I'm more than happy to have a testimonial from JS Cube.  He said:  "I had an old but working hard drive that had bad sectors in it, which made it fail any previous attempts to clone it.  Your product was my last resort, and it saved me a LOT [in all caps] of time reloading everything into my new SSD.  I was able to clone my old hard drive, no problem.  I'm sure you hear this all the time.  Thanks!!!"  With three exclamation points.  And he says:  "I love your product.  It's f@@n' awesome."



LEO:  Freaking awesome.



STEVE:  Freaking awesome.  "Best Regards, JSC."  So thank you, JS Cube.  I don't think you're a podcast watcher, but I'm happy that you're a SpinRite user.



LEO:  Oh, so he didn't know about Security Now!.



STEVE:  I don't think so.  He sent this to the GRC peeps, and it came to me via Sue.



LEO:  Can there be anybody who does not know about Security Now!?  How is that possible?  All right.  By the way, one of our chatters sent me a link to a Guardian article about "The Imitation Game" in which they go through, step by step, the historical errors or mistakes.  And there's quite a few. 



STEVE:  I know.



LEO:  So I'm going to take it back that it's historically accurate.  In fact, in some respects it's appalling inaccurate, and in some insultingly inaccurate.  However, a great movie.  And you know what, movies have to be movies, not life.  And so that's what happens.



STEVE:  Right, right.  As I said, it's a great movie, and I would say it's based on historically accurate characters.  And it would be nice to have really had a really good sense for who Alan was, you know, exactly what was his demeanor.



LEO:  Well, they give us an example that - and I don't want to do a spoiler.  But Turing at one point was blackmailed by a spy.  And this never happened.  And the Guardian says it paints Turing as a coward.



STEVE:  Correct, as a traitor, actually.



LEO:  As a traitor and a coward.  And it never happened.  And so they should - I understand from the moviemaker's point of view, the purpose of that engagement was to show how scared and lonely and persecuted homosexuals were in the Britain of that era.  But still, it didn't happen.



STEVE:  Well, and for example, I mentioned when we were talking about this a couple weeks ago, the other thing that annoyed me was this completely artificial midnight deadline, where all the work they had done would be scrapped on the stroke of midnight.  It's like, uh, no, that's not true.



LEO:  It seemed pretty stupid on the face of it, on the part of the commandant of Bletchley Park.  But so, you know what, just search for "The Imitation Game" at the Guardian, "Inventing a new slander to insult Alan Turing."  It's TheGuardian.com.  And you can enjoy the movie, but it's a good idea to understand some of it is just completely ridiculous.



STEVE:  What I did read of his character was that, while he did sort of have, for whatever reason, some aloofness to him, whether just essentially a social disability, he did understand humor.  And if he liked you, you sort of got moved into his inner circle, then he could be quite charming.  So that's not quite the person that the movie painted.



LEO:  Yeah.



STEVE:  So here's the way this whole thing actually - the history is really interesting, too.  So we can have the story, which is not historically accurate.  But the good news is the truth is every bit as interesting.  So radio was the way that we were communicating, "we" everybody, in wars.  World War I had radio.  And the problem with radio is that one person sends it, and everybody can receive it.  So eavesdropping is sort of what you do.  I mean, and there were, like, listening stations all over the place, specifically for receiving what anybody else transmitted.



Toward the end of World War I, Germany believed, up until they found out otherwise, that they had an uncrackable crypto during World War I that was protecting them.  And they were apparently quite annoyed to learn after the end of World War I that in fact their unbreakable crypto - which was not the Enigma machine.  The Enigma machine was World War II.  So the First World War, everybody had cracked the German uncrackable code and was merrily decrypting their messages.  And so they had actually no protection at all, and they were convinced their code was uncrackable.  So they essentially decided not to make the same mistake for World War II.



Now, what's interesting is that, shortly after the First World War, that is, well before the beginning of the Second World War, a German inventor by the name of Arthur Scherbius invented and developed and patented the Enigma machine.



LEO:  Wow.



STEVE:  So this wasn't something that the German military or the German war machine created.  This was a commercial product.  Not many of them sold because the number that I saw in one relating that I read said that it was $30,000.  Now, I assume that's translated into today's money.  But he was trying, I mean, the point was that communications was, like, by courier.  You would write a letter, and then you'd send it somewhere.  So he was trying to sell it to companies, corporations that needed to keep their communications secret.  But it wasn't very successful because the darn thing was very complicated.  And, I mean, beautifully engineered, you know, so-called "German engineering."  Just works of art, but way expensive.



So the other thing that is worth noting is that simultaneously, pretty much around the world, these so-called rotor-based enciphering machines came into existence.  So there was co-invention, as often happens.  It was just sort of time for these code wheel machines to happen.  And so Arthur named his the Enigma.  It was the machine that the German military then adopted.  But there were others that operated in similar but different fashion.



Sandwiched in between Russia on one side and Germany on the other is Poland.  And they were nervous because, well, they had Germany on one side and Russia on the other.  And so they had a very active "cipher bureau," as they called it, whose job it was to decrypt the messages that they were able to catch out of the air in order to know what the Russians were thinking about their border and what the Germans were thinking about their border.  And the crypto bureau in Poland did something that, as far as we know, other code breakers hadn't yet.  And that is they employed real mathematicians.  They didn't sort of employ puzzle solvers.  They employed a trio of very good Polish mathematicians who applied everything they knew about math to this problem.  And in the space between World War I and World War II, they were keeping an eye on things, decrypting messages, and things were fine.



Then Germany began purchasing and using Arthur's Enigma machine.  And the Polish mathematicians started having a problem.  They started receiving a new type of cipher over the radio that they could not crack.  And so this represented a problem because, again, they needed to know as best they could for the sake of their country what Germany was doing on the border that they shared and what plans Germany had.  So there was a traitor who provided some documents which they were able to get a hold of.  But mostly it was truly inspired reverse-engineering.  We'll talk about the - you'll get a better sense for that when I explain how the Enigma machine works and what its pieces are.



But it turns out that, although they had almost no useful information, the Polish mathematicians were able to reverse-engineer the complete design of the Enigma machine based on the code, that is, looking at what it encrypted and figuring out what the plaintext was and then thus what the wiring had to be.  And you'll have a much better sense for what an amazing piece of reverse-engineering that was when I talk about how this thing works.  They built clones of the Enigma machine from their reverse-engineering.  And they also built the first so-called "bombe."  And there are conflicting stories about why it was named that.  One report said that, well, it made a ticking sound, like a bomb that was going to go off.  And of course bombs were on everyone's mind at that period of time with all of these hostilities mounting.  The other was that it was the name, like one of the Polish mathematicians' favorite ice cream was named after that.



LEO:  It's a dessert, yeah.



STEVE:  Yeah, so we're not sure where the name came from.  But they were able to take advantage of a crucial flaw in the protocol, that is, the instructions that the Enigma operators used that I'll talk about in a second, in order to create a machine that was able to figure out, essentially crack Enigma.  And again, we'll talk about what that is.  But so that's the history of this.  Then at some point what Germany was doing changed.  And just before the outbreak of World War II, they met with British intelligence, I think the Brits and the French, and showed them what they had.



Now, both French and English cryptographers at that point were completely mystified, completely befuddled.  This is before Alan Turing's time.  So they had no idea what was going on.  And when these three Polish mathematicians said, uh, here's what's going on, I mean, apparently, in one recounting of this, one of the British agents had a fit because he was so upset that there was this much, this trove of information about what Germany was doing that the Poles had not until then chosen to share.  And, I mean, it was crucial.  It was Enigma machines they had reverse - working Enigma machines that they had figured out from decrypting.  And, oh, look, here's this thing we built that's called a "bombe," and it decrypts the code.  Or at least it did until shortly before then.



Okay.  So now we switch to Bletchley Park and the effort to decrypt what Germany did.  And I'll talk about what the change in protocol was.  Essentially what happened was the Polish mathematicians were using a trick that Alan Turing and his group didn't think was reliable.  That is, it was about a procedure in setting up the code that Turing and his group realized the Germans could too easily change.  And while it made cracking easy, it was deemed too fragile.  And in fact on May 1st of 1940, Germany did change their procedure, and the Polish approach for cracking Enigma completely collapsed.  So it turned out in retrospect to have been exactly the right call, even though what Alan and his group ended up having to build was far more complex.



Okay.  So what is this Enigma machine?  We start with a keyboard with 26 keys, so just the alphabet, A through Z.  No upper or lowercase, no numbers, punctuation, not even a space, the idea being that, if it's converted into your language, back into German, even though it'd be nice to have spaces, this is military, and you can figure out what the words are by looking at it closely.  They did sometimes use the character X in order to indicate the end of a sentence, just because X was uncommon, and that would sort of give you a clue.



The way they handled numbers, I saw one report that said they were spelled out, and that's incorrect, actually.  They would use the prefix character Y.  And then above the top row of keys, QWERT, it actually wasn't QWERTY, it was QWERTZ, a slightly changed key arrangement, but basically the typewriter that we're familiar with.  Along the top row were nine keys, so those were numbered 1 through 9, and then P was down below.  That was given the designation of zero.  And so if you wanted to send a number like 1940, you'd send a Y and then a series of alphabetic characters, each corresponding to a digit.  And that way somebody reading it would see a Y and then something that doesn't make any sense at all and realize, oh, this is a number.



So basically what we're sending is 26 symbols.  And each one of those keys is connected to a wire that goes into what's called the "scrambler."  And there's an intermediate stage I'll come back to in a second which is the plugboard which exists on the front of it.  But let's sort of take this step by step.  So you've got 26 keys, like buttons.  And each one energizes a wire.  So those 26 wires go over to a circular array of contacts.  So we have a circular array of 26, I'm sure they were beautiful brass contacts.  We then have a series of what were called "rotors."  Think of the rotor like a hockey puck.  And it's about four inches in diameter and about an inch thick.  So, you know, kind of hockey puck-like.



And this hockey puck, this rotor, has a similar set of 26 contacts on one face and 26 spring-loaded pins on the other.  So this hockey puck has connections on one side and pins for connecting to the next hockey puck in a stack.  Inside this rotor, this hockey puck, one side of the 26 connections are cross-connected, like on one face, one face of these 26 connections are cross-connected, one for one, but in a completely haphazard fashion, to the other side.  So all 26, there's, like, wires inside, and it's a maze of craziness inside as every wire from one face goes over to a different connector on the other face.  So it's called a "scrambler" because it scrambles all of the - in fact, Leo, the picture down below, on the page below that you're showing right now is a slightly better one.  Oh, are those my notes?



LEO:  No, but...



STEVE:  No, okay.  In my notes I have a better picture.



LEO:  All right, good.



STEVE:  Yeah.  Anyway, so the original machine had three of these rotors that would be inserted in the machine at any one time from a set of five.  So there was a set of five that were designated with Roman numerals, you know, I, Roman numeral II, Roman numeral III, Roman numeral IV, and Roman numeral V.  And so the part of the configuration of this Enigma machine was choosing from one of five for the leftmost rotor, one of the remaining four for the middle rotor, and one of the remaining three for the rightmost rotor.  And there were 60 different ways, five times four times three, 60 different ways to set up, basically to choose the stack of rotors which would be used.



And so to make sure everyone understands this, what we have is we have from the keyboard, as you press a key, one of 26 wires is electrified.  And that successively moves through each of these three rotors, going in one location, essentially emerging in a completely different location, where it then connects to the rotor to its left, going in that rotor and emerging in a different location, where it then connects to the leftmost rotor, going in it and coming out on the other side.  So these are rotors because, as the name implies, they can rotate.  And this is part of the magic of Enigma.



Now, we've got, as this comes out on the left-hand side of this stack, we now have 26 connections.  What are we going to do with those?  Well, what was very clever was what Arthur designed, but it was also one of the several fatal flaws in the design.  And that is that the final stage to the left was called the "reflector."  It, too, had 26 connections to match the 26 connections coming out of the left-hand side of the leftmost rotor.  And its 26 connections were connected, again in a haphazard fashion, to others.  So that is to say it had 13 wires with each end connecting a pair of the connectors on its face.  Thus it reflected.  The electricity, the current would go in one of its 26 connectors, having been well scrambled on its journey from right to left through these three rotors.  Then it would emerge from a different one of the 26 and make its way back through the same stack of rotors back to the right.  Whereupon one of 26 lights would be illuminated.



So now you get a sense for this.  So you press a button, and electric current flows through one of 26 wires through these three, the stack of three rotors, which internally each are scrambly.  And when it finally emerges, it is sent back, based on this reflector, through the scramble again, to emerge.  And that current then lights one of 26 lights.  So basically that is sort of a static picture of Enigma.  Which means that, as you're pressing buttons, very difficult to predict lights are lighting up.



But there's one interesting characteristic of this design which I refer to as a "fatal flaw."  And that is, you'll note that there's no way a letter can ever encode to itself.  That is, if you press T, and one of those 26 wires happens, nothing that can happen in there is able to send a current back out the same wire it came in.  Well, that was very clever because it allowed for a simplification of the design, but it was cryptographically a flaw because it gave a big clue to decrypting this.  No letter could ever encode to itself.



Now, the other thing we have at this point is not something very complicated.  That is, essentially, we've gone to a huge amount of effort to create a very simple substitution cipher, which is, and we've talked about those before, like the encoder ring.  You take the alphabet, A through Z.  And then you could put below it randomly arranged characters A through Z.  Now you look up the plaintext on the top row, and the corresponding ciphertext is on the row below.  So that's a substitution cipher.  We know that they're not difficult to crack because, if you know anything about the language which the plaintext is written in, a simple frequency analysis of enough ciphertext will quickly identify the letters that are most common, the letters that are least common.  You can then start making guesses about the ones in between based on your knowledge of the language, and it's easy to crack.



So that's called an "alphabetic cipher."  What we want is a polyalphabetic cipher, that is, one where the mapping between the plaintext and the ciphertext is continually changing.  And that's the first brilliant part of the Enigma.  And that is, when you press that key, whatever key you're wanting to encrypt, not only does an electric signal go to one of 26 contacts to begin making its way through, but the act of pressing the key rotates in sort of the manner of an odometer.  It rotates the rightmost rotor to its next position.  It steps it through one of 26 steps.



And there is a moveable ring on the left-hand side of that right-hand rotor.  It's also known as the "fast rotor" because it turns the fastest in sort of an odometer sense.  This repositionable ring can be also in any of 26 settings.  And there's a notch in it which determines at which position of the fastest rightmost rotor a cam will drop, allowing the second, that is, the middle rotor, and it's called the "middle rotor," to then step.  So you have a situation where, once every time around, with the fastest rotor, the second one will then engage, and it'll advance.  And when that happens is set by a moveable ring on the face of that fastest rotor.  And similarly, the middle rotor has a ring also which determines when the leftmost rotor rotates.  And then there's one extra little kink which causes the machine not to operate exactly like an odometer, which is that some of these cams can multiply engage and rotate more than one wheel in some circumstances.



So it's a little trickier than just that.  But the concept is, every single - and this is the key.  Every single time you encrypt a character, the cipher changes.  The rotor steps to its next position, completely changing the scrambling, that is, the mapping between the A through Z character set to a very different A through Z character set.  And thanks to the fact that you've got multiple rotors, the mapping is complex, and it does not repeat.  Now, the Germans understood that some information was leaking, and so they limited the length of the messages set with Enigma to about 250 characters.  They understood that, if this thing ever did repeat, then that would create a cryptographic opportunity which they wanted to prevent.



So now there's one last part of this, and that is there was a plugboard on the front of the machine.  So before I leave, we have the notion of, from a set of five rotors, you choose three, and you choose what order they're going to be in.  Then you choose also the starting position of each of those.  So you dial those to a starting position, where the message begins, as the settings.  Then finally this plugboard, that intercepts the signal going between the keyboard and lights and the scrambler stack and performs a static swap.  So with this plugboard you plug one into T and one into W, for example.  Then if you didn't have that in place, and you pressed T or W, the signal would go directly through to the T or W wires at the beginning of the scrambler stack.  But with the plugboard cable plugged into the T and the W holes, they were exchanged.  So this was both the keyboard and the lights had their wires swapped, so T would become W and W would become T.



And it turns out that the Germans felt that this provided a ridiculously large number of connections.  The Enigma machine had 10 wires that could be plugged into any of 20 of the 26 available holes in this plugboard.  Now, it's interesting, too, because you might think, well, wait a minute.  Why not 13 cables because there are 26 holes?  It turns out that's actually less secure.  If you have 13 wires, there are fewer combinations than if you only have - actually the optimal is 11.



LEO:  That's clever.



STEVE:  Yes, yeah.  For some reason, the Germans chose 10 wires.  Maybe one broke at the beginning, and they stayed with 10, or they thought 10 was an easier number.  It's slightly better to use 11.  But then 12 gets worse, and 13 actually is redundant because, if you have 12, there's only two left open.  And so you know that those are going to get swapped because there's no other choice.



Okay.  So we end up with lots of combinations.  I talked about how we have 60 different arrangements of the rotors.  Then we have the rings, which on the rightmost rotor and the middle rotor give 26 settings each.  There actually was a ring on the third rotor because that third rotor might be in a different location, but it had no practical effect because there was nobody for its ring to control the rotation of.  So that is 26 times 26, which is 676 possible combinations of two 26-position rings.



Then we have the initial rotor settings.  Each rotor, A through Z, could have its initial settings set.  So that's 26 times 26 times 26, which is 17,576 possible starting positions for the rotor stack.  The plugboard, oh, my lord.  That had by far the most complexity of all.  On the order of, let's see, what is this number I'm looking at?  It's 150,738,274,937,300.  I have it here in the notes.  But, I mean, a ridiculous number of possible ways of swapping letters.  So altogether 60 times 17,576 times 676 times the plugboard combinations ends up with about one times 10^23 possible combinations.  Which in English is 100 sextillion, or 100,000 billion billion combinations.



And, I mean, think about that.  From a simple mechanical device back in World War II era.  I mean, just incredible crypto.  And very, very clever.  Basically, a polyalphabetic cipher, which could be set to an initial condition with a vast number of combinations, and every single character you enter changes the alphabetic mapping from plaintext to ciphertext in a very complex way that never repeats during the course of your sending even a very long message.  What, 26 times 26 times 26 - no, that's that 17,576 number.  It was slightly less than that because you could have multiple rotors changing at the same time.  So the rotor positions would come back to home.  But still, Germany never sent more than 250 characters in a single message, so they prevented disclosing too much information at once.



So the way this operated in practice - so I should also mention that what this was, this was a system, it was a classic keyed cipher.  We've talked about, obviously, keying ciphers.  The concept of a keyed cipher is that, even if you know everything there is to know about the design of the cipher, that still doesn't weaken it.  In this case, actually, it does a little bit.  But the theory is that it's the key that matters.  You could completely disclose the cipher mechanism itself, and your privacy of what you encrypt remains intact.  And we know of stories through the course of World War II where U-boats would get sunk, and people would go down and recover the Enigma machine from it.  Or they would pull the crew off the U-boat, and the scuttling charges hadn't gone off yet, or failed, and again they'd pull an Enigma off.  So the Allies had Enigma machines.  We weren't limited to the ones that the Polish mathematicians reverse-engineered.  But having the machine didn't help us that much because it was a keyed cipher.  What we needed was the key.



So what the Germans created was a codebook, not of the cipher, but of the key.  And they would arrange to get the codebooks to everyone who had Enigma machines.  The book had a long enough life; three months was what I encountered in my research.  It had three months of codes, of Enigma machine settings, by day.  So on a given day, by month and date, the Enigma operators would look up the rotor order.  So this was settings for the day.  So you would grab the No. 4 rotor and the No. 1 rotor and the No. 5 rotor in that sequence to build your stack, and then insert that and lock it into the Enigma machine.  Oh, but before doing that, you would set the rings on the rotors, on two of the rotors, to 23 and 2.  Some of the rotors were numbered 1 through 26.  The other ones had A through Z on them.  I think they felt that numbers would be clearer, just so as not to confuse the other instances where letters were being used.



So you'd set the rings on two of the rotors, insert and lock down the stack.  Then you would - the codebook had letter pairings, for example, AR, KT, WM, LC, XD and so forth, 10 pairs of letters, which were the plugboard settings.  So you would take your 10 plugboard cables and plug them into those letter pairs in order to perform the static swaps between the alphabetic keys and lights and the substitution cipher stack.  And finally, the last piece of information in the code book was the starting positions of the rotors, like TXM.  So you would dial those three numbers, or, sorry, letters of the alphabet so that they showed through little windows in the front of the machine, and now you were ready.  So that would be the setting for the day.



Then the instructions to the operator were come up with three letters at random.  That's the per day key.  And we already know how many combinations there are of those, a ton.  So now the operator comes up with three letters at random which the operator enters into the machine and gets three cryptographic letters out.  Then he does the same thing a second time and is going to get a different three.  Because, remember, every time you put a letter in, the cipher changes.  It advances the rotors from the right one, which is turning fastest, on down to the middle and the left one.  So you're going to get, even though you put the same three characters in a second time, you get three different outputs.  That is used to prefix the message that is sent.  And then the operator sets the wheels back to the random setting of the three that he chose, and then encodes the message.  So essentially we have a day based on the code book, and then we have a per-message encryption based on three random letters which the operator prefixes the transmission to.



Now, one thing I didn't say, which may be obvious from the design, but this is the other very cool thing.  Remember I said that that reflector represented a flaw in the design because no character could encode to itself.  But the motivation for that was extremely cool.  And that is, think about it, if you - say that you press T, and the wires run through in both directions and come out Q, and light up the Q light.  Well, similarly, if without changing the rotors you pressed Q, the electricity is going to go in the Q wire and come out the T wire.  Which is to say that the Enigma machine creates a mirror image.  That is, all you do to decipher a message is set up the exact same conditions as was used to encipher the message because the ciphertext will generate the plaintext in a mirror image of the plaintext that generated the ciphertext.



So on the receiving side, they've got the same codebook.  They initialize their machine in the morning with the same settings.  And then over the radio they receive a message.  They're going to receive those first three letters which are the transmitting operator's randomly chosen setting for the message.  They'll decrypt it, and they'll receive the original three letters that the operator sent.  Then they're going to get three different letters, which is the reencryption that second time of the same first three letters.  And they should get the same three plaintext out.  So that was a verification.



Unfortunately, it was also a huge weakness.  And it was exactly that protocol, the fact that the same three randomly chosen letters were sent twice, that allowed the very skilled mathematicians in Poland to crack Enigma initially.  Just knowing that, they were able to analyze enough messages in order to reverse-engineer the entire complement of rotors, all the scrambly stuff going on inside, and build themselves an Enigma, which frankly is an astonishing feat.



The problem is Germany stopped, on May 1st, 1940, stopped the practice of duplicating those first three letters.  And they made some other changes, and that completely broke the Polish cryptographers' solution.  And it was that characteristic that Turing and his group understood was too fragile, so they never based their decryption on the assumption that the Germans would always be doing something that could be so easily changed.  And in fact, that was the right choice to make because Germany ended up no longer prefixing.  Basically it was unnecessary for them to do it.



So that is how Enigma works.  And the Enigma machine design did evolve over the course of World War II.  We went from five rotors, from which three were chosen, to eight rotors, from which four were chosen.  So we got more rotors and a fourth rotor in next-generation design.  But otherwise, that was the system that functioned.



So in order to crack this, there were a number of interesting clues that came out of this.  The fact that the Enigma machine could not encrypt a character to itself was crucial because what Turing and his group realized, and we did see this in the movie, was that, if they knew some of the text, that is, some of the plaintext that had been encrypted, that gave them a clue.  And in classic cryptography, this is known today as a known plaintext attack.  They couldn't choose the plaintext to encrypt, but they knew what it was.  For example, the German messages were often signed, essentially, or ended in a "Heil Hitler."



Or one of the most reliable first-thing-in-the-day broadcasts was the weather.  The weather from certain locations, certain stations, was broadcast.  And that broadcast had a heavily scripted, repeated format.  So they were able to, in fact, it began with the phrase "weather report."  So they knew the German for weather report at the beginning of the broadcast.  They knew when it was going to be sent.  And the Germans, if nothing, were very punctual.  So the punctuality of that, because they also had the time and date that was in the message, so that gave them a chunk of stuff that they knew.  So they would take that plaintext and write it out and then lay out the ciphertext of the weather report.



Now, one thing that they knew was that, by nature of the design of the Enigma machine, no letter could encode to itself.  Well, if you have enough plaintext and enough ciphertext, and only an alphabet of 26, it turns out there are lots of collisions, that is, lots of places where somewhere in either of those strings, the same character will be above and below.  Well, you know, then, that that's the wrong alignment of the plaintext with the ciphertext.  So you shift it over one.  Now three other places collide.  Whoops, that's impossible.  You shift it over again, oh, there's - nope, two places collide now.  Okay, that can't be it.  So you shift it again.  So basically they would shift it until they would find a setting, that is, just an alignment of ciphertext and plaintext that didn't break that one simple rule, that the text could not encipher to itself.



Now, if you think about the design of the machine, it didn't have to have a reflector.  The reflector was convenient.  But if instead those 26 wires came out of the left-hand side and went to light bulbs, then you would have encryption without reflection, and letters could encrypt to themselves, and the No. 1 most useful hint would have been lost.  It's true that then decrypting wouldn't have been a symmetric operation as it was the way the machine was cleverly designed.  You would have to arrange to swap the wires, the input and output wires, so that you were basically sending in on the left and coming out on the right, rather than always - rather than doing both over on the right-hand side.  But that could have been done and would have made a vastly stronger, though slightly more complex and less easy to use, system.  As it turns out, that was the Achilles heel, the fact that they were able to eliminate so many possible ciphertext and plaintext mappings, simply because the same character could not encrypt to itself.  That created a ciphertext and plaintext test.



Now, the way this crazy machine, the bombes, operated, that Turing and his group designed and built, was essentially it found and rejected many other impossibilities.  What the machine was trying to do was it was trying to determine the day's settings from one or more captured pieces of crypto for which they could guess the plaintext.  And in looking at the design, I decided, okay, I'm not going to be able to explain it because it is really, I mean, this is why Turing was a genius.  This thing - and to have built this in the technology of the era, basically with wires and rotating cams and contact, I mean, like, no electronics.  Basic electricity.



And he was able to come up with a system which would test and reject possible settings of the Enigma machine because it turns out that, the more you think about it, when you think about this network of wires, not only can a character not encrypt to itself, that's the most obvious and easy observation, turns out when you sit down with a pencil and a lot of paper, many other impossibilities fall out.  And so it was possible to automate the process, which is what Turing did, of rejecting almost all daily settings or potential settings for the day.  And then when this thing would stop there would be, based on the limited input, it would be a possible setting for a Enigma machine.  They would then run over, see if it made, you know, impose that setting, see if it made sense for a different piece of that message or some other message.  And if not, they would keep going and wait till it found another possibility.  And that's how Enigma works and how Enigma was cracked.



LEO:  Yay.  It's no longer an enigma.  This is all very cool.  And while you've been talking I've found a number of interesting Enigma emulators.



STEVE:  Oh, yes.  The 'Net has a bunch.  There are both hardware and web pages.  And one is written in Java, and the guy wants to recode it in JavaScript for browsers but has not had a chance to do it yet.  But, yeah, there was a Kickstarter project.  There are beautiful, there's like a thousand-dollar, like in a wooden box, the whole deal.  You're able to - basically they are 100% faithful reproductions of the exact Enigma technology, such that if you had the settings and German ciphertext, and you spoke German, you could figure out what they said.



LEO:  Someone named Louise Dade, who provided the graphics that we were using, has got one online.  And then this is one for Windows, and I'm very tempted to download...



STEVE:  Yes.



LEO:  ...that beautiful graphic.  This is...



STEVE:  It's just gorgeous.



LEO:  It's from the Dutch coder.  But it requires Windows, any version of Windows, including the most modern.  So this looks kind of fun.  I'm going to put this on my Windows machine.  I don't happen to have one here, so I couldn't run it.  But isn't that nice?  People love this.  It's a great subject.



STEVE:  You know, and I think one of the things that's nice is it is accessible crypto.  I mean, I just described how it works.  And it's not that hard.  It's clever.  And, boy, when you think about what they did at the time, like in World War II era technology.  Basically just all they had was buttons and lights.



LEO:  And radio.



STEVE:  And wires.



LEO:  And radio.  And is this - I guess this is symmetric key crypto because you have to have, at some point, exchanged these sheets that tell you what the settings are.  Otherwise you can't decode.  And that's of course the flaw of ciphers.



STEVE:  Well, yeah.  It's keyed.  It's keyed crypto.  And it is sort of, I mean, it is symmetric.  It's sort of like an XOR where you put in...



LEO:  Well, symmetric in the sense that you have to exchange a key with a recipient before you guys can talk.



STEVE:  Yes, exactly.  So you have to have the code.  In fact, one of the things that would happen is, since these code books were issued every 90 days, sometimes the Allies would capture a code book shortly after issue, and they would get free settings for the balance of 90 days.  If they caught it shortly after issue, they'd get almost three months' worth of settings.  If not, they would get however much time was left on the code book before it was reissued.  But so those were windfalls, when they would get the codebook.  But what was cool was, because it's a keyed cipher, even having a machine didn't help you.  We had machines.  But we still had to build crazy bombes in order to decrypt them.



LEO:  And you mentioned this, but in a very primitive way, like having a Captain Midnight decoder ring, Enigma being the ring, a very fancy version of the ring.  But you still had to, ahead of time, exchange the settings.  Otherwise you couldn't decipher each other.  And that's why public key crypto is so remarkable, because that eliminates that exchange and eliminates one of the big holes in crypto.  Oh, and we now have - John has brought me a sign so that, if I ever lose your audio, I have something to hold up.  Really, really interesting stuff.  Fascinating, actually.



And I hope people get to see - I've seen an Enigma machine in person.  Many museums have them.  There are quite a few extant still, probably a dozen.  But I'd love to go to Bletchley Park someday.  And they have quite a nice online site describing a lot of this.  Very different from the movie, I'm sad to say.  Now that I've seen all the discrepancies in the movie, it takes some of the joy I felt in watching it.  It's a wonderful movie, but not a piece of history, unfortunately.



STEVE:  Yeah, yeah.



LEO:  Thank you, Steve.  I appreciate it.



STEVE:  My pleasure.  And we've got a nice podcast, and we've got a Q&A next week.



LEO:  So go to GRC.com/feedback.  That's where you can ask those questions.  While you're there, get SpinRite, world's finest hard drive maintenance utility, and all the freebies Steve gives away all the time.  And of course 16Kb versions of the audio of this show, plus transcriptions.  I saw that Elaine Farris, your transcriptionist, has put out an EPUB book of our year-ender, or actually it was the New Year's, first show of the New Year, wasn't it.  Or was it the year-ender?  No, it was the year-ender that we did right before our New Year's Eve show, where you had all of the exploits in the year.



STEVE:  Ah, okay.



LEO:  Did you know she did that?



STEVE:  I did see that, yeah.



LEO:  Yeah, so that was nice.  And I don't know, I presume it's free, I don't know.  Anyway, I've tweeted it.



STEVE:  Oh, I'm sure, yeah.



LEO:  And but of course all this stuff is free from Steve's site, GRC.com.  We have high-quality audio and video at our site, TWiT.tv/sn, and of course on all the podcatchers.  Security Now!, one of the oldest podcasts in the world, so it's easy to find on iTunes and everywhere else.  And I'm happy to say that Mark Lane has released a new version of TWiT Pro for Android that has v3.0.  So we have - and by the way, these are all independently designed and developed by our, you know, volunteers who just do this for fun.  But TWiT Pro just got updated.  And of course Craig Mullaney does a great job with the TWiT apps on iOS.  He also did a Roku app for us.  So lots of ways to watch, even on Windows Phone.



So please do watch and participate and subscribe and be back here next Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC for a great Security Now!.  We'll see you later, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#491

DATE:		January 20, 2015

TITLE:		Cryptographic Backdoors

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-491.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Following this slow week of security news, Leo and I first discuss the news surrounding how and why the U.S. was so sure that North Korea was behind the attack on Sony.  Then we examine the cryptographic consequences of the British and U.S. governments' recent pronouncements that terrorist communications should not be allowed to remain secret.



SHOW TEASE:  It's time for Security Now!.  Leo Laporte and Steve Gibson.  Coming up we've got a little bit of security news, and then Steve is going to do something quite surprising.  He's going to go against his better political interests and judgment and actually explain why a cryptographic backdoor isn't necessarily a bad idea.  You know what?  He's right.  Stay tuned.  Steve Gibson and Security Now! up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 491, recorded January 20, 2015:  Cryptographic Backdoors.



It's time for Security Now!, the show that protects you, your loved ones, and your privacy, and your security.  And here he is, the Explainer in Chief.  We're going to call you the Security Czar here at TWiT, Steve Gibson.



STEVE GIBSON:  Oh, lord.  Okay.  I'll accept the title.  The Czar.



LEO:  You know, I was watching - it's amazing.  Here we are, almost 18 months since the original Snowden leaks, and there are more every day.



STEVE:  That's the top of our news is - we didn't have much happen in this last week.  It was relatively quiet.  But what few things we did were big.  I should explain to our listeners that I've delayed the Q&A that I had planned because for the last week I've been listening to all of the popular press, well meaning though they are, not being cryptographers, going nuts about the concept of the government mandating backdoors and how it weakens security.  So that's the topic for today is cryptographic backdoors in the context of Cameron's and then of course our U.S. President Barack Obama's echoing of this sort of vaguely stated intent.



But what I want to do is I want to get correct about the technology because that's what we do here.  And everybody's got that wrong.  It does not weaken anything to give the government access.  That is, it doesn't have to.  It shouldn't.  And so what I want to do is I want to separate out the question of policy, which is absolutely a topic of debate, and discuss it with you some more, Leo, because we sort of kind of rushed through it last week and really didn't have a chance to look at the many different aspects of it.  But I want to separate that from the technology because that's math.  And we can give the government any kind of access we have to, if we have to.  And I want to talk about, separately, the technology tradeoffs about that and how the fact is that, I mean, compelling as the term "backdoor" is, it's possible to have multiple front doors and for them to be every bit as secure as the security we have now.



Other than that, I want to talk a little bit about why the other - sort of like the only other big piece of news that occurred in the last week was we found out why it was that Barack Obama, during his final press conference of the year that we talked about last week, seemed so confident in pointing the finger at North Korea as he took off for his vacation to Hawaii.  I have some sci-fi thoughts and recommendations, and then we'll get into our content.  So I think, once again, a good podcast for everybody.



LEO:  Lots to talk about.  I was watching, and I recommend, it must have been a year ago, the "Frontline" piece, there actually were two pieces on the Snowden revelations and the NSA, they call it "the program" for capturing all the data.  And it's really well done, balanced, and a fascinating piece.  So I'm very interested in all of this.  And I have to say, I among everybody else have been kind of uncritically saying, well, a backdoor makes the software broken.  So I'm very interested in what you have to say there.  And in fact...



STEVE:  Well, and you're not...



LEO:  ...as soon as you mentioned that, I realized, of course, you could just give a key.  You could have two private keys and give one to the government.  But people like Cory Doctorow, knowledgeable fellow, that was his chief, in fact I think probably most of the people like EFF, that was their chief complaint, is that backdoor breaks the code.  So I'm very interested in what you have to say about that.



STEVE:  Yeah.  And so, yeah, because we're about technology here, I wanted to clarify that, yeah, and separate that aspect from the politics.  But the politics are fascinating, too.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  So we'll talk about all of that.



LEO:  All right.  News of the week, I guess.



STEVE:  So, yeah.  In a very light news week, we had one really interesting tidbit, which was the news was broken by an investigative reporter named David Sanger, who writes for The New York Times.  I saw him interviewed yesterday.  His story appeared in the Times yesterday.  Headline was "NSA Tapped Into North Korean Networks Before the Sony Attack, Officials Say."  And so my own headline for the podcast for this was "Let's Don't Underestimate the NSA."  I think maybe there's sort of a tendency to think well, it's sort of big and bureaucratic and, you know, stumbling over their own feet.  But the technology that's evidenced in the document - there was sort of a companion document that Der Spiegel published.  I have a link to it.  Actually I made a bit.ly link for the show, bit.ly/sn-491.  And that takes you to a three-page PDF which is a couple pages from what looks like an online conversation.  Anyway, I'll get to that in a second.



I first tried to sort of, like, paraphrase what David wrote.  And I thought, okay, I can just do a better job if I just share just the first opening four paragraphs of what he wrote.  He said:  "The trail that led American officials to blame North Korea for the destructive cyber attack on Sony Pictures Entertainment in November winds back to 2010," so four years ago...



LEO:  According to unnamed government sources.  Very important to point that out.



STEVE:  Correct.  He said:  "...when the National Security Agency scrambled to break into the computer systems of a country considered one of the most impenetrable targets on Earth.  Spurred by growing concern about North Korea's maturing capabilities, the American spy agency drilled into the Chinese networks that connect North Korea to the outside world, picked through connections in Malaysia favored by North Korean hackers, and penetrated directly into the North with the help of South Korea and other American allies, according to former United States and foreign officials, computer experts later briefed on the operations, and a newly disclosed NSA document."



He said:  "A classified security agency program expanded into an ambitious effort, officials said, to place malware that could track the internal workings of many of the computers and networks used by the North's hackers, a force that South Korea's military recently said numbers roughly 6,000 people.  Most are commanded by the country's main intelligence service, called the Reconnaissance General Bureau, and Bureau 121, its secretive hacking unit with a large outpost in China."



Okay.  So what's really interesting is the dialogue in the document that David refers to which Der Spiegel published, which is a sort of a snippet of top-secret, marked as such, conversation where somebody wonders about the term "fifth-party collection."  Like, what's fifth-party collection?  And so it poses the question, is there fifth-party collection?  And some individual responds yes.  "There was a project that I was working last year," and we don't have any dates here, so this sounds like this is the four-years-ago, 2010 timeframe.  "There was a project that I," says this writer, who's anonymous here, we don't have his name, either, or hers, "I was working last year with regard to the South Korean CNE program."  CNE, of course, is the acronym for Computer Network Exploitation, sort of general penetration and exploitation.



"While we aren't super interested in [he writes] SK (South Korea)," and then in parens "(things changed a bit when they started targeting us a bit more), we were interested in North Korea, and SK puts a lot of resources against them.  At that point our access to NK was next to nothing, but we were able to make some inroads to the South Korea CNE program.  We found a few instances where there were North Korean officials with South Korean implants on their boxes, so we got on the exfil points and sucked back the data.  That's fourth party.  However, some of the individuals that South Korea was targeting were also part of the North Korean CNE program.  So I guess that would be the fifth-party collect you were talking about.



"But once that started happening, we ramped up efforts to target North Korea ourselves."  And then he says, "(as you don't want to rely on an untrusted actor to do your work for you)."  Meaning they weren't content to continue essentially looping through South Korea to get to, like, South Korea's penetration into North Korea to get to North Korea.  Our NSA wanted our own direct connections.  So they said, "But some of the work that was done there was able to help us gain access.  I know of another instance, [and he says] I'll be more vague because I believe there are more compartments involved, and parts are probably NF," whatever that stands for, "where there was an actor we were going against.  We realized there was another actor that was also going against them," meaning North Korea, "and having great success because of a zero-day they wrote.  We got the zero-day out of passive and were able to repurpose it.  Big win.  But they were all still referred to as fourth-party."



So anyway, that's a snippet of sort of what appears to be internal NSA dialogue among people who have certainly a high degree of privilege to what's going on, where they're saying that, by initially getting in through some South Korean connections into North Korea, our networks, the NSA, had probes in North Korea.  And so the balance of David's story, where he's explaining essentially what we now believe is going on, is that the U.S. was able to be very rapidly definitive, much more so than anyone in the security community believed.  All we had was, oh, well, they were using some IP addresses.  And unfortunately, while that might make the general public happy, those of us who knew better, knew that these were, like, widely known proxies that...



LEO:  I just - I've got to say this, Steve.  I can't let you go farther with that.



STEVE:  Okay.



LEO:  This guy Sanger was the same guy who told us that there were weapons of mass destruction in Iraq based on anonymous government sources.  He has been a channel in The New York Times for anonymous government sources before which are not credible because it's basically - he's repeating government propaganda.  Now, the Snowden leaks no one questions.



STEVE:  Right.



LEO:  And I think rightly so.  So the theoretical possibility of this being true is actually very high.  But I would not credit that New York Times article in the least.  And I'm not alone.  There's a very strong opinion piece on Errata Security by Robert Graham...



STEVE:  Ah, yes.  We know him.  



LEO:  ...whom we know well, who says this is just not credible.  It may be true; it may not be.  But when you get anonymous tips from government sources, it's not journalism to rehash them.  It's merely repeating government propaganda.  It's misinformation.



STEVE:  Interesting, yeah.



LEO:  Just thought I'd point that out.



STEVE:  No, I'm glad.



LEO:  Before we get too enamored of it.



STEVE:  For context.



LEO:  Yeah.  I mean, the Snowden stuff I completely credit.  In fact, there was even some speculation in the past that that wasn't real.  But I think we pretty much agree now there's no way that could be faked.



STEVE:  No, no.



LEO:  And I trust Der Spiegel.  But I don't know if you can trust this New York Times article.  It kind of - so I've always said, well, why would the President and the FBI lie?  And what Robert Graham says is just exactly like the run-up to war in Iraq.  And in fact it's the same reporter at The New York Times who has the information.  This guy has a history, a track record.  And when the U.S. government decides it wants to do a little saber-rattling...



STEVE:  Yeah, good point.



LEO:  ...he's the first person they call.  So it doesn't confirm, it doesn't really confirm, in my opinion, this information.



STEVE:  Right.



LEO:  Although we obviously do have the means.



STEVE:  Yeah.  And I guess it feels to me like it's, from a technical standpoint, the internal NSA document feels right.  I mean, it seems credible.  It's somebody who feels like he's discussing among a trusted peer the kind of operation that they have in various facilities around the world able to do this kind of stuff.  So again, you're right.  We don't know one way or the other.



LEO:  According to - this is Sanger.  According to the officials and experts who spoke on the condition of anonymity - that always should be a red flag, when you read that.  And he doesn't have any public, you know, anybody besides the Snowden documents to publicly confirm that.



STEVE:  Right.



LEO:  And in fact all he's got is a quote from a cyberwarfare expert who says, "Attributing where attacks come is incredibly difficult and slow."



STEVE:  And that's what we've said from the beginning, is that it's just - it's so difficult to know definitively.  And we've asked the question, was there information that the government had, that it wasn't disclosing, that allowed it to state as definitively as it did that North Korea was behind the attacks?



LEO:  And to further muddy it, you've got that bastion of credibility, General James Clapper, who says, "Oh, yeah, I had dinner with the guy last fall, you know, the guy who did the attack."  So come on.  This seems a little self-serving on their part.



STEVE:  Yeah, especially Clapper.  You know how I feel about him.  We played the video...



LEO:  He's already lied to us.  He lied to us once.



STEVE:  Yeah.  We played the video of him saying, "No, we're not spying on anybody, no, sir," while he was scratching his head and, like, which looked like a bad poker tell.  Okay.  So I wanted to share with our listeners my complete amazement over the fact that there appears to be a fabulous series starting on the Syfy Channel, which I know sounds like an oxymoron, I mean, that phrase, because I'm very picky about science fiction.  And so it aired for the first time Friday, the first episode.  First of all, the title is "12 Monkeys," which of course is a famous piece of science fiction...



LEO:  Loved that movie.



STEVE:  ...that Terry Gilliam - yes, yes.  People who have seen now the first hour episode think this blows the movie away.  And I don't know where this came from because it is so unlike anything else that Syfy Channel typically airs in that it's really good.  And I just - I hope it maintains.  But I know we have tons of sci-fi interested listeners.  So I wanted to make sure that everyone at least knew that this - I'm sure they'll be reairing it through the week, and the second episode will be this coming Friday.  So "12 Monkeys" on the Syfy Channel.



I also saw, I don't know why, I guess it was because the Sunday shows were canceled for sports, I found myself poking around a little bit, looking for something to watch.  And there was a movie, a 2014 movie that was not well reviewed, called "Automata," A-U-T-O-M-A-T-A.  And, I mean, it's off of the chart.  It's Antonio Banderas, Dylan McDermott, and a barely recognizable Melanie Griffith.  I remember I was looking at her, thinking, is that Melanie Griffith?  Of course I don't think I have seen her since "Working Girl," so that's been a few decades.



LEO:  Yeah.



STEVE:  Anyway, the movie was kind of haunting.  It's only $3.99 on Amazon Instant Video, and I'm sure you can find it on whatever your source of movies is.  Anyway, I provisionally recommend it.  I don't want to get anyone's hopes up too much.  I mean, it's got some rough spots.  But there's a lot of it that's well done.  And even the critics who didn't like it said, well, you know, it's got its moments.  And it's interesting.  And it actually comes - I've thought of it again because toward the end of MacBreak Weekly, or maybe it was in between shows, you were talking about this question of what happens as computers get more intelligent.  And the concerns that some legitimate computer scientists like Kurzweil and so forth, Kurzweil I guess his name is, have, like, their worry about what happens when we actually succeed in making machines intelligent.



LEO:  Oh, a lot of people worried about that, yeah.



STEVE:  Yes, and this is in...



LEO:  Including Elon Musk.



STEVE:  So this is set, yes, this is set in sort of the post-apocalyptic, the sun has overheated, and the earth is sort of hostile to people, so we create machines in order to do a lot of the work.  And they kind of get loose.  Anyway, again, "Automata," 109 minutes long, not very, I mean, it's not fabulous.  That's why you haven't heard of it before.  But for our audience who are sort of forgiving because a lot of them do watch stuff on the Syfy Channel, I could recommend it for a few dollars.



LEO:  Apparently also on Netflix for free if you're already a subscriber.



STEVE:  Oh, yay, good.  Then in that case, give it a try because - and it has kind of a - you're not sure what's going on at the beginning.  It's sort of an awkward start.  But then you kind of get into the groove.  And I liked it, I have to say, and I find myself kind of thinking about it, like affected by it, which doesn't happen that often.



LEO:  Yeah, I use that as a metric.  Did I think about it the next day?



STEVE:  Exactly.



LEO:  Then, whether it was a great show or not, it stimulated some thought.



STEVE:  Yeah.  It had some good moments.  And speaking of a good moment - there's a transition for you, a segue.  In the middle of December - I just ran across this in my email from Sue, she forwarded it to me - from a Jarred Sutherland.  The subject was "Whew!  SpinRite Success Story."  And he said:  "Steve, I've been listening to Security Now! for several years now and have been a fan of your site and research well before that time.  I finally had a need for SpinRite for a friend whose Seagate drive which contained very important data went completely belly-up.  Now, this made me panic for a very specific reason.  I configured backups for this system, but missed a poorly placed directory."  And he has in parens, "(online backup over a slower connection, so I was selective about which folders were chosen)."  Which is to say he wasn't backing up the entire drive.  He said, okay, I will back up the documents directory and so on, but there was one that got away from him.



He said, "So I was able to restore most of the data I needed from the backup, but not this particular crucial chunk.  I was sunk, or so I thought.  A combination of SpinRite on Level 2 and a bit of fridge time allowed me to mount this drive on my MacBook and pull the data off just in time.  SpinRite saved my bacon.  What a fantastic piece of software you have here.  I will pass along my recommendation to any and all who end up in a position like me, or who don't want to by keeping a good eye on their drive.  Thank you!!! [three exclamation points] Jarred Sutherland."



LEO:  Nice.



STEVE:  And it's interesting because his mentioning the fridge reminded me that one of - we're sort of beyond this point now.  But one of the arguments that we encountered early in the days of SpinRite was how could software fix hardware?  It was like, I mean, skeptics were saying, you know, wait a minute.  If the drive's bad, then software can't fix it.  And of course we know that the reality is that there's a large band of gray between good and bad on hard drives, and that they actually deliberately operate kind of in the gray, relying on error correction to sort of keep them from going too deep into the gray or crossing into the dark.  And that essentially the drive and the OS and everybody will give up and just say, okay, it's too gray.  SpinRite comes along and says nothing is too gray.  Unless it's really not even spinning any longer, we're going to pull that one last time back from the dark, into the light.



And of course SpinRite's able to do that.  There are some instances where the drive has sort of crossed over.  And one of the tricks is you change the temperature.  You stick it in the fridge for half a day or a few hours, just to sort of throw in another variable.  It's like the drive is normally running hot, and we can't get the data, so let's cool it off.  And then you quickly plug it in and see if you can run SpinRite on it again, like in the area where it had a problem, or just start it over and sort of introduce temperature as another thing to try.  I mean, at this point we're getting desperate.  So refrigerator, fine. And sometimes, as many people have found, that's like the final little bit of magic to bring it back from crossing over to...



LEO:  To the other side.



STEVE:  To the other side, exactly.  So anyway, Jarred, thanks for sharing and reminding everybody about SpinRite.



So we've never - we're in our 10th year of the podcast - expressly talked about backdoors.  We refer to them many times sort of in an offhand fashion or tangentially, relative to something else.  Like famously we were talking last year about this notion of a backdoor when we discovered that that dual elliptic curve digital random bit generator, remember the DRBG, when it was one of the four different algorithms in the NIST formal suite of pseudorandom number generators that was approved, and we started to wonder about where it came from and whether it was trusted because it sort of had appeared in our products, and it was slower than the other ones and had sort of an unknown back story.



So anyway, so then the reason this sort of came to the fore for me is, of course, in the last week, after the Paris attacks, as we just talked about last week, David Cameron has famously been running all over the place talking about how terrorists should not be allowed to communicate in a way that the government cannot decrypt if it wants to.  And as I understand it, his statement has been stronger than the one the U.S. President Barack Obama echoed.  Cameron came to the states, and they were together, and essentially Obama was saying something similar, although maybe not quite going as far as to say that we're going to have legislation to do this which, as I understand it, Cameron has been saying.



LEO:  I think the President was a little bit cagey about how he supported this, yeah.



STEVE:  Right, right.  And I want to talk about...



LEO:  And, by the way, it would be terrible for U.S. tech companies like Microsoft and Apple and Google because who's going to want to use software with a backdoor?



STEVE:  Well, and, see, perfect segue because the backdoor is the term that everybody uses except, like, Barack never said that; Cameron never said it.  No one has ever used the term "backdoor" except those reporting on this.  And one of the problems, I think, is that that's the term we have.  First of all, we've talked about how, when you, for example, have an exploit named Heartbleed, you give it a fun name, it gets a lot more traction than if it's some CVE numerical designation that no one can remember.  And there's just this - there's a rich, deep history of backdoors in mystery novels and in sci-fi.  And it has this...



LEO:  You might remember this moment in a little movie called "WarGames."



MALE VOICE:  I want you to take a look at this.



LEO:  I think they talk about a backdoor here.



STEVE:  Yeah.



MALE VOICE:  Hey, what's that?



MALE VOICE:  I wanted Jim to see that.



LEO:  No truth to the rumor that that's Chris Pirillo.



MALE VOICE:  Wow, where did you get this?



MALE VOICE:  I was trying to break into Protovision.  I wanted to see the program for their new games.



MALE VOICE:  Wait, Jim, I'm not through yet.



MALE VOICE:  Remember you told me to tell you when you were acting rudely and insensitively?  Remember that?  You're doing it right now.



STEVE:  And a young Matthew Broderick.



LEO:  Yeah.



MALE VOICE:  Theaterwide biotoxic and chemical warfare.  This didn't come from Protovision.



MALE VOICE:  You bet it didn't.  Ask them where it did come from, Jim.  Go ahead, ask them.



MALE VOICE:  I told you already.



MALE VOICE:  Looks military to me, definitely military.  Probably classified, too.



MALE VOICE:  Yeah, but if it's military, why does it have games like Checkers and Backgammon?



MALE VOICE:  Maybe because those are games that teach basic strategy.



MALE VOICE:  Jim, how do I get into that system?  I want to play those games.



MALE VOICE:  You're not supposed to see any of that stuff.  That system probably [unintelligible] their data encryption algorithm.  You'll never get in there.



MALE VOICE:  Hey, I don't believe that any system is totally secure.



LEO:  I love this kid.



MALE VOICE:  I bet you Jim could get in.



MALE VOICE:  Yeah, I'll bet you he couldn't.



MALE VOICE:  I bet you he could.



MALE VOICE:  Well, you'll never get in through the frontline security.  But you might look for a backdoor.



LEO:  A backdoor.



STEVE:  Okay.  So, perfect segue.  In computing, a backdoor is a method of bypassing the normal method of authentication.  So whatever it is, it's a method of bypassing the normal method of authentication.  A cryptographic backdoor is a secret.  And I put in here, I was going to say a secret known only to the algorithm designer.  And I put "initially" in parens, to highlight the fact that the problem is that of needing to keep a secret.  So a cryptographic backdoor is a secret (initially) known only to the algorithm's designers or implementers.  And being a backdoor, the knowledge of that secret allows some aspects of the difficulty of decrypting the encrypted content to be bypassed, thus substantially weakening the algorithm's guarantee or promise of security.



So a perfect example was if, for example, that dual elliptic curve deterministic random bit generator had been designed to be weak, then there would be some characteristics of it which, to be a good backdoor, would withstand direct scrutiny.  Other experts could look at it and scratch their head and say, yeah, looks okay to me.  And yet there would be some properties of it which would elude observation such that the people who knew the secret would have an advantage in some fashion, based on the purpose for which those random numbers were employed.  So everybody has been correct in asserting that a backdoor, per se, weakens security.  And we know that because what that says is that there's a secret, and secrets are notoriously difficult to keep such that, if it became known, then the security can to some degree be bypassed.



So the clip from "WarGames" is another perfect example.  If there was a backdoor, then somebody installed it there, and these kids were going to attempt to discover it in order to go through the backdoor, the idea being that it's like it's another way in.  But part of that is that it's not another front door.  That is, it's not a sanctioned means for decrypting the content.  It's secret.  And when we were talking about Enigma last week, one of the strongest aspects of the Enigma technology was that the Polish mathematicians managed through a great amount of skill to reverse-engineer the entire machine itself, based on enough samples of its output.  And yet, even having the machine, because it was a keyed cipher machine, if they didn't have the key, then having the mechanism didn't help them.  So what's different here is a backdoor sort of breaks that rule.  It says there is a secret defect that can be exploited to allow someone to essentially bypass the need for the key.



So the point is, the main issue that I wanted to bring up, and there's a lot to talk about this, is that absolutely nothing prevents current crypto from operating with multiple keys.  And in fact we do that now.  We believe that the way iMessage works is that every user of iMessage has a private key which never leaves their device.  It's generated in their device as a public key pair composed of a private key and a public key, are generated in the cryptographic element, the secure element in the iPhone, and the private key never leaves.  The public key is sent to Apple for key management.  And when you are generating a message that is intended for multiple recipients, that message contains multiple keys.



Now, remember that public key crypto isn't used for bulk encryption because it's just way too slow.  So this is why we also need, for cryptography, a source of really good random numbers.  So we have a really good random number generator.  We choose a random number which is used to encrypt the message.  And then that random number is encrypted with the public key of the intended recipient because only the person who has the matching private key can decrypt that random number back to what it was and then use symmetric encryption, or decryption in this case, to get the message back.



The point is that this makes encrypting for multiple recipients possible because you take that one random number, and you encrypt it first with one recipient's public key and attach that to the front of the message.  Then you take again the unencrypted random number and encrypt it with a different recipient's public key and attach it, and then with a third, and so forth.  So you can arrange to send a message that contains essentially multiple addressees, for lack of a better term, the point being that, when the message is received, the recipient will have the ability to decrypt one of those multiple keys to get the original random number which was used to encrypt the message and thus decrypt it.



So I'm not - and I want to make sure everyone understands, I'm not advocating this at all.  I mean, as everyone knows, I aborted CryptoLink, the work I was going to do on a VPN, specifically because there was a threat that something like this could be coming along.  And at this point in the evolution of information technology and networking, we're sort of at an inflection point, I think.  I mean, it'll be interesting to see how the next few years go because the one argument that cannot actually be made is that necessarily allowing the government access, some means of access to our communications, weakens it.



Now, the problem is also that - and you'll probably remember the exact phrase, Leo.  I couldn't remember what it was.  But it's something, there's an old saying, something like once you tell one other person a secret, it's no longer a secret.



LEO:  Another great Ben Franklin quote, I'd say.



STEVE:  Something like that.  And so we cannot argue against the fact that there's a tremendous burden of responsibility associated with managing this.  But here's the way it would work, just to, like, lay out the theoretical framework.  And that is that the U.S. government, I'm sure the NSA or the FBI, somebody who knew what they were doing - law enforcement, broadly - would create a master public key pair.  The private key would be well guarded.  The public key everyone would know.  That is, that would be - it would be like, you know, go to the website.  Download our public key.



And so in this - and again, I want to make sure everyone understands I am not advocating this.  I'm just - we have to talk about the technology separate from the ethics and all the politics and everything else.  But the technology would be that, presumably, a law would have been established which does require that any legal encrypted traffic be decryptable by duly empowered law enforcement.  And the technical means for achieving that would be that, when we're going through the process of any, quote, "legal" under this draconian law, but still, if it happens, the way we do that is, while we're going through this process, in that keying phase, the U.S. government's public key is used also to redundantly encrypt the symmetric key, and that's part of the payload of the message.  So it is as secure as the math, subject, of course, to the management of this key.



So we don't have a secret like the "WarGames" guys or like the classic notion of a backdoor.  What we have is a redundant keying of all legal cryptography.  And I'm being careful with my phraseology because we'll talk about the point you raised last week, Leo, that, well, the bad guys won't use that.  Of course they'll use illegal cryptography or cryptography which cannot be decrypted, which does exist and will always exist.  And hopefully this argument will keep this draconian "1984" Big Brother crypto from ever happening.



But just as a matter of technology, then, the idea would be that this cryptography that was legal under this draconian law would all carry a key that could be decrypted only by the U.S. government's law enforcement private key, which they would have to keep absolutely secret.  And presumably there would be some process.  The NSA would do bulk data collection of maybe everybody.  And then when they recognize that some terrorists have been operating under their nose, they would pull the communications from that group of people and pull the headers off the packets, send that somewhere to have those keys decrypted, and then get them back, and then be able to decrypt back into plaintext.  I mean, it's burdensome.  But anyway, my main motivation was just to bring the point up that we don't need a backdoor because the technology we have today could allow that.



So this is obviously still fraught with problems because, as you immediately mentioned correctly last week, it is math.  And if there are, quote, "legal" cryptographic systems under such a law, all that will do is it will create an underground of cryptographic systems that don't have the government key on it, for anybody who wants to encrypt data that can't be decrypted under this technology.



LEO:  This is actually Skipjack, which was, is, a crypto system proposed by the NSA.  Remember the Clipper Chip, which is, by the way, despite all the hoorah about it, in our TVs today.  But that used Skipjack.  And the idea was there was an escrow process for a second government key, and that that key would be held in escrow and would need legal authorization for releasing.  I'm going to put...



STEVE:  Yeah, and...



LEO:  Go ahead.



STEVE:  And that's a very good point.  In my model, there's one super galactic master government key.  But a safer way to do this would be, for example, if Apple wanted to do commercial cryptography for the privacy of its users, subject to such a law, then they could give the government an Apple iMessage private key, and then the Apple technology would always incorporate the matching public key as an additional key in Apple communications.  And similarly Google could do it.  And the point is anybody who wanted, any commercial entity that wanted to sell crypto in this climate could produce a public key pair and turn over the private key to law enforcement agencies so that they're able to decrypt the traffic, given proper means and needs and protocol and so forth.



LEO:  I guess, you know, it reminds me of this conversation over Skipjack.  And one of the issues - I'm looking at a testimony from 19, I don't know, '94, I think, from Whit Diffie, '93, about Skipjack.  And one of the things he points out is that - and he doesn't have a problem with the key escrow.  But he says, if you don't make the algorithm for Skipjack public, it can't be vetted by - we've talked about this many times - can't be vetted by crypto experts, and therefore we can't be sure it's secure.



STEVE:  Yeah.  And so that was 22 years ago or 23 years ago, back when we were sort of still thinking of - remember that, like, RSA, the famous RC4 cipher that has now been discredited because of the way it was implemented in the early WEP WiFi, that was a secret.  It was proprietary.  There was a time when these algorithms were not published, were not vetted by the academic or the crypto community.  And we just sort of had to trust that they were good.  And the good news is we're past that point now.  Now we've got highly vetted, scrutinized, I mean, we're actually - we're using public competitions in order to choose what the next cipher will be.  So arguably as democratic and academic a process as we've been able to come up with so far, where, again, it's the algorithm itself is solid, and it's the key that is the secret, which is much stronger crypto.



So what do you think is going to happen, Leo?  I mean, you're as clued in to all of what's going on as any of us.



LEO:  Well, I don't know about that.  I know you listened to our conversation on TWiT with Iain Thomson.



STEVE:  Oh, my god.  I also wanted to say, fabulous panel on TWiT on Sunday [TWiT-493].  Really, really good...



LEO:  So Iain Thomson of The Register.  And he's a Brit, of course, and gave us kind of the British perspective on why Cameron would say such a thing, whether it's political or real, et cetera.  We had Ben Thompson from Taipei, Taiwan.  He's probably the smartest analyst out there.



STEVE:  They're really, really smart.



LEO:  Isn't he great?



STEVE:  Really sharp.



LEO:  His website, Stratechery, is for me must-read stuff.  And they're just so great, so smart, and it was a lot of fun.  And who was the third?  Now I've forgotten.  I got Ben - it was the two Thom(p)sons, the Thom(p)son Twins.



STEVE:  A gal.



LEO:  Oh, of course, Serenity Caldwell, the great Serenity Caldwell for iMore.  So, yeah, I thought it was a good conversation.  And Iain, you know, I said, "Iain, does Cameron mean this to be a law?"  And he said he thinks he does.  I said, "There's certainly political motivations."  You know, his party is being pushed from the right by Ukip and others.  And so you want to look strong on terrorism.  But I think the consensus was that perhaps Cameron doesn't understand the technological issues.



But I have to say, I just accepted uncritically this idea that a backdoor weakens encryption.  I mean, if Cory Doctorow says it, it must be true.  But you're absolutely right.  When you started the show I said, well, wait a minute.  Let me do the thought experiment.



STEVE:  Right.



LEO:  Of course you could have some sort of secure key escrow.  We'd have to trust that this escrow systems works and doesn't have leaks.  But if you believe that strong encryption is effective, hackers are no more likely to break that than your key.



STEVE:  Right.



LEO:  A private key's a private key.



STEVE:  And one thing, one thought I had was whether posing the question, isn't metadata enough, that is, we've argued that metadata is a big intrusion as it is, even without knowing what the conversation is.  Knowing what the network of connected people are is a huge intrusion.  And I wonder if that's not enough of a compromise.



But I listen to the talk.  I'm an avid politico.  I follow politics.  I listen to these guys talking and this argument of, wow, how can we allow conversations to occur that we can't monitor?  And, I mean, we know how.  We believe that there are other means for acquiring that same information, you know, plant bugs in the people's machines, microphones near them, I mean, do other things rather than just the opportunity for wholesale decryption of everyone's private communications.  But I just - I don't have much faith in the understanding of how intrusive that would be within our lawmakers.



LEO:  Yeah.  I think that's the problem.  And it's not going to take long before somebody, if they haven't already, pulls Cameron or Obama aside and says, "Excuse me, you understand that this would be devastating for the economy of U.K. or the United States, that no one would buy products from the United States ever again?"  I mean, it's just - I think it's a nonstarter.  Although I've had lots of email and tweets from listeners in the U.K. who say, "Oh, you don't understand, they mean to do this."  And even Iain Thomson said nobody probably would have believed the proposal a few years ago that all Internet traffic be filtered in the U.K., and it is.  So, yeah, maybe, I mean, I don't - maybe it is something that they could do.  But, boy, they'd have to isolate themselves as a country.



STEVE:  And we do know, for example, that corporations are increasingly proxying their networks with hardware that allows them to inspect in the SSL the TLS traffic of all of their users.  That's happening because more and more traffic on the Internet is becoming encrypted.  And it's just not feasible for a corporation not to be able to see into the traffic that is entering its corporate network.  So they're intercepting with HTTPS proxies in order to perform malware and traffic inspection increasingly.  And we know that there are educational systems that are doing the same thing.



So, I mean, it's tough.  In terms of legal processes, one of the things that I was imagining was that - imagine an environment where it is illegal to use encryption that cannot be turned into plaintext.  So that, if you do encrypt, then, if asked, you must be able to decrypt on demand or suffer the consequences of being unwilling to provide decryption for what's encrypted.  I mean, maybe that's sort of a half measure.



Anyway, it'll be interesting to see.  And mostly what I wanted to make the point was that, unfortunately, we really don't have the argument from an academic standpoint, from a technical standpoint, that giving the government access weakens our crypto.  It would be an additional layer of headache and management.  But if commercial entities doing crypto gave the government, you know, created a second key and gave the government a private key that allowed them access, that doesn't weaken it at all, unfortunately, subject to the need to manage that properly.  But we see people able to manage.  All of our certificate authorities are able to manage their...



LEO:  That's how it's done; right.



STEVE:  ...private keys so that no one else is able to get it.  Anyway, I wanted to put that on the radar because...



LEO:  I think you're right.  And that's why we love you, because you're a stickler for accuracy, even if you agree with the sentiment behind the inaccuracy.



STEVE:  Yes.



LEO:  Did you get this from Carey Parker?  I just wanted to mention this.  It's called "Firewalls Don't Stop Dragons."



STEVE:  No, interesting.



LEO:  Yeah.  He said he sent you one.  So he said he wasn't sure if he got the address.



STEVE:  It might have gone to our corporate mail...



LEO:  Probably did, which means you'll get it eventually.



STEVE:  Yes.



LEO:  "A Step-by-Step Guide to Computer Security for Non-Techies."  He writes, "As a software engineer, political junkie, and concerned citizen, I felt the need to do something about the current sorry state of affairs with regard to security and privacy.  I think most people are just too intimidated by technology, so they just throw their hands up."  So he's written a book on how to secure your computer, how to get your privacy.  He says, "I've been listening to Security Now! for probably four years.  I never miss an episode.  It was a real inspiration to me.  And I've included multiple references to Steve and the podcast in the book."



STEVE:  Ah.



LEO:  So that's cool.  He doesn't mention where you can get it.  I would hope it's on Amazon.  I think probably everything is.  And it looks pretty good.  I've just flipped through it.  I just got it while we were talking.  But he talks about LastPass and, you know, all the stuff that you need.  It seems like it would be a useful - how to create a master password.  And we talked about how to use a song lyric to create a password.



STEVE:  Yeah.



LEO:  And it's all in here.  So I think he's done, you know - two-step authentication.  I think he's done a great job.  And he's obviously been heavily influenced by you.  So...



STEVE:  Well, and it looks like the notion of firewalls is sort of a generic term because he's talking about all kinds of different...



LEO:  You've got to do something.  It's not about firewalls particularly, it's about how you've got to do more than just have a firewall or a - he talks about the "Christmas Story," "Be sure to drink your Ovaltine."  Remember that?  He used a secret decoder ring, and that's what the secret message was, "Drink your Ovaltine."  So I kind of like this, just flipping through it.  So I just thought I'd mention it, and since he is a fan, and he mentions the show.  It's called "Firewalls Don't Stop Dragons."  I think it's self-published by Carey, C-A-R-E-Y, Parker.



STEVE:  Nice.



LEO:  And thank you, Carey, for passing this along.  We probably should have saved it for the feedback episode because that's next week; right?



STEVE:  I'm sure we will - I didn't even look in the mailbag.  I wanted to, but when this issue of the backdoors came up, I thought, no, we have to just clarify that one technical issue that unfortunately we don't have that to fall back on.  So I'm sure there'll be lots of questions, maybe about Enigma.  That was a super popular episode last week.  So, yes, Q&A.  And then everybody wants the DeTor episode.



LEO:  Gotta do it.



STEVE:  Which, you know, it'll be the one that follows unless, you know, hell breaks loose in the meantime.  But believe me, it's like right there in my notes to talk about how much we can trust Tor.  Oh, and there it is on Amazon.



LEO:  It is on Amazon, $17.43.



STEVE:  Nice.



LEO:  Just came out.  And we were talking last week - I'm going to throw one more thing in, and then we're going to wrap it up.  We were talking last week about the historical inaccuracies in "The Imitation Game."  You and I both loved it as a movie.



STEVE:  Great movie.



LEO:  I'm sure it will - it was nominated for nine Academy Awards, I think.  Was that the one?  No, "Birdman" was.  But I think it was...



STEVE:  I think, like, seven.



LEO:  Yeah, quite a few, and Benedict Cumberbatch was nominated for Best Actor.  It was nominated as Best Picture.  But we did talk about the fact that in some ways it slanders Alan Turing's memory, which is sad, saying that he was a craven traitor, in effect.  So somebody in the chatroom said this, and I meant to mention it, "Cryptonomicon," which is my all-time favorite book, I mean, just the greatest book...



STEVE:  Neal Stephenson, yup.



LEO:  Brilliant guy, great writer, I mean, really one of our best writers.  And he happens to be technically super literate, super right on.  They talk about Enigma a lot in there in an historically accurate fashion.  So if you want a great novel that is about crypto, that is fun to read, I mean, it's something great, and it has quite a bit of Alan Turing and Enigma in there, it's "Cryptonomicon."  It's not a historical - well, it is, kind of.  It's a novel with historical stuff in it.



STEVE:  Yeah, and it's long.  It'll keep you going.



LEO:  It's so good.



STEVE:  It'll keep you going for a while.



LEO:  So good.  Hey, Steve, thank you so much.  Yes, feedback next week, god and hackers willing.  If the good lord's willing and the creeks don't rise, we'll do questions and answers next week.  You can ask your question at GRC.com/feedback.  Don't email Steve.  You can also tweet him, though.  He is @SGgrc on the Twitter.



STEVE:  I try to keep an eye on my feed and use that.



LEO:  Good way to interact with him.  And of course while you're at the site, GRC.com, pick up a copy of SpinRite, world's best  hard drive maintenance and recovery utility.  And then that's the only thing he charges for.  The rest of it, there's so much great stuff, and it's all free.  Lots of good information from the wide-ranging mind of Steve Gibson, GRC.com.  He also has 16Kb versions of this show.  He's got transcriptions there.  We have high-quality audio and video from the show at our site, TWiT.tv/sn, for Security Now!.  And of course you can always subscribe at your favorite podcast pavilion, iTunes or whatever you like to use.



Steve, have a great week.  Thank you for - I know politically you're on the side of people who hate this idea, this David Cameron idea.  But this is what I love about you.  The fact is a fact, and we've got to be honest about the facts.



STEVE:  Yeah.



LEO:  Thanks so much, Steve.  We'll talk again next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#492

DATE:		January 27, 2015

TITLE:		Listener Feedback #205

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-492.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll take a look at the security news.  Fortunately, no big panics.  But there is a great series of questions, 10 of them, from you.  Steve will answer.  We'll talk more about key escrow and more with Security Now!, next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 492, recorded January 27, 2015:  Your questions, Steve's answers, #205.



It's time for Security Now!, the show that protects you and your loved ones and your security and your privacy online with the guy who knows all, tells, all, he has a crystal ball, Mr. Steve Gibson of GRC.com.



STEVE GIBSON:  Kissing my microphone.  It's like right here in my face.



LEO:  Why are you kissing it?  Are you happy?



STEVE:  I'm happy, yeah.



LEO:  Hi, Steve.



STEVE:  Hey, Leo.  It's great to be with you again, as always in our 10th year of this weekly podcast.



LEO:  Jiminy Christmas.  Holy cow.



STEVE:  We finally do have a Q&A, since the world has left us alone.  It's really been actually kind of quiet on the security front.  There were a couple stories that just broke as I already had set up the podcast and made PDFs of notes and things.  So, for example, there's a Ghost vulnerability that's just been - just was published in something called Openwall that looks like it may have remote exploitation capabilities.  So we'll cover that next week.  I didn't want to run around and go crazy.



LEO:  Ghost is an open source firewall program?



STEVE:  Ghost actually is the name of the vulnerability.  You know, we have to give them good, catchy names now, so it's, yeah, that's...



LEO:  Right.  Openwall.  What's it called, Open...



STEVE:  Openwall.



LEO:  Openwall, okay.



STEVE:  Yeah.  Anyway, so we have a Q&A.  And I'm assuming that things are going to stay quiet, and we will finally next week discuss the deanonymization of Tor and what that's all about.  I've been calling that DeTor and promising it for quite a while, but we keep having holidays and new years and the Enigma Machine podcast that was very popular.  So we'll catch up with a Q&A this week.  A little bit of news.  Not too much, actually, has happened, but some interesting stuff.  And then we have great questions and some interesting points brought up by our listeners.



So I'm going to talk about a new marketplace that's open for Firefox; Google taking a bite out of Apple, also.  And I heard you guys talking on MacBreak Weekly about some recent Apple updates that I also cover.  And a note about Tim Cook and China.  And I also heard you mention Vivaldi, which I had a note here about.



LEO:  Yeah, yeah.



STEVE:  And I wanted to make a note to our listeners about the 10th Annual Podcast Awards.  They're not getting by me this year.  I thought, let's just swamp them.  Let's show them what crowd power can do.



LEO:  Yeah.  I'm not a big fan of the Podcast Awards;  but if you wish to win one, you go right ahead.



STEVE:  I like having them.  Why not, yeah.



LEO:  One year we won a significant number of them, and they removed us for political reasons.  So I'm not - I just ignore them now.



STEVE:  No kidding.



LEO:  Yeah.  You can win and not get an award.  So good luck.  Good luck with that.



STEVE:  Wow, wow.



LEO:  Actually, if everybody voted for Security Now! in every possible category, it'd be hard to ignore you; right?



STEVE:  It would be hard to ignore, yeah.  I figure security - wait.  I don't think there was security.  There was, oh, science and technology and education.  Although really we're not an - well, we're an educational podcast, but we're not a podcast about education.  So I don't know if there are podcasts about education, if that's what they mean.  But anyway...



LEO:  Yeah.  I'm boycotting this from now on.



STEVE:  Somebody tweeted that a new item had appeared under the Tools menu of Firefox.  And I was at Firefox v35 when I first went to Help, and it said, oh, restart for an update.  And that's like, oh, okay.  So I got a one thousandth update, or one millionth or something.  Anyway, I went up from 35 to 35.0.1, so hardly worth restarting.  But sure enough, on the Tools menu is a new apps item which simply takes you to marketplace.firefox.com, which is Mozilla's marketplace for Firefox stuff.  So it's a store that has lots of free stuff and also some for purchase, featuring apps designed for any device that runs either the Firefox OS or Firefox for Android or Firefox on any desktop.  And they just say that it makes finding favorites or new apps easy.  And, once purchased, you are able to use it across all of your Firefox devices and platforms.  So, you know, sort of like in the iOS model.



So anyway, I just wanted to point people at that.  I'm still, until Chrome solves the tabs problem, I am still over on Firefox.  And actually the footprint problem, when I launch Chrome, it just gobbles memory compared to Firefox.  So I'm still there, over on Firefox, and happy with 200 and some-odd tabs open.  So, yeah, I sort of use it as my messy bedroom of stuff that I want to get to.  I have tabs open from reference material that I was using when working on SpinRite 6.1, so that gives you a sense for, you know, SQRL took over, and we're now like at T plus 15 months of the SQRL project.  So those are dusty tabs, but Firefox is holding them open and knowing that I'm going to get back to them soon as I get SQRL wrapped.  And in fact I heard you talking about SQRL over the weekend.  A caller to your Tech Guy show asked about it.  So I just, you know, you and I will go back through this.  I will soon be demonstrating it.



LEO:  He wanted, as many have, to understand how it would look, how it would work from an end user's perspective.  And I have to say I'm still a little bit unclear about it, too.  I hope I didn't get it wrong.



STEVE:  No.  The one thing that's neat is that you need no browser extensions or plugins.  So you just run the SQRL client once on your desktop.  And that registers it to receive any SQRL URLs.  And then every browser you have automatically works.  And you don't need a smartphone.  You don't need a QR code.  But you can just click on the QR code which the website presents in case you wanted to use a smartphone.  But if you're on a desktop, you just click on the QR code, and you're logged in.  Up pops a little dialogue from the client that is there to make sure you're you and not one of your kids or somebody.  There's this new term that I hate, it's called the Evil Maid attack.  In fact, the whole problem with Thunderstrike and Thunderbolt on the Apple is they've designated this an Evil Maid attack, meaning that it's an attack that an evil housecleaner could accomplish.  It's like, oh, do we really have to call it the Evil Maid?



LEO:  I think it's tongue-in-cheek, but yeah.



STEVE:  No, it's like it's the term.



LEO:  So I did misstate it a little bit.  So what I didn't understand is, so if you run the app on your computer, it registers - is it sqrl://?



STEVE:  Yeah, yeah.



LEO:  It registers a protocol for SQRL.  I think that's not commonly known is that there are many different protocols besides http://.



STEVE:  The famous one is mailto.  You can have a mailto link, and that launches your email client with, like, oftentimes the subject and the to and from and so forth filled in.



LEO:  So if you have this, if you download an app, you run it, I presume it generates kind of a unique userID for you; right?  Is that what it does?



STEVE:  Yeah.



LEO:  And it registers the protocol, the SQRL protocol.  Do you have to keep the app on there?  Or can you at that point delete the app?



STEVE:  No, the app is there to...



LEO:  I think on most operating systems you have to because it has to run when you...



STEVE:  Exactly, yeah.  And so it sits in the tray as a little icon.  And so you create an identity the first time you run it.  And it's sort of the thing where you have to see it to believe it.  I mean, the demo has been running.  I have it down at the moment while I'm rewriting a chunk of code.  But users in our newsgroup have been playing with it for maybe about a week and a half.  And one person wrote, he said, "You know, Steve, I knew what this was, I knew what it was going to be, but it takes my breath away to imagine that something this simple is also secure."  Because that identity you create can potentially be the only identity you ever need for the rest of your life.  And it just allows you to log in.



And of course you're right that the question is will this get adopted.  There was a great blog posting that came to my attention yesterday, that'll go public on Thursday, where people are beginning to look at this and get it.  And so my position was, with this concept, I just had to give it a chance.  I have no horse in the race.  I'm not making any money, as you did say yesterday to that caller.  I just couldn't have this and not give it a chance.  I mean, it blows FIDO away. The guy who designed FIDO said SQRL blows it away.  So we'll see, you know.  Anyway, it'll...



LEO:  It requires, and this is what I said, it requires. unfortunately. companies with their own stake in all of this, unlike you, to adopt it.  I mean, if Google and Yahoo! and Facebook don't adopt it, and they all have their own kind of, well, not Yahoo!, but Google and Facebook have their own authentication stuff they want to do, then it makes it hard for it to succeed.  But I guess a ton of independent websites could adopt it.  There's no reason...



STEVE:  I've already got queries coming from independent websites.  We've got a group who have a full Drupal drop-in library so that any Drupal site can just add this side by side.  The idea is that it doesn't replace username and password.  It just sits next to it.  And so the way I have felt this would happen is that there are so many sites where they would like you to create an account, but they're just not worth it to the user.  How many times have we looked at, like, seen somebody's blog posting and gone to reply, and it wants you to create an account.  It's like your email address and all of that, and you just think, no, I've got too many accounts.  I don't want to have to come up with another password and username and blah blah blah.  So that kind of site, or all of those kinds of sites, like WordPress, could simply make SQRL be an option.  And you go, oh...



LEO:  What happens if I've done that with that site, and I then I want to go to it on mobile?  How does that get solved?



STEVE:  The identity is transportable.  So, for example, on my client you can display your identity as a QR code and then snap it with either the Android or the iOS client.  And that transfers your one identity onto your mobile device or devices so that same identity can then be used to log in there.  And so, I mean, it is multiplatform and universal.



LEO:  You'd have to have that SQRL client on your mobile device.  Or no?



STEVE:  Correct.



LEO:  What is the mechanism on mobile?  Because I don't think you have - do you have that protocol mechanism on mobile?



STEVE:  Yeah, it's all there.



LEO:  You do.  So if you go to a site that you've previously registered a SQRL ID with, you go there, you see the QR code that says use SQRL, you tap that, and then it will launch the program, and it will go back to the SQRL, the thing.  And that works on iOS?



STEVE:  So, yes. But there's two ways on a mobile.  So if you're - the term I have is "same device login" or "cross device login."  So say that you're at a hostel kiosk, or you're at a hotel executive lounge where they make some PCs available, and you want to log into your Southwest Airlines account.  Well, the last thing you want to do is put your credentials into this alien PC that you have no control over.



So if Southwest adopted SQRL, then the Southwest login would simply have a little QR code next to it.  So you would use your phone with the SQRL app to snap that QR code.  And with doing nothing else, you are logged in on that PC without entering any credentials.  The page changes, and it says, "Oh, hi, Steve.  Hi, Leo.  What do you want to do?"  So your phone uses the QR code to identify the page that you're looking at on the computer where you are, and then it transacts with the website to assert and verify your identity.  And then the website says, okay, we now know who is looking at that login page for Southwest, and you're logged in.  So, I mean, anyway, you have to sort of see it to believe it.  It's like, holy crap.  And the crypto is solid.  So anyway, you and I will do a demo.  We'll go through this in a couple weeks.



LEO:  That's cool.



STEVE:  You have a chance to use your brand new Dell XP whatever it is.



LEO:  When it comes, February 5th.  That's still a week off.



STEVE:  Okay, cool.  So Google has - I did some more digging into Project Zero.  We talked about it back in July when they announced it.  And I remember we covered it on the podcast because when I was reading their announcement blog entry I thought, oh, yeah, this is all familiar.  We did this on the podcast.  But what's interesting is nowhere in there do they say we're starting a 90-day timer anytime we discover something.  We notify...



LEO:  Oh, that's interesting.  Ah.



STEVE:  They do say - yeah, yeah.  That came as a surprise.  So they do say that we will only notify the vendor of the software in whose products we find a problem.  And they assert that the goal is to increase the security of online stuff.  And I did, in digging around, there was an example of a cross-site scripting vulnerability that Google found in their own stuff which they fixed in, I think, the number I have in my mind is like 17 days from the time it was found to the time it was fixed.  So comfortably less than 90.



But the way this actually rolled out was that, as we have discussed because Microsoft has been caught by this a few times, Google starts a 90-day timer when they inform the vendor, and the exploit goes public 90 days later.  So the way to think about this is that this is just sort of - this all fits the pattern we're seeing Google adopt.  Google has taken the position that nobody is going to fix things without being forced to, thus the whole 2015 SHA-1 website certificate problem, where Chrome is going to start prematurely warning people that websites have certificates still using SHA-1 signatures, even though there's nothing wrong with that.  It's like, okay, we're just going to push this so that it absolutely has been resolved by 2017, when Microsoft has decided they will no longer honor certificates that are so signed, so essentially two years ahead, and, you know, the others things that Google is doing.



And so this has sort of fixed that.  It's like, yes, we're going to really tighten the thumbscrews.  And the point I made last week was that this does - it's a little tighter for Microsoft because a fixed 90 days has to mesh with their 30-day window of opportunity, every-30-day patches.  And if they miss it by a day, then they have a potential of exposure of 30 days because unless it's bad enough that Microsoft is forced then to do an out-of-cycle patch, they'd really rather have it fall on their calendar schedule.



And so in digging around in this I saw other people noting that this does create a dilemma for sort of the offline-style updating, where Google has this sort of on-the-fly Chrome is updating.  I know that I've always got a process now running in my machine looking for updates to Chrome because it's just running in the background all the time.  Well, that's not the way Windows has set up to handle updates.  And arguably, the Chrome model is different than the desktop OS model.  And you look at the Chrome OS model or the Google OS model, and here we have Android 4.3 and older, apparently not going to get updated, with really bad problems.  So there's a little bit of a glass house sort of phenomenon here where Google is using the network to update the things that are easy to update on the network, but holding everybody else to a standard that you could argue they're not meeting.



So anyway, the good news is these three "zero-day," unquote, vulnerabilities that Apple had not patched by the time the 90-day clock expired, Apple was informed on October 20th, the 21st, and the 23rd about problems No. 130, 135, and 136.  Google just numbers these things sequentially.  And so 90 days later, on January 20th, 21st, and 23rd, they went public per this schedule.  And so what we do know, and I missed the comment on MacBreak Weekly, apparently OS X v10.10.2 is, like, in beta, just getting ready to...



LEO:  No, no, it's out.  It just came out today.



STEVE:  Oh, it did?



LEO:  Yeah.



STEVE:  Oh, okay, good.  Yes, that's what I wanted to ask, whether that had happened.



LEO:  Yeah, no, it came out, yeah.



STEVE:  Good.  So what that does, it fixes, as far as we know, the Thunderstrike vulnerability, which unfortunately we're calling that the Evil Maid access vulnerability because the idea being that somebody with physical access to your machine could use the Thunderbolt interface, much as they could have always previously used the Firewire, we talked about how that is a - Firewire is a DMA-level access, and Thunderbolt gives that same kind of access, although there are security controls that Apple has probably now brought to bear or done some other mitigations.  And we also believed that this fix would fix the Google Project Zero vulnerabilities 130, 135, and 136.



Although the point I was going to make was that, even though there was a window of exploitability, they weren't serious zero days.  They were only exploitable if you already had code running on that machine.  And if you have that, then it's like, well, okay, the horses are out of the barn.  So it wasn't a big problem, and Apple has probably now closed it.  And I also heard you note on MacBreak Weekly, that I'll say to our listeners, a new iOS update, 8.1.3.  And I'm hoping that it does actually make iOS 8 more stable because it's a constant source of annoyance for me.



LEO:  They're getting there.  Inch by inch.  Bit by bit.



STEVE:  Yeah.



LEO:  By the way, it's not germane to this show, but I just was handed the Apple earnings reports.  And Mac sales were up 14 percent, iPhone sales up 46 percent, iPad sales down 18 percent.  So continuous tumble in the iPad.  I know you're an iPad fan, but people are using their phones.  With big phones, I don't know if they need tablets anymore.



STEVE:  Well, I certainly agree that the phone and the tablet has probably squeezed out the mini.  I have two, and I would not buy them again.  And the other thing is that I'm a big stylus person.  And so I'm excited that Apple may be addressing that issue.



LEO:  I agree, yeah.



STEVE:  Because none of them are any good.  I have them all.  And you know, when I say "all," I really do mean all.  The active ones, the passive ones, the disks, the rubber nubbins, I mean, everything.  And the problem is that it seems to be, from an engineering standpoint, unless you give it a strong enough signal, whatever that means, just generically, there's a long latency.  Like it knows that it doesn't have a strong signal, and so it inputs a big smoothing filter which creates a smooth result, but with a lot of lag.  And it's really unnerving.



Well, and in fact, a long lag smoothing filter means you can't go fast because it won't catch up with you.  It's not like it's going to follow your path.  It's always looking at a lot of history and averaging it.  Which means, if you do something quickly, it just does a little small "nerch," which is the technical term.  And you don't actually get the path that you followed.  So you have to go really slow if you don't have a strong signal.  If you do have a strong signal because you've got something big and capacitive on the screen, or something active stimulating the screen, then it's better.  But none of it is any good yet.  So I'm really, I mean, if we had - I always pronounce the company Wacom, but you guys are saying Wacom, as in whack-a-mole, so I guess maybe - I guess that's the...



LEO:  I'll look.  Somebody sent me a video where they say how to pronounce it.  We know who you're talking about.  Wacom, Wacom, yeah.



STEVE:  Yeah.  And boy, does that - and in fact, I have one of those cute little early HP tablets, the TC1100, and that's Wacom or Wacom technology.  There's another company whose tablet I have.  Anyway, that technology, oh, is wonderful.  I mean, it is full speed, smooth.  And so I am assuming Apple will do it right when they do it and just, unfortunately, well, not necessarily unfortunately, put all of the other ones out of business, the early ones that they made their money, because I'd love to have - well, in fact, you've talked about how much you like your Note tablets.



LEO:  Yeah, which has a Wacom digitizer in it, yeah.



STEVE:  Yeah, and it just works.



LEO:  The thing that's missing on the Apple is - I didn't know about this lag thing.  That's interesting.  But the thing that's also missing is, and it probably has to do with palm rejection and other stuff.  But the thing that's also missing is pressure sensitivity.  So this will be interesting to see.



STEVE:  Well, there have been some interesting attempts.  I have all the pressure sensitive styluses.



LEO:  It's weird what they're doing.



STEVE:  Yeah.  Some use sound.  The earliest ones actually use ultrasonic sound, which the microphone could hear.  And so, as you change the pressure on the stylus, you can't hear it, but the iPad's own microphone is picking up a signal ultrasonically, telling it how hard you're pressing.  And then the newer ones use Bluetooth in order to communicate pressure through Bluetooth.  And I imagine that's probably what Apple will do when they want pressure sensitivity.  Like you, I don't care about that.  I just, I mean, not only do I not need 1024 levels, two would be just fine, down and up.  But I'm sure they're going to do it more for, you know, also serve...



LEO:  Yeah, it's for artists, not for us, yeah.



STEVE:  Yes, exactly.



LEO:  And I think, you know, they could actually put a digitizer in the screen.  We'll see.  I mean, they could put a pressure-sensitive digitizer in there.



STEVE:  So this is a little interesting.  I'm not sure exactly what this means because some of the terminology is a little soft.  But we do know that Apple's Tim Cook, the CEO, met with executives or representatives from China's so-called State Internet Information Office.  And Apple has agreed to cooperate in China's audits of their iPhone, iPad - maybe just those two things, I don't know if it was the Mac - but their consumer-level products in order to assure themselves, that is, China, that there's no spying going on.  Tim Cook reportedly told these executives that Apple products do not give data to third parties, saying, "We did not and will not provide a backdoor."  And then the director of the department said, "The Chinese government needs to draw its own conclusions so that our consumers will be assured."



LEO:  That's funny.  There's a certain amount of irony in that Apple has put privacy in its products to make the Chinese happy.  A little irony there.



STEVE:  Mm-hmm.



LEO:  By the way, Apple's earnings, 75, almost, well, 74.5 billion, up 30 percent year over year.



STEVE:  Wow.



LEO:  Big quarter.  We knew that would be - 74.4 million iPhones sold.



STEVE:  The post-Christmas...



LEO:  That's a lot of iPhones.  Yeah, well, no, it is the Christmas, it's actually their Christmas quarter.



STEVE:  Right.



LEO:  So it's their big quarter.



STEVE:  Wow.  Yeah, and it was funny to hear you guys talk about the amount of iTunes Store app sales immediately following because...



LEO:  Yeah, half a billion in the first week of January?  Half a billion dollars' worth of sales?  Wow.  Wow.



STEVE:  Yeah, wow.  And for people who used to love the Opera browser, one of the cofounders of Opera, lord knows what he paid for this website, or they:  Vivaldi.com is their site, V-I-V-A-L-D-I dotcom.  And actually Vivaldi's one of my favorite classical composers, very pleasant relaxing music.  That's the name of the new browser.  It will run on Windows, Mac, and Linux.  It uses one of the nice products of Google's work.  It uses the Chromium Blink rendering engine.  So we're past the point where it's really feasible for someone to start from scratch and build a rendering engine.  You just can't.



LEO:  Unless you're as big as Microsoft.  But any normal company, yeah.



STEVE:  Well, and do you think Microsoft rebuilt their rendering engine?  Or do you think they just basically pulled...



LEO:  You know, I've heard conflicting reports for this new Project Spartan, the new browser for Windows 10.  At first Mary Jo and Paul said, no, it's the same rendering engine.  But I just saw a report today that they've written a new one from scratch.  So I don't know.  I actually don't know.



STEVE:  And one also wonders how much from scratch it is, given that there's so much open source really good rendering engine technology.  Remember that there was some question when Microsoft announced that they'd come out with a brand new internetworking stack for I think it was Windows 2000.  It bore some strange resemblances to the FreeBSD stack, which was highly regarded at the time.  It's like, okay.



LEO:  Why write a new stack, really?  Come on.



STEVE:  Really, why would you?  Now, as Microsoft you really can't 'fess up to that.  But so you scramble it up and change a lot of variable names and things and say, oh, yeah, yeah, this is - oh, in fact it had some similar bugs.



LEO:  Oh.  See, that's the giveaway.



STEVE:  Yeah.



LEO:  When the bugs are the same.



STEVE:  Yeah.



LEO:  So have you tried Vivaldi?  What do you think?



STEVE:  I haven't.  I like what they said.  And the way they characterized it was, you know, we're not creating all new guts because why would you?  Guts are done.  What we care about is the user's experience.  And they're deliberately aiming this upmarket to our kind of listeners, to power users.  They have an interesting tab-combining feature that allows for economizing on tab real estate consumption.  When you're, like, doing research within a given area, there's a way to combine it.  Apparently it is heavily keyboard-oriented, so lots of shortcuts, so power users can use the keyboard to jump around within this browser and get a lot of fast work done.  And there was something that I thought, okay, well, this is not exactly - this reminds me of TV screens I'm seeing now where it figures out the overall coloration on the screen and then backlights the TV screen sort of to give your living room that color.  Well, this unfortunately sort of fades the chrome to the...



LEO:  Oh.



STEVE:  Yeah, I know.  It fades the coloration of the UI to fit the page that you're viewing.  It's like, well, in that case it's going to be white whenever you're at GRC.com because all of my pages...



LEO:  No, looks like it's still black, I'm glad to see.  I'm on - this is Vivaldi rendering.  You know, you've got to always test your page to see.  Looks all right.  Looks pretty good.  Let's see.



STEVE:  Yeah, the menu works.



LEO:  Your stuff's all there.  Well, of course it is.  Steve wouldn't make a bad site.



STEVE:  No, I've got simple HTML.  I've got HTML from, in fact, I have embarrassing HTML from the early days.  Stuff's there, and it works, even though I could go back and add - all my new pages use CSS extensively.  But the old ones are still there, and they still render, thankfully.  So anyway, for people who loved Opera, Vivaldi.com.  It's at technical preview level now.  Things like sync and mail and extensions are coming soon.  So it's still - it's not there.  It's not finished.  But if somebody wants another browser - again, I'm not sure why.  But for the features that it offers, it might be a thing for you.



LEO:  It's pretty clean.  It's pretty clean.



STEVE:  So I will just say, because it's here in my notes, PodcastAwards.com.  Voting is not open yet.  But it's only, right now, it's nominations.  And I'm sure enough people have put Security Now! in nominations that we will be there.  But for what it's worth, for people who want to make me happy, PodcastAwards.com can nominate Security Now!, I think for Science, Technology, and Education categories.  And when voting opens, I will let you know again because it would be fun just to sort of show some feedback from our listeners.



LEO:  And then all you have to do for the podcast URL is either use GRC.com or TWiT.tv.  Either one would be fine.



STEVE:  Oh, in fact, it's funny.  I saw a tweet.  Someone, all they tweeted was "GRC.com or TWiT.tv."



LEO:  Oh, they must be talking about this, yeah.



STEVE:  And I thought, yes, until you mentioned that, I didn't know what they were tweeting.  It's like, uh, what's the question?  So, yeah.  That's exactly what...



LEO:  You might - let's see.  Please type something in the name text field.  Please type something in the email.  Oh, I see, I have to give them my name and address.  Okay, well, there you go.



STEVE:  I think it ought to be TWiT.tv.  I mean, that's, you know, it's your...



[Crosstalk]



LEO:  Well, it depends what they want, is if they want a feed address, or if they want just a website address.



STEVE:  Oh, they know.  I mean, if you put Security Now!, there's no one who doesn't know what that is anymore.  I used to look at how many hits I got on Google, back nine years ago.  We sort of...



LEO:  I think just, yes, just do it.  PodcastAwards.com.



STEVE:  Yeah.  So I just wanted to close the loop and note that people who watched "Automata" that I referred to a couple weeks ago really liked it.  That was the funky, I keep thinking Claude Van Damme, but it's not, it's the other guy.  I can't remember.  Anyway, interesting robots and sci-fi that you'll remember I said sort of was haunting.  It had me thinking about it for days afterwards.  Bunch of people did watch it and loved it.  So I have another suggestion.  What's happened is that, with all this Super Bowl stuff, my normal Sunday program has been wiped out for the last few weeks, so I've been poking around my Amazon Fire TV thing, looking for something to watch.  And so I've been seeing things, I've been watching things I normally wouldn't.



Another movie that just came out, starring Ethan Hawke, is "Predestination."  It got a 7.5 out of 10 on IMDB, which is pretty respectable.  Rotten Tomatoes gave it an 80, which is surprising.  And Metacritic gave it a 68.  But a little over an hour and a half long, and it's based on a short story, as are many good sci-fi movies, by Robert A. Heinlein, of course a famous classic sci-fi author.



And it's funny because I didn't know that he'd written it until after, until it was scrolling through the credits afterwards.  And I sort of thought, okay.  Because, I mean, if you've read much of Robert A. Heinlein's stuff, it's absolutely written by him.  It is an extremely complicated time travel story where, when you're done, you're like, whoa.  And then the fact that it was contrived, you kind of can forgive it, because that's the way Robert's stuff tends to be.  But it was a good piece, I mean, a very convoluted, paradox-filled time travel story, exactly the kind that he would write.  And it's a movie called "Predestination."  So I liked it.  And I think our listeners will, too.  So a little heads-up and thumbs-up on the sci-fi front.



And just yesterday, on January 26, a Bruce Young, whose title is Department Adjutant at Oregon's Department for Disabled American Veterans, sent email to Sue, because he didn't have another address, with the subject "SpinRite Is a Great Product."  And he wrote:  "I'm a computer professional, and I've owned the current version of SpinRite since v2.0 for my home PCs."  And he says, parens, "(yeah, I'm that old)."  It's like, hey, Bruce, that's all right, I wrote it, so I'm...



LEO:  You were there since 1.0.



STEVE:  I'm at least that old.  And he says:  "I've restored several dozen 'dead' [in quotes] systems with this invaluable tool, most recently a four-year-old HP laptop that would hardly boot.  And anytime a CHKDSK of my PC supposedly 'fixes' [he has in quotes] a drive, I run SpinRite on it, and the problem goes away.  Sure, it takes a while to run.  But if I kick it off before bed, even the biggest troubled hard drive is finished by the time I get home from work.  And lest anyone think this tool is for techies only, the interface is easy enough to use that any computer owner can run it.  Any time you need a beta tester for a new version, look me up.  I'm ready.  Thanks."  And, Bruce, thank you for shooting that to Sue.  She sent it to me, and I get to share it with our listeners.



LEO:  Isn't that nice.  We have no backup for you, Steve Gibson.  I don't know.  I just realized, we ought to clone you somewhere on the Carbonite cloud in case we lose you.



STEVE:  Yeah, I would like to be cloned just so I can get more done.



LEO:  We need two of you.



STEVE:  Yeah.  But the problem is then we would argue because we would both want to be doing everything.  So I don't actually think that would work because my biggest problem when I had more employees and, like, a development group was that they were getting to have the fun of writing the code, and I was sort of the puppet master.  And I wanted to be the puppet.



LEO:  Wait a minute.  You want to be the puppet and not the puppet master?



STEVE:  Yeah.  I don't want to be a puppet master.  I want to do the work.  But cut the strings, and I'll...



LEO:  Oh, I see.  You don't want to do the management stuff.  Oh, I don't blame you on that.



STEVE:  Right, right.



LEO:  God, that is no fun.  That is a thankless task.



STEVE:  I know.



LEO:  But, see, you didn't do it right.  The whole point for me of getting staff was so I would do the stuff I liked, and they would do the stuff that I didn't want to do.



STEVE:  And that is now my world.  I have Greg for tech support, and I have Sue for the books.  And it's like, thank you very much.



LEO:  Yeah.  So I hired editors, money people, HR people, that kind of stuff so I don't have to worry about that.



STEVE:  Yup.



LEO:  Anyway, we've got questions; you've got answers.  I installed the Mac update, and now I'm rebooting the machine.  Let me pull the questions up here.  Question 1 from Jay Mcgee in Washington, D.C.  He wonders about this Elaine transcription service we use, Steve:  Mr. Gibson, I have a need for a transcription specialist for a few videos.  Could you forward me to your transcription specialist so I can send some business her way?  Thank you.



STEVE:  So we talk about Elaine all the time.



LEO:  Elaine Farris.



STEVE:  But we never - Elaine Farris.  Now, her contact information has changed over the course of this.  I just found her by googling, like, I don't know what, "audio transcription," and there were a few there, but hers was the only one that had an online form that I was able to sort of fill out and ask a question.  And she got back to me, and then I found out, not only was she a transcriber, but she was THE transcriber.  I mean, she, like, transcribes medical conferences where all the terminology is, like, she gets it correct.  And she heavily uses Google to, like, research things.  I know that because every so often I'll get email back from her while she's working on the transcription, saying, "Okay, you said this, and you and Leo were talking at the same time at this hour and minute into the podcast.  What was that?"  So she really cares.



LEO:  That's nice.



STEVE:  And so it's fabulous.  So she used to be On-SiteMedia.com, but now that's like "formerly known as."  She now calls herself EDigitalTranscription.com, all one phrase, EDigitalTranscription.com.  So that's where you can find Elaine.  All that online stuff is still there.  So you can send her email.  You can click on a form and fill it out.  She has a .mobi version, so EDigitalTranscription.mobi for her mobile version of the website.  And as everyone who listens to this podcast knows, I could not over-recommend her.  I mean, I can't overstate what it means to use her.  She's not the cheapest solution there is, but she is the best, and that fits me.  It suits my needs and the needs for this podcast.



LEO:  I recommend Elaine.



STEVE:  Yeah, anything technical, or even if you just want them right.  If you want them done right, EDigitalTranscription.com.



LEO:  Very good.  Now, by the way, other shows are transcribed on this network, and we use a different service, which I just asked.  I just ran out in the studio, said, "Who knows who does our transcriptions?"  And nobody knew.



STEVE:  Good.  Elaine.



LEO:  Yeah, so Elaine.  But, no, this is a service that's been doing, not all of our shows, but I think about half of our shows now.  Inspired by you and Elaine, we decided we ought to have transcriptions.



STEVE:  Well, it makes audio and video podcasts searchable.  And that's so...



LEO:  That's a big deal, yeah.  That's the main reason we do it.  Our next question from Elliot Kovacs, a 12-year-old listener in Wellesley, Mass.  I love Security Now!, exclamation mark, exclamation mark.  On a previous episode you said printers leave a watermark on paper.  I was wondering if there was a way to see this watermark.  I hope I get on Security Now!, exclamation mark, exclamation mark.  I'll just call them "bangs" from now on.  Bang, bang, bang, bang, bang, bang, bang.  I'm only 12 years old, and I am very interested in security.  Thank you.  Elliot Kovacs.  The end.



STEVE:  So it is the case...



LEO:  They're invisible; right?  They're not...



STEVE:  Well, they're not invisible.  They're just very hard to see because they're yellow.  So color laser printers use deliberately, on every page they put out, put yellow dots, like, on the paper.  And the problem is you have to get a jeweler's loop and good illumination and just sit there looking for yellow dots.  I'm not sure that a scanner, unless it was maybe a very high-resolution scanner specifically looking for isolated yellow dots, could find them.  But the point is they're just not visible to the naked eye.  The resolution of today's color laser printers is so high that the dot is very small.  And yellow is just not that different from white.  So you have to just look for them.  But if you do, you will find them.  And you'll think, oh, it's just some dust.  No, that was put there on purpose.  That is the serial number of the printer which printed that page.  And I remember it sort of surprised everyone when this came to light.  It was like, what?  My printer is tattling on me?  It's marking everything I print for, like, who knows why?



LEO:  Well, I can tell you why.  It's law enforcement.



STEVE:  Yeah.



LEO:  So they've been able, for years you could always tell which type, you know, you could match a typewriter up.



STEVE:  Yeah, in the old...



LEO:  They were so non-uniform.



STEVE:  Right, a mechanical typewriter, you're right.  Every single one, very much like a fingerprint, would have slightly different characteristics.



LEO:  So I'm sure when laser printing became popular, law enforcement went to the companies and said, hey, would you mind just putting a serial number on there, invisible, just in case?



STEVE:  Yeah.  What can you do for us?



LEO:  I don't think there's any harm to that.  If you google "laser printer watermarks," you'll see close-up pictures of the yellow dots.  But I suspect law enforcement knows exactly where to look and how to find that; right?



STEVE:  Yeah, I'm thinking.



LEO:  It's probably in the same place on the page and all that.



STEVE:  Exactly.



LEO:  And our transcription service, oh, now I forgot, I think it was Rich Hall at Perfect Security does the other podcasts.  I don't know what the story is with that, but there you go.  He's our transcriptionist for the other shows.



Question 3, an anonymous listener wonders:  How do I get started in crypto programming?  Well, first part is right.  Anonymous, good start.  I'm interested in crypto programming.  I just don't know where to start since there are tons of tutorials on the web.  I don't know where I should focus, which algorithm.  I'm asking if you could point me in the right direction to somewhere I can learn how to program crypto properly.  Thank you.



STEVE:  So the guru is Bruce Schneier.  And I say that because he not only understands it, but he's a good teacher, as well.  And behind me, let's see, no [muttering], right there.  There.  That is a copy of THE book.  That's the one you want.  It's Bruce's first book, "Applied Cryptography."



LEO:  Wow.



STEVE:  And I pulled it off the shelf, and literally - somehow it acquired dust even though there's a shelf right above it - dusted it off, and just sort of flipped through it again to make sure that's the one I wanted to recommend.  And, oh, my goodness, it is so good.  So "Applied Cryptography" by Bruce Schneier, that's the one.  Now, he's done several since.  I think he did an "Applied Cryptography," and he did something about "Secrets and Lies" or something.  He's done some others which are sort of more about the environment in which crypto is used.  And "Applied Cryptography" is a little more of a cookbook.



But this is the one.  You want "Applied Cryptography" because it is soup to nuts.  It is across the board.  It shows diagrams of all the algorithms, talks about hashes, talks about ciphers, symmetric and public key, I mean, it is sort of the introductory bible for somebody who wants a good foundation in crypto.  So I recommend it without reservation.  It's not inexpensive.  And so I'm sure there are tutorials on the web that are free.  Maybe they're worth what you pay for them.  In this case, it absolutely is.  That's the book.



LEO:  And of course Bruce is still very active, talking about security and crypto.  He's got a great website, Schneier.com, S-C-H-N-E-I-E-R, I think, dotcom.  And we refer to him, Schneier on Security, we refer to him all the time.  He's just a great guy.



STEVE:  Yup.



LEO:  He's been on TWiT.



STEVE:  He does a great blog.  And I'm seeing him catching a lot of media now.  I'm seeing him being interviewed.



LEO:  Oh, he's a god, yeah.



STEVE:  Yeah.



LEO:  I just think so highly of him.  And if you click his books link, you'll see all his books, and you can buy the books directly through him, get him a little extra money.  But "Practical Cryptography" is there.  Still, it came out in 2003, but still on...



STEVE:  Wait, but that's different than "Applied."



LEO:  Applied, not practical, applied.



STEVE:  There it is.



LEO:  There's "Applied."



STEVE:  It's that dark red one, yeah.



LEO:  1996, yup, available on Amazon in hardcover and paperback.  Get it today.



STEVE:  It is just really, really good.  It's a great book.  It's the one.



LEO:  It's in C, so you actually get code there; right?



STEVE:  There's a lot, yes, there's a lot of code toward the back of the book.  But mostly, again, it is completely readable and understandable.  It's what you want, if you want to just learn.  And it's funny because we've talked about how slowly this stuff moves.  Even though that book itself was written some time ago - the edition I have is the second edition.  I don't know if there are more recent editions.  But everything is still germane.  I mean, because this stuff moves pretty slowly.  So that's the one, "Applied Cryptography."



LEO:  I was looking for my copy.  I have it here somewhere.  Not that I would understand a word of it.  1996 is the second edition.  Still good.



STEVE:  It really is.



LEO:  Yeah.  Question 4 from Michael Zimmerman in Sydney.  He's not alone in asking this, about extra keys and all of that:  Hi, Steve and Leo.  Just finished watching Security Now! 491 with your explanation of how, if mandated, a government backdoor could be provided using additional public keys to encrypt the random key used to encrypt the payload.  This all makes sense, and I think we've seen the same idea used to provide the ability to change master passwords or provide temporary access such as application password access.  My concern, among several, is this is impractical to implement.  Let me put this up on the screen because it's such a long question, and I'll let you all, at least those of you watching on video, read along with me.



STEVE:  Read along.



LEO:  Yeah.  You've described the problem using iMessage as an example, but any legal crypto software could be inserted here.  I want to send my message to Steve and Leo, and maybe the message is "Hi," or maybe it's my copy of "War and Peace."  The message is encrypted with a random key, and a header is - well, not exactly a random key, but anyway, we'll - and a header is attached with Steve's encrypted version of the key.  We also attach a header with Leo's encrypted version of the key.



Now, the government insists on access, so there is another header attached.  The problem is, who is "the government," and how will the software know?  I'm in Australia; Steve is visiting the U.K. Prime Minister Mr. Cameron; Leo's on a cruise - this is very accurate - currently passing Korea and China.  According to Google, there are 196 countries in the world.  Maybe I should have asked how many governments.  We know that every one of them will want to be in on the action.  The list of additional headers will spiral out of control, just like the list of CAs, any one of which can be used to decrypt the payload.  Which one of them will be the weak link?  Maybe the "Whatsnamia" official with a gambling debt, open to offers from anyone.



And if there were only one additional header key for the central controlling government body, who would administer that body, and who would deal with all the countries requesting to decrypt the header?  Sure, my house is safe, and I have a front door key.  But now my house has 196 separate front doors.  All the best.  Michael.  He's describing one possible implementation, not necessarily the one that would be involved.



STEVE:  Correct.  And in fact I will wrap up this with Question 10, where I'm going to submit what I imagine would be the actual implementation.  But I included this because many people were a little thrown off by this last week.  So I want just to make it clear that my intention wasn't to suggest that this is the way it would be done, but that doing something wasn't weakening the crypto.  That was the entire focus, was to say that there are, I guess, there are two meanings of the term "backdoor."  It can mean that the cipher is broken, that is, doesn't have its integrity in a way that most people don't know.  And so that its lack of integrity, very much like a broken random number generator that is subtly broken, but no one can detect it.  But the people who know about the way it's not quite as random as we want, they're able to leverage that fact.  That's a perfect example of a defective cipher backdoor.



And so I wanted to make that distinct from the concept of the way multiple keys can be and are being used to create essentially, as Michael does say, multiple front doors.  It doesn't require weakening the crypto in any way to create a means for something like mandated decryptability of content.  So anyway, so I wanted to clear that up because many people responded as Michael did.  I just chose his from among a bunch.  I wasn't saying that I expect that this would be the implementation, but just that there could be an implementation that actually didn't weaken the cipher.  Although you could argue, and as we brought this up last week, when you tell somebody a secret, it's not a secret anymore, even one person.



LEO:  Right.  I mean, you don't have to look too far to find the actual NSA technology which is in use today, called Skipjack, which is a key escrow system designed to do exactly what they want.



STEVE:  Right.



LEO:  We'll, I think, talk about that later.  Going to Question 5, John T. in Queensland's Sunny Coast doesn't think there are trivial true positives:  See, in 489 a sysadmin explained they allow malware to enter their networks and then hope that host-based AV will clean up the damage.  Well, that guy's crazy.  Having worked in IT/infosec for over 20 years, in both management and admin roles, my first policy rule on any corporate proxy is to block executables.  Period.  No executables, ever.



That, in conjunction with a proxy-based AV scanning will block the majority of known malware at the gateway, instead of allowing it to be picked up and addressed by the host.  If the AV signatures on a host can detect the malware, then it is likely that a proxy would also be able to do so, as they tend to be more powerful, have multiple AV rule scanning engines, and be more current than the hosts.  Indeed, this process has become more difficult over the past few years as sites move to SSL, where an enforced man in the middle is required by the proxy to break open SSL traffic and scan it for executable malware content.  But it's the only way for corporate networks to remain safe in this century.  Regards, John, a long, long-time listener.



STEVE:  So I just wanted to present that counterpoint to the notion that we talked about before of local hosts cleaning things up.  Maybe that's an approach, not the one that John suggests.  And this sort of was brought to the fore for me because about a week ago someone wrote, a SpinRite user wrote to Greg saying that he had, I think it was an original PC XT, or he had a really old system, and neither SpinRite 6 nor SpinRite 5 would run on it.  Could he get a copy of 4?  And what has happened is, over the years, some really tasty op codes that I've wanted, like byte swap allows you to swap the bytes in a single instruction.  And the original chip in the PC didn't have it.  And but when the world had moved to 386s, I waited a while, you know me, I mean, I, like, waited a decade.  And then I said, okay, it's safe for me to use a byte swap instruction on the PC.  But not if you actually do have an 8088 or a 286.



Anyway, the point is that he was a SpinRite owner.  I sent him a copy of SpinRite 3.1, which I was absolutely sure would still run on an original 4.77 MHz 8088.  I couldn't get it to him.  I kept trying.  I zipped it, I encrypted it, I did everything I could.  And whatever he had that was - the email just bounced.  I could not mail it.  So finally I gave it a quiet place to live on my server, and I sent him a link, and I said, "Okay, I give up.  I can't get this to you.  Here, you go get it yourself."  And then as soon as he told me that he'd received it, I removed it.  But, boy, it is not easy to get anything executable into someone's network these days.



LEO:  As it should be.



STEVE:  Correct.  It wasn't malicious, quite the reverse.  But still he was well protected.  And that's the way it has to be.



LEO:  So if you had zipped it or somehow obfuscated it...



STEVE:  I did.  This thing looked in the zip and saw that it...



LEO:  It was smart.  That's well done.



STEVE:  Yeah.  You know, I even zipped it with a password.  And it's like, because that's supposed to encrypt it so that you can't see.  But maybe it looked at the table of contents?  I don't know what it did.  But anyway, it just still...



LEO:  I know what you could have done because nobody would do - if you base64ed it, if you encoded it, it would just look like random text, then paste it into the message and say, un-base64 this, and you'll find an executable.  That would have worked.



Nayef Alharbi in Saudi Arabia wonders about the safety of renewing a certificate:  Steve and Leo, Security Now! listener since December 2012.  Really enjoy learning and listening from you.  I am wondering, is it safe to renew a certificate rather than requesting a new certificate?  I know that making a new certificate is much more involved, but I feel it's more secure.



STEVE:  Now, that's interesting.  It's something we, in all of the time we've been talking about certificates, this has never come up.  So I love the question.  What he's talking about is the issue of rekeying when you renew.  And it is a choice.  So we have a certificate.  And remember that what a certificate is, is our public key, which is signed by a certificate authority, with an expiration date.  So, and we know why expiration dates are important, because certificates can be bad, and we may have to blacklist them.  But by having it expire, that self-blacklists, meaning that the blacklists don't have to be forever, they only have to be with some slack outside of the expiration date.  Then we can prune off of the CRL, the Certificate Revocation List.  Any management only has to live past the certificate's own self-demise.  So that means that every few years you need it renewed.



Now, it isn't technically necessary for the owner of the site to generate a new key pair.  It's certainly possible, and I've done this in certain circumstances, and I'll explain, to simply have the existing certificate, that is, the existing public key, re-signed and then redated.  So you can do that.  And so all that's really happening is that you're saying we're taking the existing public key and automatically the secret private key, and we're saying, as far as we know, they're still good.  They have enough bits in them to be as secure as we need them to be for the expected lifetime of the certificate, which is never more than three years.  So I don't feel like going through all the hassle of generating a new key pair.  Let's just update the signature, re-sign it, and give me a few more years on the existing key pair.



Okay.  The general feeling is, if you rekey and don't extend the expiration, that's always okay.  And there are ways you might want to do it.  For example, I recently rekeyed my certs and brought the expiration down to the end of 2015 because I want to stay with SHA-1 to help people get to GRC.com because you can only get to my website in any way now over TLS.  So I rekeyed it short, and I re-signed, I had DigiCert re-sign my certificate with a tighter expiration using the existing key.  I didn't rekey the cert.  And they also gave me an SHA-256 cert on the original expiration schedule, which was I think in 2016 or '17.  So the idea is you can say that's entirely reasonable because then the time horizon of your original public and private key pair hasn't been extended.



Now, it is the case that you could argue, hey, these public and private key pairs are strong enough that we're not retiring them because we think they're weak, we're retiring them just for the whole certificate hierarchy system.  I think it's probably wiser, just as a matter of practice, it's only every couple years, to have your server generate a new public key pair so that, I mean, the danger would be that somebody could be working away in the background, trying to factor your public key.  We know that's not really going to be a problem because it's secure enough.  But the effect of rekeying is to take that public key out of service at the same time that you renew your certificate with a new expiration date, thus foiling any background long-term project of trying to crack your key, which again no one's really worrying about because we've got way more strength than we need.



So it's sort of a tossup.  For example, say that you had a blogging site with low value to security.  You're just going SSL or TLS because you wanted to, but there are not hugely valuable crown jewels being protected.  Then, if it was inconvenient to rekey, you could just have the CA re-sign the existing key, and you're good to go for another two or three years.  On high-value sites, I would say probably worth rekeying.  But that is something we've never discussed.  And it's interesting that people have a choice, especially if you've got a great CA, like I do with DigiCert.



LEO:  Lee Whitfield at "32.924112, -96.7654598," which of course some of you may know as Dallas, Texas, offers some additional insight into CryptoWall 2:  Steve, great show.  Sadly, I sometimes just don't have time to get to the episodes for several weeks.  This is one of those occasions.  Episode 489 you discussed CryptoWall 2.  I've had the chance to conduct forensic investigations on these systems and have something additional to share.  Either way, CryptoWall is becoming more and more difficult to stop from propagating.



Yes, you can get CryptoWall from clicking on links in your email, from specially crafted PDFs and Office files.  But there's an additional reason this iteration is so bad:  You don't have to click on anything for this to run.  The guys that made CryptoWall 2 were able to distribute it via ad networks, including Yahoo!'s own ad platform.  If you have a web browser that allows the autoplaying of Flash content, and you happened to visit a perfectly good site that happened to contain a bad Flash ad, you could become infected.  And on top of that, to avoid detection and discovery, the keys are issued via servers on the Tor network.  This means it's difficult, or virtually impossible, to track these people down.  Wow.



STEVE:  Yeah.  So again, we know that there are two essential, well, mitigations.  One is there's no substitute for using a sponsor of this podcast who you were talking about a few minutes ago, Leo, getting yourself backed up.  Because if this thing gets into your system, all the files you care about are encrypted.  And unless you have a current backup, you will be paying somebody to get your files decrypted.



The good news is they're pretty good about doing it because they want the reputation of, you pay them, you get your files back.  So from the things that I've been seeing on the Internet, it's like they'll go to extremes.  I've even seen situations where somebody, for some reason, is unable to provide them their money, or the money transfer didn't work, and they established a dialogue with these cretins and were able to get compassion from them, at least to the extent of arranging for them to accept the payment.



So the first is, you know, there's no substitute for having a backup of the content.  And as we learned, I guess it was last week or the week before, a non-admin user can get recovered from Windows' own prior records of the changed files. So if you are running as a non-privileged, just a regular or standard user, then CryptoWall is unable, because it runs as you at the time of the infection, it is unable to reach into the privileged admin region of your system in order to also corrupt those incremental backups that Windows, the whole System Restore system that Windows is doing for people.  So I would say, until we come up with some sort of a solution, you need to be backed up, and you really cannot run as a privileged user.



It's interesting, too.  I'm seeing people who are having this problem at the moment with my Windows SQRL client because you have to be an admin in order to register that scheme, the sqrl://.  One of the features I'll be adding, it's on my to-do list of cosmetic stuff, is if it notices that you're not admin, it'll itself prompt you for the admin, well, actually it asks Windows to prompt you for the admin credentials so that it can briefly upgrade you in order to get permission to register that scheme.  I did the same thing with that freeware, Securable.  Securable had to have admin privileges in order to install a driver, in order to access the chip's registers to do the stuff that Securable does.  And I had it.  It prompts you, it has Windows prompt you for the credentials in order to give it permission.  So the good news is people are hitting this problem because they are running as a non-admin account.  That's a problem you want to hit because you want to be running non-admin.



LEO:  You could right-click on the SQRL program and say run as administrator.



STEVE:  Yes.



LEO:  Just for that one time.



STEVE:  Yes, yeah.  And if you don't, and then SQRL sees that it's unable to tweak the registry as it needs to, then it says, oh, give me a hand now, give me a hand.



LEO:  Matt in London, with our Question 8, wonders how good Enigma really was:  Steve, you threw some figures around about how many combinations there were on a three-wheel Enigma device, but what is that compared to a modern computer?  Like when you compared SQRL's master key to the chance of the world ending every 11 seconds, how long would Enigma take to brute-force on, say, a Pentium 100 or a 2 GHz quad core?  They built a mechanical machine to do it.



STEVE:  Well, yes.  The bombe was a mechanical machine.



LEO:  Far slower than any electronic computer would be.



STEVE:  Vastly slower.  And many people wondered, how does Enigma's cryptography compare to contemporary crypto?  And unfortunately, I mean, it was good for World War II.  We would cut through it like butter.  I mean, just not even a sneeze.  So current crypto technology would just laugh this off, wouldn't even pause to crack the Enigma cipher.  We've come so far.  One of the reasons is that it just actually wasn't that complex.  We did discuss how, for example, a state-of-the-art crypto like AES operates on this podcast, and I was able to explain it to people.  But the nature of the way it works is vastly different from being a polyalphabetic cipher, which is all that Enigma was.  I mean, we don't - you crack polyalphabetic ciphers in your first week of Crypto 101 in college.



LEO:  Yeah.  But it was good enough.  And that's why they changed, by the way, that's why they changed it every 24 hours.  They knew it was crackable with brute force even by hand within a certain amount of time.



STEVE:  Yup.



LEO:  But it was good enough, and that's the point.



STEVE:  Oh, it was, I mean, given the computational, I mean, basically they had to create a special purpose computer.  That's what Alan Turing did was a very, I mean, for the time, so sophisticated that nobody else understood how it worked.  I mean, he sat down, and he designed a computer, an electromechanical computer, specifically to crack crypto, based on his understanding of the constraints that the cipher mechanism put on the encipherment.  That is, it turns out, and this was the stroke of genius on his part, he recognizes, you know, the first simple thing that we talked about on the podcast was it immediately fell out of the design that no letter could encipher to itself.  The machine made that impossible.



So that's, like, a simple constraint.  But it turns out, when you look at it much more carefully, there's a huge, like, network of constraints.  And if you build a machine to probe this network of constraints, what it would do is, and this is what it was doing when it was chugging away, it was testing potential rotor positions against a series of constraints and ruling them out.  Nope, that won't work.  Nope, that won't work.  Nope, that won't work.  And then when it would stop, it was because it found a series of settings that could function within the constraints that this bombe had been programmed for.



So then they would go, and they would use one of their Enigma machines and put that set of rotors in and see if the whole cipher made sense.  The tiny piece they had would work, but the question was, does it all work?  And so many of these were false positives.  They would go back and push a button that essentially would say, okay, keep searching.  And so it would start from that point and keep moving forward, looking for other possible rotor configurations that met the constraints that the bombe had been programmed in.  The point is, our current crypto, we have technology that blasts it away.  But back then, that was amazing.



LEO:  That was good, man.  Number 9 from Jonathan Blaine in Western Pennsylvania reminds us that the Astaro/Sophos UTM is free for home use:  Steve and Leo, my wife and I have been listening to Security Now! for about two years.  Really appreciate your efforts to educate on security.  About two months ago, my boss and I were trying to figure out where my  bandwidth was going.  Actually, while I was trying to figure it out, my boss pointed me to the Sophos UTM, saying it was similar to the pretty amazing Palo Alto systems we use for work, but was free for home use.  



I see from a search on GRC that Astaro was a sponsor back in 2006 through 2008, and heard Leo mention recently TWiT still runs the Astaro Firewall.  It certainly isn't trivial to set up, and my family has had to bear with me as I got Netflix working properly on their various devices.  But it truly is a powerful tool for the somewhat more technical group of listeners of Security Now!.  It would be great if you had a chance to take a look at the free product and, if you think it's worthy, make a mention of it on Security Now! so adventurous listeners can experiment.  Perhaps we could even share rules on common issues.  Thanks again for everything.  Jonathan Blaine, SpinRite owner, avid listener to Security Now!.



STEVE:  And I should say it is what I still recommend.  I recommended it to a close friend of mine about a month ago.



LEO:  I think you recommended it last week.



STEVE:  I may have...



LEO:  On the show, yeah.



STEVE:  ...talked about the idea of taking an old PC with a couple of NICs.



LEO:  Exactly, yeah.



STEVE:  And that's the one you want is the Astaro Security Gateway.  I love the fact that he said it took a while to get Netflix working properly.  And that's kind of what you want.  I mean, you want tight admission of stuff into your network.  And we know that NAT boxes, routers, do sort of a good enough job for most things.  But Astaro really goes a lot further.  It is updating itself with patterns, and it is checking to keep bad things from coming in, which a router has no function for doing.  So I really like Jonathan reminding me to make sure that I tell people, you know, they were, what, I think they were the first sponsor for the podcast, weren't they, Leo?  And they were with us for years.



LEO:  They were our first TWiT sponsor, actually, as well as a Security Now! sponsor.  Nice guys.  Palen Schwab, who was the guy who bought the ad and has since gone on to other companies.  And of course Sophos bought Astaro.  But we always, in the ads, mentioned the free version of Astaro for download.  That was part of the ad.



STEVE:  I'm glad to know it's still there.  Stick it on an old PC with a couple of network interfaces, and look forward to having some fun pushing - it's got a lot of buttons and switches that you can flip.



LEO:  And we do use Astaro UTMs throughout the place, and it's really been great.  Makes me feel fairly secure.  You know, we're safer than Sony.



Gert Eriksen in Denmark muses about master keys to cryptographic backdoors:  Dear Steve, a very interesting topic, although I have some concerns about cryptographic backdoors.  For me, the two biggest reasons for advocating for encryption is to ensure private communication, and to make mass surveillance unfeasible for private or government organizations.  Nobody would argue that.  That's right.  Besides the obvious concern about a second front door, my concern is, if there is a master key to that door, it only requires one court order, and the master key to all communication in the past and future is loose.  And this only for a single country's government.  This is not a very pleasant thought, particularly for a non-American like me.  Also, I don't know if that's true, but I'm sure Steve will address this.



In order to avoid this, I suggest that the second private-public key pair is generated individually for each user account, and the private key is stored by the service or app provider, Apple or Google.  Then a court order will only reveal this account's communication and will not be a general master key to everything.  I will very much like to hear your thoughts about this.  I know there are some difficulty to generate, store and manage individual public-private key pairs, but the alternatives are much worse.  Thanks for a brilliant podcast.  Gert Eriksen, Copenhagen.



STEVE:  So I promised that the last question would address this.  And this is the question.  If this ever...



LEO:  You've looked at Skipjack; right?



STEVE:  Well, yes.  And if this ever happens, and we can hope it doesn't, but I'm skeptical, I think what would happen, the way this would actually get implemented would be sort of just turning the clock back legislatively, that is, legislation which required Apple and Google - and essentially we've already established that the cryptographic technology has already escaped.  It is absolutely possible for two people to encipher so that nobody else can intercept their messages.  We have that.  But what would happen legislatively is that companies who were selling products that employed cryptography would be compelled to be able to respond to the FISA letters, compelling them to decrypt specific communications of their specific users or customers.  And that they can do.



All Apple would have to do would be to maintain a master key and add that to every iMessage.  Just as right now they provide keys to the recipients of iMessage, they would add their key so that they would be sort of a ghost recipient.  And so this doesn't have to leave Apple.  It doesn't have to be governmental.  I mean, it's not - I didn't mean to imply any specific sort of structure when I was talking in broad generalities before.  So I imagine, if something happens, that's what it would be is that companies, commercial entities selling products with cryptography, would be whatever they have to do.  And that would be left up to them.  But they would be, instead of now saying "We can't decrypt it, sorry, we don't have the keys anymore," legislation would say, "Oh, that's not good enough.  If you're going to be selling crypto products, you need to be able to respond to specific orders to decrypt specific communications."  And they could do that.



And so we as consumers would know that, rather than having things the way they have been for the last year, where Apple is like, okay, we can no longer crack your phone open, we're explicitly saying we can't do it, well, they used to be able to.  Now they can't.  They may be forced to do it again in the future.



LEO:  Okay.



STEVE:  And that's, you know, I imagine that'll be the way it is.



LEO:  I mean, you don't have to guess how it would be implemented because it already has been implemented by the NSA in this algorithm called Skipjack, which is now, since 1988, public, and you can look at it and see how they implement it.  They use a key escrow strategy.  And in fact Skipjack is in probably every TV manufactured today.  So just so you know.



STEVE:  Yeah.  The idea being that it'll be - the practical way for this to happen is that the entity that is selling a product that uses strong crypto will have to somehow, if such legislation happened, they would have to be able to respond, not that we cannot decrypt, but okay, here's the data that the court order required us to turn over.  They would have to be able to comply with those orders.  If legislation happens, that's probably the shape and the form.



LEO:  Yeah.  You could also require that whenever a key is generated by any of these products, that a second key is generated which is held in escrow by a third party, not Apple, not the NSA.  Then that key can be turned over only on court order, that kind of thing.  If you think about it, there's ways and ways to do this.



STEVE:  I don't think that'll happen.  I think it'll be the way I said.



LEO:  Well, I don't think any of this will happen.



STEVE:  That's all I'm saying.  This is the way I think it'll happen.



LEO:  Okay.  All right.



STEVE:  It's basically just sort of turning the clock back a year.  Sort of it's the way things were before.



LEO:  Right.  That'd be the easiest.



STEVE:  Yeah.  So we'll have security, but...



LEO:  It raises issues because then private companies have access to your stuff.  So a better solution would be to have an escrow system that means that neither private company nor the government has access to it without an order.



STEVE:  Good point.



LEO:  Yeah.



STEVE:  Good point.



LEO:  But you know what, I think this is all pie in the sky.  There's no political will to make this happen.



STEVE:  Let's hope.  Please, please, please let's hope.  Well, I don't know.  The argument, you know, can we allow terrorists to have communications we cannot intercept. that's a tough one to - and then, of course, they yank out all the pedophiles and all that sort of - okay.



LEO:  Steve, 10 in 10.  Nice job.  Once again, a hundred percent.  Steve Gibson is at GRC.com.  That's where you'll find his great program SpinRite, the world's best hard drive maintenance and recovery utility.  You'll also find details on SQRL and all the other freebies he gives away all the time.  He's always working on something new and interesting.  Lots of information there.  And of course 16Kb audio of this show, and transcriptions, as well:  GRC.com.



If you have a question for our next Q&A, a couple of shows from now, you can go to GRC.com/feedback, or you can tweet him because Steve's also on Twitter:  @SGgrc.  And if you follow him there, he always puts up lots of great stuff.  And anything with @SGgrc he seems to respond to.  So that's another way to ask those questions.  You will find full audio and video versions of this show on our website, TWiT.tv/sn, and of course wherever podcasts are aggregated.  After 10 years, it's pretty much - I can't imagine a podcast client that doesn't have Security Now!, but you can always search for TWiT, and you'll find all of our shows.  Thank you, Steve.  Appreciate it.



STEVE:  Leo, a pleasure.  Talk to you next week, and we'll do DeTor, how to deanonymize the Tor network, which was built specifically to provide anonymity.  But it doesn't quite do it as well as we were hoping.



LEO:  That's it for Security Now!.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#493

DATE:		February 3, 2015

TITLE:		Tor:  Not so Anonymous

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-493.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a few important security events of the week, Steve and Leo revisit and dissect the anonymity promises of TOR in light of scores of academic papers which have questioned its guarantees.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We'll take a look at the week's tech news, including the latest flaw.  He's got an update on glibc.  We also talk about Tor.  Turns out it ain't all that anonymous.  Maybe you'd better be listening, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 493, recorded February 3rd, 2015:  Tor?  Not so anonymous.



It's time for Security Now!, the show where we cover your security and privacy online with this man right here, Mr. Steven "Tiberius" Gibson, the guy in charge at GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  Is this your first time watching a Super Bowl?  Is that it?



STEVE:  You know, I don't think there was as much buzz about any previous Super Bowl.  So I've been sort of warming up to it gradually, year by year.  Greg, my illustrious tech support guy, who's been with me for I think 23 years, he is just like - okay.  He tolerates employment just so that it allows him to support his need for sports.



LEO:  That's a lot of us.  It's not unusual.



STEVE:  You know, he's doing fantasy - I think he founded fantasy football, whatever that is, but I've been hearing about it, like, forever.



LEO:  Oh, yeah.  It's huge, yeah.



STEVE:  And so he's just like, I mean, sports is him.  In the same way that coding, you know, "Born to Code" is on my T-shirt.  Well, I don't know, "Born to Throw Something" is on Greg's.  And so as a spectator - I don't think he's a participant, or at least not at, you know, we're all getting kind of older, and so it's not safe anymore.  But so he's also a commercial fanatic.  And so like the Super Bowl commercials, he was just like, all over them for, like, for years, before it even became a thing.



So anyway, this year everyone was talking, of course, about Deflategate and all that mess.  And everyone was talking about the game.  So I thought, well, I'll just have it on in the background while I'm working on SQRL.  And I have to say I didn't much work done on SQRL.  My hands, my fingers were poised over the keyboard, but I was looking over here at the screen thinking, wow, these guys are amazing.  It was just - it was great.  And then of course I heard that everyone agrees that it was a great game.  It was like a fabulous game for me to have, like, lose my football virginity.



LEO:  It was.  A lot of them are not.  A lot of times the Super Bowls are kind of a letdown after great playoffs and all of that.  But, yeah, this was an unusually good game, and it was hard fought down to the bitter end.  And I think anybody could have won it.  I'm glad to...



STEVE:  And some amazing plays.  The guy who was, like, bouncing the ball around and then finally ended up grabbing it at the end and keeping it off the ground.  And it's just like, wow, these guys just don't give up.



LEO:  Yeah, it's pretty incredible.  Plus there's the great ads in between, which is always a lot of fun.  So, yeah.



STEVE:  Oh, and that halftime spectacular.



LEO:  I think you also saw the best halftime ever.



STEVE:  Wow.



LEO:  I'd venture that.  And it's interesting see the technology.  And by the way, concerts now are doing that everywhere.  Projection has become a high art.  I first really kind of realized that when John took us to see "The Wall," Roger Waters' "The Wall."  And when they build the wall, the projections on the wall are pretty spectacular, but now have gone since to other big-time concerts.  And the projections they have, the capability they have is amazing.  And you really saw the state of the art there on the stadium floor with Katy Perry on the halftime.  They were used at the Olympics, I think.



STEVE:  Yeah.  There was also a Beatles retrospective, has it been, what, 50 years or something?  I think it might have been a 50th anniversary.  Anyway, they used a lot of graphics.  But they were just sweeping, huge, and dynamic, and well produced.  No, I mean, we're just - we're beginning to get all this stuff figured out.  So, yeah.  But, oh.



LEO:  And we should give credit to a guy named Stan Honey, apparently, who's the guy who invented the yellow first-down line and hockey puck trails.



STEVE:  Oh.  First time I saw that on the grass I thought...



LEO:  Isn't that great?



STEVE:  Because, I mean, yeah.  As a programmer, and I've messed with visual stuff, I look at that in terms of pulling that off.  And it's just like, oh, my god.  And everyone else is like, yeah, okay, yeah, so?  But it's like, no, write some code.  Like, make that happen.  It is hard.



LEO:  Yeah, yeah.  This guy apparently is quite the genius.  The company's called Sportvision or Sportsvision.



STEVE:  They have all those little bots floating around over the stadium, I mean, you know, to get amazing camera angles and follow guys running down the field and everything.  It's like...



LEO:  It's pretty amazing.



STEVE:  It's just incredible stuff, yeah.



LEO:  Sometimes we'll sit down, and we'll talk about the audio, as well, because Alex Lindsay has done some NFL audio, and it's really interesting what they do.  They wire the shoulder pads and stuff.  It's very interesting.



STEVE:  And, you know, cable providers' availability to turn up the bandwidth and turn down the compression, and it really looked like we were seeing sharper video for the sports event than - and of course that's traditionally been done because sports was one of the early drivers of HD sales.



LEO:  Yeah.  Well, there were, I understand, three or four 4K cameras at the Super Bowl, but they never used them for 4K because of course nobody has, you know, there's really no way to broadcast 4K.



STEVE:  Nowhere for it to go.



LEO:  But what they were doing is using it to zoom in because they have - they can take one quarter of the screen, and that's 1080P.  So they had 4X zoom, basically.



STEVE:  And speaking of which, at the very end of MacBreak Weekly, Alex was - was that an oversampling interpolating piece of software?



LEO:  That's a good question.  Hydra, we were talking about, a camera app for the iOS platform.  And it's interesting because I don't know how it works.  It shoots 50 shots of handheld, and he said even more if you're on a tripod.  And somehow...



[Crosstalk]



STEVE:  Yup.  Because, think about it, I mean, you're - if you oversample, that's what classic oversampling is.  You take a huge number of photos of the same thing, you are going to be able to mathematically increase the effective resolution.  So, you know, in order to interpolate.  But, I mean, to see you zoom in from such a distance on the text on that screen.  That's just amazing.



LEO:  That was pretty impressive, wasn't it.  Yeah, I have to play with this a little bit.  That was Alex's pick on MacBreak Weekly, Hydra, H-Y-D-R-A.



STEVE:  Very cool.  So...



LEO:  Yeah.



STEVE:  Today is the long-awaited episode that is going to disappoint some people, unfortunately, who may have been over-relying on the guarantees of anonymity that the Tor network promises.  There was a paper that caught my attention, which I ended up being a little disappointed in.  But the references, it had, like, two pages of references to prior work.  So I dug deep and looked at everything that's been done.  And bottom line is I wouldn't trust Tor to my anonymity any longer.  It was a nice experiment.  We first talked about it in Episode 70 in March of 2008.  And we've revisited it a few times.  But the designers made some choices which arguably back then may have made sense.  But they're now built into the system, and in 2015 you can't count on them any longer.



LEO:  Oh.  Oh, dear.



STEVE:  So we're going to look at unmasking Tor's anonymity promises.  And unfortunately, there's not much left when we really dig down.  But we're going to talk about the news of the week also.  There were two main things that happened.  And that is news of Regin's apparent heritage.  And just as we were going to air last week I talked about a vulnerability that I erroneously associated with Openwall.  It turns out that's just where the link came in from a reposting to the Openwall list.  But it wasn't about Openwall at all.  It's about mainstream Linux, and it's really bad.  So we'll talk about that.  I saw in the mailbag an interesting question about SQRL I wanted to talk about, and then we'll plow into Tor.



LEO:  Steve Gibson, you've got the security news for us?



STEVE:  Yeah.  So first item is that Der Spiegel released some additional Edward Snowden documents, probably now about three weeks ago, maybe a little more than that.  And those discussed a project that the NSA was known to have had called QWERTY, Q-W-E-R-T-Y, named, of course, after the top row, the top left row of characters on our typical QWERTY keyboard.



In looking at the documents, a number of security researchers around the world, and specifically the guys at Kaspersky Lab, thought they looked familiar.  And they dug into their Regin code and found absolute clear duplication, meaning that there is a strong reason to believe that Regin, which we were previously thinking, due to the targets that it had been aimed at, was probably not a Western tool, but may have, for example, been Russian in origin because the target seemed to be us, seemed to be more Western-oriented.  But the evidence strongly implies that this is another one of the tools by the so-called Five Eyes team.



Five Eyes is Australia, Canada, New Zealand, the U.K., and the U.S., which are bound by a multilateral agreement called UKUSA, which is a treaty for joint cooperation in signals intelligence.  And this specifically looks like it was originally Australian in origin, but is now tied into this product that is directly traceable back to the NSA.  And in fact in the first page of our show notes, I took a snapshot of a screenshot showing side-by-side code of Regin on the left and QWERTY on the right.  And that particular snapshot highlights one instruction, a push instruction.  But if you look above and below, it's all the same code.  And there's just no question that this came from the same source.



So even though attribution is notoriously difficult, and of course we were talking about this with regard to the Sony attack and where that came from, it really looks like there's some serious cyberespionage technology available to our forces, I mean, to our governments, and being shared among these countries.  And remember that Regin is the one where attacks were - after it was identified, we looked at how it was being used, and it was things like going in and getting the itineraries of guests in hotels and figuring out who was traveling and which people were meeting with each other.  And, I mean, true sort of cyberespionage, where you're creeping around the Internet, pulling records out from where you need it.  And so this thing has infiltrated lots of networks in the past, and it looks like it's another one of the tools that the West has available to it.  So really, really much more interesting than we thought.



Okay, now, last week I had mentioned Ghost.  It was a vulnerability that had just been posted.  And as I mentioned at the top of the show, I mistakenly believed that it was tied to Openwall because it was in the Openwall mailing list, and that's the link that I had.  And I promised to look into it for today's podcast.  Well, it turns out it's just a straight-up very bad Linux vulnerability.



LEO:  Oh.



STEVE:  Which is, yeah, which has existed since 2000 and was sort of coincidentally removed in 2012.  But it existed for 12 years, and it was never perceived until researchers at Qualys just were doing an internal security audit and stumbled over this thing.  Even though it was removed, because it wasn't at the time seen as a security vulnerability, it still exists in many packages which are deployed that haven't bothered to update themselves to the latest, to the very latest.  It's in glibc.  And it is one of the more fundamental functions that exists.  It's in the function - I'm looking for it in my notes.



LEO:  Glibc is on every - is everywhere.



STEVE:  Oh, it is.  Well...



LEO:  That's a library that basically you need.



STEVE:  Well, yes, because it provides gethostbyname function.  Gethostbyname is DNS lookup.  Gethostbyname, just like it sounds.  Get the IP of this computer by its name.  So Qualys immediately alerted the major Linux distributors about the security hole.  And by the time this thing became public, most had released patches for it.  It's interesting in that you would tend to think that it would be difficult to exploit.  It turns out that it overwrites the heap, which is - the stack is one of the dynamic allocation structures that grows down.  The heap typically grows up from the bottom of memory, where the stack grows down from the top of memory, just in terms of the way memory is allocated.  And at most a character pointer can be overwritten.



Now, on a 32-bit machine, that's four bytes of memory.  On a 64-bit machine, that's eight bytes of memory, that is, that's the natural size of a pointer on those hardware architectures.  And so you'd think, eh, you know, you really can't do much with four bytes, or maybe eight bytes.  And what you can overwrite is strictly limited.  You can only overwrite digits and dots and a terminating null.  So what that tells us is that there was a mistake in the function such that the DNS, sort of the ASCII version of the DNS IP address could, like, just barely overflow the end of some buffer, so only those characters.



Well, it turns out that, despite those limitations, arbitrary code execution can be achieved.  And as a proof of concept, they developed a full-fledged remote exploit against the Exim mail server, which bypasses all existing protections - address space layout randomization, the no-execute bit on the segments, and everything.  And I think it was ZDNet that wrote, "Unlike some security announcements, these guys are not crying wolf.  Qualys has developed a proof of concept in which simply sending a specially created email to a mail server enabled them to create a remote shell to the [Linux] machine."



LEO:  Wow.



STEVE:  Yeah, it's like, holy crap.



LEO:  It's convenient.  That's really convenient, yeah.



STEVE:  Yeah.  So, okay.  So because it wasn't seen before as a security problem, there was no move to go back and retroactively make sure that nobody was using this 12-year span of glibc libraries.  So it exists in any Linux system that was built with glibc-2.2, which was released on November 10, 2000; and it was fixed in between releases of glibc versions 2.17 and 2.18.  So anyway, this is the kind of thing where you absolutely want to make sure, if you have exposure to the public Internet, specifically if you're running a server, a Linux Red Hat, Debian, CentOS, Ubuntu, I mean, just across the board.  As you said, Leo, glibc is intrinsic to Linux, its core networking functionality.  So this was a biggie, definitely something that you want to make sure you've gotten yourself patched for.



LEO:  Yeah, wow.



STEVE:  I ran across a fun question about SQRL that I wanted to address because it represents sort of one of the main features of the protocol which might not be clear to people.  Jay Littlefield in San Francisco is a listener.  He wrote, saying, "Hello, Leo and Steve."  He said, "Fan of the show here.  I've been listening to Security Now! on my commute for the past several years.  I'm a proud owner of SpinRite and, thanks to you two, a Harry's razor convert."  He said, "I really appreciate the great shows you produce.  I'm also very excited about SQRL and hope to use it on my own websites as it becomes available within the major website development packages."



And that work is underway.  In fact, there are guys just waiting for me to put the final, the finishing touches on the protocol because I've been adding some features and taking away some features as I've been just pushing this, like, right up to the finish line because I sort of overdesigned some things.  And when it got to actually doing it, it's like, wait a minute, we really don't need this.  And I want to keep things as simple as possible so that other people implementing SQRL don't need to put stuff into the protocol that we don't end up actually using.



Anyway, so he said, "Steve, I have a SQRL question for you that I've not been able to find the answer to in any of your podcasts or on your website.  You often cite the fact that SQRL creates a unique public/private key pair for each individual website accessed.  Because of this, a breach of one website will not compromise your identity on any other website, unlike the common practice of reusing passwords.  This is a great improvement.  But what about your identity on the compromised site?



"Let's say I'm an active SQRL user for all of my web transactions.  I read about a major security breach at, say, Target.com, where I'm an active SQRL user.  Let's assume hypothetically that their customer database has been compromised, and I'm instructed to reset my password for my account.  If I'm using a password, I can do that.  But passwords are supposed to be archaic once SQRL arrives.  If so, then what's the SQRL equivalent of a password reset for an individual site in the event of a breach?



"You've mentioned SQRL has the ability to change your master ID should it become compromised.  But a breach of my SQRL credentials at Target.com, by definition, does not compromise my identity anywhere else on the web.  Can you elaborate on how this situation should be handled by a SQRL user?  I'm afraid the answer to this question is currently lost on me.  Thanks again for a wonderful show, all you do for the community of followers.  Regards, Jay."



Okay.  So what's different about SQRL as opposed to a username and password is that SQRL is a network protocol, whereas a username and password is static data that you're requiring the Target website to hold secret.  And I've often said SQRL gives a website no secrets to keep, which is part of its strength.  That's the large part of where its strength derives from and the reason I got so excited about this when the idea occurred to me.



So the idea is that, if Target, in Jay's example, were compromised, and their whole user database got stolen, it doesn't matter because what they get is your public key.  But what someone needs to impersonate you, that is, even if they had your public key, they're not able to impersonate you at Target.com; whereas if they had your username and password, they could.



The reason is that the SQRL protocol, the core of it is a challenge to you.  The website, like Target.com, sends a nonce, a random blob of gibberish, doesn't matter what it is at all.  It can be encoded with specific information to make the website's job easier, but it doesn't have to be.  It just has to be unique.  And then the key is you sign this random blob with your private key that never leaves your device, never needs to.  And that's the whole point of the protocol.  You sign the blob and return the blob with your signature.  And the key-signing technology verifies with the public key that you have properly signed the private key.



So it doesn't matter if bad guys get your public key for Target.com because, if they tried to impersonate you, Target would send them a blob and say, okay, prove that you have the private key matching the public key which you are claiming is yours.  And no bad guy could do that.  So that's the answer, Jay.  And it's part of what makes this SQRL protocol so strong is that we don't give websites any secrets to keep.  And we're dynamically proving over the Internet through this protocol that, yes, we know the secret that matches the public key that we gave you.  So, very cool.



And I got a fun note from Igor - okay.  I didn't practice his name beforehand.  Koveshnikov.



LEO:  Thanks, well done.



STEVE:  Let's hope.  Sorry, Igor.



LEO:  I think it's Koveshnikov.



STEVE:  Koveshnikov.



LEO:  Or Koveshnikov.  Depends on...



STEVE:  In New Jersey.



LEO:  ...how Russian Igor wants to be.



STEVE:  Well, I think he'll forgive me.  He says, "Hello, Steve and Leo.  About a week ago my former boss brought me his laptop that wouldn't boot.  I remember I installed a Crucial M4 256GB SSD in it and was puzzled what could be wrong with the SSD.  When I turned on the laptop, I could get to first mouse cursor appearance in Windows, and then the hard drive light would become solid lit, and nothing would happen.



"I connected the SSD using USB-to-SATA adapter to my computer.  I could read the drive, but it took me about four days to retrieve 170GB of documents.  It would freeze on some files for long minutes and then would continue to copy.  It behaved exactly like a damaged mechanical hard drive, just without a clicking noise.  Later, it turned out that my boss followed my suggestion, and all his documents were backed up by Carbonite.  Still, I always try to retrieve most data before I start playing with drives."  Actually, that's all the sentence says, so I'm not sure where he was going with that.



And he says, "I always wanted to try SpinRite on SSD, but it doesn't make sense to run maintenance on them."  Well, that's not true, but we'll talk about that later.  "Here was my opportunity, and I used it.  Started on Level 1 just to see what SpinRite makes of the drive.  It ran quickly, but showed some R's, but nothing changed when I tested a boot.  Level 2, however, completely fixed the drive.  When I rebooted the laptop, I got the login screen, and the laptop runs just like new.  It's easy to understand what happens to damaged mechanical drives," he writes, "but really hard when it comes to SSDs.  My suspicion is it's software/firmware issues.  Something happens to internal table of cell assignments.  But then how is SpinRite able to fix it?"



So, okay.  It turns out that the push for SSD density has done the same thing to solid-state technology as it has done to mechanical technology.  In other words, they are cramming, arguably, more data into a small space than they should.  And they've become reliant in solid-state media, just the same as they have with physical spinning media, on error correction.  So that they're, like, they're on the hairy edge, sort of operating in the gray, where they know they may not be able to get some bits back, especially as those age over time on an SSD and as the technology of the SSD wears the SSD increasingly.  So they fall back to algorithmic math to fix, to figure out what the missing bits that could not be read are.



And so SpinRite actually is as useful, from all of our experience, on an SSD as it is on a hard drive.  And it can recover them and make them faster.  And I would argue that Level 2 is perfect maintenance.  It is not writing to the drive unless it needs to.  So you use SpinRite to perform preventative maintenance on an SSD, and it'll keep those U's ever from showing up.  Definitely worth doing.



LEO:  Thank you, Igor.



STEVE:  Igor.



LEO:  No, Igor Koveshnikov.



STEVE:  Igor.



LEO:  Igor Koveshnikov.  Let's talk Tor with Mr. Steve "Tiberius" Gibson.



STEVE:  Okay.  So we opened the topic back on March 28 of 2008, seven years ago, with Episode 70, that was titled "Internet Anonymity."  And we came back and revisited it two years ago on the 8th of March in 2013 with our episode on "Tor Hidden Services."  That was the one where we sort of followed the advance of Tor where they'd added the protocol that allowed the servers themselves to be hidden.  So rather than thinking of Tor sort of as a cloud, where outside the cloud you had both clients and servers, and they were all connected to the cloud, and the cloud mushed it all around so that nobody who was looking could figure out what went in and what came out where, but essentially the servers existed on regular public IPs, the hidden services changed that, hiding the servers in .onion domain names so that you got them by some cryptic URL .onion.



So that was then.  Then recently a piece of research was published.  And this is only the latest among scores of papers because this has really interested academia.  People have been asking, well, like doing academic attacks on the protocol.  And I should mention, when I mention "attacks" throughout the rest of this podcast, I don't mean malicious DDoS sorts of attacks.  I'm talking about attacking the protocol, meaning academically tearing it apart, looking for weaknesses in the design and also weaknesses in the nature of what it has to live on top of, meaning the packet-switched Internet.



And it turns out that's the Achilles heel of Tor is that the Internet was never designed for anonymity.  It wasn't.  Back seven years ago, I was looking through some of that transcript from back then, and I talked about how an IP address isn't a person's name, but it's easily mappable to an endpoint on the Internet because the Internet was designed, back when it was first created, only with the assurance that an existing Internet address could put a packet on the Internet, and it would eventually get to the other Internet address, where the packet contained both the source IP and a destination IP.  That was all it was supposed to do.



Anonymity didn't even occur to these guys.  That's many generations of evolution of application of this underlying networking structure later.  People start saying, eh, but you know we'd like to also - anonymity would be handy.  It would come in handy for, like, people who were trying to deal with repressive regimes, who want that feature added to their networking experience for whatever reason.



So the piece of this most recent research that caught my attention claimed, it made the claim that 81% of Tor users can be deanonymized by analyzing router information.  So I looked closely at that, and I was not so impressed.  What these guys did, I mean, their research was good.  So I don't mean that I was not impressed by their research.  But it was sort of - they did things to create that claim.  Their idea was that instead of performing very careful, high-resolution timing analysis of individual packets, which is what you would normally have to do in order to attack Tor at the traffic analysis side - and we'll get to that in a second.



But rather than doing that, they were using a much more sort of soft flow mapping that Cisco builds in to many of their routers, known as NetFlow.  NetFlow technology does more sort of aggregate analysis.  And due to its nature, you don't have the fine-grain visibility into individual packet timing that you would otherwise get if you were monitoring the actual flow.  But on the other hand, it's convenient to use NetFlow because it's built into so many routers.  And essentially the router is doing a lot of that job.



So these guys asked the question, could we use NetFlow, something sort of as fuzzy instead of as focused, could we or how could we use NetFlow to deanonymize Tor traffic?  Sort of as an academic exercise.  What they had to do in order to pull this off is deliberately interfere with the traffic coming from a server back to the user.  Now, that's a powerful technique.  And we're going to come back to that in a broader context also, and look at just exactly how powerful that is.  But it's powerful enough that, by delaying or dropping or blocking bursts of traffic from the server, NetFlow built into routers, as fuzzy as it is, is enough.  And so that's what they were saying, where they sort of came up with this broad, 81% of Tor users.  I'm less impressed with that.



But what happened was that paper was full of references to the prior work that had been done.  And so I spent a lot of time digging through that and came away with the unfortunate conclusion that Tor can no longer be relied upon for anonymity.  That is, if you presume that someone like the NSA, who has that kind of scope and reach, if you presume that someone like that wants to penetrate the anonymity guarantees that Tor provides, the work that's been done in attacking, and I mean that in the sense of academic attacks on this question, how good is the anonymity, the work that's been done demonstrates Tor doesn't actually provide much in the way of anonymity for that class of attacker.  And so it's important to understand that it definitely obfuscates your traffic.  But if someone is absolutely determined to find out who you are, they probably can, that is, if a nation-state-scale actor wants that.



There was a perfect example of that was recently reported by Ars Technica, where the FBI was pursuing some people involved with what was known as SilkRoad2.  And the article says, "Despite the use of Tor, FBI investigators were able to identify IP addresses that allegedly hosted and accessed [so that is both sides] hosted and accessed SilkRoad2 servers, including the Comcast-provided IP address of someone named Brian Farrell, who prosecutors said helped manage SilkRoad2.



"In the court-filed affidavit, DHS special agent Michael Larson wrote:  'From January 2014 to July of 2014, an FBI New York Source of Information [and they said in parens (SOI), so the source of information remains unknown, but SOI is a term of art] provided reliable IP addresses for Tor and hidden services such as SilkRoad2, which included its main marketplace URL, its vendor URL, its forum URL, and its support interface.'"  And I cut out all the other URLs because they're just gibberish.  But, for example, the support interface is "uz434sei7arqunp6.onion."  So they're all like that inside of Tor, and they're all supposed to be only available to people who are inside the network, specifically not to someone you're trying to hide from.



"The SOI [that is, that Source of Information] ultimately led to the identification of SilkRoad2 servers [which are supposed to be masked] which led to the identification of at least another 17 black markets on Tor," that is, black markets operating on Tor.  "The SOI also identified approximately 78 IP addresses that accessed a vendor.onion address.  A user," this affidavit explains, "cannot accidentally end up on the vendor site.  The site is for vendors only, and access is only give to the site by the SilkRoad2 administrators and moderators after confirmation of a significant number of successful transactions.  If a user visits the vendor URL, he or she is asked for a username and password.  Without that, the vendor website cannot be viewed."



So this is real-world demonstration that there exists technology for penetrating the Tor network.  Now, it doesn't have to necessarily be traffic analysis.  These people may have been doing other things.  There have been ways that the FBI has had of, for example, using various sorts of persistent cookies using Adobe Flash and Firefox I've seen specifically named, that is, non-Tor means of deanonymizing users, in which case it doesn't matter whether they're in Tor or not.  But we definitely know from the academic research that's been done of strict pattern analysis that it is possible to penetrate the guarantee that Tor provides.  And the reason is the Internet, as I said earlier, was just never designed to provide anonymity, and it really doesn't.  So we should look at Tor as an experiment in how could anonymity be provided.  But the fact is, it is extremely difficult to actually achieve.



Now, we could break Internet communications into two broad categories, low latency and high latency.  An example of a high-latency service is email, where it's a store-and-forward system.  And there, because you don't need something delivered in real-time or near real-time, you can achieve a much higher level of anonymity, especially if you do other things like padding message lengths, and obviously encrypt the contents, in order to obscure when an object leaves the anonymity network and when it enters.  The problem is that that's not useful for web surfing or for other applications, SSH for example, where you're sending keystrokes through an SSH tunnel, and you'd like them to get there in relatively short time so that you're able to get the answers back in relatively short time.  And of course web surfing is inherently a relatively low-latency activity.



And that's really the Achilles heel of Tor is that Tor was deliberately designed - I mean, and again, we should remember this was sort of done initially as an experiment, a project to see what could be achieved.  And it grew over time, and it acquired notoriety.  And it does offer some guarantees, but it is far from perfect.  And so no one should assume that it is perfect.  And also the designers, the original designers of Tor made some assumptions and made some compromises that are now coming back to haunt us.  I found a very nice summary in one of these academic papers that summed it up this way.



They wrote, "Tor aims to protect against a peculiar threat model that is unusual within the anonymous communications community."  And so they made that assertion first.  And then they step back a little bit to say, "It is conventional to attempt to guarantee the anonymity of users against a global passive adversary who has the ability to observe all network links.  It is also customary to assume that transiting network messages can be injected, deleted, or modified; and that the attacker [again, attacker meaning someone trying to penetrate the anonymity] controls a subset of the network nodes.  This models a very powerful adversary, and systems that protect against it can be assumed to be secure in a very wide range of real-world conditions."  The point this paper was making was that's not Tor.



It went on to say, "Tor, on the other hand, assumes a much weaker threat model.  It protects against a weaker non-global adversary," that is, an adversary who doesn't have complete visibility into the network, which as we know a contemporary powerful adversary like a nation-state actor might.  And then it says, "who can only observe a fraction of the network, modify the traffic only on this fraction, and control a fraction of Tor nodes.  Furthermore," the paper says, "Tor does not attempt to protect against traffic confirmation attacks, where an adversary observes two parties that he suspects to be communicating with each other to either confirm or reject this suspicion.  Instead, Tor aims to make it difficult for an adversary with a poor a priori suspicion of who is communicating with whom to gain more information."



LEO:  A poor AV wizzit what?  You want to translate the Latin, please?



STEVE:  A priori, facts known ahead of, in advance of, your intent to confirm.



LEO:  Ah, okay.  Just checking.



STEVE:  So what we discussed back eight or seven years ago was the crypto model.  That was the whole onion concept.  And nobody has attempted to attack the crypto of Tor because, as we said then, it is fabulous.  I mean, it's fun.  It's solid.  And just to briefly recap, because that's not where the problem is, the user chooses a circuit through a group, sort of a cloud of Tor nodes, where they first at random choose one Tor node and negotiate keys with that Tor node.  For example, the Tor node will give them its public key, and nobody knows its private key. They can then use its public key to create traffic that only it is able to decrypt.



So then you can think of them using that to jump their presence to that node, where then it becomes a proxy for them.  From that position, they then choose another node in the Tor network and similarly get its public key and then generate communications that only it is able to decipher.  And that's going through their first link now, which only that first link can decipher, to the second link.  Then they do it a third time.  They then essentially move their virtual presence out to that second node, running now through two proxies.  They then choose a third node, similarly negotiate it, negotiate with it.



Okay.  Now what they have is the public keys for a sequence of three nodes in the Tor network.  And they generate the traffic they want to make public.  And they first wrap it in the third  node's crypto, using its public key.  Then they wrap that in the second node's crypto, using its public key.  And they finally wrap that in the first node's crypto, using its public key.  Thus the concept of an onion with, like, shells, successive shells of crypto.



What's cool about this is that they send this onion to the first node.  The first node can only decrypt the outer shell because that's the only thing that it has the key for.  It was unable to see into any of the traffic that you used to the second node.  It may have seen you get that second node's public key; but as soon as you established communications with that second node, using that second node's public key, it was then blind to it.  So all it can do is take that outer wrapper off of the blob that it's received.



What it finds there is instructions about where to send it, that is, to the second node.  So it forwards that blob that it cannot see into because that blob is now encrypted on the outer shell with the second node's crypto.  It forwards it to the second node.  Second node takes that outer wrapper off.  Now it's got a blob that is becoming smaller, but it has instructions to send it to the third node.  The third node receives it.  It takes its crypto off.  And finally it gets to the original content you, the user, wanted to send, which it places on the Internet, and out it goes.



And the beauty of this architecture, which we discussed back in Episode 70, if anyone wants a deeper dive, is that the process is bidirectional, that is, when this information comes back, the nodes are able to reverse the path.  No node knows anything about the process except the next node that it forwards it to because it can only see the instructions that are now on the outside after it took its layer of crypto off.  So you get through this very clever cryptographic system, strong anonymity.  That's the crypto model.  The problem is the traffic flow model, and that's the Achilles heel.



Now, the designers understood this, and they did what they could to weaken the applicability of the traffic flow model.  For example, if everything that came in was routed deterministically to some exit node, that is, a packet goes in, and that exact packet comes out, then that would be a problem.  So random-length padding is added to obscure that.  Some random timing is introduced throughout this entire system.  And, specifically, we presume that the whole Tor system is busy.  The busier it is, and the larger it is - right now it's like 5,000 nodes.  Once upon a time it was 50.  So it's gotten a lot bigger.  That's good for everybody who wants anonymity through the network because it just means there's a lot more going on.



So you want busy Tor nodes with lots of traffic coming in and lots of traffic going out because one of the things it does is it puts every flow of communications - I just described one flow, one circuit - through this three-node Tor network.  It puts them all into a round-robin queue such that every flow has sort of its own buffer.  And the first thing Tor does is chop everything up into 512-byte cells.  And a cell is a term of art within the Tor network.  So even though packets may be larger coming in - and Tor operates over TCP, and we know TCP is flow-based.  So packets of different sizes are coming into the first Tor node and being reassembled into a continuous stream.



Tor then chops those into 512-byte cells that will definitely destroy the original packet boundaries.  So basically it's repacketizing the traffic into these fixed-size 512-byte cells.  The fact that they're fixed size means that they no longer reveal anything about the incoming packet sizes.  And then, in a round-robin fashion, it sends them back out.  So nobody looking at the outside of this Tor node can easily map up the variable-length TCP packets coming in from hopefully a large number of sources, and these fixed-size 512-byte packets, which are exiting full encrypted, wrapped in some number of onion wrappings, going off to other Tor nodes.  That's all they can see.



So, I mean, you can see that the people who designed this intended for it to be daunting.  The problem is that this ends up being, from a traffic flow model, a bit like metadata.  We've talked about the power of metadata.  Even though you can't see into a flow, you can still get information from looking at the fact of the flow.  So somebody who decides, okay, inside the Tor network we have no visibility into that.  We've got 12-byte cell packets, encrypted, bouncing all over the place.  But ultimately it has to emerge.  And by looking at the aggregate short-term packet sizes and timing, and performing a statistical analysis over what goes in and what comes out, what these academic papers have shown basically over and over and over is that it is very possible to form an opinion.  So the first part of the attack is having a guess.



And in fact we've seen this before.  We were just talking about this when we were talking about how the Enigma cipher was broken.  Basically those bombes, they were making guesses.  They were saying, we know it's not this set of rotor positions; we know it's not this set of rotor positions; nor is it this set.  But it might be this set.  Let's try those.  And so the bombe would stop, and the guys would quickly read out a candidate set and then go try it.  And then the bombe would start up again, or be restarted, looking for the next set.



So with Tor, it turns out, attacks like that also work.  It's possible to rule out a huge number of possible links that are in fact - where it just doesn't work, based on what somebody knows of the Tor network.  But you then end up with a bunch of candidates.  And then you apply the second-level attack, which is testing the candidates.  And it turns out that is a huge weakness.  So if an active attacker believed that two points were communicating and had the ability to deliberately introduce deterministic changes in the traffic flow, they would see evidence of that coming out the other side.



And so the final real weakness is that, if you have an active attack, rather than a passive attack, meaning that you do something to alter the traffic, you can quickly confirm or rule out assumptions of possible pairings.  And when you then operate at the scale of a nation-state, with big taps into the Internet all over the place, and when Tor is an obvious Target for bad guys using it to mask their identity, you've got means, you've got motivation, and you've got budget in order to pull this off.



So I would consider that Tor is useful as part of a defense in-depth strategy.  That is, I wouldn't say don't bother using it if you really want anonymity.  But I would say, first of all, don't do anything illegal.  Don't do anything that you wouldn't want the federal government to know about because they fit the profile of someone able to penetrate Tor.  I would say, unfortunately, the dream of a Tor user of just being able to sit back in their home or apartment somewhere with their public IP address and use Tor with confidence that they're able to do anything they want to at all, and no one can get them because they're using Tor, that's just not real.



So the only way, I mean, if you absolutely need anonymity, is to roll together old-school approaches and new-school.  Go somewhere to do this as far away from home as convenient.  Be anonymous there.  Pay with cash.  Don't go somewhere familiar.  Don't know anyone.  Don't make any friends.  Don't talk to anyone.  Don't stay long.  Plan ahead.  Rehearse for speed.  Get it done and leave.  Don't do anything there that involves your own real-world identity.  Pay with cash.  Change the MAC address of your machine.  Maybe buy a cheap laptop just for this purpose so that it knows nothing, you have no history tied to it and so forth.



And I would say, since you have control over Tor, use more than three nodes.  Don't use the default settings.  Use as many as you can so that you're - oh, and use widely geographically dispersed Tor nodes.  Those will be slower because all the traffic bouncing around has to go through all of those locations.  So, yes, it's not going to be as quick and easy.  But to get anonymity, it can't be.  Do what you need to do and then pack up shop and leave.  So new school and old school.  But unfortunately, all of the research demonstrates today that Tor was an interesting experiment.  But what we know about what the NSA is capable of doing and some evidence of what has happened shows us that we just can't rely on it for one-stop shopping of being anonymous on the Internet.



LEO:  Is there a - there is no technol- oh, go ahead, sorry.



STEVE:  I was going to say, and remember that things like cookies, persistent cookies and Verizon supercookies and all those sorts of things, unless you're very careful about stripping them out of your traffic, they're there, too.



LEO:  Yeah.  By the way, Verizon says it's going to give you a true opt-out.  We'll see.  Haven't done it yet.



STEVE:  Yeah, saw that, yeah.  No.



LEO:  Is there any way to be anonymous?



STEVE:  The problem is this notion of near real-time versus high-latency non-real-time.  I mean, if something like Tor existed for email, then the real Achilles heel is traffic.  And I don't know how you can arrange that.  If your traffic disappeared into something large, where there was no further visibility, like say you disappeared behind a university-scale NAT, where all of UCLA was 10-dot, you know, inside their network, and then you also took some old-school steps to be anonymous, it's difficult to know how they could penetrate.  But maybe UCLA NAT router tracks you inside.  So if law enforcement came to that IP, they'd say, okay, now we need your records to figure out who inside the network was using this at this time of day.  So it probably still is possible.  I think anonymity is something of an illusion on the Internet, Leo.



LEO:  You could.  But, I mean, let's say you did use a library, and you didn't check in, and you hid, you disguised yourself, and you...



STEVE:  You used a hoodie,



LEO:  And you keep moving, I think is obviously the key.



STEVE:  Yup, yup.



LEO:  You could do some stuff anonymously; yeah?



STEVE:  I do think, I mean, basically, though, there we're saying the Internet isn't providing our anonymity, the real world is providing our anonymity.



LEO:  Right.  You have to be anonymous in the real world for that to work; right.



STEVE:  Yes.



LEO:  Because if the real world knows who you are, the Internet will somehow cough that up or can be made to cough that up.



STEVE:  Unfortunately, I think it really can.  So what I wanted to do was to basically revisit this and dispel any belief in our listeners that use Tor and you're golden.  You're really not.  If somebody wants to find you, they probably can.



LEO:  All right.  Fascinating stuff.  As they're pointing out in the chatroom, Ross Ulbricht was arrested in a library.  So there you go.



STEVE:  He stuck around too long.



LEO:  Waited a little too long to move on.



STEVE:  You don't want to be chatting up the librarian.  You want to keep your head down, get in...



LEO:  Keep moving.



STEVE:  Oh, and don't go back.



LEO:  And never go back.



STEVE:  Yes.



LEO:  But, you know, if you watch any of these movies, the Bourne movies or whatever, there's plenty of good blueprints there for anonymity.  And keep moving is a big one.  And never go back.  Never retrace your routes.



STEVE:  Yup.



LEO:  Can Tor be fixed?  Or is it inherently a problem?



STEVE:  I think this is the problem, is that it's a layer on top of a system which was never built for anonymity.  And we've talked about how difficult it is to fix things that are layers on top of other things.  Like a firewall is blocking traffic that wants to get through.  So instead of it somehow operating in the reverse direction, where it's blessing traffic that might be permitted, it's trying to prevent something that the system was designed to do.  And the Internet was never designed, never designed for anonymity.  And in the face of traffic analysis, it really doesn't provide it.



LEO:  That's such a good place to stop.  I think that's the coda for all of this.  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, the world's finest hard drive maintenance and recovery utility.  All the work he does on SQRL, all that other pro bono stuff he's just doing because he's interested, and he wants to give it away.  It's all at GRC.com, as well as this show, 16Kb audio for the bandwidth-impaired, fabulous handwritten transcriptions of each and every episode.  Elaine was very grateful for the plug you gave her last week, by the way.



STEVE:  Well, she's earned it, so, yes.



LEO:  And you'll also find a copy of this show at our spot over here, TWiT.tv/sn for Security Now!.



STEVE:  The mothership.



LEO:  Every episode is there.  And what?



STEVE:  The mothership.



LEO:  The mothership.  I thought you said something else.  But okay, thank you.



STEVE:  TWiT.tv.



LEO:  Yeah, TWiT.tv/sn, YouTube.com/securitynow, lots of places.  And of course wherever you get podcasts, including iTunes.  Or use those great TWiT apps.  You'll find them on every platform.  We didn't write them.  We're just grateful that there's some great developers out there.



STEVE:  They work great.  I use them all the time.



LEO:  Yeah, Craig Mullaney and Mark Hanson, there's some great people, Dmitry Lyalin, who just do this out of the goodness of their heart.  All right.  We'll be back here next Wednesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2100 UTC, for yet another edition, and possibly a Q&A episode.



STEVE:  I think so.  You did say Wednesday, and you meant Tuesday.



LEO:  Tuesday, pardon me, Dudesday.  So if you have a question for Steve, GRC.com/feedback.



STEVE:  Yes.



LEO:  Or you tweet him.  @SGgrc is his Twitter handle.  And that's another way to reach Steve Gibson.  Thank you, Steve.



STEVE:  Thanks, Leo.  Talk to you next week.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#494

DATE:		February 10, 2015

TITLE:		Listener Feedback #206

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-494.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Boy, Microsoft pushed out a lot of patches this Patch Tuesday.  He'll talk about that.  And we'll answer your questions.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 494, recorded February 10th, 2015:  Your questions, Steve's answers, #206.



It's time for Security Now!, the show that protects you and your loved ones and your security and your privacy online with the man in charge of all of that, Steven "Tiberius" Gibson, the Gibson Research Corporation, GRC.com.  Hello, Steven.



STEVE GIBSON:  Yo, my friend.  Great to be with you again, as always.



LEO:  Hey, we've got a Q&A episode.



STEVE:  Yup, we do.  Things have been relatively quiet.  We've got a bunch of interesting news.  We had a mega Patch Tuesday today, just landed, with 55 vulnerabilities.  And I love one of the phrases that Microsoft posted, so I'll share that.  I sort of - the Adobe patches went by, but I just thought I'd give them a nod.  The U.S. government is today announcing, I don't know if they have yet, but I know that it was scheduled for today, I got the news beforehand, the Cyber Threat Integration Center, with an awkward acronym, unfortunately, because we'll probably be using it a lot.  I thought we'd give an update on the Anthem breach.  Some news about Chrome's move to HTTP/2.  And then of course we have car hacking, we have TV eavesdropping, and the news of GPG getting a new infusion of support and more.



LEO:  Oh, good.  Oh, good.



STEVE:  So lots of fun news.  And in the show notes is the image of the week, courtesy of our friend Simon Zerafa.  I just got a big kick out of this.  It was something like - there was a caption like "Passive aggressive WiFi station ID" or something.  The two items at the bottom, I just - I got a hoot out of it.  So anyone who...



LEO:  So actually, people have started to do this with their SSIDs on their WiFi networks, putting, you know, started with "Don't steal my WiFi," and then we have somebody nearby who's an FBI surveillance van.  But now it's like there's so many WiFi signals in apartment buildings, you know, it's so cluttered, that neighbors are actually communicating with one another.  So the first access point is "You're music is annoying," but they spell your, instead of Y-O-U-R, which would be correct, Y-O-U-'-R-E, a common grammatical error.  And so the response:  "Your grammar is more annoying."  Both of these WiFi access point names.  That's hysterical.  That's hysterical.



STEVE:  Yeah.  Over by Starbucks there's someone who says something like, "The pierced chick upstairs," is like...



LEO:  Oh, wow.



STEVE:  It's like, okay.



LEO:  Hey, there's an image.  Wow.



STEVE:  I don't know where she is, but she's pierced, apparently.



LEO:  I'm sticking with my dead rock stars methodology.



STEVE:  My buddy has his named something like NORAD Southwest Listening Station.  Where it's like, okay.



LEO:  I love it.  Thank you, Simon.



STEVE:  Oh, yeah, those are fun.  So we do, we're on Patch Tuesday here.  Microsoft released nine bundles, which contained at least, it's kind of hard to count them at this stage, 55 distinct security vulnerability fixes.  Three of the patches are considered critical.  And I love the way they described it, MS15-009.  It says - you're just sort of reading along - "This security update resolves one publicly disclosed and 40 privately" - it's like, what?  Forty privately reported vulnerabilities in Internet Explorer.



LEO:  Wow.  Holy cow.



STEVE:  So, baby.  You know, and this does sort of - we've noted that there's a - it's not like it's a smooth flow.  For whatever reason, there are dead months, and then there are catch-up months.  And this is clearly one of those.  There's a vulnerability in the Windows kernel mode driver that involves the rendering of embedded TrueType fonts.  There's a TIFF vulnerability.  There's problems in Office, in group policy, in the virtual machine manager.  And something called the Microsoft Graphics Component that I haven't heard referred to before in any security update.  So anyway, nothing, like, clearly crucial, but certainly worth doing, as everyone will, I'm sure.  Oh, and I did see some notes online that in some cases this can require multiple reboots of a Windows machine.  Mine, because I fired up my Windows 7 box, which is where I run Skype from just for this, got the updates, updated everything, and it was just a single restart.  But apparently in some cases it can take more than one.  So definitely good to do.



Back in the old days we were talking about Adobe all the time.  They've had a rough couple weeks.  They released an emergency out-of-cycle update to Flash to patch a zero-day flaw that was affecting Windows, OS X on Macs, and Linux, allowing remote code execution on all of those platforms, at least where they were being employed, and noted at the time of the release that there was another known zero-day exploit that that patch didn't fix, but they'd be getting to it soon.  So less than a week later they released a second zero-day update to Flash.  So we have both of those now behind us.



I've seen Firefox has - like I did the update, and then it said, no, you're still not there.  It's like, oh, okay.  And I did it again, and then I was able to run something I was using Flash for a couple days ago.  So, and of course Chrome works to keep itself updated within its own internal update mechanism.  And so this has been pushed out everywhere.  So it's a little bit of old news, but we hadn't mentioned it before, so I wanted to.  And I don't know how we're going to pronounce this:  CTIIC.



LEO:  Yeah.  Mike Elgan had a little trouble with that.



STEVE:  It's like, what?  Okay.



LEO:  Not a great acronym.  As Mike said, it's an abbreviation, not an acronym.



STEVE:  Right.  So it's the Cyber Threat Intelligence Integration Center, whose name tells you what it does:  cyber threat intelligence integration.  So this is just coming.  It's being rolled out today.  And in sort of the preannouncement it was noted that the NSA, the DHS, the FBI, and the CIA, all of our three-letter initial organizations, each currently have their own cybersecurity groups.  And they've not been communicating in any formal fashion with each other.  I'm sure they share notes on an ad hoc basis.  But similarly to the creation of the National Counterterrorism Center, which was established after the 9/11 attacks, this is intended to explicitly create a means for the individual cybersecurity groups to pool all their resources and pool their knowledge and hopefully make us as a whole, the U.S. as a whole, more responsive and aware of what's going on in cyberthreats.  And this is clearly something that we need to take a look at in the wake of the Sony breach and then the Anthem problems and the problems with Target and Home Depot and so forth.



LEO:  Is it going to replace the DHS CERT, the Computer Emergency Response Team and these other kind of...



STEVE:  I don't think so.  I think my feeling is this is more secret.  So, for example, DHS CERT is our public-facing announcing group where we have one place to notify everybody of threats publicly.  I think this is going to be under wraps.  This is, you know, so I don't think we'll see much of what's actually going on.  The idea is that behind the scenes, much as they've had their own, the individual organizations have had their own systems, the idea is for them to coordinate and share information.  I think, you know, stovepiping is the term that's often used for saying, okay, they're just not communicating.  And they're recognizing that they'd be doing a better job overall if they were, if there was some means for them to share things.



LEO:  The consensus in the chatroom is it'll be called C-TIIC.



STEVE:  Okay.  I can go with that.



LEO:  Cyber Threat Intelligence Integration Center, CTIIC, C-TIIC.  I think it's fine.  The truth is you probably won't hear it a lot because, as you say, this is more of an internal and private secretive - and you need to do both; right?  You need a public-facing something like CERT, where people learn about security.  NSA [crosstalk] right.



STEVE:  Like OpenSSL flaws can be published and discussed.



LEO:  But you also need an internal security force, cybersecurity force.  And I gather this is more of that.



STEVE:  Yeah, and for example, one presumes that ongoing attacks, you know, these groups may be individually monitoring ongoing attacks, but they have different resources that are giving them different visibility.  And so we're not aware at the public level of, like, what attack is actually happening right now on some government servers somewhere.  Presumably some group is.  But by coordinating that information from their various sources, they can do a better job.  So, yeah, I don't think much of this will come to the surface.  But we can all sleep easier now. 



LEO:  Or not.



STEVE:  Or not.



LEO:  Or not.



STEVE:  Speaking of not sleeping easy, we've not mentioned the Anthem breach, which is chilling because of not only the size, but the scope of what was leaked.  The good news is that Anthem, from all reports, did respond very well.  I mean, maybe this is the - while it's bad that we've had a breach of this scope and magnitude, and I'll discuss that in a second, they themselves detected it, rather than, as normally happens, some third party sees, like, credentials appearing on the Internet and says, eh, by the way, I mean, normally Home Depot and Target found out about these things when it became clear that the common thread among fraud was that everybody had shopped recently at Home Depot.



Well, so this is way better than that.  This is Anthem's own internal security monitoring found the problem.  The bad news is that apparently the first malicious access to Anthem's internal insurance subscriber database was December 10th, and they first became aware of the suspicious activity on January 27th.  So the bad guys were in there, apparently exfiltrating data, for some length of time.  And the data that was exfiltrated is of course the real crux of this problem because...



LEO:  Well, and the thing that bothers me is it wasn't encrypted at all.  Right?



STEVE:  Right.



LEO:  What?



STEVE:  Right.



LEO:  That's terrible.



STEVE:  By their own admission, they said that it was not encrypted in its database.  They also did a little sort of a mealy-mouthing, saying, well, additional encryption would not have thwarted the attack because an administrator's credentials were compromised, and security protocols were bypassed.  So they're saying, well, okay, but it wouldn't have mattered.  At the same time it's like, well, maybe in this case.  But that's not an excuse for not encrypting your database because a simpler form of attack might have just been able to exfiltrate the database, in which case they would have gotten nothing.  So clearly, clearly this demonstrates that they're still not behaving.  And remember, this is not Anthem's first problem.  They had problems a couple years ago that we talked about on the podcast, a much smaller security problem, but it came to light then they were not encrypting.  And now we know they're still not.  So that's certainly a problem.



LEO:  Didn't learn their lesson.



STEVE:  Names, dates of birth, member IDs, Social Security numbers, residential addresses, phone numbers, email addresses, and in some cases employment information, including members' incomes.  So what we're looking at there is the mother lode.  You couldn't ask for more for identity fraud.  And that's of course the problem is identity threat, people creating new accounts under fraudulent credentials and Social Security numbers and residential addresses.  This essentially is everything you need in order to impersonate somebody and get credit under their name.  So and of course, yes, they're - and 80 million subscribers, if I didn't mention that number before, 80 million.  Anthem, of course, is big in California.  They have 37 million subscribers in California alone.  And this is across their various properties:  Anthem Blue Cross, Blue Cross and Blue Shield, I guess Blue Cross and Blue Shield of Georgia, which is a separate group, Empire Blue Cross and Blue Shield, Amerigroup, Caremore, Unicare, Healthlink, and DeCare.



LEO:  I'd be so furious if I were a customer.



STEVE:  Yeah.



LEO:  Because the real problem is you cannot change your Social Security number.



STEVE:  Right.



LEO:  It's not like a credit card number, where you could say, oh, federal government, give me a new one.  So you have this, the rest of your life now you have this still hanging over your head.  There is no remediation.



STEVE:  Yes.  And with a credit card, that's all that's been compromised.  And so while, yes, you're then subject to credit card fraud, of which you're indemnified from, we've all heard the horror stories of what happens with identity theft.  I mean, people's lives are turned upside down.  And it's very difficult to recover from.  I mean, as you said, Leo, it is really bad.  Now, Anthem...



LEO:  We have to fix this Social Security issue because, I mean, first of all, the Social Security folks say don't use your Social Security number as an identification.



STEVE:  As identification.



LEO:  And yet everybody has it.  If you apply for credit, you have to give them your Social Security number.



STEVE:  That's what we're being asked for, yes.



LEO:  Which means that you have no recourse.  If you want healthcare, if you want a car loan, if you want a credit card, you're going to give your Social Security number to people who do a crap job of protecting it.



STEVE:  Right.  And oftentimes it's - I know in some cases - I'm trying to think if it was something I did with Verizon a while ago.  I have my cell phone account through GRC, so we use our corporate tax ID.  But had it not been that, they wanted my Social Security number.  I mean, that's my tax identification number.



LEO:  So I think they need to - we need two numbers.  It needs to be like private key crypto.  You need a public number and a private number or something.



STEVE:  Sort of like a one-way function so you cannot - sort of like a hash of your Social Security number so that somebody could verify that you know your Social Security number.  If they know it, you can prove yourself that way by just hashing it and then saying, okay, here's the hash, but not be able to go the other direction.



LEO:  If you can prove - I'm reading the documentation on the SSA.gov website.  If you want to change your Social Security number, you can, in some very specific cases.  But one of them is, "If you've been a victim of identity theft, and you continue to be disadvantaged by using the original number."  So but you have - you can't just change it because you want to.  You have to prove that you've - it has to be all after the...



STEVE:  After the fact.



LEO:  ...horse has left the barn.



STEVE:  It's sad, too, because I memorized mine when I was 16 or something, you know, when I got it.  And I love my number.  It's like, it's been in my head ever since.  And it would be a shame to have to change it.  Anthem did bring in an outside security firm, Mandiant, that is a well-known sort of inspector of these things.  And they got thumbs-up from the guy who was interviewed by several third parties, saying, well, what do you think of the job they did?  And this guy Dave Damato is the managing director of Mandiant, who said that immediately after Anthem noticed the incident, they reset some passwords and performed a series of actions to remove the attacker from the environment.  Any passwords that were affected by the breach were reset, and they began blocking traffic associated with the attacker and removing any compromised systems from their network.



And it was a sophisticated attack.  Apparently some custom, never-before-seen backdoors were inserted into the network somehow.  And it does sound like an administrator's credentials were compromised.  So this was a deliberate focused attack.  We have to learn, as we're finding out, how to do better.  There needs to be better protection.  And, boy, you're right, Leo, I mean, this is devastating for customers of Anthem Blue Cross, Blue Shield, and of the other properties, about half of whom are here in California.



LEO:  They're already seeing phishing attacks with the Anthem logo and email from somebody pretending to be Anthem saying, hey, we had this problem.  You'd better log in, change stuff.



STEVE:  Click this.



LEO:  Yeah.  So if you're an Anthem customer, congratulations.  You need to know a lot about protecting your good credit.  You need to know how to file a fraud alert.  You need to know how to check your credit report regularly.  I mean, welcome.



STEVE:  Yeah.



LEO:  In fact, probably we should all be doing this.



STEVE:  They did set up something called AnthemFacts.com, A-N-T-H-E-M-F-A-C-T-S dotcom.  And it was a little unimpressive.  There's someone named Joe who runs Anthem, and he signed his name with a big happy "Joe" and noted in there that he, too, was a victim, meaning that he was one of the 80 million.  It's like, well, okay, Joe, that doesn't really make...



LEO:  Sure, all the Anthem employees were Anthem customers; right?



STEVE:  Yes, yes, exactly, yeah.



LEO:  Oy oy oy oy oy, 80 million people.



STEVE:  Wow.



LEO:  Boy, hackers are just going to have a field day.



STEVE:  Yeah, it's not good, it's not good.  So Google announced yesterday that with Chrome 40, which is in the process of rolling out, they will be adding support for HTTP/2.  Remember that HTTP/1 was the original standard.  Then we've been running on 1.1 for the last 16 years, since 1999.  So it is time for us to move forward.  And we talked a couple weeks ago, there was that neat site, https v. http [httpvshttps.com], which demonstrated that SPDY was in fact well named.  It was so speedy that it is faster to use SPDY with encryption than to use HTTP without.  And to the extent that we move to this next-generation encryption, there's no longer an argument to be made that it is a speed impediment.  It's just not.



So what Chrome is doing - and I'm putting it in the show notes to remind myself, this is truly Google at its best.  There's nothing heavy-handed about this.  All browsers now support SPDY, which started out as Chrome's test protocol.  They put it in their browser.  They supported it on their servers.  And of course lots of people using Chrome also had the occasion to use Google's properties, increasingly so.  And so Google was able to meter this and install metric surveys to tune it and tweak it and see how much benefit was gained from this part of SPDY and how much benefit was gained in the real world from that part.  And ultimately Chrome, IE, Firefox, Opera, Safari, and even Amazon Silk server all support SPDY, just because it was a good thing.  It then - essentially unchanged, just some little committee-ish tweaks here and there - it, essentially unchanged, became the core of the HTTP/2 protocol.



We'll give it a full podcast here as soon as it settles down and gets ready to be finalized, which is right in the process of happening, to give full coverage of what the change from 1.1 to 2 means.  But they're now going to support this next generation in Chrome 40.  And then they'll leave SPDY in place while HTTP/2 comes fully up to speed.  And then their plan is next year, in 2016, to at some point remove support for SPDY itself from Chrome, presuming by that time that everybody, all of the - basically HTTP/2 will have had a chance to take hold.  And we're still looking for more pervasive server-side support.  That's sort of the next piece of this is for that to become widespread.  Everything supports 1.1.  And this puts good pressure, I mean, essentially SPDY itself puts good pressure on servers to begin supporting that.



LEO:  If you wanted to support it, you would do it at the server level. 



STEVE:  Correct.



LEO:  You'd update Apache.  You'd put a plugin or something in Apache.



STEVE:  Correct.



LEO:  Yeah.  It's not the web page itself, it's the server.



STEVE:  Right, exactly, because the web page is up at the application, at the content level.  And this is down in the protocol level itself.



LEO:  You're going to hate our new page.  It's all JavaScript.  It's all Node.js.  You're going to just hate it.



STEVE:  I'll drop my drawers for TWiT.tv.



LEO:  Well, but see, but you just say, "NoScript, please allow Leo to take over my computer and use it in any way he sees fit."  The good news is we don't have your Social Security number, Steve.



STEVE:  Well, and I was...



LEO:  Actually, we do.  Wait a minute.



STEVE:  But probably not on your website.



LEO:  Not on the website, I can promise you.



STEVE:  Not on the website.



LEO:  Actually, you know what's funny, and you've probably gotten your 1099 at some point in the last few weeks...



STEVE:  And in fact I got a request from you to update my W9 information, and I sent that back to your W9 coordinator.  I thought, oh, you have a W9 coordinator.



LEO:  Oh, yes.  Because, well, this is a sideline, but we use ADP, which is a payroll system.  And you're actually not being paid by us.  None of our employees work for us.  They all work for ADP in Florida because of the way the system works.  So, but we trust that they have good security because they do have your Social.  We don't.



STEVE:  GRC always used an outside certified.  That just makes so much more sense.



LEO:  It's crazy to do that, yeah, yeah.



STEVE:  So did you see "60 Minutes"?



LEO:  No, I heard they talked about DARPA.  Yes?



STEVE:  They did.  But they also gave a really disturbing demonstration, which I'm glad they did because the public needs to have seen this, and now has, of car hacking.  And the most disturbing aspect of it was - it's funny, too, because the car that they were demonstrating, I'm sure aficionados of cars knew what this was, but they blanked out all of the identifying information about what make and model this car was for the sake of putting this on the air.



The disturbing thing was that not only did someone, as we've seen before, hack into the dashboard and put the "60 Minutes" reporter's name up in the display - this was Lesley Stahl who was doing this segment, and so it's "Hi, Lesley," which she thought was cute.  But it overrode her braking.  And in a non-braking, that is, where she slammed her foot on the pedal as the car was approaching and then drove through a set of cones, it disabled her brakes.  And so first they did some little cutesy stuff, as you're showing now, where it squirted her windshield wipers and so forth.



LEO:  Where did they - did they get the hacker from central casting?  Because heavyset guy with a beard and a black T-shirt...



STEVE:  He's like the perfect hacker; right.



LEO:  Yeah, yeah.



STEVE:  Yeah.  So first they squirted soap on the windows and turned on the windshield wipers.  It's like, oh, okay, that's cute.  Then right there they're showing that they somehow overloaded the car's systems in order to get access to the car's networked computers.  And so she thinks this funny.  But then they bring her around and have her driving to a set of orange cones.  I think that's what you're showing right now.



LEO:  Yeah.



STEVE:  And it's like, okay, now go up here and stop in front of these - drive up to these cones.



LEO:  And Mr. Neckbeard has a different plan.  "Oh, my god, my brakes, they don't work, agh."



STEVE:  Now, that's disturbing, Leo, because I have a hard time, I mean, we know that cars are now full of computers and that this is going to be a problem.  But for the computer to be able to override the braking system to me seems irresponsible.  Maybe you need it to stutter the wheels in order to do antiskid braking.  But that ought to be the limit of what it can do.  I mean, there's a point here where, if the car is, as they say, "fly by wire," it has to be responsible for the way it operates.



LEO:  I think that what you could point to is cost savings on this.



STEVE:  Yeah.



LEO:  And I've talked to Ford about this, and they say we have two computer systems, and the system that runs your multimedia center...



STEVE:  Your entertainment system.



LEO:  ...which is the point of access for a lot of these hacks, is in no way connected to the computer system that runs your car, and never should be.  I mean, I'm not an expert on this stuff.  But I think if the same computer is running your car and your radio, I think that's a cost savings, not a sensible thing to do.



STEVE:  So Senator Markey asked all of the car manufacturers, sent them a questionnaire.  And I have a bunch of tweets for the show that I tweeted - I'm sorry, a bunch of links for the show that I tweeted.  One is bit.ly/carhacking, which links to a 12-page report that the Senator's office just published, I think it was yesterday, which details the responses that they received in response to the questionnaire.  And it's a little disturbing because a lot of the companies don't apparently have the kind of security that we would like to see in place.  So I don't know how this gets resolved.  We have legislation to mandate seatbelts and mileage.  So it looks like, unless they take responsibility for the security of their mobile computers, you know, it's one thing for your thermostat at home to be taken over.  It's a little worrisome when that can happen to your car.  And like you, I've not dug into this deeply.  I don't know the details of this.  But we need our carmakers to be responsible.



And of course we've got all the news about the Samsung TV listening to people.  Leo?  So there's been a lot of tweeting about this.  And Parker Higgins, who's the EFF's director of copyright activism, tweeted that Samsung Smart TV's privacy policy warns users not to discuss personal information in front of their television.  So I dug into this a little bit because I was curious what the Samsung privacy policy was.  And so quoting directly from what Samsung has, Samsung says:  "You can control your Smart TV and use many of its features with voice commands."



LEO:  Sorry, I was in the bathroom.  I apologize.



STEVE:  No problem.



LEO:  I peed all over my shoes when you talked to me.



STEVE:  Oh, sorry.  You're able to listen?



LEO:  Oh, yeah, I keep a - I monitor.  Well, I don't want to miss it.



STEVE:  Ah, okay.



LEO:  Go ahead.  Mine does this, by the way.



STEVE:  Okay.  So we'll talk about this.  So of course Samsung said:  "If you enable Voice Recognition, you can interact with your Smart TV using your voice.  To provide you the Voice Recognition feature, some voice commands may be transmitted along with information about your device including device identifiers, to a third-party service that converts speech to text or to the extent necessary to provide the Voice Recognition features to you.



"In addition, Samsung may collect and your device may capture voice commands and associated texts so that we can provide you with Voice Recognition features and evaluate and improve the features.  Please be aware that, if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party through your use of Voice Recognition.



"If you do not enable Voice Recognition, you will not be able to use interactive voice recognition features, although you may be able to control your TV using certain predefined voice commands.  While Samsung will not collect your spoken word, Samsung may still collect associated texts and other usage data so that we can evaluate the performance of the feature and improve it."  What do you think?



LEO:  I think this is a tempest in a teapot.  I commend Samsung for...



STEVE:  Full disclosure.



LEO:  ...being explicit, as they should be.  But most devices, including, by the way, your smartphone, aren't smart enough to understand what you're saying.  They have to send it to a server.  Siri does this.  Google does this.  Windows Cortana does this.  They send it to a server which interprets it and then sends the information back.  And I would not expect a TV to be smart enough to do that.  In fact, they say that.  They say, well, if there's certain canned responses, we can handle those.  But everything else is going to go to a server.



I'm not sure why they're using a third party.  I'm glad they revealed that.  But it may just be they don't have the expertise to do this.  Who knows what they're doing?  They may be using a human like an Amazon Mechanical Turk-style system to interpret what you're saying.  The good news is you just turn it off.  And I have, by the way.  I never found the speech recognition to be very valuable.  But I am not concerned about - you know, if you have an Xbox One, it's always listening.  Always.  And always sending everything you say back to Microsoft.  I mean, it bothers people, but it doesn't - it's like, so what?



STEVE:  Well, yeah.  So I think - I agree with you.  I think full disclosure makes sense.  I think that what I like is what Amazon did with the Fire TV, where you have a button you press that presumably starts it listening.  You then say what you want to say, and then you let go.  Now, that's less magical than "Hello Google" or "Hello Watch" or, you know, where it's sort of like always listening, so you just are able to start it to listen by addressing it using some keyword.



LEO:  Although in those cases, for instance the "Hello Google," that doesn't leave the phone because the phone is smart enough - in fact you have to train it - to be able to recognize it and then send the rest of it to space.  So that's much like pushing a button.  And I don't know how - I'm trying to remember on my Samsung.  I turned it off almost immediately, not because I was worried about privacy, but just because it wasn't useful.  You can also wave at it.  And every time I stretched while I was watching TV, the TV would start to do stuff.  "Yes, master."  So I don't remember if you issue a command or not.  I think you have to somehow signal.  No, they don't want to send everything you say upstream.



STEVE:  No.  They couldn't possibly be streaming everything that everybody who owns one...



LEO:  Why would they do that?



STEVE:  Yeah.



LEO:  They're not owned by the NSA, are they?  No.



STEVE:  Well, I think that technical users will understand, for example in the case of Siri, that your phone is not itself figuring this out.  I mean, for example, your phone doesn't know everything that you're asking Siri about.  So your phone is your conduit to something which is performing this speech recognition, which is really impressive.  I mean, it's like, in the same way that no one can beat computers at chess anymore, or like IBM's Watson can actually play "Jeopardy" and win against the best humans that we have, it's clear that within constraints, computers are now getting good enough to do things they have not traditionally been able to do.  So winning at "Jeopardy," playing chess, and now answering questions within certain, you know, a narrow range, they're able to do, and provide valuable features.



LEO:  I can't wait.  Mike Elgan has the new Amazon Echo, you know, that black tube.



STEVE:  Uh-huh, yeah.



LEO:  And it's always listening.  So you say things like "Alexa, what time is it?"  And in a beautifully - by the way, best voice synthesis ever - voice, it'll say "It's 4:53."  And in fact I don't know if we're reviewing it today on Before You Buy.  I think we are.



STEVE:  So right after this podcast.



LEO:  Yeah.  I immediately ordered it.  In fact, what I want, the real problem with it is it can only be in one place.  You want one in every room because you pretty soon become dependent on it.  And I would like Sonos, I want Amazon to buy Sonos because I have Sonos speakers in every room.  Sonos already has beautiful sound.  And I want them to build that capability into Sonos speakers so that I can, as I wander through my house, say things like, "I wonder where I left my socks."  It's great.  Who cares who's listening?



STEVE:  It would also have olfactory sensors built in, then.



LEO:  Clean socks.  Now, you know, actually I think the real point of this story is this is why companies don't disclose, because you see all the attention Samsung got for disclosing something that pretty much everybody else is already doing, and disclosure scares the hell out of people.



STEVE:  They were being responsible.



LEO:  They were doing the right thing.



STEVE:  I'm interested, though, in your comment that you quickly become dependent upon it.  Is that what Mike has found?



LEO:  I don't know.  Now we have devices that listen all the time.  And I don't use them all that much.  The reason I use the phone that much is that you kind of have to get it out and speak to it.  Alexa is there, it has a very nice, some sort of array  mic technology because anywhere in the room, in a normal tone of voice, you can say, well, here's an example of a query that Mike said, "Try this."  Alexa - and by the way, there's only two words you can use right now, "Amazon" or "Alexa."  But in fact I asked Alexa, "Alexa, is there any other name I can use for you?"  And she said, "Right now you can only use Amazon and Alexa."  But the implication is soon you'll be able to use more.  It is like interacting with a human.  And it's very Hal 9000, very much - and so the query that Mike suggested, he said, "Ask her how old Michael Jackson is."  So I say, "Alexa, how old is Michael Jackson?"  And then Alexa says, "Well, Michael Jackson died in [whatever year], but at the time of his death he was 50 years, eight months, three weeks and two days old."  It's very smart.  And I'm just - I am very - you know what?  I think, if we can get over this privacy...



STEVE:  This is transformative.



LEO:  Yes.  But we have to get over this hump.  And what I'm afraid of is that people are so worried about privacy that Congress will pass a law against that stuff, and we won't have this technology.



STEVE:  Well, I love the idea of a key phrase to enable.  I think, as I said, that's why I like the Fire TV.  I press the button, and then I say something, and then it goes and finds it.  And it's, like, it's shockingly good.  It's like, okay, this stuff has arrived.  And we should understand that you verbally asking Alexa how old Michael Jackson is, is indistinguishable from you typing the question into Google.



LEO:  It's that same kind of thing, yeah.



STEVE:  It's identical in every privacy aspect.



LEO:  Right.



STEVE:  It's just you're doing it verbally rather than textually.



LEO:  Right.



STEVE:  And it does become magical to be able to do it verbally.



LEO:  It does.  And I do think that, by the way, Kinect and these other devices, all of them, and I'm sure the Samsung, as well, have trigger phrases because they don't want to be sending every bit of data upstream all the time.



STEVE:  They can't.



LEO:  Just the cost of it is ridiculous.



STEVE:  They can't, yeah.  I mean, it's just almost impossible.



LEO:  Too much space, yeah.  So they all have a trigger.  If it's not a button push, as with Siri, it's a verbal command, as it is with Google.



STEVE:  And there was also facial recognition I encountered in Samsung's privacy policy.  What's that about?  You're, like, able to log into Samsung just by staring at your screen?



LEO:  Well, I haven't tried that.  I don't know if my TV is smart enough to do that.  But Xbox One does.  When I walk in the room it says, "Hello, Leo."



STEVE:  Except you also said that it misrecognizes...



LEO:  It thinks Lisa is her son because Lisa doesn't have an account, but apparently she looks enough like her son that when she walks in the room it says, "Hi, Michael."  I, by the way, again, I guess I'm a sucker, love this.  I don't have to log in.  It just knows I'm there.  And when you're playing a game it's great because, if another person sits down, it'll say, "Oh, hi, Michael," and Michael can join in.



STEVE:  And it's like my thumb is now my access to my phone.  And Apple has nailed that technology, and it is never a problem any longer.  It's just thank you very much.



LEO:  You know, I started using the iPhone, I mentioned before the show that I started going back to the iPhone 6 because I'm going to want to get ready for the Apple Watch.  And I have to admit, for that alone, the iPhone is a superior device.  The fingerprint is incredible.



STEVE:  And the SQRL client for iOS, when you are facing a QR code, and you want to identify yourself to the website, you just put your thumb on the button, and you're logged in because it's like, okay, the person doesn't just have Steve's phone, he also has Steve's finger.  And hopefully it's still attached.



LEO:  I just think that there should be - Larry Page asked for this a couple years ago at Google I/O - a place for those of us who just want all the new technology and don't give a damn if somebody's listening, so that we can go there, and the rest of you can sit in your little cave and have privacy.  Good luck.  I don't care.  I want the stuff.



STEVE:  I think the right solution is for Samsung not to be hurt because everybody else also needs to disclose, in which case Samsung isn't being penalized.  I think disclosure is important.  But just make it an option.  Allow it to be turned off.



LEO:  Exactly.



STEVE:  As Samsung has done.



LEO:  Exactly.  That's the right answer.



STEVE:  And I think it's neat that Amazon gave their thing the name "Alexa" because you're not probably going to - it's not "coffeepot" or something that you might say by mistake.  It's a word, it's a name for that.  And I guess maybe if it's not sensitive enough, you might be talking about a Lexus car and it might go boing.  Does it make a sound when it acknowledges you?



LEO:  No.  There's a little glowing ring on the top that wakes up and starts going [making sound].



STEVE:  I've seen the picture, or I've seen the commercial.  It's cool.



LEO:  Some idiot in the chatroom said, oh, well, it's just the same as Anthem giving up your Social Security number.  No, it's not.  Sorry.  It's not the same.  You can want security of your Social Security number and still want something you can talk to in your house.  They're not mutual inconsistent.  And I agree with you.  Give us the choice.  Let us turn - but what I really am concerned about is these privacy advocates shutting down technologies because they don't want that to happen.  And so just give us the choice and disclose.  That's it.  That's all you need to do.  Give us the choice and disclose.  And I agree with you, if everybody did that, then there'd be no harm to Samsung for telling the truth.



STEVE:  Right.  And the fact is I think certainly for some people they will be concerned enough that they'll choose not to use it.  For many others, it's like, hey, this is convenient.  I want to be able to just ask the air what time of day it is.



LEO:  So cool.  Choice, that's all.



STEVE:  Yeah.  Yeah.



LEO:  [Janie] says, well, that's what privacy is.  No, no.  See, that's the problem.  There are people out there who would very much like to prohibit this kind of stuff.  And if you lobby loud and long enough about it, Congress is going to say, well, I guess we should prevent this.  And I really hate to see technology held back by Luddites.  That's all.



STEVE:  Yeah, I think it's too late to have it held back.  I think we just - and I have no problem with requiring the people who offer these services to be responsible with the information that is collected.  We need that, too.  I mean, and here's Anthem.  Anthem is offering a service called health insurance, but we could argue the fact that in 2015 their database of 80 million subscribers was not encrypted was irresponsible of them.  They can say, oh, well, the nature of the attack was such that they would have been able to decrypt it anyway.  Okay, this attack, but not all attacks.  And having that much data, that crucial, crucially personal data not encrypted, there is just no excuse for that in 2015.  So thank you for offering health insurance, but not for doing an inadequate job of protecting the Social Security number that you got along with it.  And why do they have to have that?  Is that clearly important for them to have my...



LEO:  No.  In fact, Dr. Mom says she does not give it to health insurance companies.  So, but I just don't...



STEVE:  Ah, interesting.



LEO:  But I just don't know what the policy - I don't know what hoops you'd have to jump through.  You obviously have to give it to an employer.  The whole purpose of the Social Security number is to identify income.



STEVE:  For tax reporting purposes.



LEO:  Well, for taxes and for retirement, for Social Security.



STEVE:  And Social Security, right, accrual, yeah.



LEO:  But I don't see any reason to be using it as an identification number for any other purpose.



STEVE:  No.  So we have a nice story.  Eighteen years ago Werner, is it Koch, K-O-C-H, decided to create GPG, in 1997.  He wrote the first instance of Gnu Privacy Guard.



LEO:  Yay.



STEVE:  Yes.



LEO:  I use it.  Love it.



STEVE:  And it was never a huge money winner for him.  He notes that since 2001, meaning since it was four years old, 14 years ago, it had been generating about $25,000 a year in GPG donations, so below the income that a similarly skilled programmer would have been able to generate by hiring himself out to a company, yet he kept it going.  In 2013 he was right on the verge of calling it quits.  He has a young daughter.  He's the sole breadwinner for his household.  And it just - it was straining him too much to be the sole developer and support for this thing and not be generating any greater amount of revenue.



But the Edward Snowden revelations occurred right at the point where he was thinking of bailing; and he thought, okay, I can't.  This is clearly too important.  And of course GPG was what Snowden was using in order to communicate.  So he decided to stick it out.  He then in December started trying to crowd fund and generate revenue, which was more successful than he had been so far, but it wasn't generating the amount of money that he was hoping to.  So on February 5th a Julia Angwin did a posting, a story about him in ProPublica, and this went public, her story did, her posting, at 10:24 a.m. on the 5th.  By 8:10 p.m. that day, he had reached his funding goal, which was $137K.  Facebook and the online payment processor Stripe both independently pledged to donate $50,000 a year.



LEO:  Yay.  Yay.



STEVE:  And her going public with the story allowed him to then disclose that the Linux Foundation's Core Infrastructure Initiative had just the week before given him a one-time grant of $60,000.  So this was a big win.  He's now rolling in dough.  He can afford to hire a full-time programmer, which he has wanted to do, in order to really get behind this and give it what it needs.  And thanks to Facebook and Stripe - and I want to say to both Facebook and Stripe, thank you for this.  They have, combined, created a 100K a year ongoing pledge to support GPG.  So as we've seen, it's often just the case that people need to make it clear that something that is essentially core infrastructure is in need of some financial help.  And there are big public companies and well-funded organizations that are able to say, oh, glad you told us.  We're going to help you.



LEO:  Yay.



STEVE:  Yeah.  So this is a nifty story and a nice turnaround.



LEO:  And we've recommended Gnu Privacy Guard, GPG, for a long time.  It's basically the open source version of PGP, which makes it better than PGP because it's open source.



STEVE:  Right.



LEO:  And it's available - he maintains Gpg4win, which is the Windows version - Gpg, the number "4," win.  And then there's GPGTools, which is the Mac version, which I recommend.  And I've given them money.  I didn't realize it didn't go back, flow back to him.  So I'm glad to support him.  It's such important work.



STEVE:  Yeah.  I also ran across - and I'm trying to think where this was.  I think it was someone - oh, no.  It was in the mailbag for today's Q&A, but sent anonymously, so I don't know who it was from.  But it's an interesting slide presentation.  I created a bit.ly link, bit.ly/sslslides, all lower case, S-S-L-S-L-I-D-E-S.  And what I liked about this - so this was a Google presentation showing the work of the Chromium team, trying to come up with the way to communicate the difficult concept of the various ways a communication over the Internet, through your browser, could be insecure.  And really I was impressed by this.  It demonstrates the depth of their intent.  And it was just a good demonstration of, I don't know, it's like 30-some slides, at least, where they show the way Chrome has evolved over time to show different types of problems.  And it illustrates - and they're also, like, giving themselves a grade, A through F.  And they're demonstrating from their own metrics the number of people that have responded in which fashion to different types of warnings that Chrome has offered over time.



Anyway, it's really interesting:  sslslides is the resource on bit.ly.  And so I wanted to aim our listeners at it because I think we'll find it interesting.  And it highlights the real problem, sort of a fundamental problem with this whole experience, that is, we want using the web to be simple and easy and safe.  Yet it really does rely on an interlocking family of complex technologies.  You were talking on The Tech Guy show this weekend, Leo, about how, for example, I think somebody was - you were giving a complete answer to a complex question.  And somebody was...



LEO:  Somebody said it was a Steve Gibson answer.



STEVE:  Right.  They were complaining that it was too complicated.



LEO:  Well, it probably was for the radio audience.



STEVE:  And you said...



LEO:  But there's no way to do it simpler.



STEVE:  ...look, sorry, right.  If you gave a simple answer, it would be wrong.  And unfortunately, only a full answer is correct.



LEO:  We were talking about bandwidth and why, you know, DSL versus cable and, oh, my god, it was - yeah.



STEVE:  Right, right, right.  So...



LEO:  So this is good.  This slide show is good.



STEVE:  Yeah.  It really is good because it demonstrates the problem of what can you show the user that they will understand because, you know, you show, like, the fields of a security certificate, and even podcast listeners, I mean, even listeners to our podcast are like, wait a minute, is that good or bad?  I mean, it's complex stuff.  And so they break it down in terms of the visual semantics, how can we convey what we want to convey - which is unfortunately complex, there's just no way around the fact that it's complicated - so that people will get the message that we're trying to give them, rather than just go, uh, what does that mean?  Yeah.  So anyway, I commend that slide deck to our listeners.  I think everyone will find it interesting.  And you've been stepping through it while I've been talking.



LEO:  Yeah.  She grades various messages as to intelligibility and accuracy.



STEVE:  Right.



LEO:  It's not an easy thing to do.



STEVE:  No.  I mean, what I liked about this was it really does highlight that this is a hard problem, that is, we have complex technology which users who don't want to know anything about that have to understand, just like your caller over the weekend said, well, why are my pages loading slow?  And it's like, oh.  Where do I begin?



LEO:  That was the question, wasn't it, yeah.



STEVE:  Yeah.



LEO:  Um, well...



STEVE:  Okay.  Let's see.



LEO:  Blame Canada.  There's the easy answer.  But I don't know how useful that is.



STEVE:  Yeah.



LEO:  This is good.  And I like this:  Opinionated design works where text fails.



STEVE:  Yeah, exactly.  Where you sort of have to have Fred Flintstone with a mallet hitting them over the head.



LEO:  Yeah, say it out loud, yeah.



STEVE:  In order to, really, to get their attention.



LEO:  It's good.  And she's - I don't know if she's a Google employee or she's with the Chromium effort, which is a Google effort, so...



STEVE:  Right.  Adrienne Porter Felt is her name, with the Chrome security team, where they're really - they're working to figure this...



LEO:  Thinking about what do we tell people.



STEVE:  Yeah.  How?  How do we explain this?  Yeah.  Which is why I'll be interested to see what they do where they're trying to tell people that, I mean, look at these - the issues that addressed were, like, fraudulent certificates, something clearly fraudulent.  So how, then, are they going to say the certificate of the website you're visiting is using a hash function that we're trying to get websites to stop using, even though there's really no problem with it today?  Good luck communicating that subtlety, you know, in an icon.  I don't know how you do that.



Oh, speaking of slides, many people have wished that my DigiCert presentation video slides were available.  And so while I was in bit.ly land today I created bit.ly/sqrlslides, which gives you a PDF of my slide presentation for the SQRL presentation, so you could sort of flip through it while I was jumping around onstage there, or just browse through it yourself.  So a bunch of people have asked.



I did want to follow up on last week.  We had Audible as a sponsor, and we mentioned in that context the Expanse series, which you had listened to, Leo, in the past because when you went there they were available on Audible.  I've finished the first book now, which was wonderful, really fun.  So I was liking it last week, though I think I was like a quarter of the way in.  It's behind me now, and I'm into No. 2, which is every bit as good.  So I can now without reservation recommend at least the first book and as far as I am in the second book of the Expanse series of sci-fi.  It's just enjoyable.  It's sort of classic space opera.  It's not super complex.  It's not nearly as involved as Peter Hamilton's stuff, but just good old-fashioned space opera.  And remember that the reason I got into this was that Mark Thompson noted that the Syfy Channel was turning this into a series that we'll be seeing later this year, so I wanted to read it first.  And some interesting, fun stuff.  So, yay.



And for my weekly SpinRite mention, I thought I would just - in the last 12 hours I saw two tweets that came by because they happened to have the @SGgrc in them.  And they weren't actually directed to me.  James Bliss tweeted:  "Again, thanks to @SGgrc, it appears to others that I have a superpower.  I do, all thanks to him, and it's called SpinRite."  And then he linked to GRC.com, the "What It Does" page on GRC.com.  That was the first tweet.



And the other one was from James Munn, who apparently I saw part of a conversation, a dialogue he was having, because again he had @SGgrc in it.  So he tweeted to a Patrick Klepek, he said:  "Get and run SpinRite 6 on it from the great @SGgrc!  It has rescued many a HD [obviously hard drive] for me."  So thanks, James.  Oh, they're both named James.  James and James, thanks for your tweets and letting me share them, yeah.



LEO:  Question No. 1 from Matt at an undisclosed location.  He worries about fuzzy string matching.  Who doesn't?



STEVE:  I know.  Those fuzzy strings.



LEO:  You guys are such geeks, man.  Matt writes - oh, wait a minute.  Now somehow I blew it.  Here we go:  Steve, I thought I recalled you saying that you'd developed a novel method - oh, I remember this - for fuzzy string matching.  I believe it was for processing/recognizing SpinRite testimonials in your records.  I realize your plate's awfully full and you've no shortage of topics for Security Now!, but I wouldn't mind hearing about your solution.  Thanks for all you do for your community.



STEVE:  Okay.  So I see people asking this from time to time.  And Matt's memory is correct.  I spent some time dipping into sort of an unsolved question in computer science.  It was technically called LRS, Longest Repeating String.  So it wasn't a fuzzy string match as much as a longest repeating string.  The idea was that I was sometimes editing the testimonials to fix grammar a little bit, just because I'm posting it in someone's name, and I want it to look right for them.  And that meant that, if I wanted to find duplicates in order not to duplicate post, I needed to find a match where most of it matched, but not all of it matched.  And that meant that, if there was a long run of text that was exactly identical, then that was probably the same testimonial in two different locations.



So I and a bunch of neat followers in - we have a newsgroup called "thinktank," where we go to sort of do brainstorming stuff - worked out what was actually probably a new algorithm in computer science which I was able to describe in text well enough to the people who had been following along, because I iterated the solution three or four times, every time I came up with something substantially better.  They were able to independently write it in a higher level language because of course I was implementing mine in assembler.  Anyway, the point is that it is on GRC at GRC.com/dev/lrs.  And the source code is there from - all I can think of is his handle, Sparky.



LEO:  MASM?



STEVE:  Paul...



LEO:  Oh, a person wrote it.



STEVE:  Yeah.  And all of mine are there.



LEO:  You could say just Sparky's source code is there.



STEVE:  Sparky, yeah.  I can't believe I'm blanking on his first name, but...



LEO:  Paul Byford?



STEVE:  Yeah, it's Byford, Paul Byford.  And all of my EXEs are there, and a list of all the iterations we went through.  So for anyone who's interested, I never had a chance to put it on the website because it wasn't crucial.  I solved the problem.  And I need to get it documented because it is a new solution, I think, that no one has come up with before.  But it's there, /dev/lrs, as in longest repeating string, for anybody who's curious.



LEO:  Good.  Good, good, good.  I thought we did a show, but maybe we just talked about it.  But we did talk about it.



STEVE:  We just talked about it.



LEO:  Didn't we?  Yeah.



STEVE:  Yeah, yeah, yeah.  We did at the time.  And what I want to do is I think in order to convey it - it's a cool solution.  And I wanted to animate it so that you could see it working in order to have that, like, that a-ha moment where it's like, I understand that, because it's working.  But, so, one of these days.  After SpinRite 6.1.  It's another thing that I'm pushing to the other side of SpinRite 6.1.



LEO:  But to be clear, it's not fuzzy matching, it's direct explicit matching.



STEVE:  Correct.  And there were lots of applications, like genetics, like gene sequencing, to find the longest run of gene sequences.  I mean, what it is, is it's incredibly fast for finding the longest repeating string in a large corpus, which turns out to be a rather hard problem in computer science.



LEO:  I would bet.  I've never looked at grep source code.  But I would bet, I would hope that the people who wrote the various regular expression parsing tools in various languages and various libraries would have done something that's efficient like that.  That's one of the features, one of the things that grep can do.



STEVE:  I don't think it can find a longest duplicate string.  See, the idea is you could say "find this string" in something else.  This goes the next step.  It says "find the longest repetition, not knowing what it is."  So you're not asking for it to find a certain thing.  You're saying what's the longest string that occurs twice in this entire text?



LEO:  Ah.  Well, I'm sure you can make an expression that does that, but I'm not sure I'd want to try.  I'd be surprised if you couldn't do that.  There's a great book, by the way, on grep that I love:  "Mastering Regular Expressions," I think it's called.



STEVE:  Yes.  And I think I mentioned, oh, no, it was on Coding 101.  By the way, I never mentioned this, but I've been on the last three...



LEO:  I heard.  I haven't seen it yet.



STEVE:  ...episodes of Padre's Coding 101.



LEO:  What, are you teaching assembly language?



STEVE:  The Padre just asked me to come and talk about stuff.



LEO:  That's great.



STEVE:  And so for three - and because I'm able to do that off the cuff, I don't have to do any prep.  It wasn't stealing any time from my work on SQRL.  So I said, yeah, I'll show up.  And so I did that three times.  But I was mentioning that - because the week before last I was talking about compilers versus assembly language.  And some people took umbrage at the idea that I was saying, eh, you know, assembly language is more efficient than compilers.  But I drew the example.  I used regex as an example of something I would never want to have to write in assembler.



LEO:  No.



STEVE:  Because it's just a huge complex problem.  And there are some things that make sense in assembly language; other things, eh, they just really don't so much.



LEO:  This is the book I was referring to by Jeffrey Friedl.  It's a computer science classic.



STEVE:  I own it.



LEO:  And it's fun, actually.



STEVE:  Yup.  Yup.



LEO:  It's actually - maybe that's how geeky you and I are.  But actually it's a fun book to read.  Question 2, Sean Robinson.  He wonders whatever became of the Portable Sound Blaster project?



STEVE:  Another blast from the past.



LEO:  Mr. G., Mr. G., give us an update, what's going on?



STEVE:  Okay.  So that, similarly, I didn't update the pages for it at GRC just because it sort of didn't seem necessary.  But enough people ask continuously that I will get around to fixing that, too.  Everything that happened, happened in plain sight over on the Google Groups.  And so if you google "portable sound blaster," you will find groups.google.com, and I think it's just, like, /portablesoundblaster.  Everything that you want to know is there, including, and I have at the top of the first page that comes up, a zip file of the finished design.



What we ended up with was a very elegant, very small and simple-to-build circuit, perfect for like a little father-and-son project, a bill of materials that you can all source from DigiKey.com, which is a great source, an online source for electronics components.  And it produces an extremely loud, high-frequency sound.  Now, the problem was that what we learned was that, from my recounting my experiences with mine, people were wanting too much from it.  They were saying, well, you know, two houses down there's a barking dog, and I want this to shut it up.  And it's like, I'm sorry, that's just - it won't work.  Or 25 yards away is a dog.  It's like, well, no, it doesn't do that.  Or I'm on the ninth floor, and there's a dog barking on the third floor.  It's like, sorry, no, it won't do that.



So what it will do is, if you were being attacked, this would just stop a dog cold at three feet away from you.  Because remember, that's what I did.  That was my use for it was basically, at pointblank range, to blast this ferocious German shepherd in the face.  And after a couple of those, it no longer lunged at the gate.  And then it did knock seagulls out of the sky, so there was that.  But it's not going to keep a barking dog from barking a long way away.  That just isn't - we don't have - I don't think that technology exists.  So if you want a handheld defensive device - for example, a mailman.  This would be perfect for a mailman who's being nipped at or for dogs chasing him.  And there were some people in the group who - and I should say a bunch of people successfully built it, and it works for them.



LEO:  Wow, that's neat.



STEVE:  As a nice little handheld, high-frequency blaster.  It was funny, too, because some guys, while they were building it and testing it, they couldn't hear it, but their teenage daughters upstairs were complaining.



LEO:  Dad.



STEVE:  Stop that, yeah.  So that's where we are.  Anybody who wants it, I haven't moved, I haven't ever had time to transport that all back over to GRC.  But it is "portablesoundblaster" in a Google Group, and everything is there - the design plans and schematics.  And everybody posted their results and pictures of their projects and everything.



LEO:  So we're going to stamp that one completed.



STEVE:  Done.



LEO:  Done.  Brian Tannahill in Overland Park, Kansas, has come up with maybe another use for SQRL:  When I log into the system at work from home - it's a VPN - I have to enter my logon and password information three times.  First I connect to the VPN.  Then I connect to the network.  And finally I log into my own machine at the office.  Would it be practical for an employer to use SQRL to simplify remote logins?



STEVE:  So naturally my increasing proximity to having SQRL up and running and demonstratable and finished and the fact that over the holidays we aired the DigiCert presentation of it has stirred up a lot more interest.  I don't want this podcast to become the SQRL podcast, just because there's a lot more going on.  And so I've been responding to a lot of people just by mail who had questions.  For example, someone was asking, hey, if we had a static QR code, could people use that?  And I explained, no, because one person's signature could then be captured, and it could be replayed in a classic replay attack in order to impersonate them, which is why the SQRL code needs to change every time, and you need not to be able to use it more than once.



And so Brian - but Brian's question was a little different.  And so I just sort of wanted to capture everybody's questions and say that there are indeed other things, many other things, where this protocol could be used.  And in Brian's instance, absolutely.  He's looking at various types of online logon, first to a VPN, then to his network, then to his machine.  And I don't - it's not clear how his machine could log him in.



But if, I mean, we know that Windows, if it was a Windows system, you are able to replace the logon technology.  I could easily imagine that Windows could present you with a QR code which you would then see, having remote connected to your machine on your VPN, then on your network.  So you could very easily just present, essentially, three different QR codes at each stage, either tap it and the client on your machine would log you in, or snap it with your smartphone in order to proceed through each stage.  So, yeah, there are many different things. Basically it needs to be an online login where you're challenged with a unique QR code to which only your SQRL client is able to respond.  And it's that simple, really.



LEO:  Question 4 comes from Andy Marks in Louisville, Kentucky, with some thoughts about improving Tor:  As you said last week, vulnerabilities of Tor include analysis of timing, the size of the data.  It seems a logical improvement of Tor is to mask the actual time by increasing it and setting a fixed or random data size, even if it gets bulky.  That could help mitigate the problems with Tor.  Tor is a program that runs on a server.  Changing Tor to do these two tasks and rolling out the changes shouldn't be unrealistic.  I know it would need to get tested.  I don't see the big deal with Tor being changed to improve security.  In addition, the number of Tor nodes and the amount of traffic, even if it is artificial, can improve Tor security.  Does it make sense?  A lot of programs are broken and need to be fixed.  Tor can be fixed.  Andy Marks, Certified Ethical Hacker.



STEVE:  So, okay.  This question stands in for all of the similar questions that I encountered.  And the reason I chose this one was Andy's conclusion was perfect for making my point:  "A lot of programs are broken and need to be fixed; Tor can be fixed."  No, it can't.



LEO:  Oh.



STEVE:  And so I love that Andy finished that way because what I hoped to convey, and I will underscore it, is that this isn't a problem with Tor.  This is asking Tor to do something it really can't do.  It's not a bug.  It's not adding something more.  It's that the Internet resists anonymity.  The nature of it actively resists providing that.  It wasn't designed to provide anonymity.  It isn't good at it.  And so we're trying to - and Tor needs to be considered an experiment.  Usable, yes.  Worthwhile, yes.  Better than nothing, yes.  Perfect, no.  And nothing can make it perfect.  It can't be fixed.  Yes, you could have more nodes.  But then the nation-state organization just needs to monitor more of it.  And in fact some of the studies demonstrated that just being centrally located gave a single entity enough information in order to deanonymize people.  And then there's that problem of you being able to use Tor to confirm an identity, which is an even more powerful attack against it.



So the point I wanted to make is not that it should be scrapped, but that it was originally created as an experiment; that it certainly has its purpose.  Communication does go in, and you know not where it's going to come out.  It provides anonymity services.  I just wanted to sort of say that researchers have broken that guarantee, and there's no fix.  You could continue to do things to sort of water down or make it more difficult to break that anonymity guarantee.  But we're in that fuzzy world where we're trying to do something which is fundamentally, I don't want to say impossible, but kind of impossible.  Like denial of service attacks, where they just keep getting bigger, and so we keep making the pipes bigger to absorb them, and so they get bigger.  It's like that.  The Internet wasn't designed to provide this.  It just won't.



LEO:  End of story.



STEVE:  Yeah.



LEO:  Yeah, I got a lot of tweets, people say, oh, you guys don't understand Tor, blah blah blah.



STEVE:  Right.



LEO:  And I think you do.  I want to just say I think Steve knows what he's talking about.



STEVE:  Well, and the people who were most upset with me were Tor...



LEO:  Tor users.



STEVE:  Were Tor node, well, or Tor node...



LEO:  Tor node operators, yeah.



STEVE:  ...operators who were like, well, he doesn't know what he's talking about.  It's like, well, and they didn't listen to the podcast.  They just saw some of the Twitter traffic and jumped in for the ride.  So it's like, oh, okay.



LEO:  Justin Aborn in Boston.  He wants to know how to be sure about emailed links.  He wants to know how whether to click on them:  My bank just emailed me a clickable link.  I'm 99.9% sure it's truly them, but I navigate to their site by hand, rather than click on the emailed link.  To check the fit of my tinfoil hat, what do you recommend as the minimum procedure to confidently click an emailed URL?  It would be a lot more convenient if we could just click on them.



STEVE:  Yeah.  And I liked this also because in the context of Anthem, as you said, Leo, we're seeing now a big phishing wave of fake email coming out.  The only way, I mean, the old-school way is to look at the email headers, which are generally available.  But, boy, that's confusing.  And headers are highly prone to being spoofed.  I think the only thing I could suggest, first of all, is don't.  They're just, you know, it's really not worth it.  But if you have to, what you need to do is look at the source.  That is, you need to be able to examine the source of the email.



The problem is that email today is HTML.  And there's what you see is the result of the HTML markup which has created a presentation.  And so you can see text that is underlined that says "Click here to email Anthem."  Or I don't think he gave an example.  Or his bank.  And in fact it can even show you http://bankofamerica.com, like with no typos, exactly that URL, except that that's the presentation of the HTML.  The markup is in brackets on either side of that, and it's hidden from you, by design, by the browser.  By the browser or now, you know, email has become HTML, so your email client is hiding that on purpose to give you a nice, visible, simplified link to click on.



So it's only by looking at the source that you can verify the actual URL that you're going to click on, if you did.  And you might very well see that http://www.bankofamerica.com inside of brackets where on the left-hand side there is http://fakebankofamericawebsite.com, which is the actual URL that you will visit if you click that link.  It's only by looking at the source that you can know.  And the other problem is scripting gets involved, too, because there could be an on-click phrase, even if the href, as it's called, is correct.  If there was an on-click, it turns out the JavaScript gets invoked before the href in the link is visited.



I just was dealing with all of this, as it happens, because I've added automation to the SQRL demo so that when you authenticate with a client the web page, the SQRL demo web page immediately, instantly updates itself to show you that you're now logged in.  So I was visiting all this.  And the JavaScript is invoked first.  And that could be in an included library that you don't even see.  So, boy.  Unfortunately, the bad guys have a real advantage here.  And I hope maybe I've made the case for my first recommendation, which is don't, because...



LEO:  So a number of people in the chatroom are saying in some email clients, if, for instance, you hover your mouse over the - the real problem is that the presentation layer is HTML.  That hides what the actual link is, even if it looks like it's a link, as you said.  But if you hover your mouse over that, can you capture on hover in JavaScript and prevent the status line from showing the actual URL?  Or am I going to see the actual URL in the status line at that point?



STEVE:  Whether it was in the status line, or sometimes it comes up as a little toolkit right there.



LEO:  As a toolkit, right.



STEVE:  Right.  Unfortunately, that will show you the static href, not the on-click call.



LEO:  On-click.



STEVE:  Yes.



LEO:  And that's what you're going to go to is what happens when you click.



STEVE:  Yes.



LEO:  So it can actually be so obfuscated that it's in JavaScript.



STEVE:  Even that, right.



LEO:  And you can, you know, you say, well, view source.  But even then the JavaScript could be further obfuscated.



STEVE:  Oh, yeah.



LEO:  You wouldn't see anything that says HTTP.  You might see just nonsense.



STEVE:  Yeah.



LEO:  Wow.  So hovering is not going to do it.



STEVE:  Not even that.



LEO:  You really just shouldn't.  You should, I guess, what you should do is manually go to the website, by hand enter the URL.



STEVE:  I really think, yes, in fact, I think that that's...



LEO:  So right-click, copy, and paste isn't going to do it, either.



STEVE:  Nope.  It won't because you're actually, you're going to execute code as a result of clicking on that.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Isn't that amazing.  That's great.  That's - I think, frankly, turn off HTML email, period.  It shouldn't be allowed.  It's a bad idea.



STEVE:  And scripting in email.  I mean, how much malware has crawled into people's machines from email scripting?



LEO:  Yeah, yeah, yeah.  A good email client will not do HTML.  Unfortunately, most of us now use web browsers to do email.



STEVE:  Right.



LEO:  Which means you're screwed.



STEVE:  Right.  Basically you are...



LEO:  Don't click that link.



STEVE:  You're receiving a web page from someone you have no control over, you don't know who they are, they're claiming to be somebody who is working in your benefit.  The best advice, and I don't remember where it originated, if it was from Brian Krebs or someone else, but I loved it, and we've discussed it here through the years, and that is never do something that you didn't go in search of.  If a popup says, oh, you need to update your Flash Player, no.  If you weren't going, if you didn't have some reason to go looking to update your Flash Player, don't accept an offer to do so.  You just can't do that safely.



LEO:  Back it up.  All right.  Moving on to Michael Horowitz, who, by the way, wrote Computerworld's, or writes Computerworld's "Defensive Computing" column, so there.  He says:  Just an FYI, Steve.  For those of us with separate routers and modems, it turns out you can communicate with the modem via a private IP address, even through a router.  I tested this with multiple modems and routers.  And it's in his Computerworld article, "Talk to Your Modem."  This can be a useful feature for learning about an ISP connection.  My next blog post will detail how it's a bad thing.  Some modems have clickable buttons and no passwords, letting malicious JavaScript click the buttons.  Oy oy oy.



STEVE:  Yup.  It's funny because, by coincidence, I was just working with a buddy of mine who's having a problem with his cable modem.  And he had a Motorola SURFboard.  Is it a SURFboard?  Yeah.  And it turns out that the Motorola's LAN-facing interface responds to 192.168 - and there is a picture of it, you've got it right up there - 192.168.100.1.  So that's a private network on the LAN side.  So then your router, which is behind it, probably becomes 192.168.100.2, that is, another on its WAN side.  It's on that network to the cable modem.  And then of course on the LAN side of the router is the IP, the set of IPs, things like 192.168.0.something or .1.something.



And the point is that - and this is what Michael was noting was that the router will send anything not in its LAN network outside.  So that inside you can do 192.168.100.1.  The router will see that that's not .0.1 or .1.1 or something in its network.  So the 192.168.100.1 goes out the WAN interface, reaches the cable modem where you can now bring that up.  And apparently he's gone further, and there are nasty things that could be done, as he said, by JavaScript running in a browser, to penetrate your router and get to your cable modem, which he'll be talking about in the future.  I just wanted to raise the flag to our listeners, who may have a separate router and modem, that that's possible.  And I can vouch for the fact that, in fact, it is.  Never a dull moment.



LEO:  Yeah.  But I do have to say the information that you're getting from the modem, it's kind of interesting to see what the cable modem's up to.



STEVE:  In fact, that's why we did this over the weekend was you're able to get the signal strength of upstream and downstream and, like, really useful diagnostic information to see how many channels you've got bonded, what kind of connection it's got upstream and downstream to the ISP.



LEO:  How do you find the private IP address for the modem?  You just google it?  The model and google it?



STEVE:  You could look at the WAN IP of your router.



LEO:  Oh, see what's attached, yeah, yeah.



STEVE:  Yes, exactly.



LEO:  Okay.  There you go. 



STEVE:  But it's interesting because he gave the example of 100.1, and that's what we found this weekend.  That's what apparently they generally use.



LEO:  Interesting.  I'm going to try it tonight.  I have a Comcast business account, so I have business-class router.  I don't know who makes it, but that'll be interesting to play with.  Glenn Musser, in Phoenixville, Pennsylvania and Fort Myers, Florida - a little snowbird action there - wonders about CloudFlare's SSL option:  Steve, I have a few websites with non-sensitive information.  I have used CloudFlare.com's free services for some time, and I recently turned on their "Flexible SSL" feature.  They explain that visitors have SSL between the visitor and CloudFlare.  The visitor sees HTTPS on the site, but of course no SSL between CloudFlare and my web server.



For example, SeniorTechGroup.com supports my free tech group gatherings.  I don't get paid in any way, so I don't want the extra cost of paying for an SSL certificate.  My site, when you go there, SeniorTechGroup.com, shows the green lock in the web browser.  But does that have any value?  Any downsides?  Thanks for your great podcast.  I listen to every one.  You inspire many security discussions at our tech group gatherings.  And he gives a link to the CloudFlare SSL Help page [support.cloudflare.com/hc/en-us/articles/200170416].



STEVE:  So this is sort of a mixed blessing.  I was a little disturbed to see CloudFlare doing this.  They really are responsible about reminding and explaining that this is not actually providing any security.  The problem is I'm not sure what value it offers to show people - yes, you're showing it there on the screen.



LEO:  It looks good.  I see a green padlock and everything.



STEVE:  Yeah.  And the problem is, in fact, it's not a secure connection to the destination web server.  Essentially CloudFlare is acting like a proxy that is stripping SSL security from the connection.  And again, they make it very clear, and they say, you know, this is not safe.  Yet they're offering it.  And I don't get why they're offering it because it's really, I mean, okay.  So what benefit is there?  There would be the benefit in an open WiFi setting of the traffic from the person surfing to that site getting to CloudFlare servers, that is, out of the open, unencrypted environment.  Similarly in a hotel setting, for example, where you either have open WiFi, or maybe a shared Ethernet.  We've discussed that at length in years past.



So you would have encryption to prevent eavesdropping to CloudFlare's servers.  They're then going to terminate the SSL connection at them.  Essentially they're synthesizing a certificate on the fly in order to terminate that connection.  Then they set up a non-SSL connection back to the actual target server.  So, mmm, no security exists there.  And anybody sniffing the Internet would be able to see the traffic.  And so the only, I guess the only concern is that there could be some  tendency to trust what should not really be trusted to the degree we would be used to trusting it.  But I can't argue that, for example, encrypting in an open WiFi setting is a useful thing to offer.  That's better than not having any at all.  So there's that value.



LEO:  You can examine the certificate, and you'll see that it belongs to CloudFlare.



STEVE:  Yeah.



LEO:  But I don't know if the people who use this site would do that.



STEVE:  Yeah.  Given that it is now - that annual expiring certificates can be had for free, Glenn, maybe it makes more sense just to get a free certificate from RapidSSL or Start, I think it was StartSSL.com.  Use their free one-year certificate.  It does require an annual annoyance of updating the certificate.  But it never costs you anything.  And then you've got your own HTTPS and real security.  And you can still run that through CloudFlare.  They're able to then create a secure connection to your server, as well.



LEO:  Question 8 comes to us from Justin Malone in Lacey, Washington.  He thinks he's found a HSTS vulnerability:  What would happen if an attacker were able to intercept and modify regular HTTP traffic and add the HSTS header as the traffic is passing by?  Would this force devices to attempt to make a secure connection to a server that doesn't support it, or does the implementation of HSTS require the client device be able to see a certificate prior to caching the STS header?



STEVE:  Well, I loved this question.  I take my hat off to Justin for thinking, for recognizing the problem.  The good news is the designers of the HTTP Strict Transport Security, which is what HSTS stands for, thought of it, too.  The problem that Justin notes is that, once you have given a - once a server has supplied the HSTS header to the client, the client will cache it.  And until that HSTS header expires, and the expiration is part of what the client receives, the client will refuse nonsecure connections.  So what if a server that did not offer HSTS support, that is, just a regular HTTP server, what if somebody maliciously intercepted that interceptable connection - it's interceptable because it's not secure - and tacked one of those HSTS headers into the server's response going back to the client?  Then the client would go, oh, this site is saying from now on always use HSTS.  And it would then refuse not to.  And if the server didn't support it, it would break that client's ability to connect.



The HSTS guys foresaw that problem.  And so the rule is no client will accept an HSTS header unless it is receiving it over an SSL connection which is completely verified with an up-to-date cert and in every way correct from the server.  So that prevents exactly this malicious attack which Justin foresaw.



LEO:  Brilliant.



STEVE:  Very cool.



LEO:  No. 9, Paul Dove in Hampton, United Kingdom wonders whether there's a way to block Flash completely in every browser.  Oh, I like that:  Hi, Steve.  With yet another Flash vulnerability in the news this week, I think it's time we got rid of it completely.  But with Flash built into the Chrome browser, it's not that easy.  Even if you disable the plugin for yourself, I've still seen it enabled for other users of the PC.  I've googled for a registry hack or something like that to permanently disable Flash for all users, but couldn't find anything.  Then I wondered, is there a way to configure a firewall to block all Flash content?  Do you think that's possible?



STEVE:  Well, once upon a time, before all of our communications was encrypted, it would have been possible.  Do you remember Proxomitron, Leo?



LEO:  Yeah, yeah.



STEVE:  Yeah.  Proxomitron was a really very cool local proxy, the idea being that your browser connected to it, and then it connected to the Internet on your browser's behalf, just like a proxy.  And it was a - you could create rules that did all kinds of cool things.  People used it to change their hosts headers, their user-agent, basically to tune and tweak their web browser interaction.  And one of the things you could do, for example, would be to - and Proxomitron did this - would be to examine a page coming back from a server and, like, strip out things that you didn't want to have.  And, for example, Flash tags were often stripped out, or ads were stripped out, all kinds of things.



The problem is now we're increasingly going to security, to SSL/TLS connections that nothing can see into between your browser and the remote server.  I've poked around at Chrome, and I don't see anything other than going to chrome://plugins.  That's not something that is normally available at the settings page.  There you can see extensions but not plugins.  But if in Chrome, you go to - up in the URL you put chrome://plugins, no hyphens or anything, just P-L-U-G-I-N-S.  That'll take you to a page most people don't normally see, which lists rather comprehensively all kinds of things that are typically enabled unless there's some problem that Chrome has found, all the things that Chrome can bring to bear in order to display pages.  And Adobe Flash Player is right there among them.



Now, as Leo is pointing to right here in the podcast, you are able to disable it.  When you click that, it turns, like it grays out the whole region, showing you that it is no longer enabled.  And then you can click it again to enable it.  But as Paul noted, that's a per-user setting.  Nothing that I could find in Chrome is global.  So I don't see a solution other than going to each user's session and manually disabling Flash, the Adobe Flash plugin for that user and that login session.  That's the only thing I can see to do it.



LEO:  Can we at least say that Flash in Chrome is safer?  Because it is sandboxed; isn't it?  And they keep it up to date for you and all that?



STEVE:  Yeah.  I agree with you.  I think that using it in Flash is a better place.  When I opened Chrome, because I'm not in there a lot, mine was auto-grayed out with a warning that it was no longer current.  And so I updated Flash because we just had those two zero-days.  In fact, that's what triggered Paul's email is all of these zero-day vulnerabilities.  And then it came back to life, and then I manually disabled it because I'd just as soon fly without it if I can.



LEO:  You can.  So, but if - okay.  So updating Chrome does not automatically update the Flash in Chrome?



STEVE:  I think it does.  But since I...



LEO:  You just don't update Chrome enough.



STEVE:  Exactly.  I'm not running Chrome often enough to give it a chance to auto-update.  But it does, it absolutely - in fact, the notes from Adobe talk about Chrome and IE.  IE is also now keeping Chrome up to date itself.



LEO:  Yeah.  Flash, yeah.



STEVE:  Both of them - yeah, I'm sorry, right.  Both of them Adobe was working with in order to push these zero-days out to both Google and to Microsoft so that they in turn could get them out to their browser users.



LEO:  Well, I am now disabling Flash.  I'll see what happens.  Unfortunately, you need it to watch, for instance, TWiT on Ustream and some of our other - although, you know, now that Google's YouTube has eliminated Flash entirely, it's all HTML5.



STEVE:  I know, it's 100% HTML5.



LEO:  I have to think we're getting to that point where everything will be HTML5, HTML5 with HLS.



STEVE:  Didn't I just - was it on one of your podcasts, there's a compiler now that's compiling JavaScript into - oh, no, it's compiling Flash SWF into HTML5 and JavaScript.  So we're seeing, really, I think we're approaching the end of that, which can't come too soon because here they are now, still, two zero-day exploits, people actively infecting people's computers, sometimes with Flash-based ads [crosstalk].



LEO:  That's the real problem because a lot of these ad networks are automatic.  Yahoo! and Google don't really check the contents of the ads.  And so it's easy to buy an ad that has malware in it.  Somebody's saying, I don't know if this works, but you can, if you modify the - let's say you have other users on your machine.  You've disabled it.  I guess you could just go into their browser and disable it.  But you could also create a new shortcut bookmark or icon that says "--noflash chrome.exe."



STEVE:  Ah.



LEO:  So maybe that's another...



STEVE:  So that at launch time...



LEO:  At launch it's disabled, yeah.



STEVE:  It's disabled, yes.



LEO:  Yeah.  I haven't tried that, but somebody said to try that.  And that's Windows, of course.



STEVE:  That's a great hint.



LEO:  Brian Williams - not that Brian Williams - in Kentucky, although maybe he is, I don't know - wonders about...



STEVE:  I think he's hiding somewhere.



LEO:  Hiding in Kentucky, wonders about personal certificates.  Steve, we hear a lot about server certificates, but what about personal certificates?  I mean, each side of a TLS key exchange requires a cert; right?  What else can we do to beef up the crypto on our end for our client apps that do SSL/TLS?  Can we periodically generate new certs with higher bit-lengths than default?  Thanks for all you do.



STEVE:  So I think there's a bit of a misunderstanding that I wanted to address in Brian's question.  It is not the case that each end of an SSL connection uses a certificate.  Each end can, and it's possible for the server side, for some connections that are sort of based on the server's configuration, to query the client and require a client certificate.  And it is good security to do so, the idea being that you would install a user certificate or a client certificate in the browser, and then that would assert your identity to the server in exactly the same way that the server's identity is being asserted to the client, that is, when we go to GRC.com, for example, or Amazon, or Google, over an HTTPS connection, that remote server's identity is being asserted and guaranteed by the certificate that it has sent.  Similarly, clients can offer certificates, not just username and password or other stuff, but an actual SSL certificate can be installed on the client.



But it never really caught on.  It's not the way people typically operate.  Apps can have client certs, which they use in order to assert their app identity to a remote, like to the company that publishes them, when they want to establish security where each end is authenticated.  But again, that's not the typical browsing experience.  Most browsing is single-side authentication where that side is the server, not the user.



LEO:  Steve, you did it again.  Ten questions.  We've come to the end of our Q&A Episode #206.  Almost as many question-and-answers as Microsoft has updates today.



STEVE:  It was close.



LEO:  It was close.  I thank you for doing such a bang-up job to help keep us all safe and secure on the Internet and remind people that they should go to Steve's website, GRC.com, to get a copy of SpinRite, yes, the world's best hard drive maintenance and recovery utility, and also all the freebies he offers, like SQRL, and you find out more about all the stuff he's up to.  You should have a science fiction page, too, by the way, with all the recommendations in there and stuff.



You can also find this show.  He actually has two forms of the show.  He has the 16Kb audio, very low-bandwidth audio, for people who don't want to download a giant audio file.  But he also does transcriptions, which are the smallest version of all, great transcriptions by Elaine Farris.  You can get all of that at GRC.com/securitynow.  We will do questions again in a couple of episodes.  If you want to leave him a question, don't bother to email, just GRC.com/feedback; or you can tweet him, @SGgrc, and that's a good way to get a hold of him.  Steve actually is quite active on Twitter now.



STEVE:  It's a great social medium.



LEO:  Yeah, it is.  I agree.  Let's see, what else?  Oh, we have full-quality audio and video on our site, TWiT.tv/sn, so you can watch Steve as he answers those questions and waves his hands.  You can also subscribe, which is probably the best thing to do.  That way you'll get every episode automatically.  That's kind of the idea behind podcasts.  iTunes has it, very single podcatcher in the world, including all your apps on your smartphone and everything, they all have Security Now! because it is one of the longest running shows on podcasting.  Ten years soon, yes?



STEVE:  And it seems to be having the reverse of podfade.



LEO:  The reverse of podfade.  That's what we specialize in, reverse podfade.  So, yeah, please do subscribe.  That way you'll get it.  Or get one of the great TWiT apps on every platform, including iOS, Android, Windows Phone, and Roku.  And you can watch, like on the big-screen TV if you want, on your Samsung.  You can talk to Steve, and the Samsung will respond.  That's fun.  Or the Alexa, one or the other.  Sorry.  Oh, man.



STEVE:  Uh-oh.



LEO:  Sorry, Lisa.



STEVE:  The "A" word.



LEO:  Alexa, thank Lisa for listening for us, will you?  Thank you all for listening.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#495

DATE:		February 17, 2015

TITLE:		HTTP/2

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-495.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with several VERY interesting security events and stories of the week.  Then we take a close look and a deep dive into the operation of the industry's first change in the official HTTP protocol in 15 years - the finalization and emergence of the HTTP/2 IETF specification which significantly streamlines web browser and web server interaction.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with the latest security news, including that new hacking ring that Kaspersky discovered.  What did they call it, the Equation Group?  Details on that and a lot more, plus Steve's going to take a look at the new web protocol for speeding up page loads.  It's from Google, and it's called HTTP/2.  Details ahead on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 495, recorded Tuesday, February 17th, 2015:  HTTP/2.



It's time for Security Now!, the show that protects you and your loved ones online, your privacy too.  And here he is, the man in charge of Security Now!, Mr. Steven Gibson from GRC.com.



STEVE GIBSON:  Yo, Leo.  It's great to be with you.  Well, we're 495 episodes in, in our 10th year, and we're closing in on Episode #500.



LEO:  Amazing.



STEVE:  Yeah.  I figured with all of this recent discussion of HTTP and the forthcoming spec for HTTP/2 and SPDY and how HTTPS over SPDY is faster, outperforms HTTP, it was time to take a look at, formally, at what is HTTP/2.  We got no changes in the HTTP protocol since Version 1.1 in 1999, so 15 years ago.  And we've been sort of tolerating it and coming up with workarounds for its various problems ever since.



So this week we're going to do - first of all, an amazing week of security stuff, largely because Kaspersky's having their security analysts conference down in Cancun, Mexico right now, yesterday, today, and tomorrow.  And so they've been dropping some bombs on the industry of the things that they've been tracking and aware of for some time.  So we're going to talk about actually a little bit of a compromise that Google has made in their Project Zero ideology; the fact that Kaspersky has sort of unveiled a very longstanding advanced persistent threat in the global banking world; also some details on something that we actually found out about, believe it or not, on December 29th of 2013, but we didn't really - it didn't really catch our attention.  And that's this hard drive firmware rewriting.



LEO:  Unbelievable.  This is the Equation stuff; right?



STEVE:  Yes.



LEO:  Oh, man.



STEVE:  The Equation Group is the name that Kaspersky has given to them.  And they're, like, the elite group who apparently feed the Stuxnet and the Regin group their technology.  Also a fabulous tip about credit freezing to protect yourself from identity theft.  And then we're going to plow into HTTP/2 and explain exactly what it is that the industry has pretty much already moved to, kind of quietly, but it's being finalized here.



LEO:  A lot of interesting stuff.



STEVE:  It's a great podcast.



LEO:  As you said, a great week.



STEVE:  Yeah.



LEO:  And I think we should go to Cancun next year.



STEVE:  Yeah, when I found out that was going on, it's like - and there was Kaminsky, who I last saw when I was presenting.  We both were, actually, on November 7th in Las Vegas for the DigiCert conference.  And I thought, oh, Dan.



LEO:  He went down there, huh?  Yeah.



STEVE:  He's talking about who knows what.  So, yeah.



LEO:  Well, maybe next year.  I just assumed Kaspersky would have its conference in Moscow in the middle of winter, and I thought, well, I'm not going to that.  But Cancun, well, now...



STEVE:  I think we understand why everybody would want to have a high attendance for that conference.



LEO:  Yeah.



STEVE:  Now, I should mention we'll be talking about Carbanak.



LEO:  That's something else.



STEVE:  That's the cybercrime group that's been stealing maybe as much as a billion dollars from the global banking market.  But that's not Carbonite.  Carbanak is something different.



LEO:  Yeah.



STEVE:  I wanted to point out this picture of the week, courtesy of our often contributor to the show, Simon Zerafa.  It's just such a perfect picture.  It's the first page of the show notes for the week, showing a kid on a unicycle driving down a little commercial strip of shops, having just passed a sign that has huge blocks letters, "NO," and then underneath it "bicycle riding, rollerblading, roller skating, skateboarding, and scooter riding."  Clearly, they were trying to say no to everything.



Anyway, the point is the caption of this is "Why Blacklisting Fails."  Which is - this is just perfect because this kid is on a unicycle, not a bicycle, not a rollerblade, not roller skating, not skateboarding, not scooter riding.  He has obeyed the sign.  Yet he's riding his unicycle where they don't want him to be because they blacklisted certain things rather than saying "Only pedestrians," for example, only people using their feet.  No, they went the other direction.



LEO:  That would be whitelisting, wouldn't it, if they said only walking people.



STEVE:  Exactly.  Only people walking.  Oh, just perfect picture.  So I love that and wanted to commend that to anybody who's interested.  It's in the first page of the show notes.



So Google, apparently reacting to the backlash to their rigid, or I should say previously rigid, 90-day "we will disclose vulnerabilities whether they're been patched or not" policy of Project Zero, has softened their stance.  In a rather, eh, sort of snarky blog posting, they start out by substantiating the success of this policy.  They use Adobe as an example, talking about how Adobe has managed, with all of their multi-platform, multi-reach stuff, the Adobe Flash team has managed to successfully fix 37 Project Zero vulnerabilities within the 90-day deadline.  But on the other hand we see Flash constantly doing out-of-cycle patches to fix these things.  And the problem that we've discussed several times is that Microsoft, because they really, unless it's something dire, have to stick with a 30-day policy with their standard second Tuesday of the month schedule because their patches need to be vetted by corporate IT.  You could argue that the corporate IT team can just block Flash.  But they can't block Windows.  They are using Windows.  So they have no choice.



So anyway, so Google says, you know, sort of saying everybody else manages to do this.  And then they say, stepping back more generally, talking about the success of their Project Zero, that the 154 Project Zero bugs fixed so far, 85 percent were fixed within 90 days.  And then if they further restrict that to essentially half of those, the 73 issues filed and fixed after October 1st of 2014, so that's sort of saying once we came up to speed, once everybody fully understood what Project Zero was, that is, the more recent problems, that number jumps to 95 percent of those 73 issues fixed more recently within the 90 days.  And then they finally say, "Furthermore, recent well-discussed deadline misses" - and in those phrases they have three links which correspond to the Windows problem and the two OS X problems, they said - "were typically fixed very quickly after 90 days."



So what they've done as a consequence, I mean, so basically they're saying, okay, here's where we stand.  We think we're doing something good for the industry.  People have improved their responses, given Project Zero, that is, the most recent responses have been faster than the earlier ones.  The 90-day deadline misses have dropped from 85 percent originally to only 5 percent misses, so 15 percent misses down to 5 percent misses.  And those that missed were quickly fixed.  So, okay, fine, Google, thank you very much.  So now they're saying, "We've studied the above data," and I love the way they said this.  They wrote, "and taken onboard some great debate," sort of like a small dinghy takes water onboard.



LEO:  Some engineers wrote this.



STEVE:  "Taken onboard."



LEO:  They've taken onboard some debate.



STEVE:  "Some great debate and external feedback around some of the corner cases."  These are corner cases; right?  Like did you mean greater than one or greater than or equal to one?  Oh, well, we really meant to include the equality case.  Okay, good, "for disclosure deadlines," writes Google.  "We have improved the policy in the following ways.  Weekends and holidays, if a deadline is due to expire on a weekend or..."



LEO:  Oh, man.



STEVE:  I know, "or a U.S. public holiday, the deadline will be moved to the next normal working day."  Okay.  So, you know, like when the mail is delivered, except you do get mail on Saturdays still.  But not on federal holidays.  So if the deadline falls then, they'll bump it.  They'll give you one or two days extra.



Then, grace period.  And this is the big one:  "We now have a 14-day grace period.  If a 90-day deadline will expire, but a vendor lets us know before the deadline that a patch is scheduled for release on a specific day," so the vendor's got to come back to Google and say, "Please, Google, we're ready, but we just need some more soup.  I mean, we just need two more weeks."  So if they'll tell Google the specific day within 14 days following the deadline when the patch will be released, "the public disclosure will be delayed until the availability of the patch.  Public disclosure," writes Google, "of an unpatched issue now only occurs if a deadline will be significantly missed, by more than two weeks."



And then finally, the last change is Google wasn't dropping their Project Zero stuff into the standard CVE pot which is maintained by the industry.  So the third change is the assignment of CVE numbering.  Google writes: "CVEs are industry standard for uniquely identifying vulnerabilities.  To avoid confusion, it's important that the first public mention of a vulnerability should include a CVE.  For vulnerabilities that go past deadline" - thus the public disclosure - "we'll ensure that a CVE has been pre-assigned."  So those are the changes.  Basically it means another two weeks added to the existing 90 days.



LEO:  I kind of understand the need to set a deadline because, as they point out, the three times that we had to reveal it publicly, it got patched right away.  And so if you don't set a deadline, and you don't reveal it publicly, then companies just drag and drag and drag.  But there's two things.  This first strikes me as some real arrogance on the part of Google.  Like, well, we're going to do it right, and obviously these other companies just don't care.



STEVE:  And somehow they have a problem.



LEO:  They have a problem.  I think you've got to give credit to Microsoft and Apple and whoever else that they do care about security, and they're going to try to patch these flaws.  Give them some credit.  



STEVE:  Certainly.  And...



LEO:  They're like a schoolteacher who says, "Well, you know, you didn't hand in your report, so we're going to give you an F."



STEVE:  Yeah.



LEO:  We're grownups here.  It also feels a little bit, I don't know, I don't want to say something politically incorrect.  But it feels like it's snarky.



STEVE:  I just said, I used the term "snarky," yeah.



LEO:  It's engineers who are being a little too literal-minded.  You know?



STEVE:  Yeah.



LEO:  You could just say, look, we're going to give you about 90 days.  We're going to contact you, and we're going to beat the drum louder and louder if you don't fix this or something.  You don't have to - I don't know.



STEVE:  Yeah.  That's my reading, too.



LEO:  We're not in school.



STEVE:  At the same time, thank you, Google.  Thank you for...



LEO:  Well, yeah.  They got it fixed.



STEVE:  ...being a little accommodating.  It's clearly, I mean, as I've said, from my perspective, the big problem is the timing of the 90-day counter relative to Microsoft's fixed 30-day schedule because it could be that just - what would it be?  It would be just before a 90-day - I'm sorry.  Just before one of Microsoft's second Tuesdays, a problem is found, and Microsoft is notified.  Now there's three fixed cycles, but they're going to miss that because the 90 days will expire just before another one of Microsoft's scheduled releases.  So it does make sense to add a little bit of forgiveness in there because Microsoft's challenges, I think, are well understood.  It was driving people crazy.



Remember, once upon a time Microsoft would just drop these all the time, and IT was scrambling around trying - and there were some problems where they would patch things that would break IT software and then have to roll them back and so forth.  So this has all been sort of negotiated over time.  This is the way it makes sense to work.  And other companies have followed suit.  You know, everybody else now tries to do things on some schedule or in batches to minimize the problems this creates.  So again, thank you, Google.



LEO:  For being flexible.



STEVE:  For being flexible.



LEO:  Or really more like for not being too inflexible.



STEVE:  Well, you know me, I mean, I've arranged my security certificates specifically to fudge Google.  I'm thumbing my nose at them, keeping SHA-1 signed certs because there's nothing wrong with that.  And my certs expire on December 31st at the end of the year so that I get the happy Chrome indicator.



LEO:  It's that same kind of arrogance, to me.  It really feels like...



STEVE:  Right, it is.



LEO:  ...a real arrogance about - the subtext of this is that, oh, really Apple and Microsoft don't care as much as we do about your security.



STEVE:  Right.



LEO:  And that's, I think, patently false.



STEVE:  Yeah.  Microsoft had already announced a drop-dead, in 2017, at 2017, of SHA-1, in a context of there being nothing that anyone knows that's wrong with it.  And Google just decided to push that forward because they've got the most popular browser on the planet now, and they can arbitrarily enforce this.  I don't know, did you see that wonderful video of some guy trying to figure out what Chrome's trying to tell him with a red slash through the HTTP?



LEO:  No.



STEVE:  Oh, it's been floating around for the last couple weeks.  And it's like, here's a typical user, scratching his head.



LEO:  Right, a normal user, yeah.



STEVE:  And he's like, okay, well, now - and he, like, figures out how to work around it.  He, like, and it was so painful because this was some marketing spam in email.  And if he clicked on it, he got this warning from Chrome because it was HTTPS.  But if he, like, removed the HTTPS, which he doesn't understand, and just put www.marketingacceleratorsareus.com and some other crap, you know...



LEO:  It worked.



STEVE:  Then it worked.



LEO:  It's magic.



STEVE:  Without any security, now I don't have a notice.  So, I mean, so this was just - it was just like, oh, so painful.  But this is, you know, it'll be interesting to see how Google flags this stuff in Chrome and what problems it causes because the problem is Google's going to be trying to say something that users will notice, saying that websites are not secure, and the websites are going to be saying yes, we are.  There's nothing wrong with our certificates.  So, yeah, exactly as you say, Leo.



LEO:  Hubris.  It's hubris, yeah.  But that's all right because, you know what?  What goes around, comes around, boys.



STEVE:  So the Carbanak cybercrime group, which is what Kaspersky has named them, there was a lot of news about this in the last week.  So here's what we know about this.  They've been operating silently since 2013.  It feels Russian because it's sort of a social - it's a very sophisticated group doing social engineering phishing to get a foothold into a bank's network by getting someone to click on a link in email.  That gets them in.  Then they spend between two and four months patiently infiltrating the banking network.  They get onto the network.  They get to an executive's computer who has access to the video camera feeds, which they then start studying in order to learn how the bank operates, in order to impersonate the normal processes and operations of the bank so that, when they start acting, those actions will fit right in with the normal flow of what the banking is doing.



So we're talking sophistication.  They have silently attacked at least a hundred banks, e-payment systems, and other financial institutions across 30 countries which Kaspersky has identified.  And while this began back in 2013, it is still going on today.  They limit their attacks to $10 million per bank, once they finally engage on a specific bank.  And so they demonstrate enormous patience in essentially working to remain covert until they're ready to act.  They have done things in two main ways.  One is that they will get control of the bank's ATMs and cause the ATMs to emit cash, and then have a mule, knowing what the cash and the ATM schedule is, come by and pick up the cash as it's coming out of the ATM.  And one of Kaspersky's unnamed banking clients lost $7.3 million through ATM cash withdrawal using a coordinated system of mules to go to specific ATMs at specific times and pick up the cash that was just magically being spit out by the ATM.



Then the other thing that they do is, once they've infiltrated a bank's cash management and account management network, they will change, they will edit account balances, for example, take a balance of a thousand dollars and add a zero to it.  So now the balance says $10,000.  But before anyone notices, and Kaspersky noticed that the banks typically only perform a verification suite every - I think I saw 10 days was the number.  So very quickly after adding a zero, for example, to a thousand-dollar balance, turning it into $10,000, they then transfer 9,000 out of the bank to one of another set of accounts that they have set up, returning the original balance to 1,000.  So the user's balance now looks correct, yet $9,000 is gone.  And they've identified JPMorgan Chase as one of the recipients of funds from this group and also, in China, the Agricultural Bank of China as another recipient.



So this has been revealed, there was a press release just yesterday at the start of Kaspersky's security analysts conference, which is just going on now, as we mentioned, down in Cancun.  And they said:  "The cybercriminals began by gaining entry into an employee's computer through spearphishing, infecting the victim with the Carbanak malware.  They were then able to jump into the internal network and track down administrators' computers for video surveillance.  This allowed them to see and record everything that happened on the screens of staff who serviced the cash transfer systems.  In this way the cybercriminals" - so they were essentially spying on the spies, the internal spies of the bank.  So "the cybercriminals got to know every last detail of the bank clerks' work and were able to mimic staff activity in order to transfer money and cash out."



So, and what's really interesting, too, is that banks have never acknowledged this previously.  They're all keeping mum about it.  And one of the things that I guess Obama was talking about last Friday when he was in Silicon Valley, talking about the cybercrime bill that he wants to get made, is that there would be reporting requirements that would not have allowed banks to keep this quiet as they have been.  But this has been silently going on for probably maybe two years.



LEO:  Or more, goodness knows.



STEVE:  Or more.  Yeah.  And in fact...



LEO:  I mean, it's been going on forever.  This particular hack, though.



STEVE:  Yeah, Kaspersky did acknowledge that their own verification, they've been able to verify $300 million, but expect triple that.  And now we're seeing numbers like a billion, which was about triple 300 million.  So a lot of money.  And also, interestingly enough, the banks are absorbing this.  I mean, this is not something that they're blaming their accountholders on because it's not their accountholders' fault.  It's their own internal network security which is being compromised.



LEO:  Wow.



STEVE:  So the biggie is this hard disk drive firmware overwriting.  Kaspersky has named this group, which is apparently a group within the NSA, they call them the Equation Group because they have a great affection, apparently, for using cryptography and all the various cipher technology in order to obscure and manage the malware that they're using.  The Kaspersky group has put together a riveting, I think it's 44 pages, an FAQ in the form of a PDF.  I created a bit.ly link because I wanted to turn people onto this.  It is really interesting.  So it's bit.ly/bad-hdd.  I called it that because people were all concerned recently about the BadUSB, which is what that was called.



Well, this is essentially the equivalent of BadHDD, that is, bad hard drives.  So what we know is that there is - this has been specifically done in targeted attacks.  There is malware which is deliberately overwriting the firmware in hard drives.  Kaspersky has found two different versions which they call version three point something or other and four point something or other.  The four point something or other understands not only hard disk drives, but also SSDs because there were names like OCX and OWZ and, you know, the various SSD manufacturers, more than a dozen different makes and models of drives.



It turns out that hard drives probably all have the same problem that some thumb drives have, and that is they've got, we know that they've got very sophisticated controllers on them.  It was a bit of a wakeup call that USB thumb drives would have sophisticated controllers.  But we know that hard drives do.  There is a well-documented standard in the so-called ATAPI interface.  The ATAPI API is what, for example, I with SpinRite use a great deal.  There is a download microcode command that allows external microcode to be provided to the drive.



The problem is there is no upload microcode.  That is, the API itself is write-only.  The hard drive manufacturers do that on purpose because they don't want anybody reading out the microcode.  I mean, this is proprietary.  They've got fancy error correction technology.  Essentially, each hard drive manufacturer considers the firmware on their drives to be crown jewels.  Their intellectual property, you know, the exact management of defects, the exact management of the technology on the drive is theirs.  They don't want anybody reading it out, getting access to it.  Some hard drives have the firmware stored off-chip, that is, in a separate little serial flash which does make it downloadable.  And some hard drives also use the ARM architecture, which means that they have a known instruction set.  And if the external firmware is not stored on the same chip, it makes it easy to access it and reverse engineer it.



Now, Kaspersky believes that this Equation Group is part of the NSA because they have seen that this Equation Group firmware or malware, which is laid out in this 44-page PDF, apparently was employing zero-day flaws before Stuxnet and Regin were both employing them.  It's not clear whether the Stuxnet Group and Regin Group got them from the Equation Group.  But this looks like a group within the NSA.



And the other thing which really sort of puts the frosting on this is we read about this and were chuckling about it in that large dump - you'll remember, Leo - that Der Spiegel made back late in 2013 as part of the original multiple rounds of Edward Snowden dumps.  This is, and F-Secure reminds us of that, this is the IrateMonk NSA slide.  The NSA slide that disclosed this IrateMonk project had it tagged as TS/SI/REL.  And I'm sure that TS is Top Secret.  I don't know what the SI or the REL are.



But that slide said, "IrateMonk provides software application persistence on desktop and laptop computers by implanting the hard drive firmware to gain execution through master boot record substitution.  The technique supports systems without RAID hardware that boot from a variety of Western Digital, Seagate, Maxtor, and Samsung hard drives.  The supported file systems are FAT, NTFS, EXT3, and UFS.  Through remote access or interdiction, UnitedDrake" - which is another one of the NSA programs in these slides - "or StraightBlaze are used in conjunction with SlickerVicar to upload the hard drive firmware onto the target machine to implant IrateMonk and its payload, the implant installer.  Once implanted, IrateMonk's frequency of execution" - that is, dropping the payload - "is configurable and will occur when the target machine powers on."



So this sort of closes the loop on this.  We saw that slide.  We talked about it.  But it was a little bit maybe sort of like overwhelming.  I mean, there were just so much of this NSA disclosure back then that this was just one of among many.  Remember we were talking about passive eavesdropping and things you could beam microwaves out that would bounce things back and just, you know, this was among all that technology.  Here, though, we've got Kaspersky, who has found samples in the wild.  They've been able to pull this stuff out of drive firmware.  As I said, sometimes the flash ROM is not in the CPU chip itself, which would have made it much more difficult to access.  But it's a little eight-pin surface-mount chip that they're able to pull.  So they were able to reverse engineer this and see the signatures of all of the various drives that this thing is aware of and that it knows how to, essentially, how to operate.



Now, someone at Kaspersky said that, without the source code, this would be impossible.  I would argue that's not the case.  It would be true if you could not read out the firmware because, if you're dealing with flash that's on the same chip as the processor, and you only have write access to the firmware, you would absolutely have to know everything about the hardware architecture like only the manufacture could in order to knowledgeably perform a write-only overwrite of that processor's firmware and have anything survive.  If, however, the serial EEPROM is outside the chip, then you could certainly obtain what it has.  And if you knew that this was a standard CPU architecture, for example, they seem to be using ARM throughout the industry, then you'd disassemble it and start reverse engineering it.  So it certainly is possible.



However, the other way that it may have been that the government or government agencies had access to source, not through reverse engineering, is they may have been doing large drive purchases and said to these various drive manufacturers, look, we're happy to sign a nondisclosure agreement, but we're buying from you essentially computers with software in them when we are buying hard drives from you.  We need, under NDA, you to provide the source for the firmware.  And in order to make a large sale to the government, we know that manufacturers like Western Digital and Seagate and Samsung and so forth, they'll turn over their source under a promise that it will never be disclosed.  So it may very well be that an agency would have said, okay, NSA, we need you to vet this source code of these WD drives we're buying, and the NSA would have been more than happy to do that and probably would have retained copies.



So it's foreseeable, we can understand how the law enforcement agencies with the U.S. government could have obtained the source, and this is very powerful.  Essentially it gives them three things.  It gives them persistence, invisibility, and local caching.  For persistence they get extreme hardware lock persistence which survives everything - disk reformatting, OS reinstallation.  If you suspect something a little funky is going on in your computer because you're not sure, what do you do?  You reformat the hard drive.  You reinstall the OS.  This thing is able to live through that.  It gets into the firmware of the drive, you can't get rid of it.



Invisibility, of course, once the drive is infected with a malicious payload, the drive itself, the firmware, you can't scan for it.  It doesn't appear.  Only its behavior, if you happen to catch it misbehaving in this fashion, then you'd have a chance.  The problem there is that the misbehavior is going to happen as the first thing during the system's boot-up.  It's going to replace the master boot record, and maybe not every time.  So you could watch it looking just fine and say, okay, well, looks good.  But it only takes doing it once in order for it to swap a master boot record with something else in order to preload its own malware, which then is there before the OS and, as we know, essentially functions like a rootkit.  But this one you can't get rid of because now it's built into the hard drive.  And that would be a pre-boot rootkit that is then able to subvert the operation of the operating system because the operating system has to rely on the first things that load in order to check that everything else that loads subsequently is all right.



And then, finally, local caching.  What this could do is it could set aside some chunk of hard drive space.  So it's not constrained to just the write-only firmware.  It can take back some space from the hard drive which, since it's now the modified firmware, it no longer allows access to that region.  If it decreased the apparent physical size of the drive, that could be a tipoff that this drive has been infected because it would be reporting a smaller sector count than exists.  On the other hand, drives do report in some cases a reduced size if their spares pool of bad sectors that are being swapped out for defects, if the spares pool becomes exhausted, the drives have the ability to reduce their reported size, essentially taking back unused sectors.  So it's not the case that all drives of a same make and model always even report the same physical size.  So you can't rely on the drive saying that it's a little bit smaller as a means of detecting that.  So that's a problem.



But what that does is it gives the drive huge amounts of space, that is, it gives the malware huge amounts of space where it could sequester sort of pre-exfiltrated information, waiting, for example, for a system that doesn't always have network connectivity, or doesn't have a USB plugged into it.  It could store the stuff there so that, again, no scan could find it.  And then, under a certain set of circumstances, it is able then to dump that out when it has access to some sort of communications facility.  So, wow.  These are the details, it looks like, of the IrateMonk project that the Snowden slides talked about, but we never actually had samples found in the wild.  And now we know that this exists, and it has been used globally, essentially, around the country and around the world.



I did want to say also that, again, our friend of the show Simon Zerafa retweeted a link that I remember him tweeting some time ago.  Wait a minute.  And I'm thinking that - oh, no.  I was going to say I thought I created a bit.ly link for it, but I didn't.  I did tweet it just now, so anyone who's interested can check my Twitter feed.  There is an interesting project at SpritesMods.com, S-P-R-I-T-E-S-M-O-D-S dotcom, where somebody reverse engineered a hard drive.  So it's all of this stuff.  If you want to see, if you're interested, a real-world look at reverse engineering a hard drive, where essentially there's a standard interface called JTAG which is an embedded processor debugging interface that allows an attachment to essentially read and write firmware, set breakpoints, start and stop embedded processors.  It turns out that hard drives often have JTAG interfaces which are enabled.  And if you know what you're doing at the hardware level, you can connect to a hard drive and play with it at a level below the officially sanctioned ATAPI API.  And this SpritesMods.com site has a really interesting multipage report about that being done.



Okay.  Lastly, and this is - I probably should have done this first, but these other stories were just too interesting, and the industry's been buzzing about them.  I created a bit.ly link for this, and it's important:  bit.ly/freezecredit, all lowercase.  So bit.ly slash F-R-E-E-Z-E-C-R-E-D-I-T.  This takes you to a page where the guy explains that a service that is available to anyone for all three major credit bureaus - Equifax, Experian, and TransUnion - allows consumers who are not the victims of identity theft to lock their credit reports.  It's not free, but it's not too expensive.  The cost varies, depending upon where you are, from $3 to $10.  In California it was $10.  And because I was curious to do this, although I wasn't worried about this recent Anthem breach, I locked my credit reports.  It was $10 for each of them.



LEO:  You may have to pay to thaw it, as well, and this is important.



STEVE:  Yes, that is correct.  It is not an annual fee.  It is a one-time lock.  But you do also - and it's annoying.  First of all, it's annoying that this costs anything because they're making money from being a credit aggregator.  We're not making any money from the fact that they have these reports.  And of course the danger is that somebody could - and in fact, from the Anthem breach, all the information is required to apply for credit in somebody else's name.  And so the idea is that somebody would impersonate you, apply for credit in your name, then the credit-granting institution would pull your credit report to see if your credit is good; and, if so, grant this person credit in your name.  They would then run up a big balance, whatever they were able to, take the money and run.  And then you're stuck holding the bill, potentially, because they've been able to impersonate you.



By freezing your credit reports, you are preventing that credit-granting agency from obtaining your credit report.  It's locked.  And so that's a double-edged sword, of course.  It means, first of all, you prevent new credit from being acquired or granted in your name.  At the same time, you prevent that, and maybe it's what you want.  So, for example, in my case, I haven't applied for credit in decades.  So I was more than happy to lock my credit report across all three agencies.  And if at some point in the future I need to get credit or have someone look at my credit, then I can pay $10 each for one or more of these companies to either temporarily - you're able to, per query, allow a query to be made or to remove the lock.  And when you apply the lock, you are given a long PIN that they generate which you must keep because that now becomes your out-of-band means of thawing this freeze on your credit.



Anyway, I wanted - I understand that there are people for whom freezing is not practical because they're busy in their lives.  They're getting more credit cards or buying homes or cars or whatever, all of which this would be a problem for.  But if you're at a point where you don't mind blocking the world from seeing your credit report, and I just did that, I think this is a great option for people who are concerned about identity theft.  So bit.ly/freezecredit will take you to a page that explains this and contains links, which is what I followed, to all three of the major bureaus.  So I'm glad to know that service is available.  I wasn't aware of it before.



LEO:  Yeah, I mean, I think this is probably something new.  You used to be able to do this kind of thing, lock your credit report.  But they didn't make any money on it, and they still pretty much discouraged it and changed the laws and - these companies, these three companies, have huge legislative clout because they make a lot of money.  And I agree, this should be free.  But they don't do it for free because they're replacing the revenue that they get from giving your information to companies with revenue from you.



STEVE:  Exactly, from you saying yes and no.



LEO:  Right.



STEVE:  Yup.  Yeah, and I...



LEO:  But it's a good link.  Save it because it does explain how to do it for each of the three credit unions, and each is different.



STEVE:  Correct.



LEO:  Credit reporting, not credit unions, credit reporting systems.



STEVE:  Yeah, and in fact one of them, which one...



LEO:  I think it's TransUnion.



STEVE:  I saw it here a second ago.



LEO:  You have to call them.  Oh, no, that's not it.



STEVE:  No, I was able to do it online.  Oh, but it was TransUnion that made me create an account, which was so annoying.



LEO:  Right.



STEVE:  The other two don't.  You have to prove your identity by knowing - but unfortunately you're proving your identity knowing everything that Anthem just released about you.



LEO:  Well, but remember, at TransUnion, Equifax, they know it anyway.  You're not giving them information they don't know.  That's how they can ask you that question.



STEVE:  Correct.  Yeah, but my point was that anyone who got the data from Anthem also could, for example...



LEO:  Oh, could do the same thing, yeah, yeah, yeah, yeah.



STEVE:  ...could do the same thing.  So, and then you receive this long PIN, and you need to hold onto that.  But it was - I didn't have to talk to anybody.  I did it online.  They did take $10, each of them, from my credit card that I provided them.  And now my three - my credit report is locked for all three of them.  And I'm glad.  So, and I know our listeners, I'll bet this appeals to a bunch of them.  So I wanted everyone to know because I didn't know about that before.



LEO:  Mm-hmm, mm-hmm.



STEVE:  I just finished the second book in the Expanse series, "Caliban's War."  And if anything, it was even better than the first one.  So I'm at the point now where I can at least recommend the first two.  Mark Thompson, who's read them all, tells me that number three is at least as good as the first two.  I haven't started yet on number three.  But it really is fun.  So I just wanted to commend it to everybody.



Also, there's now a trailer for the Expanse series coming to Syfy on the Syfy.com, S-Y-F-Y dotcom site, called "The Expanse."  And it looks like it may be pretty good.  I'll tease people just a little bit.  And this is not a spoiler.  I hate spoilers, so I wouldn't ever do one.  But you learn this right off the bat, so this is not spoiling anything, and that is that another, an alien intelligence intended to essentially cultivate the Earth with its own organism, and so some billions of years ago launched a biological package at the third planet from the Sun, except that just by chance it got captured by one of the outer planets and became an ice moon.  And it sat there for billions of years while life evolved on the Earth, and then we colonized the solar system.  And it got discovered.  So I won't say anything more about what happens, but it is a lot of fun.



And then the other thing that this book spends time on, which is I think just intellectually interesting, is that, as the solar system is colonized, we colonize Mars and then the so-called "Belt" further out - and "Belters" is a common topic in sci-fi, you know, who are like mining for minerals and ice and so forth in order to supply the required raw materials for a solar system-wide civilization.  As is sort of going to happen, the needs of the various groups of Earthers and Martians and Belters differ, and that creates political divides, and they sort of drift apart over time.  So anyway, it's just good science fiction.  And I do want to add it to my list of recommendations.  I like it.  And we're going to get, you know, it's going to be a TV series on Syfy.  As people know, I wanted to read it first, and I'm in the process of doing that.



I wanted just to mention actually sort of a follow-up from a testimonial from an Igor Koveshnikov in New Jersey.  I didn't mention this last time when he shared his story.  Remember that he, we talked about him only a few weeks ago, he had installed an SSD in his boss's laptop that went bad, and he was really curious to find out that it went bad.  The good news was that SpinRite fixed it.



But he said:  "Related to my testimonial, as far as I understand, SSD completely hides its internal structure behind wear leveling and optimization in firmware and represents the drive externally as a standard mechanical drive.  When SpinRite runs on Level 2 and higher, it reads a sector and then writes it, supposedly to the same sector.  But SSD is using wear leveling and writes data to whatever its algorithm decides are the most appropriate cells in memory and may not be the same as where the data was read from.



"Is there any way to get closer to the hardware of SSD" - oh, and he says and SSHD, meaning a hybrid - "or will it always be a black box?  Will it be addressed in the new version of SpinRite?  Right now, according to my own and many other users' experiences, we know that SpinRite repairs SSDs just as it does hard drives.  But I think we can only speculate on how.  If you ever come across more info on internal mechanics of SSDs, please share it with us, preferably on Security Now!."  Then he said, "Shout out to my wife.  She's a software security specialist and listens to every episode of Security Now!."



So anyway, just to quickly answer Igor's question, as we know, it is the case that wear leveling will cause the sector which SpinRite may have recovered to be written somewhere else.  But we really don't care.  In fact, that's almost - it's almost exactly what happens with hard drives that have spare sectors, when the sector goes bad to the point that it can no longer be safely corrected.  And as we know, modern hard drives allow a lot of correction before they get scared about how much correction they're having to apply and then decide they need to relocate that to somewhere else.  If it happens that a sector is written to a different location, it's the recovered data after SpinRite has recovered the data from the bad spot that the drive, the SSD, may itself choose not to use.  But even if it thinks that the sector is still fine and rewrites it somewhere else, the wear leveling mapping logic will know where it went so that, when that same numbered sector is read again, it reads from the right place.  So the badness will sort of have been opportunistically mapped out, even if it wasn't deliberately mapped out.



So again, wear leveling helps us.  And the SSD is preserving itself by making sure in general that we're writing the same amount across all of the SSD's physical surface, even if we're actually tending to write specifically numbered sectors much more often than we are others, which as we know is the typical pattern of hard drive use.  So SpinRite does its job, and the SSD does its, and it all works out for the best.



LEO:  It's so easy.



STEVE:  Yeah.  Nothing to it.



LEO:  Nothing to it.



STEVE:  Nothing.



LEO:  All right.  Back we go to the subject at hand, in this case HTTP/2.  SPDY, S-P-D-Y, was also from Google; right?  But they're abandoning it now.



STEVE:  So, yes.  I wanted, for the sake of "fair and balanced," to say that I thought it was interesting that Microsoft on their pages is taking credit for HTTP/2 and somehow manages never to mention Google once.



LEO:  Did Microsoft have anything to do with it at all?



STEVE:  Nothing whatsoever.



LEO:  Oh, dear.



STEVE:  Nothing whatsoever, no.  They are the absolute beneficiary of what I think is Google operating in the best of all possible ways.  We know that I'm annoyed with Google when they throw their weight around, as we were talking about earlier, with arbitrary deadlines on the speed at which they would like to see the industry moving forward on various things.



But Google is at their best when they are spinning off groups to experiment with new protocols.  And nowhere ever have we seen a better example of that than with what started off as a research project, SPDY, which was not an acronym or an abbreviation, it just meant "faster," to examine what could be done to improve HTTP.  We've been with HTTP/1.1, which is essentially HTTP/1.  There were a few changes that were made.  For example, technically with 1.1 you could do something called "pipelining," that is, you could send other queries down the connection, even though you hadn't yet received the results from the first query.  But there were problems with making that happen.



LEO:  [Sneezes] Excuse me.



STEVE:  Of course.  There were problems with making that happen, and it never ended up being practical.  And it turned out that it wasn't of much benefit.  So for 15 years we've been living with the same thing.  So what's wrong with what we have now?  I'll talk about that, HTTP/1.  Then we'll do another break for a commercial so I can rest my voice, and then I'm going to tell you about HTTP/2.



So HTTP/1 is what we've had.  It's what today virtually everybody is using.  The problem is that, in the last 15 years, web pages have gone crazy.  They've gone from a page of text that maybe had a few pictures to ridiculous, asset-heavy, graphics-heavy, script-heavy, where all kinds of stuff, the page's text, its layout, all kinds of ads and images, scripting coming from libraries being sourced from all over the place, are all being sucked in and pulled together to display one amazingly complex multimedia page event, essentially.



So the way this happens is the browser requests sort of the raw content, the description of what the page will have, essentially in a resource from the server that hosts the page in HTML.  Then the browser looks through all of the other assets that the page wants to have - links to advertisers, links to the JavaScript that it needs to run, links to Flash objects, so links to plugins that it may need to load, I mean, just everything.  And today's pages are just packed with all this stuff.  So then the browser needs to turn around and start asking this array of other websites - lots of stuff no doubt from the same website, but also lots of other ones.  It needs to ask all of them to start supplying all these things so that it can assemble the page.



So the problem is that the HTTP protocol is the only thing we have, the HTTP/1, for doing that.  So the browser opens up, because it's now in a huge hurry, because pages have gone crazy, and because HTTP can effectively only be used for one thing at a time, that is, the protocol is a request for something, and then that something is returned, and then often the connection is dropped.  Now, one of the things that we did get that is used in HTTP/1.1, thank goodness, is something called "keep-alive," where at least we don't need to create another TCP connection.  We can make another HTTP request, a query, over the same TCP connection.  So that's good.  Otherwise we'd be in big trouble.  But even so, it's ask for and then receive; ask for the next thing and then receive; ask for the next thing, then receive.



So it was originally the case that there was a two-connection-per-server constraint placed on browsers, just by convention.  The industry said it's impolite to open more than two connections from a browser back to a single web server because that would just overload it.  It would be too many connections. Well, servers got faster, so that that wasn't such a problem for them.  And it was just a matter of demand, really.  Pages got so complex that web browsers began cheating.  They said, well, you know, Firefox wants to look faster, so we're going to allow six connections to a server.  And then Microsoft said, wait a minute, we're going to go for eight to make our pages load faster.  So it was clear that the notion of trying to ask browsers to behave themselves and not open lots of connections back to the same server, that just wasn't going very well.



So there were several problems with that.  The benefit was that now you had parallel pipes back to the server.  And so that was good because now you could, for example, be receiving at least six things at once, rather than having - and they could be done in parallel rather than needing to individually wait for each one to come back over a single connection.  The problem is that opening a TCP connection is not fast.  That is, TCP - and we've discussed the way TCP operates in detail in the past.  TCP has a problem, and this is just inherent to a packet-switching network like the Internet.  That is to say, how fast should we go?



We know that if we go slower than we know we can, then we're not utilizing the available bandwidth.  But if we go faster than we can at the chokepoint that may exist somewhere between the client and the server, if we go too fast, then buffers will overfill in routers, and packets will start getting dropped, and that's bad because there's a delay in us finding out that packets have been dropped because we only know they've been dropped when they're not acknowledged by the receiver in TCP.  So TCP adopts sort of a careful exploring the bandwidth, where it slowly - it's called "slow-start," where it slowly begins sending more and more packets and waiting until it senses that it's beginning - that some are being lost, and then it backs off a little bit.  And then it starts creeping forward again until it has a problem, then it backs off.



The point is that, if we open lots of connections, they all have to independently, individually go through the same TCP slow-start process in order to sense the bandwidth between the two points.  And so that's not optimal.  And if we're connecting to a secure server, every one of those TCP connections, after establishing TCP, has to then establish the TLS connection, go through the whole security handshake rigmarole in order to establish security.  And only once that's done can they begin doing their one-request-at-a-time, HTTP/1-style requests.



So it's been a big mess.  There's been pressure to move more things at once because pages have become huge.  Browsers have to manage all of this at their end, and that's becoming a big problem.  There is sort of this fight between how many connections, how many parallel TCP connections in order to then do TLS, and that puts a security burden on the server for handling all the crypto, and then all of these HTTP connections to the browser.  So that's the world that we've been living in.  And Google decided we must be able to do something better.



One of the other problems with HTTP, and we've talked about the HTTP protocol, there are request headers that we never see.  The user doesn't see them, but they're things that specify, for example, the user agent, the name and model number of the browser that is making the request.  And if the browser has a cache, that is, it may have a copy of some of these things, so it's able to say "I want this, but only send it to me if it's newer than the one I have in my cache.  And let me know, in which case I'll know that I still have the current thing."  So there's a whole bunch of other stuff going on behind the scenes.



And of course we know about cookies, too.  Browsers often have lots of big, long cookies which are relatively static for a given server.  But every single request the browser makes sends these cookies back to the server as part of the request to say this is the state that I currently have with the server, if that changes the server's behavior relative to the browser.  So there's a huge amount of redundancy in what the browser is sending to the server, and no effective way to remove it.



So that's the problem that we've been living with for 15 years.  It's been getting worse and worse because pages have just gone crazy.  They've exploded with complexity.  And it's been time to come up with a replacement, an improvement.  And to their unending credit, Google has done it, and they have done a beautiful job.  We're going to talk about that next.



LEO:  Oh, how exciting.  It's not "S," is it.  Can it not be "S"?



STEVE:  It's a very good point.  I was going to bring that up, but that's a perfect segue.  The definition for HTTP/2 does allow it to operate non-securely, that is, without a TLS tunnel.  Although it's in the spec, nobody currently does that.  So it's going to be very interesting to see whether servers that offer full HTTP/2, when they finally make the migration from SPDY - right now everybody technically is still running SPDY.  For example, the draft that I read last night in order to bring myself completely up to the minute on what /2 is doing was Draft 17, which is the latest one.  And it is dated February 11, 2015, meaning six days ago.



LEO:  Wow.  Wow.



STEVE:  Yeah.  So they're at the point of crossing their T's and dotting their I's.  So it's not like there are any big changes remaining.  And there is already support for HTTP/2 among, I think, I know that there's an Apache mod.  Nginx supports it.  Microsoft has announced, even though they don't talk about where it came from, they do announce that somehow it will be appearing in Windows 10 Server.  And it is right now in the Windows 10 preview is HTTP/2 per the current spec.  And all the browsers support it.  As we mentioned last week, Chrome will be dropping support for SPDY next year.  There'll be like a year overlap.



And I think it was with Chrome 40 we talked about last week, Chrome will be formally supporting HTTP/2, which of anyone in the world, the Chromium people have the smallest changes to make in their browser because they already had SPDY.  Of course, Firefox supports it.  Safari supports it.  It's essentially ready.  So I think we're going to see it happen soon.  The reason is it really works.  This is not, you know, one of the things we've talked about is why is it that so many better things take so long to get adopted or never really get off the ground.  It's because there is adoption inertia.  If you've got something that is, well, this works well enough, then there's just no impetus to change.  It's the reason, for example, that I have believed that SQRL has a chance, because usernames and passwords just don't work well enough.  I mean, they're really broken.  But if something's not really broken, it's like, eh,  you know.



And as it is it took 15 years to fix HTTP/1.  And while you couldn't really say it's really broken, look what I've just described as what the industry has had to go through in order to keep ahead of the fact that the protocol really was no longer up to the game that it was being asked to play.  So SPDY, which is for all intents and purposes HTTP/2, is what you get when an independent team who really understands the way the Internet and the web work can say we're going to not do 1.2, but we're going to do 2.0.  And by the way, it's not .0, it's just /2.  And that was the case deliberately.  They didn't want to create some notion of subversions and things.



This is a complete break from what we have had.  There is no backward compatibility between 2 and 1.1 or anything before it.  Zero.  This is we're going to start over and do it right, do it well.  And you could argue /1 was right for the times; /2 is right for today.  So the first thing that they do is one connection, period.  Now, at first you think, wait a minute, wouldn't two be faster?  And if you stop and think about it for a second, no, because 2 is going to have to move over the same bandwidth.  If you've got two connections to something remote, they're still going to have to come over the same channel.  So why not run one connection twice as fast than two connections half as fast?  So one connection.



And the other reasons we want only one connection is, as I was saying, all the other problems associated with multiple parallel connections.  TCP, you don't want to have to ramp it up and have six or them or even two of them independently figuring out how fast they can go because they're both going too slowly.  Instead, have one connection and have it figure out how fast it can go, and it'll be going as fast as it can.  So that makes more sense, one TLS security negotiation, one, rather than even two, just one.



And the other thing is that, if you think about it, the existing HTTP protocol is a hierarchy of standards.  And as we know, the whole layered networking model, we'll skip some of the lower layers because the ones we're concerned with are you first make a TCP connection, then maybe you bring up a secure tunnel on top of the TCP connection, and then inside that tunnel you put HTTP requests.  The problem is that we still have to make a TCP connection.  We still have to bring up a secure tunnel.  But what if there was some way of signaling that what we were going to be doing with the secure tunnel was HTTP/2?



And again, the Google guys did not miss a trick.  They've added a pseudo cipher suite to the TLS v1.2 spec, which is the one we're at now that has wide adoption.  Even GRC supports it, so you know it's been around for a while.  The pseudo cipher suite is a clue to tell the server, during the security negotiation, we're going to be doing HTTP/2 over this connection.  So they short-circuit another round of sort of protocol negotiation delay, and the server then is able in that negotiation to acknowledge it's able to do HTTP/2, let's go.



And because this is a fundamentally asynchronous protocol, and I'll explain what that means a little bit later, but the server has something called "speculative push," which is sort of the equivalent of speculative processing.  The very latest CPUs, when they're executing instructions and come to a branch, if they're so far ahead by doing what they can of, for example, of the instructions being finished which will determine which branch to take, these CPUs take both branches.  It's not the road less traveled.  It's, well, just travel both roads.  And so that's called "speculative execution."  The chip will take both branches, start executing instructions down both.  And then, once the results from a previous instruction are known, it discards the branch that turned out not to be taken in that case.  So this is a little bit different.  This is speculative push, where nothing prevents a server from sending ahead some things that, for whatever reason, it knows the browser is ultimately going to get around to asking for.  So this is just really cool.



So we have one connection, ever.  There's no reason, no benefit conceivable beyond that.  And so we only have one connection between the client and the server.  And we short-circuit the argument or the questioning about whether each end supports HTTP/2 by tucking that information into hints in the security negotiation.  So that's all resolved immediately.



The next thing we do is agree that we're going to divide this single connection into frames.  So frames is an abstraction that HTTP/2 lays on top of its single connection.  And what that does is it allows it to support simultaneous multiple streams.  You have a 9-byte frame header.  Now, remember, this is distinct from packets.  TCP, the underlying communications protocol, that's chopping things into packets in order to move them around.  And TCP guarantees that lost packets will get replaced, and that out-of-order packets will get reorganized in the proper flow by the time they need to get used.  So what HTTP/2 can rely on is that its communications is just seen as a single stream, that is, what it sends, what either end sends comes out of the other end eventually in the same and proper order.



So what it does is it divides the TCP stream into arbitrary length frames, so frames on top of the TCP stream.  And there's a header that is 9 bytes on the top of the frame.  So there's a little bit of a per-frame overhead of 9 bytes, meaning that you wouldn't want to have lots of itty-bitty frames because then the payload of the frame starts getting large relative to the per-frame header.  On the other hand, you don't want to have really monstrous frames; otherwise, whatever is in that frame is dominating the stream.  So the point is you get a benefit from chopping what would normally be a single-stream connection into multiple virtual connections using this frame abstraction.



So you have this 9-byte header.  The first 24 bits of it, so 3 bytes, is the frame's length, the frame's payload length, meaning except for the header - you ignore the header - the length of the payload that the frame is carrying.  And you only ever use 14 of those 24 bits without permission from the other end to use more.  So they've given themselves plenty of growing space.  Up to 16MB is 24 bits.  But normally they only use 16K bytes, which is 14 bits, as a maximum size of a frame.  And most frames are probably going to be a lot smaller than that.



Then there's an 8-bit, that is, 1-byte frame type, so that gives you up to 256 possible frame types, of which right now they use only a handful.  Then you've got a 1-byte set of flags which are frame type specific.  So different frame types may or may not need some flag bits; and, if so, this gives them to them.  And then, finally, a 32-bit stream ID, that is to say, what of many streams is this frame the next one of?  And for whatever reason, the high bit of that is always zero, must be zero when being sent and must be ignored when received.  So technically it's a 31-bit stream ID in a 32-bit space.  So that's the 9 bytes.



But basically that means we've got frames that can range from very small to up to 16K, unless we receive permission from the other end to use even bigger frames.  And then basically a frame type, some flags for that frame if it needs them.  But then the cool thing is a 32-bit stream ID.  So the 32-bit stream ID, and that's 4GB of possible stream, so that's just, you know, it's big because, not that we need that many, but we don't want to run out of them.  What that says is that, as I said, this frame is the next one of that stream.  And the simultaneous multiple streams allows essentially a multiplex conversation between the two endpoints.  That is, it allows requests - it allows, for example, the browser to just, at its whim, to arbitrarily create new streams by successively numbering stream IDs and to stick requests for web resources, scripts and assets and so forth, from that same server.



That is, remember, one connection is between one client and one remote server.  You might have other SPDY, or I should say HTTP/2 connections, one each, to other servers that are also contributing content to this page, but only one to that one server.  So the browser just sits there emitting queries for assets, giving them successively numbered stream IDs, over the same connection.  Those all then begin arriving at the server.  It starts finding them and sending the response over an otherwise similar HTTP protocol back to the server.



Now, that's worth mentioning.  The actual content of these streams is HTTP protocol, that is, the familiar one, the text-based protocol with request headers and so forth.  So the nice thing is that we haven't redefined the HTTP protocol on the wire, that goes into the wire.  What we've done is we've sort of created - you can think of it as a shim.  That is, you could have something on the other side that is still just generating standard traditional HTTP queries.  Once upon a time, that would have had to wait for essentially available connection space or a free connection in order to put the query on the wire.  Now that standard HTTP query, thanks to HTTP/2, which manages how we handle wires, it's able to send them all out as fast as it's able to generate them, give them individual stream IDs and shoot them out there.  But my point was the format of the query data, the query itself, that stayed the same.



Now, the server, then, is sending all this stuff back.  The other thing that the client can do is give streams priorities and interdependencies.  It's able to say, I want this stream at high priority.  For example, the main, the base page's main HTML, which the browser needs to have back immediately in order to have all the other URLs that it needs to request, it's going to say, get that back to me absolute top priority.  Don't slow that down on behalf of other assets that I may also be asking for or may start asking for even before I've got the whole main base page back.  So it's able to say that all the other assets are dependent upon this first stream, or it's able to say they're lower priority.  So there's a sort of an interlocking semantics that allows priorities and dependencies to be resolved by whichever end is doing the sending.



Now, so what we've got is one connection, optimized for speed.  It comes up, we get going immediately, and the client is able to start sending requests down, packetizing them in individual frames, giving them unique streams.  They come out at the server end.  The server starts, it looks at the dependencies and the priorities, and that allows it, as it's accumulating this increasing block of stuff it wants to send back, it allows it to send them back with the priority and dependency that the client has requested and, essentially, for there never to be a dull moment.



Notice that it's accumulating a big blob of stuff, and it's going to be squirting it through the connection as fast as it can, given the constraints that the client has put upon it.  So it's going to keep this one connection absolutely maximally busy.  There will not be pauses in between assets being requested and sent back.  So we get absolute much better utilization of that one connection even than if we had six connections or more as we at one point would have because each one of those six would have still been an ask and get, ask and get, ask and get.  And the server would have been sitting here, like essentially waiting for the things it sent to get there so that it could receive another request over one of those connections for the next thing that the client knew that it wanted.  So this completely transforms the nature of the way data is able to move from the server to the client.



Now, the other cool thing that I just - I didn't ever pay attention to this before, but I had to in order to understand how header compression was being done because, as I mentioned, there's a huge amount of redundancy in the way headers are handled.  The client is almost always emitting the same header contents.  And that's hugely redundant when you're asking for a whole bunch of things from the same server.  They're coming from the same user agent.  They're going to be carrying the same cookies.  It's going to be the same time of day.  There's all these things that are not changing.  Yet, as I said, the HTTP textual protocol is still carried unmodified, which is very clever.



Okay.  To understand header compression, we need to know a little bit about the way compression works.  That is, these two geniuses, Lempel and Ziv, and that's where the initials "LZ" came from, back in the '70s, I think it was '77, acquired a patent on a concept they had which became named Lempel-Ziv compression, LZ compression.  And that's where ZIP came from, the Z in ZIP and GZIP and LZW and LZA and so forth.  All of these are descendents of this original concept.  And the concept is as follows:  You are sending something to the other side that the other size knows nothing about, has no knowledge of it.  And in fact you don't either.  This is called "stream compression" because the idea is that you are receiving bytes in a stream, knowing nothing about it in advance.



So what you do is, as you receive bytes of data, if you can do nothing more, and I'll explain what that means in a second, you just send the byte on.  But you also keep a buffer of the most recent X number of bytes you have sent.  That is, you send them on, and you put them into a buffer that you maintain of what you've just sent.  And as you receive them, you look upstream a little bit to see what's coming, and you look for matching patterns in what you've already sent.



And the genius of what these guys came up with was the idea that, if you were getting ready to send something that you had not that long ago sent, even a piece, even three or four characters, or five or six, you could instead send a reference to that string that you have in your buffer to the other side.  The other side is doing the same thing you're doing.  As it's receiving characters from you, it's maintaining a buffer.  Separate from storing these characters in the destination file, it's maintaining a buffer.



And it turns out, and this was the cool part, these two buffers are synchronized.  You're maintaining a buffer of what you've sent.  It's maintaining a buffer of what it's received, which is what you've sent.  So when you send it a reference to the buffer, to a substring that appears in your buffer, that's a reference to the same substring in its buffer.  The point is you've only had to send a reference, not the actual substring.  You've got compression.  So that's the way compression works.  All of this LZ compression is based on that, the idea of synchronized buffers which both ends are able to maintain, never having to actually share the buffer, but evolving it on the fly.



So that set of buffers is known as the "compression context."  That is, it's the context that each end maintains, one while compressing the other to decompress what the other has compressed in a communications channel.  And the same thing happens if you, like, store a file on a hard drive and so forth.  If all of these connections were being made separately, and if you even had GZIP, for example, dynamically doing communication stream compression on the connections, they would all have separate contexts.



The genius of what the Google guys did is to use one compression context per connection - not per stream, per connection.  And what that means is you instantly get cross-query compression.  That is, an HTTP query goes out in the first stream and is compressed.  It won't compress much because we haven't seen those request headers before.  But the second query goes from the same browser to the same server with the same cookies, the same user agent, all the same redundant headers, it goes out over the same connection, using the same compression context as the connections, which is the same compression context that just got through compressing the headers for the first stream.  And all it is, is pointers into that context.  It gets the most perfect compression you could get for free.  And the same thing happens at the other end.



So the beauty is you're not redefining the HTTP textual protocol, where it's got headers and cookies and user agents and all that.  All that stays.  But the beauty is, essentially, you send it once, and then all you're ever sending again is very short pointers into the compression context that was established by the first query that went.  You could still change things if you wanted.  You'll get slightly less compression.  But you'll be getting as much compression as you possibly could because you have one compression context for all the simultaneous multiplexed streams.  And just because I didn't say it yet, to make sure it's clear, when the server is sending a whole bunch of things back, it's able to interleave these if it wants to.  It's able to send chunks of different stuff, each with their own stream ID.  They are received at the other end, and they're demultiplexed back into the original assets that requested by stream ID, and the client knows what to ask for.



So that is it.  That is HTTP/2.  It's worth noting also a couple things.  First of all, that the speculative push is fun because it means that the server can anticipate what the client might ask for.  Right now, in HTTP/1, it's not possible.  First of all, there's no way for the server to send anything that hasn't been requested.  But notice that that's always been something lacking.  That is, the server is sending a page whose contents it has.  It has to wait for it to go to the other end for the client to get it, then for the client to read it, and the client to request the things that the server already knew was on the page that it was sending to the client.  So the server really does have more early knowledge of what's on the page than the client has.



Now, caching in the client prevents it from having to ask for things a lot more.  So the server just wouldn't want to send everything on the page because the client may very well have a lot of that stuff already cached and know that it hasn't expired or just ask if it is expired, depending upon how long that object said it would be good for.  So you don't want to overuse speculative push.  But, for example, if there was a period of time where the connection wasn't in use, and the server believed it knew other things that the client might want, it could use that time in order to send them.



It's worth mentioning that, while we've got this great protocol, this does put a substantial obligation on the client and the server to make maximum use of it.  That is, yes, now we can ask for things all at once.  We can, like, try to figure out what the optimal priority and interdependence is, but that's not for free.  That requires a kind of logic that clients and servers haven't needed to have built into them yet.  So it may well be that what we're going to see over time is an improvement in the performance of HTTP/2 as each end gets better and more clever at using to its maximum capacity and capability the features, the rich feature set that HTTP/2 for the first time ever makes available to each end.  And that's what it is.  And full credit to Google for this.  This is a beautiful piece of work.



LEO:  I suspect that a lot of this is in response to the capabilities of modern servers, in particular servers running Node and other Ajaxy solutions, where they really would love to be able to do this.  You know, Google basically created AJAX 10 years ago with Google Maps and Gmail, the idea that stuff would load in the background so that when you slid a map around, those tiles would already be there.  And but of course modern server technology of the time didn't really support it very well.  And I think a lot of this is really in response to what servers can do and what sites using AJAX technologies have wanted to do.  And now it's in the server; right?  In the client, yeah.



STEVE:  That's certainly part of it.  Mostly, it's just this connection burden.  Now we have...



LEO:  Yeah, eliminating that, yeah.



STEVE:  Yeah, we can multiplex now much more data over a single connection.  And we already saw, remember that httpvshttps website where, side by side, you run SPDY with encryption compared to HTTP without.  And is it any surprise, now that we know what this does, is it any surprise...



LEO:  It's a lot faster.



STEVE:  This just blows its socks off.



LEO:  Yeah, yeah, yeah.



STEVE:  Yeah.



LEO:  That was a fun thing.  We did that a couple of weeks ago, yeah.



STEVE:  Yup.



LEO:  Steve Gibson does it again, ladies and gentlemen.  I hope you've been listening.  Yeah, I hope you learned something.  We do Security Now! every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That would be 2100 UTC.  You are certainly invited to listen live.  I think it's a lot of fun to listen live, especially if you're in the chatroom and you can chat along behind the scenes and help each other...



STEVE:  Interact.



LEO:  ...understand what's going on.  But if you can't, hey, don't worry, we've got on-demand versions available for you.  Steve hosts a 16Kb audio file, MP3 file that's pretty light, pretty small, for the bandwidth-impaired.  He also has transcripts, which are excellent if you like to read along.  Or if you want to search, that's the real value of it.  You can search the topic and find the part you want.  All of that's at GRC.com.  That's where you should go if you have questions because I think, technology news permitting, we're going to have a question-and-answer session next week.



STEVE:  Q&A is on the schedule for next week.



LEO:  So the best way to ask questions, don't email Steve:  GRC.com/feedback for the feedback form.  Or if you can do it in 140 characters, tweet @SGgrc.  He follows the Twitter.  You can also, when you get there, get SpinRite, the world's best hard drive maintenance and recovery utility.  You can also get a lot of other freebies, those things Steve gives away, they're awfully good:  GRC.com.  Our website for this show is TWiT.tv/sn for Security Now!.  That's where we put the high-quality audio and the video files of the show.  Show notes, too, other things, and all of the other shows we do on the TWiT Network.  You can also go to YouTube.com/securitynow.  We have a copy there suitable for sharing with others.  And of course wherever you get your podcasts because we're on everywhere.  Being as we've done nearly 500 episodes.  By now they've figured out we exist.  Don't forget to vote for Steve at the Podcast Awards.  You didn't mention it.



STEVE:  Oh, I didn't.  Thank you, Leo.



LEO:  PodcastAwards.com?  Is that right?



STEVE:  Yup.



LEO:  Did you get nominated?  We don't know yet.



STEVE:  Don't know.



LEO:  Okay.  So right now you're voting to get him nominated.  And then I'll expect you to vote to make him the winner.



STEVE:  Please, I would love that.  It would be fun.



LEO:  Steve cares about these things, so we want to support him.



STEVE:  I do.  Make me happy.



LEO:  Make him happy.  He deserves to be happy.  We'll see you next Tuesday.  Thank you, Steve.



STEVE:  Thanks, Leo.  Talk to you then.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#496

DATE:		February 24, 2015

TITLE:		Listener Feedback #207

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-496.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Oh, yes, of course we're going to talk about Superfish and Komodia and what it really means.  And of course nobody better to do that than Steve Gibson.  Then 10 of your questions; 10 of his answers.  A great Security Now! is coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 496, recorded Tuesday, February 24th, 2015:  Your questions, Steve's answers, #207.



It's time for Security Now!, the show where we cover your security and privacy online with the guy who knows more than anybody else out there and is a great Explainer in Chief, Mr. Steven Gibson of the Gibson Research Corporation.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again, as always.  And we have such a great show that I considered dropping the Q&A to next week, except that next week we may even top this one.  As I mentioned a couple weeks ago, "60 Minutes" did a segment which was really unnerving, where they had a group on, talking about in this instance car hacking, who disabled the brakes on an unlabeled vehicle.  It had a manufacturing label on it, but they, like, blacked it all out with tape because they didn't want to embarrass the maker of this car.



LEO:  Although, as you pointed out, if you knew anything about cars, you probably could figure it out; right?  Yeah.



STEVE:  Yeah, I'm sure it's, like, everybody except me knew what that was.  All of the hybrids sort of look the same.  They've got this weird sort of hybrid look to them.  And so this was, I think, one of those.  And they told Lesley Stahl, who was doing a segment on "60 Minutes," to stop in front of the orange cones.  And so she puts her foot on the brake and runs right through the cones.



LEO:  Yeah.



STEVE:  Anyway, it turns out that this group that were, I guess they were a subcontractor or hired by DARPA to do the research, are fans of the podcast.  We're going to have them on next week to talk about...



LEO:  What?



STEVE:  Yeah, to talk about...



LEO:  Cool.



STEVE:  ...carjacking.  And actually they wanted to broaden it a little bit.  They're also big fans of and [clearing throat] I guess have done some work on drone hijacking.



LEO:  Oh.



STEVE:  So we're going to talk about vehicle hijacking, vehicle hacking.  And because they're - it's funny because when we were talking, going back and forth in email, the guy said, well, one of the main techies managed to get one line into the "60 Minutes" program.  You know, it's like, yeah, that's a problem.  And I said, oh, yeah, I said, you know, we've all done interviews where they interview us for half an hour and then almost all of it winds up, as they say, on the cutting room floor.



So but for this podcast, because we're techies, we're going to get the whole scoop on, like, what they actually had to do to take over the cars, and what the state of that is.  One of these guys is ex-NASA and knows all about what it takes to do formal proving of security because they had to do formal proofs of, like, space shuttle software correctness in order to get, you know, not to have, like, oh, wait, we need a patch for this?  No, we can't have any patches on this space shuttle software.  So a great podcast next week, and everyone's going to want to catch it.



But this week, of course, we had not only our regularly scheduled Q&A #207, but major, like, everybody was buzzing.  In fact, Twitter was really unusable for me for a day while everyone who follows me wanted to make sure that I knew about what I'm calling Lenovo's big mistake because I think that's probably the best way to characterize it.  And then we have another stunner from Edward Snowden.  We've got TrueCrypt back in the news in a good way; the fact that the HSTS support is gaining its final major adherent; some tidbits and follow-ups; and then, of course, 10 questions from our listeners.  So not a dull second, I think, this week.



LEO:  Yeah.  You've got people glued to their sets.  Do you use a set?



STEVE:  It's funny because I asked my sister years ago, when my niece and nephew were in high school, I said, "What channels do they watch?"  And she says, "Oh, they don't watch TV."



LEO:  No.



STEVE:  "They watch their laptops."



LEO:  Yeah.



STEVE:  They cut the cord, like, long ago.  So you need to turn the volume up on your laptop.



LEO:  Okay.



STEVE:  And play this YouTube link which is the first thing on the show notes here under "Komodia."



LEO:  Oh, lord, lord, lord.



STEVE:  It's only about a minute.  It's about a minute and a half.



LEO:  Okay.



STEVE:  But it is just a hoot.



LEO:  All right.  YouTube.com, let's look.



[Clip]



MALE VOICE:  So you want to develop a network interception application like parental controls or anonymizers.  Maybe you want to do it yourself, or you've already got a working proof-of-concept on a virtual machine supporting one or two browsers.  Now the fun begins.  You've got to ensure you're supporting all the current OSes and the 64-bit flavors.  What about the five leading browsers?  And you'll want minimal conflict with the top 40 antivirus products.  Could be you want to support HTTP decoding and SSL decrypting.  And that's going to get really complex.  You could skip doing all this QA, but do you really want your clients doing the QA for you?  Twelve to 18 months go by, and finally you can get to work on your core application.



You know, there is an easier way.  Introducing Komodia's Redirector [Leo yells], the network interception SDK that allows you to develop your solution instantly.  It's used by more than 100 clients, including some Fortune 500 companies, to develop parental control software, anonymizers, game acceleration, and other custom solutions.  By using Redirector, you can focus on your core application without getting into technologies like LSP or WFP.  With a simple-to-control interface, you can intercept website traffic and network applications [Leo:  Oh, my god] from any programming language.



So where do you want to be in the next year and a half?  Slaving away with the QA, or launching your product?  Make the right choice.  [Leo:  Oh, my god]  Komodia's Redirector.  [Leo:  Oh, this is...]  Get your free 14-day trial now.



[END CLIP]



LEO:  Oh, this is not a joke.  That's an ad for Komodia.



STEVE:  It is a professionally produced, high-quality ad, basically saying we're producing an SDK which will keep you from having to roll your own.  And what happened was that, among many other companies, if we believe them a hundred others, a company called Superfish said, well, we can barely get out of bed in the morning, so we're going to use the 14-day free trial that Komodia is making available, and we're going to wrap our product around that because, boy, that really sounds like it will do the trick and save us all that time independently developing that ourselves.



LEO:  Can you explain what it did, too?  I mean, I, you know...



STEVE:  Oh, yeah.  We're going to get there.



LEO:  Good.  All right, all right.



STEVE:  Oh, yeah, yeah.  And then along comes Lenovo, who, like so many companies today, is adding crap to their product.  I mean, I'm having to - every time I update Flash, I've got to prevent Adobe from installing a trial version of Norton Antivirus on my computer.  It's like, turn that off.  I don't want that.  But unless I'm careful, I get it.  And we've talked about all of the crapware, which is probably the best term for it, which is being installed on stuff, retail things that we purchase.



LEO:  Did you hear...



STEVE:  I've heard everything you've said about it since you heard about this.



LEO:  ...what Rene Ritchie pointed out from the How-To Geek, remember, How-To Geek did a great piece where they used CNET's Download.com to download a file, and the top 10...



STEVE:  Top 10 Downloads.



LEO:  ...loaded with stuff.  But they just updated that piece to say, and by the way, two of the adware programs that you get by using Download.com have Komodia in them.



STEVE:  Yeah, yeah.  Okay.  So...



LEO:  So this is everywhere.



STEVE:  So my take is that, first of all, it was going to come to light sooner or later, and Lenovo happens to be, as we know, they're now the number one PC producer; right?  Or they were until last week.  And they unfortunately chose to preload Superfish onto people's systems, and Superfish uses the Komodia SDK, the ad for which we just heard or saw, in order to pull this off.



Now - so, okay.  First of all, the greater concern, the sort of overriding concern is that, to some degree, this is a generic response to the same problem the NSA has been complaining about, that is, the NSA has been complaining about - or in general law enforcement, the three-letter initial organizations.  Law enforcement generically has been increasingly upset that, in their term, the problem of the Internet going dark because we are increasingly bringing up security.  We've got efforts that'll be going online a few months from now from the EFF, the whole adding the technology to essentially make encryption free.  It's traditionally not been free because you have had to purchase certificates of varying grades and quality and repute from certificate authorities.  And in order to drop the friction of going to TLS to zero, the EFF is going to be doing this "we all encrypt" effort to essentially automate with your server the process of getting and maintaining an SSL certificate.



So even before that, you know, there's been major efforts to move us to security.  Google, to their credit, has been pushing this, and maybe overly pushing it, but still pushing it.  And the whole HSTS, the HTTPS Everywhere effort, and all of that.



LEO:  As somebody said, five years of progress in securing your transactions out the window in one fell swoop.  I mean...



STEVE:  Okay.  So the point is that the Internet is going dark, and law enforcement has been affected by this.  But so, too, have other services which we have traditionally relied upon.  For example, antiviral software is also doing this.  Antiviral software is installing a certificate in our browsers in order to crack open our secure connections in order to do AV scanning inside of SSL tunnels.



So I sort of want to put this in context.  We're going to talk about what an extra unbelievably awful job Komodia has done.  But the overall view here is that things that we say we want, no one is saying they want visual discovery, which is the Superfish product, which was wrapped around or layered on top of Komodia's odious HTTPS proxy.  But I'm seeing HTTPS proxies now being installed by AV software because that's the way they're choosing to solve this problem in order to have visibility into the increasingly SSL/TLS connections that browsers are making.



LEO:  Yeah, but I did not ask my antivirus to watch my SSL streams.  Who, I mean, do you really want that?



STEVE:  That's the default.  When you install...



LEO:  I don't - but I didn't ask it to do that.  Well, I don't use antivirus.  But if I did, that's not what - I want to look at why do they want it to do that?



STEVE:  Many, well, AV tools, as you know, for years have been filtering our Internet connections, trying to catch this stuff before it gets into our computer.  And so if we're saying yes, we want you to monitor our use of the Internet; we want you to block, you know, downloading things.  We want you to see that something coming in is bad, really on the fly, before it has a chance of landing and being executed.  That's what we're asking for.  And so that's what these things are doing now.



LEO:  So we are asking for that.



STEVE:  We really are, yes.  And I found myself - I'm thinking, what was it I just - it might have been Malwarebytes.  I turned that off because I knew to turn it off, but it was on by default.  And so this is the way this problem is being solved.



LEO:  Is it possible to do this safely?



STEVE:  Okay.  So let's talk about that.  The jargon that we saw explode across the Internet was "man-in-the-middle attack."  And while it's technically true, the man that's in the middle is installed on your computer.  So this really wouldn't, if done correctly - if done correctly.  And that's the key.  It's unnerving that all of the certificates that you see when you look at websites are actually signed by your AV.  And there is a tremendous responsibility on the AV product to do it correctly because it is so much easier to do it incorrectly.  And that's the path that Komodia took.  And that's what's actually mostly upset security researchers because, for example...



LEO:  Well, there's also the larger issue of, yeah, Komodia is a man in the middle on your system.  But it then passes it on to Lenovo or someone, a third party.  So it's acting as a man in the middle for somebody else.  Presumably your Norton is not doing that.



STEVE:  Okay.  So the reason everyone's sort of trying to gloss over this is it is complicated.  So what any of these things do is they put a certificate in your OS.  Now, we should note, this is also what corporations are all doing now because again, they have no choice.  Their network's users' traffic is probably mostly today, but probably all in some not too distant future, going to be over secure connections.  The corporate IT guys were becoming increasingly blind to what their own corporate IT traffic was.  They want border AV.  In order to do border AV today, in 2015, you need to crack open SSL connections.  And sadly, there's no next level of encryption unless you do something special.  That is to say, unfortunately, credit card information and usernames and passwords are being protected by SSL. 



I don't want to put a plug in here for SQRL, but of course SQRL doesn't even need SSL to be secure.  SSL is optional in SQRL because its own security is so strong, it doesn't rely on that.  So using a different authentication system than just usernames and passwords and trusting the SSL encryption does protect you from this.  But within a corporate environment, you probably have a certificate.



And in fact I've had the SSL, can't remember what I called it, page on GRC now for quite some time, for a year or so.  When I realized this was going on - oh, SSL Fingerprinting.  When I realized this was going on, I created a page to allow people to see whether anything was intercepting their certificates.  Yup, there it is, Fingerprints.  Because GRC has a view of unfiltered certificates, the actual certificates from the sites.  And if yours doesn't look the same because a fingerprint cannot be forged, then something is interfering with yours.  So nobody behind an AV system which is changing their certs will see the same fingerprint.  Nobody using one of these Lenovo laptops or, unfortunately, any of these other hundred products, whatever they are, that is using Komodia, is going to see the same certificate.



Okay.  So we want to believe that corporate AV proxies are doing a good job.  We want to believe that AV, that is, the AV products we purchase and now probably pay an annual license fee, are doing a good job.  Microsoft has a privileged position in Windows in that they don't have to do this in order to provide real-time Internet connectivity filtering, and their stuff does this.  The problem is they're always a little bit behind the curve.  It takes them a few months to, like, add awareness to this.  And I did hear just today that they've added awareness for Superfish to whatever brand of AV they're now offering. So that was a pretty quick response.  And fast response is what they're trying to do with their solution.



Okay.  So what did Komodia do wrong?  There it's sort of hard to know where to start.  The first thing they did wrong - okay.  So to understand the architecture, in order for these to function, your browser must have the public key of the certificate authority.  That's the way the CA system works.  So when we talk about the "root CA store" in any of our operating systems - Windows, Android, Mac, doesn't matter, iOS - the root CA store, those are all of the public keys belonging to the certificate authorities who have signed the certificates of remote servers.  So when the remote server sets up a connection with us, they have - they've signed the certificate with their private key that they protect, I mean, that's the crown jewels of any of our certificate authorities.  They absolutely protect it to their death.



And in fact they protect it so much now that the certificate isn't signed with their root, it's signed with a sub-CA because they don't even want to expose their actual root certificate to even their own signing process, they're so obsessed with security.  Nothing gets their private key.  So all we have is the public keys.  But as we know, that allows us to verify the signature, that is, allows the web browser to verify the signature on the certificate for that site that we have received.



So if you're going to do an HTTPS proxy, if you're going to crack open SSL/TLS connections in order to see in them for whatever reason - in the case of corporate IT to filter the Intranet's traffic before it gets to you in order to look for malware; in the case of AV which you have installed on your machine, that AV tool installed a certificate in your root CA store - because they are going to - the only way this works to intercept, they're going to spoof the certificate from the remote website.  When they see you wanting to create a connection, an SSL connection, they intercept that attempt, manufacture a certificate on the fly which they sign with their private key.



And this is the big weakness of all of these systems.  That private key, which is never supposed to leave the depths of a real certificate authority, it must exist in that proxy in order to create spoofed remote server certificates, SSL/TLS certificates on the fly.  Now, a good implementation of a proxy will create a unique public key to put in your browser, that is, to put in your root CA store.  It'll create a unique key pair, a public key and a private key, every single time.  The worst thing that Komodia has done is to reuse the same private key throughout their entire product suite.



LEO:  So not only is it visible on your machine, but everybody's is the same.



STEVE:  Yes.  And the password that protects their private key that's in the Superfish software installed on Lenovo laptops and a hundred other software products is "komodia."  It took Robert Graham three hours of poking at this thing...



LEO:  It's a great story, by the way.  Read his blog post about how he found the password.  It's great.



STEVE:  Yup, yup.



LEO:  He says, "I used ghetto tools."



STEVE:  Exactly.  So basically he just said, okay, maybe the simplest dumb thing will work.



LEO:  And it did.



STEVE:  And it did.  Yeah.  And he basically...



LEO:  So it's the same - now, what is the purpose of the password as opposed to the key?



STEVE:  The purpose of the password is supposed to be to - you're supposed to have the password in order to decrypt the certificate's private key on the fly.



LEO:  Ah.  Oh, okay.  Well, that's why you'd want to use the same one for every machine.  Simplifies the code.



STEVE:  Well, not only the same password.  That would be bad enough.



LEO:  The same key?



STEVE:  But the same key.



LEO:  The private key.



STEVE:  Now, what does this mean?  This means - this is like the Death Star scenario.  This means everybody who has any version of the Komodia-based software, a hundred companies including Fortune 100 companies, we don't know, you know, doing parental control software - again, these companies do not roll their own.  They say, ah, you're right.  We saw the ad on YouTube.  We want to save ourselves 18 months of painful cross-platform, cross-browser, cross-everything development.  We'll take the 15-day free trial, get the SDK, fire it up.  Oh, look how easy it is.  Drop it in, off we go.  We don't have to do all that.  And every one of these products, based on this, has installed the same public key in the root certificate store on all these platforms.



So that it's very much like the Hong Kong Post Office problem except this is worse because at least the Hong Kong Post Office's private key is hopefully unknown.  In this case, the private key, it took Rob Graham three hours, 180 minutes of just sort of trying stuff, and he now has it.  In fact, it's on Pastebin.  Everyone now has it.  There's a link to it in the show notes, and all of our listeners...



LEO:  In case you want it.



STEVE:  ...now have it, in case you'd like it.  And this allows you to do anything you want on any of those machines.  You can now create your own certificates for websites which all of those machines will trust.



Okay.  Now, Part 2 of how bad this is, is that during this connection setup, it's now created a fraudulent certificate to make your browser happy.  Now it turns around, and it connects to the remote server in order to make the connection to that remote server's HTTPS.  Unfortunately, it's got the worst set of security ciphers ever seen.  It still has 40-bit, four zero, 40-bit RC4 and MD5 hash as the cipher.  Which, you know, which everybody can crack.  It does 40-bit - four zero bit - DES, not even 3DES, just once.  One DES.



LEO:  What?  No.



STEVE:  I mean, these are ciphers from...



LEO:  Is this a high school kid that wrote this?  What is...



STEVE:  ...that everyone stopped using.  Even I stopped using them 10 years ago, they're so broken.  And this thing supports them all.  So all that anyone would have to do is be connecting - now, okay.  You would have to still have a server on the other end that agreed to this craziness.  But this demonstrates how bad this software is, that it's willing basically to drop all the way down almost to no encryption in order to connect to the remote server and complete your connection.



So there is a site that I link to in the show notes here, Filippo.io/Badfish, which anyone can use.  It takes a few seconds, and it will check your system for whether or not you've got Superfish, Komodia, there's another one called PrivDog which has come to light through all of this.  That's another - it's a piece of software people install on their computers, not knowing what they're doing and how bad this actually is.  And Leo, you just did it, and...



LEO:  Now, I'm on a Mac.  I'm not vulnerable.  Or am I?



STEVE:  Well, Komodia says you are.  Mac was one of the platforms.



LEO:  So they make a tool for Mac developers, as well.



STEVE:  Correct.



LEO:  Now, okay.  So you raise a very important point, which I'm glad you did, which is that these so-called man-in-the-middle attacks, these self-signed certificates that companies put on there, are often used for good purposes.  But it does point out that you have to trust, if it's your antivirus, that you have to trust that, not only are they trustworthy, but that they've implemented it in a trustworthy way, or didn't borrow Komodia code or something.



STEVE:  Or they may even have the best of intentions.



LEO:  With the best of intentions, right.



STEVE:  They could also have bugs.  They could have, like, for example, SQL Server, who thought that a database would cause such a problem?



LEO:  Right, right.



STEVE:  You know, because...



LEO:  So should we just eliminate self-signed certificates?  Is that a bad idea?



STEVE:  I think it's really a bad idea.  I think that, now, Windows apparently has some hooks in it.  And I've not taken the time to dig in.  But I remember when Microsoft was going to be doing this.  They talked about making hooks available for traffic filtering specifically for AV.  And I don't know why people are not taking advantage of it.  But people aren't.  They're just doing this.



LEO:  So they don't have to be doing - you don't have to do this.



STEVE:  No.  I don't think you do.  Because Microsoft still is smarting from those antitrust days, and they didn't want to have features in Windows that were exclusive to them.  As Microsoft has crept into the AV filtering business in Windows, which they're now solidly in, they've had to make those same hooks available to other vendors.



LEO:  Is there a way to go through your certificates on a system and see what certificates...



STEVE:  Yes.



LEO:  And delete ones you don't want?



STEVE:  Yes.  You can look at your root store.  And I'm trying to think, what was it that I - oh, I know.  It was on Jenny's laptop.  Jenny's laptop got a bunch of crapware installed on it, both hers and her mom's.  And I went through and deleted the - and it was doing this.  In fact, it may have been, I'm afraid to say this, I think it was Malwarebytes.  After I removed Malwarebytes, it left its public key certs behind.  And so I went into the Windows - it's called personal - I think it's the personal certificates.  Windows divides them up into different places.  So you can see the ones that have been added.  And they're pretty obvious that, I mean, they're not like DigiCert and Global Trust and Symantec.  Or actually Symantec may have installed some, too.  I think I have seen - although Symantec, it's VeriSign now, so that may be why those are there.



LEO:  So would it say "Komodia" if you have a Komodia cert on there?  Would it say it's from...



STEVE:  It probably does.  It probably just says hi, you know, we're Komodia, trust us.  It's like, oh, no.



LEO:  On the Mac, you know, you just go to Keychain Access, and you can see both your personal certs easily and other certificates that are installed, and you can go through those and remove those.  So on a PC it's a file that you look at?



STEVE:  No, you've got to go into...



LEO:  Is there a tool?



STEVE:  ...admin tools.  You can go in, it's the Certificate Manager.  And I think...



LEO:  Ah, okay.  So you go to the administrator - you can right-click on your computer, select Properties, and then bring up the Certificate Manager there.



STEVE:  Yeah, but it's not surfaced on all systems.  Sometimes you have to go into the Run dialogue and go certmgr.msc or something like that, in order to get to the - but certainly you just Google how do I get to Certificate Manager in Windows, and there's lots of stuff there on the 'Net.



LEO:  Sounds like anybody who listens to this show should be doing that.  You're all sophisticated enough to do that.



STEVE:  I really - yes.  I absolutely agree.



LEO:  Wow.



STEVE:  And for what it's worth, the show notes have a ton of more links to all of these things we've been talking about.  Get your own copy of the private key if you want and so forth.



LEO:  Where do you - yeah.  I searched for Certificate Manager on this $59 tablet, actually, and it popped right up.  So I can just...



STEVE:  Oh, good.



LEO:  I can just run that with a $59 tablet.  Okay.  Good.  People should probably do that.



STEVE:  Yeah.  So...



LEO:  It may break some software, though.  It might break your antivirus.



STEVE:  Yeah, I would say see whether what you see looks like something you want.  For example, in corporate IT you don't want to be deleting the certificate that your gateway AV has installed, or you won't be able to get on the 'Net at all.  I mean, you'll quickly know that was a mistake.  So don't discard these with abandon.  I know that our listeners have been having fun with this ever since we've been talking about how - I want to say "rich" and "deep" the certificate store, the root store has grown.  There are people who are seeing, who are experimenting, our listeners experimenting with how few they can survive with.  And the fact is it is a very steep exponential decay, where you go from 450 down to 10, and pretty much all of the Internet that you care about is being served by the 10 largest certificate authorities on the 'Net.  And then it just, you know, nobody is, I mean, how often are you actually encountering a certificate signed by the Hong Kong Post Office?



LEO:  Right.



STEVE:  Maybe never.  But it's there.  So you could - that's the kind of thing you could safely delete.



LEO:  Yeah, and I see, for some reason, some weird certificates in my Apple, as well.  I might want to just take those...



STEVE:  Eh, I know.



LEO:  Do not confuse Komodia, which is K-O-M-O-D-I-A, which Comodo, with a "C."



STEVE:  Actually, Comodo is in the doghouse, too.



LEO:  What?



STEVE:  They're the people - yes, Comodo, the CEO of Comodo is involved with this PrivDog tool which some people are feeling is even worse than Komodia.  And I thought it was interesting that Comodo, who is unfortunately a certificate authority, they have another branch, or I guess it's Comodo themselves, who are selling software which is doing some of this same stuff.



LEO:  [Expelling breath]



STEVE:  Yeah.



LEO:  I should have asked.  We had Gregor Freund, as you know, on yesterday.



STEVE:  Yeah.



LEO:  He was the guy who created the first popular firewall product, which we recommended...



STEVE:  ZoneAlarm.



LEO:  ...heartily for many years, ZoneAlarm.



STEVE:  Yeah.  We didn't recommend the color.  The color scheme was really annoying.  But...



LEO:  The bright red.



STEVE:  Oh, my god.  Orange, orange and red.



LEO:  Did it make a noise?  I feel like it might have made a noise, too, like [harsh buzzer sound].  Anyway...



STEVE:  Well, I think it was just when your eyes saw it and there was, like, some neural feedback of some sort because it was, like, ugh.



LEO:  But would even - that's more than 10 years old.  Would that have used, would all firewall software do this kind of stuff?



STEVE:  No.



LEO:  No.



STEVE:  Because that was just looking at IP addresses and packets and blocking where they were going to.  And that's on the outside of the...



LEO:  It didn't have to inspect the stream and the contents of the stream to do this.



STEVE:  Correct.  It's the so-called "deep inspection."  If something's doing deep inspection...



LEO:  That's what gets you in trouble, yeah.



STEVE:  ...the only way to do it is to crack these things open.  In fact, one of the other consequences of this we've talked about is that this also breaks all the caching that ISPs are doing.  And there has been some rumblings that it may before long become a requirement for customers of ISPs to install the ISP's public key in their root store to allow the ISP to crack open your secure connections for the sake of caching in order to decrease their bandwidth.  Because the problem is this absolutely, you know, SSL creates a one-to-one association between your browser, hopefully, and the remote server.  And that's having a real impact on ISP bandwidth.  Let's hope that never happens.



LEO:  Oy, oy, oy. 



STEVE:  I mean, that's - oh.



LEO:  And where would we get your show notes?  People are listening, going, okay, I want your show notes.  Is that at GRC.com/securitynow?



STEVE:  I always tweet, I tweet the link just before the show.  So it's in the Twitter stream, and it's always the same format.  And they're always linked.  So, okay, so you go to GRC.com/sn and then look at the show notes for last week, which are the third - it's the third icon.  And then just add one to the number.  That is, the URL is just, you know, it just increments.



LEO:  Okay.



STEVE:  It's something like - I don't have it right here in front of me.  It's, you know...



LEO:  @SGgrc on Twitter.  Just go to Twitter.com/SGgrc, and you'll see the link there.



STEVE:  And you'll see it right there, yes.



LEO:  Yeah.  I'm so scared now.  I don't want...



STEVE:  Yeah, I mean, it is...



LEO:  I'm willing not to have anything do deep packet inspection on my system.



STEVE:  I agree.  I think...



LEO:  I can live without that, thank you.



STEVE:  The problem is with doing that comes great responsibility.



LEO:  Right.  And I don't trust anybody.



STEVE:  And Komodia demonstrates how irresponsible it's possible to be.  And the problem is, even well-intending AV tools, we're requiring, we're hoping that they're not going to be making any big mistakes.



LEO:  Right.



STEVE:  And unfortunately this is a lot to verify.  And I agree with you, Leo.  I think it's better just to say, no, I don't want anything cracking my traffic open.



LEO:  I want my traffic to Amazon and my bank to remain encrypted.  Of course, if you're using PGP, if you're using your own personal encryption layer...



STEVE:  Another layer.



LEO:  ...you're safe.



STEVE:  Exactly.



LEO:  But you're not with Amazon and your bank because they don't support that.



STEVE:  No.  Right.  In fact, that's a nice segue into our next story because The Intercept dropped the news from another tidbit from Edward Snowden, that GCHQ, the U.K.'s equivalent of our NSA, in cooperation with the U.S. NSA, infiltrated the network of Gemalto.  Gemalto is not quite the sole source, but for all intents and purposes the sole source, of the world's SIM cards.  They produce two billion SIM cards per year.  They're a multinational firm incorporated in The Netherlands.  Their clients are AT&T, T-Mobile, Verizon, Sprint - the big four in the U.S. - and 450 other wireless network providers around the world.  Gemalto operates in 85 countries, has more than 40 manufacturing facilities, and they've got a major one in Austin, Texas and a large factory in Pennsylvania.



So essentially what we learned - and this is the slide, this is the picture of the week on the front page of show notes is the slide that Snowden captured and has revealed.  Essentially, their network was infiltrated some number of years ago, and GCHQ was bragging that they now had all of the private keys in all of the SIM cards that Gemalto has been producing.



LEO:  And how many is that?



STEVE:  That's all of them, essentially.



LEO:  They sell two billion a year.



STEVE:  Yeah.



LEO:  So it sounds like it's all of them.



STEVE:  It's pretty much all of them.



LEO:  All the U.S. carriers use Gemalto.  Everybody does.



STEVE:  Yup.  Everybody.  When I saw the name, it's like, okay, I know the name because that's where the SIM cards come from.



LEO:  There's no other company?  It's all Gemalto?



STEVE:  It's basically Gemalto.  There are some others like, you know, because there's always room for one more.



LEO:  You've got to admire the NSA.  I mean, they've obviously hired the best hackers they could afford.



STEVE:  You know, Leo, I've been approached at earlier phases in my life, and I remember thinking, eh, working for the NSA would be boring.  I was wrong about that.



LEO:  No.



STEVE:  I don't think...



LEO:  Only the smartest people work there.



STEVE:  Yeah.  I mean, they've got mathematicians, but it's the hackers at the NSA who are busy.



LEO:  Well, you remember that scene in "Good Will Hunting" where they try to hire the mathematic genius of - and then he says, why should - they said the question you should ask yourself is why shouldn't I work for the NSA?  And he has actually a long - it's on YouTube - but very good answer.



[Clip from "Good Will Hunting"]



WILL HUNTING:  So why do you think I should work for the National Security Agency?



NSA AGENT:  Well, you'd be working on the cutting edge.  [Leo:  Yes, you would.]  Be exposed to the kind of technology that you wouldn't see anywhere else because we classified it.



LEO:  What year was this?  This is like 1998?  '97?  We did not know how right they were.



STEVE:  Oh, boy.



LEO:  And how right Will was, if you listen to his answer.



STEVE:  So with the stolen encryption keys, "intelligence agencies can monitor mobile communications without seeking or receiving approval from telecom companies or foreign governments."



LEO:  Basically, that's the keys.  That's the keys.



STEVE:  Yes.



LEO:  They can get anything they want.



STEVE:  "Possessing the keys sidesteps the need to get a warrant or a wiretap and leaves no trace on the provider's network that the communications were intercepted.  Bulk key theft such as this enables intelligence agencies to unlock any previously encrypted communications they had already intercepted, but did not yet have the ability to decrypt.  As part of the covert operations against Gemalto, spies from GCHQ, with support from the NSA, mined the private communications of engineers and other company employees throughout multiple countries.  Gemalto was totally oblivious to the penetration of its systems and the spying on its employees.  Gemalto has refused to comment, other than to say that they had no prior knowledge that the agencies were conducting the operation" against their network.



Matt Green, our cryptographer friend at Johns Hopkins, explained to The Intercept, that broke this story, "Gaining access to a database of keys is pretty much game over for cellular encryption."



LEO:  What you want to know is what SIM cards does the NSA use?  Because I bet it's not Gemalto.



STEVE:  Yeah, see, the reason this was a perfect segue that you brought us into was you mentioned that the problem with the lack of trustworthiness of TLS, that is, of HTTPS now, is that we're relying on it for protection of in-the-clear data - credit card numbers, usernames, passwords.  When I'm looking at my credit report, it was delivered over SSL, and I'm looking at my Social Security number, and I'm answering questions and confirming things to the website.  So that is our sole wrapper of encryption.  And so it is not TNO, obviously.  We never claimed that it was.



But the good news is that we do have TNO solutions that are essentially encrypting within our cell phone communications.  So when you use the encrypted verbal and text communications, them having the decryption key for the wrapper of that, that is, the external tunnel no longer helps them.  So this is why having iMessage encryption, even though it's of dubious value with Apple maintaining the keys, I would argue that for most communications iMessage is safe.  You just can't absolutely depend upon it.  You need to use something like Threema or one of the other tools where you're carrying the obligation of managing the keys, but the flipside is nobody else has them.



So just to finish on the topic of the GCHQ and the NSA and cell phones, 2G was the original platform.  Remember, and I've talked about this through the years, I remember, like, telling my attorney, when I was using first-generation analog cell phones,  like we'd stop the conversation at some point, and I would say, "Wayne, I'll call you back on a landline once I get to the office."  Because I knew from my own experience you could just get a cheap police scanner, and it would scan the frequencies that cell phones at the time used, and you could hear people's conversations - and some of them were, I mean, it was entertaining - because there was no encryption.



Then we went to 2G, which is the current, still the dominant platform globally.  And that encryption is trivially cracked.  So you don't really even need the keys for 2G.  The NSA can cut through that like butter.  And it is still the dominant platform.  But 3G, 4G, and LTE, that's not crackable.  You need the keys for those.  And now we know GCHQ, with the help of the NSA, basically attacked the Gemalto network, got it infiltrated, did what they call  "implants" on a number of their servers, and have exfiltrated the database that relates the SIM card to its private key, which you otherwise would not have.  They make that data available to the carriers, that is, the carriers have to have that in order to decrypt what this SIM card is doing, that is, they have to know the private key of the SIM card.  Nobody else is supposed to know.  Well, now we know that, as you said, Leo, got to give  them credit.  They have all of those.



LEO:  They're good.



STEVE:  And understand, too, that the other thing, the other factor here is that SIM cards were never introduced originally for privacy.  They were introduced to control billing fraud.



LEO:  Oh, that's interesting.  Ah.



STEVE:  Because billing fraud - yes.  And so the whole SIM card supply chain never really had security as its focus.  It was to bring fraud down, which was rampant in the early days of analog cell phones.  So when they went to SIM cards, it was a billing hook.  But as a consequence, not that much security surrounded the whole supply chain from one end to the other.  And as we know, the weakest link in security is what will get attacked and cracked.



LEO:  Yeah.



STEVE:  TrueCrypt, an update.  This was a tweet actually by Matt Green, who has been overseeing the audit of TrueCrypt.  The good news is the audit of TrueCrypt, that final version 7.1a, is underway.



LEO:  Oh, good.



STEVE:  So we'll remember that late in 2013 they brought out the very first crowdfunded audit of TrueCrypt and raised $70,000.  Part 1 was finished, and it examined only the boot and the startup, the initialization process, and came out with a clean slate.  Then Part 2, which is the much more challenging part, was going to be the detailed look at the cryptography of TrueCrypt from the symmetric encryption through the random number generator and basically everything else.



But then we all got blindsided when late in the spring of 2014 the TrueCrypt authors decided to throw in the towel and pull the plug on the TrueCrypt project.  After recovering from the shock of that, taking a look at where things stood, talking to attorneys and so forth, they've decided they're going to move forward.  A group called the NCC Group's Cryptography Services has the contract to perform the Phase 2 audit.  And Matt wrote that they will be evaluating the original TrueCrypt 7.1a, and are to begin shortly.  However, to minimize price and make the donations stretch farther, they've allowed the start date to be flexible, he said, which is why we don't have results yet.  But it is underway.  And that's the one they're going to be doing.



A lot of people have asked me, what about this or that spinoff?  And for what it's worth, the attorneys have examined the license agreement, and all the spinoffs are illegal.  It is not legal to do anything with the source code.  All we can do is look at what we've got and continue using that.  So people may or may not care about the legality of that; but it's a little dicey, then, taking cryptographic software from somebody who you know is breaking the law and who knows they're breaking the law.



And finally, IE is the last browser to adopt HSTS, the strict transport security for HTTP in Windows 10.  It's in the technical preview, either now or coming.  But IE was the last browser in heavy use that did not support HSTS.  And there are a couple interesting things.  There is a site, HSTSpreload.appspot.com.  That's a site that allows anyone who has a server that wants HSTSpreload to add it to the Chromium list which all the browsers are now using.  Firefox and Opera and even IE will be using the official Chromium preload list.  GRC.com has been on it now for quite some time.



And in fact, if you put GRC, or, yeah, GRC.com into HSTSpreload.appspot.com, it'll verify.  It'll say, oh, GRC.com is already in the list.  And there's another cool thing you can do with Chrome, a fancy URL.  If you put in chrome://net-internals/#hsts, that takes you basically to a browser of the Chromium preload list.  And you can then put things like GRC in, GRC.com.  And, oop, it'll pop up and show you, yep, you're in the browser.  And it allows you to easily see who's in and who's not.  But you can also use HSTSpreload.appspot.com, not only to query the official global list but to submit your own server for inclusion.



And the reason that's important, just to finish this topic, is that the one weakness of HSTS is that the very first time a browser goes to a server which is issuing HSTS headers, if that first contact were intercepted, and the "S" was removed from the HTTPS, then they could downgrade your security, and the user would never know.  Once that contact has been made, though, over an SSL/TLS connection, HTTPS, then the server will give the browser permission that lasts for, like, a year.  It's three million something minutes, I can't remember the number now, but it's a long time.  And GRC has been issuing that header for quite a while, ever since I went to HSTS, that is, HTTPS Everywhere.  And of course an increasing number of sites are doing that now.  Once the browser has that, then it knows to silently upgrade any HTTP connection to HTTPS.  And then the man in the middle never has a chance to actually intercept and interfere.



A couple of little bits of miscellany and errata.  In talking about HTTP/2 last week, I had a lot of fun talking about the Lempel-Ziv compression and how that worked and how, by using a single compression context across all of the streams, you automatically got header compression.  That's true.  And HTTP/2 does that.  But the surfacing of CRIME, which was an attack on compression, people will remember that there was a very clever way of probing the data being compressed by changing it.  By using essentially compression artifact, using the change in size that zlib, the GZIP library, used, it was possible to reverse-engineer the data that was being compressed.



So after zlib was already in use for SPDY, CRIME occurred, and they backed out of using standard Lempel-Ziv-style compression and went to essentially the same thing, a shared context, but where specific headers are pretokenized, essentially, because the headers are just not - they're so well-known, things like user agent and cookie and URL and so forth that are so well known, those are pre-assigned to tokens.  And then there is a context maintained which is such that subsequent streams only talk about the deltas from the stream before.  So I just wanted, for the sake of completeness, to correct that.



Also I wanted to mention that "Citizenfour," which is the movie I talked about after staggering out of the theater and being so impressed with it, it is now airing on HBO.  It's just shy of two hours long.  It won an Oscar on Sunday for the Best Documentary.  It scored an 8.3 out of 10 on IMDB, and something I've never seen before on Rotten Tomatoes, 98%.  So, and I think the movie is absolutely worth seeing it.  People who listen to the podcast will remember that the way I described what I learned from it was I came way with a much better appreciation of the notion that even though I may not be super concerned about privacy for myself, I came away with a much better respect for the fact that privacy is a right; than I should respect other people's concern for to a greater degree than I think I had before I saw the movie.



So again, I commend everyone to check it out.  It's the story of Edward Snowden, but really well done, I mean, basically they had the foresight to always have a camera running, from their very first meeting, when Laura and Glenn walk into the hotel room and have no idea who this guy is.  I mean, absolutely none.  We get to see all that.  There's a lot of stuff that has not been seen before.  So I thought it was really good.



LEO:  It's on iTunes and Google Play, as well, if you don't have an HBO subscription.



STEVE:  Ah, good.  Good, good, good.  And have you seen it yet, Leo?



LEO:  I have not.  I will watch it tonight.



STEVE:  I really recommend it.  It really is, I mean, it's, I mean, we sort of think, my god, more Snowden?  How could there be anything we don't yet know?  And it turns out I know as much as we all do, and I was really impressed.  It's really worth - I think it's a very worthwhile movie.



LEO:  Speaking of privacy, you know, and you to some degree, I to a much greater degree, I'm not worried about my privacy because I'm kind of living in public anyway.  But I agree with you, I think we certainly should consider that.  Somebody in the chatroom, and I just wanted to circle back a little bit to the Komodia thing, said, "Well, Leo, you're not concerned about privacy.  Why would the Komodia thing bother you?"  It's not merely privacy.  It's a security issue, as well.



STEVE:  Yeah.



LEO:  We should emphasize that.  It's not merely that somebody could see your stuff.  It's that it's so poorly implemented...



STEVE:  Yes.



LEO:  ...a bad guy could take advantage of it.



STEVE:  Yes.  And that's exactly it, is that we don't even know, no one's even looked yet at what bugs this thing might have.  But imagine - I'd be surprised if it didn't have buffer overruns in it.  How could it not, with it being such a piece of crap?  So that anyone using it, surfing the 'Net - and by the way, it's going to be obvious to a server that you're probably using Komodia because who else would be advertising this cipher suite?  I mean, this ridiculous...



LEO:  No one else would do this.



STEVE:  Oh, my lord.  I mean, it's either a browser from prehistory, you know, IE2, or it's Komodia in 2015.  So you could have probably no problem at all sending malware back up that connection, taking over the user's computer.  And, boy, you sure do not want their root certificate, for which everyone on the planet now has the private key, you don't want that matching public key in your root store of your computer.  Wow.



LEO:  Okay.  I'm sorry, I didn't mean to distract you from...



STEVE:  No, I'm glad.



LEO:  "Citizenfour," everybody should watch.  I'll be watching it tonight.  And I was so pleased to see that they won the Oscar.  That was great.  That was amazing.



STEVE:  Yeah.  Yeah.  So I just - I am now through with number three book in "The Expanse" series.  I finally know why it's called "The Expanse."  That's all I'll say about that.  Apparently some people felt that I did a bit of a...



LEO:  Spoiler?  Bit of a spoiler?



STEVE:  Yes, yes, yes.  Yes, thank you, a bit of - no wonder I couldn't remember the word.  I hate the idea that I would have done that.  But when I went to search for a word that I used, I was shocked that it was so far back in the book.  I thought the word, the term I used was something we encountered much sooner.  So I really apologize.  If anyone felt - actually it turns out that what I said was more of a tease that isn't exactly correct.  Or, I mean, even though it seemed like a spoiler, it actually isn't.  So I'll let you figure out what that means.  I did also learn that the 10-episode Syfy series coming out sometime later in 2015 is just book one.



LEO:  Wow.



STEVE:  I was wondering, like, how much they had stretched it, how much they were going to do.  So that's cool.  Now, I'll say of book - because I said that book two was better even than book one.  Book three, I think, it felt like it had been stretched out a little bit.  I mean, there was a lot that happened.  It was fun.  I like the guy's writing style.  And actually it's a pseudonym for two people.  Leo, why do people do pseudonyms or, no, what do they call it?



LEO:  Well, you know, Stephen King famously did because he wanted to write books in the genre Westerns.  So he wrote them as...



STEVE:  Pen names is what I was trying to think of.



LEO:  Yeah, so he wrote as Richard Bachman because he didn't want people to say, oh, it's a Stephen King novel, and then say, oh, it's a Western.  So that would be one reason.  Why O. Henry used O. Henry instead of his real name is beyond me.  I don't know.



STEVE:  So people just choose to for some reason.



LEO:  Privacy?  Security?  I don't know.  That's...



STEVE:  Anyway, so this is a...



LEO:  I don't know.



STEVE:  The book says it's by one guy, but Wikipedia knows better, it's a couple guys.  Anyway, so three is absolutely worth reading.  I've not started into book four yet.  Mark Thompson said that I would be a little less impressed with four.  I don't know what that means yet.  But so far I really, I mean, I like the characters.  I really, you know, it's great.  It's not at the very, very pinnacle of the books we've recommended, the Hamilton stuff, the Michael McCollum novels, the Pournelle-Niven stuff.  I mean, that's world-class.  This is maybe just a notch below.  But when you're looking for something - and they're on Audible, too.  So...



LEO:  I'm putting them on my list.



STEVE:  Consider that, yeah.



LEO:  I have two credits waiting for me.



STEVE:  Actually, you've already got the first one.



LEO:  Oh, that's right, that's right.  That's the one where he's drifting through space debris, looking for stuff to scavenge; right?



STEVE:  There's definitely good stuff.  So, and I got a fun note from someone who apparently isn't too familiar with me because he referred to me as Dave.



LEO:  Dave?  Hey, Dave.



STEVE:  So his name is Fred Elbel.  And the subject was "Testimonial for SpinRite."  And this came through Sue.  So he says "Dave:  This is a testimonial for SpinRite.  You may place the following text on your website, but you may not publish my email address."  And nor will I publish your use of my name, Fred.  I guess his name is Fred.  My name, of course, is Steve.  So he's not a podcast listener.  And so in fact this explains it.  He says:  "After doing a backup of an old XP system, it failed and would not boot because of a boot drive error.  I wasn't sure that the backup had even completed okay.  Then I remembered reading about SpinRite and wondering what the heck it actually did.  After reviewing the material, watching the videos, and reading testimonials, I decided to give it a shot.  I created a SpinRite CD image on another system and booted it up on the bad system.  I then ran it in Level 2 against the bad drive.  The next morning the computer had powered off, so I ran SpinRite again.  It completed in an hour or so.  At that point the computer booted and ran flawlessly!"



LEO:  Wow.



STEVE:  "SpinRite is a fantastic tool," he says.



LEO:  We agree.



STEVE:  "And is certainly worth the purchase price.  Fred, Denver, Colorado, USA."  And for the record, my name is Steve.



LEO:  Thank you, Fred.  Thank you, Dave.  Steve Gibson, he's here to the rescue.



STEVE:  You know, an interesting attack, I've sort of been thinking while you were talking, would be anybody in an open WiFi environment - hotel, caf, whatever - could intercept someone's HTTPS connections and just send them back a Komodia-signed certificate.



LEO:  Oh.  And [crosstalk] on there.



STEVE:  And if their, well, if their browser accepts it, then that just says, okay, good, we get to filter their entire conversation.  And it's just that easy.  I mean, so the man-in-the-middle attack is, to the degree that there was something going on with a third-party server - and you're right, there was - it was never exactly clear what, although in all of the futzing around that Lenovo and Superfish did, they talked about, oh, shutting down the third-party data polling or whatever the hell it was doing.  So there did seem to be some skullduggery about doing something with the data that they were intercepting.  But even absent that, having that Komodia cert on your system really does open you for an attack, just that simple.  Anybody in the middle can just grab a connection, see if your browser accepts it.  If not, oh, nothing gained, nothing lost.  But if it does, bang.  They completely own all of your secure traffic.



LEO:  Terrible.



STEVE:  Yeah.



LEO:  And a lot of people just say, yeah, sure, whatever, okay.  Must be Microsoft.  Question No. 1 in our listener-driven potpourri, from Kai Harder, Frankfurt, Germany.  He's noticed a new phishing trick:  Steve, I recently received a clickbait spam email.  "You can see my private photos here," said the link.  Examining the email source, as you recently advised, told me the link led to a shortened URL.  I was about to delete the message when I saw an unsubscribe link near the bottom.  Sure enough, same URL.  Maybe this is old - of course.  Maybe this is old news to you, but I wasn't familiar with this scheme before.  You regularly warn people about not clicking links in email, but you've got to include "unsubscribe" links in here because this is a really nasty one that people might not think of.  I am always clicking the unsubscribe link.



STEVE:  Actually, I am guilty of unsubscribing to email that is unsolicited from people I know.  So, I mean, it is dangerous.  But you get on mailing lists, and you're hoping that they're going to honor your unsubscribe.  So, I mean, it's things like Twitter.  Twitter just - I keep, you know, they're trying to commercialize and incentivize and amortize and monetize Twitter.  And so I'm getting crap from them that I don't want.



LEO:  All the time.



STEVE:  And so, yeah, so I trust them to honor an unsubscribe.  But the reason I grabbed this was it is - this is the way people are getting CryptoWall on their machine.  This is the way that GCHQ is penetrating the employees of Gemalto.  So ostensibly good people are using it to get in and get the information they feel they need.  And we know that bad guys, I mean, this is the vector.  It is social engineering email.  And I just liked this because you get email you don't want.  And, so, boy, even if you're smart enough not to click on the nasty private photos link, you see, oh, look, but I can stop getting more of these.  Uh, er, you know, and before you know it, your drive's encrypted.



LEO:  Yeah.  Well, I do it on a Mac, so that's probably all right.  Or a Chromebook.  That would even be better; right?  Do it on a Chromebook.  And then, even if that unsubscribe link leads to something nasty...



STEVE:  Yeah, well, and I, of course...



LEO:  And don't give any credentials, either.



STEVE:  Right.  I do it with Flash, Java, and JavaScript all disabled, so there's that, as well.



LEO:  But if you don't, I mean, if you click "unsubscribe" and it says, oh, and by the way, what's your credit card number, I would not give it to them.



STEVE:  Yeah.



LEO:  That'd be another thing.



STEVE:  That would be a bad sign.



LEO:  Bad idea.  Juun Pei in Mountain View, California, had a question about embedded spy firmware in hard drives.  We found out about that this week.  Did we talk about that last week?



STEVE:  Oh, yeah.  Actually...



LEO:  We did.



STEVE:  ...we did cover it in the podcast, yup.



LEO:  Because it was the Kaspersky security conference.



STEVE:  Exactly.



LEO:  Yeah, yeah.



STEVE:  That was underway just as we - it was, like, on day two, and they had announced it on day one.



LEO:  So with Kaspersky finding that spook firmware in Western Digital and Seagate drives, among others, do whole-drive encryption tools such as the trusty TrueCrypt defeat the ability of the spooks to see what's on a compromised machine?  I've been reading what others are saying on some 'Net forums.  The idea is firmware like this would use any OS it was aware of to do its bidding.  From what I know about computers, as soon as firmware like BIOS loads the OS, the OS takes over.  So how can firmware even listen for incoming connections to the machine or exfiltrate data?  Also, if that's possible, wouldn't simple packet captures reveal that's what's going on?



STEVE:  Okay.  So this is an instance of us not having enough information.



LEO:  Right.



STEVE:  One of the things that is important for people to understand, because I've been flooded with people asking if SpinRite could, like, fix this, it's that Kaspersky did not find the spoof firmware on any drives.



LEO:  Oh.



STEVE:  Because you can't. 



LEO:  Oh.



STEVE:  What they found was the evidence of it in the dropper, which is where all of the awareness of those different drives'  makes and model numbers was.



LEO:  Yes, yes.



STEVE:  So because the firmware, you can't see it.  It's write-only.  The API, the firmware API doesn't let it be read back.  And once it's written, it protects itself from being overwritten.  So you can't even refix it by updating from the manufacturer's good firmware.  It gets in there, and it protects itself because it's got all the keys.  It's the firmware that decides what the firmware should do.



LEO:  So it's like a rootkit in that regard.



STEVE:  It is, exactly.  Oh, and by the way, I forgot to mention that Komodia makes rootkits also.



LEO:  Yeah, that's handy.  The full-service hacker, yeah.



STEVE:  In fact, a link that we didn't go to in the show notes that I meant to, the Komodia site immediately went offline.  And I don't know why. They immediately declared they were DDoSed, except that DDoSed page came right up.  And then, but I had already seen the site because I, you know, thanks to my Twitter followers, I was clued into this thing immediately.  I went to Komodia because I drilled down, figured out where the real problem was - it was with them - browsed around their site, and then a while later when I went back it was DDoSed.  Ah, but I remembered.  The old Internet archive.  And so I went back, and I have archived links in the show notes.  Their product list is a hoot and a half.  Because they're just, oh, yeah, SSL interception, we've got that.  Rootkit, you'd like a rootkit?  We've done all the hard lifting and the rootkit.  Just click here, and you get your rootkit for two weeks' free trial.  So, yeah.



LEO:  Do you think it's just some guy, like a 19 year old who says, ah, this would be a good business?



STEVE:  Boy, I bet he's been making some money.  But I think that game's up, yeah.  I mean, you saw the ad.  The ad was super...



LEO:  That's well done.



STEVE:  Oh, my god.  I'm sure that even if - say that the Superfish people said, hey, Lenovo, we'd be happy to pay you to install this crap on your laptops.  And the Lenovo engineer says, uh, we're really not sure.  Who is this Komodia?  Oh, go look, check out the YouTube ad.  These guys are on the up and up.  Oh, okay, fine.  Yeah.  So anyway...



LEO:  What a world.



STEVE:  What I wanted to say was that we cannot see the firmware on the hard drives.  No one, not even Kaspersky, has been able to see the firmware on the hard drives.  All they ever found was the installer.  So we don't actually know much about it.  We know what firmware could do, and we believe that it substitutes the boot sector for its own.  So when the boot sector which the BIOS jumps to in order to start things going, when that happens, the firmware could supply a different one.



Now, the question is, would the drive being encrypted render this ineffective?  And I'm strongly inclined to say yes because there was this - there was also this sense of which file systems that firmware was aware of.  It knew about FAT and NTFS and EXT2 and a couple others.  But the fact that it was file system-specific makes me think, well, then there were a lot that, you know, it might have a problem if what's physically written on the drive is encrypted.  It's not a file system it knows how to interpret.



On the other hand, if it was smart enough to hook the OS after the TrueCrypt bootloader had loaded, maybe it's smart enough.  Or maybe, I mean, maybe they have this as a TrueCrypt-defeating mechanism, which could be possible.  We just don't have enough information because unfortunately no one has ever been able to see into the firmware.  All we saw was the thing that was able to install it into the drive.



LEO:  Yeah.  Wow.



STEVE:  Yeah.



LEO:  Steve in Utah is looking for a low-level formatting tool:  Steve, with all the wonderful free stuff you have, I'm wondering if you've ever written a low-level formatting program that can be used on my hard drive.  If so, please tell me what it is called.  And if you haven't written one, well, where could I get something like that?



STEVE:  Well, let me think.  Have I ever written...



LEO:  You have to think, I'm sure.



STEVE:  ...a low-level formatting tool?



LEO:  What could that be?  What could that be?  Is it called Spin, Spin [crosstalk]...



STEVE:  Yeah, maybe just the preeminent one of the entire history of human mankind.  Of course, famously, that's what SpinRite 1 was.  It was the low-level formatting tool to end all low-level formatting tools.



LEO:  Not famously enough, apparently.



STEVE:  Yeah.  So, yes.  I saw this, I said, oh, this is too much fun.



LEO:  It's great.



STEVE:  Yes.  Now, what Steve of course wants is - I'm not sure because what happened is that SpinRite's low-level formatting was so good that, in order to be that good, it had to do a whole lot of other things that weren't about low-level formatting.  That is, it had to have fabulous data recovery because once I low-level formatted the drive, I was never going to be able to recover data again.  So I had to recover it first.



LEO:  Right.



STEVE:  And then drives stopped being low-level formattable, yet SpinRite continued, not being a low-level formatter anymore because it couldn't be, no one could, but being a data recovery tool.  It just sort of changed because it was always a fabulous data recovery tool, and that part lived on.  So Steve, I'm not sure why you want low-level formatting.  It sounds like you want to zero the drive.  And the low-level format command does still exist in drives.  Anything, any low-level formatting tool - just google "low-level drive formatting tool," you can find one.  When viruses are particularly upset with you, they will trigger the low-level format command, and your drive will start going tick, tick, tick, tick, tick, tick, tick, tick, tick.  Now, it isn't low-level formatting.  It is zeroing.  So if that's what you want, they are all created equal.  There's no way for one low-level formatter to be better than another because all any of them can do is issue one command to the drive, which is "format," and the drive will go off and do that.



LEO:  So it's in the drive firmware.



STEVE:  Yeah.  It's supported by the firmware.  And no drives low-level format themselves because they all have all of this high-level intelligence on them.  They've got sector pools, spares pools.  They've go servoing information.  They've got all this management architecture actually living there on the surface of the drive.  So no drives today actually perform a low-level format.  They have converted it into a "write zeroes to the drive."  And that's what they do.



LEO:  Yeah.  Very good.  So, Steve, you've got one, you just didn't know it.



STEVE:  Yeah.



LEO:  Tom in Indiana, he's a little worried about HTTP/2, which we talked about last week.  Will there be a way for browsers to still block ads, scripts, unwanted audio and video completely?  That is, will browsers be able to block the remote web server's speculative push?  If not, those of us with bandwidth limits, for instance on wireless, you know, 4G networks, and expensive service are going to get hit hard.  Blocking BS is easy now.  A program just modifies the page.  But it seems now that a user will have to eat and pay for that BS, even if it is not displayed as output, just it's cached.



STEVE:  Great question.  And I didn't get into the absolute weeds in our discussion of HTTP/2 last week.  So a couple quick notes.  Each endpoint, the browser and the server, are able to, well, by spec, they exchange a settings frame which allows them to set their connection policies.  So the browser could constrain what the server is able to do, that is, not give it so many streams that it's just got free streams available to arbitrarily send things down to the browser.



The other important thing to note, which I didn't mention, is that the same origin policy still applies to server push.  That is, remember that we're making one connection between the web browser and the server at one domain.  So the same origin policy is what we've talked about often in the way browser pages are restricted, like script from a given origin cannot just arbitrarily go and get resources from some other origin, from some other domain name.  It's only able to make queries from the same origin.



Well, same origin applies to server push, meaning that there's no way for other domains' content to get mixed in or pushed to the browser.  But finally, and most importantly, the mechanism that implements server push is actually called a "push promise frame."  The push promise frame is sent by the server to the browser, saying I recommend that you allow me to push the following content.  And that push promise identifies the resource.  So the browser has to not decline the server's suggestion.  And it can.  For example, it might respond, "No need, I've got it in my cache."



So that's the way we solve the problem of an aggressively pushy server, saying, hey, let me send you everything else on this page.  Instead, what it sends is it sends intent to push, essentially, and the browser can very quickly decline those that it doesn't wish to have.  Those could be ads that it doesn't want to take the time.  But remember, ads are typically going to be coming from a different origin anyway.  So there wouldn't be ads coming up that same stream unless the same server was wanting to serve ad content, for example, to solve the problem of cookies not being tracked across domains and so forth, which it's conceivable some servers would.  But more importantly, the browser has to say, yeah, I don't know about that.  Go ahead.  Send it when you have a chance.



LEO:  Yeah.  I'd like to see that.  Send it along.



STEVE:  Yeah.  Yeah, when you have, yeah, when you've got some spare time.



LEO:  Joe Meady, I'm sorry to say, in Stratford, Connecticut, had a CryptoWall encounter.  I'm sorry to hear that, Joe.  Steve and Leo, love Security Now! and the other shows on Tech TV.  I like it that he called it "Tech TV."  That's exactly what it is.  I watch them on my Roku.  It's tech for your TV.  While I was watching The Tech Guy show live on Sunday, my wife calls down to me from the home office and says, "Oh, hey, Joe..."



STEVE:  Joe.



LEO:  "Joe, I can't open the QuickBooks file.  I get an error that says I may have the CryptoWall virus?"  So I ran up into the office and, sure enough, she's got the virus.  I shut down the computer immediately, while it was in the process of encrypting her files, and I managed to stop it from going any further.  What a terrible way to interrupt a live TWiT show, he says.  I didn't add that, he added that.  I booted up Ubuntu -oh, Joe, thank goodness you're there - so I could copy off any data that was not compromised.  Fortunately - oh, Joe, I'm loving you even more - my wife was not an administrator.  So I'm wondering now how she got it.  I've read that CryptoWall makes a copy of your data file.  It encrypts it, then deletes the original file.  I was wondering if I could recover some of the files by undeleting them.  Is that possible?  Probably he gave his wife the administrator password.  And so when...



STEVE:  Actually, what we know is that CryptoWall cannot delete the, what are they, the system restore copies.  So you can still get infected with CryptoWall locally, but it cannot make the deep deletes that your system really needs.



LEO:  If you're not an administrator.



STEVE:  Right.



LEO:  He said, I'm wondering if I could recover some of the files by undeleting them.  Is that possible?  Can you recommend a good tool to use to undelete files?  I think she got the virus from an email from one of her clients, possibly a family member.



STEVE:  Yup.



LEO:  I'd like to track down the source of the infection.  Can you give me any guidance on that matter?  I was thinking about using a virtual machine to track down the email or website.  Unfortunately, not all her pictures were backed up.  Oh, sigh.  She's pretty upset and even considered paying the random.  I told her not to.  Her machine was an XP machine.  This happened while I was in the process of getting her new hard drive up and running with Windows 7.  One more day, and I would have been done. Oh.  Any help is appreciated.



STEVE:  Okay.  So the best thing to do for Joe and anybody else is BleepingComputer.com.



LEO:  Great site.



STEVE:  Yes.  That's the site.  Rather than trying to go through all the possible variations, this does put you in self-help mode, but clearly Joe is up to the task.  I mean, look at everything else that he did, firing up Ubuntu and getting all the not-yet-fully-encrypted files off.  There you will find forums, and they've got one devoted to CryptoWall where you'll find a bunch of, unfortunately, people who are in similar straits, and pointers to all the best tools and solutions and commentary, write-ups on the state of the art in how to deal with it.  CryptoWall just came out with version 3.0, which uses Tor more deeply.  It gives people more time.  I think 2.0 only gave you, like, five days.  This one gives you a longer grace period.  So it's not gone.  It's still bad.  But BleepingComputer.com, that's where you want to go find the right forum to tackle CryptoWall, and we'll just turn you loose with that, Joe.



LEO:  Do you have an undeleter you recommend?



STEVE:  I don't have any favorite undeleter.  Yeah, I don't know.



LEO:  It all started with Norton; right?  That was the first one I used.  I think that's one of his first...



STEVE:  Yup, that was...



LEO:  That was his first program.



STEVE:  That's what put him on the map, Norton Undelete.



LEO:  Remember that well.



STEVE:  Yup, Peter Norton.



LEO:  On the original PC, I don't know if it's still true in Windows, it was an upside-down "E."  They replaced the first letter of the file.



STEVE:  E5 was the character.



LEO:  It appeared on the screen as an upside-down "E."



STEVE:  Yup.



LEO:  And that's how you knew it was deleted.  That's all it did.



STEVE:  Yup.  Well, actually it...



LEO:  I guess it would remove it from the catalog or something; right?



STEVE:  Yeah.  Well, no, it overwrote the first character in the directory.



LEO:  Right.



STEVE:  And then it released all the chain of allocation.



LEO:  Right.



STEVE:  The allocation chain in the FAT.  But it didn't overwrite the first cluster, which was part of the directory.  So when you wanted to undelete, you'd go through and look for the E5s.  Oh, and there was a way to tell what that was.  Or no, no.  I think it would prompt you, what do you think the first character of this file was?  And you'd go, oh.  It would say, you know, blerch urity, and you'd go, oh, security.  And so that would give it the name.  And then what it would do is it would have in that directory entry the first cluster of the file.  So you could always get that back if you hadn't done much writing since then.



But the other thing the FAT tried to do was it wrote in a go through the drive forward and then loop back to the beginning and overwrite.  So even so, it would generally not be writing over what you had done.  And so then it would sort of heuristically look at the file allocation table and check to see whether that cluster was free, and was the one next to it free, and what about the one after that, and after that, and after that?  And so it would try to rebuild the original contiguous block of clusters to end up meeting the length of the file, which was also stored in the directory.  So there was a lot of information there.  Peter did the work and created the world's first undelete utility and made a lot of money.



LEO:  Mark Goldstein, Northern Virginia, notes the world is changing.  Mark, wow, really?  Oh, I shouldn't be sarcastic.  For the past 15 years I've been in cybersecurity and privacy.  Whenever I would meet someone at a cocktail party - whatever happened to cocktail parties?  That's another thing gone; right, Mark?  They would ask what I did for a living, and almost immediately after hearing they would suddenly realize, I think I need to freshen my drink.  But lately, with cyber-something on the front page news, now everybody wants to ask questions about security and encryption and so on.  Even the U.S. President is talking about encryption and the need for government monitoring, metadata and such.  We cyber geeks are becoming much more relevant now.  Have you noticed that, Steve?  You get access to cocktail parties?



STEVE:  Ah, yep.  When I'm involved in computers and security, people are like, oh, Internet security, oh, yeah.



LEO:  Ooh, very nice.



STEVE:  Yeah.  That's a big thing.



LEO:  Very nice.



STEVE:  Then they go freshen their drink.



LEO:  Yeah.  It's a short conversation, I've noticed.



STEVE:  You finish a sentence, yeah.  They don't run.



LEO:  Mike Woolard in Ohio wants to use SQRL in a multiuser environment:  My company is looking into implementing SQRL with our web applications.  More than 30 percent of our customer service calls are password related.  That's probably low for some companies.  And SQRL should zero that.  We offer a SaaS - Software as a Service - B2B solution, where the users of the application are generally not tech savvy, and in an environment where multiple users tend to share workstations to use our application.  That would make sense.  They'd have to have separate passwords, each of them.  Because of the password issue - oh, they also tend to share accounts.  That's not what we want.  Well, that's one way to get around it.  Why have extra passwords?



We want to avoid having the user logon and off Windows to use SQRL for authenticating onto our sites.  I see from SQRL's documentation there's a flag that can be set to always ask the user to select an identity.  And he's reading up on SQRL at GRC.com/SQRL.  Just wonder how the details - how this works, if you've had any other suggestions for implementing it in an environment like this.  Thanks, and I am a SpinRite user, he says, for five-plus years.  That's an interesting use.



STEVE:  Yeah.  Actually, I anticipated this because of the, I would say, the multi-SQRL household, but actually the multi-user household.  You know, many places have a shared machine.  Sometimes the computer is yours, and there's no one logging into it.  That's like the case for me, my main workstation and so forth.  But many families have accounts for all of the different people in the household.  With SQRL, you can, first of all, have multiple identities.  You don't need one for yourself.  That's the whole point of SQRL.  And in fact I go through some lengths to make sure, if they're creating another identity, that it's actually for another person, that is, I don't want them to think, oh, I need to create an identity for every website.  So no, no, no, that's the whole point, one ID, maybe for the rest of your life.



But you wouldn't want your son to use your SQRL identity.  Now, unless you gave him your SQRL password, he couldn't because you need - you are prompted for that in order to make sure that you didn't walk away and leave the computer on and with SQRL able to stand in for you to authenticate you all over the Internet.  So there's two choices.  You can change the identity that SQRL will use.  So you can create multiple identities for multiple people, and name them, you know, Johnny, Dad, Mom, Susie.  And if you realize that, when you sit down, oh, SQRL is set to Dad, and you see that very promptly in the first dialogue, and if you don't change it, your password, your password won't work for Dad's SQRL identity.  So you can change it.



But it occurred to me, in an environment where people might be frequently changing, setting an option in SQRL so that it always, it proactively asks you to select from a dropdown list box which user do you want to authenticate as, that's how we handle that.  So it's one additional step.  But it's very quick, and that just allows you to say, yeah, I'm Joey.  And then Joey types in his password, and off he goes with SQRL, with Joey's SQRL identity being the one that will authenticate him on the Internet.  So, Mike, it's entirely operable in your situation.  It'll work.



LEO:  Excellent.  A good use for it, in fact.



STEVE:  Yeah.



LEO:  In a previous episode, Steve - this comes to us from Steve in Alton, Illinois.  In a previous episode you mentioned that DDoS attacks could mostly be prevented if all ISPs checked for traffic having origination IP addresses that are outside their network - spoofed traffic - attempting to exit from the network.  I'll rephrase this.  If ISPs simply said no packets can come from our network without having an origination address within our network.



STEVE:  Perfect.



LEO:  So I'm wondering why this seemingly simple precaution isn't being done.  Would this stop all of these attacks or just certain kinds?  For instance, if the server being attacked was within the same ISP as the attacker - well, I'll let you explain it - or they used UDP or SMTP instead of TCP/IP, would doing this cause any other networking-type problems with, for instance, VPNs or other types of forwarding?  Why aren't ISPs doing this?  Or is it just because it would be expensive?  Why, Steve, why?  I want to know the same thing.  Why not?



STEVE:  Yeah.  I mean, many in the industry are wondering.  And this is the tendency that Google is being so proactive about over on the security side.  It'd be wonderful if they had some way of enforcing this with ISPs.  It is just laziness.  It doesn't seem to be a big problem.  It's called egress filtering.  You filter the traffic egressing from your network.  Ingress is coming to you.  Egress is leaving.  And so all you have to do is drop packets that do not carry a source IP originating from that network.



LEO:  And I can't think of a single reason why anybody would legitimately be doing that.



STEVE:  There is none.



LEO:  There's no reason why something coming from your network shouldn't have an IP address within your network.



STEVE:  Correct.  Now, it does not...



LEO:  It doesn't because they're spoofing IP addresses.



STEVE:  Exactly.  That's the only reason.  It is a breakage of the fundamental IP layer for anyone to put an address other than their own in the outgoing packet.  And in fact you can't do it.  OSes will not let you do it.  At the software level, you have no control.  And...



LEO:  This was why you were upset about raw rockets in Windows XP.



STEVE:  Exactly.  You should not have that control.



LEO:  But if you're a Linux user, you can do it, obviously.  I mean, their software, the operating system will let you do it.  Windows Server will let you do it.



STEVE:  UNIX has always allowed it, if you had root privileges.  Even there, UNIX original guys said nobody should log on as root.  Nobody should be able to overwrite the source IP in outbound packets.  And so if you're not logged on as root, and you can't overwrite the source IP, you can't do it even on UNIX.



LEO:  Yeah.



STEVE:  But the problem was raw socket technology was there, and bad guys get root privileges.  Then they can do it.  So the final piece of Steve's question is does this completely solve the problem?  No.  But, for example, the traffic, recently we were talking about DNS reflection attacks where you send a little query to a DNS server, and it sends a big response back.  You want to spoof your source IP when you send a DNS query out to Google's DNS servers so that it sends it back - it thinks it's sending it back to you.  It sends it back to your victim, instead.



Where this won't help is TCP.  So, for example, if HTTP queries are being used to flood a server, an HTTP server, with valid requests for pages, those cannot have a spoof.  So TCP flooding would be blocked by egress filtering.  The fact is all ISPs should be doing egress filtering because it blocks all the SYN floods and the DNS spoofing attacks.  It blocks a huge class of them.  Not all, but enough that it's worthwhile, and it's so simple to do.  They just don't because they didn't do it last week or the week before, and everything seems fine.



LEO:  You know, the same, there's kind of an analogous situation with port 25 and spam.  For a long time, ISPs would allow you to basically serve, have an email-sending device on your local PC and spam people.



STEVE:  Right.



LEO:  And eventually - and one of the reasons they didn't disable port 25 is because it would cost them a lot of money, they thought, for all the tech support calls they'd be getting.  Why can't I use port 25?  I don't think they got any, but let's say that's why they didn't.  Eventually, just public opinion forced them.  Most ISPs now block port 25; right?  They don't...



STEVE:  Right.



LEO:  They don't allow you to have your own mail server.



STEVE:  Right, 25, and the Windows filesharing ports, those are all blocked, 135...



LEO:  139, 135, yeah.



STEVE:  Yup, 135, 139, 443.  You just can't use those because they've been so troublesome in the past.



LEO:  Right.  And it is probably the case when you're a Comcast, and you have literally tens of millions of customers, that even if one tenth of 1% call your service, call your help line because something's not working - but I can't think of anything that would be broken by preventing that.



STEVE:  And we can see the quality of the service that Comcast provides.



LEO:  Oh, yeah, all right.  Well, that's one of the reasons; right?  It's expensive to give you good service.



STEVE:  Exactly.  They can't afford to put UNIX gurus on the phone.



LEO:  Right.  Also very important mitigation would be to get rid of these amplification attacks.  NNTP servers and so forth need to be patched.



STEVE:  Yes, yes.



LEO:  Because you still probably don't want to use your own IP address when you're launching an amplification attack.  But...



STEVE:  Oh, no, it'll just come right back at you.



LEO:  Oh, that's right.  You need to spoof that there, yeah.  You're going to have to spoof that.



STEVE:  I just flooded myself, oh, my god.



LEO:  That's what I would do.  Let me just see, I'd like to try an amplification attack.  Wait a minute, where did my Internet go?  Good point.  You have to spoof the IP address.  Peter Sysak, S-Y-S-A-K, in Ontario, Ottawa, Canada, wonders about SpinRite parallel operation:  Just bought a copy of SpinRite - smiley face - to use for various purposes, one of which being to maintain my five 2TB NAS drives.  Five drives, each 2TB.  I'd like to know if SpinRite will process the drives in parallel.  In other words, can I plug in all five, or two, and have SpinRite work its magic in parallel?  I'm currently running drives one at a time, so doubling up or more would be terrific.  Because, as we know, SpinRite could take a while.  Thanks, Steve.  Keep up the great work.  I emailed you guys a while ago and mentioned I had started listening to Security Now! from No. 1.  I am catching up.  Let's see.  We're at Episode 496, soon to hit our 500th episode.  Where is he?  Episode 157.  You've got a way to go, dude.  Can't wait to get caught up.



STEVE:  Hey, but he's going to be fully tuned up by the time he gets there.



LEO:  Yeah, good news.



STEVE:  Okay.  So as soon as SQRL is wrapped, and I should say, I haven't been talking about it much, but we're making great progress.  There's now a full login demo account system is online.  A SQRL protocol diagnostics is online.  There's a Mac OS X client is up and running and in beta.  iOS client is up and running.  Drupal, and there's some X.  Is it Drupal 7 or, no, Drupal 7, is that something?



LEO:  Drupal 7 is the latest version, yeah.



STEVE:  Okay.  Then we have that is up line.  A test server, a command line client is in the works.  I mean, it's all happening.



LEO:  Wow, that's great.



STEVE:  So once that's behind me, my logic is to do something to hold everyone over while I completely rewrite SpinRite.  So 6.1 is sort of the catch-up.  That's why I'm making it free.  It will reduce the time to run SpinRite on one drive to about 1TB per hour.  So that means a 2TB drive will take two hours.  So that's way faster than we've had.  But it will not do multiple drives at once because none of the architecture in none of the existing infrastructure in SpinRite supports that.  That is the absolute wish list, one of the main features of 7 will be that I will spin up and simultaneously run SpinRite on every drive you have, and they will all be running at 1TB per hour.  I can do that.  I'm writing it in assembly code.  The hardware can do that.



So nothing is going to stop me.  The reason I'm not doing it first is I need to bring SpinRite up to where it should be so that people are okay while I work on 7.  And 7 will have a GUI and be file-system aware and all kinds of stuff.  But that's a big project.  So 6.1 will make it way faster and practical to run on today's multi-terabyte drives, whereas it's still painful.  But everybody gets 6.1 for free.



LEO:  Nice.  Finally, Question 10, Andy in Alabama.  He wonders, what are you doing with Java on your site?  What?  Steve, love the podcast, and I've heard you talk often about how unsafe Java in the browser is.  I just noticed the Big Number Calculator on GRC requires the user to have Java installed.  Hey, I understand it's served over TLS from your site, TNO aside.  But wouldn't having Java installed open users up to malicious applets on other sites?  With the recent JavaScript optimizations, is there some reason you don't use asm.js or something like that?



STEVE:  So it's a really good question.  I have really no defense.  I was using that Big Number Calculator, which I did not write, but, like, all the time when I was doing things like Password Haystacks and Perfect Paper Passwords, all those times where I wanted to know what is 2^326.  And I don't want, like, oh, well, it's about 10^77 or something.  I want digits.  And this thing gives them to you.  Anyway, it's just so cool that I decided to grab the Java and put it on GRC.com where I had easy access to it.  And I thought, well, since I want it, maybe it would be handy for other people.



So, yeah, I guess to the degree that it requires Java - and, I mean, I have Java on my system.  I need it for all kinds of things.  Eclipse is Java-based.  Other things that I use are Java-based.  I mean, you know, real Java.  But I'm also using Firefox with NoScript, and Java in the browser is completely disabled.  In fact, there's no plugin for Java in Firefox.  And I've got Java security turned up from, you know, Sun Java's control has it disabled in the browser.  So it's possible to turn Java off for the browser now, in latest versions of Java, so that it's not a problem for the browser.  You would need to turn it on for GRC if you wanted to use the Big Number Calculator that I've got there.  But it's possible to have it installed and keep it away from your browser.



So, oh, and I also saw this because I saw the note about asm.js, and I got a big kick out of Microsoft poking Google in the eye because asm.js is the Mozilla solution for superfast scripting, superfast JavaScript.  Google does not offer it.  Microsoft is supporting it in Windows 10 and in the next version of Internet Explorer.  So I thought that was - I saw that and thought, oh, okay, yeah.



LEO:  That's interesting.



STEVE:  Maybe Chromium will consider it.



LEO:  Yeah.



STEVE:  Yeah, it's neat.  The idea is that it is a subset of Java which can be compiled much more efficiently.  Java is a so-called "automatic language," where things like first use of a variable defines its type, and it determines a lot from context.  And it automatically allocates storage and then has a garbage collector to determine as best it can when that's no longer necessary.  All of those things impose a huge burden on the interpreter and end up slowing your code down.  But you can use a proper subset of JavaScript that deliberately eschews any use of those things.  And, boy, you can then compile that down to something that screams, which the beauty of that is you're still writing in JavaScript, hundred percent legal JavaScript.  Or I should say the compiler is because you'd rather take something like maybe a C# compiler and compile that to asm.js.  And then you've got something written in a high-level language which also runs on all the browsers that support asm.js.



LEO:  I'm a little confused by the interchangeability of Java and JavaScript.  You're writing Java in JavaScript?  Is that what you're saying?



STEVE:  No, I'm sorry, you're right.  His note brings them...



LEO:  You've confused the hell out of me here.



STEVE:  Yeah.  His note says...



LEO:  Why don't you use asm.js, which is a hyper fast JavaScript.



STEVE:  Which is also...



LEO:  And you could have recoded Big Num Generator.  But you'd have to rewrite it.  You didn't write the original.



STEVE:  Correct.  I think he assumed I wrote it because it was on GRC, even though on the site I do have a link to where I got it from and gave credit to the original author because the guy did a great job.



LEO:  We should also point out that it's fine to put Java on your system.  Disable the browser extension.



STEVE:  Correct.



LEO:  Disable browser support.  Use Java locally only.  And then Java is not any more dangerous than anything else.



STEVE:  No.  Java, in fact, is a very mature nice language.  The problem, the mistake Sun ever made was in saying, oh, think of how amazing it'll be if people can just download Java applets and run them in their browser.  Yeah, somebody called Adobe thought that would be really good, too.



LEO:  Well, you know, I have to say they did a lot about sandboxing.  I mean, they knew that there was a risk to that, and they thought they were writing something safe.



STEVE:  After a huge amount of pain.



LEO:  Yeah.



STEVE:  Remember how much pain we went through, I mean...



LEO:  Right.  Well, because of ActiveX we knew that the idea of running code in a browser is a bad idea.



STEVE:  Bad, bad.



LEO:  Local code downloaded to your browser is a bad idea.



STEVE:  Right.



LEO:  Anyway, it doesn't matter because that's ancient history.  Nobody uses Java anymore.



STEVE:  No.



LEO:  Anyway.  And can I ask you one question, Question 11 from Leo in Petaluma, California?



STEVE:  Yeah.



LEO:  We were talking about this on MacBreak Weekly, and I was curious about FaceTime versus Skype and whether one is more trustworthy than the other.  Both claim to be encrypted, do they  not?



STEVE:  Oh, I would - FaceTime, hands down.



LEO:  But that's because you trust Apple over Microsoft.



STEVE:  Well, it's because I trust at least Apple is making all the right noises.  We know that Skype has been compromised.  We know for a fact that Skype security can be monitored under request from the NSA.  I mean, if they shut down the relay servers so that now that no longer exists, Microsoft did a number of things specifically to allow eavesdropping on Skype conversations.



LEO:  Ah, okay, okay.  So, yeah.  Because one of the things I remember is Gary Kasparov, who was a world champion chess player.



STEVE:  Yeah, chess.



LEO:  He ran for President of Russia, and he said I will only use Skype because otherwise the Russian police are spying on me.  He trusted it.



STEVE:  That's the old Skype.



LEO:  Yeah, it was old Skype.  It was pre-Microsoft's acquisition.  So you're saying Microsoft has compromised Skype.



STEVE:  Proactively compromised Skype in order to make it a, I mean, and there was some logic to it.  I mean, they explicitly said we need to be able to comply with telecommunications warrants if we're served with them.  So under those circumstances we will.  Whereas Apple is at least still saying we will refuse those.



LEO:  Okay.



STEVE:  I mean, again...



LEO:  It doesn't strike me as exactly a technical difference.  It's more of a belief that one company is going to protect you more than...



STEVE:  If I had to, yeah, if I were asked which seems more trustworthy, I would say FaceTime is currently.  But if you really needed it, you'd want to layer a third-party TNO application on top.



LEO:  Right.  I mean, use Secure Voice or Silent...



STEVE:  RedPhone or Silent Circle, yeah.



LEO:  Yeah, because those are open source encryption technologies, and you know those are secure.



STEVE:  Yup.



LEO:  Whereas here I just - it strikes me you're saying - not you particularly, but the people in general are saying, well, I trust Apple.  And I think that that's a - I love Apple.  I'm not saying don't trust them.



STEVE:  Oh, and I've been screaming about the fact that I...



LEO:  And Trust No One is trust no one, not trust no one except Apple.



STEVE:  And the problem with iMessage, for example, is key management.  Apple does your key management.  And if you're outsourcing your key management, you no longer have TNO.



LEO:  Right.



STEVE:  Because they could easily, I mean, when I'm sending an iMessage out to multiple people, Apple has sent me all of their public keys, which I use to multiply encrypt the message out to each of them.



LEO:  Right.



STEVE:  Nothing prevents Apple from tossing the NSA in there.  There's no visibility into key management.  That's the problem.



LEO:  Yeah, and even the EFF in its scorecard which we've mentioned before...



STEVE:  Great, great site, yup.



LEO:  ...talks - and Cryptocat is all green checks.



STEVE:  Yup.



LEO:  FaceTime, I have to point out, is not all green checks.



STEVE:  Yup.



LEO:  But neither is iMessage, Kick Message, a lot of solutions.  There are really only a few that are, you know, OTR encryption is the way to go, and only a few - Signal, RedPhone we mentioned, Silent Text we mentioned.  Telegram, TextSecure, there are only a handful.  And FaceTime's not one of them.



STEVE:  No.  I mean, it's going to be the tools that are explicitly privacy enforcing.



LEO:  Right.  Okay.  I just wanted to clarify that.  Mostly I wanted to understand, is it a technical thing, or is it kind of a - it's almost political.  It's who you trust, who you believe.



STEVE:  The difference between them, yes.



LEO:  And we don't know of a technical - we suspect that Microsoft is, well, they even said they are, so I guess...



STEVE:  Yeah, they have said they are.



LEO:  The problem is secret courts.  That's the real problem...



[Crosstalk]



STEVE:  Yeah, yeah, exactly.



LEO:  That's the real problem.



STEVE:  Yeah.  Well, and arguably an outlaw law enforcement.  If you're hacking Gemalto's network in order to steal the private keys of the SIM cards, that's outlaw law enforcement.



LEO:  Right.



STEVE:  I'm sorry.



LEO:  It is.



STEVE:  You know?  Yeah.  And you're doing it to circumvent, oh, the court system that was put in place for allowing you to obtain those keys legally.  You're saying, oh, it's too much trouble.  We'd just rather have them all.  Trust us.



LEO:  Yeah, well, the other thing they say is, it's okay, they're not U.S. citizens, so who cares?



STEVE:  Yeah.



LEO:  Who cares?  They don't count.  Ah, what a world.  Steve Gibson...



STEVE:  Indeed.



LEO:  ...thank you for making this a much, much safer world for all of us.  If you go to GRC.com you can find this show, 16Kb audio of it, full text transcripts written by Elaine that make it very easy to follow along.  He also has SpinRite there.  That's his bread and butter, the world's finest hard drive maintenance and recovery utility.



STEVE:  Used to be the world's finest low-level formatting utility, but began to do...



LEO:  Can you do low-level formatting through SpinRite?



STEVE:  I took it out.



LEO:  Turned out the [crosstalk] stuff was better.



STEVE:  Yeah.  I mean, in fact, somebody had an old, old machine, and neither 5 nor 6 would run on it.  So I sent him a copy, actually I opened, I have a copy of 3.1 on the shelf up there.  I opened the box and took out the diskettes.  And then I think I mentioned how hard it was to get the copy of 3.1 to him because email is so tightened down these days.  So finally I put a link on the server and said, here, click the link, then tell me when you have, and I'll take it off.



LEO:  That's right.



STEVE:  So but that one will still - that will do low-level formatting on a drive from the '80s.



LEO:  I love it.  If you want audio and video of this show, you can get it from our site, as well, TWiT.tv/sn, YouTube.com/securitynow, iTunes, wherever you get your podcasts.  Or get the app.  There are podcast apps, yes, but also there's TWiT apps on every platform.  We don't make them.  We thank our third-party developers who do that.  You'll find them there.  Steve is @SGgrc on Twitter.  Follow him there for updates all week long.  It's a good place to ask questions, too, or GRC.com/feedback.  In two weeks we'll do a feedback episode.  What are we going to do next week?



STEVE:  Car hacking.



LEO:  Oh, that's right, we've got the car hackers themselves.



STEVE:  Yes.  We've got the guys who did the actual hack and can tell us how they pulled it off with all the kind of detail that our audience wants.



LEO:  Nice.  Can't wait.



STEVE:  Yes, yes, yes.



LEO:  Thanks, Steve.  We'll see you next time.



STEVE:  Okay, my friend.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#497

DATE:		March 3, 2015

TITLE:		Vehicle Hacking

HOSTS:	Steve Gibson & Leo Laporte

GUESTS:	Lee Pike & Pat Hickey	

SOURCE:	http://media.GRC.com/sn/SN-497.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's tamer-than-usual news; then we host a terrific interview of the team (recently featured on Sunday's "60 Minutes") who have been working with DARPA to address the challenge of hardening high-tech networked vehicles - autos and UAVs - against malicious hacking attacks.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here, and we have a great show planned for you, not only some security  news, but a little later on in the show an interview with the two guys who hacked the car Lesley Stahl was driving in during "60 Minutes."  We're going to talk about vehicle hacking and why it's going to be and may already be a huge problem.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 497, recorded March 3rd, 2015:  Hacking Vehicles.



It's time for Security Now!, the show where we protect you, your privacy, and your security online with this guy right here, Mr. Steve Gibson.  Yes, sir.  You going to do the "live long and prosper" for us in honor of...



STEVE GIBSON:  Oh, I have a little mention down in our Miscellany today because I had an encounter with Gene Roddenberry.



LEO:  We have an amazing show for you.  Coming up a little later on, we're going to talk to two guys who are kind of heavy-duty researchers in what they call, what, physical security?



STEVE:  They called it "cyber-physical security."



LEO:  Cyber-physical security.



STEVE:  That is, attacks against physical things that we care about, like driving down the freeway in our car.  Yes, I mentioned a couple weeks ago when "60 Minutes" had that segment showing a wireless hack of a car that the producer, Lesley Stahl, was driving.  And the person who was in the passenger seat was part of this team who said, "Okay, now, Lesley, pull up and stop in front of this line of orange cones."  So Lesley pulled up to them, put her foot on the brake, and nothing happened.  And I...



LEO:  That's scary.  She plowed right into the cones.



STEVE:  Yeah.  And it's interesting because, as I mention later in the show - I don't know how I know that I mention it later in the show, but I'm psychic [laughter].



LEO:  To pierce the veil of secrecy, we recorded the second half first because we wanted to let Lee and Pat, our guests, get going in their life.



STEVE:  I got out of my time machine and came back to meet with Leo.



LEO:  We edited this to be in a different order than the actual recording order.  In standard podcast order, right, with the top-of-the-show news and then our interview.  But it's surprisingly jarring, when all our lives we've pushed down the brake pedal, and the car slows down and stops. to push down the brake pedal and have the car not stop.  And it turns out that I was just naively assuming there would still be a physical backup; that we wouldn't entirely be relying on fly-by-wire technology.  But these guys explain in the future that in fact what's happened is pressures for lightening the weight, lowering the cost, adding features.  All of these things have sort of come together to turn these cars into rolling computer networks with upwards of 50 different so-called ECUs, the individual computers scattered around the car.  So, for example, there'll be DC supplied to the whole array of lights along the back of the car.  And the CAN bus runs over.  And over the CAN bus comes the instructions for which lights to turn on and off.  There isn't, you know, used to be there was a big wiring harness.



LEO:  A physical wire that goes to the back, yeah, point to point.



STEVE:  Right, where the big bundle of cables went back to all the specific lights that you want.  Now they just send it DC.



LEO:  But that makes sense because we're used to that with networking.  It makes sense.  Have a central bus and send signals to different components.



STEVE:  Yup, and in the future, one of these guys will say, yes, the CAN bus is the best network that the '80s could ever come up with.



LEO:  That's a pull quote from the future, ladies and gentlemen.  I look forward to that.  But we have some other security news to talk about, too, I know.



STEVE:  Yeah.  So this week we're going to talk about another SOHO router backdoor; an interesting but not-yet-perfect web-based encryption service, which is a little bit of a lesson for our audience I thought they'd get a kick out of.  And I just wanted to make a note of a blurb that came up during the week about creating an Internet service and having your life threatened.  And then two little blurbs about the evolution of DNS and search, some miscellaneous stuff, and then our main feature of the week, which is this report on hacking vehicles from the guys who have done it.  So otherwise there wasn't really much horrifying security news.  So instead, the entire topic of the show, having your car hacked is somewhat horrifying.



LEO:  Okay, Steve.  Let's see.  What have we got?



STEVE:  So this generated a lot of Twitter traffic because it seemed really severe.  Upon closer inspection, it's real, but it's sort of a corner of the 'Net.  Still I wanted to bring it to people's attention, if for no other reason than to reinforce the importance of something we've been long saying.



What was discovered by a couple of guys who reverse-engineered the firmware that they found on their own router - and these are security researchers who presented their findings to the International Conference on Cyber Security and Cyber Law a couple weeks ago, on February 21st, was that there was an undocumented backdoor because in their firmware the password "super," S-U-P-E-R, for both username and password was burned into, embedded and hidden in the firmware, alongside whatever username and password the user would assign.  So that meant that this particular router they had would respond, with no other documentation about this anywhere, if you used "super" twice for username and password.  And they then did a partial scan of the Internet and found more than 200,000 routers sitting on the 'Net into which they were able to log using "super" for the username and password.



Now, the good news is none of these are big brand-name routers.  Well, although Realtek is a name we recognize, although they're big for network interface cards, and TRENDnet is a name I know.  But Digicom, Alpha Network, Pro-Link, Planet Networks, Bless, SmartGate, and Blue Link are among the model numbers, makes and models of routers that they have found.  And these are all - it looks like there's some sort of an underground router firmware that's being shared, like these are sort of off-brand routers.  The hardware has become commoditized.  So you build commodity hardware, stick your logo on the front, and then you get this not-sure-where-it-came-from firmware that happens to have "super" as the username and password.  So maybe the bargain basement router is making you vulnerable.



The problem is that this particular router, as evidenced by the fact that at least 200,000 of them have been found, has the WAN admin enabled by default.  Which means all of those routers they were able to log into.  And right now today, those are all completely open to remote exploitation.  So, again, you absolutely want to make sure, not only that your router doesn't respond to "super" as its username and password, but that you have explicitly disabled WAN interface.  We know that that's not complete protection because we've been covering stories where routers will still respond to magic Ethernet packets or to funky packets on some strange port, because the designers of the router wanted to have admin access, sort of off the record.  Which is just not a safe thing to do.



LEO:  Did they say the brand?



STEVE:  Yeah, there's a bunch of these.  It's on that next page of the show notes, Leo, Digicom, Alpha Network, and so forth.  So they've identified...



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  What they did was they scanned the Internet and found all of these routers.  When they logged in, the routers said, yeah, I'm a Digicom.



LEO:  Hey, I'm Super Super.



STEVE:  Yeah.



LEO:  Hey, Super Super.



STEVE:  Exactly.



LEO:  Well, if you turn off WAN administration, then they'd have to have physical access.  So that at least - but there's no other way to mitigate that; right?  I mean, that's just built into the firmware.



STEVE:  Correct.  And so, again, the other lesson here, I think, is that what we're seeing is that router firmware is too much on the frontline to leave it up to the manufacturers.  I'm here to say now in 2015, given that there is well-documented, well-scrutinized, third-party, open source replacement firmware, that's what you should be using.  The Tomato firmware and the DD-WRT firmware, and there's another one, too.  I can't think of it.  Of course Astaro has their platform that you can load into a small, like a fanless PC form factor, and that would make sense, too.



LEO:  And, you know, we should also give a pat on the back to ASUS because they actually make - they sell routers with DD-WRT in it.



STEVE:  Perfect, yes, yes.



LEO:  So, I mean, the problem with DD-WRT is it supports a subset of all routers, so you've got to make sure you have a compatible router.  Or, if you buy one of these ASUS routers, it's in there, and upgrades are not coming from ASUS, they come from DD-WRT.



STEVE:  And I like their ad.  They said, "You spoke, we listened."



LEO:  Yeah.



STEVE:  Which is to say, you know, we're going to sell you a router specifically so that you are in control of the firmware.  And again, I think the router is our first line of defense on our networks.  And we're seeing too many examples of both deliberate and inadvertent exploitation of the trust that we put in the firmware.  It's time to revoke that trust, to say nope, I'm only going to run something that I know, essentially, as my interface to the Internet.



LEO:  But this is another case of the race to the bottom.  You're selling $30 hardware.



STEVE:  Yup.



LEO:  It's commodity hardware.  You're not going to put any effort into it.  Nor, and this is even worse, are you going to patch it.  You're just going to assume, eh, they'll buy a new one.



STEVE:  Right.  So those 200,000 people are probably toast.  They're people who did just buy some off-brand router at Staples that they had on sale because they were trying to move a bunch of them.  They said, oh, this is probably as good as anything else.  Well, no.



LEO:  Do you like DD-WRT?  Or do you have a preference?



STEVE:  I don't.  I like, I actually like what Astaro has done, just because it's got, for our audience, for the more technical audience, it is a very powerful solution.



LEO:  Yeah, that's a great way to go.  But that requires having PC hardware and putting the operating - yeah, it's complicated.



STEVE:  Multiple NICs and so forth, right.



LEO:  And there is OpenWRT.  Maybe that's the other one you were...



STEVE:  Oh, I think that was the other one, yes, yes, right.  And Tomato, a lot of people like the Tomato firmware.



LEO:  I've used Tomato.  I love Tomato.  But I think that's an even smaller subset of supported routers.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  So anyway, okay.  Next up, if you can show the picture of the week, Leo, I got just the biggest kick out of this.



LEO:  I love it.



STEVE:  This is actually a screenshot of Notepad after I decrypted a file under a new online service.  This is the GRC CipherSuiteOrdering.txt.  That's the file I've talked about which is just readable ASCII.  It'll say, you know, ECDH, Elliptic Curve Diffie-Hellman underscore CBC, you know, so forth.  I mean, it's legible, readable ASCII.  Except not in this screenshot.  So here's the problem.  This is a neat service that needs a little more work.  It's called InstantCryptor, I-N-S-T-A-N-T-C-R-Y-P-T-O-R, InstantCryptor.com.  The guys look like they've got their hearts in the right place.  It is a browser-based, on-the-fly, very simple to use, encryption/decryption service.  It's all done in the browser, and in the FAQ they explain it, and it all makes sense.  There's no reason why you cannot do this securely in today's JavaScript in the browser.



And in their documentation they explain:  "The password will be hashed with the SHA-256 algorithm.  The mode for encryption is 256-bit Rijndael/AES in CBC mode."  All of our listeners know what all that means.  "The file blob [meaning the resulting blob] will be read as an array buffer and fed into the encryption function.  The result is then uploaded to the chosen cloud service.  The uploaded files are displayed in the tool, and decryption works accordingly.  The code of the main JavaScript file is unminified, and the interested developer can have a look at it."  So I like that.  They're saying, here it is.  We're not obscuring the code.  We know you're going to want to see this for yourself.  So there it is.  And then they conclude, saying:  "The main action happens in the last two functions at the end of the file."



So what they have is this browser-based service, InstantCryptor.com, that runs under Firefox or Chrome, because you're going to have a little bit of browser centricity because it's using code for the specific JavaScript implementation where there may be differences between browsers.  And, you know, Microsoft is always lagging, so it's not running on theirs yet.  And it can target either Dropbox or Google Drive.



So I went there.  I said I want to use Google Drive.  And it took me to Google's authentication permission screen and said, "Do you want to allow this site to have access to your Google Drive?"  And I said yes.  So at that point it switched me back to there.  And they said, "Enter a password you would like."  So I typed in a password.  And then it said, "And would you like to browse for files?"  I clicked on the "browse," and I chose the CipherSuite text file that I just had sitting around, and I said, go, baby.  And in no time at all, it had encrypted it and uploaded it.



I then went over to Google Drive, and they had created an InstantCryptor folder, where all of my encrypted files from this service would live.  And it was absolute gibberish.  And then I thought, huh.  Okay, cool.  And so I then reversed the process.  But I was curious because nowhere did this mention authentication.  And so I used a different password to decrypt the file, and the results are what you saw.  It's a wonderful-looking unicode catastrophe.



So that's a problem because what that means is that they're doing encryption, but not authentication.  And we've talked about why this is important for years.  All good encryption not only encrypts, but authenticates, because although the nave user could be forgiven for thinking, well, if they don't know the password, then they're going to get gibberish.  But the problem is this also doesn't detect any either accidental or malicious modification.  And we know there have been attacks on SSL where authentication was not done correctly, where information leakage does occur.  So it's theoretically possible for someone to mess around with an encrypted file that does not have an authentication wrapper around it.



The proper thing to do, what these guys need to add, and I'm hoping somehow this message will get to them, is that after they encrypt, then they authenticate.  That is, they take the same password, or maybe a hash of that password, and they run it through, they use that to key an HMAC, which generates a message authentication code, and they add that to the end of the file.  That's what they upload.  Then when you go through decryption, the first thing they do before they decrypt is they authenticate.  So they take the password you provide.  They're already doing an SHA-256, but that's to get the encryption key.  They hash out again in order to get the HMAC, the authentication key.  And so they process the file, the encrypted file, as they did before uploading it.  They do it again before decrypting it.  And they verify that they get the same message authentication code as is tagged onto the end of it.



When that verifies, that tells them two things:  There has been no modification of the file, either inadvertently in transmission or by any malicious agent.  So it verifies the contents and that the password is correct.  So what they should have told me when I typed in the wrong password is, uh, sorry, that password is not the one used to encrypt this file.  And hopefully they're also doing some password hardening, that is, they didn't say so, they just said SHA-256.  If they're simply doing a hash of my password, then that's a problem because it would be possible to start doing a brute-force attack if they're only doing one SHA-256, and just look at the beginning of the file until they guess something that makes the beginning of the file look correct.



So anyway, it's sort of a nice little object lesson.  Simple, clean, cool service.  I imagine people might like to use it because you could, if you shared that folder, you could then send your password or have that known through some other channel, get it to somebody, and say, hey, I just uploaded a file, I just encrypted it because this particular one we care about.  You know the password.  And then they could get it.  Or you could take it and email it to them, whatever.  Anyway, just sort of a cool service, but missing a few important things for a service like this.



I'm sure you saw the news, Leo, that ISI has now essentially made a death threat against Twitter founder Jack Dorsey.  In an online post which has since been removed on the "Just Paste It" site they said:  "Your virtual war on us will cause a real war on you."  And then they had a doctored photo of Jack with gun sights centered on his face.  They're unhappy, that is, ISIS is unhappy - ISIS is apparently behind this - because Twitter is being sociably responsible and taking down the terrorist Twitter accounts as quickly as they find them.  And I guess Twitter has hundreds of people whose full-time job is responding to reports of this and verifying them and then taking fraudulent accounts down.  And it's just sort of a sad wakeup call that that's, you know, on one hand it demonstrates, I guess, that the Internet is as real as everything else in the world today, but it's also unfortunate.



LEO:  Also it demonstrates how media-savvy ISIS is.



STEVE:  Yes.



LEO:  And that's really the real story here is that they have, unlike other terrorist groups, figured out exactly how to play the game.



STEVE:  Yeah, well, they have camera crews and lighting consultants.  And it's just like, oh, lord.  Yeah, wow.  Now, this is interesting.  This is not a security story.  But we talk a lot about DNS.  And I thought this was really just curious.  And that is the news that Google has just paid $25 million for the entire .app top-level domain.



LEO:  That's a valuable domain, if you think about it.



STEVE:  Oh, my goodness, *.app.



LEO:  All you have to do is search for all the apps whose domain name is somethingapp.com to realize how valuable that is.



STEVE:  Right.



LEO:  Almost every app on iOS and Android has a website that is somethingapp.com.



STEVE:  So then it turns out this is not that new because Amazon last year paid 5 million for .buy.



LEO:  Oh, ho ho ho ho.



STEVE:  Also 2.2 million for .spot.  And until Google's 25 million purchase - and these are auctions, by the way.  So Google outbid everybody else who wanted *.app, essentially.



LEO:  Who gets the money from that?



STEVE:  That goes to ICANN to support all of the things that they're doing.



LEO:  They're doing good.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  And then Dot Tech, a company called Dot Tech paid 6.7 million for .tech, T-E-C-H.



LEO:  We should mention that this all - ICANN created this policy maybe a year ago, something like that, where you could register a TLD, any arbitrary TLD.  And if you had sufficient, I don't know what, funds, I guess, you could own it.



STEVE:  Well, yeah.  And so this is what I want to talk about because, for example, Amazon has applied for a total of 76.



LEO:  Wow.



STEVE:  They're called gTLDs, generic Top Level Domains.  And Google has applied for a total of 101.  So, for example, Google also wants .blog, and they want .cloud and .search.



LEO:  Wow.



STEVE:  And so here's two interesting tidbits from Google's application to ICANN.  For .blog they said:  "Our application for the .blog TLD describes a new way of automatically linking new second-level domains to blogs on our Blogger platform.  This approach eliminates the need for any technical configuration on the part of the user and thus makes the domain name more user-friendly."  Okay.  And I'll just read the second one, then we'll talk about this.  They also want .dev. So for .dev they said:  "Second-level domain names within the .dev proposed gTLD are intended for registration and use by Google only, and domain names under the new .dev gTLD will not be available to the general public for purchase, sale, or registration.  As such, Google intends to apply for an exemption to the ICANN Registry Operator Code of Conduct as Google is intended to be the sole registrar and registrant."



Now, this represents a complete change in the way - as demonstrated by the fact that Google is going to need an exemption to the ICANN policies.  Because Google is saying, now, traditionally what would have been done is it would have been dev.google.com.  But Google has a lot of money, and ICANN has said we'll sell global top-level domains.  So Google says, oh, good.  We want .dev just for ourselves.  We're going to use it internally; .dev will never be available for anyone else.  That's Google internal top-level domain name.  And they're saying this similarly about .blog.  We're going to buy, we're going to outbid anybody else for .blog and then use our blogging platform to automatically hook blogs to the .blog TLD.  So, for example, I have a WordPress blog, blog.grc.com.  And I've got my DNS set up so that blog.grc.com redirects to the IP address at WordPress so people can get to the blog.grc.com with that domain name, but it actually goes to WordPress.  And so what Google is saying is, eh, we'd just like to buy blog, please, and then it'll be Steve.blog will be the name for this.



So anyway, I just thought it was interesting.  I mean, as you said, Leo, it's generating a lot of money.  It's also taking potentially powerful global top-level domains off the market forever.  Now, I don't know that it's a bad thing.  They've never been on the market before.  And the counterargument is will anything ever really replace .com?  Consumers are so invested in .com being where you go that, you know, that's always the domain you want.  And when I see things that are, like, .net or .org, I think, wow, I hope people remember that it's a different suffix on the end of that name.



LEO:  Yeah.  No, I think we've seen this before.  Remember when Sex.com sold for some ungodly amount of money and was never really worth anything.



STEVE:  And XXX, triple-X, I think also did.



LEO:  Well, because everybody thought, oh, the generic, you know, TV.com went for a lot of money because the generic .com name is going to be somehow hugely valuable.  And then I think what happened is nobody really - who enters in dot anything?



STEVE:  Exactly.



LEO:  If you want to go to a site, if I want to go to GRC, I'll just type GRC into Google, and it'll bring me there.



STEVE:  Exactly.



LEO:  So I don't even know how relevant that all is anyway, anymore.



STEVE:  Agreed.  And in fact, that takes us perfectly into the second story because Google has also announced a skunkworks project that is apparently not yet public.  Well, I mean, I know it's not public, but it is private.  And that is that they have been building something for some length of time called a "Knowledge Vault."  And New Scientist has a story explaining that apparently all the big companies we know about - Apple and Microsoft and Google and, like, the main big movers on the Internet, they're all doing this.  We see this ridiculous falling cost in the cost of storage and the ability now to send bots out and suck in the whole Internet, which of course is the way Google's index works.



They've announced something called KBT, knowledge-based trust.  There's an interesting paper, a whitepaper that I've linked to in the show notes, which is full of summation symbols and differential calculus and, I mean, it is really toe-curling academic stuff.  But what they're proposing to do, in the same way we've talked about before, for example, the famousness of Google, the thing they did that immediately took us all away from Alta Vista that we were using at the time, is to rate a site based on the quality and count of links linking to that site.  That was a simple means for them to get a metric on the quality of a given page on a site.



Now Google is claiming that they've noticed that the Internet is full of misstated untruths and fallacies.  And they're not wanting to rank as highly sites containing untruth as sites containing true things.  And Google believes they have a way to mechanistically tell the difference.



LEO:  Wow.



STEVE:  Which is an amazing claim.  And so they're saying that they have this knowledge vault which contains 1.6 billion facts.  This automated knowledge vault has 1.6 billion facts.  And of those, 271 million are rated as "confident" facts.  And that means that Google's model ascribes a more than 90% chance of that being true.  And apparently it builds this huge cross-referenced fact base, knowledge-base structure.  And in the same way that Google said a while ago, and we've talked about it recently, that they're going to add whether sites are using security or not as an additional hint to the ranking engine in Google searches, they are saying, this is what they are proposing to do, that they're going to start affecting ranking results based on this knowledge vault's determination of the factualness, the truthfulness of individual sites.  And the world is changing.



LEO:  Well, and it also raises some issues.  I mean...



STEVE:  It does, yes.



LEO:  I mean, facts is facts.  But we may be not in agreement on whether something's a fact or not. 



STEVE:  Really.  Now, it's interesting because it used to be that you uprated yourself, if you were an SEO-crazed person.  I've never just bothered.  I just figured the only way to do SEO right is just have a site with high-quality content, and don't worry about it.  But of course that's not why you have an SEO department whose whole goal is to give you a high search order ranging.  But traditionally, you know, it was arranged to get inbound links and make your server run fast because it's also heard, for example, that Google is going to tend to increase the ranking of sites that are served faster because they want to encourage that, and they think that maybe the speed of the server is connected to the quality of a site.  I mean, they're looking for "signals," as they call them.



And so I agree with you, Leo, the notion of Google, who, I mean, Google is now a verb.  You don't go to a search engine to look something up, you "google" it.  And Google is our portal.  It's the way we view the Internet.  Anything I want to find out, Google is my search engine.  I put the term in.  I put a sentence in.  Sometimes I ask it a question.  And there's, like, there's my answers, right there.  So it's incredibly valuable.  And now they're adding this new twist which is, eh, we're going to try to downgrade the sites that are BS.



LEO:  Some stuff is verifiably factual.  But there are people who say we didn't land on the moon.  And...



STEVE:  I don't think we're going to be hearing from them anytime soon, Leo.



LEO:  Well, but, I mean, I don't know.



STEVE:  They're going to disappear.



LEO:  I'm sure they believe that what they're saying is factual.  Is it up to Google to decide that?



STEVE:  And, exactly, isn't that interesting.  Because the other controversial thing that has been reported is that when I pull up a Google search, and for example when Jenny pulls one up, we get different results.



LEO:  Right.  Because you're logged in, yeah.



STEVE:  Yes, we're logged in, and we have relationships with Google, and Google knows something about us and tries to give us the results we want.  Well, the problem is that tends to increase the fragmentation of sort of the community because it's sort of like a self-fulfilling prophecy or self-reinforcing selection.



LEO:  Yeah.  I mean, what if they had done this in the time of Galileo?  And, well, everybody knows that the Sun revolves around the Earth.



STEVE:  Yeah, yeah.



LEO:  That's a fact, isn't it?



STEVE:  Epicycles.  Epicycles, yeah.



LEO:  Yeah.  So that's a fact.  So facts...



STEVE:  Yeah, who is this weird guy?  Good thing that he doesn't show up in the...



LEO:  Can't find him in the Google search.



STEVE:  Yeah.



LEO:  I think that is a typical engineering point of view, that there are facts...



STEVE:  Boy, if you look at this paper, though, your eyes will cross.



LEO:  I did, I did, I looked at the math.  Holy cow.



STEVE:  Oh, whew, baby.



LEO:  Yeah.



STEVE:  And I will say, independently, the concept of an automated knowledge vault is intriguing.  I mean, we saw what IBM's Watson could do on "Jeopardy!."  It's like, okay, I'm giving up and going home.  Thanks anyway.  It was just shocking to see what it could do.  And so I think, with processor power becoming what it is, and storage becoming as big as it is, there's something, you know, we may still not know how the human brain works, but we may know how to model knowledge and regurgitate it and see how it referentially links to itself.  Wow.



So, Spock.



LEO:  Yes.



STEVE:  I'm sure everyone who is listening to the podcast knows that Leonard Nimoy died last week, 83 years old, COPD.  And I think he was not misquoted as saying that he wished he hadn't smoked as much as he did.  I think he gave it up, as I recall, but he spent a lot of time smoking.  And so he was in the hospital at the time and had been battling COPD for some time, so it didn't come as a surprise to people that were close to him.  And I heard you guys talking about it on TWiT.  There was a question about whether Shatner was going to be able to be there.  And first it was thought that he wouldn't be, but then I heard later that he was able to get on a plane and make it to the memorial.



LEO:  I guess so, yeah, yeah.  He had a charity event that he had to go to, but I think he managed to work it out, yeah.



STEVE:  Yeah.  And everyone knows that I've always been very much of the Star Trek generation.



LEO:  You can tell because those of us in the Star Trek generation practiced so that we could get our fingers to do that.  I can only do it on one hand, but...



STEVE:  Yeah.  And actually...



LEO:  It doesn't come naturally, I don't think.



STEVE:  The best man at my wedding was unable to do that.



LEO:  Oh, dear.



STEVE:  And I begged Gary, I said, because Gary had really a dark sense of humor, and I said, okay, now, you know, you're going to be asked to say something.  Please don't embarrass me.  Please.  You know, I mean, because lord knows what he could say.  And so he honored my wish.  And he got up with the microphone, and he said, "Steve asked me not to embarrass him, so I'm not going to."  And he held up his hand, and he had two rubber bands...



LEO:  Oh, how funny.



STEVE:  ...around each pair of fingers because he wasn't able to do the "live long and prosper" sign...



LEO:  Oh, that's funny.



STEVE:  ...without a little bit of help.  But I did hear during the news coverage of this, some people got the story wrong about why "Star Trek" only had three seasons.  They were complaining that it was - I think it was on at the wrong time.  The person that I saw talking about it, I think it was George Takei, actually, because he was interviewed on one of the shows, said that it was on at, like, 10:00 o'clock on a Friday night.



LEO:  Oh, that's terrible.



STEVE:  And, yeah, because, I mean, no one's watching TV then.



LEO:  Yeah, right.



STEVE:  But I had an occasion, I was at Comdex one year, and that's the year that I bumped into Stew Alsop, who was at the time the editor-in-chief of InfoWorld.  And he and I set up the deal for me to do the column, which initially was called "Behind the Screens," but there was a collision with CompuServe.  They had a trademark on that.  So then he said, "Steve, we can't call it 'Behind the Screens,'" so I renamed it "Tech Talk," which of course was the column that I did for eight years every week in InfoWorld.  We are at a bar hanging out and having a couple of beers, and he said, "Hey, do you have any dinner plans?" And I said no.  He said, "Well, I'm going to meet some people, and we're going to go to dinner.  Why don't you tag along?"  I said I'd be glad to.



So we go upstairs in the Las Vegas Hilton and knock on this random door, and someone opens it.  And there's some geeky-looking kind of heavyset guys just sort of lounging around, apparently waiting for Stew.  So we walk in, and they introduce themselves, and I don't remember anybody else's name in the room because one of the people there said "I'm Gene Roddenberry."



LEO:  Wow.



STEVE:  And at that point it was like, oh, my god.  Now, I'm not going to...



LEO:  All conversation ended.



STEVE:  I'm not going to start drooling and be the crazy born-again fan boy, everything.  But I did arrange to sit next to Gene at dinner.  And so I just said to him, you know, I'm a fan.  So I love sci-fi.  What you did with "Star Trek" was, I said - in fact, I did tell him, I think, that my buddies and I made a "Star Trek" movie, and I talked about that in the podcast, where we scratched the emulsion in order to make phaser beams and had arranged to have people stand under a chandelier and beam out and all that.  I mean, seriously geeky stuff.  Oh, and I talked about how we made the audio track because Scott Wilson's sister had stuffed bunny rabbits, and so the aliens were the Bunnons.  And we...



LEO:  The Bunnons.



STEVE:  And we used a still-frame camera in order to march them down the hallway and attack us and so forth.



LEO:  We are attacking you.  Yeah.



STEVE:  Yeah.  And that was where "yo-sha ba-di-dro, sna-na ba-na-ni, pa-shor-yor-nar-ros" came from.



LEO:  Aha.



STEVE:  Because if you reverse that, it comes out "We are the Bunnons.  Surrender your ship or be destroyed."  So, oh, yes.  Anyway, and so I said to Gene, "What happened?  We only got three years."  And he said, "Oh, there's an interesting story there that," he says, "not many people know."  And he said this was before the time that Nielsen was doing demographics.  Nielsen was in the ratings business, and they were just counting heads.  They weren't counting whose heads.  But they were collecting the data, they just weren't using it.  So based on the numbers compared to other shows that "Star Trek" was up against during the original Kirk and Nimoy and Shatner and Spock years, "Star Trek" really didn't do that well, compared to - just in terms of raw numbers.



Years later, Nielsen introduced demographics where they realized it was important to care who was watching.  Because five year olds weren't buying anything.  Neither were 70 year olds.  But yuppies in their 20s and 30s and 40s were buying cars and baby formula and homes, and it turned out that in the process of developing and tuning the Nielsen demographics, they reprocessed all of the data they had collected in the past, just because they had a database of it, in order to design their model.  Never in the history of television had there been a show that more exactly perfectly targeted the demographic that advertisers wanted than "Star Trek."  And no one knew it then.  And had they known it, it'd probably still be going today because it was exactly the audience that advertisers wanted.  And I just said, wow, that's a cool story.  And that's straight from Gene himself.



LEO:  Yeah.  That makes sense.  I mean, it's obvious in hindsight that the show was immensely influential.



STEVE:  Oh, look at the legs it's had.  It's changed our culture.  I mean, we have things like phaser beams and tractor beams and "Beam Me Up, Scotty."  All of that came from there.  I mean, none of that exists.  We're amazingly creative little monkeys.



Okay.  So you said you would see it last week.  I know that you've seen it since last week.  Our listeners haven't had your corroboration of my opinion of "Citizenfour."



LEO:  Oh, it was really good.  It was surprising because I'd put it off because I thought, I know the story, and it's going to be kind of grim, and it's just going to be slow, and I don't really need to spend two hours watching this.  But, you know, Laura Poitras did a really good job of adding drama.  And as you said last week, it's really interesting that she had the cameras right from the beginning.  In fact, Lisa and I were watching, and Lisa loved it, too.  And I said, "Oh, he's got the shirt on.  He's about to do the interview" that was the first, you know, I recognized the shirt.  And so, and that was, like, half an hour in.  So you really got a sense of - and I was staring at Edward Snowden the whole time because you could - he didn't - outwardly it wasn't really obvious that he was nervous.  But it was so clear that the guy was just really scared of what was about to happen.



STEVE:  Yeah.



LEO:  And knew that the NSA would not be happy.  And I feel like he was waiting for somebody to break down the door at any moment.  It was a really - the tension...



STEVE:  Oh, when you saw him twitching.



LEO:  He was very twitchy.



STEVE:  The alarm went off in the hotel a couple times.



LEO:  Yeah, wasn't that a moment?



STEVE:  And they're, like, oh, my god, you know.  And like someone knocked at the door.



LEO:  They put the T-shirt over his head.



STEVE:  Yeah, I mean, yeah.



LEO:  Wow.



STEVE:  Yeah.  Anyway, so I wanted to make sure - it appeared briefly on - the Huffington Post published an article, I guess it was yesterday, with a link to the show, which I presumed was legitimate because it was the Huffington Post, you know, not some PasteIt.com or something.  It turned out it was not legitimate.  I got a tweet back from - because I said, hey, you know, here's a copy of "Citizenfour," anyone who wants it.  It is on, you said, oh, yeah, it is on iTunes and HBO Go.  So I just wanted to - I wanted your confirmation of my opinion because, as I said, I loved it.  And I came out of there feeling something I really - with an appreciation I didn't have before, which was that even though - and I know you are of the same feeling.  Even though we are not crazy concerned about privacy, I came away with a deeper respect for the rights of those who are.  That is that, you know, privacy is a right.



LEO:  Yeah.



STEVE:  And if that's how we're going to define it, then we ought to honor that definition, rather than say it's a right and then not have it treated like one.



LEO:  It was also fun to see Ladar Levison in it, and Jacob Applebaum, although Applebaum I think has posted, not exactly a rebuttal, but, you know, and I didn't get a chance to watch it, so I shouldn't speak.  But somebody sent me a link.  The subhead was something like "Misrepresentations are justified for the greater good."  I got the impression that Applebaum might have thought that he was a little bit misrepresented in there.  But in any event, must watch.  And if I can find the video, maybe the chatroom can pass it along.  Just fascinating.  And of course we haven't seen the end of it.  I mean, I don't know much more material there is, but every week there's something new.



STEVE:  Yeah, yeah.



LEO:  It's incredible.  And here we are, 18 months in.



STEVE:  Okay.  So two more things.  I know also that you have also fallen in love with a previous show recommendation of mine.  I once explained that I normally like shows involving titanium endoskeletons with plasma-driven robots and such.  And so when somebody was recommending "The Good Wife" to me, that was about as far, as a title, off of, like, what kinds of stuff...



LEO:  Me, too.  Me, too.  Yup.



STEVE:  ...would appeal to me.  But it is fabulous.  And I know you've discovered it, and you've been running forward through it.



LEO:  Yeah, yeah.  Lisa and I are really enjoying it, yeah.



STEVE:  Yeah.  And so to that I wanted to add one more show, which is really coming on well.  It's in its third season.  So for those who like to binge, there's plenty there.  And that's, on FX, "The Americans."  Are you watching it?



LEO:  Oh, yeah.  I've seen a couple of seasons of it, yeah, yeah.



STEVE:  Okay.  Because for those of our listeners who haven't been, it tells a really interesting story of some embedded Russian spies in Washington, D.C., back in the Reagan era, so it's set back in time, Cold War.  And just, anyway, I'm loving it.  So I wanted to put that out there as another recommendation from me of, you know, not technical shows, but just really good television.



LEO:  Yes.  I agree.



STEVE:  And today voting opens for the Podcast Awards.  I don't know why the page says "Vote today, vote tomorrow, vote often."



LEO:  Well, there you go.  That explains a lot.



STEVE:  Maybe they want you to come back for advertising impressions.  I don't know.  I would love you to come back to vote for Security Now!.  So it's PodcastAwards.com.  I'm down at the very bottom in the Technology.  The first item in the Technology section is Security Now!.  I would love to win this year.  I just - we haven't won for a number of years.  I think it would be fun.  So I'd just like to see if our audience has the power to make that happen.  I imagine that they do.



Okay.  And this is totally crazy, but apparently authentic.  Some Cornell University researchers were wondering about epidemic outbreaks.  And so they decided to model what would happen if zombies were real.  So this is the "Zombie Outbreak" model.  There's a beautiful animated, automated tool on GitHub.  I've got the link to it in the show notes.  And Vox.com has the original link about the "zombie apocalypse science."  And this was legitimate mathematical modeling.  And if you just want the short version, you want to head to the Northern Rockies.  That, it turns out, in the event of the Zombie Apocalypse, is where you want to be.



LEO:  Oh, good to know.



STEVE:  Yeah, good to know.  But if you're curious, you might put in "zombies-usa," imagine that, into the universal Google search finder.  That will probably take you to the GitHub page that has that as its name, Zombies-USA.  And then it's just a beautiful - it's a map of the U.S. with bright spots showing population centers, and you can see what happens if the zombies decide to get restless.



And lastly, this I've been waiting on.  I've been sitting on this since February 24th, just waiting for its turn.  I got the biggest kick out of it because this was a Francisco Gomez, who wrote to Sue, who forwarded it to me on Tuesday, February 24th.  The subject was "Oh, my god, you guys are incredible/SpinRite."  And he said - this is not long.  So he said, "I could write a looong [with a bunch of o's] email, telling you how great you are.  But after 12 hours other people spent fighting and failing to get the data restored, you guys made me look like a hero in front of my wife.  Her IT department said she had lost all of her data.  But after using SpinRite and running chkdsk, I was able to extract all of the data, even when the hard disk drive was encrypted.  You guys are geniuses.  Sent from my iPhone."  So thank you.  And that's why the email wasn't very long, because he was typing it on his touch screen.  Anyway, thank you, Francisco.  I appreciate that.



LEO:  All right.  We've been waiting for this for a long time, Steve.  I'm very excited.  You mentioned this last week, that you would have these guys on the show.  And we even showed the video.  Was it Andrea Mitchell who plowed into those cones?



STEVE:  No, it was Lesley Stahl.



LEO:  Lesley Stahl, that's right, yes.



STEVE:  It was on "60 Minutes" a couple weeks ago.  One of their segments was talking about the problem with the current lack of real security in automobiles.  And I was just - I was floored by the idea that there was no longer a reliable connection between the brake pedal that the drive controls and the braking of the vehicle which the pedal is supposed to enact, essentially.  I mean, the idea, I mean, it's one thing to say, oh, we've got software because we want to have USB and play our iPhones through our cars, and we want OnStar, and we want to be able to approach the car and have the doors magically unlock and all these fancy things.  Oh, and I'd like to have the car know whose key is using it so that it automatically adjusts the seats so that it remembers the preferences of the current driver.



All of that is cool stuff.  But I don't, in the process, want to sacrifice the fundamental imperatives of the way the car works, that is, that the thing you need is when you press on the brakes, you stop.  And of course we know, what was it, about a year ago that Toyota went through the acceleration problems.  We never really got a straight answer about that.  There was some nonsense about, oh, the carpet was getting tangled up...



LEO:  That was their story.



STEVE:  ...in the accelerator pedal.  Okay.  And then a couple years ago we covered on this podcast the UCSD researchers who were working with, I think, University of Washington.  And that was sort of the first surfacing of our sort of low-concern that something was wrong with the way cars were being developed, that it just, like - and it's not surprising, either, because this is what we see time and time again is a system which is not computerized, then begins to get computers, but the focus is on making it work.  And only after the fact, sometimes after a great deal of pain, is making it secure.



So by happy coincidence, I was going through the Security Now! mailbag a couple weeks ago, and I ran across a note from one of the guys at Galois, which is G-A-L-O-I-S dotcom, who were the people who are shown on the "60 Minutes" report who are recipients of funding from DARPA because, just in the same way that the Defense Advanced Research Project Agency was the originator of the Internet, now DARPA has something called HACMS, sort of an awkward acronym, but the best way to pronounce it is HACMS, where they're funding various organizations, whether commercial entities or educational or research or governmental, whatever.  They don't really care who they're giving money to, but they've pulled together a project whose goal is to tackle the challenge of truly securing our cars.



And so for this week's podcast, thanks to their interest, I mean, they're Security Now! listeners, at least some of them, we have the guys who have successfully hacked, not only cars, but UAVs, to talk to us about the nature of the vulnerabilities, how acute the vulnerabilities are.  And their focus has been on working with DARPA and the other team members on coming up with ultimately and someday a true solution to this problem.



LEO:  Well, without further ado, let's say hello to Lee Pike and Pat Hickey from Galois.com.



PAT HICKEY:  Hi.



LEO:  Hi, Lee.  Hi, Pat.  Welcome.



PAT:  Thank you.



LEO:  Good to have you.  So what was the brand of car Lesley was driving?



STEVE:  No, no, no.  We can't...



PAT:  We've been asked not to.



STEVE:  So here's the point, is...



LEO:  That's all I want to know, so I don't buy it.



STEVE:  ...all cars have this problem.



LEO:  Yeah.



STEVE:  And they increasingly have this problem.  There are somewhere - as many as 50 so-called ECUs, sort of autonomous subassembly computer units, in a high-end car.  And even economy cars will have maybe half that, in the low 20s.  And so the reason the make and model wasn't shown was, first of all, they don't want to really upset anyone.  And it's really not fair to discriminate because all cars today are like this.



LEO:  Well, wait a minute.  All cars are like this?



STEVE:  Take it away, guys.



LEO:  I mean, you can hack my car?



PAT:  Probably not in specific.  What we've been part of is security researchers have found vulnerabilities.  We reproduced some of those to help the "60 Minutes" folks demonstrate that.



LEO:  So each model would have a different exploit.



LEE PIKE:  That's right.



PAT:  Yeah, or makes might have some components that are common across several model years.



LEE:  And many are going to be shared because it's all coming from the same suppliers, the subcomponents.



LEO:  Right.  What is the typical avenue of exploitation?



LEE:  Well, so it depends.  I mean, there's two kind of classes.  So one class of exploits is if you have physical access to the car.  And this makes it much easier because you can basically hook right into the data bus.



LEO:  Yeah, we've always said that.  If somebody has your computer, you're...



LEE:  Right.



LEO:  You're pretty much screwed.



LEE:  That's right.  Well, it's even easier than that because, if they have your computer, and you've got an encrypted hard drive, it's password protected.  There's some challenge to get into your computer.  There's no such challenge to get into an automobile.



LEO:  Interesting.  And CAN bus is the bus on most of these?



LEE:  That's right.



LEO:  We use CAN bus for our audio.  Can you hack my audio?



STEVE:  One of the problems, you could sort of divide attacks into two categories.  There's like a targeted attack where someone specifically wants to attack someone else, like Putin is unhappy with one of his adversaries, for example, and decides to go after them.  And then the other would be sort of opportunistic attacks.  And we see both classes of those attacks on the Internet.  And it turns out that the same sort of models apply here.  For example, the diagnostic computers in car dealerships are also connected to the Internet.  And so when that computer connects to your car, that's a standardized interface, and it's a means for the diagnostic computer to access the networks in the car.  And all of those little ECUs are firmware-reprogrammable, meaning that they can be attacked.



PAT:  That's right.



LEE:  Yeah, and furthermore, you know,  you can, with a computer, you need to actually grab it.  If you want to reprogram it, put a new program on it, you need to have access. But for convenience you don't want to have to pull out every small ECU in the vehicle.  So you can do this all over the bus, which makes it even more problematic.



STEVE:  For example, in one example of an attack, a malicious CD was put into the CD player on a car.  And believe it or not, cars have buffer overrun problems, just like we do in all of our regular software today.



LEO:  Yeah, yeah.  I guess the real concern, though, mostly, is what happened to Lesley Stahl where she was hacked remotely.  I mean, if somebody's got access to my car, I'm going to presume they can do stuff to it.  But the real scare is that I could be driving by somebody.  How hard is that to do?



PAT:  So pretty much all modern cars, the high-end ones, will have a telematics unit, which is a cell phone modem, a 2G or a 3G modem.  And the attack that was demonstrated in the University of Washington/UCSD paper was that you could call that cell phone number.  There was an in-band modem that had a buffer overflow.  So if you played all the right tones to it, you could reprogram its firmware and [crosstalk]; right?



LEO:  An audio hack, I like that.



PAT:  The telematics unit is your gateway into the system.  It's just as if you have physical access at that point.  So all the other attacks then can be executed.



LEO:  Wow.



STEVE:  Yeah, so basically you have a car connected to its own cell phone, and it's got problems in the software that can be overrun.



LEO:  It's got to be pretty targeted.  Is that right?  I mean, it's not going to be something that somebody could just say, oh, I see a car over there.  Or is it?



LEE:  Well, I mean, once you find the vulnerability, it's not going to be automobile specific.  So just like a computer virus or worm, right, once it finds a particular vulnerability in an operating system, any car with that telematics system is going to be vulnerable.



LEO:  Right, right.



PAT:  And the other strategy that these attackers showed was that the telematics units tend to all be in, like, specific phone number blocks.



LEE:  That's right.



PAT:  So the search space defined, oh, I know there's a car of this make and model parked in this parking lot.  Let's just sit here for a couple of hours until we guess the right phone number.  So it's doable.  It's not trivial, but it can work.



STEVE:  So probably the way to think of it is a little bit the way we think now of Windows and Mac and Linux.  Those three different operating systems all have vulnerabilities, but the same virus cannot attack all three of them.  You need an OS-specific virus.



LEE:  That's right, yeah.  And in addition, like I was mentioning earlier, you've got, even in different makes and different models, the same suppliers oftentimes delivering that software to multiple different vehicles.  So it could be a completely different vehicle and vulnerable to the same attack.



PAT:  Right.  And this isn't something that typically, like, consumers or even the car manufacturers themselves care that much about.  They're just buying an off-the-shelf part.



LEO:  Well, they will.



LEE:  That's right.



PAT:  I hope they will.



LEO:  Are there attacks in the wild already?  I mean, have you - or is this all theoretic?



PAT:  There's none that we know of.



LEE:  Yeah, other than key fob entry into vehicles.



LEO:  Yeah, right.



LEE:  That's been reported in the media, but...



PAT:  They tend to focus on the most profitable attacks first.



LEE:  Steal the car, in other words.



PAT:  Yeah.



LEE:  That's right.



PAT:  Others in the media have shown you can go on the black market eBays, essentially, and find a kit that does the keyless entry, some kind of buffer overflow or who knows what with the keyless entry.



LEO:  And the attacks you're talking about really would be more malicious or even murderous attacks.



PAT:  Yeah, but it also could be used for this exact same...



LEO:  To steal a car?



PAT:  ...like, car theft thing.  It's probably just that there are lower hanging fruit at the moment.



LEO:  Right.



STEVE:  I guess, too, that if you have a given piece of hardware that can unlock the doors only of a certain make and model, that's fine.  You just walk around the city looking for that particular car, and those are the ones you steal.



LEO:  Or you have the hack for the cars you want the most.



STEVE:  Right.



PAT:  Yeah.



LEE:  Yeah.



LEO:  We know the car thieves are looking for specific models, generally, yeah.



LEE:  I think it's important to remember, too, it's not just about people wanting to steal vehicles.  But as cars become more connected, you have your personal information on them.  People might want to track you.  Governments might want to track you.  You're vulnerable to these invasions of privacy, vulnerable to having your personal information stolen through the vehicle.



PAT:  Right.  Another attack that was demonstrated by the same researchers is, using the microphone that's for the phone calls or other functions to listen to whoever's in the car without them ever knowing it.  I think that one was demonstrated on "60 Minutes," as well.



LEO:  Well, mostly they're just going to hear me singing, and swearing a little bit as people go by.



STEVE:  And I guess then we're, unfortunately, for the last year and a half, we've been talking about the consequences of well-financed nation states' interest.  And this does unfortunately sound like the sort of thing that the high-end law enforcement organizations might task a division to go develop these capabilities for as broad a spectrum, as broad a class of vehicles as possible so that they have them available to them when they need them.



LEO:  We're talking to Lee Pike and Pat Hickey.  They're with Galois.com.  And they were, well, their technologies were featured on a "60 Minutes" piece with Lesley Stahl showing how easy it was to hack an unknown American - is it mostly American cars?  European cars have the same problem?  Japanese cars?



LEE:  They all have them.



PAT:  Yeah, all of them have them.



LEO:  It's all the same.  There's no advantage.



PAT:  Yeah.  I mean, we've heard either anecdotally or in published work from every single make and model that you can think of.



LEE:  If you get an F-150 from 1970, it might not be vulnerable.



LEO:  The dumber the car, the better.



LEE:  That's right.



PAT:  Yeah.



LEO:  Now, aren't auto - but I presume auto manufacturers are aware of this.  But, as I mentioned, their timeline for updating models is a lot slower than, you know, computers.



LEE:  That's right.



PAT:  Right, but [crosstalk].



LEO:  What are they doing to mitigate these problems?



PAT:  And the other thing we found is that car manufacturers are very cost-sensitive.  So if you have to add a TPM-like device, a Trusted Platform Module, which is used to secure some computer boot chains, if you had to add one of those to every ECU, it would increase the final sales value of the car by, like, thousands of dollars.



LEO:  Right, right.



PAT:  So the heavyweight solutions we're used to won't apply in this field, unfortunately.



LEO:  I remember talking to the folks at Ford, and they said one solution would be to have two computers, have the telematics computers separate from the computer that runs the car.  Is anybody doing that?  That's certainly a costly solution.



PAT:  I mean, that's actually the case now.  There are separate computers for all these separate tasks.  The problem is that they're all on a completely unprotected network.  That network has no authentication or access control.  So the telematics computer, once it's been reprogrammed through a buffer overflow somewhere, can start acting like it's the brake pedal sensor.



LEE:  And, you know, there's also a - sometimes safety and security are in tension with each other.  So you might think, oh, let me completely separate the cabin from any of the engine control.  But if you're in, say, an accident, and you've got sensors that detect a crash in your engine or near the front of the car, you might want to tell the cabin, you know, unlock all the doors so you can get out.  So it's not always obvious that you can make these security constraints.



PAT:  Right.  It can be difficult to completely isolate components.  And right now there's not very many good mechanisms for doing fine-grained compartmentalization.



LEE:  That's right.



PAT:  Which is generally part of every security story is the principle of...



LEE:  Least privilege.



PAT:  ...least privilege.



LEO:  Right.  Well, so sharing a bus is inevitable because they have to talk to each other.



PAT:  Right.



LEO:  But you need to have some procedures in place to.



LEE:  And one thing that's problematic is, you know, in particular you've mentioned the CAN bus already, and it's a broadcast bus.  You know, there's no time division.  And it's got a very small payload size.  So it's really incompatible, it wasn't designed for having any kind of security.  So it's very difficult with - and that's not going to go away any time soon.  There's too much infrastructure around it.  It's a cheap bus.  People know how it works.



PAT:  Right.  I mean, there are upcoming buses that'll allow, like, upgrades to CAN that allow higher bitrates so you can actually start adding signatures on every packet.  Whereas right now there's only an 8-byte payload.  So...



LEO:  Oh, wow.



PAT:  ...even if you only - if you gave up just one byte for a signature, well, then it'd be easy to guess; right?  And you'd have given up a quarter or an eighth of your space.



LEO:  I didn't realize it was so unsophisticated.  This ain't Ethernet we're talking here.



LEE:  No.



PAT:  This is the finest field bus 1980 could design.



STEVE:  So, okay.  You guys' focus has been on fixing this.  So talk to us a little bit about the notion of provably secure systems.  And we ought to also mention that you have also been spending time on the whole UAV issue.  And we were talking before the show that of course, oh, yeah, no one's ever hacked a UAV.  They're completely secure.



LEE:  Yeah.  So our specialization at Galois in general is a branch of software engineering called "formal methods."  And the idea is, rather than giving you incomplete evidence about the correctness of a system that you get through testing, the realization is that software fundamentally is a mathematical system.  And we can prove properties about this.  So rather than just trying to test and, you know, always missing bugs, let me give you a piece of software where I've proved the correctness once and for all that, no matter what inputs it gets, it computes the right values.  And so using these techniques we've developed, and we've been applying these to the embedded system world in particular for this program, so that the kinds of things that we've talked about here just aren't possible, so things like buffer overflows.



LEO:  That's interesting that you could prove correctness.



LEE:  That's right.  And this isn't a new idea.  So this has been around for, well, nearly since the beginning of computer science.  But so one of the things that makes it possible today is that, because of the power of computers, before you had to do these proofs by hand.  So literally you're a mathematician.  You're sitting down with a pencil and a piece of paper.  And this works for a 10-line program, but it doesn't scale to a hundred-line or a thousand-line or a million-line program, especially if it's concurrent.  But with more powerful processing, with better algorithms, we can actually have the computers do the proofs for us.



LEO:  And these are not brute-force kind of testing every possibility.



LEE:  No.



LEO:  This actually mathematical proof.



LEE:  That's right.



PAT:  Right.



LEO:  That's impressive, wow.



STEVE:  Algorithmic theorem proving sort of process.



LEO:  Yeah, that's amazing, yeah.



LEE:  That's right.  And this has been taken up in the hardware industry.  So, for example, Intel, after the FDIV bug, started doing this in designing hardware.  And there the payoff is obvious; right?  It's very hard to patch, well, you can't really patch hardware.  So they have to get it correct.  Part of the problem is that in the software industry we've had this kind of sense that, oh, you know, software, we can always fix it after the fact, or how hard is software to write?  And so we just haven't been applying these same approaches.



STEVE:  And I think, again, where the industry is, what we've seen, as I mentioned, we're seeing it now with the Internet of Things.  People are finally beginning to - people jumped on the concept of having their refrigerator on the Internet so they could talk to it at work for some reason.  That was all good.  But immediately those Internet of Things things started getting hacked.  And really, as soon as you have telematics systems, where cars have cell phones, and they're able to use technology to call 911 if the car has some problem, or the OnStar system, or you need to ask to get your car unlocked because you locked your keys in somehow, all of that stuff, now our vehicles, our cars are Internet of Things vehicles that unfortunately move at very high speed and carry our bodies around in them.



LEO:  Yeah.  Kind of want to make sure that's reliable.  It's not like a rocket to the moon; but, hey, you know.



LEE:  Right.  So, you know, in the academic world, people call these things cyber-physical systems (CPS).  So the idea of we're having software-intensive computers meeting physical systems where they can kill you, they can destroy property.  So this is, yeah, this is [crosstalk].



PAT:  Nonmaterial harms like privacy invasion, as well.



LEO:  We're talking to Lee Pike, who is the research lead at Galois for cyber-physical systems, and Pat Hickey, his colleague.  They are the ones who demonstrated on "60 Minutes" hacking a car while Lesley Stahl was driving it, a very brave thing of her, as it turns out.  Somebody in the chatroom asked, are more modern vehicles like, let's say, Tesla, less prone to this kind of thing?  Or are they even more so because they're so reliant on electronics?



PAT:  Yeah, the increased reliance on electronics is just - right now there's not the kind of culture where they focus on the safety first.  They focus on the features first because that's what people buy; right?  They can understand it from...



LEO:  Oh, yeah.  My Audi, my brand new Audi has lots of gizmos and gadgets in there.



PAT:  Right.



LEO:  That's not necessarily more secure.  That's probably less so.



PAT:  Oh, right.  In fact, most of those are like new attack surfaces; right?



LEO:  Great.



PAT:  Every cell phone it supports connecting to is a fresh stack to look for a buffer overflow.



LEO:  Right, right.  I know you don't want to speak specifically about any brand, so we'll table the conversation about Tesla.



STEVE:  Well, and one question I have is have you seen any evidence that there is any specific manufacturer who is extra good about this?  Or are they all just so hampered by the CAN bus and the legacy load that they're dragging forward that they're just more concerned about the shape of the exterior metal than they are the composition of the internal code?



LEE:  So I don't know if I want to speak about any particular manufacturer.  But I think there has been - the work has been a wakeup call to the industry in general.  And there's committees looking at improving the security of automobiles, people taking this more seriously, even on the safety side, for example, with the Toyota case.  So I'm somewhat optimistic.



PAT:  Right.  The real problem is that right now car manufacturers might leave out seatbelts if they weren't required to, you could cynically say, if they weren't incented to by regulations.  And there are no incentives from, like, any kind of regulators about cybersecurity yet.  And that's something that I can personally hope will happen in the near future because I think we do need it.



LEO:  And we've always seen tradeoffs between security and convenience, as you talk about that all the time, Steve.  And then somebody in the chatroom is pointing out buyers would probably rather see a car start up faster than have a slow check for authentication.



PAT:  Right.



LEO:  That would be seen as a detriment, even though it might keep them more safe.



STEVE:  There's a presentation by the gal who's been running this DARPA project, the HACMS project.  And she referred to - so she is in the middle of this.  She knows all about what they're doing.  She's participated in the R&D.  And she had an interesting observation to make which was - which essentially we saw on Lesley Stahl's face on "60 Minutes."  And I imagine that this kind of publicity does more to incent manufacturers to try to be able to say "Our cars don't have this problem" than anything else.  But Kathleen, who is with this DARPA project, explained how unnerving it was when she was driving a car and knew what was going to happen, she knew - I mean, she was in an area where it was safe, she wasn't actually going to run over anyone or damage the car - that when the car was hacked, and she hit the brakes, and nothing happened, I mean, it was viscerally jarring because from the first moment we get behind the wheel when we're 16, every single time we press the brake pedal, the car slows down.



And you can imagine the panic.  In fact, we've seen it on Hollywood movies for years.  Back then it's someone drains your brake lines overnight, and you live at the top of a steep winding road hill, and now you're in trouble because you're pumping on the brakes and nothing is happening.  But that's the sort of thing which hacking vehicles today means.  I'm just stunned that - and this is what surprised me was that the electronics is in even the braking loop, that there isn't still like a fallback.  And I understand, you know, I guess regenerative braking is certainly one reason why you're actually not braking in a traditional fashion.  In a hybrid vehicle, you're wanting to capture that energy and put it back in the battery.  But on a car with disk brakes, I would like to know that there's an actual...



LEO:  An override.



STEVE:  ...mechanical, yeah, mechanical linkage.



LEO:  I presume handbrakes are, but they're disappearing.  Modern cars have electronic brakes.  I don't have a handbrake in my car.



PAT:  Yeah.



STEVE:  And Kathleen mentioned on this video that the ECU, there's an ECU in charge of your seatbelt tensioning.  Can you imagine if your car suddenly grabbed you?



LEO:  My car grabs me all the time.  Oh, but, you mean for other reasons, yeah.  Unexpectedly, yeah.  So this is a bad trend, really, the move towards fly-by-wire, or as somebody in the chatroom said, die-by-wire vehicles.



LEE:  Well, it's, I mean, so I think the other side, to play devil's advocate, is that you can have more advanced, say, braking, or more advanced control.  You can have a lighter, cheaper system that you build because you don't have to put in hydraulics; you don't have to put in physical connections.  And so to the end consumer, I've got a more advanced vehicle with more features that's cheaper and more fuel efficient.  That's as good as it gets, except for the security aspect.



PAT:  I think, you know, there's a lot of smart automotive engineers that really know how to make good design tradeoffs when they're building cars.  But the design tradeoff they don't have in their mind or maybe aren't weighing high enough right now is security.  And that's something that I think is fixable.  And there's just, you know, many steps are going to be required to fix it.



LEE:  And we need to decide - go ahead.



STEVE:  No, no, I'm sorry.  Go ahead, Lee.



LEE:  We need to decide as a society, too, right, what the limits that we're willing to - what kind of costs we're willing to incur for extra security; right?  So we could have a perfectly secure, basically everyone driving an Abrams tank.  But no one wants to pay for that.  You know, it's not fuel efficient.  And so there's a tradeoff.  And in commercial aviation there's legislation; right?  It's not up to the individual manufacturer to decide what that kind of reliability is.  And we don't quite have that yet in the commercial automotive world.



STEVE:  So, yeah, I was going to say that I guess that I was wondering whether the best we could expect is pretty much to follow the same course we've seen with consumer computers, where finally, after a long time of email scripting being enabled by default, that finally got turned off because it was causing so much havoc.  And so incrementally, but really arguably very slowly, we're moving forward.  And even today we're still getting, you know, CryptoWall is encrypting people's files, and we've got spyware now in the ads that we've been talking about.  We were talking about Komodia just last week.  And so on one hand, it would be sort of pessimistic, but maybe realistic, to think that we're going to have to go through the same process.  On the other hand, it is, as you were just saying, Lee, the case that the automotive industry is subject to a great deal more functional regulation than somehow the PC software business has ever been put under.



LEE:  Correct.



STEVE:  Maybe just because of history.



LEE:  So, but, you know, legislation tends to just ignore - so, you know, we talk about boxes, right, like you deliver some sort of unit that may or may not have software in it.  But the software is just treated like a black box.  And you just assume that the software works correctly.  And I think that kind of mindset we need to move away from.  And so, you know, a lot of times the automotive manufacturers who are integrating the systems, they can't even see the software.  It's proprietary.  The suppliers provide it.  And so there's no, you know, we just assume that it works correctly, but of course it's not the case.



DAN:  I think the angle on how our work fits into that is, you know, right now I'm sure every one of those suppliers has a QA manager.  And that QA manager goes to the sales team and says, here, here's what you can tell the manufacturers, that it must be safe because our team used a bug tracker and used source control and used some automated...



LEO:  There you go.



LEE:  ...you know, Coverity, maybe, it's like a code quality metric.



LEO:  Right.



LEE:  Just for instance.  And that's wonderful.  But you have to trust that the team did their jobs, and without very much visibility into that team, and without, you know, it's very hard for a third party to verify that a bunch of humans did an activity correctly.  The idea with formal methods is you don't have to trust the process that created the artifact, but you could do a test on the artifact that would prove the properties about it.



LEO:  Is this form of verification commonplace in the auto industry?  I mean, are they aware of this, even?



LEE:  There's some awareness.  So as far as I know, the main application that, you know, across the software world in general is static analysis, so the idea that there's vendors who have tools that will run over your source code and try to find vulnerabilities.  There's two problems with this in general, though.  So they're great, and everyone should be doing this.  The tools have really come along.  But they give a large number of both false positives and false negatives.  So, you know, you might see a whole bunch of reports, but the engineers, you start - your eyes glaze over because there's too many false positives.



STEVE:  Positives, yeah.



LEE:  The other problem is that one might argue that this is at too low of a level for some of the properties that we care about.  So, you know, all you can really - it's not going to tell you, does your software implement the function that you implement, because that's in your mind, or it might be in comments, or maybe there's a couple of assertions.  So this is really just saying have you written your C or C++ correctly.  And so some of the verification work, and the most important verification work, is at the architectural level, so looking at things like data flow, looking at things like the networking.  And so we're doing work and research in that area, as well.  So before you even write a line of code, is your design correct?  There's a nice paper from Amazon, actually, recently about using - they've recently taken up formal verification in designing some of their highly distributed algorithms for the data centers.



PAT:  Yeah, a lot of those are for databases where the algorithms are really just too complex for a human to do in their head.



LEE:  That's right.  And it's not even about the source code at that point.  So they talk about the benefits of using formal methods tools to find out is this algorithm going to work?  Are there bugs in it before they even write a line of code?  Because once you've written the code, it's kind of game over.  It's so hard to go back, try to fix bugs, if there's a fundamental design flaw upfront.



LEO:  I wonder if heads of state in their big armored limousines, they must, I mean, there must be, somewhere, somebody who's really paying attention to this.  They would be targets, I would imagine.



PAT:  I don't know anything about that in specific.



LEO:  I'm just thinking that it seems like a real great opportunity for bad guys.  And I think you make an interesting point, that the methodologies that are used currently in software development for PCs just - it's just not going to be sufficient...



LEE:  That's right.



LEO:  ...for this kind of platform.



PAT:  Right.



STEVE:  I saw in one of...



PAT:  I guess the stance on security needs to take it from the beginning to produce a secure system.  Security isn't something you can bolt on afterwards.



LEO:  We've talked about that a lot, haven't we, Steve.



STEVE:  So, yeah.  So, okay.  In one of the papers I actually saw an acronym that chilled my blood.  And I needed - I'm glad I have you guys on the line because there isn't actually an SQL, a SQL Server, in any cars today, is there?



LEE:  Yeah.



PAT:  You know, who knows?  If you have an MP3 player in your car, that might be a Linux application that's backed by SQLite.  I would implement it that way, probably.



LEO:  And it's certainly in your phone, so...



PAT:  Yeah.



LEE:  Yeah.



PAT:  So why not?



STEVE:  Yeah, yeah.



PAT:  I mean, these are great tools.



STEVE:  There was a mention of SQL injection attacks.  And I thought, oh, my lord, we really aren't learning anything.



LEO:  You've got to cover everything.  So I'm curious, as we start talking about autonomous vehicles, I mean, I don't think an autonomous vehicle is necessarily more vulnerable.  If you could take over the system, you could take over the system.  Doesn't matter if a human or a computer is driving.  But I wonder if the move toward autonomous vehicles will support you guys in the sense that people are going to be more aware of the potential risks, and they're going to pay more attention to correct this and so forth.



PAT:  Yeah.  So certainly a vehicle being autonomous helps people think of that problem a lot more clearly, like, okay, I'm going to be giving it commands from my desk.  But how do I know somebody else can't do that?  It helps break away that abstraction of the human being in control by proximity.  But as far as, like, certification goes, or the culture of security goes, I think that's just totally on a case-by-case basis, whether the people building that particular system cared about this enough, or whether they didn't.



LEO:  Right.



LEE:  But I would actually argue that, you know, autonomy, it introduces yet another vector of attack.  So there's just a whole bunch of software there.  And then, furthermore, now we're talking about a whole bunch of additional sensors that your vehicle, aircraft or automobile, is now dependent on.  So, you know, if your GPS - your car might use GPS coordinates to help you navigate.  But if your car is actually using GPS, the autopilot, to navigate, well, then, you know, we have to think about what happens when there's a denial of service, or someone's attacking some of the sensors.



LEO:  And it's interesting, you also mention it's not merely to take over the car to steal it or to disable the brakes to kill the occupant.  It could be a privacy - used to invade privacy, as well.



LEE:  That's right.  And there's even new standards that are being proposed by the Department of Transportation, so vehicle-to-vehicle communication is what it's called, the idea that this allows, regardless of the make or manufacture, different vehicles to communicate with each other so that you can do collision avoidance is one of the main use cases.



LEO:  Mmm, right.



LEE: But this is, you know, so there's a nice safety argument for this.  On the other hand, you can use the same infrastructure, perhaps, if it's not implemented correctly, to track vehicles.  So if every vehicle is broadcasting where it is, if everything's using a public key infrastructure, and it's not done correctly, you might be able to determine, you know, where's someone going, what are they doing, without having to, say, physically bug the vehicle.



PAT:  Right.  We've seen over the years lots of attacks that, without attacking the PKI specifically, there are various other ways that you could differentiate certain cars from each other, or, sorry, certain computers from each other and make very educated guesses about that being the same computer, as you saw before.



LEO:  Well, this is exciting, isn't it, Steve.  Isn't that special.  Really, what I find interesting is Lee and Pat's background and kind of almost a higher level of academic research and proving software correct and so forth.  And it sounds like we need to use a variety of disciplines going forward to protect ourselves.  And, you know, it's frankly not just cars anymore.  Everything.  It could be elevators next.



LEE:  Yeah.



STEVE:  Well, and they have a great paper, I linked to it in my Twitter feed, titled "Securing the Automobile:  A Comprehensive Approach," which is, like, maybe, oh, it's 10 pages long, although the last page is all references.  It looks like maybe the last two pages are all references.  And it is exactly that.  It's academic and scholarly, and it talks about the development of formal software proofs for the correctness of this.  And I guess I like it because I'm glad that DARPA is once again spending taxpayer money to encourage individuals with the proper experience and talent sets and backgrounds to consider how we fix this in the future.  Maybe not today.  Maybe not the next model year's car.  But at some point it'll probably be some catastrophe that occurs, as is so often the case, that finally is a wakeup call and makes Congress move and puts a mandate in.  And we'll be annoyed that it'll have a 10-year implementation horizon, but the automakers will have argued that that's how long it takes to move the whole supply chain up.  And a decade later, we may have the fruits of the labor that these guys are investing in right now.



LEO:  Lee, are you any relation to Rob Pike?



LEE:  Not that I know.



LEO:  Okay.  Just chatroom wanted to know.  And, you know, there's an article in the Huffington Post.  Richard Clark is a national security expert, advisor to many Presidents, speculating that a journalist who was killed in an early morning auto accident last week might have been killed, he said it was consistent with a car cyber attack.  So, I mean, I think that may be a little bit sensationalistic.  But I wonder how long before this kind of stuff starts hitting the...



STEVE:  So we're calling them cyber-physical, cyber-physical attacks.



LEO:  Cyber-physical, yeah, yeah.



STEVE:  Wow, okay.



LEO:  That's what these guys are experts in.



STEVE:  We will add that to our lexicon.



LEO:  Hey, it's great to talk to you.



STEVE:  Thanks very much, guys.



LEO:  Lee Pike, Pat Hickey from Galois, G-A-L-O-I-S dotcom.  Really appreciate your taking the time to join us today.



PAT:  Thanks for having us.



LEE:  No problem, thank you.



STEVE:  Thanks, guys.



LEO:  What an interesting subject.  I just - I find that fascinating.  And I really - we've kind of talked about this before, the idea of proof of correctness in software.



STEVE:  Yeah.



LEO:  Which really does seem like the realm of the academic.  But if it's possible.



STEVE:  Well, yeah.  And I think Lee put it exactly right, and that is, it's a little bit like the puzzle I solved, the longest repeating strings problem, because some people tweeted back and said, oh, that's been solved, it's on Wikipedia.  And it's like, yes.  It's been solved for toy problem sets, like for very small corpuses.  It's trivial to do.  You build a substring tree, essentially, and then you just ask that tree where the longest repeating string is, and the tree expresses it.



The problem is, for a huge corpus, you can't build the tree because the size of the tree explodes.  Similarly, you can do trivial software proving systems that can prove that where you express what an algorithm is going to do, the software is able to take that machine definition expression and analyze the algorithm and verify it.  And exactly as Lee said, the problem is it doesn't scale.  It just, I mean, or I should say until recently we haven't had the power of the computers and the RAM necessary and the formal attention.



There's, again in this DARPA presentation, it shows an exponential improvement in the strength of software-based correctness proving.  And essentially in the last 10 years there's been a series of breakthroughs that have made it far more practical to begin to apply this kind of technique where you can finally say definitively, you have a definitive counterargument to the complaint that all software has bugs.  It's like, well, we can actually mathematically prove that some doesn't.



LEO:  Fascinating.  Steve, what a great show.  Thank you.



STEVE:  Absolutely.



LEO:  Lots of fun.



STEVE:  I was so tickled to get the email from these guys saying, "Hey, we watch Security Now!, and we're the guys that were on '60 Minutes.'"



LEO:  Cool.



STEVE:  So I'm glad we could have them, you know, put a face behind the story.



LEO:  Galois.com.  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility, all his great freebies.  More work on SQRL coming down the pike.  It's getting exciting now.



STEVE:  Yeah, we've got iOS clients and Mac clients and a whole bunch of different web server platforms.  So we're getting there.



LEO:  You can also leave questions for him next week if, the good lord willing and the creeks don't rise, we'll have a Q&A episode.  Go to GRC.com/feedback to leave your question, or tweet Steve at @SGgrc, and we'll try to get your questions on.  Steve has 16Kb audio versions of this show on his site, along with great transcriptions from Elaine Farris.  We have full-quality MP3s and video and all of that stuff at TWiT.tv/SN.  You can also subscribe to any of those formats on iTunes or whatever you use on your smartphone or your mobile device.  But do subscribe because you don't want to miss an episode.  And you don't want to be one of those people who says, "Steve, I've started listening at Episode 1."  There's almost 500.  It's going to take you a while.  Subscribe now.



STEVE:  Yeah, there are, like when we did that set on how the Internet works and how CPUs...



LEO:  Good stuff.



STEVE:  Remember the whole processor architecture stuff?  There are some gems back there.



LEO:  Thanks, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#498

DATE:		March 12, 2015

TITLE:		FREAK and RowHammer

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-498.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with several VERY interesting security events and stories of the week.  Then we take a deep dive into two of the week's big security stories:  FREAK and RowHammer.



SHOW TEASE:  It's a little early in the morning, but Steve Gibson is here.  He's back.  He's got a little bit of a cold.  But we're going to talk about two major exploits, you've probably read about them in the headlines, FREAK and RowHammer.  We'll also look at Microsoft's Patch Tuesday update and a lot more.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 498, recorded March 12th, 2015:  FREAK and RowHammer.



It's time for Security Now!, the show that protects you and your loved ones online, in this case a very early edition.  Hey, Steve Gibson.



STEVE GIBSON:  Hey, Leo.  Great to be with you, a little bit later than usual in the week, but here nonetheless.



LEO:  You almost made it 500 shows without getting sick.



STEVE:  Oh.  Oh.



LEO:  Steve never gets sick.  And I guess you got a bad - sounds like a cold.



STEVE:  It's funny, I realized I've sort of forgotten how.



LEO:  How to be sick?



STEVE:  Yeah.



LEO:  You probably don't have any cold medicines in the house or anything.



STEVE:  No.  There's sort of a protocol, like okay, now I do this and this.  It's like, I was, like, rediscovering.  It's like, okay, well, that's interesting.



LEO:  So we missed our Wednesday.  And by the way, even though we made great pains, put it on the front page of the website, I tweeted it, you tweeted it, still people said, "Where's my Security Now!?"  People love the show.  And so I'm glad to say, even though it's late, you will get a Security Now! this week.



STEVE:  Absolutely.  So, yeah.  Some tweets I saw said, well, there goes my Wednesday commute.



LEO:  I know.  People are hooked.



STEVE:  It's like, okay, well, you know, how about Friday?  You can wrap up the week with a Security Now!.  And as it turns out, the fact that you were able to run MacBreak Weekly long on this particular Tuesday was fabulous because you had a really great panel, and it was a marathon, a three-hour marathon.



LEO:  It worked out well.  It worked out well.  We did a three-hour, which we couldn't have done.  So, yeah, no, it was actually serendipitous.  However, here we are.



STEVE:  So this was set to be a Q&A, but two really important and interesting things happened that just can't be covered briefly, or shouldn't be.  And that is something called FREAK, which is an acronym for something, doesn't really matter what, and RowHammer, which is a surprising, recently surfaced weakness in DRAM which - I guess I would characterize RowHammer as not really a side-channel attack; but, if you really, really, really, really, really, really, really want to exploit a system and have no other means, this might work.  So...



LEO:  Sounds the kind of thing the NSA really likes.



STEVE:  Yeah, I was going to say exactly that because the details are specific to the processors and chips.  And so it's the kind of thing where the NSA might say, "Oh, look, he's got one of those laptops, so let's hammer him."  So anyway, so that's a - so today's podcast will cover those two things in detail.  And then we'll do the news of the week first.  So I think everyone's going to be satisfied with our slightly delayed podcast.



LEO:  Sounds excellent to me.



STEVE:  We'll talk about Patch Tuesday, which happened.  The news that the CIA has been dogging Apple's encryption since 2007, since before the iPhone, and has been putting a lot of pressure against, like, into cracking the iPhone.



LEO:  Yeah, we didn't talk about it on MacBreak Weekly because I thought, oh, we'll talk about this on Security Now!.



STEVE:  Yes.



LEO:  It's really better for Security Now! since this is, you know, a security issue.



STEVE:  Yeah.  And then some odds and ends about routers and redirection.  I did want to check in with you about the Apple Watch, which I have a few comments about.  And then we're going to plow into these really two big security stories, deep in technology.



LEO:  This is great.  We're loaded for bear, baby.  Even though it's 8:00 in the morning where we are, I hope you have - back East they're thrilled.  Hey, there's a show at my time, when I'm awake, yeah.



STEVE:  So we had a Patch Tuesday.  Last Tuesday was Patch Tuesday.  Not anything really significant, although Microsoft did fix, in this Patch Tuesday - one of the problems with this FREAK exploit got fixed on Tuesday, on March 9th.  So that was good.  So there were 14 bundles.  Five were criticals, and all of those were remote code execution vulnerabilities.  And the remaining nine they just flagged as important.



There was the standard cumulative security update for IE, which it's the standard monthly update.  And with the boilerplate from Microsoft saying the most severe of the vulnerabilities could allow remote code execution if a user views a specially crafted web page using IE.  So, you know, go to a site and get owned.  So that's been fixed.  The second one was a VB scripting problem.  And I got kind of a kick out of this because they said - this is Microsoft saying "resolves a vulnerability in the VBScript scripting engine in Microsoft Windows.  The vulnerability could allow remote code execution if a user visits a specially crafted website which uses VBScript."  And I thought, okay, so nobody does that.  What website has VBScript?



LEO:  I don't know.



STEVE:  Maybe something inside Microsoft.



LEO:  Or Intranets, I bet, yeah.



STEVE:  Yeah.  Well, but, okay, yeah, right.  In a Windows-based company.  But why would you, in this day and age, not use JavaScript, which has become the industry standard for client-side scripting?  So this is Microsoft saying, well, we produced something a long time ago, and we needed to keep it going, so we fixed a vulnerability that you really don't care about because you're not using it.



LEO:  Did you see that they made a "Time to break up with IE8" website now?  I think it's...



STEVE:  Oh, my god.



LEO:  I think it's Microsoft.  It's...



STEVE:  So it's gone from 6 to 7 to 8.



LEO:  Yeah.  So it says, "Break up with Internet Explorer 8 on your six-year anniversary." So I guess that IE8 is six years old.  And it's pretty funny because they're having people tweet their little breakup stories.  "I'm leaving you because at least five of your action bars are not mine."  I just love it.  And then there's a little heart cursor that goes around.  It might be their Valentine's Day thing.  And then there's a button that says, "Oh, god, no, I'm not ready."  And you click that, and it shows a video of "Internet Explorer encountered another problem and needs to close."  It's pretty funny.



STEVE:  Now, this is by Microsoft?



LEO:  Well, they've done these before, remember, because of the insecurity.  Let me just see, if I press the "Dump" button, if it goes to Firefox or - "Text a breakup to IE8."



STEVE:  I just think this is very classy, and not the sort of thing you typically see from staid old Microsoft.



LEO:  No, they did something cool for IE6, remember, because they were really concerned about...



STEVE:  Oh, my goodness, yeah.



LEO:  Yeah.  I don't - here's a WTF button.  Let's see what - "Break up with IE8.  For whatever reason, IE8 recently increased in browser share.  Join the intervention and stop supporting IE8."  You know, it might be the Firefox - it's really not apparent who this is from.  "A public service, lovingly crafted by humans."  It might not be anybody.  It might not be Microsoft.  It just is.  But I love it.  It's well done.



STEVE:  It's really well done.



LEO:  Yeah.  Wasn't Stuxnet fixed again?



STEVE:  Yeah.  Yeah.  Apparently there was like a multi-year-old patch that prevented the Stuxnet infection.



LEO:  Oh, oh.



STEVE:  And then a workaround was found.



LEO:  Oh, lord.



STEVE:  So you could still get your PC infected with the original Stuxnet nastyware.  So, yeah, that's, again, we've got - the big revelation of the last couple years, and we'll talk about this in the next story about the CIA and Apple, is we've lost our virginity in this industry.  I mean, it used to be just, you know, we gave them different colors of hats, white hat and black hat, and maybe gray hat sometimes, hackers.  And we thought those were the people, the only adversary that we had.  Come to find out that for, like, since the beginning, the U.S. three-letter-initial law enforcement and intelligence-gathering agencies have been absolutely frantic and furious and, unfortunately, well staffed and well funded to be every bit as aggressive, if not more so, than actual bad guys.



I mean, only recently we're seeing where this sort of use of malware is an actual profit center.  For example, with the new file encryption technology that really does induce people to pay the ransom, previous to that viruses, as annoying as they were, they were annoying.  You know, they got into your system and sort of mucked things up.  But it was always sort of, oh, okay, why?  They must just be doing it because they can.  Well, what we know is that law enforcement and intelligence gathering are doing it because they feel really put upon, really endangered by the growing use of encryption.  And it was foreseeable that encryption would grow.



And in fact we'll be talking about, in this FREAK attack that had people freaked out late last week and early this week and is still a problem, it is entirely because of the NSA's paranoia over cryptography that this FREAK attack is possible.  And we'll talk about the export-grade ciphers which the U.S. government enforced on the industry in its early days because they wanted to weaken crypto only enough that it was strong enough to protect people kind of in general, but weak enough that they could crack it.  And it was funny because, by calling strong crypto a "munition," which is like, what?



But now I understand that maybe better now than I did before.  By calling it a "munition," by categorizing it that way, you could restrict its export.  And what that meant was that within the U.S. we could use these so-called "munitions" peacefully with each other to get strong encryption.  But that meant automatically that the encryption strength had to be downgraded for any connections leaving the U.S.  And that meant that international communications could be cracked.  So that was the rationale behind this notion of encryption as a munition is it's like, we don't allow their export, so we're going to call them a munition.  You can't make a connection outside the country with strong crypto.



And so that also tells us that the NSA has been tapping the 'Net also for a long time because that's the other part of using crackable crypto is sucking in all the data so that you can decide what you want to crack.  So in that vein, more Snowden documents have come to light, published this time by, I should say "again," by The Intercept, because we covered the release of Snowden documents from The Intercept just recently.



LEO:  The Intercept is that thing that Pierre Omidyar started.  He hired Glenn Greenwald away and created this, I don't know what it is, for-profit journalistic enterprise called The Intercept.



STEVE:  Yeah, well, someone's being paid by the word.



LEO:  Well, and also a lot of people left The Intercept, or at least some people left, unhappy with the way it was being run, I think.



STEVE:  Boy.  



LEO:  Is it really long?



STEVE:  It is redundant and long.  You get teases up at the front.  And then it's like, well, and then halfway down they kind of come back to that and add a little embellishment.  I mean, it's like classic, how can we bloat this story to the largest size possible?  I was, I mean, and I'm very tolerant of that.  Normally I don't notice that.  But this was just like, oh, come on.  So when I was putting things together, I just, you know, it was like, okay, well, I already read that earlier.  And I read that earlier.  And so, you know, tell us something you haven't already said in the first graph.



LEO:  Some of the best editors have left, is what the problem is.



STEVE:  Wow.  So here's what we know.  And there's a lesson in this for our listeners that you and I have spoken of often.  And it's a little creepy.  And that is, we have discussed this before in the context of HDMI and DVD, within the life of this podcast.  And that is, when we were talking about DVD encryption in the early days, it was obvious really that, if your household, your - I guess we don't even have them anymore.  But if your entertainment system's DVD player had the ability to decrypt an encrypted DVD that you had stuck in it, and by definition it has to have the ability to decrypt it, then right there sitting on the shelf is a box vulnerable to reverse-engineering.  And if you reverse-engineer it, then you know how to decrypt DVDs, too.  That is, the Achilles heel in this system was it absolutely depended upon keeping a secret.



And, boy, talk about a widespread secret that they were keeping.  It's no surprise that they couldn't.  But if something that you have access to must withstand divulging its own secrets, then it's inherently insecure.  Which is not to say, I mean, in the absolute sense.  Sitting there in front of you is something that knows how to decrypt what you want to know how to decrypt.  There are ways to ask it what it knows.



So essentially the CIA, the Snowden documents show us through a series of slides that the CIA has for, what would it be, eight years been actively financing lots of Lockheed Martin employees, who's like a large - 80% of Lockheed Martin's business is government contracts.  And so they subcontract out a lot of this stuff.  So they've been financing continuous cracking efforts against the iPhone.  There's an annual meeting or meet-up called "The Jamboree," which they have in order to pull all the various components together.  And then they give each other slideshow presentations of the capabilities that they have managed to develop since the last Jamboree a year ago.



So the researchers have claimed over the course of these years - and some of this, as is the case, we have to remember, with the Snowden documents, is old news.  So things like going to the iPhone 6 and the newer iOSes, we know that Apple has been proactively aggressively working to thwart, if not the CIA, then the hackers, because it is also a danger to Apple's users if the iPhone gets rooted and hacked, jailbroken, and malicious [indiscernible] is in there.  Apple wants to protect its users.  So in the process it's protecting them also from the CIA eavesdropping, against which law enforcement wants to push back strongly.



So the researchers claim to have modified Apple's Xcode development platform so that any application built with it, built with Xcode, which is like that's how you build applications, will automatically include backdoors.  And infected apps can somehow invite or entice - entice was the word in the document, it's like, what? - can entice other apps to join in.  Okay?  Also another target and, I mean, like a threat, it's a little unnerving to hear stuff that we revere for security being labeled a threat by law enforcement.



But the TPM, the Trusted Platform Module, has long been a target of this group.  And I have long wondered why it never really took off.  And I have to wonder, sort of in a Machiavellian way, if on some level all of these agencies aren't really working not to have a secure platform created because it would make their job so much harder.  So, yeah, you know, we got TPM years ago.  BitLocker can lock to it.  But, you know, and there are some OSes that boot sort of through it.  But, boy, it sure has never met its potential.  So anyway, they don't like it.  They don't like anything that is going to keep them from getting the information they want.



So quoting from a small piece of this Intercept article, they said:  "The Snowden documents do not address how successful the targeting of Apple's encryption mechanisms have been, nor do they provide any detail about the specific use of such exploits by U.S. intelligence.  But they do shed light on an ongoing campaign aimed at defeating Apple's efforts to secure its products and, in turn, its customers' private data. 



"In the top-secret documents, ranging from 2010 through 2012" - so again, they are a bit dated - "the researchers appear particularly intent on extracting encryption keys that prevent unauthorized access to data stored  and firmware run  on Apple products.  In an abstract of a 2011 presentation at The Jamboree, the researchers noted that the intelligence community is highly dependent on a very small number of security flaws, many of which are public."  In other words they're using the same hacks that hackers are to jailbreak phones.  They have no, I mean, that's been the only means that the CIA, NSA, FBI, and so forth had of cracking an iPhone was basically the public hackers are doing the work for the intelligence firms or agencies.



However, in this abstract, after explaining that the intelligence community is highly dependent upon a very small number of security flaws, many of which are public and which Apple eventually patches, then they promised that their presentation could provide the intelligence community with a, quote, "method to noninvasively extract" encryption keys used on Apple devices.



Another presentation focused on physically extracting the key from Apple hardware.  In other words, the first is a side-channel attack of some sort, maybe using EMF emissions or power consumption.  And actually elsewhere in this document those were specifically mentioned.  And this physical extraction with a key, back in the early days of chip fabrication, that was known as "popping the top."  You pop the top on the chip and get out your high-resolution electron microscope or just a very good microscope, and there in front of you are all of the traces that a chip designer can reverse-engineer the chip's circuitry from.



I mean, and so this brings us full circle to the problem that Apple faces.  And that is, just as with a DVD or an HDMI screen, which again HDMI of course is encrypted transit video, in those cases the consumer is seeing the unencrypted contents, the unencrypted data, because it's been decrypted for them by something in the living room.  Similarly, anyone holding, like, booting an iPhone and installing software is holding the device that is able to decrypt that encrypted stuff.



And so there is, I would argue, a limit to what Apple is able to do.  I continue to believe, all the evidence is that, even if Apple didn't know about this, and maybe they didn't, or maybe they did have some clue that this was going on, they've been taking all the measures you could ask to increase the security of their device in order to raise the bar as high as possible in order to thwart this.  But we should remember that we're holding the decryption device in our hand.



LEO:  Right.  I wonder, you know, this is what, 18 months in, now.  It was June of 2013 that the Snowden leaks began; right?  I mean, we're well into the leaks.  And maybe we're getting to the bottom of the barrel here.  And the only reason I say that is the Gemalto story, where Snowden claimed, or the papers claimed, I think it was Snowden, wasn't it, that...



STEVE:  Yes.  And that was our previous mention just a few weeks ago of The Intercept.  It was another story in The Intercept.



LEO:  So this story claims that the NSA had hacked the keys of this SIM card manufacturer.  Gemalto makes billions of SIM cards a year.  They're in most of the phones in the U.S.  But Gemalto then did an audit.  Now, whether this is to be trusted or not, I don't know.  But they did an audit, and they said, yeah, you know, we saw some NSA-style attacks.  They never got past our office systems.  Our keys are intact, and the systems were not - the integrity of the systems that encrypt the SIM cards was never at risk.  Now, maybe Gemalto, I mean, I don't know who to believe here.  But I'm wondering if we're starting to get to the point in these papers where this is stuff, it's a little more speculative.



STEVE:  Right.



LEO:  You know what I mean?



STEVE:  Right, right.  And certainly, why would they hold the best stuff to, like, a year and a half later?



LEO:  Yeah, this is good stuff.  This is juicy.  Well, I'll give you an example, the Xcode thing.  Now, that makes sense.  If you really want to compromise a system, compromise a development tool that's used by everybody.  But you get Xcode from Apple.  And you would be a strange developer that would get Xcode from some third-party source.  So the NSA or the CIA in this case would have to - I think this is a barrier that's pretty high - get into Apple's servers, modify Xcode in such a way that nobody noticed.  I just don't think this is credible.



STEVE:  Or plant an Xcode change in a specific developer's machine.



LEO:  That you could do.  You know, retroactively.



STEVE:  Yes.



LEO:  But on the other hand, Xcode is patched all the time.  And, I mean, this is why, when you get GCC or other open source compiling tools, you always get an MD5 hash, and you're supposed to compare the two.



STEVE:  Right.



LEO:  There are automated tools that will do that and protect you from hacked code.  But if you're getting it - okay.  So it'd have to be post facto, after you downloaded it.



STEVE:  I think, yeah, because nowhere in this paper did they talk about how they infected developers with the infected Xcode.  They said we've got an Xcode that is like an auto backdoor installer.  And presumably they were then solving that problem by installing these in specific developers' environments.



LEO:  Which makes it much less of an attack.



STEVE:  Right.



LEO:  I mean, it's a very specific attack.



STEVE:  Right.



LEO:  I'm not saying, I mean, certainly these need to be paid attention to.



STEVE:  Yeah, we just don't know.



LEO:  And as I said last week, no one is anymore questioning the validity of these documents.  There are just too many; there's too much detail.  These aren't made up.



STEVE:  Right.



LEO:  Snowden didn't write this in his cabin in the woods.



STEVE:  Yeah, I mean, yeah, the slides are always rather sobering because it's like, wow, there's a vocabulary for this.  There's this huge machine that is rumbling forward, working on taking privacy away.



LEO:  That's the biggest takeaway, is not whether they've had success in one area or the other, whether they're managing to crack Apple or not, but just that they're, at least until recently, continually attempting this.



STEVE:  Right.



LEO:  But if you think about it, if you're law enforcement, TPM, any form of encryption, any form of security is, if you're trying to investigate a criminal, going to thwart you.  So of course it's seen as an enemy in that regard.



STEVE:  A threat, right.



LEO:  I think they also value, you know, and this is the weird kind of schizophrenic nature of this, they also value it.  And they're always talking about CERT, and all these other agencies are always talking about how important it is to encrypt and protect your privacy.  President Obama said, yeah, everybody should have encryption.  So it's this weird dichotomy.



STEVE:  As long as we can see into it.



LEO:  Well, I don't even know if they say that.  As long as we can see into the criminals' encryption I think is the subtext.



STEVE:  Right, right.



LEO:  As a good and honest citizen, you should have the right to privacy.  But you cross that line, we want to be able to see what you're up to.  You can't fault them for that.



STEVE:  No.



LEO:  But you can't fault us for trying to thwart it, either.  Not everybody who encrypts is a criminal.



STEVE:  Exactly.  So I got a tweet from a James Bennett Saxon, who was following up on our conversation about router firmware and how, at this point, you really just can't trust the firmware on especially a low-end commodity router.  And so he tweeted:  "@SGgrc I have FIOS with Verizon-supplied router.  Can I wipe their scary firmware?"  Now, I liked this because it raised a really good point, which is there are situations you're going to be in where you can't replace the firmware, for whatever reason, on the router that you're stuck with.  I'm sure that Verizon's random router firmware for their FIOS offering is not going to accept a Linux build downloaded into it.



So what I wanted to remind people is that routers are stackable.  And if you, for whatever reason, have cause to mistrust your actual border router, like in this case the Verizon-supplied router that interfaces to his fiber optics externally, or FIOS system, there's nothing to prevent you from connecting that router only to another router that you do trust.  And then that router, that second router, the internal router, becomes the one that supplies your internal network.  They stack very nicely, no downside at all.  Some additional features, actually, when you think about, like, having maybe a less trusted network and a more trusted network.  So I wanted to remind people that, if they're frustrated with the inability to change their firmware, you can just install a router inside that one that you do trust with running whatever firmware...



LEO:  Oh, that's a good idea, yeah.



STEVE:  ...that you choose.



LEO:  That's where you put your Astaro gateway.



STEVE:  Exactly.  So I got a tweet - I was talking about my blogs, and I don't remember the context of that, but on the podcast recently I mentioned that I have two blogs at WordPress.  Steve.grc.com is my personal one, and blog.grc.com is the corporate Gibson Research blog.  And I started getting tweets from people that said, "That doesn't work.  I'm getting SSL errors."  Well, I fixed it.  And I had actually intended not - I had intended to leave it bad, just for that purpose, so we could show it.



LEO:  I can show the tweet.  I can show the tweet, I guess.



STEVE:  Yeah.  But I loved what this turned out to be.  I mean, when I saw these tweets begin to come in, it's like, huh?  What?  And so...



LEO:  Are you hosting this, or is it a WordPress.com hosted blog?



STEVE:  Exactly.



LEO:  Ah.



STEVE:  It is WordPress.  And what I'm using, there are two ways that I could use my own domain name to allow people to get to the blog.  And one is by doing a so-called "301 Redirect," where anyone who comes to blog.grc.com, that would go to my server.  And my server would respond to the browser with a 301 permanent redirect, meaning that this website is saying that, to get the content for the domain you're asking about, blog.grc.com, go over here.  And so then I would redirect the browser to WordPress.com/ - and I think, I don't remember now what the username is, I think it's AgileSynapse, which was very briefly my first Twitter handle before I decided that shorter is better.



LEO:  What?



STEVE:  Yeah.  The problem is...



LEO:  You can use Steve Gibson, you know.



STEVE:  Oh, that was long gone.



LEO:  Oh, really.



STEVE:  Oh, lord, and I feel sorry for Steve Gibson on Twitter.  I'm constantly seeing him replying to people saying, no, I'm not that Steve Gibson.  It's like, oh, okay, well, sorry about that.



LEO:  So the other Steve Gibson, we will buy back that handle if you want it - if you don't want it.



STEVE:  Nah, I love SGgrc.  I think that's established now.



LEO:  Yeah, it's short, which is great, as you said.



STEVE:  And short is what you want.  So the alternative solution is what's called a CNAME record.  It's always been in DNS, thanks to the brilliance of those guys.  And it's essentially, it's called an "alias."  And a CNAME record says that, yes, you found the DNS for this domain name, but that's an alias for another one.  And so essentially what that does is it's a DNS redirection rather than a browser protocol redirection.  And that's how, up in the URL, when you're at steve.grc.com or blog.grc.com, that domain name is still in the URL.  So it didn't change to WordPress.com slash something down in the directory.



LEO:  Which a 301 would do; right?



STEVE:  Yes.  And so I pay WordPress some nominal fee, like $5 or something annually, for their support of that because they  need to essentially jump somebody down into their directory hierarchy to where my blog stands in that directory hierarchy, in other words, under the AgileSynapse subdirectory, to find the blog.  So there is a tiny little bit of work on their part, and there would be none if I used a 301 Redirect.  But it looks more like it's a blog coming from me.



What broke?  What broke was when I was talking recently about Strict Transport Security.  I've had that in place now for a long time.  But in covering the updates to it, as we did a couple weeks ago, I saw two new parameters that could be added.  One was "include subdomains," and the other was "preload."  And I thought, oh.  And I thought, okay, let's see.  Are there any subdomains that I have at GRC that should not be security enforced?  And I thought, no, you know, media.grc, www.grc, GRC itself, I want security enforcement on those.  So I added "include subdomains" to the header which the GRC server emits.



But there's a problem because what that told all the browsers was that every subdomain of GRC needs to have HTTPS enforced.  And blog.grc.com and steve.grc.com, to the browser, look like domains.  I mean, they are.  So the CNAME comes along, and it transparently switches the browser to WordPress's domain, and the browser checks the certificate.  It's looking for GRC.com, and it gets WordPress.com.  And it says, huh?, and won't allow the connection.



So a couple weeks ago I broke this CNAME redirect of those two subdomains that, I mean, they don't really have to be secure.  They're off in the WordPress boonies.  But by doing that, and using Strict Transport Security, I made it impossible to get to those sites.  So I went back in, simply removed "include subdomains."  And this was really perfect because, after I did that, I went to Firefox and tried again to go to steve.grc.com, and it said no.  Well, it said no because it was holding onto, as it should, the most recent instance of the Strict Transport Security header that it had received from GRC.



So I thought, okay, yeah, that's good.  So then I went to GRC, just brought up the home page, refreshed it for good measure.  Then I went back to steve.grc.com, and it came right up.  So the Strict Transport Security header was refreshed by an actual visit to GRC, losing the "include subdomains" tag, and it all worked again.



LEO:  Someday would you - I would love an explainer on what all this junk means.  CNAME is canonical name.  And I use it, too.  As you can see, this is a DNS record for Leoville.net.  And so that was - I used to host it, but now I've moved it to be hosted by WithKnown.  So I had to add a CNAME there, and an A record to point to their server IP address.  I have no idea what I'm doing here.  I do this all by rote.  So if you ever wanted to do a show where you explain what this...



STEVE:  On configuring DNS.



LEO:  Well, what does it mean?  You know, part of the problem is every domain name system has - this is Hover.com, but all the registrars have different systems.  Your SoftLayer has a different system.  So, but it all resolves down to something like this, this record.  And I'd love to know what that stuff, all that means.  It'd be a great subject.



STEVE:  Yeah, and actually that sort of human readable record is a proxy for the actual BIND format record, which is way less intelligible.



LEO:  Oh, there's weird numbers.  There's 1799 and stuff.  There's all sorts of weird stuff in there.



STEVE:  Yup, versions and dates.  And MX records, of course, have a priority on them, due to some imagined future that actually didn't occur, where you would have different - you'd have like a hierarchy of mail servers, and they would have priorities in terms of what someone wanting to send mail would try first and try second and try third and so forth.



LEO:  Right, MX records and...



STEVE:  Or they could have the same priorities, and then it would be round robin.  So, yeah, interesting.



LEO:  Crazy.  And I know enough to cause real problems.  So I would like to know more.



STEVE:  It's always nice when something or someone does that for you because it's like, oh, thank god.



LEO:  Well, I had - it's funny because I had conflicting hosting information in there, and it wasn't resolving.  And Ben Werdmller, who's great, at WithKnown, gives great support, said we'll do an nslookup on that, and you'll see what's going on.  And, like, it was - half the time it was going to Dotster.com, half the time Hover.com.  It was very confused.  But nslookup is a very useful tool there, too.  Is there a way to dump the BIND record, like you could see what it says?  Probably is...



STEVE:  Oh, yeah.  In fact, you can do - nslookup has some parameters.  There is an "any" matching for nslookup where you can say nslookup, I don't know what the exact syntax is because I haven't used it for a long time, but you can say "any."  Normally you're asking for the A record, and so it defaults to A.



LEO:  Right.



STEVE:  But if you do nslookup and do /?, you can coerce it to give you its own help for how to do that.  And the "any" dump just says I want everything from the server.  And actually, there's a story I did add to the notes today.  I'll probably pick it up next week.  And that is, I noticed that CloudFlare seems to be lobbying for eliminating the "any" option because, boy, is that an amplification attack.  Because you can do it over DNS, a tiny query saying "give me all DNS records"...



LEO:  [Mimicking heavy machinery]



STEVE:  Yes.



LEO:  Actually, somebody in our chatroom says, and this might be why, nslookup is deprecated, and you're supposed to use "dig" now.  And I just went "dig Leoville.net," and, boy, you get a lot of stuff.  This is actually much more useful.



STEVE:  Yes.



LEO:  Yeah.  Wow.



STEVE:  Wow.  Deep voodoo.



LEO:  Deep voodoo.  Someday, will you, please?  I want a show.



STEVE:  Yeah, okay.



LEO:  I trust you.  You're the only person I trust to explain this stuff.



STEVE:  We'll make it intelligible.



LEO:  Someday.



STEVE:  We have, I think, this and a couple more weeks, and then it's over.  So I did want to encourage our faithful listeners to vote for Security Now! on the PodcastAwards.com site.



LEO:  Vote early, vote often.



STEVE:  Vote early, vote often.  I came back the next day and it said, oh, it hasn't been 24 hours.  It's like, okay, fine.



LEO:  So what do you mean?  So they allow you to more than once, but...



STEVE:  They tell you to.  They say, you know, come back tomorrow.  It's like, why?  So we see your ads again?  I mean...



LEO:  That's why, yeah, there you go.  You just nailed it.



STEVE:  So I would like, I'd just love to win.  And then I'll leave everybody alone for the next 10 years.  But it'd be fun to win.  So PodcastAwards.com.  And thank you.  We're at the Technology section at the very bottom.  I saw a tweet from someone who said, "Dang, Steve, you and Tom Merritt are in the same category.  What do I do?"



LEO:  Uh-oh.  Uh-oh.



STEVE:  And Tom responded very kindly.  He says, "I voted for Steve."



LEO:  Aw.  I think that means you're supposed to vote for him.



STEVE:  I didn't.  I want to win this sucker.



LEO:  [Laughing] I love it.  All right.  So PodcastAwards.com.  Vote your conscience, often.



STEVE:  Vote your conscience, and vote it often.  Yes.  Okay, Leo.



LEO:  Yes.



STEVE:  The Apple Watch.



LEO:  Yeah.



STEVE:  So my biggest puzzle.  So I'm just loving being alive now because this, well, to the degree that I am at the moment.  This is just such a fun time because I want to see what's going to happen.



LEO:  Yes.



STEVE:  This is really - it's bizarre, and it's over the top, and it's crazy.  The biggest, well, many things stand out in my mind as being like, okay, maybe.  One is that the bands are such a large percentage of the watch price.  It's like, holy crap.  The $549 watch, which is the one, I call that the Mama Bear.  It's not Papa Bear, and it's not Baby Bear, it's Mama Bear, the one in the middle.  The $549 watch, the final price can range up to $1049, depending upon what band you choose.  What?



LEO:  Oh, it's worse than that.



STEVE:  The band can be as much as the watch?



LEO:  If you look at the gold watch, yeah, if you look at - oh, more.  If you look at the gold watch, the only difference between the $10,000 gold watch and the $17,000 gold watch is the band.



STEVE:  Yes.



LEO:  And so you're telling me that a leather band with a gold clasp is $7,000?  I think that's not right.



STEVE:  And selling you a $10,000 gold watch with the plastic band, it's like, come on.



LEO:  Nobody's going to buy that, and that's obviously the point. 



STEVE:  Yes.



LEO:  So Kevin Rose, who is, of course, you know Kevin, former Screen Saver and Digg founder, and a watch fanatic.  Kevin has in later life, I guess he's made enough money now that he can afford, like, fancy wristwatches.  In fact, he's created a blog called Watchville.  There's a Watchville app.



STEVE:  And why not?



LEO:  Why not?  He's rich now.



STEVE:  I mean, and Kevin - yeah.



LEO:  So this is his take on the Apple, the expensive Apple watch.  This is on TechCrunch.  "The gold Apple Watch is perfect for douchebags."  He points out, and I think he's absolutely right, that technologically there is no difference.  The watch that you buy for $349 is exactly the same, except for a gold case, as the watch you buy for $17,000.



STEVE:  Which is really interesting.  It doesn't have, like, double the...



LEO:  The RAM or anything.  There's a sapphire - one difference is there's a - the more expensive watches have a sapphire screen.  So he says, really, in fact he quotes Anna Kendrick, the movie star, "We should be thanking Apple for launching the $10,000 Apple Watch as a new gold standard in douchebag detection.  Anybody who's wearing that watch," he says, "is proving that they just have more money than brains."  Or they're really - si it's a very ostentatious way of showing off.  I'm excited about - I like wearables.  You know, I wear the Moto 360, the Android Wear watch.



STEVE:  Oh, I'm behind you buying one.  So I'm glad for that.



LEO:  And Apple's done an interesting psychological thing, it's technically called "anchoring," where you start with a low price that is like the price everybody pays attention to, $349.  But it's not the watch you want.  You want the next one up, always.



STEVE:  No one wants the cheap one.



LEO:  Right.  So they've established - they've done two things.  By setting the outer limits at $349 and $17,000, they've made you not feel so bad about spending the same amount for your watch as you'd spend for your iPhone, six or $700.



STEVE:  But Honey, it's, like, less than my iPhone was.



LEO:  Exactly.  And it's not $17,000.  So anyway...



STEVE:  And, you know, that lens of yours is even cheaper than the high-end watch.



LEO:  I know.  And the lens, I'm getting something for my money there.  But the watch...



STEVE:  Well, see, and that's just it.  I'm actually not going to buy one, at least not the first one.  I remember, you and I were at this point in our relationship was when we were flying to Vancouver.  So we'd stopped going to Toronto to do Call For Help, and we'd switched over, and we were going to Vancouver.  During one of the days that I was doing shows with you, the controversy that day hit of the Apple, the new announcement of the next iPhone with the radically lower price.  And there was a lot of conversation about that, that, well, you know, the people who were early adopters, they really wanted that iPhone at that high price.  So, you know, yeah, they got an arrow in their back.  But they got the phone that they wanted, and Apple - because you may remember it was a precipitous drop in price, just bang.  Now the iPhone costs this.  It was like, whoo.



LEO:  Although I have to point out that if you got an iPhone 6 Plus...



STEVE:  I did.



LEO:  ...and maxed it out, it's over a thousand dollars.



STEVE:  Yes.  Yes.  Yes.



LEO:  So it isn't exactly cheaper.  Still the most expensive iPhone ever.



STEVE:  The other thing about it that seems so conspicuous is somewhere in a meeting with a lot of these amazing bright creative people sitting around, someone said, you know, like Tim, he said, "Attention."  He said, "Okay, we're going to do a watch.  It'll do all of the expected iPhone extension things.  But what more can we give it?  What more could a watch do?"  And someone raised their hand and said, "Oh, doodles.  It can do doodles."



LEO:  Yeah, that's a silly one.



STEVE:  And it's like, okay.  Good.  Write that down on the whiteboard.  Anybody else?  I could send my heartbeat to, like, anyone else.  Oh, oh, wait a minute.  Write down on the doodles who also has a watch.  So this stuff is inter-watch stuff, not watch to phone.  And of course this is also classic network externalities, where Apple is creating features that require one at each end.  And it works because, as you said on one of the shows, Lisa is now getting one, which she wasn't planning to before, so that you and she can doodle, do intimate doodles to each other.



LEO:  Exactly, yeah.



STEVE:  Which, you know, so, yes, it works.  But it has this sense of straining for a reason to exist.  It's looking for a market, rather than it fulfilling an obvious need.  So although, again, for somebody who is iPhone-centric, who is messaging all the time, I mean, I'm not saying I won't ever get one.  But it seems unwise to get the one in the first year.  And I don't need it enough that it's like I have to be an early adopter of this thing.  Well, although it does sound fun.



LEO:  [Exclamation]



STEVE:  But, okay, but...



LEO:  They got you.



STEVE:  Like with a really good band, $349 with a good band, it's going to be $800.



LEO:  Yeah, I'm going to get the steel with the Milanese loop band, which is $650, I think, or $699.



STEVE:  The band, the band thing is - I don't get it.  And they, like, I saw some marketing that said every single link is individually machined.



LEO:  Yeah, that's BS, yeah.



STEVE:  And hand-tooled and polished.



LEO:  That's the link, that's the link band.



STEVE:  We're only able to do two a day.



LEO:  Nine hours.  They say it takes nine hours to mill.



STEVE:  Right.



LEO:  But that's - and Kevin Rose's point is that people buy expensive wristwatches because of the craftsmanship involved.  And I think that's an attempt, you see, the watch itself, there's no craftsmanship.  It's stamped out by Chinese slave labor.



STEVE:  And it's Apple's secret aluminum.  It's their alloy.  They show it glistening, going down the runway.



LEO:  Yeah, yeah, yeah, those movies are good.



STEVE:  We're sprinkling in a little bit of magnesium, and a little bit of zinc.  And this is the best aluminum that's ever been.



LEO:  Somebody's saying buy it without the band.  I don't think you can buy it without the band.  I think that you have to - or I guess you could buy the rubber band.



STEVE:  You could buy it with...



LEO:  And then you can snip it off and put a...



STEVE:  It's a rubber band.  The rubber band.



LEO:  I'm sorry, fluoroelastomer.  They don't even want to say "rubber."  But I believe fluoroelastomer is rubber.  I could be wrong.  Rubber band.  Even - it's so funny because I think Christy Turlington, when she came onstage, the model at the Apple event wasn't briefed fully because she called it a rubber band.  And I think that was a...



STEVE:  Whoopsie.



LEO:  Whoo.



STEVE:  We don't call it that.



LEO:  Whoo.  It's fluoroelastomer, please.  Now, Apple's great at marketing.  There is something here.  I think one of the clues to why there's drawings and heartbeats is the original Apple Watch was, according to The Wall Street Journal and a leak, supposed to be much more of a health device.  But they, for a variety of reasons - for technical reasons, battery reasons, and FDA reasons - they couldn't make it the health device they wanted to.  So at that point, not so long ago, they were casting around for, oh, crap.  It can't do that.  What else could we have it do?



STEVE:  Right.  So it has an accelerometer and a heart rate sensor.



LEO:  Which they all do.  This does.



STEVE:  Yeah.



LEO:  And that's what you can easily do.



STEVE:  My shoe does.



LEO:  Yeah.  It's not a hard thing to do.  Yeah, your Nike Pod, Fuel, whatever it is, Nike Pod is doing that.  So, but I do think that there is something about wearables.  I figured out what it is, actually.  One of the reasons I love Android is because of the widgets.  I can turn on the screen, and without diving into an app, instead of, on the iPhone you see a grid of apps, and you can't really get much information from the screen.



STEVE:  Correct.



LEO:  You have to dive into the apps to get anything out of it.  But on the Android I have widgets.  These are all informational.  There's calendars.  There's news.  There's weather.  Without doing anything.  And I realized Apple's never done that.



STEVE:  Windows has that, too; right?



LEO:  Yeah, Windows Phone has more information on the screen.  Apple's never done that.  Apple's effectively a grid of icons.



[Crosstalk]



STEVE:  Yeah, well, we could [indiscernible] time, yes.



LEO:  The watch is the widgets.  The other thing that became apparent that wasn't completely apparent originally is that you don't - the watch does everything the phone does, just on a little screen.  So you can even be Dick Tracy and talk - I have a phone call.  So, and because it supports WiFi, your phone doesn't have to be within Bluetooth range, it just has to be on your network.



STEVE:  Yeah, that's brilliant, that it's able to use WiFi to bridge [indiscernible].



[Crosstalk]



LEO:  So that's valuable to me.  I can leave my phone here and wander around the studio and [indiscernible].



[Crosstalk]



STEVE:  It's valuable [indiscernible] everybody.



LEO:  Yeah.



STEVE:  Yeah.



LEO:  So there's some - they've found some value in it.  It's not that it's completely useless. 



STEVE:  If you were to lift your arm very slowly and kind of, like, trick it so that it didn't know you were lifting your arm, can you see the time?



LEO:  No.



STEVE:  Or do you have to give it, like you have to do a Heil Hitler in order to get this thing to wake up and...



LEO:  There is a low power mode that just shows the time.



STEVE:  Okay.



LEO:  And I think it goes into that if you get down to a small - I think.



STEVE:  That display is always on?  Or never on?



LEO:  That one is always on, but only when it's running out of juice.  Normally, it's much like the Android Wear watch, where you don't want to leave it always on.  It'll kill the battery.  But a gentle twist of the wrist turns it on.  Or a tap of the screen.  They have to do that because the problem is these devices are so small they can't hold much lithium ion.  Where you going to put it?



STEVE:  Yeah, in the strap-on optional battery pack, you know, that goes on your forearm.  Really takes the bling out of a $10,000 watch.



LEO:  This is a problem with all portable devices, mobile devices; right?  You can't get too small because you have no battery life.  We've got to get this - what happened to supercapacitors?  We've got to get this battery life thing solved.



STEVE:  It'll be good.  And that would be perfect for this application because a supercapacitor could charge so fast that you'd just briefly touch it to a dock.  And, you know, they could set them up next to electric car charging ports and things, so that they're all...



LEO:  Supercapacitor doesn't give you more capacity, it's just faster to charge it.  Do you get more capacity per square inch?



STEVE:  It is, well, of course it doesn't do anything today because they don't really exist in a practical fashion.  



LEO:  Except in my screwdriver is the only place.



STEVE:  But if it could reach - yes.  If it could reach parity with chemical storage, electrochemical storage, then you get instant charging.



LEO:  Which is great.



STEVE:  Which is super great, yeah.



LEO:  Providing enough voltage in the charger.



STEVE:  As long as it doesn't, like, blow up and fuse and turn into a...



LEO:  On your wrist.



STEVE:  ...a microwave on your wrist.  Yeah, you don't want to burn, don't want a $10,000 shaped spot on your wrist when this thing goes nova.



LEO:  I get some value, not enough to make it a must-have, out of my Android Wear watch.  I anticipate a similar kind of reaction to the Apple Watch.  Of course I will buy one, and I'm not going to buy the anchor watch because that's cheap.



STEVE:  That's right.  It's cheap.



LEO:  So I'm going to buy the middle one, like everybody else.  Which is ridiculous.  And I can tell you this.  If I didn't have this job, I certainly would not.  But I'm also buying a MacBook.  What do you think of the new MacBook?  



STEVE:  Oh.  Oh, yeah.  I'm - it's just...



LEO:  You crack me up.



STEVE:  It's Apple at their finest.  I love the...



LEO:  Steve, there's a lot of people in the chatroom are saying, oh, no, this thing is a Netbook for double the price.  Because the Core M isn't a superfast processor.  But, you know what, processors are pretty fast nowadays.



STEVE:  That's right.



LEO:  Why are we turning up our nose at 1.2 GHz, really?



STEVE:  I never liked that, like, basically they fixed everything that annoyed me.  I never liked that weird, like, front of the pad click-down thing.  That seemed wrong.



LEO:  Yeah, this is, I think, the Force Touch is a great idea.



STEVE:  Oh, it's beautiful, yes.



LEO:  It's thin.  It's light.  Two pounds, which is really pretty light.



STEVE:  Oh, lord.



LEO:  Are you worried about one connector, though, the USB FC?



STEVE:  I guess I'm worried about one odd connector because I don't have any of those USB devices.  Maybe we'll start getting them.



LEO:  Yeah, Google's already announced a new Pixel that uses two of them.  Apple should have done two, by the way.



STEVE:  Yeah, I think so.



LEO:  Then it would be easy; you know?  But they only did one.



STEVE:  But my point is that we will then need an outboard converter.  And I've always been a little annoyed by Apple, like the main device sells at a good price, but all of their little accessories really do seem jacked-up profit margins for the other thing that you need because, oh, your TV doesn't have a lightning connector?  Well, you're going to have to get [indiscernible].



[Crosstalk]



LEO:  Well, here's the good news.  Type C is not, is no longer proprietary.



STEVE:  Right, right.



LEO:  In fact, that's kind of stunning.  I can't remember Apple ever - or most laptop manufacturers ever doing nonproprietary power connectors.  That's a profit center.  So that in my opinion is a good thing.  And by the way, USB Type C, because I had to look this up, not only does it power, but it can power up to a hundred watts.  You can put a lot of power across it.



STEVE:  Hundred watts.



LEO:  I know.  I don't think any laptop does that.



STEVE:  A lot of those pins must be conveying power.  And so you can use as many as you like.



LEO:  I think you're right.  I think it's probably like that.  If you're going to use it for video, you obviously aren't going to put a hundred watts of power across it.



STEVE:  Exactly.



LEO:  Yeah.  I'm really - I think that, because Apple will jumpstart USB Type C, we're going to see it everywhere.  It is a standard.  And that is a good - if the one thing accomplished by the MacBook is that laptops, like phones, have a single standard adapter for their power, that's huge.  And at least the dongle you buy is going to be usable with other things.  It's not just an Apple dongle.



STEVE:  And it also means, yes, it also means crazy video.  I mean, through - that means that USB-C is now fast enough.



LEO:  Yeah.  There's two 10-gigabit channels on it.



STEVE:  Oh.  Oh, 10 gigabits.



LEO:  Two.



STEVE:  Oh, nice.



LEO:  Yeah.  So that's good.  I'm excited.



STEVE:  Yeah.



LEO:  If for that alone.



STEVE:  I just love gorgeous engineering.  And the new MacBook Air is just - it is just sex.  It is, you know, the idea that they say, okay, well, we want a wedge-y sort of overall profile.  So that means that we're going to have a wedge-y sort of interior cavity size because the screen is going to be flat.  But if we have a standard prismatic cell, as they're called, the lithium polymer cell, which can be any shape you want as long as it's square, then we're going to lose a lot of space.  And in their video they just show that so elegantly, where at any thickness, this thing can't, like, come down into the nose, into the front edge of the laptop because it's too thick.



So Apple scallops their batteries in a series of multiple scallops.  They figured out how to come up with a layered battery that ends up being one unit, but where, as it goes lower, these scallop sizes pull back, and the effect ends up being the equivalent of a wedge-shaped battery that is then able to tuck itself right down into the smallest interstices of this case.  And I don't remember what the number was.  But it resulted in substantially better overall power delivery.



So I just - and they took the existing logic board that was already high density and said, okay, this is three times bigger than we need it to be, or maybe it was four.  We're going to cut this thing down to much smaller.  And when you look at it, it's like, oh, my god.  I mean, so they designed it so that the components would nest into each other.  And of course the big change is no moving parts, no blower any longer.  So they were also able to remove the fan completely.  So not only is it always silent, but boy, getting rid of that is a great achievement.  So, oh, I think that is - I think currently it's the penultimate statement in a fully functional portable laptop computer.



LEO:  But you use the iPad for, like, you'll take the iPad to Starbucks; right?  I mean...



STEVE:  Oh, my lord, yes.



LEO:  So this is kind of midway between a MacBook Pro and an iPad.  It's kind of - it's light, it's thin.  By the way, not the lightest and thinnest notebook out there.



STEVE:  Oh, and the new design of the keyboard, so that the keys are not kind of rocky tilt-y any longer.  They came up with what they called a "butterfly" design, so that they were able to get even less height, yet like a firmer feeling key, so that you can still type on it.  And the keyboard also goes edge to edge on the - anyway, I don't mean to sound like an Apple fanboy on this.  But, boy, you know, I have...



LEO:  Well, those keys are not going to have the travel of previous laptop keyboards, so...



STEVE:  They can't.



LEO:  They can't.  There's nowhere for them to go.



STEVE:  There's nowhere for them to go, yeah.



LEO:  So I've used, like, my ASUS, I'm sorry, my Acer S7, which is equally thin, the keyboard was almost unusable at first because it had so little travel.  I made a lot of mistakes on it.  They improved it in the second generation, the Haswell version.  So I'm curious.  We'll see.  You kind of got used to the S7.



STEVE:  At some point it becomes too much of a compromise.



LEO:  Right.  Haptic, I think haptic on the trackpad, though, I can't wait to see what that feels like.



STEVE:  Oh, yes.  And on the Watch.  The Watch has it, too.



LEO:  Rene Ritchie, who was there - and the Watch has it, too.  Rene Ritchie, who was there, and Serenity Caldwell and Jason Snell, all said it's kind of uncanny, even though the trackpad doesn't click anymore, because of the haptics, it feels - you feel like there's a physical thing happening.  It tricks you.  And so I'm curious about that.



STEVE:  Yeah.  And then of course the deep touch, or power touch, or power click, or...



LEO:  Force Touch.



STEVE:  Force Touch, right.



LEO:  Which is actually a terrible name.



STEVE:  I know, I thought the same thing.



LEO:  It's not a good name.



STEVE:  While Tim was saying it, I was thinking, well, how about something else?



LEO:  Yeah.  Force implies that you're using force.  And I would hope it's not like I have to [groan] push down on that thing [groan].  More touch, slightly more touch would be good.



STEVE:  I think they've just done a great job.



LEO:  Well, they've obviously won you over.  I presume you're going to order one immediately.



STEVE:  Yeah, I like my existing Air, and this one replaced it.  It's just, as I said, it's just a work of art, a work of engineering art.



LEO:  I'm going to get the gold one because I'm that douchebag.



STEVE:  I have a gold S, I mean, a gold iPhone 6 Plus.



LEO:  It's kind of - it's not like bright gold.  It's kind of a nice, tasteful...



STEVE:  And we know it's not real gold.  It's just painted on.



LEO:  Yeah, it's gold paint.



STEVE:  So it's like, you know, yeah, gold tone.



LEO:  At least they're not charging a hundred bucks more for the gold one.



STEVE:  My god, or $10,000.  So my only mention this week of SpinRite was just - it's from a tweet that came in on the 11th, which was - what is that?  Yesterday, at 7:22 in the morning, Michael Parker tweeted:  "@SGgrc Hey.  A decade of waiting to use SpinRite, but never found a need.  My day finally came.  It saved my SSD, which would not boot.  Thanks."



LEO:  Aw.



STEVE:  So further substantiation of what everyone is seeing, which is SpinRite has a bright future because it moves right into solid state mass storage without skipping a beat.  So thanks, Michael.  I did thank him via the Twitter for his note and for implicitly allowing me to share that with our listeners.



LEO:  Steve Gibson, you are a trooper.  We hoped you'd be better by now, but a cold is a seven-day affair, isn't it.



STEVE:  We're going to get it done.



LEO:  Thank you for being here.



STEVE:  Glad to be.



LEO:  If you're tuning in right now, we've got about a half an hour before TNT, and we're going to get the FREAK and the RowHammer on right now.



STEVE:  Okay.  So this is bizarre, FREAK.  I got a lot of tweets from people when the news broke, saying, oh, my god, should I worry about this?  What should I do?  And the answer was it's a bizarre thing that was discovered in today's contemporary, as of two weeks ago, SSL/TLS secure network stack software, existing in Apple's own SSL, their secure transport technology, and the most recent version of OpenSSL, actually before v101k, are vulnerable.  So, and the OpenSSL guys were given a heads-up about it last month.



But it's not something that the end user has to worry about.  And unfortunately, this was another one of those things where the popular press jumped on a sort of true but technical aspect that sounded really bad.  What was discovered was a surprising cipher suite downgrade attack that would - and this is what's shocking - that would downgrade to a cipher suite that nobody even supported.  It's like, what?  What?



LEO:  Well, there's a reason nobody supported it.



STEVE:  Well, but, okay, but there's a subtlety there, too.  The way TLS works is that your client gives the server a list of cipher suites that it knows.  And then the server looks at its list and picks the one that is the best, that it considers best, from its list that the client also supports.  And then it uses that to establish the cryptographic connection.  Long, long ago, as you said, Leo, and this ties back to what I was talking about before, the export-grade cipher suites were eliminated.  So, and the way that actually feels is that, in a list of cipher suites, we've talked about GRC's list, I think it's - I have a bit.ly link, bit.ly/grcciphers.  And that gives you a text file of the list of cipher suites.  And among those are RC4 at 40 bits.  And it was like, you know, and 40 bits is the symmetric key length.  And with that comes RSA-512, which is 512-bit for the public key component of the cipher suite.



Remember that we both need a cipher suite, and this is why it's called a "suite," is it specifies it's a chain of different crypto.  There's the specific public key negotiating side, the shared symmetric key technology and length, and then how they do message authentication.  And so a given one of these specifies those things.  And I saw them a couple months ago there in the list of ciphers that Windows Server 2008 R2 that I'm using offers.  And they're like, they were down at the very bottom of the list.  And I only had, what, 2K of registry space to list mine.  So any sane person would never get down that far.  But you'd also never choose that.  You would never, like, say, oh, yeah, I want to, today, in 2015, I want to support a 512-bit RSA.



Now, we're still using 1024-bit RSA and moving to 2048.  And it's important to remember that 512 is not half of 1024.  It's half in terms of bit length, but it's 2^512.  The 1024, RSA-1024, while only being twice as long, is 2^512 stronger.  So it's a radical jump from 512 to 1024.  And we're making another similar, even more radical jump when we go to 2048.  That's 2^1024 stronger than 1024-bit RSA.  So what we're talking about is a dawn of the Internet, like the original Netscape browser's SSL, when strong crypto was still regarded as a munition, therefore in this weird case you could use it in the U.S., but not outside of the U.S.  So browsers offered their list, their sort of a curated list of cipher suites that are strong, that they support.  The server does the same thing.



Here's what some researchers discovered completely out of the blue.  Remember that cipher suites all come with a commonly recognized hex designator.  That is, all of them, there is that long textual form, but there's also just a simple two-byte designator to say - sort of give it a family and within the family designation.  And some standards body, IETF or ICANN or somebody, probably IETF, have standardized on what these numbers are.  What these researchers discovered, and they stumbled upon this because they were - they wanted to experiment with building a very strong fuzzer for SSL and TLS.  A "fuzzer," of course, is the industry's term for just throwing all kinds of random stuff at an API and see if you discover any surprising breakage, something that it's not supposed to do.



And here's what they found.  If a man in the middle intercepted the client's opening handshake to the server, and that opening handshake is going to contain a range of cipher suites that we would all think in this day and age are strong, even Chrome, for example, we know Google would be the last place on Earth that any browser is going to send a weak cipher suite.  So the man in the middle intercepts that, removes them all, and puts in that designator for export-grade crypto from the dark ages and forwards it on to the server.  The server, 37.6% of the servers on the Internet will go, oh.



LEO:  Yeah, sure.  You're stupid, but I'll be stupid, okay.



STEVE:  Shoot.  If that's all we can do, then I guess so.



LEO:  Wow.



STEVE:  I mean, there is a cipher suite that is no cipher.  There's like a null.  I think it's zero.  And fortunately I think they don't respond to that.  But the 36.7%, or 37.6, something like that, more than a third, said, oh, okay.  And so the server then responds to the client, and the client, who never even offered that cipher suite, but sees that the server has decided to use this export-grade cipher, says, hmm, well, I have that.  So, okay.  So this begets so many questions.  First of all, why are these even in any OS at all?  There's absolutely no reason for it.  The null cipher is gone.  Kill this one, too.



But the point is that no one did.  OpenSSL was vulnerable.  OpenSSL, you might argue that because it has such a wide range of applications, and many of them are like it's the development and testing platform for TLS, they're going to keep them all around.  Okay.  So maybe allow them to be installed, or allow there to be some sort of special access to these really, really brain-dead ciphers.  But don't advertise a secure set and then accept one that you never advertised.



So that was what they found.  They found both that a shocking number, I mean, even Apple's Secure Transport was vulnerable to this.  A shocking number of existing systems - oh, and IE, that's what Microsoft fixed on March 9th was they removed this "characteristic" from Internet Explorer.  It, too, was vulnerable to this.  So not only were these absolutely no longer can we even consider this to be secure cipher from the OS, but it's still there.  It also turns out that you could just use one of these that was not advertised, and both ends would say, oh, I didn't really think you were going to come back with that one, but okay, fine.



And so that's FREAK.  The response, as you can imagine, has been swift, as swift as possible.  Apple's fixed it; Microsoft's fixed it; OpenSSL has had it for a while.  Akamai, I had in my notes here the number of - okay.  So who had vulnerable servers?  36.7% of the 14 million sites serving browser-trusted certs, meaning that in a scan on port 443, you don't know for sure that you're probing a website because you're not scanning by domain name, you're scanning by IP address.  So you're just covering the entire Internet.  But when it returns a cert that browsers trust, it's a very good bet that this is a web server.



So that was their selection criteria.  So the Internet had 14 million sites serving browser-trusted certs, and of those 36.7% were vulnerable.  But many of those, it turns out to be Akamai content delivery network, CDN, endpoints.  So that skewed the numbers a little bit.  And Akamai is busy, they're going to be doing like a major retrofit in order to bring their whole network up.



But there were some embarrassments in here, too.  The U.S. government sites, such as www.nsa.gov...



LEO:  What?  What?



STEVE:  ...was vulnerable to this; www.whitehouse.gov and irs.gov.  And the FBI tips site, tips.fbi.gov, all vulnerable.  And the Facebook.net site, it's connect.facebook.net, that's the domain name that serves the ubiquitous across the Internet "Like" buttons from Facebook.  It was vulnerable.  And an attack, a man-in-the-middle attack on that could have had huge consequences for the security of Like buttons everywhere.  So this thing was - it was pervasive.  In the show notes, if anyone's interested, I have a complete list of the vulnerable TLS client libraries and the web browsers.



Well, in fact, so Chrome, versions before 41 on various platforms were vulnerable.  So I just said that Chrome wouldn't be advertising insecure cipher suites, but even Chrome left them in there for, like, no explicable reason.  Internet Explorer on OS versions before March 9 are vulnerable.  Safari on OS versions before March 9 are vulnerable.  Opera, versions before 28, which I'm sure is recent, are vulnerable.  Android browser is vulnerable, switch to Chrome 41.  And, you know, we've discussed before how unfortunately Google, for just practical reasons, is unable to go back in time and service the millions of very earlier version Android browsers.  They're always going to be vulnerable.



The good news is the sites they are probably going to be connecting to will not be vulnerable.  And you need this vulnerability on each end.  So essentially this won't affect Android users even of early browsers because there'll be nobody vulnerable for them to connect to.  And the BlackBerry browser is vulnerable, and we're still waiting for a patch for that.  I'm sure BlackBerry, because they're a going concern, will fix it.



LEO:  Sort of a going concern.



STEVE:  Well, yeah, exactly.  At least, you know, still interested in...



LEO:  Still in business, yeah.



STEVE:  ...not having any overt security flaws in their products.



LEO:  No, in fact, that's a big part of their product pitch, isn't it.



STEVE:  Yeah, exactly.  So really interesting discovery.  It's like something that has been lurking in our TLS libraries from the beginning that we just didn't see.



LEO:  Did you check if ClintonEmail.com was vulnerable?



STEVE:  I had that thought, actually.  I didn't see that Windows Server was ever vulnerable.  And ClintonEmail.com was using Windows Server 2008 R2...



LEO:  Yes.



STEVE:  ...as its OS platform.



LEO:  Although they didn't get secure certificates for the first three months of her term as Secretary of State, so...



STEVE:  Wow.



LEO:  Yeah, that's just come out.  So, but it is secure now, if you'd like to use it.



STEVE:  Well, yeah, exactly, yeah.  Okay.  Our final topic.



LEO:  RowHammer.



STEVE:  RowHammer.



LEO:  Like this name.



STEVE:  Exploiting DRAM.  Exploiting DRAM.  So this began with a team of researchers at Carnegie Mellon University, which I in the past have referred to as Carnegie Melligan, but we don't do that anymore.  Carnegie Mellon.



LEO:  Really?  Carnegie Melligan?



STEVE:  I said Carnegie Melligan once, and it's like, okay, what?



LEO:  That's the Irish, the Irish - it's in Dublin, Carnegie Melligan.



STEVE:  It has sort of more of a rhythm to it.



LEO:  Yeah, it does, it's nice.  Actually, I want to start a university called Carnegie Melligan.



STEVE:  Yeah.



LEO:  I like it.



STEVE:  So these researchers did the groundbreaking research.  And in the show notes is a link to a 12-page PDF that is really interesting, has a lot more details than I'm going to go into because I'm going to go into plenty as it is.  They discovered a way of affecting, deliberately affecting bits in RAM that were not otherwise under their control.  That is, when a process is in an operating system, it has RAM that's been allocated to it by the OS.  And so, but part of the containment that the OS provides through the page table mechanism is this interprocess isolation.  That is, a process sees RAM, and it might even see the same address ranges of RAM, as some other process.  But the page table mechanism in contemporary CPUs, pretty much all of them that support virtual memory, virtual memory is the name for this, is such that when the process generates a fetch of any kind, or a write, that address is mapped through several layers of indirection.



So basically what looks like an actual memory address is actually a pointer to a slot in a table that the processor uses to map that to a physical RAM address.  And this becomes important in a minute because of the work that the Code Zero guys at Google followed up this initial groundbreaking research with.  So what these guys at Carnegie Mellon discovered was that they could perturb bits in RAM in adjacent rows, thus the term "RowHammer."  We've talked about DRAM before.  DRAM is the only technology which has steadfastly resisted the normal performance increase curve that everything else has gone through.  It used to be about the same speed of the processor, but the processors just went crazy.  And the speed of RAM, while increasing, really lagged behind.



At the same time, the density of DRAM has increased so that we've got an incredible amount of DRAM now on a small set of chips that was never possible once upon a time.  The Intel, the first DRAM was I think the 11.03?  Maybe it was 11.02, but it was 11.0 something.  And I think - and it was like the classic DRAM.  It was 1-Kbits.  And so that was addressable as 10 bits.  So that would be five bits for row and five bits for column.  So that's a 32 by 32 array of bits, which was all we could do back then.  And everyone thought, oh, my god, that's - we don't have any, so thanks very much, Intel.  Now we have gigabits.  We have that by dramatically shrinking the cell size of DRAM.  And DRAM is essentially capacitors, which can be charged up to a certain level.  And just through the nature of how small they have become, they tend to discharge by themselves.



So the idea with DRAM, it's really nice that we've got this, like, this incredibly low-component-count cell.  But because it isn't very static, it's necessary to come back around and read it before it has had a chance to discharge into the uncertain region, where we're not sure if it was ever a one or it was always a zero.  So thus DRAM must be refreshed.  And it's typically refreshed every 64 milliseconds.  What these guys discovered is that, if they could arrange to hammer the adjacent row in DRAM a huge number of times in between refresh cycles, they could flip some bits.



And they didn't do the work of exploiting it.  But to their credit, the Code Zero team did.  Google's Code Zero team picked up this potential problem and basically weaponized it.  They have two proof-of-concepts now.  One was an attack on their own Native Client technology in Chrome.  Native Client is the very impressive but kind of scary idea of running native x86 code in the browser.  Rather than JavaScript, you run actual machine language, thus giving your browser the same performance on a browser-based application as a native application on the computer would have.  To pull this off, they do all kinds of voodoo, among which is they break the instructions into 32-byte blocks and analyze them in those pieces and make sure that no skewed analysis could create a privileged instruction.



So what they do is they only permit a subset of x86 instructions that are safe to run in sort of this scary sandbox that they create.  But it turns out that, if you were to flip a bit in one of these 32 blocks of machine code, you could turn what was previously scanned and checked out as being safe into being unsafe.  And so they created an exploit that actually managed to break out of their own Native Client sandbox.  And it was the guy that was the project lead on this, he had been the developer and the previous cracker of the Chrome sandbox, so he chose that as his first target.



The second proof-of-concept exploit they pulled off was against a 64-bit Linux system.  And what's scary is it is shockingly powerful, and we don't have a solution for it.  The good news is it's because Linux broadcasts a processor's page table, called the "page map," that the processor can see how its physical memory is mapped into its logical memory.  That's sort of the - it's necessary for this particular exploit.  So, for example, I'm not aware of any way for a non-driver in Windows to access that mapping between virtual and physical memory.  But Linux makes it simple.  It's /proc/PID/pagemap, and it gives it to you.  So by using a short loop in machine language, they were able to flip a bit in their own page table which gave them global access to the system's memory.  They were able basically to take control of their own process page table from the OS, giving them complete global access to the system's RAM.  And this is, I mean, just an amazing work of engineering.



What I did want to share, just in closing, is that they created a GitHub site where they have a self-test for Linux users.  And I've got it in the show notes.  It's in GitHub,  /google/rowhammer-test.  And in Google's testing, half of the 30 laptops they tested, they were able to exploit.  And in the Carnegie Mellon research, almost all of the DRAMs, they had 129, I think it was, different DRAM modules from three major manufacturers.  They were able to compromise 111 out of the 129.  And they noted that the problems seemed to be recent.  It was new models of DRAM that was having the problems as opposed to old.  So it's looking like the cell size has recently shrunk in order to bring up the density to such a point that we're seeing the integrity of DRAM damaged to a point that it's now exploitable.  So that's RowHammer.  I'll probably have a few more words about it next week.  But I wanted to let everybody know what it was and what was going on with it.



LEO:  Thank you, as always.  You're the best, even on a day when you're feeling not so hot.  And thank you for making that effort.  Hey, one note I just wanted to pass on.  This came in as we were talking, and I know many of our viewers are science fiction fans.  Terry Pratchett, who is a wonderful, wonderful author, he created the Discworld series, they're really comedy-fantasy novels, but just brilliant, he's passed away.  He was suffering from early-onset Alzheimer's.  He called it the "embuggerance" and actually continued to write with some effort.  His last novel came out last year.



STEVE:  And also to reread what he'd just written.



LEO:  Now, come on.



STEVE:  Oh, okay, sorry.



LEO:  But you're right.  He certainly joked about it.  But it's very sad because he was only 66.  He was one of the, I think, one of the great minds, one of the great writers.  If you have not - this is an opportunity, if you've not read the Discworld series, to read some of it.  But very sad, Sir Terry Pratchett passed away at the age of 66.  And this would be a good time to break out those Discworld books.  There's something like 70 of them.



STEVE:  Oh, my goodness.  



LEO:  Yeah.



STEVE:  All by him, or by..



LEO:  Yeah, yeah.  The last one, he had a device he was putting on his head to kind of help him because it was hard to write, of course, towards the end.  But he managed to come out with one last one last summer.  And I haven't read it.



STEVE:  I think actually the problem was probably that he wrote 70 of those novels, and it damaged him.



LEO:  I don't know.  I don't know.  It's very sad.  He had suffered from, I mean, 66 is very young to pass away from Alzheimer's.  He contracted it I think seven years ago, so he was in his late 50s when he contracted it.  So for those of us in our late 50s, that seems too young.  Anyway, a great loss.  But read his stuff because it's just a great - and it's all on Audible, if you want to listen.  I just love it.



Steve Gibson is with us still.  Despite a cold, he is not, in fact, incapacitated, as you can see.  His mind works under all circumstances.  You can find him at...



STEVE:  The show must go on.



LEO:  It's amazing that after, and we've been doing it for 10 years, that this is the first time you've missed an episode.  And you didn't miss it, but first time we've delayed an episode due to illness.  So thank you for coming in early.



STEVE:  So Q&A next week.



LEO:  Next week Q&A.  So go to GRC.com/feedback to leave your questions.  Or tweet him, because we often take tweets in the questions, @SGgrc.  You'll also find SpinRite at GRC.com, the world's best hard drive maintenance and recovery utility, and lots of freebies.  And 16Kb audio versions of this show, which sound kind of like they were recorded by Thomas Edison in his lab, but they're small.  Smallest version, though, is the text version.  Elaine Farris does a great text transcription of each and every episode.  Those are all at GRC.com.  We have high-quality audio and video versions at our site, TWiT.tv/sn, and wherever podcasts are found.  And I hope you'll subscribe so you don't miss an episode.  This is one of those shows, almost 500 in now, where you really - 498.



STEVE:  Two more, baby.



LEO:  And, you know, TWiT just did its 500th Sunday.  So this whole network is starting to show signs of aging.  But we soldier on.  Thank you, Steve.



STEVE:  Thank you, my friend.  Talk to you next week.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#499

DATE:		March 17, 2015

TITLE:		Listener Feedback #208

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-499.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, of course.  We'll get through all the security news and then answer some questions.  How secure is the new Type-C connector?  Is it susceptible to BadUSB?  Steve has a good idea, something that could make him a million dollars, but he's going to give it to you for free next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 499, recorded Tuesday, March 17, 2015:  Your questions, Steve's answers, #208.



It's time for Security Now!, the show that protects you and your privacy and all that stuff online.  And there's never been a better time for Security Now!.  Steve Gibson is here.  He is our Protector in Chief.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you on our regularly scheduled Tuesday.



LEO:  You sound better.  Are you all better?  You feeling good?



STEVE:  Ah, we're just sort of in the mopping-up phases of last week's disaster.  Yeah, as I mentioned then, I hadn't been sick in, well, I have never been sick on a podcast, and I don't think I've been sick in 10 years.  So it was - I guess it was something you have to go through every so often as these viruses - it's funny, too, because I had various friends wanting to just get together and hang out.  And I said, no, no, no, no, not until I am absolutely sure that this thing is dead and gone.  It exists to try to reproduce and live.  That's what a virus is, you know, it's a life form trying to perpetuate itself.  And this one stops here.



LEO:  Yeah, there was a science fiction novel I read, oh, I wish I could remember who it was.  That's exactly what he - he's talking about his parents, who got replicated out of existence by another life form, a virus.  Oh, I wish I could remember.  Anyway, yeah, that's kind of what it is.  If you think of it that way, it is, it's another life form.



STEVE:  You might be thinking of, what was his name, Phssthpok?  I think it was a Larry Niven novel ["The Protector"].



LEO:  Might have been a Larry Niven.  I wouldn't be surprised, yeah.



STEVE:  Yeah.  And we don't understand the lifecycle of the species until the very end.  One of the things I loved about Niven's books is that they really surprise you.  You feel like you're engaged, and you're watching the plot, and you know what's happening.  But there's a whole big meteor about to drop on you.



LEO:  I love that kind of - I love that.



STEVE:  Where you just don't - you're completely blindsided.  You do not see it coming.  Now, that kind of book doesn't read a second time as well because it really does depend upon you being fully informed, yet completely unaware of something crucial.  But anyway, yeah.  And I don't think that Jerry does that.  He has that when he co-authors with Niven, but...



LEO:  Oh, maybe it's a Niven thing; huh?



STEVE:  I think it's a Niven thing because in some of Larry Niven's own books, he does that.  And I see it when they do it together, but not in Jerry's solo work.



LEO:  I love plot twists.  I just love them.



STEVE:  Yeah, yeah.  So we have sort of an interesting week of stuff.  Not huge, catastrophic, sky is falling news, but good stuff to talk about.  There's a new nasty crypto thing now making itself known called TeslaCrypt. I want to talk about the Yahoo! announcement at SXSW on Sunday, their move to eliminate passwords.  Then there was a big scurry because, if you didn't really understand the problem, you could easily say "Comodo does it again."  But that's why I said, uh, kinda.  And then the InstantCryptor guys, who I introduced a couple weeks ago as sort of a teachable moment, where they were doing a web-based encryption, but it really missed something important.  They found out, tried again, but still haven't got it right yet.



LEO:  Oh, no.



STEVE:  So we have more teachability.  And then a great - we have a Q&A this week, so 10 questions, comments, and answers from our listeners.



LEO:  Good show ahead.  The news.  That'll kick things off.



STEVE:  So can you bring up our picture of the week?



LEO:  Yes, I can.



STEVE:  This is a capture of the screen which someone is presented when they've been unlucky enough to get TeslaCrypt installed.



LEO:  It's like a CryptoLocker, kind of, but for a specific...



STEVE:  Well, okay.  So it is, it's like, it's very much like CryptoLocker.  In fact, it even borrows a little bit on the CryptoLocker brand by using a CryptoLocker.lnk link which it leaves on your desktop, even though...



STEVE:  Oh, that's a...



LEO:  ...the guys, yeah, it's weird, sort of like they want to trade on the brand.  The guys at Sophos have noted that the code is completely different.  So in no way is this CryptoLocker.  But what strikes me when I'm looking at this is how professional-looking this has become.  The first CryptoLocker was that annoying neon red, amateurish sort of, it looked like it was just sort of thrown together at the last minute.  This thing's got TeslaCrypt in barcode across the top, and that's actually a legitimate barcode.



LEO:  Wow.  Wow.



STEVE:  So they took the time to actually do - if you notice, the barcode above the T at the front and the back are the same.  No other letters in there repeat, so you can't verify that further.  But, and, I mean, look at it.  What I love is just how cheeky this thing is.  It says, oh, by the way, all your important files are encrypted.  It's like, what?  And then very clean-looking text, "Your Bitcoin address for payment" is like this.  And at the moment the cost for private key for decrypting your files will be 1.5 BTC.  And they handily convert it into U.S. dollars.  It's about $415 U.S. at this point in March.



And so they can accept payment to give you the benefit of their decryption of the files that they just stole from you, essentially, either by Bitcoin or by something called PaySafeCard or Ukash.  Although the cost for using either of those two, the non-bitcoin choice, is higher, it's 400, which is around $600 U.S. at this point.  And as a final teaser, sort of as a proof that they really can do this, they will decrypt one file for you to prove they can.  So you could, like, oh, my god.  And then when you sort of settle down, and you think, okay, what one file must I really have?



And they don't decrypt it on your system because that would subject their private key to capture.  Instead you upload the file to them, they use your private key which only they have to decrypt the file, and then allow you to download it again in order to verify that they're able to do that.  So this is what we predicted on this podcast the first instant that CryptoLocker came out, the first one, because it was making too much money.  Oh, and I should also say that it says here, "Payment verification may take up to 12 hours."  And similarly there is a time limit on your ability to do this.



So basically they're moving forward with this model of encrypt your files because it makes, well, basically it makes money.  They've taken something away from you in a way that you can pay to get it back.  And unfortunately, many people do.  What's different about this latest version, this TeslaCrypt, although brand new code, so not apparently related to the others, is that, as like the others, it will seek out photos, financial spreadsheets, office documents and so forth.  But in addition, it seeks out files related to dozens of games, including saved games, configurations, maps, and replays.



LEO:  It knows how valuable those are to some people.



STEVE:  Exactly.  You have a major first-person investment in that stuff.  So it targets Call of Duty, World of Warcraft, DayZ, Minecraft, Fallout, and Diablo, as well as configuration files for Steam, which is of course the online gaming platform.  And also, maybe because of the time of year, looks for files related to tax returns and personal finance such as Intuit's Quicken software and iTunes stuff.  And it can now extend its reach into devices and drives connected by any means.  And it will encrypt the files out on those, too.  USB drives, network file shares, cloud storage folders, and other connected storage devices.



So, you know, this is, I mean, this was foreseeable when we first saw the first one.  And what was so troubling was that these guys had done the crypto right so that it was pay them or, hopefully, fall back on a backup and recover from the point of backup, essentially.  But so this is, you know, the predictable evolution of this concept of encrypting your files.  I think, unfortunately...



LEO:  Not surprising, yeah.



STEVE:  It is, exactly, it's the way of the future.



LEO:  Did you see Triangulation yesterday?  Because we had a guy named Marc Goodman on it.  It was great.



STEVE:  I missed it.



LEO:  Yeah, it's about - the book is called "Future Crimes."  But he's a former LAPD street cop who - it's a great story.  In '95 his sergeant said, "Hey, Goodman, do you know how to start spell check in WordPerfect?"  He said, "Yeah, it's Control F2."  He said, "Good, you're hired.  You're on our forensics team."  And he was like, well, you know something about computers, anyway.  But he became a forensics guy, worked for the Secret Service, the FBI, Interpol.  And it's a really compelling book because he's talked about how these guys - this isn't some teenage hacker in Bulgaria anymore.



STEVE:  Right, right.



LEO:  He said they're like startups.  They have health plans.  They have HR.  They have, you know, they recruit.  You get a job.  And that's why it's starting to look like this.  They probably have actually designers working there because there's so much money in it.  So these things are run like startups.



STEVE:  You can imagine them on some foreign soil saying, oh, let's get the money of those rich Americans.  I mean, for them it's just sport.  It's like, why not?



LEO:  Well, it does raise this issue, and he says this, too, he says, you know, I feel like if you're young and you're smart and you're a math major or a computer science guy or gal, and you're thinking about what to do, I would hope you would have, you know, some altruism, maybe want to do public service, maybe want to help law enforcement fight these guys.  But unfortunately there's so much money in being a bad guy.  And I worry that maybe we've raised a generation that's not immoral, but just kind of amoral, and that they're going, well, you know, it's a good job.  It's a good gig.  I'll do it.



STEVE:  Yeah.  Hey, I had it in my rsum, I floated it around there, nobody would hire me, except these guys would.  So I'm doing it.



LEO:  Well, and he says we need about, what was it, a million new cyber experts in law enforcement next year.  And there's just nobody - they can't hire enough people anymore.



STEVE:  No.



LEO:  You would like it because he recommended, he's a listener, and he recommended all the things we talk about.  He has a protocol, in fact you can go to TrueCrimes.com and read it, you'll completely recognize this, called Update, which is what everybody should do.  He says the best model for this is not to fight fire with fire, but in fact kind of treat it like a public health issue with kind of an epidemiological foundation, have people protect themselves, do the right thing.  Update their software.  Don't run as administrator.  All that stuff we've been talking about for years.  The only thing I disagree with is one thing.  He says, "Turn off your router when you're not using it, or unplug the Ethernet cable because that reduces your attack surface by that many hours."  I don't think that's...



STEVE:  Technically.  But, yeah, it's not...



LEO:  But everything else...



STEVE:  I wouldn't have mine on right now if that was true, yeah.



LEO:  Well, I mean, like, when you go to bed, unplug.  But you would never do that because you've got services running all the time.  I don't know if that's going to help you much, anyway, but...



STEVE:  Yeah, I sort of agree.  And it's funny, too, because immediately I jumped to - and this idea of the epidemiological model, that people, eh, you know, really they don't get involved because they feel like they don't really understand their computer.



LEO:  And they feel like, hey, it's just me.  And we have to emphasize that, if you don't get vaccines, it's everybody who suffers from it.  It's a societal problem.  If you don't protect yourself, your computer becomes part of the problem.



STEVE:  Right.  And what I was going to say was that, from a health standpoint, I'm increasingly in touch with how actually the model is the same on health.  People don't understand their own body, don't really know what they should do.  They get conflicting advice and suggestions from everyone.  So they just sort of tune out.  It's like, eh, well, I'll just have some, you know, chips, and that doesn't seem to hurt me immediately.



LEO:  We should get you on the radio show more, maybe, and do kind of this "for real people" stuff, you know, for non-geek.



STEVE:  I mean, as you noted, it's becoming increasingly important.



LEO:  Yeah, no, let's talk because I would love to get you on maybe the radio show every few weeks and talk about it.



STEVE:  Good.



LEO:  Yeah.



STEVE:  So Yahoo! announced at SXSW on Sunday that they had decided to make the option of no passwords.



LEO:  This cracked me up.



STEVE:  Yeah.



LEO:  Oh, I'm really curious what you think of this.



STEVE:  Well...



LEO:  They are one-time-only passwords; right?



STEVE:  What I like about this is that listeners to the podcast already have all of the information that we need in order to, like, parse this, to understand it.  We were - it's funny because I'm seeing people in the press talk about something you know and something you have.  And I'm thinking, you know, did they get that from us?  Because, I mean, we've been talking about this stuff for years, you know, not quite a decade, I think.  But those were the terms that we introduced for this notion of multifactor authentication.



And what Yahoo! has done is, I mean, they do have multifactor authentication, and they have traditional single-factor username and password, where it's something you know.  What they've now done is created a different single-factor authentication which is not something you know but something you have.  In other words, what they're promoting is that, if you elect to flip your Yahoo! account in this direction, then when you want to log in, you do not give it a username and password.  I guess you have to give it a username.  It has to know where to send the one-time password.  So you just must give it a username.  And to a device which you have preregistered with your account, it then sends a - and they call it an "on-demand password" is their new term for that.  It's like, okay.  So they own a little chunk of rather useless intellectual property.



But the idea is that it then sends your phone, via SMS, exactly the kind of thing we've always been talking about, some sort of never-to-be-repeated string.  You enter that into this login screen, and it says, oh, okay, fine, you're authenticated.  And so Yahoo! is of course billing this as that wasn't a password that you had to remember.  You now no longer have to remember anything.  Isn't that wonderful?  And the reaction has been, well, largely from the security community, everybody's in favor of innovating on authentication.  Of course I've been spending the last 18 months innovating on authentication.



And it's funny because I see, I've got so many people tweeting, I was cc'd with mentions in people tweeting to Yahoo! or anybody else in the press who dared mention this, about SQRL.  It's like, yeah, yeah, yeah, we'll - don't.  It'll happen if it's going to happen, and it's not yet ready to be shown.  But so in general people are happy with the notion of innovation.  But a great chunk of the security community is made uncomfortable by the fact that now you don't need something you know.  It's only something you have.  Or rather, it's only something you are sent.  And that's a crucial difference.  It's not actually something you have.  They're billing it, not as something you know, but something you have.  It's not.  It's something you are sent.



So that distinction is the Achilles heel of this, as many people have noted, because it's an SMS message.  And one of the number one things that malware does when it can in a mobile platform is capture SMS messages that are received by the phone and send them back out.  So it just - it makes people uncomfortable that Yahoo! has, like, almost out of frustration with the problems they're having, done something different, but with a different set of problems.  And mark my words, we will see this thing defeated.  I mean, it's not like they've come up with something super secure.



LEO:  No, it's less secure; right?



STEVE:  Yeah, exactly.  The reason SQRL is special is that it is an online transaction.  The server challenges your device to prove a secret that only it has, and it responds to the challenge.  This has nothing like that.  So that, if somebody intercepted this token going to your phone and entered it themselves, they're logged in as you.



LEO:  And that's easy to do, I think.  I mean, SMS is not very secure.



STEVE:  Exactly.  It's a very weak, low-security messaging system, really never designed for authentication.  It was designed for, you know, "Hey, I'll be five minutes late" sort of messages.



LEO:  Well, it's fine for second factor.  But this is one - this isn't second factor.  And I think that's kind of...



STEVE:  Yes.



LEO:  To me it feels like Yahoo's trying to trick people into thinking, oh, this is like second factor, it's more safe, when it fact it's much less safe.



STEVE:  Right, because you are not needing to provide anything you know.  And in fact this would be something which, in a situation where you might be coerced to login, you can't say "I'm not going to give you my password" to the authorities.  They put you in front of a screen, type your name into Yahoo!, and your phone sends them the key they need to log in as you.



LEO:  They don't need you at all.



STEVE:  That's just one example of a problem that this system has.



LEO:  They don't need you at all.  They need your phone.  They can type in your name.  They don't need you.



STEVE:  Correct.  Correct.  Correct.  And so the challenge in designing something that is easier to use is we do want a device that can stand in for the user.  And that's why, and I don't mean to keep coming back to SQRL, but until this thing is out of my brain, that's where I'm living.  But so that's why SQRL prompts you every single time, only once for your full password, but then it reencrypts the first "n" characters, and you can decide how large "n" is.  And it keeps that in RAM.  It never writes it anywhere.  So every single time, every single time that you want to log in, you just get a little dialogue to confirm the name of the server where you're logging in, and you type click click click click, just like the first four characters of your password, and you're done.  It's not like people are logging in two times a minute.  I mean, when you think about it, you're not really authenticating that often.



But, and the key is, you miss that once, and it wipes it out of RAM.  So now you have to provide your full password again.  So it's, you know, I've worked to come up with a secure compromise where it wouldn't get in your way, yet it really, it truly would be a way for you to authenticate the device to then stand in for you.  Which is the power we're giving devices in this sort of a loop, like Yahoo! has implemented.  But even in this day and age it's just like, eh, we'll just send you an SMS.  Good luck.



LEO:  We should point out you don't have to use this; right?  It's opt-in.



STEVE:  Correct, correct.  And they do have two-factor authentication.  So the problem is, as you said, Leo, people aren't going to understand the danger.  They're going to go, oh, this is new.  This has just been announced.  This must, you know, Yahoo! must have figured out something to make this safe.  It's like, yeah, right, you know?  The authorities get your phone, and they're now able to log you into Yahoo!, if you choose this option.



LEO:  I don't think they even need your phone because can't they do a pen register and just get your text messages?



STEVE:  Exactly.  You are able to pull past messages received.



LEO:  This really is a pretty straightforward process.



STEVE:  Although I'm sure that it has a short lifetime and a single-use function so that you're only able - I hope it has those features so that it would expire and immediately expires when you use it.



LEO:  Somebody makes an excellent point, though.  If the system you use has some form of SMS password recovery, that would be no more secure than this, if that worked to recover the password with just a text message.



STEVE:  Yeah, that is a good point.  If you say, oh, shoot, I don't remember my password...



LEO:  Just send me a text.



STEVE:  Yeah.



LEO:  We've got to get rid of passwords.  We really do.



STEVE:  We do.  We do.  We do.



LEO:  It's just a bad system.



STEVE:  So this article, this whole issue of the Live.fi certificate that got loose.  Microsoft's all in a froth now, and they're sending out special notices, and everyone's running around.  I just - I have some technology, I'm pointing to it on the screen here, which monitors Chrome's CRLsets, which is, of course, the very controversial, very weak revocation mechanism that Chrome now has.  We went over this in depth, and I got into it with Google, of course, when I realized how worthless this was.  But the one thing they do is at the very top of that file are hard-coded revoked certificates.  And I'm somewhat dubiously proud to be number five in the list...



LEO:  Oh, wow.



STEVE:  ...for my, well, for my revoked, remember revoked.grc.com.  So they added me manually when people said, oh, look, Chrome has a bug.  And so they took me out.  And it's like, okay, fine, and then I changed my certificate, and now I'm back again, and they never changed their header.  So that revoked certificate that I'm no longer using is still revoked, and maybe it's always going to be there, I don't know.  But I'm no longer revoked because I just changed my cert.  But anyway, for the longest time it had eight entries.  This morning, about an hour ago, ninth popped up.  And I got a notification from the monitor, hey, the blocked, they call it "blocked SPKIs" changed, and there's a number nine.  And this must be the certificate that everyone's running around like crazy about.



So here's the story, though.  This is really not Comodo's fault.  Any certificate service could have made this mistake.  And it's really not the certificates - so my point is it's not the CA's fault in any way.  And I'll also note, just as an aside, I was a little surprised when I was doing some background research.  Comodo is running around flapping their wings because, as of February 17th, I think the blog post of the founder said, they are now the number one certificate provider on the Internet.



LEO:  What.  Wow.



STEVE:  For the first time.  Historically, for 20 years, it had been VeriSign.



LEO:  Right.



STEVE:  And of course VeriSign, they were the certificate provider.  Symantec purchased them some years ago, and but you still get to them at VeriSign.com.  They had always been number one.  They had been tied, and now Comodo has passed them by as the number one certificate provider on the Internet.  Which, you know, I don't think says anything particularly useful about them.  They're the last provider I would use for a certificate because, I mean, for example, they're the Superfish people also, and all of the Komodia...



LEO:  No, no, no, no.  They don't do Komodia.  They do something similar.  They used Komodia in one of their things.  Not Superfish, though.



STEVE:  Correct.  Oh, okay, right.



LEO:  Comodo does, what is it, I forgot what it's called, but they have an equally horrible program, yeah.



STEVE:  That's, you're right, good.  Okay.  So here's the problem.  When you go to any certificate provider, certificate authority, and say I want a cert for my site, they say, okay, you need to prove you're in control of that domain.  So what does that mean?  How could you do that?  For example, they can give you some text which you put on a certain page.  Like I've seen this, they'll - or they'll give you a crazy-looking page name, some grid-looking thing, just gibberish.html, and say, put this on your root, and let us know when you have.



And so then their automation will go check for that page on that domain.  And if it's there, it proves you're somebody who has control of the web server of that domain.  And so they go, okay, you proved it, so we'll give you a certificate in order to add TLS, HTTPS encryption to that site.  But if you'd rather, you could just use email.  They say, just make sure that you're able to receive email from admin, administrator, postmaster, hostmaster, or webmaster at domain, whatever your domain is, dot whatever.  And so these are the traditional webmaster or domain master sort of admin accounts:  admin, administrator, postmaster, hostmaster, and webmaster.  Those are the options that Comodo offers, although all of the CAs offer variations on that.



So just because this guy in Finland was curious, he thought - he had an account with Microsoft's Live service.  In this case it was Live.fi.  And the email service allowed you to set up aliases.  And he said, huh.  What if I try to set up an alias for hostmaster?  And it let him.  So he then became able to receive email sent to hostmaster.  That's all this was.



LEO:  Wow.



STEVE:  And then he goes to Comodo because, you know, they're now number one.



LEO:  I'm the hostmaster.



STEVE:  And he says, "I'd like to have a certificate, an SSL domain certificate for Live.fi."  And they go, okay, yeah, we do that.  Prove that you're in control.  And they say, what email would you like us to send your authentication challenge to?  And he said, "Uh, let's use hostmaster@live.fi."



LEO:  Whoa.



STEVE:  Email came in, he clicked the link in the email, they said, "Yay, you qualify.  Give us your 25 bucks, and we'll send you a certificate."  That's what this was.  And any other CA would have done it.



LEO:  Oh, my god.



STEVE:  So the mistake...



LEO:  Is Microsoft at fault for letting you create a hostmaster address?



STEVE:  Well, yeah, I think so.  I mean...



LEO:  Probably shouldn't do that.



STEVE:  So the real problem is that - and I love - Dan Goodin wrote, has written a number of pieces about this in Ars Technica.  And one line that I liked in his most recent note, he said, "The ease in obtaining such certificates and the difficulty in killing them off once they're issued are potent reminders of the continued insecurity of one of the Internet's most important security mechanisms.  And so the real fault is that...



LEO:  You're right, revocation.



STEVE:  ...it is that easy, is that authentication of domain control is as weak as it is, as weak as receiving an email to one of a number of preset accounts.  Now, what this means is, of course, to protect themselves, everybody who has an email system where users can create aliases or their own accounts absolutely must block all possible common names that any CA might use.  That's the problem.  There's no standard.  Comodo, I have never seen admin before, or really even administrator.  They just made those up.  But postmaster, certainly.  Hostmaster, okay.  Webmaster, yes.  But administrator or admin?



So the problem is this particular CA added a couple.  So to be secure against how trivially easy it is to authenticate via email, you'd have to make sure that you the domain controller went around and looked at every policy of every CA, and, I mean, that includes the Hong Kong Post Office, and makes sure that you have blocked anyone acquiring any of those email addresses because, if you don't, someone can, and they will prove to the system that they own it, and off they go.  Unbelievable.



Now, Windows 8 and on has added an automatic updater for revoked certificates.  It is available, but not installed by default, for Vista and 7 and also the server-side versions of that, Server 2008 and Server 2008 R2.  So I have a note here, I have a link in the show notes to the automatic updater.  If you're using 8 or later, you're already covered.  If you're not, that is, if you're on 7 or Vista, it's probably worth adding this.  It's a little lightweight gizmo, a little service that runs in the background, which will then, from now on, automatically allow Microsoft to revoke any certs of this sort that happen.



You know, this doesn't happen often.  There's a grand total of nine, and I'm one of them, on Chrome's bad guy list.  So it's not like there are a lot of these.  But when they happen, they tend to panic a lot of people.  And of course everyone ran around, even though this one guy had the cert, he could have said, hey, look, I didn't give it to anybody.  Here, you know, I'll shred it.  And oh, my god, no.  And so everybody, you know, all the browsers now have to scramble around and make sure that they don't, you know, that this didn't actually somehow get out and go somewhere else, when it was this easy to do all along, which is, again, the wakeup call for this whole system.



Note that none of this works for EV.  That is, it only works for domain.  On the other hand, the problem is that having a redundant domain certificate is fine.  That is, Live.fi might have been protected, probably is, by a legitimate Microsoft Extended Validation cert.  But that doesn't mean that the domain cert isn't just as good because that level of verification is all you're asserting.  And as we've said on this podcast before, it ain't much.  And this story just goes to prove it.



LEO:  Wow.



STEVE:  Okay, now, InstantCryptor.  These are the guys, it's www.instantcryptor.com.  And you'll find a new little blurb on their page acknowledging indirectly our coverage of this a couple weeks ago.  Remember that screenshot, I had a picture of Notepad, Leo, a couple weeks ago where it was just all full of crazy Chinese characters because I had decrypted with a different password, and InstantCryptor wasn't verifying the password in any way, which meant that, if you mis-entered it, you got gibberish back.



And I said, eh, you know, what that means is all they're doing is hashing the password to create a key and using the key with AES and Cipher Block Chaining to encrypt the file.  Which is fine and all, but it's really not the way it ought to be.  For one thing, you're not able to detect any modification to the file, which you'd really like to have.  What is necessary, I explained, was known as "authenticated encryption," where you're both authenticating and encrypting.  And there are a number of ways to do that.  So yesterday I saw a tweet from CloudRail, who are the guys behind this, and they said, "@SGgrc Thanks for your feedback about InstantCryptor.  We've updated it according to your advice to make it even more secure.  Any feedback?"  And unfortunately, here comes the feedback.



LEO:  Oh, boy.  You asked.



STEVE:  Yeah.  And I also found in my mailbag when I was pulling the Q&A questions together, an email that the subject was "Feedback on InstantCryptor.com," from Mannheim, Germany.  And the email read:  "Hello, Steve.  One of your listeners, who calls himself 'Advait from India,' has made us aware that you've discussed InstantCryptor.com in your podcast.  I'm the main developer behind this product and was eager to learn of your opinion.  In fact, we've modified the encryption procedure such that now the plaintext plus a hash value of that very plaintext is input for AES-CBC encryption, which allows us to check upon decryption if the password used was correct and if the message has been modified."  Except it doesn't.  "I'd be happy," Florian goes on, "to get feedback from your side and could provide you with more details.  Feel free to contact me under the mentioned email address."



Okay.  So what they did was they - it was another good effort.  But this is another, you know, the underlying lesson here is stop trying to invent cryptography.  That is, we're done with that phase, as I have said often.  There's nothing more.  There may be more bits, and every decade or two we get some major breakthrough the way we got elliptic curve after RSA.  You know, but that was a long time ago, and now it's only now beginning to roll out.  And the ways we put these pieces, the way the blocks are assembled, that's all done now, too.  But these guys sort of did another ad hoc solution, which it turns out is wrong.  So what they do is you upload, or, I'm sorry, not upload, because this all happens in your browser.  You point your browser at the file you wish to encrypt.  What they were doing was simply encrypting it and then sending it up to the cloud.



Now, they're doing an SHA-256, that is, they're doing a digital signature of the file, sticking that on the end of the file, then encrypting the blob.  And that's what they send up.  And their logic was, and their logic was correct, but unfortunately not thorough, is that when they brought the blob back down into your browser, and you gave it a password, it would use that password to decrypt the blob, which should return the original plaintext and the SHA-256, which is 256 bits or 32 bytes tacked onto the end.  Then if they run SHA-256 again on all but the last 32 bytes, they should wind up with the same result as those last 32 bytes.  That is to say, that has of the preceding file, the digest, should match.  And it's certainly the case that, if you entered the password wrong, that is, if you used a different password, you would get gibberish, and there's absolutely no chance that a hash of that gibberish would hash to the gibberish, the different gibberish at the end.



So this does detect, I mean, be careful with this because there's so much it doesn't detect.  It does detect a different key used to decrypt.  It turns out, though, that solid as we would think this is, there are well-known ways to fool it.  If it were possible to get the user to upload something malicious, for example, it's possible to insert that malicious different stuff into this one and then have it go undetected.  That is, there are well-understood means in the crypto world for circumventing this solution.  And I knew that was the case, but I thought, okay, I need somehow, I need something I can explain clearly.



So I shot a note off to a friend of the podcast, Taylor Hornby, who's a.k.a. FireXware, who has his site Defuse.ca, D-E-F-U-S-E dot ca.  And I said, "Hey, Taylor, here's the situation."  I brought him quickly up to speed.  He was a few episodes behind, so he hadn't run across this yet.  And I told him, I said, I'm looking for the succinctest way of explaining how this is wrong.  And so he said the quick answer is that it's well-known how to forge messages under this scheme, that is, where you hash, using an unkeyed hash, and then you encrypt.  And that's part of the problem here is that SHA-256 is not keyed.  So bad guys - and you can intuitively get it that anyone who wanted the hash to balance can make the hash balance by changing the cryptographic content and then rebalancing the hash.  And the math behind this makes your eyes cross.  But this is nothing for the cipher guru people.  They're able to pull this off.



So he said:  "The attack is pretty neat.  It's explained in the second part of this answer."  Then he provided me a link to StackExchange.com where some of this sort of math is shown [crypto.stackexchange.com/a/16431].  And he said the more complete answer is that today the burden of being called "secure" is to have been proven secure in what's known formally, because the other thing that's neat about cryptography now is this is all - all this stuff has moved into formal academic land.  So it's called an "indistinguishability/non-malleability model."  And there's even some, like, symbology for this.  It's IND-CCA2.



And then he provides a Wikipedia link to ciphertext indistinguishability.  And he says the dominant attitude today - and here's the real takeaway.  "The dominant attitude today is that, instead of finding and fixing individual problems, we just outright refuse to accept anything that isn't proven IND-CCA2 secure."  And that's this INDistinguishability under adaptive Chosen Ciphertext Attack.  That's what this approach is still victim to.  He says:  "That's the important lesson.  You can't iterate on crypto design by fixing problems that come up.  You have to start with something proven secure.  And we have things that are proven secure."  And he also, he ended by saying the Telegram messenger is another example of ignoring this lesson because, again, they just sort of made something up.



And so the way to do this right, and I will forward this text to Florian since he was kind enough to write to me and tweet me and provide this content for the show, is the only way to do this, and you've also heard me say this, is encrypt, then hash.  That is, encrypt, then authenticate.  This is the problem that SSL made back in the early days.  So for these guys to do this right, they would encrypt the message under a key derived from the user's password.  Then they HMAC, and that's a keyed - HMAC is a Hashed Message Authentication Code where you give it a key.



And the point is there's no way for the bad guys to know what that key is.  The key you derive also from the password, from the user's password.  Maybe just run, they're going to run the password through SHA-256.  Just run it through SHA-256 again in order to create a key which you use for the HMAC.  So then you key this HMAC, and that produces an SHA-256-esque hash, which is the authentication code that you tack on the end.  So the result is no bigger than it is right now in what these guys are doing.  Yet because you've encrypted first, and you've authenticated that encrypted result with a keyed HMAC, using a different key than the encryption key, that is utterly tamperproof.



And then, when you receive the blob, the first thing you do, because the last thing you did when you were generating it was to authenticate, the first thing you do when you're going to decrypt it is authenticate that there was no change to what you've received, and then you use the key from the password to decrypt the file.  So, and if everyone would just do that, this is what I meant when I said this problem has been solved.  If you do that, if you encrypt, then authenticate with a keyed hash, then you get what Taylor explains is this crazy indistinguishability under adaptive chosen ciphertext attack-proof solution.



And I will mention - this is me speaking, not Taylor - that he consults.  He loves auditing people's crypto.  That's, I mean, he really enjoys it.  So Florian, if you're hearing this, I will mention this in my note to you that follows, but it's Defuse.ca, D-E-F-U-S-E dot ca.  And Taylor would, I'm sure, love to help.  He did dig into your code a little bit and confirm the things that I had said, so he's already up to speed.



LEO:  He's a good man.



STEVE:  Now, because we've talked so much about the Large Hadron Collider and that fabulous...



LEO:  "Particle Fever."  "Particle Fever."



STEVE:  ...fabulous movie "Particle Fever," I just thought I would note...



LEO:  Which is free on Netflix now, by the way.



STEVE:  Is it.



LEO:  Yeah.



STEVE:  Is it really.  Oh, fantastic.  And everybody, if you are a Netflix subscriber and you have not yet seen "Particle Fever," please, please, please.  You will, you know, this is the one I talked about a year ago where I came out of the theater, and the elderly friend of mine who I went with and I simultaneously said, "That's the best five bucks I ever spent."  I mean, because it's a little small art theater, and they weren't asking for a ton of money, and it was a matinee, and it was five bucks.  And, wow, I mean, it was really interesting.  Anyway, with that lead-in, they are in the middle, after having been down for two years for refitting and beefing up, essentially, they are in the careful process now of bringing the LHC back online at the highest power level it has ever operated.  It was running at 8 TeV.  That's Trillion Electron Volts.



LEO:  Oh, that sounds like a lot.



STEVE:  I know.  Whew.  And they're adding five to that.  So they will be at 13 TeV.  Now, 8 TeV, essentially the level at which this operates, that is, the power at which this runs determines their ability, essentially how much they can see.  And they were able to prove the existence of the famous Higgs boson two years ago.  And in 2013 Peter Higgs, who is still around, shared the Nobel Prize for its discovery, although the Nobel waited until it actually had been discovered.  But he hypothesized, he said there has to be this thing here, even though no one had ever seen one.  He says, "It's got to be there."



Well, it took them smashing stuff together, photons, at 8 TeV in order to finally see the Higgs boson.  Now they're going to 13 because what they want to find is something that surprises them.  So far the standard model is holding up.  But there's this, you know, there still remains questions.  What's up with this dark matter that most of the universe seems to be made of, but we can't find it anywhere.  And, you know, which is to say the model says there must be dark matter, in the way that the model said there must be the Higgs boson.  Well, they found that.  But they haven't found the dark matter yet.  But maybe that means there's a glitch in the model.  Who knows?  The model is the most successful thing that physics has ever created.  It's done so much, the so-called "standard model."



Anyway, what they're hoping is that, essentially, it's like they're turning up the resolution on their scope.  They're going from 8 TeV to 13, and they don't know what they're going to find, but they hope some stuff they cannot explain because it will then be up to them to explain it.  And in doing so, they're going to learn something.  So far they've managed to prove something and demonstrate that this crazy experiment is bearing fruit, which I just think is so very cool.



LEO:  Well, not fruit, but bosons, anyway.



STEVE:  Bosons.  Ah, wait a minute, let's see.  Well, I'm thinking.  I was wondering if there are any fruit names in there because we've got charm, and we've got, you know, all the quarks have, like, these weird designations...



LEO:  Yeah, I know, it's so magical.



STEVE:  ...spin and charm and so forth.  But I don't think we have bananas and pears and...



LEO:  I don't think so.



STEVE:  I don't think so.



LEO:  So it is, like, accepted that they confirmed that the boson exists.  That's not a question.



STEVE:  Yes.



LEO:  All right.



STEVE:  Yes, yeah, they did.  And Peter got his Nobel and...



LEO:  Yeah, I guess you get a Nobel Prize, that's confirmation enough.



STEVE:  Yeah.  Yeah.  Okay, so...



LEO:  Do you - before you get...



STEVE:  ...I was going to say something about Barack and the Peace Prize, but I thought, no, no, no.



LEO:  Yeah, no, no, no, please.  Before you get to SpinRite, I know you want to do that, but a couple of questions I had for you, and maybe something we can talk about down the road, or maybe it's in the questions, actually, I haven't looked in the questions, Google's new OAuth solution, some people in the chatroom are asking about that.



STEVE:  Didn't know there was one.



LEO:  All right.  So I don't either, so we'll have to look at that.  And then we've talked about BadUSB before.  And a number of people raised this issue.



STEVE:  Oh, it is, it is in the questions.



LEO:  Okay.  We'll get to it, then, good.



STEVE:  Yes, yes.  I was raving about the MacBook last week and how, you know, about this one connector.  And it really - what we're going to need, I'll just - I'll give people a tease.  We're going to need a condom.



LEO:  [Laughing] Okay.  I have a Snuglet, will that do?



STEVE:  I don't know.



LEO:  All right.



STEVE:  We're going to need a USB charging condom, which we'll discuss here in a minute.



LEO:  Oh, that's good idea.



STEVE:  In the meantime, in the meantime SpinRite.  This is a little quickie in keeping with the spirit of the Q&A.  Brandon asked, from Wisconsin, he said:  "SpinRite GPT/EFI/UEFI?"  He said, "I'm a longtime listener, and user of your products.  It all started for me with ShieldsUP!.  And I've been wondering about your future ideas for SpinRite.  I know that you're re-writing it for much faster speeds and all sorts of wonderful features we've heard about, but I don't believe anyone's brought up the compatibility side of things.  Are you planning on updating SpinRite to work with GPT formatted drives" - that's the GUID partition table as opposed to the so-called MBR, the Master Boot Record format - "drives that SpinRite 6 doesn't agree with because they are 'MBR Followed by EFI'?  And are you planning on adding UEFI boot support?"



So I just thought I'd be explicit, since I guess I hadn't mentioned it before.  Yes, SpinRite's full support for the Mac, among other things, requires that.  And even later model PCs with Windows, what, I think at least 7, certainly 8 and beyond, everything's moved to UEFI booting rather than the old-style BIOS, and to drives using this GPT because they've got much larger fields.  The problem with the old Master Boot Record format is that it had a partition size limit of 32 bits' worth of sectors.  And 32 bits' worth of sectors, that's, of course, it was at one time seemed like we're never going to get there, 4.3 billion.  But 4.3 billion times 512 bytes per is about 2.2TB.  And we now know that there are partitions bigger than that.



So drives and OSes and everybody have been forced into a format that allows greater than 32-bit descriptors, which is what the GPT does.  And so SpinRite will be 100% aware of all of that stuff and be able to run on drives of probably, it's safe to say now, any size.  Although I have said that before and been wrong.  So it's a little bit like Gates saying no one will ever need more than 640K of RAM because, you know, that was 10 times what the Apple II had, and surely that's enough.



LEO:  It's got to be plenty.



STEVE:  Yeah.



LEO:  Got to be enough.



STEVE:  Two things.  While you were reading that, I just checked my Twitter feed, and Simon Zerafa sent a note saying that the axion, A-X-I-O-N, apparently is a candidate for the dark matter particle.  There's a Wikipedia entry says:  "The axion is a hypothetical elementary particle postulated by the Peccei-Quinn theory in '77 to resolve the strong CP problem" - we all know about that - "in quantum chromodynamics."



LEO:  Oooh.



STEVE:  Oh.  I hate those quantum chromodynamics problems.



LEO:  Hate that when it happens.



STEVE:  Especially when there's strong CP.



LEO:  Oh, yeah.



STEVE:  "If axions exist" - at least they gave it a good name - "and have low mass within a specific range, they are of interest as a possible component of cold dark matter."  And this thing goes on and on and on.  So I have, I mean, this is, whoa.  But, you know, good.  Whatever that is.



LEO:  Sounds important.  That's all I can say.



STEVE:  Yeah.



LEO:  Sounds like 18 TeV might not be enough.  We need more power.



STEVE:  If I add seven to today's date the 17th, I get March 24th.  Which strikes me as the last day that voting is open for the Podcast Awards.



LEO:  Well, get in there.  It's not too late.



STEVE:  So that means that this is the second to the last podcast in which I'll ever be able to annoy and remind and bother people that I would love to win for best technical podcast.



LEO:  Come on, everybody, let's get him in there.



STEVE:  And it is necessary, by the way, to check your verification email, if you haven't, because they are sending out verification emails in order to make sure that you're not, like, making up a new email address every time.  So you have to click a link in the verification email in order to prove that you're legitimate.  I found one in my own.



LEO:  Yeah.  Have that sent to hostmaster@live.fi, and we'll make sure to count your vote.



STEVE:  Yup, and somebody at Microsoft will happily click on that for you.



LEO:  But you can - so does that eliminate the vote often thing?  You have to - or do you...



STEVE:  No, they still want you to come back and vote more.  And they say you can do it every day.  And so some people have been really neat.  They've been tweeting reminders out to the people who are following @SGgrc.  So really appreciate that.



LEO:  If you don't win this, we've failed.  We have failed in every way possible.



STEVE:  One way or the other, I'll never mention it again, either in humiliation or in glory.



LEO:  Okay, good.  Ready?  Question 1 has arrived.  Thump.  Message for you, sir.  Winfield, a listener in the U.S., wonders about freezing his credit, the cold dark heart of his axion:  I just listened to your piece on freezing credit reports.  I'm curious what your opinion is on services such as LifeLock, LifeLock.com.  Also - and I have an opinion which I will share with you about that.



STEVE:  Good.



LEO:  Also, wouldn't freezing one credit reporting bureau be enough, instead of all three?  If you freeze one and have an issue with others, doesn't the one that's frozen prove to the others they're incorrect?  Now, if only.



STEVE:  Yeah.



LEO:  I've not had an issue, but certainly do worry about the potential.  Thanks for the terrific show and information.



STEVE:  So we'll get to LifeLock in a second.  I wanted to say that, unfortunately, the way the bureaus operate is...



LEO:  Independently.



STEVE:  Independently.  And a credit-granting organization normally has a relationship with only one.  So, for example, a bank or a car dealer or loan shark or whoever, I don't know.  They'll have an account with Experian, or with TransUnion.  And so they always go to TransUnion in order to check someone's credit.  That's what they do.  So unfortunately it sounds like Winfield is hoping to sort of, like, cheap out his solution by only freezing one and spending $10, or at least in California, rather than three and spending $30 total.  But, unfortunately, you really do need to lock them all.  So tell us about LifeLock, Leo.



LEO:  So I've actually been a LifeLock customer for years.  In fact, I bought it for my kids, too, because a kind of worst-case scenario on identity theft is that your kids' socials get compromised because that's a lifetime; right?



STEVE:  Yes.  We're so old, it doesn't really matter that much; you're right.



LEO:  Yeah, at this point I don't need good credit.



STEVE:  Well, we're not buying that much.



LEO:  I don't need good credit as much as, you know, they have a lifetime ahead of them of credit that they're going to need.  LifeLock is sometimes controversial.  I don't think it's controversial.  I explain where the controversy comes from.



STEVE:  In the old days; right?  Because I think they overstated what they were doing, and they got slapped for that.



LEO:  I don't think they did.



STEVE:  Oh.



LEO:  So here's what happened.  What they chiefly did was they would put fraud alerts on your accounts, was one of the things they would do immediately.  And Experian and Equifax and TransUnion didn't like that so much because, if there's a fraud alert on your account, they can't issue credit cards.  You won't get those credit card offers in the mail, and that's a big revenue source for the credit unions.



STEVE:  Wait, I can stop those offers by putting a fraud alert on my account?



LEO:  Absolutely.



STEVE:  Ooh.  That might be a good thing.



LEO:  So they used to do it.  So the credit unions, I think, in my opinion, there's some evidence for this, but it's, you know, it's murky because nobody's saying what happened.  But in my opinion the credit unions, and we've seen this happen in other cases, ganged up on and got states' attorneys general to sue LifeLock.  For mostly - and the FTC, for exactly what you said, overstating their capabilities.  I don't think they did.  However, they got enough judgments against them that they have  and I know this because they've been an advertiser on the radio show in the past, and I think, no, we never had them on the podcast.  But I happily endorse them because I know they work.



But they have gotten so gun shy, they can't say anything anymore.  So their ads are horrible.  I keep telling them, guys, nobody's going to buy this product because they cannot tell you what they do because their wrists are tied by these various judgments.  So what they've done, which I think is fantastic, they bought one of the biggest, if not the biggest backend providers for credit cards that does the analytics that credit card companies use to detect fraud.  Credit card companies use this company that LifeLock owns to do fraud detection.  So as a result, LifeLock has jacked into the flow of credit card transactions from almost everybody, basically.  And so they notify you in the same way that they notify Visa and MasterCard.



STEVE:  Ah, that somebody's applying.



LEO:  Saying we know what's going on.  Because they can no longer put the fraud alerts on.  They were stopped.  And so but they do other things.  They do analytics that I think are really very, very valuable.  It's controversial, it's not cheap, and I think one complaint is, oh, I don't want to spend all that much money, and I would understand that.



STEVE:  And it is an annual fee; right?



LEO:  It's an annual fee.  I do it because I'm a public figure, and so presumptively may be more of a target than others.



STEVE:  Be a target, yup.



LEO:  So, by the way, I've never had a problem.  And I've found them to be very, very good.  They will do other things.  You're also buying insurance to help you if you do get identity fraud and things like that.  But I believe that they in fact do exactly what they say they do.  In fact, they do more because they've been hogtied by these judgments against them, so they can't really tell you what they do.  I keep saying, you guys, you've got to tell people about this.  "We can't."  It's like, but this is great.  "We can't."  So really they became an enemy.  In my opinion, what happened is they became an enemy of the credit unions, the credit reporting - not credit unions, the credit reporting agencies.



STEVE:  Right, right.



LEO:  Because they were effective, in fact.  And so they, you know, I think - let's put it this way.  I use it.  I can't prove that I need it, but I've never had a problem.  They've been very quick.  I check all the time.



STEVE:  And is it, like, 49 bucks a year, that kind of thing?



LEO:  Yeah, it may be more than that because I have the kids involved.  It's not a huge amount.  Maybe it's 150 with the kids.  I can't remember exactly.  And you can log in.  You can see a lot of information that you wouldn't see otherwise.  I feel like they do the right thing.  It's 10 bucks a month, somebody's saying, Packrat.  And I'm not sure I would recommend that for everybody.



STEVE:  Right.



LEO:  If you're willing to take the time to pay attention and get your credit - you can get an annual credit report for free.  If you're ever turned down for credit, you could get that.  If you don't want to get LifeLock, you need to do all that.  You need to get your credit report every year.  You need to check.  You need to be proactive.  You need to have the great time calling the credit reporting agencies.  They've automated that now.  There's no human.  And it's not a very pleasant process.  So if you could do a credit freeze, do it.  But they really don't want to do it because it costs them money, in effect.



STEVE:  Yeah.



LEO:  If you've had problems, though, you can get it.  So LifeLock Ultimate is $30 a month; the base package is $10 a month.  I think I'm doing it all.  I can't remember, though, exactly what I'm doing.



STEVE:  Why are we not surprised?  Well, at least you're not doing the gold Watch, so, you know...



LEO:  No, no.  But I feel like I am, I could be a target.  And so...



STEVE:  No, I agree, yeah.



LEO:  There are certain things that I do that I don't necessarily recommend everybody do.  And that's...



STEVE:  And your nature is to be very open and sort of forthright and, oh, here's where I am.



LEO:  It was on this show that I accidentally flashed my Amex card on the screen.  That worked out well.



STEVE:  I never tell anyone I'm going to be out of town until I get back, and then I say I was.  It's just, you know, standard security protocol.



LEO:  Yeah.  I think if you do the freezes it ends up costing you so much money that you might as well just do LifeLock, frankly.



STEVE:  Well, I did, I froze all three for $10 each, and I'm really happy I did that.



LEO:  For how long, though?  Like every three months you have to do that?



STEVE:  No, it's ever, period.  You pay it once.  You pay it once, and you're locked until you need to unlock it.



LEO:  That's good.



STEVE:  Yeah, for me that's the perfect solution.  At my point in life I'm not buying anything that I need credit for.  I don't want anyone messing with my credit.  So I just locked all three of them.  It's a one-time payment of $10 in California.  It varies by state.



LEO:  It's the kind of thing that we can do because we're not applying for credit cards, buying cars, buying houses.  If you're doing a lot of stuff like that, it's a pain, kind of a pain.



STEVE:  Right, because then you need to pay, you need to then do $10 for an exception to that, and that starts to add up.



LEO:  Right.  Freeze lifts vary by state, and if you have to pay when you're shopping for credit, it's worth it.  Okay, even if you have to pay.  Just a planning issue, says Mark in our chatroom.



Question 2.  That's a great question, by the way.  We've never really addressed that, so thank you.  Jesse in Easton, Maryland.  Some input on HTTP/2 mandatory TLS.  And if you listen to this show that all makes sense:  The Packet Pushers podcast recently covered HTTP/2, and their host mentioned that mandatory TLS in HTTP/2 was removed from the spec because of concerns from ISPs it would impact their ability to provide caching as well as supercookies if all web pages were encrypted.  And the IETF working group had initially proposed mandatory encryption.  Just wanted to know your thoughts on that.  Love the podcast.  Been fans of you and Leo since the TechTV days, and SpinRite user for 10 years.  Remember, I interviewed Vint Cerf, and I asked him if there's anything he would change.  He was the father of the Internet.  And he said the one thing we would have changed, we would have built in encryption into all these protocols.



STEVE:  Yes.  Yes.  It would have been difficult way back then because it was, I mean, well, first of all, we're still trying to get it right today.  I mean, people are still, like, oh, no, you can't do compression because there's a BEAST attack.  And if you change, if you twiddle something that we see how it compresses differently, then we can reverse engineer it.  I mean, it's just staggering how difficult some of these things are to get right.  But I just thought it was interesting.



I liked this question because it was, you know, I made the point of noting when we were talking about the evolution of SPDY into HTTP/2, that whereas SPDY was exclusively encrypted, we lost that when we went to HTTP/2.  And assuming that Jesse knows of what he speaks, and I assume he does, it certainly does make sense that there are still people who have not given up on unencrypted web connections.  ISPs would like the ability to cache in order to reduce their bandwidth.



But, I mean, anybody who has that as part of their business model today, or supercookies, for example, needs to absolutely give that up.  They need to, if nothing else, plan from this moment on that connections will be opaque to them, and do whatever you have to - add routers, add bandwidth, but plan for the idea that your customers will be connecting directly to the servers, and you're not going to be able to see into it.  Because that's the way it's going to go, whether it's in the spec or not, whether HTTP/2 can optionally be unencrypted.  I mean, it makes sense that it should be because it'll be really fast.  I mean, we saw that adding encryption and this compression and the binary protocol that is added in HTTP/2 is so - makes the system work so well that it completely removes the overhead of encryption.  So if you had no encryption overhead and had HTTP/2 unencrypted, that would be even faster.  And browsers are still going to support it.  Web servers are still going to support it.  So there'll be a place for it.



But more and more websites are just going to be encrypted because users are going to want that more.  So, you know, the web is going encrypted, like it or not.  And I think everybody pretty much likes it except those people who are, in one way or another, counting on it in some model not being encrypted.  And that's of course the NSA and ISPs.  And Verizon, who wants to put a supercookie on your stuff as it heads out on to the Internet.



LEO:  Kyle Day in a Dallas, Texas - I guess a typo.  [Silly accent] In a Dallas a Texas.  He wonders, Steve, how could SQRL be used for multiple account logins to the same domain?



STEVE:  Sorry, Kyle.



LEO:  All the usual praise for you and Leo.  Seriously, your podcasts are worth more than free.  Well, you know, they're free because we've got great advertisers, so you don't have to pay for them, but they do.  I have a question about your SQRL solution.  I've listened to all your podcast episodes.  I never quite picked up on one thing you may have already covered:  How does SQRL handle logging into multiple accounts on a single domain?  For example, with my current password manager, I have both my and my wife's logins saved to iCloud.com.  Could be any domain, of course.  Using my current password manager, I would navigate to iCloud.com, select which login, mine or my wife's, that I want it to populate and log me in with.  I do the same thing with Google.  I have several Gmail accounts.



STEVE:  Right.



LEO:  I think eight.  So I get to choose.  But how would SQRL handle multiple logins to the same domain?  As I understand it, the single SQRL identity is what identifies me to the website's server.  Is it possible to identify as someone else, or maybe a second account that I own?  I have a PayPal business and a PayPal personal account, but they're both accessed at the same domain.  They're both my own personal accounts.  How am I going to manage multiple SQRL identities to accomplish this?  Thanks.  Kyle.



STEVE:  This question caught me because just in the last week we finalized the way of doing that.  There are sort of two different concepts in SQRL.  What SQRL promotes, as everyone knows, is the idea that one identity can be used, potentially for your entire life.  That is, you could very likely create a SQRL identity with GRC's client and export that to your iOS or your Android or your Mac or wherever, or create an identity on any of those, and cross-export them, the point being they would all have the same identity so that you would be known as the same pseudonymous entity at any site, no matter which one of your devices you were using.  But this is per domain.



So this is what Kyle is asking, is what if I want two accounts, if I, I myself, my identity, want two accounts at the same domain?  And what we have is a - we're still not sure what we're going to call it, a sub ID or an account ID or an alternate ID.  The idea is that remember I was just saying earlier that every single time you authenticate, the first time you give it your full password, and then subsequently you can give it a shortcut.  We call it the password hint.  And if you did that, you'd just get your normal sort of primary account at that domain.



If you wish to appear for any reason you have, we're not telling you how or why, you want to just, for some reason, one time you want to appear to be someone else, or you do want to maintain sort of formally additional accounts at the same domain, there's a button on the dialogue that just says "Account."  And so you type in your shortcut, do do do do, hit the Account button, and then anything you want.  You could number them, one, two, three.  You could do A, B, C.  You could use your own little acronym for the second account and third account.  And there's no limit.



What we do is we take whatever you type in after you press the Account button, and that gets added to the hash.  So it creates an infinite number of alternative identities for your primary identity at that domain.  So it just expands it infinitely.  And I'll just mention that this is different than multiple users sharing a computer because Kyle's question was a little mixed up.  For example, he talks about he and his wife.  In the two different people mode, SQRL clients will support multiple, like, people identities.



So in a household who had a shared computer, you could have Mom, Dad, Bobby, and Susie, and their client would show those four identities.  And so they would choose who they are and then just normally log in under that identity.  And then all of those identities, if they wish to, could have multiple accounts under them.  So, I mean, we got that.  That's in there, too.  And it's going to end up being very simple and easy to use and give people complete control and freedom.



LEO:  Cool.



STEVE:  And we'll just hope.  We'll get it done, we'll show it to the world, and we'll see what happens.



LEO:  More and more it's starting to feel like it's something that needs to happen.



STEVE:  I know.  We needed this a year ago, but it's better late than never.



LEO:  The threat to you is that somebody like Microsoft or Google or some consortium comes up with some solution which would not be as good, but it would be some solution.



STEVE:  There is FIDO.



LEO:  There's FIDO, yeah.



STEVE:  FIDO is, you know, there's that.  And the problem with FIDO is they didn't know, or, yeah, well, actually they didn't know, I know that they didn't know because when I ran into Brad Hill at the DigiCert conference, he was stunned by the crypto I was using, which allows me to not require the server to keep my credential.  That's what FIDO does which is so crazy is you give your credentials to the server to hold for you.  Then, when you go there, you ask for them back.  And then you authenticate against them.  It's like, okay, I guess, okay.  Anyway, SQRL doesn't need that.  So, which is why Brad was really impressed and said it was the most well-thought-out authentication protocol he'd ever seen.



So it's certainly the case that FIDO could happen.  But FIDO is device-tied.  And even though it's technically an open spec, only one company has ever managed to write the FIDO protocol because it is so complicated, this Nok Nok Labs.  They're the only people who have it, and they'd like to make money licensing it.  And so when you hear that, like, Microsoft is going to support it under Windows 10, yeah, they licensed the code.  Instead, with SQRL, it is really, I want to say "dead simple," except even simple turns out to be complicated.  But we've got, like, 12 or 13 people, I mean, there are test servers up and running, and people are in the process of following my implementation and verifying theirs against mine.  So, I mean, we'll see what happens.



LEO:  Somebody said all you have to do is get Tim Cook to announce it and say it's magical, and you'd be done.



STEVE:  That would make my day.



LEO:  Kostas Kritsilas in Calgary, Alberta, Canada wonders about RowHammer:  In the last episode you discussed RowHammer, a vulnerability that researchers at Carnegie-Mellon discovered, where they could flip a bit or bits on an adjacent row by repeatedly accessing it between refresh cycles 64ms apart.  Additionally, you said the Code Zero group within Google had weaponized it.  My question is this:  In order to do this, would the code need to have - would the code not heed to have - would the code not heed, but I think he means "need," to have direct control over the read/write operations, and perhaps some level of knowledge exactly as to when the refresh cycles are to occur at the hardware/chip level?  That being the case, would it not be fairly difficult to take control of this, given there are multiple board chipsets, and only two manufacturers, Intel and AMD, but many versions of the chipsets?  Or do all chipsets basically operate pretty much the same way?  Kostas.



STEVE:  So I was glad to see this because we were up against a hard out last week on Thursday.  We had Tech News Tonight, or Tech News - what do you call the morning one?



LEO:  TNT, Tech News Today.



STEVE:  Today.  And so I couldn't spend as much time on RowHammer as I wanted to. There are a couple points that, as a consequence, I left out.  First is, well, since then there's already been some news.  Linus has submitted a change to Linux which will remove that visibility into non-privileged applications port mapping.  I mentioned that last week as being crucial to this.  The application has to have access to its own page table in order to know where to hammer in order to change a row.  And so the quickest remediation for this flaw is to take that away from non-privileged processes, and that's been submitted into the official Linux tree.



The other really tricky thing is, exactly as Kostas says, is that in order to hammer the row, you have to bypass everything the system has done to keep this from happening.  That is, I mentioned at the beginning of my discussion this last week how slow dynamic RAM has remained.  It just - it cannot get sped up in the same way that all of our static silicon processing has.  As a consequence, processing speed has just shot past it.  The only thing engineers have been able to do is caching.  And of course everyone is familiar with L1, L2, L3 cache and so forth.  There's even cache in the RAM chip itself.  That is, when you read a row, the results of that read are stored so that, if you read other things from the row, it won't read them again.  And rows are typically about 64 bits long in today's dynamic RAM.  And so the idea is that every single bit of caching has to be bypassed in order to hammer on the chip at full speed.



The way they do this is there is an instruction that the Intel has that I'm sure AMD must.  I'm trying to think whether the ARM architecture does.  I think that the ARM doesn't, but Intel does.  It's a non-privileged instruction.  So one question people had was why was, I think it's cfflush, or maybe just cflush, cache flush.  But so at the instruction level, the code running basically is in a tight loop.  All it's wanting to do is to pound on the two rows back and forth on either side of the target row.  And so it does a write to one row, then it - or does it do a read?  I can't remember.  Then it flushes the cache in order so that - because what happens is normally when you are - when you're reading from dynamic RAM, you bring a block, a so-called cache line, which is like 64 bytes now, that bring a whole chunk in at once.  And so if you were - I think that they are reading.  And so if you're bouncing back and forth between doing reads, you won't be going back to the DRAM every time.  You will instead be pulling it out of any of this pipeline of caches, the L1, the L2, or the L3 cache.  And so that'll be done very, very fastly - very fastly.  Very, very quickly, excuse me.



The reason, though, that you may sometimes need to explicitly flush the caches, that is, tell the caches to forget what they have, is if you had two processors sharing memory, and these processors might have processes running on them that are sharing a region of memory for, like, sharing data.  So one processor might put something in the shared region.  The other one would read that out.  Well, before it does that, it needs to flush its local cashes so that it's actually reading the physical memory.  Otherwise it'll just be reading out of cache, and so you can't trust that shared region of memory as a communications mailbox unless each processor that is about to look removes any memory it has of what it saw there last, so it actually pulls it from the physical RAM.  And anyway, so pulling it from the physical RAM is what it turns out disturbs the adjacent line or the adjacent row in the cache.



And the last part is none of this works if you have ECC or even parity check memory, which is the other point I didn't have time to talk about last week, which is, for example, in server-class machines, you will often have error correcting memory specifically to absorb these kinds of problems.  If a bit flips, the ECC works on a different fashion, but similarly to the way it does on a hard disk, where it's able to correct a single-bit error or reliably detect a two-bit error within that little chunk of, you know, it's like eight bytes of memory that it's guarding.  And then there's another, an additional byte to protect that and provide the ECC data.  So if you are a server-class machine with ECC, you never have to worry about this.  And even if you just went for parity memory, it'll catch single-bit flips, as well, though it would not detect two-bit flips because that brings the parity back again.



So, and the last point I made was that, in Google's testing of, was it 24 laptops, they found that they were able to induce these errors in a usable fashion in half of them.  And that's why I made the comment that you could imagine this being a part of a toolkit that an attacker would have, where they would have identified which laptops were potential victims, and if they were like, if their target happened to be one of those known vulnerable laptops, then they could try the RAMhammer attack on it and see if they were able to get control.



LEO:  Right.  Half is not a very - or maybe that's better than nothing, I guess.  It's not...



STEVE:  Well, and this is a new problem.  We didn't have this more than two years ago.  So this is - we're introducing this new because we keep making the DRAM more dense and the cell sizes smaller, and therefore the signal is less large compared to the noise.  The so-called "signal-to-noise ratio" is unfortunately dropping.



LEO:  Sam Abuelsamid - and by the way, I should know your name, Sam, because I see you all the time, Sam Abuelsamid in Ypsilanti, Michigan.  He says:  Terraced batteries, nothing new.  As nice a piece of engineering as the new MacBook is, Apple did not invent the stepped battery.  Motorola and LG both have used similar batteries in their phones for years.  You can see it at AndroidCentral.com.



STEVE:  So, okay.  Thank you.  I'm...



LEO:  There's a lot of those.  Oh, you know, they didn't invent that or this.  Apple doesn't, you know, Apple doesn't have to invent new stuff.  It just is an interesting use of it.



STEVE:  Well, and, for example, we know that they acquired the fingerprint scanner people.



LEO:  Right, AuthenTec.



STEVE:  But, boy, they sure turned that into something far more useful than the fingerprint scanner people ever had.



LEO:  You still going to get a MacBook?



STEVE:  Oh, yeah.  I'm going to - yeah, yeah.  It's just - it's too nice.  I'm a little worried about the keyboard.



LEO:  Ah, me, too.



STEVE:  I've been reading reviews.



LEO:  Yeah.



STEVE:  Yeah.  And they say that it's a little, you know, the little rocky, high...



LEO:  There's not much travel.



STEVE:  Exactly.



LEO:  Yeah.  I am, I'm going to let Lisa get one and watch.  Maybe you and Lisa and watch.



STEVE:  I think I won't preorder one.  I'll wait to go and look at in the store.  Wait, when will they be in the store?



LEO:  April 10th.



STEVE:  They won't be in the store till the 10th?



LEO:  Well, nobody's...



STEVE:  I wonder if I could see one before.



LEO:  You could play with the Force Trackpad now because it's in the 13" MacBook Pro.  But I think you're going to have to wait till the 10th.



STEVE:  I think I'm going to love that regardless.  That just sounds like a complete win.



LEO:  Everybody's raving about that.



STEVE:  Yeah, the haptic feedback trackpad.



LEO:  It's also a slow processor.  I'm not - I'm really not sure.  You can get the haptic feedback in other ones.



STEVE:  I'm not doing 3D modeling or DNA research or anything.



LEO:  No, that's true.  You know what I got?



STEVE:  I'm checking my mail.



LEO:  You know what changed my attitude on all this, I got the new Chromebook Pixel.



STEVE:  That's the Pixel 2 or the, right, the new Pixel.



LEO:  Pixel 2, I guess, yeah.  Two years down the road it's much faster, snappier.  Boy, what a gorgeous screen.  And it does do everything I want, pretty much.  There's a couple things.  I can't do photo editing.  But again, the MacBook, I might not want to do photo editing.



STEVE:  Does Apple have their stuff on Android yet?  Like their Office Suite stuff?



LEO:  Yeah, there's web-based versions of Microsoft Office and iWork, Apple's solution.



STEVE:  I'm just thinking of Jenny.  This might really be the right thing for Jenny.



LEO:  Boy, from a security point of view, it's incredible.  First of all, it's got a TPM chip.  They sign everything.  You can't modify, you can't access many of the files.  You can't just kind of browse around in the directories.  It's locked down.  And if anything bad goes wrong, they've got this Power Wash, it just wipes it all clean.



STEVE:  But it's not cheap, now, is it.  It's a thousand dollars?



LEO:  It's $999, yeah.



STEVE:  Yeah.



LEO:  But you know what I realized is that, you know, I've played with every Chromebook.  And by the way, I hated Chromebooks.  I've hated the whole idea.  Didn't get it.  Until I started using them.  And I'm starting to get it.  And I'm seeing students use it.  And I'm starting to get it.  But then what happened was a lot of the reasons I didn't like it, because they were cheap hardware, and it was junky.  And but you put it on nice hardware, I use the Chromebook more than anything else now.  I'm using it all the time.



STEVE:  Well, and I think it makes sense for somebody who just wants to get their work done; who doesn't want to, like, live for the sake of having a computer, but just wants the computer to let them do what they need to do.



LEO:  You know what's wild, it has SSH.  So I moved my RSA key over, my private key over, imported it into the SSH module, then deleted it.



STEVE:  Client, yup.



LEO:  And now I can SSH to a Linux box.  So I've got - anything I can do on a Linux box, I can do pretty snappily.  So I feel like I'm got everything.  I've got a chatroom in there.



STEVE:  There's probably an OpenVPN client, too, I would imagine.



LEO:  Oh, I'm sure there is, yeah.  Well, and Google also has a remote access solution that you can access any computer remotely.  So if I need a Mac, I could access.  I think it's getting better and better.  Anyway, just - I know.  I know.  People are going, you're crazy, Leo.  You need a real computer.  A manly computer.  That's actually the one thing I miss.  I cannot really do programming.  I can only do web-based programming.  I can't really do real programming.



STEVE:  True.



LEO:  You know, I can SSH to Emacs and run Lisp.  But that's about it.



STEVE:  No.  Then, I mean, your hair that has just come back would fall out.



LEO:  I actually - I like Emacs.  I used to be a VI guy.  I'm kind of coming around.



STEVE:  Yeah, well, you know that when all of the texture of the left and right paren keys has been smoothed off...



LEO:  You've been doing Lisp.



STEVE:  That you've been doing Lisp.



LEO:  I love Lisp.  I'm starting to come - I'm coming around on functional languages.  Screw these imperative languages.  Anyway, Mike Robles in Wauconda, Illinois wonders about anti-keystroke logger protection:  Steve, long-time listener.  I'd like to get your opinion of something called Zemana AntiLogger, particularly the free version, Zemana.us.  According to Zemana, this software not only protects against keyloggers, but they also claim it prevents SSL intrusion - protects SSL, prevents MITM, and monitors fake CAs.  It got good reviews.  Have you looked at this?  What do you think?  By the way, thanks a lot for all you do to promote security awareness.  Sincerely, Mike Robles.



STEVE:  So, you know, if it could wash the dishes and my car.  I sort of tripped over this one because these are the sorts of claims which are difficult to really honor.  For example, you know, okay, first of all, I should say this thing's been around for a while.  This keystroke logger is, kind of this anti-keystroke logger functionality that it professes, is sort of funky.  Because inside of Windows there's a long chain of processing that keys go through which is mostly a testament to the age of Windows.  As one thing or another, or someone had a new good idea, it had to keep all the other previous good ideas and add this one to it.



And so, as a consequence, there's about 10 different API levels where you can access keystrokes.  And they're all targets for attack where a keystroke logger could get itself.  So their claim to fame is they insert something at the very end, or I should say they insert something at each end.  They put something way deep down in a driver in the kernel close to where Windows is finally so tired of processing this keystroke that it gives up, and it says, fine, here it is.  And way up at the front, right underneath the keycap itself, so that it catches it before anybody has had a chance to mess with it.  And then they say they encrypt it.  So it's like a little encrypted link from the key top down into the kernel, just before, like, the original primal NT function gets it.  And in between is gibberish.



So if any of these keystroke loggers link into this chain anywhere there, they're going to get gibberish.  And, I mean, this is how they describe it.  I think, okay, this is gibberish.  You know, all the keystroke logger has to do is link in ahead of them off the top end or below them at the bottom end.  It's not like they have some privileged position.  And maybe the keystroke logger is smart enough to do that, or maybe that's just how it operates.  So the strongest claim you could possibly make is we saw a keystroke logger once that we could prevent.  Okay.  Maybe two or three of them.  I don't know.  But not all of them ever.  It'd be like saying, here's the antivirus solution for all the antivirus today and forever.  Just install this, and you're good to go because we solved that problem.  It's like you can't solve the keystroke logger problem.  They're claiming to have done so.



And so this is sort of a - I don't mean to pick on these people.  There's a class of these.  They all sort of feel the same.  It's like, you know, somehow they didn't invoke military-grade encryption anywhere in there.  They avoided that catchphrase.  That's also typically a sign of a problem.  But anyway, so, Mike, maybe it's good.  But it just feels like more gunk in my computer, you know, something, one more thing to go wrong, sort of like power windows.  I don't know, I'm just grumpy about these things that say, okay, this prevents all of these, because nothing can prevent all of anything.



LEO:  Wow.  That's an epigram for the centuries.  Maybe put that on your tombstone.  "Nothing can prevent everything."



STEVE:  Nothing can prevent all of anything, yeah.



LEO:  I tried, but nothing can prevent everything.  Here's one from Chris in Tokyo.  And he's got that question I had about USB Type-C:  Steve, with BadUSB and the inherently insecure nature of USB looming, what do you think of laptop manufacturers, even Apple, using USB Type-C for power?  As far as I know, nothing has been done on the specification side to address security issues.  Do you know anything about this?  If I were a bad guy, man, I'd be planning where to offer "free" power to commuters, travelers, and coffee sippers looking to top off their fancy new laptop batteries.



STEVE:  Yeah.  And the industry is reacting similarly.  BadUSB is still fresh in our mind, and we're now seeing, for example, famously, the MacBook that has only a USB connector.  Which means you'll have to connect to USB in order to get power.  And I was looking at the little, at my maglock, how it's got those four little gold dots.  And it's like, oh, I miss you because all you could be is DC.



LEO:  I miss you, MagSafe.



STEVE:  Yes, I do, because you're so innocent.  Look, four little connectors.  Instead, you peer into that USB-C, and it looks like an octopus has just taken over.  So...



LEO:  The good thing is, as I've been told, the Apple power adapter doesn't have any firmware.  So you couldn't actually put BadUSB on an actual legitimate Apple adapter.  The issue is going...



STEVE:  Ah.  And, see, of course.  And that's not the attack.  The attack is how many times have any of us, as people propose, ever asked to borrow somebody else's power adapter in a pinch, or plug into the seatback in the airlines.



LEO:  Well, exactly, yeah.



STEVE:  Yeah, or, you know, or there's, like, power outlets all over the place now that are USB.  And presumably at some point in the future they'll be USB Type-C.  Which is why I said somebody needs to make a condom.  And as soon as somebody does, let me know, and I'll tell everybody.



LEO:  How would that work?



STEVE:  The idea would be, it would be a tiny little thing which has a male USB-C on one end and a female on the other.  And all it has is the power wires...



LEO:  Oh, smart.



STEVE:  ...going between them.



LEO:  Oh, that's easy.



STEVE:  Yes, it is.  It's trivial.  Someone needs to make one.



LEO:  You could make one yourself.  You just solder it together.  Of course.  Because if there's no data, if it's just power wires...



STEVE:  Then you're back to, oh, look, it's like my maglock.  It's like my cute little maglock.



LEO:  That's brilliant, Steve.  I wonder if somebody's selling that?  If not, let's do it.



STEVE:  Yeah, like I said, as soon as someone - now everyone knows, make a condom.  As soon as someone has, I'll tell everybody, and then we'll...



LEO:  You should do it.  You should call it the SpinRite Power Condom.  Seriously.  It'd be trivial.  You'd just need a bunch of Type-C connectors, male and female.



STEVE:  Male and female.



LEO:  Yeah, because you have to have an innie as well as an outie, and just wires.  It's like how the power wires are.  There's probably none.



STEVE:  Yeah, we're on Question 7.  By the time this podcast is done, there will be a project on Kickstarter.



LEO:  Kickstarter.



STEVE:  I mean, and the reason I'm not doing it is because everyone will, and it's really not, I mean, it's worth having one, but it's not worth taking the time to do it.  There are lots of other people who can do plastic and...



LEO:  You could have $5 million right now in your pocket.



STEVE:  The USB Type-C Power Condom.  We need a condom.



LEO:  Why didn't I think of that?  Brilliant.  How about this?  Look at that.  There's already one for USB Type-A adapters.



STEVE:  Ah, good.



LEO:  It's called Charge Safely, the SyncStop.



STEVE:  Perfect.



LEO:  Look at that.  Protect your data.



STEVE:  Have them do one for the next one.



LEO:  It's just - they call it a USB Condom.  Oh, man.  Yeah, they've got to be doing a Type-C next, of course.



STEVE:  No doubt, no doubt.



LEO:  "A condom that stops trojans, what an irony," says Wistful in the chatroom.



STEVE:  I will mention that, with any, well, first of all, your new beloved Pixel is also USB Type-C.



LEO:  Yes.



STEVE:  Right?



LEO:  Yup.  It's got two of them, one on the...



STEVE:  So those do.



LEO:  One on each side, which is kind of cool because you can charge it either way.  You could have video out either way.



STEVE:  Oh, that is very nice.



LEO:  Isn't that nice?  I wish Apple had done that.



STEVE:  I love that it itself is reversible.  And now it's even side-to-side reversible.  So that's double nice.  And let's hope that we're not going to run across the Firewire-style problem that Thunderbolt also had, where it's a DMA-style interface.  Presumably - I've not had any chance yet to look at USB.  Presumably they understand that they need to be providing some protection.  But again, remember that in the BadUSB case, it was the device you were plugging in that was the problem.  So the idea would be, you would be plugged - you think you're just getting power, yet you're getting power, and there's also a drive hidden there which is screwing around with your computer without your knowledge and permission, which is why you need the power condom, to say I want power and nothing else.



LEO:  Great idea.  All right, Steve.  Let's see.  We've got a couple more questions before we wrap this puppy up here.  And Question #8 comes to us from John Hughan in Austin, Texas.  He's wondering about TPM.  We were just talking about TPM in the...



STEVE:  Yup.



LEO:  I don't know if the original Pixel had TPM.  I bet it didn't.  That's awesome.



STEVE:  They've been around for so long.



LEO:  Yeah, it just adds cost.



STEVE:  They may have had it.



LEO:  But, see, that's what you get when you spend a little more, like $999.  You get things like a TPM module, which means...



STEVE:  Well, you get nice hardware.



LEO:  It is nice.



STEVE:  You can't really do really nice hardware for 200 bucks.



LEO:  No.  The screen.



STEVE:  You know, you're going to get some green frog laptop.



LEO:  Yeah.  Steve, I was thinking about your point that having a device that can decrypt what you want decrypted makes a lot of sense and makes a system inherently - oh, wait a minute, I'm sorry.  That having a device that can decrypt what you want decrypted makes a system inherently [in]secure because the key has to be on the system.  That's what we were talking about last week.  But in that case, why do we trust TPM to provide our security for things like whole disk encryption keys?  If we conclude that TPMs aren't secure, are we using them for sheer lack of a better alternative?  It stands for the Trusted Program Module; is that right?



STEVE:  Platform, platform.



LEO:  Platform, that's it.



STEVE:  And so he adds, are we using them for sheer lack of a better alternative?  Yes.



LEO:  Oh, really.



STEVE:  Yeah.



LEO:  But it is a secure store itself; right?  I mean, you can't - it's hardware.



STEVE:  Well, yeah.  But this was the point that I was making last week was that, in the same way that a DVD player is hardware, we were able to reverse-engineer the keys.  And there's a fundamental problem when you are relying upon a local secret to be kept.  The secret is in this thing I'm holding.



LEO:  You got it, yeah.



STEVE:  And so all I have to do is pry it out of there.  And in fact, prying it out of there is what's often done.  The lids are popped on these things.



LEO:  Physically, wow.



STEVE:  Yes.  So I did want to mention, which I didn't before, is that because that's a known problem, things that attempt to protect their physical security are made deliberately vulnerable.  For example, I've seen systems where they use a long-life battery and then run fine wires through, like, the air, and then pot this thing in black plastic.  So that, if you're trying to dissolve the plastic or etch away at it or file it away, you'll break a fine wire, and it'll lose power and forget what it knows.  I mean, the point is a lot of effort has gone into the recognition that the physical security of a small piece of electronics has now become crucial.



And the key of the Trusted Platform Module is very similar to what Apple has done with the Secure, was it called Enclave?  I can't remember what they called it, the secure element in the iPhone.  And that is, it will never export its secret.  You can ask it to use its secret in order to prove something or to obtain decryption, but it will never export the secret.  So you give it something, it does the work and says here's the result.  But you never get the actual work, only the work product.  So the answer is yes.  TPMs are better, I mean, as a local repository for secrets, which they're as safe as we've been able to make them.  And the manufacturers of the TPMs make them literally brittle so that any attempt to tamper with them will fracture them and cause you to lose the secret.



LEO:  That's interesting.  And then you'd know - or if not, you'd at least know.  Or whatever.



STEVE:  Yeah, yeah.



LEO:  And I don't know if Google ever said there was a TPM in the original Chromebook Pixel, but a teardown reveals an Infineon chip that is likely to be a TPM module.



STEVE:  Yup.  Yeah.



LEO:  Why not?



STEVE:  You know, TPM has been around so long, yeah.



LEO:  It's cheap.  And again, for $999, you can do anything you want.



STEVE:  Yup.



LEO:  Bubba Mustafa, who's waiting for DerbyCon 5.0 - I'm not sure what...



STEVE:  I had no idea what that was.  I thought maybe you would know what the reference is [hacker security conference in Louisville, Kentucky, September 25-27, 2015].



LEO:  No, no idea.  Worried about SSL/TLS hijacking/proxy:  Steve, after listening to the episode about Superfish and understanding that enterprises will proxy the traffic to do deep packet inspection and other security defenses, doesn't that mean the whole SSL/TLS model is fundamentally broken?  Can't my ISP, Big Brother, Chinese, Wookies, whatever, pop in on one of the hops and play man in the middle?  Does HSTS fix this?  Granted, of course that's only if both sides support it.  Can HSTS be proxied, as well?



STEVE:  Okay.  So I did like the addition of Wookies as a possible attack...



LEO:  Wookies.  Never know when the Wookies are listening.



STEVE:  That's right.  Okay, so I wanted to sort of just make sure we hadn't sort of gone overboard with Superfish.  First of all, HSTS won't fix it because all that does is force you to use encryption.  That's all it does, force you to use encryption.  But if the encryption itself is broken in some way, being forced to use it, well, that doesn't matter because the encryption itself is broken.  For any of this to work, your browser must trust that man in the middle.  Your browser must trust that proxy.  That's done in the case of Superfish because Superfish has installed itself in your computer and given it a certificate, that is, given your browser, you know, remember the 400-some certificate authorities.  Well, now there's 401.  And no longer is the Hong Kong Post Office number one on our suspect list.  Now Superfish is in there also.



So the point is an ISP cannot use, cannot break SSL and TLS, nor can Big Brother, well, technically, except I'm sure that the NSA can mint any certificate they want to, like, on a whim.  It has to be that they control a certificate authority, among all those that the browser trusts.  It has to be.  But not an ISP.  An ISP would have to require that you load a certificate in your browser in order for your browser to trust them.  And I have mentioned that it's a bit of a chill that ISPs might in some horrible future become ballsy enough to say, oh, yeah, sign up for us, and here's how you install our certificate in your browser so that we're able to protect your security.



So if that day comes, oh, that's going to be a dark one, the idea that people might not have a choice but to install an ISP's certificate because what that would mean is the ISP is doing a man in the middle, maybe in order to do the kind of caching which SSL/TLS prevents, in order to lower their bandwidth.  But I sure hope we never see that day.  But anyway, for what it's worth, it's not easy to do this.  You need to get the browser to trust the proxy.  And that requires adding a certificate that the proxy provides.



LEO:  Finally, #10, Alan Figgins in Auckland, New Zealand had a question about Target-style security breaches and SQRL:  Steve, I have been a listener since the day you netcast Episode 1 of Security Now!, a grateful user of ShieldsUP! since the Nineties, and owner of a SpinRite license since the early Noughties, so a huge thank you.  In Episode 493 there was a question regarding SQRL and, in particular, whether there might be a potential security issue if, well, Target, to continue using them as an example, is compromised, and their SQRL database would be exfiltrated.  Your response to that query was it wouldn't really matter too much, since the bad guys would only have gotten a list of users' public keys, and there is no particular value in those to any other person or website.



I agree with that statement, but I am wondering if there might be another security issue whereby a bad guy gets into Target's SQRL database and, rather than exfiltrating it, they replace a user's public key to be the matching half of a public-private key pair that they, the bad guy, have generated.  Now the bad guy can log into Target's website using SQRL, sign the nonce with the private key that they have which now matches the public key held by Target, giving them access to the user's account.  Is that correct, or have I misunderstood how SQRL works?



STEVE:  Alan, you understand it perfectly well.  And, yes.  If somebody were able to alter a database of accounts, then there is no way to prevent that.  And you could argue that there's theoretically no way to prevent that.  That is, any authentication system would fail that level of breach.  And in fact, if bad guys get in, it's not really even clear to me, like, that that's what they would do.  It's like, if they have that level of control, to alter the account database of some target like Target, then they've got free run of the place.  So you're absolutely right.  SQRL won't protect nor - that would be like changing someone's password to something else.  So now the bad guys can log in as them with a password that they have changed.  Or, I mean, like any authentication system.  If you change what it is that the destination service has that identifies a person as some other person, then it's going to identify the new people.



LEO:  It doesn't matter if it's a password or a SQRL, it's...



STEVE:  Doesn't matter if it's anything.  I mean, nothing even theoretically can breach that.  So there was another - this is sort of along the lines of let's explore this all the way.  And I'm glad to explore it all the way.  We have explored that.  And it's like, yeah, nothing can withstand that sort of attack.  So it's not - there's nothing I can do.  I mean, there's absolutely nothing.  So I don't consider that a problem or even a characteristic of, I mean, it's sort of like the nature of authentication is something is identifying the accountholder.  And if you change that, then they're going to be identified as somebody else.



LEO:  Steve, we've done it again, 10 questions.



STEVE:  Yes, and Episode 499 is behind us.



LEO:  Uh-oh.



STEVE:  Here comes 500 next week.



LEO:  You know what that means.  Next week we're going to do something.  I'll have to get you a cake.



STEVE:  I don't eat cake.



LEO:  Set off fireworks.  I'll get you a meat cake.  It'll be all protein.



STEVE:  Give me a carrot.



LEO:  A carrot?  You're easy.  Yeah, 500 episodes.  Isn't that great?



STEVE:  Yeah, love it.  



LEO:  Five hundred great episodes, I might add.



STEVE:  I'll have something to say next week.



LEO:  I'm glad you're feeling better.  I am so happy.



STEVE:  That's what we're going to do for 500.



LEO:  Okay, good.  Kind of a special little thing.



STEVE:  I have some feelings.



LEO:  I'll eat cake.  You watch.



STEVE:  Perfect.  Just don't choke, don't spit it out when you hear what I have to say.



LEO:  Uh-oh.  It's not going to be your last episode; is it?



STEVE:  No, get some Kleenex.



LEO:  Oh, oh, no.



STEVE:  No, no, no, no, no.  No, it's not, not bad.



LEO:  Okay.



STEVE:  It's just how good this is.



LEO:  I'm glad you're feeling well. 



STEVE:  Me, too.



LEO:  We do this show, and I guess you don't want to miss the next one.  We do this show every Tuesday.  Now, it's been a little confusion because people say, did you start early?  Well, the problem is we start daylight savings time early.  Saving time.



STEVE:  We strange people in California.



LEO:  Yeah, well, the U.S.  We start it...



STEVE:  Oh, wait.  Our daylight savings time changes at a different time than other people's daylight savings?



LEO:  Yeah.



STEVE:  Oh, my lord.



LEO:  So they haven't gone to summertime yet in Europe.  So we moved the podcast without telling them, kind of.  We are still at the same time as far as we're concerned, which is 1:00 p.m. Pacific daylight time.  That's, of course, 4:00 p.m. Eastern daylight time.  But it is a different time - actually it's now 1:30, isn't it, 1:30 and 4:30 daylight time in the U.S.  But it's a different time UTC because UTC does not change.  If only we were UTC.  It does not change.  And you need to calculate the offset from UTC to your local time, and then this will all make sense.  So, just so you understand, we are at 2030 UTC.  So you have to figure out your own offset, from now on until we go - we move.  That's the problem, we did, we moved on you.  And let's just blame the stupid - blame Ben Franklin.  We don't need it anymore, but we got it.



STEVE:  It's annoying.



LEO:  It's annoying.  It doesn't save energy.  People die as a result of it.



STEVE:  Four heart attacks.



LEO:  I almost had a heart attack.  And I know I have crappy sleep.  I think you got sick because it just changes your circadian rhythms for no reason.  It doesn't save energy.  The farmers don't like it, and that's a canard.  There's no value to it whatsoever.  The reason it doesn't save energy is it's a push.  We use more air conditioning and less fuel oil or vice versa.  So it's a push.  So there's really no value to it.  And I do predict that sometime in our lifetime this time change will end.  I really think so.



STEVE:  I don't know.  We're pretty old.



LEO:  Well, that's how optimistic I am.



STEVE:  Okay.



LEO:  I'm just an optimist, Steve.  As Alex Lindsay says, I just want the sun overhead at noon.  I don't care about anything else.



STEVE:  How about sometime during this podcast daylight savings time will change?



LEO:  That'd be good.



STEVE:  That'd be good.



LEO:  Yeah.  Thank you, Steve.  Always a pleasure.  You'll find 16Kb versions of this show, show notes, transcriptions, everything you need at Steve's site, GRC.com.  You'll also find SpinRite there, the world's best hard drive, maintenance, and recovery utility, and lots of freebies.  And everything you need to know about SQRL so you can implement it on your website.  If you can't watch live, and you want video, we have that, too.  We do high-quality audio and video at our site, TWiT.tv/sn.  It is also available wherever podcasts are aggregated, including iTunes.  You can get the TWiT apps on almost any platform and watch that way, as well.  Thanks to our third-party developers for those.  But whatever way, you don't want to miss an episode.  And if you're going to miss an episode, you definitely don't want to miss next week's Episode 500 of Security Now!.



STEVE:  Ooh, boy.



LEO:  And one last week to vote in the Podcast Awards.  Make sure you vote for Steve.  PodcastAwards.com.  Vote early, vote often and often and often.  Vote all the time.  Don't vote for any other show.  Don't dilute your vote.  Vote for Steve.



STEVE:  There is no other show.



LEO:  There is no other show.  There's one show.



STEVE:  Even the people competing with us in that section have voted for us.



LEO:  There's no reason you shouldn't win this every year.  But I guess we have to go through the motions.  So please vote.



STEVE:  I just decided this one I want.  Then I'll be quiet from now on.



LEO:  Well, that's kind of how I feel.  It's like, you know, I could have it every year because we have such a devoted audience, and they're very active, and they participate, and they're big.  



STEVE:  It's a great audience.



LEO:  There's 70,000 listen to this show.  If each and every one of you voted every week...



STEVE:  Yeah, we'd break their web server.



LEO:  It'd be like, okay, well, let's see who - are you in the technology, or what category?



STEVE:  Technology.



LEO:  Well, let's see who won technology.  Let's see.  Oh, here's a podcast with 300,000 votes.  What's the next biggest one?  Oh.  I guess he won.  Thank you, Steve.



STEVE:  Thanks, my friend.  See you next week.



LEO:  See you next week for Episode 500 of Security Now!.



STEVE:  Yay.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#500

DATE:		March 24, 2015

TITLE:		Windows Secure Boot

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-500.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I discuss the recent Pwn2Own hacking competition.  We examine another serious breach of the Internet's certificate trust system and marvel at a very clever hack to crack the iPhone four-digit PIN lock.  Then we take a close look at the evolution of booting from BIOS to UEFI and how Microsoft has leveraged this into their "Windows Secure Boot" system.  We also examine what it might mean for the future of non-Windows operating systems.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here to celebrate his 500th episode with a look at the new Secure Boot.  You can expect Windows 10 computers to be more locked down than ever.  How does that work?  He'll also talk about the latest security news, including a new entry on the Google Do Not Trust List.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 500, recorded Tuesday, March 24, 2015:  Windows Secure Boot.



It's time for Security Now!, the show where we cover your security online.  And we couldn't do it without this guy right here, the Explainer in Chief, Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Leo, Episode 500.



LEO:  Oh, my goodness.



STEVE:  Now, some people, notably Simon Zerafa, who's tweeted several times, saying, well, what about 512, you know?  Shouldn't that be, like, a thing?



LEO:  Oh, you binary bigots.



STEVE:  And it's like, well, okay, yeah, that's going to be good in 18 weeks.  But right now, Episode 500. 



LEO:  Well, you know what it does, it points up the fact that this is really just an odometer number.  There's not really much, I mean, when you say we've been doing this show for 10 years, now, that's meaningful to me.



STEVE:  Right, right.



LEO:  And that's coming up very soon.



STEVE:  Well, exactly, because you have some of your daily shows that are in the triple, or, what, in four digits already.



LEO:  Giz Wiz is, yeah, Giz Wiz is in thousands.  But our 10th anniversary, do you know, have we figured out when that is?  Because that's in six months or so, I think.



STEVE:  I think it was shortly after TWiT.  I think we started Security Now!, like in the late summer.



LEO:  Okay.  So soon.



STEVE:  So, yeah, maybe about six months, yeah.



LEO:  Yeah, because our TWiT, April 19th will be our 10th Anniversary TWiT.  That's going to be a fun event.



STEVE:  Nice.



LEO:  Get all the original guys on the show.  And I'm looking forward to that.  So that's a special This Week in Tech on April 19.



STEVE:  So this week I was sort of moved to this topic because of some news that came out of Microsoft's WinHEC, the hardware engineering conference in Shenzhen, China about four days ago.  And a slide that was shown, talking about the UEFI Secure Boot and TPM details, caught a lot of people's attention because, under UEFI Secure Boot, in order to get the Windows 10 Logo, which is the prized, what everyone wants to have on their laptops so that they can say we're an official Windows 10 Logo laptop or desktop or whatever, you must ship the machine with Secure Boot enabled.  You must have UEFI v2.31 or later.  And 2.31 is when Secure Boot essentially happened.  It sort of appeared in 2.2, but 2.31 is now the standard.



Then they said, for Windows 10 Mobile, "Must not allow Secure Boot to be turned off on the retail device."  Well, that's not a biggie.  That's sort of like the iPhone.  You don't want the iPhone's boot integrity to be - you're not supposed to be able to turn that off, you know, it's an appliance.  So the Win 10 Mobile is an appliance in that sense.



But what generated a ton of news stories when people saw this is that, for Win 10 desktop, for the first time, they said it's the OEM's option whether to allow the end user to turn off Secure Boot.  Now, if this stands, and this is subject to change by the time it finally happens late this summer, presumably, but this is a policy change from Win8 because Win8 also used UEFI Secure Boot, had to ship with it enabled.  However, in order to get the logo certification for Win8, the OEM had to allow the end user to turn it off and had to allow them to add their own security certificates to the UEFI Secure Boot database.



So this sort of, I mean, this has sort of always been Microsoft's approach is, for example, in XP they added a firewall.  And this was still when the market was selling third-party firewalls; but, oh, not to worry, it's off by default.  And sure enough, it really didn't affect anyone because it was off by default.  But then, of course, famously with Service Pack 2 they turned it on.  And so Microsoft sort of creeps along like this.  Anyway, so the issue is that, if you were to purchase a machine which the OEM had removed the opportunity to disable Secure Boot in the BIOS, then that's a Windows appliance.  You can't put Linux on it.  You can't do anything else with it that you may want to.



LEO:  You don't own it, really.  It's not yours.



STEVE:  Well, it's sort of more like a big flat phone in that sense.  So anyway, this stirred up a bunch of commotion.  And I thought, this is a perfect opportunity for us on Security Now! to look at the technology of UEFI, what's that about; what's Secure Boot;, how does Windows interact with it.  And down at the technical level with certificates and hashes and all that, how does that all work?  So that's the topic for the show today, Windows Secure Boot.



LEO:  Excellent.



STEVE:  And there was a little bit of news, really a perfect teachable moment for an iPhone/iPad four-digit PIN hack.  I just loved the cleverness of this, so we'll talk about that.  Another, an even worse certificate was found in the wild than we talked about last week.  And I've heard you now both on MacBreak Weekly and on TWiT talk about the Pwn2Own contest, which I thought was just amazing because that kid who cracked all the browsers probably could name his salary.



LEO:  Yeah.



STEVE:  Actually, he doesn't need a salary, given the prize money.



LEO:  Yeah, $255,000 he won.



STEVE:  Yeah, yeah.  So we have a great podcast today.



LEO:  Excellent.  I'm excited.  I hope you are, too, since it is, after all, our 500th.  And Lisa and I wish you a very happy 500th and our deepest prayer that you will do another 500 for us.



STEVE:  It's going great for me.  I ought to also mention, just because we won't be talking again until after, I turn 60 in two days.



LEO:  Happy birthday.  That's a big one.  I hope you're doing something fun.



STEVE:  Well, I've got all kinds of plans.  So it's funny because, you know, like...



LEO:  That's a huge birthday.  Wow.



STEVE:  Yeah.  And I guess what I like about it is that it was as I was approaching my five-oh 10 years ago that I'd just published SpinRite 6.  It was cruising along.  And I got sort of, as I was approaching 50, I got focused on health.  And so that's when I really began my dive into learning about supplements and longevity and health and inflammation, and got into the whole issue of heart disease and cholesterol and, of course, famously Vitamin D.  And then later the whole ketosis thing and all that.



And for me, as I turn 60, what's exciting for me is that I can literally, I can truly say that I feel 10 years younger today than I did 10 years ago.  Like, I mean, I just - I've never felt better in my life.  We saw that I got a cold a couple weeks ago, so I'm not impervious.  But I just, you know, nothing hurts.  I wake up feeling fantastic.  I'm going to do some scans on the day after my birthday.  I like to get my carotid artery ultrasound scan, and I did remove a little bit of plaque about five years ago that was initially there when I began this quest for health, and that's all gone now.  I reversed that.



LEO:  Wow, great.



STEVE:  Anyway, I'm just having a great time.  So six-oh.  And it does feel like a milestone.



LEO:  Oh, yeah.



STEVE:  And I'm just - I'm glad that everything's going so well.



LEO:  Or as Web4384 says, "It's only 32 in hex."



STEVE:  That's right.



LEO:  Just remember that.



STEVE:  That's right.



LEO:  Although I don't want to know what it is in binary.



STEVE:  No.



LEO:  I'm sorry.  He's got it wrong.  It's 4C.



STEVE:  Four Charlie.



LEO:  Four Charlie.



STEVE:  Okay.  So...



LEO:  Security news.



STEVE:  Security news.  You want to click the second link in the first page of the show notes.



LEO:  Okay.



STEVE:  FoneFunShop.co.uk, and there's some trailer stuff.  This is a really interesting hack for the iPhone and iPads which worked through v8.1, but inevitably was going to be foreclosed on as soon as Apple realized what was going on.  But the fact is, this was hardware, a hardware box, costs about 120 pounds, which until just November, which is when they went to 8.1.1, was able to crack four-digit PINs, if you had your iPhone protected by a four-digit PIN code.



Now, we've talked about how hard Apple worked to make that impossible, specifically the famous "Erase all data after 10 attempts" lockout, the idea being that you just can't guess four-digit PINs day and night because after 10 mistakes it does a - basically, remember, it throws the keys away.  It doesn't actually have to wipe the data because the phone is encrypted, and all it needs to do is wipe the key which is required to be inline in the hardware that performs the on-the-fly encryption and decryption as data goes in and out of memory.



So get a load of this.  What this hardware does, you have to open the phone up physically.  In fact, there's a picture of it in use on the link above, that TechWorm.net link, that shows the screen popped open, I mean, the phone guts exposed, which has to happen.  Then you stick some probes inside.



LEO:  Oh, wow.



STEVE:  Now, what this does is - get this, Leo.  It tries 0000, determines instantly whether it worked or didn't.  And if it didn't, it does an instant power cut to the phone before...



LEO:  To prevent the deletion.



STEVE:  Yes, to prevent the counting.



LEO:  Ah.



STEVE:  So Apple made a little mistake, and this is why this is such a perfect example of, like, real-world security.  Apple's programmers said, okay, so if they don't enter the PIN code correctly, and "Erase data after 10 attempts" is enabled, then we increment a counter which we store in nonvolatile memory so that we are continuing to increment it until they enter it correctly, in which case we zero the counter.



What these guys did was realize they could break power, disconnect the battery so fast after a guess failure that the phone was in the process of recording the guess, but wasn't able to complete that update.  So just a brilliant hack.  I just love this because this is the kind of way security breaches occur, where something looks absolutely solid until somebody really motivated looks at the same code everybody else has been looking at and says, "Wait a minute.  What if we chop the power right here and then reboot the phone and then try the next PIN?  And if it fails, chop the power, reboot the phone, go again."  And it turns out that works.



 So all Apple had to do is change the sequence.  They pre-increment before they do the test so that they've recorded the pending failure in case it does fail, rather than post-incrementing.  They did that.  They changed that in 8.1.1.  That's all they had to do to foreclose on this really cool hack.  But until last November, even with the iPhone 6 and v8 and all of its various incantations getting up to 8.1.1, you could crack it this way, if it was protected by a four-digit PIN.  If you were using the more complicated passwords, there was just, you know, there was no way it was going to guess.  As it was, it could take like 111 hours, so many days to go through 0000 to 9999.  But if you're law enforcement, and you needed to get into somebody's phone, and it was protected by a four-digit PIN, this would do it until a few months ago.



So I just love this as a perfect example of how clever the hackers can get and how something that looks innocuous can be even further hardened against this sort of attack.  But you'd also have to argue that, boy, it's hard to find all of these.  It just takes, you know, it takes bad guys poking at the things that are trying to be secure, acknowledging they're going to find some holes, and then plugging them and hoping you don't add new holes as you move forward, which of course is always the challenge.



In the news, we discussed last week the really interesting hack with Live.fi where Microsoft had not blocked all of the administrative email account names that certificate authorities might use to authenticate ownership of a domain, and as a consequence an enterprising person in Finland said, hey, what was it, hostmaster@live.fi.  He set up that as an alias to his otherwise Live.fi email, and then he had a certificate issued for himself for Live.fi.



Well, it turns out there was another instance of that that was a little less reported, and that was somebody also did the same thing at Live.be, which was another one of these Microsoft properties, but just in a different top-level domain.  But the big news of the week, which caused Chrome to immediately reissue and update their CRLSet - remember I was talking about how - in fact it was last week.  I'm looking up at my CRLSet monitor here, which was at nine.  And you'll remember that I'm entry number five.  You know, revoked.grc.com is - I'm at five.  And since then there have been a few other problems.  But Live.fi was nine because they added nine.  And I imagine that Live.be was 10, and then something even worse was 11 because they're now up to 11 of these explicitly blocked certificates.



LEO:  There seem so few.



STEVE:  Well, it is, because these are the ones which are not yet expired.  So there have been horrible problems in the past, but those certificates have now expired themselves just by their date.  So that's one of the nice things, I mean, I remember years ago grumbling about the need to constantly be issuing certificates, how they expired, and it was just a moneymaking enterprise for the certificate authorities.  I have a much, I think, and I know that our audience does now, too, a more sophisticated and mature understanding of the fact that, yeah, that's maybe not ideal, but it's the best solution we have because, if certificates weren't expiring, that list which you note is so short could not be that short because every certificate that had ever had this problem would have to be on that list.  Now it's only those that haven't otherwise expired themselves.  So this is that tradeoff that we make where we really don't have a perfect system.



And the event that occurred which caused the 11th entry in that table is another biggie.  It turned out, and we have to thank Google for this, I mean, one of the neatest things about Chrome is that Google has pinned all of the Google certs, which is to say the Chrome browser knows the serial numbers of every legitimate Google certificate, meaning that you can forge other people's certs; you cannot forge Google certs.  And look at them with the Chrome browser, the Chrome browser will have a fit just instantly and immediately has instrumentation sending alarms back to Cupertino.  And immediately...



LEO:  Mountain View. 



STEVE:  Mountain View.  Immediately Google knows...



LEO:  Those other guys are there in Cupertino.



STEVE:  Right.  Immediately Google knows that one of their browsers somewhere in the world has just encountered a fraudulent Google certificate, and that happened again last week.  It's happened several times.  It's how we find out about these things so quickly is somebody messes with Chrome.  And Chrome just - it's finicky this way.



So what it turns out happened was China's CNNIC, that's the China Internet Network Information Center, which is a large Chinese certificate authority, under an agreement with an Egyptian intermediate certificate authority called MCS Holdings, CNNIC issued MCS holdings an intermediate certificate that had signing authority, meaning that that certificate had the bits set in it that allowed it to sign other certs.



LEO:  This was an error.



STEVE:  This, well, okay.  So the agreement was that MCS Holdings would only issue certificates for their own domains.  Instead, they broke their agreement with CNNIC, which is the root certificate authority that all of our browsers trust.  I mean, this is like the equivalent of the Hong Kong Post Office.  This is, you know, CNNIC is a CA, a root certificate authority all browsers trust.  So their self-signed certificate is in all of our OSes and phones.



LEO:  Is that China NIC?  Is that what that is?



STEVE:  Yes.



LEO:  All right.



STEVE:  Yes.  So this CNNIC issued an intermediate certificate that itself could be used to sign other certs to this MCS Holdings, this Egyptian intermediate certificate authority, with the promise from MCS Holdings that they would only use it to sign their own domains.  Instead, they installed it in a proxy.



LEO:  Whoa.



STEVE:  So what they did was they stuck it in a piece of equipment that was then able to filter all of the traffic moving through it.  Now, we've talked about this a lot because of course this is what some of the spyware that we've been talking about recently has been doing.  But they didn't have a certificate that could sign other certs, that is, a certificate that was chained to a root cert that everybody already trusted.  That's what's different about this.  MCS Holdings had this certificate that could sign other certs, and it was trusted by the root cert that we all use.



Normally, when you want a proxy, like when the spyware is proxying, they have to install their public key in your browser in order for you to trust what they sign with their private key.  But by installing - and this is the reason MCS Holdings presumably did this was they put this certificate in a proxy so that everybody downstream of the proxy would trust all of the security, and they'd be cracking open, basically performing a man-in-the-middle attack, cracking open secure transactions for whatever reason they had.  But somebody inside of that network had Chrome.



LEO:  Woohoo.



STEVE:  And the moment they went to a Google property, the Chrome browser received a fraudulent Google cert from this proxy appliance and raised holy hell and immediately exposed the fact that something was generating these fraudulent certificates.  Google got on it, figured out what was going on, and has blacklisted that cert.  Firefox will be updated.  I got a couple updates from Firefox.  There was a Firefox update, I think we're at like 33 - let me take a look here, just see where I am.



LEO:  They said it's going to ship in Firefox 37.



STEVE:  Ah, right.  So I'm at 36.0.4.  One of those changes was to fix the Pwn2Own vulnerability we're going to talk about next.  But you're right, in 37 they will push out a Firefox that has this intermediate cert untrusted, much as Chrome now has, thanks to the CRLSet.



LEO:  Now the interesting thing, the Mozilla security blog points out that the CNNIC, the China NIC, said as you said that it wasn't permitted by their policies and have revoked the intermediate certificate.  But this is an issue because, as we know, certificate revocation is basically meaningless.



STEVE:  Yes.



LEO:  So they have to add it to the list, that 11-member list, which includes Steve, of certificates you should not trust.



STEVE:  Right.



LEO:  Firefox does the same thing.  But if certificate revocation worked, this would have been automatic, and it's kind of annoying.



STEVE:  Exactly, yes.  And this is where I kind of went off on my complete tirade many months ago, when I realized that Chrome was misrepresenting their own CRLSet because they're having to manually revoke highly important certificates by adding it to a special list at the top because their CRLSet isn't actually big enough to really do much good.  And this highlights, again, essentially the problem that we talked about last week, which is it is - we have currently a brittle system.  It's brittle because a tiny mistake that any one of the hundreds of certificate authorities that we implicitly trust, a tiny mistake they make requires a scramble.  Suddenly all of the browsers and other trust anchors that exist on the Internet have to scramble in order to deal with the event of a tiny mistake being made.  So this, I mean, it's just not stable the way it is.  And the good news is there are things on the horizon that are going to probably fix this.



LEO:  Interestingly, Mozilla will introduce with 37 a similar list.  They call it, what is it, OneCRL, but it's the same idea.



STEVE:  Yup.



LEO:  And they acknowledge that certificate revocation using OCSP doesn't work.  So they're going to do a list just like Chrome does a list.  So I guess, you know, maybe that kind of confirms this as the best way to do it.



STEVE:  Yeah.



LEO:  Till we fix it.



STEVE:  So at the CanSecWest security conference over the weekend - I have to say this guy is gifted.  This was the Pwn2Own competition, or challenge, which is cosponsored by HP's Zero Day Initiative and Google's Code Zero program.  I'm sorry, Project Zero program.  Found a bunch of bugs.  Microsoft Windows was found to have five, IE had four, Firefox had three, Adobe Reader three, Adobe Flash three, Apple Safari two, and Chrome one.  Overall, a total of $442,500 was paid out to researchers.  But more than half of that was grabbed by one guy.  And he's a Korean researcher, is it pronounced Jung Hoon Lee?



LEO:  Your guess is as good as mine on that one.



STEVE:  Yeah.  He pulled off - okay.  So as I just noted, IE, Firefox, Safari, and Chrome, all four browsers collapsed under the pressure from these guys.  He was responsible for three of the four.  And against Chrome he won $110,000, which is the single biggest payout in history.  As you mentioned on MacBreak Weekly, he used more than 200 lines of code.  This used Chrome's...



LEO:  Oh, 2,000.



STEVE:  I'm sorry, 2000 lines of code.



LEO:  Two thousand.



STEVE:  Two thousand lines of code.



LEO:  Which is like writing an application.  I mean, that's a big deal.



STEVE:  Well, and he made reference to the Chrome Native technology, which I'm going to have to cover on a podcast soon because it's really interesting.  I took a look at it recently relative to exploit mitigation that they're doing.  But this is the technology that is really sort of frightening, that allows you to run native x86 code at full machine speed, no interpretation, like any JavaScript or Java or Flash or anything else has, native code in a special sandbox in the browser.  So it's very likely that 2,000 lines of this is what he used.



So he said, "Using more than 2,000 lines of code, Lee took down both the stable and the beta versions of Chrome by exploiting [get this] a buffer overflow race condition in the browser.  He then used an info leak and the race condition in two Windows kernel drivers to get system access."  So the standalone Chrome bug fetched him $75,000.  The privilege escalation bug got him another $25,000.  And then Project Zero - so that would be $100,000.  Then Project Zero independently paid him $10,000 when Chrome was hacked at that event.  So just for Chrome, the Chrome takedown, $110,000.



Then in IE11 he earned $65,000 for exploiting a 64-bit version, this is IE11-64, with what's called a "time-of-check to time-of-use" - the acronym is TOCTOU, time-of-check to time-of-use - vulnerability.  Who even knew there was such a thing?  The vulnerability exploits the time between the time a file's property is checked and the time the file is used.  This is another one of those little shim sort of things where, if you're really good, and you really understand this stuff, you can foil the system designed to be foolproof.  And normally this would lead to a privilege escalation, but in this case the attack enabled him to gain read/write privileges on the browser, while another attack he used allowed him to escape the sandbox via a JavaScript injection which allowed him to evade other IE11 defensive mechanisms.  So again, this is some serious aikido of this kind of hacking.



LEO:  Yeah, almost all of the CanSecWest exploits were what they call "chained."  That's a chained exploit, taking advantage of a flaw, flaw, flaw, flaw, flaw down the road.  That's why 2,000 lines of code.



STEVE:  Yeah.  And it's because one problem will get you a little bit of a beachhead, but nothing you can immediately exploit.  So you have to take that and then leverage that into something else to get a more powerful advantage and then do it again. I mean, I feel like we're in the land of science fiction now.  It's just amazing to me that this is all true.



But then, anyway, finally in Safari he found a "use after free" vulnerability which exploited an uninitialized stack pointer in Safari's sandbox in order to break out of the sandbox, and that earned him $50,000.  So he took home $225 grand for a few minutes' worth of a demonstration.  As we noted, and as you have said on both those prior podcasts, Leo, these are, I mean, it's a little bit of a mixed blessing because this 2,000 lines of code he didn't sit down and write right there.  He had figured out that he was going to be able to crack Chrome.  And in fact, in some background research I did, he did this through static code analysis.  That is, he sat there looking through code in order to find a way to do this.  So he earned his money.



And so I guess I'm glad that these vulnerabilities have been removed.  It certainly does take this level of skill in order to find them.  These vulnerabilities are increasingly difficult to find and exploit.  And of course that's the good news for all of us.  Browsers are getting more secure.  Now the key, as I keep mentioning, is for us not to break them by adding stuff to them.



And so we have a Firefox update coming.  I'm now at 36.0.4, and I was at .3 yesterday.  So they've been revving it a bunch.  I don't know whether this may already have the provision for that erroneous cert or not.  I mean, it's not a huge problem.  It's very likely the case that no malicious certificates were minted by this proxy.  But it is very cool, I think, that somebody using Chrome downstream of the proxy visited Google, and that just sent Chrome into a fit and immediately identified that an illegitimate Google certificate was in use, and then we were able to figure that out.  So this is some cool instrumentation that Google has been building.



LEO:  No kidding.



STEVE:  And I loved Sunday's TWiT, Leo.  I just wanted to...



LEO:  Thank you.



STEVE:  ...mention that.  And...



LEO:  I don't remember it.  What happened?



STEVE:  I completely agree with you about VR headsets and pornography.



LEO:  Have you tried it?



STEVE:  I watched - no, no, no.  And you are right.  And I was a little disappointed that everybody else was just, like, in shock when you said that, as if...



LEO:  They hadn't even thought of the idea.



STEVE:  Well, I mean, any student of history and technology knows that, for whatever reason, adult entertainment is always on the leading edge of new technology.  The reason VHS videocassettes took off, initially, adult entertainment was what people were purchasing.  And we are probably - everybody listening to this podcast is old enough to remember that in the early days, the Internet was mostly porn.



LEO:  Right.



STEVE:  I mean, that's what - it was a huge...



LEO:  May still be, but we just know not to go there.



STEVE:  Yeah, I haven't seen any in, like, forever.  But, I mean, it used to be on sitcoms and things.  I mean, it was a massive porn database.  That's what it was.  And people sort of had a sense of anonymity.  And so that made them feel safe.  And so, you know...



LEO:  I actually think it's not only not changed, it's gotten - that really is probably a huge amount of the Internet traffic.  And people just, I think, everybody just kind of pretends it's not the case or just ignores it.



STEVE:  Well, if nothing else, there is a lot more now.



LEO:  Yes.



STEVE:  It used to be that, you know, there wasn't that much else on the Internet.



LEO:  Right.  There's a ton of other stuff, too, right.  Everything's on the Internet, yeah.



STEVE:  Right, yeah, exactly. 



LEO:  Yeah.  The porn guys were early on.  They were VHS, every new technology.  Credit cards, you know, online charges.



STEVE:  I'm sure the very first tintype photographs, it's like, oh, look at this picture, oh.



LEO:  But my point - well, I don't know if I want to belabor it.  But my point was, having tried it now...



STEVE:  The VR.



LEO:  Somebody who has a Gear VR headset, which is based on Oculus, surfed to one of these sites that offer it.  We didn't buy anything.  They had trailers, so I looked at the trailers, which are explicit.  And the experience is very realistic.  It's notably more realistic than just watching it on a screen, on a flat screen.  And while I haven't really enjoyed the realism of games - you get seasick because you're moving, and it's moving in a little different way, and it's just tough.  And regular movies don't lend themselves, I think, so well to the idea of you're in the movie, certainly nothing that was made yet.



STEVE:  Yeah, you know, I mean, like what was James Cameron's big one, the...



LEO:  "Avatar."



STEVE:  "Avatar."  It was like, it was in 3D.  It was nice.



LEO:  Yeah, but VR the idea is that you're not just watching the action on the screen, you can look around; right?  So that doesn't - moviemakers are not going to be that interested in letting the viewers' attention wander to any part of the screen.



STEVE:  No, no.  They're artistes.



LEO:  Yeah.



STEVE:  They want to control your focus.



LEO:  And maybe they'll play with that.  But nobody has to date.  Well, as it turns out, I don't want to go into great detail here, but...



STEVE:  Well, but actually there's no need to.



LEO:  You get it.



STEVE:  All I wanted to do was to, yeah, I just - listening to TWiT, I thought, what's wrong with you guys?  Leo is right.  It's obvious that that's going to be a market for virtual reality headsets.  It's always this...



LEO:  More obvious than you think, Steve, because it's a light years' different experience.  It's like you're there.  And that is what people want with porn.  Not with many other experiences.  Gaming, yes.  If they can get it to work, great.  But, boy, they've got it now.



STEVE:  It's a visceral, emotional, deeply wired into the human psyche thing.



LEO:  Right.



STEVE:  And so, yeah, anyway, I immediately understood what you were saying, and I just wanted to say that those guys somehow, maybe they were just too shy.  I mean, you know, we're adults.



LEO:  I think they were absorbing it.  But I'm surprised there's been nothing written about it.  Nobody's talked about it.  It happened with Google Gear very quickly, or Google Glass, rather, very quickly, that there were attempts to use it.  That's not the same thing.



STEVE:  Yeah, a little window over here.



LEO:  That's looking in a window over your eyebrow.



STEVE:  No.



LEO:  Imagine an immersive adult experience that a lot of people would be very interested in.  And it is not like - it is almost as...



STEVE:  It is really convincing.  That's the point.



LEO:  It's the thing this was made for, practically.  And why nobody's written about this is beyond me because I feel like this will be a very big part of what makes VR happen.



STEVE:  I think it's just too soon.  It's just, you know, they're still showing 3D cubes.  It's like, oh, look at that 3D cube floating in space.  It's like, well, no.



LEO:  I remember going to SIGGRAPH 15 years ago, 1991 or '92, and they had - you could fly on a pterodactyl.  Now, some of you may remember this.  It was a very famous VR demonstration, required a lot of hardware.



STEVE:  Oh, my goodness, rooms.



LEO:  And you're flying.  And as you're flying, you can look around.  That's cool.  But if you were flying with a naked woman?  I don't want to go any more.  But I'm just saying...



STEVE:  No need.  No need.  I just, you know, it was just my reaction to them not understanding how obvious, I mean, just, if nothing else, the history.  For whatever reason, that has always been a major application of leading-edge technology.



LEO:  And you ain't seen nothin' yet.  That's all I'm saying.  It's just beginning.



STEVE:  And the other thing I wanted to mention about Sunday's show was it was interesting to listen to Ed Bott defend his position on privacy.



LEO:  I give him that opportunity every time.



STEVE:  Yeah.  And it's, I mean, and you and I sort of feel similarly.  But that's the sort of - that's the feeling that I got when I came out of the Snowden movie, "Citizenfour," was a deeper sense of respect for the rights of people who wanted privacy for its own sake.  I really think that that's where Ed is.  He's like, he wants it for its own sake.  He feels like he's always had control.  He doesn't want to lose that control.  And, you know, it's his right.  And I think...



LEO:  Of course it is.  Nobody denies that.



STEVE:  Right, right.



LEO:  And the only point I continue to make is that a lot of the services you use today, like Google and Facebook, are paid for by that trade of data for utility.  And to me it violates - it's an ethical violation.  And by the way, I think people think that I'm talking about TWiT.  I'm not.  We don't - we have kind of a different model anyway.  But I guess it would be the same thing.  If you'd never listen to the ads on our shows, but love the shows and listen to the shows every time, that's the same kind of ethical violation.  You're saying, "I'll consume the content, but I will not support the way you pay for it."  And that's, you know, it's fine if you don't want to participate.  So don't.  But don't use Google and Facebook and say, "But I don't want to see the ads."  Because...



STEVE:  Although Ed did keep reminding you that it's the tracking that he objects to.



LEO:  Yeah, yeah.  And you don't...



STEVE:  Not the ads.  Because, I mean, he really understands the incredible amount of data that is aggregated about us.



LEO:  Yeah, I understand, too.  Yeah.



STEVE:  And so that's the thing that he objects to.



LEO:  And when you watch a show, we don't in any way track whether you saw the ad or not.  We can't.  We wish we could, but we can't.  There's no way of us, when you get a show, knowing anything about you.  We don't.  So even when you watch live, I mean, there are a few trackers on our site for analytics because, you know, somebody pointed out, well, you've got a Facebook "Like" button on your site, which I think we do somewhere.  That's a tracker.  Of course, Facebook then is getting a bit of data about you, mostly just your IP address and maybe your browser, whatever they can deduce from the browser.  Maybe they're setting a supercookie?



STEVE:  They know where you are, yeah, because...



LEO:  Yeah, well, your IP address, yeah.



STEVE:  Well, no, they know you're at TWiT because your HTTP referrer header will say that there's a Like button on TWiT.tv.  So they get that.



LEO:  Yeah.  It's basically giving Facebook a window into whoever visits our site.



[Crosstalk]



LEO:  I'll take those buttons off.  We won't have them on the new site.  We will have analytics because we need to know how many people visit our site, not necessarily for advertising reasons, although that's part of it, but we want to know that.  You know.  And so if you're using an ad blocker, you're basically saying, yeah, I'm going to steal your stuff.  To me.  But I understand the other issues.  The privacy issue is absolutely right on.  Just don't visit sites.  You can listen to our show.  That's safe.



STEVE:  Yeah.  So just a really short, nice little note from a listener of ours, Phil Horowitz, who's in Montreal, Quebec, Canada.  He said:  "Hello, Steve and Leo.  My simple everyday SpinRite story: I was helping a friend who had a Windows 8 computer that hung at startup.  He didn't know what to do.  So he brought the computer over, and I ran SpinRite.  As I have seen before, there were no evident errors that were corrected.  But nevertheless, after SpinRite completed, the PC started.  Great.  Love Security Now!.  Haven't missed a show.  Phil Horowitz."



So, and I did want to take this opportunity just to say back to the listeners of this podcast on the occasion of our 500th podcast, I just wanted to say thank you because the support that I feel from our listeners, I mean, how many times have I read testimonials or tweets from people who have said, "I know the only thing you sell is SpinRite.  I bought a copy, even though I didn't need it, to support you and the podcast.  And I now know that, when a drive crashes, that I'll probably be able to recover it and save it."  And that means a lot.  I mean, it's one thing for people to say, "Hey, you know, love the podcast."  But when people vote with their dollars, that's significant.



And for me - as Leo, you're always mentioning that SpinRite, as I just said, is the only thing that I sell - the podcast, this podcast has been one of the best things I've ever done for helping to get the word out about SpinRite.  Prior to that, the reason I was doing the InfoWorld column back in those early days was that I was able to trade an ad insertion with InfoWorld for my column.  They let me let the world know about SpinRite; I put a column worth of content in InfoWorld every week.  And so that worked for me.



And for me, this is the same sort of thing.  I love doing the podcast.  But my ability to tell people about SpinRite for the last 10 years of the podcast has allowed the word to spread.  It's helped innumerable people who wouldn't have known about SpinRite and would have lost data that they considered vital and important.  And as I often say, it's paid all the bills.  It allows me to have Sue and Greg to do the backend bookkeeping and tech support and gives me the freedom to push forward on other things.  So anyway, I hear thanks from our listeners all the time for the podcast, which really means a lot to me.  But I want to really turn that around and say thank you to our listeners for making this possible for me.  Because your support and you guys all do that.



LEO:  Thank you.  We do.  We agree.  Awesome people.  Keeping up the content flowing.



STEVE:  So, speaking of content.



LEO:  Yes.



STEVE:  Windows Secure Boot.  Okay.  So this will sound familiar because it's very much the same story that any system booting in a hostile environment would have.  The reason it'll sound familiar is it's the Apple iPhone story.  When we did the series, I think it was three podcasts, on I think it was iOS 7, all of the things that Apple did in order to really lock down, I mean, seriously secure iOS.  They're booting that phone in a super hostile environment.  Bad guys desperately want to get in.  And the phone is sitting there all by itself, no one to defend it.  It has to defend itself.



So there's now sort of a well understood approach to this.  And it involves a so-called "trust anchor," that is, some absolute, single point of trust.  And the evolution of what the device does, whether it's a phone, a desktop, a laptop, or whatever, all sort of flows from that first point of trust.  So the original PC had the BIOS, an acronym everyone's familiar with:  Basic I/O System, BIOS.  And it was just about as simple as it could be.  I meant to have a copy of it next to me.



I have the original IBM XT Technical Reference Manual, which is this really nice sort of clothbound, little sort of mini three-ring binder.  And just innocently printed at the back of this technical reference is the listing of the BIOS.  And it was really useful for me.  It allowed me to create my first product for the PC, which was this crazy thing called FlickerFree, where I rewrote the BIOS handler for the display screen in order to remove the scrolling flicker that the CGA, the Color Graphics Adapter, card had, and also sped it up by hundreds of times.  It was just amazing what a difference just rewriting a chunk of the BIOS could have.  And similarly, in the early days of SpinRite, I needed to understand what was in the BIOS in the PC XT in order to interact with it because I was essentially taking the place of DOS.



Well, the idea with the original BIOS was very simple.  The concept was the BIOS is going to be a layer between the hardware and the operating system.  So that there would be hardware on the motherboard.  You'd have serial ports, a parallel port, a graphics display, or at least a text display, keyboard, in the early days cassette input and output, and floppy drives, and maybe a hard drive.  That was pretty much it.  That was the I/O of the PC.



And rather than expecting any software that ran on that PC to talk to the physical hardware, what IBM provided was an interface layer, formally called a "hardware abstraction layer," an HAL, the idea being that, no matter what type of disk controller you might plug in, whether it was RLL, or SCSI later on, or MFM or whatever, you could always talk to different makes and models of hard disk controller through the BIOS, interrupt 13 of the BIOS, in order just to say read and write these sectors, move the head, format the track and so forth.  There were commands you could give.  Similarly, interrupt 10 was the video interface.  And so you were able to say clear the screen, print this line of text, and so forth.



Well, the problem, as the industry evolved, people wanted to pierce that layer because they wanted additional function.  I remember, for example, I replaced the video portion of the BIOS with a little TSR, Terminate and Stay Resident program, FlickerFree, in order to dramatically enhance the performance of the screen on that system.  But famously, there were things that people started to want to do that you could not do through the BIOS.  I want to say VisiCalc.  Was VisiCalc on the PC?



LEO:  Oh, yeah.



STEVE:  Or was it Lotus?



LEO:  Well, VisiCalc was, and then Lotus.  VisiCalc started on Apple, of course, yeah.



STEVE:  Right, right.  And so in Lotus I remember they were programming the video RAM directly because they just couldn't afford the overhead of the BIOS.  The BIOS could have allowed them to do it.  But the things they wanted to do, scrolling quickly, horizontally and vertically; moving, like, highlight bars around the screen.  It just couldn't do that.  So they had to bypass the BIOS and go direct.



So many older systems are still BIOS based.  The BIOSes have lived for decades, mostly because you could bypass it.  You would use the BIOS to essentially power the system up.  It would initialize the hardware.  It would sort of settle things down.  Then it would look through a list of possible boot devices, checking them in sequence for a sector that said it had access to a bootable partition, and it would go and see if it could boot the partition.  If so, it would run that code, and off you'd go.  The operating system then, rather than using the BIOS - for example, DOS actually did use the BIOS.  But the first thing Windows did was say, okay, fine, get out of the way.  And Windows brought its own drivers, essentially to talk directly to the hardware.



So this was the situation up until probably, what, the mid-1990s or so, when the BIOS began to show its age.  Systems were evolving.  We were beginning to want much more capability.  People wanted to be able to boot their system over the network remotely.  They wanted, corporate IT wanted to be able to do an inventory of what was plugged into the motherboard without even talking to the operating system, actually have the motherboard be smart enough.  Motherboards started to want to be able to monitor the voltages of their power supplies, and the current.  They had multiple fans, and so they wanted to control temperature in various areas.  They had fancy RAID arrays that they needed to support.



Essentially, the very modest platform that the PC XT originally was, that the BIOS was able to service, that platform just exploded.  So we needed something new.  And so the so-called EFI then became the unified extensible firmware interface, UEFI, which is now the state of the art in firmware.  Some people say the "UEFI BIOS," although technically that's not right because the BIOS is the BIOS, and UEFI is a different firmware than the BIOS firmware.  But today's UEFI offers a vast array of services.  There's essentially almost an operating system within the motherboard to manage the modern complexity of all the peripherals.  There's an ACPI which is the power control that allows various power-down states.  And all that has to be communicated and coordinated with the hardware so that the motherboard understands how to do that to all of its hardware.



So you still need sort of a central point of responsibility.  And as I mentioned, there's fans and voltage and current monitoring, remote network booting, just all the chassis management and everything.  So the UEFI has just exploded in size.  It's really left the original BIOS way behind.  So it got to the point where it was time to talk about security.  And the UEFI has gone through a number of versions.  It was at 2.2 that we first really got what was known as "Secure Boot."  And in the same way that the iPhone depends upon its hardware in order to provide absolute security, the Secure Boot is the same way.



There is a platform key, abbreviated PK, which the manufacturer of the device - we'll use the term "motherboard" just for short, but it could be also the main board of the laptop or whatever.  There is a platform key which the manufacturer is able to use to sign the firmware which first wakes up when power is applied to the device.  So essentially everything we have learned about the way certificates and public keys and all of the PKI, the public key infrastructure, works, that is all there in the UEFI system firmware.  The manufacturer has the private key that it probably doesn't let go of.  There are some instances where really large purchasers may acquire the private key for their systems if they want absolute control over the firmware of the systems that they're purchasing and managing, although it's probably not necessary because of the hierarchical nature, sort of in the same way that you can get a certificate to secure your server.  You don't need to be a certificate authority yourself.



So essentially, if we sort of reuse the jargon of the web, the manufacturer of the motherboard, this UEFI motherboard, is the certificate authority.  It is the trusted CA for their device because, burned into the ROM of that board, unmodifiable, is a public key which is used to verify the signature of the first startup boot firmware that wakes up when the system receives power.  So at a hardware level, before anything happens, the signature, the digital signature, in the sense of an SHA-256 MAC signature, is taken of the very firmware to start, and verified against this platform key.  And of course so what that means is that only signed firmware will be booted by that board.  If anything changes, if a byte changes in that firmware, or someone, anyone tries to replace the firmware - and in fact there are also rollback provisions, using timestamps, so that it is not possible to put an earlier version of firmware on top of a later version.



So the system has been designed in very much the same way the iPhone was, with a security framework that starts with absolute hardware support and then works to never lose that.  There are three databases that are contained in nonvolatile RAM or ROM, doesn't really matter.  It won't lose its memory when it's powered off, but it can be rewritten.  Thus these are databases.  There's something called the KEK, the Key Exchange Key, database, which contains essentially signatures, the spec refers to them as "trust anchors," but they're just cryptographic signatures of entities that are allowed to modify the other two databases.  There's an "Allowed Signatures" database and a "Forbidden" database.  And either of those databases can contain either certificates that sign other firmware, or hashes, that is, digests, fingerprints of other firmware.



So what we have is an architecture where all of the firmware modules, that is, for example, in UEFI you still have things like Option ROMs to extend the knowledge that the base firmware has of specific peripherals.  So, for example, a network hardware will have its own Option ROM with UEFI-compatible firmware in it.  In order for that Option ROM to be initialized at boot, which has to happen in order for it to initialize the network hardware, that Option ROM has to either be, well, first of all it has to be signed.  And the signer of that has to have their certificate in the Allowed Signatures database and not have that certificate in the Forbidden database.  Or if there isn't a certificate for the firmware, then the cryptographic hash of that firmware has to be in the Allowed Signatures database.



So you have an explicit whitelist/blacklist system for every component of UEFI firmware.  All the various pieces of additional firmware extension that exist on the motherboard are individually hashed, and in some cases signed, in order to allow that firmware to - and I should mention that the firmware is enumerated when the system powers up.  And then that initially signature protected initial boot code goes out and checks the signatures of all of the other pieces of firmware.  As it's doing this, it's also leaving an audit trail.



There's another component of this which is oddly named.  It's called "Measured Boot."  So we have Secure Boot, which is sort of the implementation side of making sure that nothing that is known bad or unknown is ever allowed to run.  And then the Measured Boot is an auditing system, an auditing function which is going on throughout this entire process in the background, which uses the Trusted Platform Module as its audit store because in a compromised system the compromising software could alter the audit trail.  We often hear, for example, how bad guys get into the system and then erase the logs of them getting in, in order to cover their tracks.  So you want to prevent something like that from happening.



So this Measured Boot is also running step by step through the entire boot process, creating essentially an audit trail of everything that is run.  So at some point, after all of the UEFI firmware has been enumerated, all of the separate pieces of it have had their signatures checked, certificates have either been found for them, or they are explicitly whitelisted in the allowed signatures database, finally then the system will enumerate boot candidates, like mass storage boot candidates, and begin to turn this boot system over to the operating system that wants to run on top of all of this.



So that's where, of course, Windows comes along.  Windows is able to have, well, first of all, as we know, 64-bit kernel drivers have to be digitally signed.  So the UEFI firmware is able to reach up into the Windows boot loader, which is an EFI image also.  EFI images are Microsoft format portable executable files.  And that's just a standard for UEFI.  So UEFI is able to reach up, verify, in the same way that it verifies its own firmware, it's able to verify the first boot modules of the operating system also, to make sure that they are explicitly whitelisted and that they have not been changed.



Then Windows introduces - the operating system itself has this notion of boot drivers, which are kernel drivers flagged for early loading.  It's just a particular property that the driver has in its header which says "I need to be loaded early in the process."  There's a special one of those that supports Windows Secure Boot which is called ELAM, E-L-A-M, which is the Early Launch Anti Malware.  And Microsoft uses the acronym AM for antimalware throughout their spec of this.  So the idea is that the EFI, the UEFI firmware verifies the signature on these drivers.  The drivers are signed by Microsoft Authenticode.  So, and that technology is also available to the UEFI firmware.  It's able to verify Microsoft Authenticode signatures in order to know that it's able to trust these pieces.



This ELAM, the Early Launch Anti Malware, gets in, inserts itself into the boot process, and then essentially takes over responsibility.  That's the handoff between the UEFI and the Microsoft boot process, where Microsoft is now able to know that, up to the point that it has received control, only signed and trusted modules, from the first moment power started to flow through the motherboard to now, have been able to operate.  Microsoft's own boot system then pulls in the balance of the pieces of Windows, verifying every piece of them, and also doing antimalware checking against various types of dictionaries that it has available as this progresses.



And the final thing it does is it looks in the Trusted Platform Module for this Measured Boot audit, and it has the ability to send that out of the machine to a remote server where that audit is verified.  It understands that, if something has gone wrong, it can't be trusted to audit itself.  But the TPM is able to produce its own signed audit trail, which cannot be altered.  So that can be sent out to a third party in order to verify the security of the boot.



And so, for example, there's another term, "Trusted Boot," which technically is the combination of a secure boot and an audited boot, which is this Measured Boot technology.  Together, they allow Windows to get itself up and going in a trusted state.  And, for example, it might be, in a large enterprise, that that computer is not allowed onto the network until that measured boot that is the audit has been verified by some other machine on the network, confirmed that this system is up in full trusted mode.  Every piece of it that has run so far is trusted.  There's no malware present.  And then the machine is given permission to get onto the corporate network.



So essentially what we've got is a rather straightforward, although it is really complex, the specification.  I was looking at - it's now at 2.4 Errata Level E, I think.  It is a 3,000-page - it was a 2,998-page specification.  And, I mean, it's just unbelievably complicated.  But it's because you've got this, you know, everybody got their features in.  And the fact is, I mean, UEFI is like a world unto itself.  It is a whole operating system.  There's a command language.  You can issue commands.  You can get consoles.  I mean, it's amazingly sophisticated.  Basically, all we normally see is, you know, we turn the computer on, and up boots our operating system.  All of this stuff goes on hidden in the background.



So understanding what this is, we can imagine what it means if we could not turn it off.  Because if you own a computer, and there is no way to turn this off, to turn off Secure Boot, then you have an appliance.  You can't change the operating system.  You can't mess around with the computer at all.  It is, I mean, you can do things that it allows you to do, but nothing that it doesn't because, from the first moment this thing receives power, everything has to be signed and trusted.



Now, this is why, because this was sort of a controversial move, why the Windows 8 Logo requirements, as I mentioned before, explicitly said that Secure Boot must be enabled when a new machine is shipped.  But it must be possible for the user to manually disable.  I should also mention that there is a post-boot programmatic interface between the operating system and the UEFI.  That is to say, UEFI exposes a large array of services for managing all of these trust databases which Windows, for example, knows how to talk to.  And that's necessary.



For example, when we're updating kernel drivers, they're probably going to all be signed by Microsoft certificate, so they would be trusted anyway.  But you might have, for example, a third-party driver which Microsoft needs to bless and, for example, put its signature into the trusted UEFI database when Microsoft installs that driver into Windows.  Or at least Microsoft wants to verify that this driver that it has installed into itself to be booted will be trusted by UEFI at boot time so that UEFI will allow that driver to load.  So there has to be a post-boot interaction between the operating system and basically the crossing guard, you know, the guard of the bridge which is sitting there deciding who gets to run or not.



So the controversy is that, whereas with Windows 8 Microsoft said systems must be allowed to allow the user to turn that off - and that's the key.  You cannot programmatically turn it off.  There has to be no way for malware to turn it off because that's what "programmatic" means is that malware could flip that switch, then cause the system to get rebooted, and then gain an early foothold.  Basically what we're doing is we're preventing any kind of firmware hack or bootkit or rootkit-style exploit, which has always been the Achilles heel.  We've talked about how the operating system can't be responsible for what happens before it gets in control.  It can do the best job it can to prevent anything bad from happening once it's in control.  But before it's in control it's not there.  So if something is able to modify it before it runs, then it's already corrupted by the time it becomes aware and is able to operate.



So this whole system is about preventing messing with the firmware and messing with the operating system as it loads up to the point where it's then able to do the best job it can of assuming responsibility for anything that happens subsequent to that.  And the unknown is how the systems are going to look, the Windows 10 Logo certified machines, where Microsoft has specifically said OEMs can choose whether to allow users to disable Secure Boot or not.  If that option does not exist in the BIOS, then essentially you've got Microsoft Windows installed...



LEO:  And that's it.



STEVE:  ...and that's it, baby.



LEO:  But I think there's a...



STEVE:  You can upgrade.



LEO:  I think it's nice that you have the choice, so you don't have to buy that.  You should find out if the OEM is doing that.  It is completely appropriate that people should be able to buy a machine that is locked down.  You know, I think about the Chromebook Pixel, which is Google's thing.



STEVE:  Yes.



LEO:  Now, they're not using UEFI.  They're using Coreboot, which is an open source...



STEVE:  Yup, yup.



LEO:  And actually someday I'd love to hear what you think of that compared to UEFI.  But in the Chromebook they have a very, I think a nice solution.  You can disable it.  You have to reboot into developer mode.  It puts a big thing up that says, you know, you're now going to be able to run unsigned software.



STEVE:  Good.



LEO:  But if you want to do that, you know, but if you want to back out, press the spacebar.  So for most unsophisticated users it will always be - and they have a TPM module in there.  It is secure.  It's signed.  They've made it a very, I think, I'm not an expert, and I'd love to get your opinion on that, but a very secure platform.



STEVE:  No, what you described in terms of the user experience I think is exactly right.  I would opt for, I mean, absolutely have this thing be secure.  But something feels, I don't know, a little creepy.



LEO:  You bought the hardware.



STEVE:  Yes.



LEO:  You should be able to modify it.



STEVE:  That's what it is, exactly.  It's like, you know, I can't do anything else with this?  It's like, I mean, it does turn it into a big phone, essentially, that I can't do anything with.  That's like, you know...



LEO:  We see the need for it.  We talk about it every day on the shows.



STEVE:  Yes, yes.  And for a lot of people, for a lot of people, I love the idea that we've got this level of security.  Most people can't even get into the BIOS.  They don't know where it is.  I mean, I have a hard time.  Is it Delete, or is it F2, or like...



LEO:  And they change it, don't they.



STEVE:  It's difficult to get in.  So it's already hard enough.  And if they simply say, "You almost certainly never want to turn this off," I mean, put up a flashing red screen and say, "If you turn this off, we're no longer responsible.  We're going to find out you did, and you no longer get support."  It's like, "You're on your own."  I think that's the way to do it.  But it'll be interesting to see.  Now, I'm wondering politically what's going on.  You think this is OEMs asking Microsoft, please don't require us to allow the end user to disable Secure Boot because some of our customers have on Windows 8, and they've gotten themselves in trouble.  We really don't want to have to do that.  Or is it Microsoft saying, eh, Linux.  Don't think you need Linux.



LEO:  I'm pretty sure it's Microsoft.  I think you nailed it at the beginning where you say Microsoft eases into these things.



STEVE:  Creeps, yes.



LEO:  And they kind of telegraphed this.  And you may remember when Windows 8 came out there were a lot of Linux enthusiasts saying, oh, my god, this is terrible.  They found out you could, yeah, you could disable UEFI.  You can put Linux on these machines.  But that, I believe, was Microsoft announcing to the world, hey, we're going in this direction.  And I don't think it's - I don't disagree with it because - as long as some OEMs offer machines that you could put Linux on.  But the problem is somebody...



STEVE:  Any system...



LEO:  Or anything else.



STEVE:  Any system where you're going to install the operating system.



LEO:  Right.



STEVE:  It's going to be UEFI today, and it'll have that option.



LEO:  Right.  There has to be.



STEVE:  Right.  And if you install Windows 10, I'm sure Windows will say, hey, turn on Secure Boot.  Everything's set.  The databases are established.  All the trust anchors are in place.  Turn on Secure Boot, and you get to have your system locked down.  You don't have to worry about rootkits and bootkits and firmware crud getting in.



LEO:  Well, exactly, exactly.  And as we live in this world of increasing threat, I think the mass of the market is very much interested in that as a solution and is never going to install some other operating system.  They never - they installed Windows in the first place.



STEVE:  Nope, nope.  Just give us a choice for - in those particular situations.



LEO:  But for us - yeah.



STEVE:  Yes.



LEO:  And that's, I have to say, one of the things I really like about the Chromebook Pixel, you can install Linux on it.



STEVE:  Nice.



LEO:  And but you have to go put it in this insecure boot mode.  And they're very clear about what you're doing.  And if you're smart enough to do it, and you know the commands, then do it.



STEVE:  Now, if you...



LEO:  It's funny, I run it - for a while I put crouton on it, and Linux.  And, you know, I don't need that.  It's just messing it up.  I want to know that this is...



STEVE:  Crouton?



LEO:  It's called "crouton" because it's a chroot script.  It turns on a chroot virtual machine.  And then you put Linux in it.  And it's, like, very elegant, actually.  It's a clever hack.  "Elegant" may not be the right word.  It's a clever hack.  But I like the idea that when I'm using the Pixel I know exactly what it does.  It's absolutely secure.  I just don't have to think about it.



STEVE:  It's worth noting also that, even though this would give Richard Stallman a seizure...



LEO:  Oh, he'd hate it in every form.



STEVE:  Oh, my lord.  It is possible to do certificated drivers with Linux.  So it is often possible to still be in a non-Windows OS and use Secure Boot.  You just have to go through the extra effort of getting stuff signed and certificates installed.  But entirely possible.



LEO:  And, by the way, I'm told in the chatroom, and I believe this is true, that Stallman does endorse Chromebook because that is an open source, free SFS program.  What about SpinRite?  The way I use SpinRite right now, I boot to a new operating system.



STEVE:  Correct.



LEO:  FreeDOS.



STEVE:  Correct.



LEO:  What are you going to do about that?



STEVE:  So if it turns out that we end up in a world where we're in Secure Boot, then I'll just do a version of SpinRite as a kernel driver because that's something I've always been thinking about.  And that would allow it to run.  Because I have an Authenticode, you know, all of my software is signed by Microsoft Authenticode.  It's all Gibson Research Corporation, and we're trusted.  And so I'm able to do kernel drivers.  And a kernel driver has all the capability that I would need.  So it may be that that'll end up being another piece of SpinRite that comes along, if it turns out that there are people who need SpinRite to run in a Secure Boot environment.  



LEO:  It does mean that - somebody's saying in the chatroom, and I think this is true, used hardware has reduced value.  You know, remember one of the solutions to running an old XP machine was put Linux on it.  Well, that won't be an option on old Windows 10 machines in many cases.  It makes them more disposable, really.



STEVE:  And relative to SpinRite, remember that the story I just read, Phil Horowitz's friend had a Windows 8 computer that was hanging at startup.  If that was a Windows 8 computer, it probably had Secure Boot.  He turned that off, and then he booted SpinRite, and it worked just fine.



LEO:  I presume the system recovery boots would still work.



STEVE:  Oh, yeah.  In fact, there is some fancy stuff Microsoft does.  I mean, it has all this sort of multilevel fallback stuff where, if it gets to the point that it thinks it's okay, and it looks back at that Measured Boot audit and sees something fishy, it's able to immediately abort its own boot and fall back to recovery mode in order to, like, restore drivers and things. So there's all of this magic scary stuff going on that we hope works right.  Although it seems like sometimes that stuff has a problem, too.



LEO:  It's only a matter of time before somebody figures out something.



STEVE:  Yeah.  So essentially, we've seen the evolution of our hardware platforms, along the same line that we followed Apple with the iPhone, where in order to put up the level of resistance to hacking that we really have to have in this day and age, the system has no choice but to essentially whitelist every component that it's going to load.  And if you're going to whitelist every component, then you're going to be rigid against non-whitelisted components or operating systems.



LEO:  I love this show.  You learn so much from this show.  If you enjoy it, I do hope you will listen each and every week.  Subscribe, that's the best thing to do, and you can do that at TWiT.tv/sn or using your Podcatcher or iTunes or whatever you use to listen.  Almost all of them will have a subscribe option.  You can also listen through our great third-party apps.  We have wonderful developers on iOS, Android, Windows Phone, Roku.  I bet you there's BlackBerry.  There's certainly Windows and Mac that you can always do it that way, too.  But please, make sure you tune in every Wednesday at 1:30 Pacific Daylight Time.  I say that because I think there's still some error in our calendar on the website, and I want you to understand we've moved to Daylight Time.



STEVE:  We've also moved to Tuesday, so...



LEO:  Did I say Wednesday?



STEVE:  Yeah.



LEO:  One of these days.  It's only been six months.  Tuesday, thank you.  And so that is 1:30 Pacific Daylight Time, 4:30 Eastern Daylight Time.  If you're on UTC, that's 2030, or you can make the calculations yourself.  Most other countries are going to summertime soon, I think.  So this won't be as much of an issue.  There's just this little interregnum that is a problem.  You can get - Steve's got 16Kb versions of the audio at his site, as well as full text transcripts that are great.  That's GRC.com.  You'll also find SpinRite there, world's finest hard drive and maintenance utility, plus lots of other freebies.  Steve's giving stuff away all the time.  Did you hear our conversation, was it on TWiT, about Microsoft's new Passport and - hello.



STEVE:  And I appreciated your little mention of SQRL.  You said, well, you know, Steve's got this SQRL thing he's working on, and we'll see.  Yeah, we'll see.



LEO:  Microsoft's supporting FIDO.



STEVE:  Yeah.  We'll see how that goes.  There's a lot of problems with FIDO.  For example, FIDO doesn't have any identity management at all.  That is to say, if your identity escapes from you with FIDO, there's nothing, there's no mechanism in FIDO for remediating it, for recovering it, for pulling it back.  All of that is built into SQRL.  So this is why Brad Hill, who was one of the chief architects of FIDO, said he thought SQRL was the best-thought-out system that he had seen.  So, but again, you're right.  It doesn't have everybody behind it.  But it does have a lot of small guys behind it, a lot of - I'm getting email from people saying we want to support it on our website.  We want to use it here or there.  All the various platforms are going to be supported.  We'll have SQRL clients available.  And we'll just see.  It might very well live side by side.  I would have no problem with that at all.



LEO:  Yeah.



STEVE:  And for one thing, FIDO is all based on hardware.  And, you know, for example, you guys were talking about, and I really liked the idea, that you need this 3D vision in order that a photograph won't fool your face recognition in Windows.  It actually needs to be a 3D representation, taken from multiple angles at the same time, to know that you're not putting a flat picture up in front of it in order to cause someone to be able to log in.  So all of the biometric stuff is part of the FIDO spec.



And one of the advantages is that SQRL doesn't require any hardware.  You're able to have a software-only client, which is absolutely secure.  So it's also free, and you can add it to existing systems.  For example, none of the hardware right now that Windows 10 will run on is currently available.  You don't have 3D cameras unless you add that.  So anyway, we'll see.  I'm going to get it done.  I'll get back to working on SpinRite 6.1.  And we'll give SQRL a good launch and see how it takes off.



LEO:  Find out more about SQRL at his website.  Questions next week, you think?



STEVE:  Yup.  Let's do a Q&A.



LEO:  GRC.com/feedback.  I suspect Steve's going to say this, but you correct me if I'm wrong.  Don't put birthday greetings there.



STEVE:  Yeah, there's no need.  We all know that I'm getting old.



LEO:  I think that you probably would not like hundreds of those.  Is there somewhere?  Should people tweet you if they want to say happy birthday?



STEVE:  Absolutely.  That would be very nice.



LEO:  It's the big six-oh for Steve Gibson, @SGgrc.  GRC.com/feedback if you've got questions for next week.



STEVE:  Yeah, you know, I could see us going to a thousand episodes because, you know, this last 10 years have been - it's been good, Leo.



LEO:  I don't know about 10.  Yeah, I can give you about 10 more, too.  We'll both be almost 70.  It'll be...



STEVE:  I do think that Pournelle is probably on his last legs.  He was...



LEO:  He's in his 80s, late 80s, yeah.



STEVE:  Is he really?



LEO:  Well, I don't know exactly how old he is, but...



STEVE:  He's got so much wisdom.  I love Jerry's wisdom.



LEO:  Love Jerry.



STEVE:  But, boy, he's been battling.



LEO:  Poor guy.



STEVE:  Yeah.



LEO:  But you know what, he's doing fine.  He got back from the stroke.  He was on TWiT a couple weeks ago and was fabulous.



STEVE:  Yeah, yeah.



LEO:  The mind continues.  It's the body that falters.



STEVE:  Right.



LEO:  If you're lucky.  Or [indiscernible], I don't know.  GRC.com.  Thank you, Steve.  We'll see you next week, right here on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#501

DATE:		March 31, 2015

TITLE:		Listener Feedback #209

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-501.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  I'm here.  We're going to talk about the latest security news.  Yes, another survey of bad passwords coming up.  And then 10 great questions from you, our audience members.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 501, recorded Tuesday, March 31st, 2015:  Your questions, Steve's answers, #209.



It's time for Security Now!, the show where we protect you and your loved ones online, your privacy, your security, with this guy right here, the Explainer in Chief, Steven "Tiberius" Gibson.  And he is here once again to both put us all on edge, and then make to us feel better about...



STEVE GIBSON:  Starting into our second set of 500 podcasts.



LEO:  501.



STEVE:  The first set of 500 is done.  I should mention to people who are wondering where 500 is, I just realized, when someone sent me a tweet saying, "Hey, Steve, when are you going to put up 500," that I never got the transcripts from Elaine.  In 500 episodes, this has never happened.  She is sort of in a perilous strange world where there's like snow on cactuses.  I've seen photos from her porch.  And I don't know where, but, I mean, there's, like, huge windstorms.  There's electricity going out.  I make the small bandwidth audio because she had been bandwidth constrained, but I think her satellite provider fixed that - I'm looking up at the sky because that's where the satellites are - fixed that a while back.  Yeah.



LEO:  They're up there somewhere.



STEVE:  Anyway, I mean, but there's a lot going on in her world.  She's also got all kinds of animals all over.  There's a menagerie, and they're getting sick and having to go to the vet, and things are happening.  So I sort of, I get a little sort of side channel of this through the last 10 years that we've worked together.  But never has she gone radio silent.



So what I'll do is, after the podcast - and so the reason I didn't post 500 is I'm sort of a - I have a system.  And when the transcripts arrive from Elaine, that's my trigger to assemble everything, convert to PDF, convert to HTML, get everything up and posted.  Anyway, I will put everything up minus the transcript for 500, and we'll hope that she's okay and that I hear from her.  We will be transcriptless for a while one way or the other, but I will alter my routine so that I can operate without the transcript trigger to cause me to post this.



LEO:  How do you do that?  Do you do a little cron job or a watch folder or...



STEVE:  You know, I often say that investments in infrastructure come back to reward you over and over and over.  And I have something - if I can do it here.  I'm going to type - I'm going to move the microphone down so you can hear it, and I'm going to type "get 500."



LEO:  Oh, you mean you can actually publish it in real time.  He's going to - okay, there's Steve is now typing "get 500."



STEVE:  I guess you couldn't hear it.  It said "Auto-initiating media workstation monitor."



LEO:  Auto-initiating media workstation monitor.



STEVE:  Anyway, so that's a system that I wrote that periodically checks for the appearance of the audio from you guys.  And so that alerts me to when the audio appears.  But here's what is just so dumb.  And this is a little bit like the cobbler's kids going without shoes.  Everybody else in town has shoes, but not the guy that makes the shoes.  I have manually done this 500 times.



LEO:  Wow.



STEVE:  Manually ran a - I have a Perl script that converts the text file from Elaine to a CSS-laden HTML document.  Then I bring that up in IE because its PDF printing is better than the other browsers, print that to a PDF, then collect all of those and blah blah blah blah blah.  Anyway, all manual, and so stupid.  I mean, again, if I had invested in a little infrastructure - I just didn't think this was going to go for 10 years.  Like I said, oh, you know, maybe, you know...



LEO:  A few, five, whatever.



STEVE:  Maybe Leo will get tired of The Cottage and, you know.  Or it'll be a heat wave, and we'll just shut down and never start up again.  I just didn't know.  Had I known, I would have done things differently.  And here I am, manually doing this.  And at this point I'm so busy I don't want to take out any time to do it, so I'll just keep posting it manually so that I can get SQRL done and then SpinRite 6.1.  I have a whole big growing list of things I promised myself I would do once SpinRite 6.1 is published.



LEO:  Wow.  Good for you.



STEVE:  We'll hope that happens.



LEO:  That's awesome.



STEVE:  So this is a Q&A.  Last day of the month.  Tomorrow is April Fools.  And it's a good thing the podcast did not fall on April Fools.



LEO:  Thank god.  I hate April Fools.  I hate it.



STEVE:  I do, too.  I do, too, because you have to, like, look askance at everything that you see.



LEO:  Yeah, can't trust anything.



STEVE:  Wonder, like, okay, wait a minute, you know.  And invariably every major site will do some April 1st goofy thing.



LEO:  Not me.  Not me.



STEVE:  And we have eschewed that in the past, eschewed or something like that, and we will in the future.  So anyway, Q&A #209 for the beginning of our second set of 500 episodes.  Now it's clear to me this is never-ending, so I...



LEO:  Do a little infrastructure, will you?



STEVE:  Do a little infrastructure building.



LEO:  When you say infrastructure, it's really writing software or writing a script; right?  It's not - you're not laying concrete.



STEVE:  It's like, I can look up right now and see total SpinRite sales for the day so far, total from yesterday, total week to this time, total for last week, month to this time, total for last month and so on.  I've got bar graphs.  I've got bandwidth stuff.  I've got all kinds of metrics going on so I can see exactly what's happening.  And so these things I built.  And oh, well, you know, now "Yabba dabba do" comes out of my phone when I'm like in a restaurant.  And only my brother-in-law thinks it's annoying.  Like when I was up for Mom's birthday, he picked Jenny and me up at the airport.  And a "Yabba dabba do" came out of my pocket, and he says, "That's annoying."  It's like, okay.  So I silenced the phone for my visit.  But anyway, so, yeah, that kind of infrastructure stuff is fun.



LEO:  Cool.



STEVE:  That kind of stuff, yeah.  It's very much like your timer.  That's something you invested in, and now it's just going to give back, you know, as you said, wasn't that big a deal.  But what a convenience to have that.  So what I've seen is those kinds of investments just pay off so well.  Or like the little buzzer I have that lets me know when UPS is walking to the front door.  Just, you know, so that the package doesn't get stale.



Anyway, not much happened, although some interesting things.  We've got to talk about the GitHub and GreatFire.org DDoS attack because the mechanism of this is really interesting.  There was a very disturbing vulnerability discovered in routers that are often used in hotels, convention centers, visitor centers and so forth.  A really fun analysis of 10 million passwords.  You're going to want to find the link low down in the show notes, Leo, and get that PDF, or get that page ready because...



LEO:  All right.



STEVE:  Just tons of interesting stuff there.  And this being a Q&A, we've got 10 great questions, comments, and thoughts.  And I was a little bit light on the front end because there's some deep stuff we're going to be doing in the Q&A, some questions that deserve some good attention.  So I think we have, for 501, a great podcast.



So the picture of, well, we'll skip the picture of the day.  The first page of the show notes I always put something up if I can.



LEO:  I love this one.



STEVE:  It's sort of a fun - yes.



LEO:  You sure you want to skip it?



STEVE:  Well, we'll be coming back to it.



LEO:  Oh, okay.



STEVE:  And we'll just note that "monkey" is now number 15.



LEO:  Moving down.



STEVE:  Yeah, it is, you're right.  I think it was 10 for a while; wasn't it?



LEO:  Yeah, "monkey" should be higher.



STEVE:  Yeah, "dragon" has now taken monkey's place at number 10.



LEO:  Oh, okay.  We're not talking the Chinese zodiac here, folks.



STEVE:  Yeah.  And there are some that we cannot pronounce on a family-oriented show.  But anyway.  Okay.  So there's been something going on for about a week.  Apparently the first site to come under problems was GreatFire.org.  And we've not talked about them before.  But as I understand it, their mission is to make available Internet content which is otherwise blocked by China's censoring Great Wall Firewall.



LEO:  I think we have talked about them.



STEVE:  Well, but maybe not in any more depth than just that.



LEO:  No, because they were the ones who - what did they do?  They identified something - oh, I'll have to go back in time.  But, no, I'm pretty sure we have talked about them.



STEVE:  Okay.



LEO:  Anyway, they're not merely a place to echo this stuff.  They are monitoring what China is doing with this Great Firewall.



STEVE:  Ah, okay.  So they're using Amazon's cloud content delivery network in order to host the content that they are mirroring and making available.  And since many of China's own businesses also use the same CDN, it turns out that it's extremely difficult, and so far has actually been impossible, for the China censors to block these guys, the GreatFire.org people, because they're using a common CDN to many huge Chinese properties.



So then on March 26th - and so this GreatFire.org had been having problems with attacks like for a week or two before this hit GitHub.  And when it hit GitHub, it sort of came of course to the tech community's awareness because GitHub is a resource that is beloved by many of us.  There's, for example, I don't know how many SQRL projects are currently hosted on GitHub.  But, like, 40 or something, I mean, it's amazing.  You go to GitHub and put "SQRL" in, and although some were quickly created and have been abandoned, many are underway because I'm talking with their authors on a daily basis at this point.



Anyway, so the following message was posted on the 27th, which was last Friday.  GitHub posted:  "We are currently experiencing the largest DDoS (distributed denial of service) attack in GitHub.com's history.  The attack began around 2:00 a.m. UTC on Thursday, March 26, and involves a wide combination of attack vectors.  These include every vector we've seen in previous attacks, as well as some sophisticated new techniques that use the web browsers of unsuspecting, uninvolved people to flood GitHub.com with high levels of traffic.  Based on reports we've received, we believe the intent of this attack is to convince us to remove a specific class of content."



And as we'll see in a minute, GitHub hosts some tools which are used for circumventing Chinese censorship.  And so they are, based on the attacks they were seeing, it looked like they were under attack because they were hosting those tools.  So how this attack works:  Millions of global Internet users, so this is not just Chinese users, although China is where the problem is injected.  Anybody anywhere in the world visits thousands of different websites, hosted also anywhere in the world, whether inside or outside of China, will randomly receive malicious JavaScript which is used to launch an attack against GreatFire.org's websites and, more recently, GitHub, which is hosted - and this is content hosted by Amazon cloud services.



It turns out that, much in the same way that people - like many, many, many websites use Google Analytics.  When you use Google Analytics, you embed an invocation of some of Google's JavaScript into your website so that the pages you display invoke that script.  That creates a fetch from your browser to Google Analytics and allows them to see who you are, thanks to cookies, and where you are, and basically supply analytical information back to the webmaster, the owner of that website, using very nice Google-based UI.



Well, it turns out that the Chinese site Baidu, B-A-I-D-U, has the same thing.  There is Baidu Analytics code which is just h.js.  They want to keep it small.  And so what happens is, when sites anywhere in the world are hosting Baidu's Analytics code, much for the same sort of purpose that other sites might use Google, that means that the people visiting those sites, who are also located anywhere in the world, will cause their browser to fetch Baidu's h.js JavaScript.  Somewhere inside China, before the traffic gets to the Baidu servers, some entity, and it's now believed to be Chinese authorities, are intercepting the incoming query for the h.js file and replacing it with attack JavaScript.



So the users, users all over the world, their browsers retrieve this maliciously intercepted and replaced Baidu Analytics JavaScript with code which has been analyzed, I've got links in the show notes to the deminifying and analysis of this script, which uses the web browsers to then pull web content from two different URLs, GitHub.com/greatfire and GitHub.com/cn-nytimes, which is a Chinese language version of The New York Times, which the Chinese government objects to people having access to.  They block it and don't allow people to have access to it.



So what has been seen was a phenomenal amount of web traffic.  And the problem with this sort of attack is that it is not a protocol, like a lower-level protocol-style attack like a TCP flood, where you can say, oh, okay, like a TCP SYN flood.  This is a higher level HTTP protocol attack, meaning that valid queries, there's nothing invalid about them except the number of them, valid queries are being made over HTTP to those pages at a level that essentially creates a denial of service, completely floods the servers.  They have been, while this attack has been going on, they've been seeing 2.6 billion requests per hour, which is an increase of 2,500 times over the normal level of traffic that they see.



LEO:  It has to be an amplification attack; right?



STEVE:  Well, yeah.  I mean, the problem is, once this script starts running, it itself, the one instance of this malicious script starts making queries over and over and over and over.



LEO:  Of course.  It's amplifying itself.  Right.



STEVE:  Right.  So people all over the world...



LEO:  Oh, gosh.



STEVE:  ...are using, are going to sites all over the world that are getting this malicious script into their browsers all over the world that are then just firing off queries, bang bang bang bang bang bang bang bang bang, using JavaScript to pull the content of these pages, thus creating a devastating and very hard to block, I mean, basically you have to do upstream protocol-level blocking.  It requires some sophisticated filtering.  And the problem is this is expensive.  That is, even though these requests are coming in very fast, because the content is being served by Amazon, Amazon's CDN is designed to handle serious traffic.  Consequently, this is costing GreatFire.org $30,000 per day in Amazon billing because Amazon is a pay-go, you know, you pay as you use it.  And suddenly their apparent usage has spiked.



Now, one question is whether Amazon will get onboard and not actually charge for the bandwidth which is being consumed.  GreatFire doesn't know yet whether they're going to do that or not.  But apparently they have asked Amazon if they would consider forgoing this because this is not legitimate bandwidth, this is clearly an attack against these guys.



LEO:  Wow.



STEVE:  But anyway, I just thought this was interesting.  It's an interesting hack which is difficult to fix because Baidu is saying we're not doing anything wrong.  We're not seeing anybody asking for our analytics services any longer.  No, because that's being intercepted, and those queries are returning malicious code from someone, some intermediary.  And it has to be Chinese authorities because you've got to be able to intercept major pipeline traffic inside of China, and at the protocol level.  I mean, again, because this is not down at packets, this is protocol.  That's a much more difficult hack to pull off.



So anyway, I thought the mechanism was interesting because basically it turns innocent - thousands of innocent users browsing the web are now having their web browsers running malicious JavaScript, that they innocently got, which is pounding on two sites that those browser users would probably wish not to be doing, if they had a choice.



LEO:  Yeah, amazing.



STEVE:  Yeah.  Now, one thing could happen.  This is the sort of thing where, for example, Google could respond by pushing out an update to Chrome that is aware of this behavior and won't execute that JavaScript or, for example, will detect that redundant queries are being made in fast order to GitHub properties and do a rate-limiting on something.  I mean, it's the kind of thing that the browser could do.  Otherwise it's going to require some sort of filter to be put in somewhere.  Wow.  Really interesting.  And it's another consequence of the fact that our browsers are running executable code that they receive from any website they visit, which is a mixed blessing.  We love the convenience of that.  But as all of these conveniences that we enjoy, they can be turned to a dark purpose, as well.



A security site, Cylance, discovered something very disturbing, which is that a very popular router, manufactured by a company called ANTlabs in Singapore.  The router family is called InnGate, I-N-N Gate, as in an inn, a hotel.  And for whatever reason, these are extremely popular routers used by hotels, convention centers, visitor bureaus and such, to manage traffic and allow people to get online.  I mean, there are thousands of them in the world.  What the Cylance folks discovered is one of the most basic sorts of flaws you can have, which is an open rsync daemon running on TCP port 873 on all of those routers.  Excuse me.



LEO:  Rsync is used by UNIX heads to do backups.



STEVE:  Yes.



LEO:  I use it.  It's great.



STEVE:  Yes.  And in this case it's a little too great because it turns out that the instance of rsync included with the InnGate firmware is incorrectly configured to allow the entire file system to be read and written without authentication.



LEO:  Oh, that's not so good.



STEVE:  So a remote unauthenticated attacker can read or modify any file on the router's file system.



LEO:  Wow.



STEVE:  So this is TCP port 873 running rsync.  You can, if you were to scan the 'Net and find listening ports 873, you then go to your Linux box, and you type rsync, space, and the IP address, you get a listing of the root of that router's file system.



LEO:  Wow.



STEVE:  I mean, it's just like that.  So there have been some interesting reports of attacks on hotels where - I remember there was - some Asian high-end hotels were having their visitors compromised after visiting.  And it turns out that - so all kinds of things can be done with this.  In a quick scan of the Internet, the Cylance folks found 277 immediately accessible devices in 29 countries.  On their page a ways down, on their blog page talking about this, there's a map of the world, and it looks like most of them are in the U.S.  A hundred of them were quickly found throughout the United States.



So one of the problems - yup, there's the map.  One of the problems is that the severity of the issue is escalated by how little sophistication is required for an attacker to exploit it.  I just explained in a sentence how anybody can do this.  I mean, that's how bad it is.  And, I mean, I'm not giving anything away because this is all over the security community, and people are scrambling now to deal with this.  But an attacker exploiting a vulnerability would have access to launch attacks against guests on the affected hotels' WiFi.  Targets could be infected with malware using any method, from modifying files being downloaded by the victim or by directly launching attacks against their now-accessible systems.  Given the level of access this vulnerability offers to attackers, there's no limit, apparently, to what they can do.



And, for example, if an attacker had compromised an InnGate device at a hotel with the vulnerability, they could obtain shell access via SSH, which is running, by the way, in those routers, in order to get root access, and then run tcpdump, which is also present on these devices, to dump all the network traffic going through the router.  Any unencrypted traffic, anyone who is, for example, seeing session cookies that are not being maintained over a secure connection, but as used to be the case, remember like with Firesheep, where you negotiate your logon credentials securely, but then the site drops you back.  High-profile sites are no longer doing that.  You know, Facebook and Google and most others are now HTTPS all the time.



But any other site that is not keeping you secured throughout your entire session means that your session cookies, your logon authentication, is freely sniffable by this kind of an attacker.  So, again, we're well past the time where any site that uses persistent logon can ever allow nonsecure, nonprotected session cookies to happen.  And unfortunately, hundreds of thousands of sites still do that.  Those that haven't deliberately switched over are still vulnerable to that kind of attack.  Or, for example, a tool like SSLstrip, which removes the S's from the HTTPSes in order to prevent HTTPS from ever having a chance to get started, could strip out even a site's best effort in order to protect users.



So anyway, this is a bit of a sobering vulnerability, and it's one more reason for our listeners to remember that any places like open WiFi or hotel WiFi, or even hotel wired networking, if anyone still uses wires in a hotel, these are just really unsafe places not to really be secure.  The solution is to always use a VPN in those circumstances.  Use a VPN.  Even though we know that your traffic will be coming out of the VPN server at some single location, you just want to wrap a secure tunnel around your local traffic until it gets out, like out into the wider Internet, and away from this last-mile region where there are just so many potential vulnerabilities like this.



There is a site, WP Engine, which is a major WordPress hosting site that did a beautiful, I mean, just a really fun analysis of two different password databases.  They pulled them together and did a very nice analysis, one of the nicest that I've seen in a while, that I thought it would just be fun to talk about for a second.  For example, because of the depth of information they had about the account holders, they've been able to give us some demographics that we haven't seen before.  For example, they did a chart of the birth decades from, okay, of the 10 million total accountholders whose passwords they have, 220 of those accounts included date of births.  So they were able to show a chart.  And the highest incidence of date of births of people in this 220,000 subset nearly looks like maybe 95% - wait, this doesn't sum to a hundred.



LEO:  That's not percent.  It's 95,000.



STEVE:  Oh, it's in thousands, it's in thousands, okay, right, 95,000.  So but it is...



LEO:  Percent would have been more useful because this is just raw numbers.  I mean, there are probably more users from that cohort.



STEVE:  We do know that it's of 220,000, so 95,000 of 220,000.  So what's that?  That's less than 50%, but not way less.  Anyway, for example, the born in the 1980s is more than twice as many as the next greatest, which is born in the 1990s, which is about half that amount, and a little bit less than that was 1970s.  And then it rapidly falls off.  So sort of interesting demographic.  Also, where they had gender information, it was almost exactly two-thirds male, one-third female.  That is, 485,000 credentials that had gender information, two-thirds male, one-third female.



And then we have, of course, the ever-popular list of the 50 most-used passwords.  Still solidly in first place is our all-time favorite, "123456."  And the runner-up for first place, of course, is just "password."  And it's amazing that sites still allow you to enter that as a password, or even 123456.  It just, you know, these must be old sites because I don't think you could do that today.



LEO:  No.



STEVE:  In most sites.  They just won't let you get away with that.  Third most popular, add a "78" to the end of "123456."  Then of course "qwerty" is there.  Anyway, the link is in the show notes for anyone who's interested, or it's just WPEngine.com/unmasked.  So if our real-time listeners are curious, or somebody listening to the podcast near a web browser, WPEngine.com/unmasked - U-N-M-A-S-K-E-D.  As we were noting earlier, "monkey" has fallen down to the 15th place.  Actually just looks like it's been pushed down by a lot of simple numeric passcodes, or passwords, which is disturbing.  "Letmein" is still there in number 16.  For some bizarre reason, "michael" is number 20.  "Mustang" is 21.  And it sort of goes on there.  So the top 50 are those we've seen before.



I got a kick out of the next thing, which was they looked at when a site tells you that you must have a number, you know, a digit in your password, a password cannot be all alphabetic, you must have a digit.  Well, what do people do?  There's one of these heat maps showing where the area is the number of times it occurred relative to the others.  And almost a quarter, just about a quarter of them is just the digit "1."  So if a site says, oh, no, you can't just use that, you've got to have a digit, so someone says, okay, fine.  Oh, actually there is a percentage.  It's 23.84% simply put, literally, the digit "1" after it.  Now, there's a slightly more creative group, 6.72%, instead use the digit "2."  We drop to about half that, to 3.86%, who just jump right to the digit "3."  They don't mess around with "1" and "2" first.  And so on.



But again, it's some interesting demographic breakdown.  And it actually sort of goes almost numerically, "123," then "12," then "7," then "5," then "4," then "6," then "9," then "8."  But basically, if people are told they have to have a digit, they just tack one on the end, and almost a quarter of the time it's just the digit number "1" to satisfy the requirements.



And then the last thing, scrolling way down, Leo, the keyboard patterns.  This is the other analysis that I thought was really interesting, that I hadn't seen before, which is they looked at passwords and mapped them to where the keys were on the keyboard.  And so this page shows the 20 most common keyboard patterns occurring within those 10 million passwords.  And as we already said, of course, there's "qwerty," which is just the first six keys in lowercase across the top row from left to right of the keyboard.  And then the second most common is you keep going a little bit further.  Maybe you think, okay, well, eight letters.  Or six is not enough; I'll go for 10.  So then they keep going to "uiop," which actually is all of the top alphabetic characters on the keyboard.



Then some people get a little more clever.  The third most common is "1qaz," so that's coming down the leftmost diagonal from "1" down to "z," so the upper left to the lower left.  Then, since they haven't really gotten critical mass yet, they go back up and do "2" and come down the same, you know, the adjacent diagonal to "x."  So that's the third most common.  And then the fourth is they don't go up into the numerics at all.  They probably will after they get spanked for not doing that.  But those guys just go diagonal staying in the alphabetic.  Anyway, it turns out that there are many of the passwords that have been found that look a little bit gibberish-y, also look sort of suspiciously familiar.  And it's because in fact they are just derived from some sort of a linear sequence of key tops on the keyboard.



LEO:  I'm trying to figure out this number 20, which, by the way, he actually poses as a puzzle.



STEVE:  That's interesting.



LEO:  I haven't read the answer.



STEVE:  You're right, that's completely...



LEO:  "Adjmptw."  It is alpha, I know it's alphabetical order.  And it is from left to right, "adgjmptw."  



STEVE:  I don't see a pattern.



LEO:  Yes.



STEVE:  A-D-G skips every other.  But then J doesn't, otherwise it would be K.  You're right, Leo, that's - okay.  And apparently that's happened many times.  That's the 20th most frequent occurrence.  Oh, there's an unimaginative one, "mnbvcx."  So that's the lower row of alphabetic right to left.  Boy, we really need to get away from passwords.



LEO:  We need to get away from keyboards.



STEVE:  We really need.  And then we've also got - they analyzed on iPhones with the keypad the 20 most used, what they called "key walk."  Or am I confusing that with what's above?  No, because that's keyboard, and they are definitely showing it on the iPhone, although they're not showing, they're not breaking it down in the same fashion.  But so the idea is that people are doing a simple series of 10 keypad entries and creating passwords that way also.



And then what is this, the 10 most common word selections in 10 million passwords.  So again - oh, they broke it down by category:  fruits, animals, anything begins with...



LEO:  Colors, noun, verb.  Ilove..., my..., days of the week.



STEVE:  Yeah.



LEO:  Number one name in passwords, John.  Number two, David.



STEVE:  Number one superhero, of course, Batman.  Number two, Superman.  Then Ironman.  Who's Hawkeye?  Hawkeye Pierce?



LEO:  No, come on, don't you know your superheroes?



STEVE:  I don't know my superheroes.



LEO:  Yeah, yeah.  Well, Hawkeye's a superhero.



STEVE:  I would have thought Spiderman would be higher up there.  Who's Gambit?  Is Gambit a superhero?



LEO:  You're asking the wrong guy.  I'm not...



STEVE:  Thor I know.  Wolverine I know.  Punisher and Cyclops.



LEO:  Yeah, yeah.



STEVE:  Okay.  Anyway, I just thought that was fun.  And, you know, nothing very surprising.  As I said, we've got to get away from those passwords.



Okay, now, Leo, this is completely random, but it's time for Miscellany.  I picked up this on the news.  There was some conversation about it this morning when I was making coffee.  And this is the Active SETI project.  Up to now SETI, the Search for Extraterrestrial Intelligence, has been passive, meaning we've been using big ears, looking, scanning the skies, using supercomputers, famously using distributed, like there's a SETI screensaver where your system's unused cycles can go to perform signal analysis, trying, basically filtering the random noise, looking for any kind of coherent information.  Now they're starting to talk about transmitting.  And I'm not sure how I feel about that.  What do you think about that?



LEO:  Why wouldn't - what, are you afraid that they're going to attract attention?



STEVE:  Yes.  I don't think...



LEO:  Oh, come on, Steve.  What?  Why would you let anybody - no, you've read too much science fiction.



STEVE:  I guess maybe.  But Gibraltar Earth was a scary series.



LEO:  I know, I know.  Okay.  Let me explain this whole thing to you.  It's very simple.  We're too far away.  We're all too far away from one another.



STEVE:  Yeah, we really are way on the wrong side of the tracks.



LEO:  Everybody is.



STEVE:  We're out on an unsociable galactic arm, yeah.



LEO:  Until some race discovers faster-than-light travel, we're stuck here.  Wormholes, schmermholes.  We're stuck here.  They're stuck there.  Let's hope it stays that way.  But they could still radio us.



STEVE:  Yeah.  So if you're saying that, then I don't think I want to wave a red flag, you know, they're...



LEO:  They can't get here.  And by the way, the big issue is the speed of light.  Those signals we're sending out?



STEVE:  Oh, no, no, no.



LEO:  They may respond thousands of years from now.



STEVE:  Oh, no, this lightspeed limit, that's not a problem.



LEO:  We're only going to reach nearby stars with the signals.



STEVE:  Well, we, but not they.



LEO:  Oh, you think they've come up with FTL or wormholes or something.



STEVE:  Well, everybody else, everybody else has it except us, Leo.



LEO:  No one has it.



STEVE:  We still have fur on our bodies.



LEO:  It turns out you can't do it.



STEVE:  Yeah.



LEO:  Maybe Einstein was right.



STEVE:  If it can't be done, then I consider that a blessing because I think we need some separation here.



LEO:  Well.



STEVE:  That just, you know, look at this dumb little planet of our own and what a problem we're having dealing with our own race among ourselves.  I just, you know, I don't think I want to light off a big flare and say, "Hey, we're over here."  I think we'd just better...



LEO:  You're familiar with Fermi's Paradox; right?



STEVE:  Yes.



LEO:  Well, the paradox is, if you make completely normal kind of assumptions, that we are on a typical star, there are billions of stars in this galaxy that are billions of years older, with a very high probability, in fact we know this to be fact now, many of those stars have Earth-like planets.



STEVE:  Yup.



LEO:  The issue is interstellar travel because he asks, why is it, given all of that, we haven't been contacted?  Well, I'll tell you why.



STEVE:  Right.



LEO:  We're too far away from each other.



STEVE:  Right.



LEO:  That's my opinion.



STEVE:  Which I think is a blessing.



LEO:  It's not a bad thing.



STEVE:  I don't think it's a bad thing.



LEO:  No, no.  In fact, that's a science fiction meme, practically, of the alien race come to chew us up and spit us out.



STEVE:  Yeah, yeah.



LEO:  It's a cookbook.  Are you ready for questions?  Is that it on that list?  You've got one more, one more.



STEVE:  I have one question in the spirit of the Q&A from a Filipe - you think it's Filipe or Filipe?  He is listening, so...



LEO:  I'd say Filipe, but maybe Filipe.



STEVE:  So Felipe, he sent a tweet saying, hey - because he saw the show notes and saw that I had picked up on his question that he had sent in the mailbag.  He had a question about SpinRite, running SpinRite on brand new drives.  And we've talked about it a few times before.  But he said, "Hello, Steve.  Thanks for Security Now!.  Here's a quick question.  Do you recommend running SpinRite on brand new HDD or SSD drives?  What level would be adequate to find a possible problem with new drives?  Cheers."



And I'll reiterate that I, well, first of all, I and Greg and everybody who knows runs SpinRite on brand new drives.  It's just part of what you do.  Back in the early days of SpinRite, Compaq Computer Corporation over-purchased drives and ran SpinRite on them all and returned those that appeared to be the weakest.  The drive manufacturers didn't like that behavior, but they weren't going to argue with Compaq because Compaq was such a huge OEM purchaser.  So Compaq was using SpinRite to prequalify the drives on the dock before they even accepted them.  And of course we all remember those days where drives had a list of defects marked on the label, but the OEMs that were using those drives never bothered logging those defects into the drive.



My point is that today the world is very different, but no drive manufacturer does anything like running SpinRite on their drives because they can't afford the time.  It takes, I mean, they're mass-producing drives.  What they rely on is the technology that they have built in, the huge amount of error correction, and the ability to spare out sectors.  Now, they do sort of a pre-assembly analysis and look for defects on the surface.  So there are already sectors that have been taken out of service.  But they don't have time to run the entire drive again once it's been assembled.



So the experience of myself and Greg, who of course is a SpinRite user himself, and hundreds, thousands of SpinRite users, is have a new drive, just give it to a machine and let SpinRite loose on it.  Just Level 2 is fine.  Just do a read pass over the drive with SpinRite looking very carefully so that the drive is able to, once it's been assembled, this will be the first time the drive has actually read its own sectors because that doesn't happen in the factory.  And SpinRite will have an opportunity to work with the drive and take any sectors out of service before you start putting data on it.



So, yeah, I do think it makes sense.  And the same thing is true for SSDs.  As we have seen, they're a little more like hard drives than we expected because they're cramming so much density in.  Oh, and I just saw an announcement, too, it was a little scary.  Some manufacturer has decided to increase the number of levels stored on an MLC drive, a multi-level cell drive.  Normally, on what used to be called an SLC, a single-level cell, you would either store a high charge or a low charge, that is, one bit of data, only two voltages.  But in order to double the density, in order to get twice as much data in the same space, the somewhat lesser reliable drives, our so-called MLC, they store four voltage levels - zero and a quarter and a half and, well, I'm sorry, between zero and a quarter, between a quarter and a half, between a half and three quarters, and between three quarters and full.  So four different ranges.  And that gives them two bits of data stored in a single cell.



So it's a clever hack that doubles the density.  But as you can see, you have to be able then to discriminate the voltage in a cell much more exactly than if you only have to tell between empty and full.  Now you've got half, you know, partially empty and partially full that you need to be able to determine.  Well, some manufacturers decided they're going to go to three bits, which is way aggressive because now we're talking eight different voltages in a cell.  So we'll see how that turns out.  It looks like SpinRite's going to be busy with SSDs for a long time to come.



LEO:  And thanks to the Urban Dictionary we have solved the riddle, "adgjmptw."



STEVE:  Uh-oh.



LEO:  There was a little bit of a hint in that it's in alphabetical order.  It's the letters you get when you press "1" through "9" on your keypad or cell phone.



STEVE:  Oh, that's what that was.  And that's why they showed the cell phone down below.



LEO:  Cell phone, yeah.



STEVE:  Yes.



LEO:  Clever, hey?



STEVE:  Interesting.  But don't anybody use it because it's now in all of the cracking dictionaries.  Everything...



LEO:  Apparently...



STEVE:  Go ahead.



LEO:  The reason it's in the Urban Dictionary, it is also used as a term of frustration when your texting conversation has come to a bitter end.



STEVE:  Who does that happen to?



LEO:  You mash, you go [frustrated noises].



STEVE:  Wow.  Okay.



LEO:  Let us give you some questions, my friend.



STEVE:  Great. 



LEO:  I think you feel brilliant, smart, ready to answer these.



STEVE:  Energized.



LEO:  Energized.  And, after all, since you picked them, I presume you know the answers to them.  Starting with Question #1 from Joe Pracht, and that's how he says you pronounce it, in North and South Carolina.  That's a little bit of a mystery, but we'll just leave that to you, Joe.  He writes, and this is a long one, he's recovered CryptoWall files without paying any ransom:  Steve, I am a network and systems administrator for a large nonprofit covering North and South Carolina.  Ah, you have given us the answer.  We have had two XP computers infected by CryptoWall.  We have a Group Policy block in place for CryptoLocker and are working to remove all XP machines from the network.  However, in both cases we had the users disconnect the computers and ship them over to us.  During Episode 496, Listener Feedback #207, Joe Meedy wrote you with a question about CryptoWall and made the statement, "I've read that CryptoWall makes a copy of your data file.  It encrypts it, then deletes the original file."  So, smart man, Joe Pracht.



STEVE:  Uh-huh.



LEO:  He thought about this.  He said:  I created a full image of the infected drive - that's always the first thing to do, just image that sucker off - and then used R-Studio to attempt the recovery of deleted files.  I'm not promoting R-Studio over other products, he writes.  This just happened to be one our department had a license to.  The recovery brought back deleted files of all types.  I contacted the user of the initially infected laptop to discuss some of the files we found.  I mentioned a picture of kids at a Japanese steak house, and the user was ecstatic.  Not all files were recovered, but we recovered enough to make the user very happy.  Thank you and Leo for the last 10 years.  I'm a longtime listener and can't wait for the new show every week.  Joe Pracht.  Wow, that's a great story.



STEVE:  Well, yeah.  I thought this was important to share because this demonstrates that, clever as these CryptoWall/CryptoLocker crypto bad guys are, they're making a fundamental mistake, and that is they're not overwriting the unencrypted files.



LEO:  Shhh.  Ixnay on the overwrite-ay.  You're worried about connecting with aliens.  You're giving away the store here.



STEVE:  Well, unfortunately it's out of the barn anyway.  And the bad news is, or the good news is, until they fix this, this is a hot tip for recovering some of your files if you don't want to pay the ransom.  The problem is it won't recover them all because new files are being created, which is the bane of deleted file recovery.  We all know from the old days of the DOS E5 flag in the directory that, when you delete a file, all that really happens is that it's removed from the directory, and its clusters are returned to the file system.



But DOS has always allocated in a sequential manner.  That is, it sort of, in order to reduce fragmentation, it allocates in a forward moving through the drive cluster sequence so that it tends not to immediately overwrite recently deleted content, or actually recently created content.  It's creating it in an ongoing fashion.  So you have vulnerable unused space which anything could say, oh, look, this is free.  Let's take it and write data in it.



But still, what this says is that these guys have missed a trick, the bad guys have.  If they were doing it right - and, well, for example, throughout my SQRL code I never release a buffer that contained anything sensitive without wiping it first.  So I wipe the buffer, then I release it so that, if it goes anywhere - so the memory I'm no longer possessing that anybody else could get has nothing sensitive in it.  And so the mistake these guys have made is in not scrubbing the contents of the file prior to deleting it.



Now, I don't think it probably really matters because most people are going to see the CryptoWall/CryptoLocker ransom note, and it's kind of all or nothing.  They're going to see that the files they can see that they care about are all scrambled.  They're going to probably pay ransom.  However, for our listeners, it's worth noting, and this is why I really thank Joe for posting this, that for now, at least, the files that are unencrypted are just deleted.  And if you use some good undelete software, there's a good chance you can get a chunk of them back, at least.



LEO:  Hmm.  But that's only CryptoWall, not CryptoLocker.



STEVE:  Well, we don't know about CryptoLocker.  He did use both terms in his note.  He said "recovered CryptoWall files."  And then he does say "Group Policy blocks in place for CryptoLocker."  And he also talks about XP machines.  So there's a little bit of confusion here.  But so I guess my point is, if you are ever faced with a, for example, a family member who says, "Oh, my god, I desperately need this one file, this is the only thing I care about," that kind of scenario, you might take a look to see if it's just sitting there undeleted after crypto whatever has done its deed.



LEO:  Question 2 here from Daniel Aleksandersen in Oslo, Norway.  He says new Windows versions are auto-sharing WiFi passwords:  Windows Phone 8 have shared network passwords by default with Xbox, Skype, and Outlook Friends.  This innovative feature is now enabled by default in the latest Windows 10 preview builds, as well.  Is this at all secure?  Granting random people access to an internal network sounds not ideal.  What is going on?  I didn't know about this.  What is this?



STEVE:  Yeah.  And this is really interesting.  Actually, either last week or the week before I shared a SpinRite story where the user who sent this actually had a two-part, and I didn't share the second part, but it lodged in my brain.  And he was clearly, he was obviously a listener.  And his experience, which I'll now share, was a little more worrisome.  He had a friend who was using Windows 8 at home.  And one of the guy's machines crashed, his Windows 8 machine.  Oh, yeah, I think it was last week because remember I talked about a Windows 8 data recovery.  Well, that was the email that also went on to say that that machine that crashed was fine, and he used SpinRite to recover it.  And he then allowed that user onto his home WiFi network to do whatever.  Then, separately, later, that person brought a different machine over that was having some weird problems, maybe infected with malware?  It was on his network. 



And so, first of all, this is behavior that Apple has been using among their iOS-enabled devices.  I've seen this myself.  There are a couple restaurants I frequent where the management has given me their password.  In fact, there's one where they wouldn't give it to me; but they said, well, "Let me have your iPad.  We'll enter it.  But we need to keep it secret because we don't want everyone to be using our WiFi."  But, you know, they like me.  So they entered the password secretly into my iPad, and my phone was then on their network.  So Apple was bridging and is bridging WiFi passwords through iCloud or iGlue...



LEO:  It's probably continuity.  It's probably handoff.  I would guess.



STEVE:  Well, yeah.  And so what's happening here, Windows 8 is apparently doing the same thing.  And that is that - and it's now enabled by default, says Daniel, in the Windows 10 preview builds.  I don't know for sure whether it was something you had to turn on in Windows 8 or not.  But the idea is, if you have a household with Windows 8 or 10, and you give one machine your WiFi credentials, they're glued together, and the other machines are able to get on the network.  And so the issue Daniel is raising, and actually it was last week's SpinRite testimonial guy who said, wait a minute.  The person whose one system I permitted onto my network could have brought back a different infected machine, and it's already on my network.



LEO:  Steve, this is what LastPass does.  Apple does this through the Keychain, the chatroom is saying.  Of course they do.  You can share your Keychain.  But that's what LastPass does.  Right?  If you memorize a password on one machine, it's on your LastPass, and you can use any other machine with that password.  That's what every machine does, everything does.



STEVE:  Except that - no, no, that's completely different because LastPass bridges browsers together so that you're able to log into another site on a different machine with LastPass.  But to me that's different than any machine in a cluster just, like, knowing the private credentials of someone's WiFi network.



LEO:  Well, it's done securely.  It's through Apple's Keychain mechanism.  There's a Keychain...



STEVE:  Right.  Well, okay.  So, see, but that's not the problem.  It's not the security of the password sharing.  It's the side effect that an unauthorized  machine...



LEO:  Right.  Well, you should consider that, when you're giving somebody a password, you're giving them the password, not the machine.  The user.



STEVE:  And now we know that you're giving their network of, yeah, their network - yeah, okay, I see what you mean.  Good point.  So, for example, sort of the same thing, the user may have entered the password privately into the guy's Windows machine, although there are ways to pull those out in hex, so it's not like...



LEO:  Yeah.  That doesn't happen that often.



STEVE:  ...it makes it secret, yeah.



LEO:  Does it really?  The guy says, "Give me your machine, I'll log you in."  I wouldn't give them my machine.



STEVE:  Well, and of course we already know that the right solution is to have a second guest network which is not on your internal network and is protected because that's...



LEO:  But just consider, if you give enter a password on a machine, you're giving, not the machine the password, the user the password.



STEVE:  Right.



LEO:  And most systems - Android, iOS and Macintosh, now Windows 10 - have the capability of automatically sharing because we all use multiple devices.



STEVE:  Right.



LEO:  And you're right, because LastPass doesn't monitor WiFi logins, so it doesn't happen there.  But you could, I mean, it could if you wanted it to, I guess.  But that's only because LastPass doesn't monitor that.  Keychain does.  All passwords are stored on the Mac in your Keychain.  Question 3.  Shall I move on?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  Yeah, no, I completely - I'm agreeing with you.  These systems are built into the OS; whereas, for example, Last Pass is running in the browser.  And so it has limited visibility.  It can't see WiFi passwords because it's browser script.



LEO:  Somebody says 1Password will.



STEVE:  Oh, interesting.



LEO:  Yeah.  And Apple will because Apple stores passwords in the Keychain, which is actually a better place than storing them in the clear in the browser or somewhere like that.



Joe Kouba, Tucson, Arizona wonders how, when brute-forcing, do we know when we've got successful decryption?  Steve and Leo, I've been listening since Episode 0.  Thanks for all the work you put into this.  The passion alone is what makes listening an enjoyment.  I'm technical in the area of computers, but I've never gone deep with encryption beyond what I learned in computer science classes in college, so my question might sound silly, and I'm hoping there's a simple answer I'm just not understanding.  If I have a file that's encrypted, and I'm attempting to crack it by throwing computer power against it, how does the computer know when the file is cracked?  How do I know I have plaintext?



For example, say I have a text file that contains "Hello, World," but when it's encrypted it's just garbled text.  It'll be obvious when it's properly decrypted since the file will become readable.  But how do you know a file is cracked if you don't know what's inside?  The data may not be obvious as some English words.  It might contain data that by itself also looks like garbled text.  So actually this would be the perfect example, if I'm encrypting a binary file, how do I know when I've decrypted it?



STEVE:  Right, right.



LEO:  This has long puzzled me.  How you know when it's cracked?  Thanks for your time.



STEVE:  So this is a perfect follow-on to the discussion we've been having in the last couple podcasts about encryption and authentication because we were using the example of that web-based service, which was initially performing no authentication, only encryption.  And the problem was it had no way of detecting the wrong password.  And remember, Leo, we showed that little Windows Notepad of crazy unicode gibberish when I generated that by giving it the wrong decryption password.  It could not detect it, so it just gave me gibberish rather than the proper ASCII back out.  And so that allowed us to talk about the need for authentication.



It is absolutely crucial, and all proper encryption systems also authenticate because, as a friend of the show, FireXware is his handle, explained also, there are well-understood means for replacing chunks of encrypted files with other chunks and altering the file that's encrypted.  So encrypting a file is never enough.  You absolutely also must authenticate it.  That is, what that does is, it verifies that it is the same file that was encrypted; nothing about it has changed.  And, for example, SSL and TLS do this.  And all good encryption does.  SQRL encrypts the SQRL IDs, and I use a hybrid, an authenticated encryption technology which provides both.  And so when you enter your password, it decrypts your identity.  And the first thing it does, well, actually it decrypts the password and then checks the authentication of the encrypted contents to verify the password.



So, Joe, the answer is, encryption that is correct, that is done right, will always also be authenticated.  And as I've also said, the authentication you do after you encrypt - which means that, when you're decrypting, you first authenticate.  So any brute force decryption would first be a brute force authentication.  You would take a trial password and see whether the file authenticates for decryption with that password.  If not, you know you've got the wrong one.  The second it does, then you've independently verified that the password is correct, and then you can proceed to decrypt with absolute confidence that you've got the right password, and the decrypted result will be correct.



LEO:  Very clever.



STEVE:  Really neat.



LEO:  Murray, Murray Wood in Vancouver, wonders about UEFI secure boot and a crashed hard drive:  Steve, thanks for the UEFI explanation last episode.  I'm wondering how, if Secure Boot can't be turned off - which it usually can, but I guess maybe the new machines you can't, I guess it's what we were talking about, huh - would one go about replacing a hard drive?  I assume that the UEFI databases are stored somewhere on the drive.  If you have a hard drive crash, the new drive would need to be initialized somehow.  It seems an initialization utility would be needed, and wouldn't that defeat the purpose of UEFI?  I look forward to your answer and enjoy the show.



STEVE:  So a lot of interesting questions about UEFI, of course, from last week, because the discussion stimulated, as we would expect, questions for the following week's Q&A.  Okay, first of all, I wasn't clear that the databases are stored on the motherboard.  They're in nonvolatile memory in the UEFI firmware.



LEO:  You need a secure store for them; right?



STEVE:  Correct.



LEO:  Yeah.



STEVE:  Exactly.  So they are not on any hard drive.  So because the UEFI secure boot exists separately from whatever it might be booting.  The whole initial warming up phase is done just on the motherboard with its firmware, with its expansion ROMs, verifying signatures and hashes and everything, before it even worries about like what to do next.  So it's all going and up and warmed up before that happens.



Now, if it turns out that the drive has crashed, then it's like, okay, how do we recover this?  Well, in the same way that you do now because, for example, the Windows 8 or Windows 10 boot DVD is also signed.  So you're able to boot a recovery DVD, a recovery disk through UEFI from the system's CD drive or a thumb drive or whatever because it, too, is signed.  And so UEFI will check the signature on the boot media whether, I mean, regardless of what it is.  And if it works, it's just as golden as booting the original crashed drive.  You're up and going.



LEO:  Very sweet.



STEVE:  Yup.



LEO:  Martino Jones in Ypsilanti, Michigan dual-boots Windows and Linux under UEFI:  Hi, guys.  I'm sure others have also sent in emails about this already.  However, I thought I'd share just in case.  I didn't know you could do this.  I currently have Linux installed on my machines.  My laptop is running Ubuntu with UEFI turned on, and Fedora is dual-booting with my Windows 8.1 gaming desktop.  This also has UEFI turned on.  On my desktop I have Windows installed on one HDD and Fedora on the other.  The Grub2 boot allows me to boot with UEFI into Linux, so I never have to turn it off.  Love the podcast, watching and listening for a couple years now.  Happy 500th!



STEVE:  Yeah.  So I wanted - I wasn't clear enough.  Actually we sort of ran out of time talking about the non-Windows side of UEFI Secure Boot.  This has been around long enough that there are, like, the major installations of the various flavors of Linux all have their security certificates worked out and available and installable in order to certify them for UEFI Secure Boot.  And the reason I chose Martino's note is I wanted to make sure everyone understood that this in no way even - it's not clear, if you can't turn it off, how you'll be able to add Linux to a system with Secure Boot enabled.  But I still imagine you probably can, as long as all the tools you use to do that are signed.  And signed tools are now available across the board for many of these major flavors of Linux.



This might be a bit of a problem if you were, like, hooked on some really minor sort of backwater unknown brand of Linux, rather than the main, major builds.  But all of them have got UEFI Secure Boot available.  There's a little bit more you have to go through.  But as Martino shows, once you do that, it's really not in your way at all.  So I didn't want anybody to feel put off that UEFI was going to be locking them out in the future.  It really won't.



LEO:  Good.  That's good news.



STEVE:  It just gives us protection.



LEO:  Bob in Florida wonders whether the Chrome miniLock file encryption extension is any good:  Would Steve be able to review miniLock file encryption in Chrome?  I'd love to hear his thoughts on an app that seems very good to me.  I haven't tried this.  I'll have to.  I was looking for a file encryption app to be able to use with a Chromebook.  It will actually work with any system, and I found the website, miniLock. io.  It's got to be JavaScript; right?



STEVE:  So it is 100% wonderful.



LEO:  Oh, neat.



STEVE:  It is, first of all, it's by our friend Nadim Kobeissi.  He's the guy who is famously behind Cryptocat.  And we remember Cryptocat.  He's a Ph.D. candidate, getting his Ph.D. in applied crypto.  MiniLock.io is his recent project, and it is as beautifully done as anything could be.  He has had it audited.  Matthew Green and a number of other cryptographers have been involved in the project, have looked at his spec.  There has been a full code audit.  The architecture is really well thought out.



So here's what it is.  First of all, Chrome browser and Chromebook, so the Chrome OS, compatible.  It uses my favorite elliptic curve crypto.  It's the same crypto that I chose and am using for SQRL, that is, the Daniel Bernstein Curve25519 crypto.  The beauty of that is that, and this is why I chose it for SQRL, actually it's the reason SQRL exists, is that that crypto allows you to have a deterministic private key.  And what that means is that - whereas, for example, with RSA, you have to randomly choose primes and then use those as your private key.  The point is, randomly choosing isn't deterministic.  That is, you can't immediately go to one.



With the crypto that I use and that Nadim is using, this Curve25519, you're able to say, "This is my private key."  That's the key to SQRL is that, when you take your identity, your SQRL identity, and mix it with the web domain, the result is your private key, every single - and every time you go back, it's the same private key.  That's the secret.  And Nadim has leveraged this same characteristic in a very clever way.



Here's how it works.  You use your email address and a passphrase.  He checks the entropy of the passphrase to make sure it has at least a hundred bits of entropy, using an entropy-measuring formula that somebody else worked out.  So you use your email address, which is easy for you to remember, and a passphrase, and it uses them both just to get sufficient entropy.  That directly creates your private key under the Bernstein elliptic curve crypto.  And the private key creates the public key.  The beauty of this elliptic curve crypto is that, for example, unlike PGP or RSA keys, which are massive, these keys are 48 characters.  They are tweetable, for example.



LEO:  That's nice.



STEVE:  Yes.  So with miniLock.io, so here's how it works.  You load it in your browser.  You fire it up.  You put in an email address, your email address, and a passphrase.  It gives you your public key, which you can then give to anybody who you want to enable to send files to you.  Because it's 48 characters, you can tweet it.  You can email it.  You can even read it to them over the phone.  I mean, these keys are so small that they're way more convenient.  So, and the point is, that is a public key generated from the pairing of your email address and your secret passphrase.  That enables anybody...



LEO:  It doesn't like mine.  It says it's too weak.



STEVE:  Ah, well, yeah, got to...



LEO:  Yeah, 123456789.



STEVE:  Oh, darn.  Keep going, 1011121314.



LEO:  It's suggesting popexaggerationlagunedetectionsmustilymotivationscairo.  So there you go.  I'll have to get another phrase.



STEVE:  So the idea is that, when you use your email address and your passphrase to create a public key, that allows you to receive encrypted files from anyone.  So you send this to somebody, you tweet it, for example, out into the universe, or tweet it to a friend, or send it through a text message, whatever you want to do.  They then use miniLock in a similar fashion.  They drop a file that they want to securely encrypt and send you.



And we're talking world-class security.  I mean, this is absolute unbreakable bulletproof security.  They drop the file on the browser, having given it your public key.  It encrypts that file so that only you are able to decrypt it.  And it can do multi-way, it can do one-to-many encryptions.  So you could drop many different people's public keys in to encrypt that one file so that that group of people, the individual members are able to decrypt it.  The way he designed the file system, the header, and nothing about the encrypted file gives away the identities of either party at either end.  So it's also anonymous and proof against tracking.  You then take the resulting file and send it to these people.  And only the people who have the matching private key, which is always regeneratable from their email address and their passphrase, are able to decrypt the contents of the file.



So it is really nice.  I spent some time, as you can tell, digging into it and understanding what's been done.  And so for Chrome and Chrome OS, for Chromebooks, it's a terrific little, absolutely bulletproof, properly designed, state-of-the-art crypto file exchange tool.



LEO:  This is so cool.  That is really great.  So now if I want to send this image that I just miniLocked, I'd need somebody's public ID, and I could just paste it in.  It automatically puts mine in.  And it's okay for me to show this; right?  Because I could tweet it and everything.  That's a public key.



STEVE:  Yup.  Yes.  That is the full public key.  And what that does is that allows anybody who has it to encrypt a file that only you can decrypt.  So that allows them to encrypt something, knowing that you're the only one who can decrypt it.  And so unless you give your credentials away, it's a secure one-to-one channel between two people.  And also you're able to drop multiple identities in and multiply encrypt the file.



LEO:  That is so great.



STEVE:  Yeah, it's just - it's beautifully done.  So, Bob...



LEO:  You're right, this is neat.



STEVE:  Thanks for asking, Bob.  I'm glad you - it had crossed my radar a few months ago.  I remember looking at it thinking, on, this is correct.  But I just, you know, I got distracted by something shiny and never got back to it.



LEO:  Well, now I'm going to tweet out my miniLock key; right?  And this way people can just search through my Twitter stream, and they'd have it.



STEVE:  Yup.



LEO:  Gosh, I love that.  And that's all they need to send me private stuff.



STEVE:  Correct.  Now somebody can encrypt a file to you, and only you are able to decrypt it.



LEO:  Love it.  Put this on your blog, too, I guess.



STEVE:  Yeah, I mean, exactly, you can post it publicly.  You might put it on your private web page.  It's like, hey, anybody who wants to send me something, use miniLock, and here's my public key.



LEO:  It's probably not as easy as doing, like, PGP if it's built into your mailer.  But you could use this for email, too.  Just create a text file, miniLock it, and then attach it, and then send it.



STEVE:  Sure, sure.  I guess what I like about it is that PGP is sort of like, it's there whether you need it or not.  My use case is more like, hey, I want to scan some financial documents and send it to my accountant, but I don't do that every day.  So this allows you to very handily have absolute state-of-the-art public key encryption at your disposal.  And use it only when you need to.



LEO:  Nice.  Very, very cool.  It doesn't, you know, PGP is useful for signing and other things.  But this is great.  Andrew Stevenson, Dorset, United Kingdom.  He found tracking protection in Firefox.  He's looking at an article on Ghacks.  The full link is in the show notes.  Firefox users right now can enable tracking protection by going to about:config, searching for privacy.trackingprotection, and double-clicking on the setting.  That'll set it to TRUE, and it's enabled.  Mozilla is going to be adding this feature in private browsing mode from Firefox 39 and up.  But if you're still using an older version of Firefox, again, about:config, double-click privacy.trackingprotection.  That'll set it to TRUE.



[ghacks.net/2015/03/27/firefox-39-tracking-protection-for- private-browsing-mode]



STEVE:  So this is very cool.  There's been a project underway for some time now, like more than a year.  A group of ex-Google engineers got together and created something called Disconnect because they were upset about tracking.  It's not so much - and this is sort of where we have to be careful with our terms because it's not about seeing ads.  It's about having large databases of profile assembled by little tracking bits scattered all over the place.  And there are companies, as we know, whose entire purpose is building portfolios of information about individuals.



So at the moment we're at Firefox 36.0.4.  And as you said, if you go to about:config, as we know, there's like a bazillion little twitchy configuration things.  So in the search box, put in "privacy.trackingprotection."  That'll show you two items that come up and match that string.  The first one is the privacy.trackingprotection which you can just double-click in order to toggle it, and it'll flip to TRUE, and the little TRUE goes bold.  What this does is something that will be surfaced in the UI with Firefox 39, so a few major versions from now.  But it's available to all Firefox users today.



What this does - and so right now under Privacy in the Options on Firefox, the only option you see is that sort of unfortunately failed Do Not Track.  I had high hopes for it.  I liked the idea of browsers saying, yeah, please don't track.  We always knew that it would be a choice for trackers to decide whether they wanted to honor it or not.  So what you see right now under Privacy, under the Options dialogue, is an option for that checkbox, "Ask trackers not to track me."  Coming in 39, that gets pushed down, and there's one above it that says "Turn tracking protection on."



What that does is the Disconnect folks have a very comprehensive block list of tracking companies.  This doesn't block advertising.  This blocks just the aggregate trackers.  And Mozilla has built that into Firefox, and we can enable it today.  So basically we're getting a significant feature in Firefox.  It will be in the UI with Version 39, where you just go Options and Privacy, and you'll see it.  But we can turn it on now.  When you do, the little icon in front of the URL will show you, it turns into a shield if you've gone to a site where any of the block list domains were attempted to be queried by your browser.



So I of course turned it on, and I went to The New York Times.  Bang.  Up came the shield, indicating that at least one domain was blocked from tracking me at this site.  And if you're curious, you can use the Web Tools Console under the Security Tab to see a list of all the blocked sites which were prevented from tracking you from the page you were on.



So Andrew, thanks for the tip.  I had not seen this yet.  I'm delighted to know that it can be turned on now, and everyone gets the advantage of it.  And then eventually, when we get to the major Version 39, everyone will be able to see it right there in the privacy tab of the options dialogue.  Very cool.  Oh, and I forgot to mention, in tests it speeds up the median page load time by 20%.  Just blocking all the other queries, the tracking queries that your browser would otherwise be making gives you a 20% speed boost across the board.



LEO:  I almost said "Chapter 8."  Sometimes it feels like that.  Question 8.  Styles Bytchley - can that be his name? - in Toronto wonders - maybe it's pronounced...



STEVE:  Well, it's spelled B-Y-T, Bytchley, B-Y-T, yeah.



LEO:  Bytchley, Styles Bytchley in Toronto wonders why can't UEFI protect against Equation Group's HDD BIOS rewrite?  Been with you since day one, podcast definitely something I look forward to every week.  I'm a proud SpinRite licensee, and it has saved me.  You guys are great, Happy Birthday, blah blah blah.  By the way, Happy Birthday.  I forgot.



STEVE:  Thank you.



LEO:  Was it a good one?



STEVE:  And Leo, I just wanted to make sure you knew how much I appreciated this 10 years of podcast.  Some...



LEO:  I thought so.



STEVE:  Of course, I mean, I tell you guys.



LEO:  I guessed that.



STEVE:  Okay.  I wasn't explicit.  And I was thanking our listeners, and someone tweeted me saying, hey, you didn't thank Leo.



LEO:  Don't listen to the tweeter.



STEVE:  I thought, well, I thank Leo all the time.  But, you know...



LEO:  You don't know.



STEVE:  Just for the record, this is great. 



LEO:  Some people use - I know that, of course.  Some people use Twitter as a way to stir up trouble.  Just ignore that.  Styles Bytchley writes:  I just finished listening to Episode 500 on Secure Boot and UEFI, and it seems like there ought to be a method for this to prevent the hard drive firmware attack you were describing in 495.  Wouldn't a hard drive that had been infected by that Equation Group hard drive firmware rewrite have something different about its driver/hash/fingerprint that could be detected by UEFI as different than the original whitelisted item?  Cheers, Styles.



STEVE:  Alas, no.



LEO:  No.



STEVE:  I loved the idea because it was clever.  And it sort of - it was a nice intersection with this notion that UEFI sort of, like, absolutely protects us.  Now, having said that, it would definitely complicate things because the idea is that, well, I mean, it'd be interesting to see if the hard drive firmware rewrite could get around Safe Boot.  That is, the Safe Boot cannot prevent the hard drive firmware from being rewritten because that happens after the system's booted, when some malware somehow arranges to run and get in and issue standard ATAPI, which is the AT attachment API, the ATAPI commands that allow drive firmware to be updated.  Drive firmware can typically be updated by commands to the drive.



So that's what the whole Equation Group's project is about is, remember, subverting our hard drive's firmware to perform on-the-fly sector replacement.  The problem is that, if it then tried to do that, that is, the next time the system boots, it could run afoul of UEFI if its replacement sectors weren't also signed.  So then we've got to wonder, okay, well, if someone has the capability, like a state-level actor, one of the three-letter agencies, to get a replacement firmware into, like, across-the-board families of drives, as we saw when we were talking about this a few weeks ago, couldn't they also arrange to get that replacement sector signed so that UEFI Secure Boot would function, especially in the world we're moving to where Secure Boot is just going to be the way things are in the future.  And I have to sort of imagine that that probably wouldn't actually stop them.



So unfortunately, Secure Boot doesn't protect the drive's firmware from being altered.  And I wouldn't bet that it actually prevents the altered drive contents from being able to run, either.  I think they probably can sidestep that, especially when we're trusting so many CAs.  I mean, we're just - that's the problem with the trust being as broad and deep as it has become.



LEO:  You're getting the word out.  I got a call on the radio show on Sunday, somebody asking me about CAs.  They didn't know it was called "CA," but they kind of understood what was going on.  And they said, why are there so many of them?  And there's a bunch in foreign countries.  I said, "Like the Hong Kong Post Office?"  He said yeah.  And but I showed him and the audience how to check the certificate of a website.  So he understood what the CA was up to and why it's important, not only that the certificate match, but that the CA actually be trustworthy.  I wish I could have given him a tool to remove CAs.



STEVE:  Yeah, we're going to get to that in Question #10, as a matter of fact.



LEO:  Well, there you go.  As if we planned it.  Grayson Palmer in North Carolina wants to send links in email.



STEVE:  I love this email.  This is just so wonderful.  Okay.



LEO:  I'm responsible for security at a regional retail company.  I have educated our employees to be very careful about clicking links in emails - good man, Grayson - especially when the email is unexpected, or if the hover-over help shows the link is really going to take you to StealMyCredentials.com.  Now, when I want to send them emails with hyperlinks, I get back a bunch of, "Hey, you told me not to click this, Grayson.  Is this safe?"  That's a good sign they're aware of the dangers.  I like that part.  I also get some, "You know, should you be sending out hyperlinks when you've been telling us not to click on them all this time, you hypocrite?"



Of course what we've really been telling them is not to click on hyperlinks in emails from unknown senders, or ones that have other telltale signs.  Is there a simple "best practice" for this?  I would love to be able to send out hyperlinks in emails, and yet somehow be able to show non-technical users it's okay for them to click.  You know, maybe a little padlock symbol like you see in browsers.  Or am I just relegated to saying, hey, you've got to trust me, it's from the internal security team email address?  An example is a recent effort my team went through to point out to users where the Help & Resources page is of the IRS, where they can learn a lot about avoiding tax scams.  And he puts the link in here, but I'm not going to click it.  What do you think?



STEVE:  And so I love this because, okay, several things.  The short answer is, no, there's no solution to this.  And in fact he mentions, unfortunately, telling them not to click on links from people they don't know or trust.



LEO:  That isn't even it, is it.



STEVE:  Correct, because many times, you know, the way email spread was that a user's email account either, like at Yahoo! or in their computer, would get compromised, and the malware would send out email.  And, you know, so like you get email from your mom saying, "Oh, honey, this is the funniest video I've seen in years, check it out."  And then Mom provides you the link, except this never came from Mom.



LEO:  Right.



STEVE:  So you can't - so the idea of trusting anything doesn't work.  The notion of some sort of a symbol or something doesn't work because anything can be spoofed.  That's the problem.  So I sort of loved this Catch-22 that Grayson got himself in because he's trained his people properly, so much so that they're, like, refusing to click on the links that he sends them.  The problem is there is absolutely no way in that channel, that is, in the email channel to tell people to trust it because it's the channel itself that is not trustworthy.  And the way I'm phrasing this is the key.  That is, you have to use some other channel.



Specifically, I imagine that he has control of a web page.  And so what you could do is tell people in the email, manually go to this web page.  Don't click on a link to it.  I'm not giving you a link to it.  He could, like, give them a non-link and say type this into your web browser.  And there you will find the IRS help in filing your taxes link.  So give them a page within the company where they can go to get things.  Maybe make it a fixed page, so it's always the same page.  And they could, like, create a shortcut in their browser.  And so then Grayson could update that page with the things that he's, like, easy access links for things.  And that way it stays around.  It's always there.  They're able to tell their friends about it if they want to share it.



And essentially this is another way of looking at that really wonderfully pithy bit of wisdom, which is never do anything you didn't go looking for.  Remember that?  Brian Krebs was the first person who suggested that.  And that is, when a website says, oh, you need to update your Flash, wait a minute.  You didn't go looking for a Flash update.  It was offered to you.  Never accept anything which is offered to you.  Only do things that you initiate, that you go looking for.  And so in this case the readers of the email would themselves go looking for the page that Grayson has put up, saying go check out this page because there you're going to have links you can trust, not in the email channel, but in using a different channel because you just can't trust.



LEO:  Or say "google this phrase."



STEVE:  Yeah.  That would be good, too, yes.  And we do that often on the show.  Google this, and you'll go to the right place.



LEO:  Right.  Or you could use "Let me Google that for you," the website.  You've seen that; right?



STEVE:  No.



LEO:  It's a snarky way to respond to an obvious question.  Chatroom knows it.



STEVE:  Oh, yeah.



LEO:  It's lmgt...



STEVE:  Is salt bad for you?  Let me google this for you.



LEO:  So what you do is you go to "let me google this" - I have to google that.



STEVE:  Oh, it's the abbreviation?



LEO:  Yeah, it's the abbreviation.  It's lmgtfy.  So then you enter in the phrase you want.  Is salt bad for you?  Then click the button.  You could either do "I'm feeling lucky," by the way, or I would do a Google search.  And now it creates a link, which I'll copy.  And you could put that link in the email and train them that, only if it says lmgtfy.com.  And then, by the way, they can kind of verify because, when you hit it, it goes to Google and types it in for you and then presses Search.  So I think that works.



STEVE:  Wow.



LEO:  Lmgtfy.com.  Or just type the prose words.  Go to Google and search for quote something.



STEVE:  Yeah.



LEO:  Yeah.  Because Google, if you give it a specific search, will give you the right page.



STEVE:  Yes.  For example, if you searched "IRS help and resources"...



LEO:  Perfect.  You'd get that page.



STEVE:  ...which is the body of that URL, it's going to be the first thing that comes up.



LEO:  It's why we don't even really have to give out URLs anymore.  You do this now in the show.  Sometimes you say, oh, well, just google, and you'll find it.



STEVE:  Yup.



LEO:  It's amazing.



STEVE:  It really is.  And I heard you on one of the other podcasts talking about how...



LEO:  They're very powerful.



STEVE:  ...amazing it has become.  I mean, it is the front door.  Google is the front door to the Internet.



LEO:  It's the Internet for people now.



STEVE:  Yes, it is.  In fact, I've had very, you know, my less techie friends, who don't understand what a browser is, it's like they don't know that Google is not the Internet.



LEO:  No.



STEVE:  They just - that's how they find everything.



LEO:  If they want to go to Yahoo!, they don't go to the browser bar and type Yahoo.com.  They type "yahoo," hit return, and then click the first link.  And in fact that's why one of the top search terms, the most searched-for terms on Google, is "Yahoo."  Or at least it used to be.  I went to Google, they have a great - one of the buildings at Google, this was years ago, it had a great big screen that would show you the top searches in real time.  And Yahoo! was like, boom, boom, boom, boom, boom, boom.



STEVE:  Oh, neat.



LEO:  That's probably changed since then.



STEVE:  Yeah.



LEO:  Yeah, nobody goes to Yahoo! anymore.



STEVE:  I hope so.



LEO:  Last question, and this is the one I actually would love to know the answer to, it comes from Wayned in the middle of Southern Maryland.  He wonder why users can't allow or disallow CAs, Certificate Authorities:  I'm listening to SN-500 return to a question I've had in the past:  Why cannot we select which Certificate Authorities we want to allow?  We could go through and edit the list to disallow CAs, but it takes a bunch to eliminate all of the ones that make no sense.  Since I live in the U.S., I speak English and a little French, I don't know that I will ever, ever, ever need to use a certificate issued by Hong Kong, Serbia, Japan, et cetera.  I may feel the need to allow the France CAs; but then again, maybe not.  Can you explain what's going on?  Maybe this is the guy who called the radio show because that's basically the question in a more technical form.



STEVE:  So, yeah.  I guess the best way to phrase it is that we were never supposed to care about this.  The designers designed it to be hidden and perfect.  And unfortunately it's, we know now, it's not perfect.  And so its imperfection is causing people who wish it were less hidden to want to have some access to it.  They, for example, Wayned understands that it's the ridiculous four or 500 CAs that we trust which is causing some weakness.  But at the same time, the sense I get is that the danger hasn't yet risen to the level where it makes sense to go through the trouble.  There are definitely listeners of this podcast who have decided they're going to run the experiment.  I get email from them.  I get tweets from them.  They turn off all their CAs.  They disable them.  And you can do that, down in the plumbing of your operating system.  You're able to move them to...



LEO:  Can you pick and choose?  Or...



STEVE:  Yeah.



LEO:  You can.  Oh, I didn't know that.



STEVE:  There's a whole Certificate Manager, for example, in Windows, where it looks a little bit like your registry.  It's tree structured, and there's trusted providers and untrusted providers.  And you can drag them all down, and then your browser starts having a fit because you can't do anything.  But then one by one you move the certificates that are causing the fits back into the trusted category, and those will be DigiCert and GlobalSign and VeriSign and GoDaddy and Comodo.



And what you'll find is not surprising.  Very few CAs cover the bulk of the sites you visit.  And so very quickly the alarm bells start tapering off, to the point where after having maybe 20 or 30 CAs, you're not seeing alarm bells anymore, yet you no longer have the other 370 certificate authorities being trusted.  So it's absolutely possible to do it.  It isn't made easy because you can get in trouble.  You could delete the certificate by mistake, for example, I mean, Microsoft doesn't want people digging around in there.  It's just supposed to all just sort of be automatic and magic.



So there isn't a super friendly user interface to it.  They haven't made it simple.  And I guess my point is that it's not anything that I have bothered to do or that I would even recommend.  Enthusiasts who want to experiment with it have done this.  And their results are pretty positive generally.  As I said, you add about 30 to 40 CAs, and everything seems to work just fine, even though you're no longer trusting all the other ones in the planet.  Which might be a benefit.



But I guess my point is that the actual danger, the true danger that we appear to be in from trusting all the others just doesn't seem to be that significant.  With Chrome out there, Google instantly spots fraudulent certificates.  And the CRLSet gets pushed.  Everybody scrambles around for a day, and we get a news topic for the podcast.  But nothing happens.  I mean, it's not the end of the world.



Now, the only place where it might be interesting is if law enforcement were using some of those off-brand CAs to sign their fraudulent certs when they want to intercept our traffic.  That is, if we winnow the CAs down to only those that we know and look legitimate and actually seem to be signing certificates that we encounter on the web, then it very might well be that we're no longer trusting the CAs that other - and I don't just mean U.S. agencies because, remember, no one will be surprised if Chinese intelligence is able to get any kind of cert it wants from China.  And as we know, the CNNIC or, yeah, CNNIC, the China NIC, they're providing certs.  I'm sure Chinese intelligence is able to get a cert for any domain that it wants.



LEO:  Wait, wait, I can't delete the China cert.  I can delete a lot of certs, but I can't delete that one.



STEVE:  Ah, interesting.  Sticky.



LEO:  That's an Apple or Chrome thing.  This is the Chrome cert store.  Maybe I did something wrong.  Oh, these are - maybe these are system certs.  I need to go to...



STEVE:  Yeah, again, it's not mean to be simple.



LEO:  Yeah, no.



STEVE:  It's not for your common user.



LEO:  You should know what you're doing, yeah.



STEVE:  Yeah, you really do need to know.  Otherwise you break your computer.



LEO:  Well, you just - you'll get a lot of - you can go to sites where the cert won't be there, and you'll get - if it'll let you on the site, it'll just warn you; right?  Or...



STEVE:  Well, it depends.  For example, if the site is an HSTS site, you cannot bypass a certificate warning there.  It will not let you.  But otherwise you're often able to say, oh, yeah, fine, you know, I trust you anyway.  Go ahead.



LEO:  Google actually, and this is what I told people, as you said, on the show, has such a good system for certificates, that if you just click the icon, the padlock icon, it'll say this is good, this is safe, you're all right.  I mean, I think that's very - I think they do a good job, in Chrome, anyway.



STEVE:  Yeah.  So I guess in conclusion I would just say it is absolutely true that a user could curate the CAs they choose to trust; and that, as you'd expect, very few CAs cover most of the market, especially in any region of the world.  You just don't need to trust that many.  And in fact, it's like a very sharp falloff, where you end up with trusting 40, and now that seems to be all you ever need except maybe the oddball case here or there, which might actually be good not to trust one of those.  So, but the issue is then it becomes a management headache, something you have to kind of keep an eye on.  You're going to get errors from time to time.  And I have to wonder if it's really just worth the effort, if the problem is bad enough to worry about it.  And we are in the process of fixing this problem with other certificate technologies that are in the process of coming online.  So it's certainly a question that is interesting.



LEO:  Speaking of interesting, I was just clicking on the cert at Bank of America in Chrome, and it says, "Your connection to BankofAmerica.com is encrypted with obsolete cryptography."



STEVE:  Ooh hoo hoo...



LEO:  The connection uses TLS 1.2.  So that's Google doing a little bit...



STEVE:  Yeah, it's using RC4, and that's the problem is Google does not like RC4, 128-bit RC4, and SHA-1.  So not only are they using a bad cipher, but they're also using an SHA-1 cert.  Now, I am, too, because as we know there's nothing wrong with SHA-1.  In fact, just yesterday I had my favorite CA group, DigiCert - a domain that I use sort of for background plumbing stuff is GRCtech.com.  And it was expiring next month.  So I asked DigiCert to make me two certs, an SHA-1 that's good through the end of the year, and then an SHA-2, that is, SHA-256, that I'll be using after that, just because I want to continue using SHA-1 certs all the way through 2015 so that I'm not setting off alarms in Chrome, yet everyone is still able to get to GRC, because people using older OSes cannot get to newer sites that have non-obsolete crypto.  Although I do think it's time to turn off RC4.  One wonders, Leo, why...



LEO:  A bank.



STEVE:  Well, not only the bank, not only why they're offering it, but why your browser wouldn't...



LEO:  Accepted it.



STEVE:  Well, why your browser wouldn't have chosen, why your browser wasn't offering something that they would have chosen first.  You might try going to SSL Labs and put that Bank of America into the SSL Labs site and see what the order, the cipher suite order is because that's weird.  You would think that your - certainly your browser is offering much more modern ciphers.  So it must be that the cipher ordering at Bank of America is really bad, like either they don't have any strong ones, or the strong ones are at the bottom of the list, and they should be at the top of the list.



LEO:  Yeah.



STEVE:  Because there's no good reason you should be getting that kind of...



LEO:  Where does it show the list?  Is that at the bottom?  Oh, here it is, cipher suites, yeah, number one.  There it is.  TLS RSA with RC4 128 SHA.



STEVE:  Oh, my lord.



LEO:  That's number one.  That's the preferred list, the preferred...



STEVE:  Oh, my lord.



LEO:  Huh.  Huh.



STEVE:  And the good ones are below it.



LEO:  Below it.



STEVE:  Oh, goodness.



LEO:  That's really surprising, frankly.



STEVE:  Wow.  Wow.  In fact, that's almost a little spooky, Leo, like, okay, that's really very difficult to understand.



LEO:  This is BankofAmerica.com.  I'm not going to some weird site.



STEVE:  Wow.



LEO:  Yeah.  That's not good.



STEVE:  That's sort of hard to - that's hard to understand.  Yeah, and look at all the better ones that are below.



LEO:  Yeah.



STEVE:  And so your browser certainly offered a mature list.  And from that, the BofA said, eh, we'll go with RC4, it's fast.



LEO:  Let's go with the crappy one.



STEVE:  Yeah.



LEO:  I got this.  I got it handled.



STEVE:  Wow.  Wow.



LEO:  That's, boy, you know, you have to - I'm kind of in some ways not thrilled about SSL Labs, especially giving poor grades to my friend Steve Gibson and so forth.



STEVE:  I'm back at an A+.



LEO:  You're back to an A?  All right?



STEVE:  Yeah.



LEO:  But it's really, I mean, maybe the grades, they could downplay the grade thing because that's kind of like it's too broad a brush.



STEVE:  And I understand, you know, Ivan Ristic is behind SSL Labs.  He's a great guy, got a neat book out about securing SSL and TLS.  But his thing is ranking security, and I think he's doing a good job.  I'll take some dings right now while I stay with an SHA-1 cert.  I've already got SHA-2 certs waiting in the wings.  I'll deploy them on New Year's Eve of 2015, and then I'll go from an A to an A+.  Right now he's saying, eh, Gibson's using a weak signature.  It's like, well, okay.  I mean, weaker, but plenty strong.  So but Ivan's service, I love SSL Labs.



LEO:  Yeah, I mean, my point is grades don't tell the whole story.



STEVE:  No.



LEO:  But it's really great to be able to look at things like encryption suite order.



STEVE:  Oh, my, yes.



LEO:  I didn't know I could do that.



STEVE:  Yes.



LEO:  That's fascinating.



STEVE:  Yes.  And that's...



LEO:  And a little disturbing.



STEVE:  That's, I mean, that's actually - that's concerning.  I mean, you kind of wonder how that could happen by mistake is what I'm saying.  It's like, whoo, wait a minute.  Although who really cares about decrypting BofA traffic, I don't know.



LEO:  There's nothing important going on there.



STEVE:  Really, no.



LEO:  If I notice any big wire transfers in the next few days, I'm going to blame you guys at home; all right?  Hey, thank you, Steve Gibson.  GRC.com.  That's the place to go for your 16Kb versions, transcriptions as soon as Elaine digs herself out from the cactus snow.



STEVE:  Yes.  I haven't heard from Elaine.  So here's the deal.  I will be posting the audio of the podcast shortly after I get it.  So even before the transcripts come, normally I wait for the transcripts, and I do it all at once.  But I'm not sure where Elaine is.  So I'll get 500 posted as soon as we disconnect now, and 501 a few hours from now when you guys get the audio edited.



LEO:  Yay.  And by the way, my main banking is done at this place, USAA.com.



STEVE:  Yay, A+.



LEO:  A+.  And if you go down and look at the cipher suites, they don't even support...



STEVE:  Nope.



LEO:  ...the weak cipher suite at all.



STEVE:  RC4 should not even be in the list anymore.



LEO:  On the list.



STEVE:  No.



LEO:  What is Bank of America up to?



STEVE:  That's why I'm saying, Leo, that's sort of beyond bizarre.  That's really - that's difficult to excuse.



LEO:  Hmm.  What was I saying?  Oh, GRC.com.  Now, if you have questions for future GRC.com/feedback, if you want to get SpinRite, that's the best place to do that, the world's finest hard drive maintenance and recovery utility.



STEVE:  Only place to get SpinRite.



LEO:  You can make Steve's pocket go "Yabba dabba do."



STEVE:  A late birthday present.  And by the way, some people did buy copies of SpinRite for my birthday.  Which, you know...



LEO:  Oh, that's a great idea.  Everybody wins.



STEVE:  Wow, I mean, I really appreciated it.  So I couldn't say thank you to everybody, so thank you so much.  My Twitter stream went crazy.  After I thanked people for thanking me, then it even went more crazy.  So I thought, okay, I'm just going to shut up now because it's self-fulfilling.  So thank you, everyone, for the birthday wishes last week.  I really appreciated it.  And especially for the presents, wow.



LEO:  Yeah.  You got presents?  Well, SpinRites.



STEVE:  SpinRite, that's what I mean.



LEO:  But, see, that's a present that everybody gets a present.



STEVE:  And one guy I did reply to.  He said, you know, "I bought a copy of SpinRite to thank you for the 10 years of the podcast and for everything you do."  And I said wow, I said, you know, I don't...



LEO:  That's nice.



STEVE:  I'm a little uncomfortable with charitable contributions, but someday SpinRite is going to save him, too.



LEO:  Think of it as a guy's taking you out for ice cream.  You get ice cream; he gets ice cream.  Everybody gets ice cream.



STEVE:  And I'm going to keep SpinRite going for, you know, it's already been going for 30-plus years.  It's going to keep going.  So it'll keep paying people back.



LEO:  Yay.  And don't forget SQRL is there.  If you want to get rid of passwords, help do it.  Tell your favorite website, "Use SQRL, use SQRL, use SQRL."



STEVE:  We're on our way.  We're on our way.



LEO:  On our way.  I have other versions of this show, high-quality audio, we even have video if you want to see how gorgeous Steve and I are.  You can get that at TWiT.tv/sn or wherever podcasts are stored and forwarded, lots of places to get that, including our own apps.  We don't do them, but the TWiT apps on all the platforms.  But whatever you do, make sure you subscribe.  That way you'll get every episode.  No more voting on the Podcast Awards.



STEVE:  Closed down last week.



LEO:  Alea iacta est, the die is cast.  We'll find out soon whether you won.  Of course you did.  What else?  Oh, if you want to watch the show live, you can do that, too.  It's Tuesdays, 1:00 p.m. actually 1:30 p.m. Pacific, 4:30 p.m. Eastern time, that's 2030 UTC, live.twit.tv.



STEVE:  Ah.  I just checked to see whether I had heard from Elaine because I sent her a note.  She says, "I'm fine, and I did send it, and I've just forwarded that email.  Perhaps your mailbox was just swamped with birthday messages," says Elaine.  So we're all good to go.  I will get her - and it didn't come through again.  Interesting.  Something seems to be catching it.  So I'll let her know I didn't get it.  But anyway, so it looks like Elaine's fine, transcripts are happening, and we'll be up to speed again.



LEO:  Good.  Very nice.  Thanks, Steve.



STEVE:  Thanks, Leo.



LEO:  See you next time.



STEVE:  Thanks, buddy.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#502

DATE:		April 7, 2015

TITLE:		The TrueCrypt Audit

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-502.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I catch up on a busy and interesting week of security events.  Then we take a close look at the results of the just-completed second phase of the TrueCrypt audit, which focused upon the implementation of TrueCrypt's security and privacy guarantees.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  How long ago was it that the TrueCrypt audit was begun?  It's finally done.  Steve will tell us the good and the bad news next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 502, recorded Tuesday, April 7th, 2015:  The TrueCrypt Audit.



It's time for Security Now!, the show where we protect your security and privacy online, 502 episodes of secure insanity with Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  And no end in sight.



LEO:  No end - that's the good news.  Things are not getting better.



STEVE:  Yeah, we had a busy week.  Google threw their weight around with China NIC that we'll talk about.  Firefox has jumped forward with a really interesting idea known as "opportunistic encryption," to allow HTTP sites that don't have strong certificates to still encrypt.  Google had another mistake where on Saturday a critical certificate of theirs expired.  And so that's part of the news.  The other part is what they replaced it with, which I found interesting.  Microsoft, there were announcements that Microsoft was abandoning Do Not Track, the DNT header.  I'm not sure that's true, so we'll take a look at that.  I found an interesting little blurb, actually someone tweeted it to me, I thought it was interesting, about the market in IPv4 space heating up as it becomes increasingly rarefied.



And the big news of the week, for our audience, at least, is that TrueCrypt, the second phase of TrueCrypt audit was completed.  And I've got Matt's short version from his blog, and an analysis of the full audit and what it means.  So I think a great podcast today.  Lots to talk about.



LEO:  Matt is, of course, Matthew Green from Johns Hopkins, the cryptographer who's doing the audit.  I cannot wait to hear.  This isn't going to solve the mystery of what happened to the TrueCrypt programmer, but it's at least going to let us know whether we should be able to use TrueCrypt.



STEVE:  You know, yeah.  What it gives us is two things that I think are really nice.  It gives people who are using it and want to keep using it an exact calibration on that.  And to the degree that there have been forks of the source, and we know there have, it also gives those people who forked the source some specific things that they could look at and improve on.  So really useful, I mean, just across the board.  So this ends up improving the future and, in my feeling, giving people a calibration on where they are now, if they're TrueCrypt users.



LEO:  Well, I think there was some concern because when the guy abandoned the project he said, "Don't use TrueCrypt, it's not safe."



STEVE:  Yeah.  And you know what my take was.



LEO:  Yes.  And I think...



STEVE:  I put up an archive and said, "Here it is."



LEO:  It is safe.  So we'll find out.  Was Steve right?  Coming up.  What a tease.  All right.  Let's start with the security news, Steve.



STEVE:  Yeah.  So, okay.  So probably something maybe not surprising, but still certainly another example of Google throwing its weight around, was the upshot to that certificate that was discovered installed in MCS Holdings' proxy.  Remember that somebody within MCS Holdings' network made the mistake of using Chrome to try to go to a Google property.  Chrome has all of the valid certificates pinned, that is, essentially "pinned" is the cryptographic term.  When you "pin" a certificate, you're no longer relying upon its signature, that is, that it is signed by someone you trust, sort of a one-degree-removed trust.  You have pinned its hash, essentially, the actual entity of the certificate, and that's what you're checking against.  Which means it cannot be spoofed.  You cannot give somebody a certificate that looks like a Google certificate, that appears to be signed validly, but was signed by someone who is not actually trusted.



So Chrome comes with the knowledge of Google's valid certificate.  So the second it sees something that appears to come from Google, but isn't, it sends alarms out.  So that alerted, immediately alerted Google on March 20th, just last month, to this invalid certificate that they tracked down to CNNIC, China NIC, essentially, a major Chinese certificate authority.  So the other shoe dropped on April Fools Day, April 1st, but this was no joke.  Adam Langley updated his existing blog posting, saying:  "As a result of a joint investigation of the events surrounding this incident by Google and CNNIC, we have decided that the CNNIC Root and EV CAs will no longer be recognized in Google products."



LEO:  Wow.



STEVE:  So this is removing the root trust of every certificate that that certificate authority, CNNIC, has issued.  Because basically, whatever happened, CNNIC was unable to make Adam and company happy.



LEO:  CNNIC said it's not our fault, somebody did this.  Right?



STEVE:  Well, okay, yeah.  So we'll get to that.



LEO:  Okay.



STEVE:  So Adam says:  "This will take effect in a future Chrome update."  Because, again, they have to, like, essentially build this intolerance into Chrome.  They have to remove a certificate from the root that Chrome brings with it because it has its own certificate technology.  So he says:  "This will take effect in a future Chrome update.  To assist customers affected by this decision," which is everyone who has a currently valid certificate issued by CNNIC, "for a limited time we will allow CNNIC's existing certificates to continue to be marked as trusted in Chrome through the use of a publicly disclosed whitelist."



So, I mean, this is a mess.  But that's what they say they're going to do.  "While neither we nor CNNIC believe any further unauthorized digital certificates have been issued, nor do we believe the misissued certificates were used outside the limited scope of MCS Holdings' test network, CNNIC will be working to prevent any future incidents.  CNNIC will implement Certificate Transparency for all of their certificates prior to any request for reinclusion.  We applaud CNNIC on their proactive steps and welcome them to reapply once suitable technical and procedural controls are in place."



So that paints a very happy picture.  We're all one big happy Internet community.  However, CNNIC doesn't really see it that way.  CNNIC, and I'm looking at a - oh, it's on 4/02 of 2015.  I can see that date buried in the URL.  So the day after this announcement, CNNIC posts an announcement on their own site, and it reads:  "The decision that Google has made is unacceptable and unintelligible to CNNIC, and meanwhile CNNIC sincerely urge that Google would take users' rights and interests into full consideration.  For the users that CNNIC has already issued the certificates to, we guarantee that your lawful rights and interests will not be affected."  And it was signed China Internet Network Information Center, April 2nd, 2015.



So this is all we know.  We don't know anything more about what was going on behind the scenes, what motivated Google to do this.  It's got to be more than we're seeing because this is big.  I mean, this is, first of all, it's not just removing the root, but it's coming up with some way of whitelisting existing certificates, but that proactively then prevents any non-whitelisted certificates.  So maybe CNNIC will provide Google with a whitelist, and so that's what CNNIC means when they're assuring their existing customers that their service will be noninterrupted.  Now, of course the other question is, are the other browsers going to follow suit?  Are we going to see Mozilla and Microsoft and Apple yank the cert also?



LEO:  They kind of have to.  I mean, it's not meaningful if they don't; right?



STEVE:  Well, yeah, I mean, or it just could be Google being, you know, strong-arming again.



LEO:  Of course they can then say, "Hey, we're the safest browser," if the other guys don't.



STEVE:  And one thing it does is, if the Chrome - so the idea, what would happen is Chrome would not be able to visit any large CNNIC website customers.  That is, big businesses, commercial websites, any entities who had a certificate from CNNIC in the same way that I got mine from DigiCert.



LEO:  Well, wait a minute.  You could go visit it, but you'd have to override the thing that says don't go here, this cert isn't good.



STEVE:  Maybe.  See, you cannot do that on sites that are enforcing SSL.  So, for example, my site...



LEO:  Oh, interesting.



STEVE:  ...which uses HSTS, one of the benefits of that is we really up the ante.  And if a site is offering Strict Transport Security, the browser will not allow you to bypass that.  And also, I mean, if you want to log in, and you don't have - and Google, if you want to log in on Chrome, won't accept the SSL cert.  Even if you did force it, you'd be doing an in-the-clear login.  Your credentials, I mean, you know, your credit card information, nothing would be encrypted.  So it's, I mean, it's a disaster.  So it's affecting all of the websites who purchased their certificate from CNNIC.



And whatever it is that happened, Google was unsatisfied with CNNIC's response, maybe with their procedures, with their auditing, I mean, who knows what.  We just don't know more.  But it's got to be serious for Chrome to just say we are removing a major certificate authority from the trust store in Chrome until such time as they, I mean, Adam says, "We applaud CNNIC on their proactive steps and welcome them to reapply."  Yeah, reapply for global trust on the Internet because Google feels that they [crosstalk].



LEO:  Google needs to be transparent, though, about the reasons they did this.  I think it's unacceptable for them to just do it and not say why.



STEVE:  Yeah.  I mean, and Adam's posting is all peaches and cream.  It's like, oh, well, we had...



LEO:  That's typical Adam Langley.  It just drives me nuts.  I mean, maybe they're - I'm sure they have a good reason.  If they do, they need to say what it is, though.  Otherwise, this is, you know, kind of like a trial without representation.  It's a kangaroo court.



STEVE:  Yeah.  I mean, all he says, "As a result of a joint investigation," blah blah blah, "we have decided that the CNNIC root and EV CAs will no longer be recognized in Google products.  That's phenomenal.  I mean, it puts them out of business, essentially.  Just, bang, you're out of business because Google now...



LEO:  When they say "joint," them and who?



STEVE:  Yeah, well, exactly.



LEO:  Joint with whom?



STEVE:  "As a result of a joint investigation of the events surrounding this incident."  Oh, by Google and CNNIC.



LEO:  Okay.  So CNNIC investigated.  It's very confusing.



STEVE:  Yeah.  And CNNIC's position, which we talked about before, is that they issued an intermediate certificate with signing privileges to MCS Holdings under the understanding, the agreement that MCS Holdings would only sign certificates for their own domains.  But when MCS Holdings instead put that certificate in a proxy, it was signing certificates for every domain that went through the proxy.  And Google's was one of those.  It synthesized, it fraudulently created a Google certificate, which Chrome saw inside the proxy, and all hell broke loose.



LEO:  Wow.



STEVE:  Because that's - Chrome is on a hair trigger.



LEO:  That's amazing.



STEVE:  Yeah.  But the consequence is this is the kind of - this is the response, I mean, and this is really - this is the strong side of Google that we're seeing is, oh, and, well, we'll get to this in a second because I was going to say people have been commenting and asking why GRC's using obsolete security, or obsolete cryptography.  It's like, oh, boy, okay.  So anyway, so I thought this was interesting.  We'll see what happens with this and keep an eye on it.  But it's like, here the majority browser now on the Internet just says we're no longer going to trust any certificates without some sort of whitelisting guarantee, but apparently nothing new that CNNIC signs will be so.  So its existing customers are being kind of grandfathered in, in a whitelist.  Presumably CNNIC will provide that to Google, which will then - a public whitelist.  So we'll all be able to see it.  And maybe that's so that the other browsers can do it, too.  Maybe Google is going to promote this across the browser industry.  Wow.



LEO:  You know, this stuff is complicated.  We had a listener send us a note saying, "I can't download from your podcasts anymore.  Something changed at work, and now it's saying that Cachefly, who's our provider, is using SSLv2, and so work said we won't download it."  But what's weird to us is, first of all, Cachefly says no, we're not.  And it's not HTTPS.  So what we think is somebody's using HTTPS Everywhere.  And there are risks to enforcing HTTPS on sites that don't do HTTPS.



STEVE:  Yes, yes.



LEO:  But we can't figure it out.  But I think that that's what's - we think that's what's going on.



STEVE:  That makes sense, that some crazy IT guy said, okay, we're just going to not have - we're not going to allow non-HTTPS connections.  So just - and this is the problem.  There are still services where, like, a CDN.  What does a CDN need security for, delivering MP3s?



LEO:  Right.



STEVE:  Ultimately, yes, that's where we're going to move.  But let them do it when they want to.



LEO:  He wrote, "I and several of my friends can no longer access any of our favorite TWiT shows.  This happened when our tech security rep removed SSLv3 from our browsers.  If you have any influence with Cachefly, it'd be nice if they stopped using SSLv3."  But they're not.  So you're right, they did add something else.  They added a policy that said...



STEVE:  Wow.



LEO:  Or maybe they just turned off podcasts.  It is work, after all.



STEVE:  Yeah.  Yeah, exactly.  Someone looked at the size of those downloads and said, wait a minute, you know?



LEO:  Just don't, I mean, don't turn on HTTPS for Cachefly, I guess, is the key.



STEVE:  Yeah.  So we're going to talk about Firefox for a moment and then come back to Google, just because I don't know why.



LEO:  Because there's so much to say.



STEVE:  Because there is.  So Firefox began to offer something known as OE TLS, Opportunistic Encryption TLS.  Opportunistic encryption is an interesting idea.  Everyone who's been listening to the podcast certainly understands the way the Certificate Authority system works, the way I purchase a certificate from my CA, DigiCert, every few years.  They recertify me, make sure I'm still here, phone calls, email, go through that process.  In return, they sign my certificate asserting my identity so that somebody else who goes to GRC.com is receiving that assertion signed by someone they trust.  In this case, they trust DigiCert, who has down their homework.



But that's the process for authentication and encryption.  There's a case to be made for encryption only, that is, you know, if we just have HTTP, well, we have neither authentication nor encryption.  Everything's just in the clear.  So session cookies, like Firesheep was able to sniff and do session hijacking.  Those are in the clear.  With HTTP, for example, you could have a man in the middle who was intercepting and modifying things.  I mean, there's no protection at all.  But it's easy because it requires no certificate, no authentication.  Up until recently it was faster than bringing up a secure tunnel and so forth.



So that's the way things had been.  Not all sites, the gurus of the Internet argue, really do need authentication.  That is, sites that are not using it, are not using any encryption now, could at least add encryption so that, well, I guess I would call it "opportunistic sniffing."  You know, just for example, we think that the NSA has big taps all over the Internet, and they're just spooling everything that goes by into their server farm in Utah to look at it later.  Now, if it's encrypted, that's a lot more work.  But to the degree that anything is still not encrypted, it's in the clear.  And we know from, like, sniffing hotel WiFi and non-switched networks, there's a huge amount of passwords and usernames and things still passing by in the clear.



So opportunistic encryption is a means for allowing a website to sign its own certificate, so-called "self-signed certificate."  So a website would offer a certificate which allows the standard SSL/TLS handshake to proceed, with the understanding that no higher authority has verified that website's identity.  It's the website asserting its own identity on its own behalf.  So it would be xyz.com makes their own certificate, and they sign it. And so, I mean, and that's possible.  In fact, that is exactly what the root certificates are.  The root certificates that our certificate authorities have installed in all of our devices, those roots are self-signed.  They sign themselves as the anchor.  And the only reason we trust them is that they came with the operating system.  They're in a protected store.  And so we look to them for the signatures of all other certificates.  So with v37, which is just out, Firefox has added this facility.



Now, the problem is, in order to do it, it's kind of weird because you can't - a website can't just put a self-signed cert on a regular domain where anyone could connect to it because no browser's going to trust it.  If you just connect to it on port 443, like https://xyz.com, well, your browser's going to say, what the heck is this?  You sure you want to do this?  I mean, all kinds of bells and whistles would go off because your browser would see that it was being given a self-signed certificate.



So the way this works is you go to http://, that is, standard HTTP domain.  And the browser says, oh, fine, you know, xyz.com, no security.  It connects on port 80, as it normally would.  But when it gets the server's headers, the response headers, from the first reply from the server, if this server wants to support opportunistic encryption, there's an additional header that's added to the response.  It's Alt-Svc, alternative service, alt service.  And so it's Alt-Svc:, and then either "h2" if the server is supporting HTTP/2 on some other port, or "spdy."  SPDY could also be used if it was a server that didn't yet support HTTP/2, but did support SPDY 3.1, for example.



So that header says there's an alternative source of the same service on that port.  And typically it is also 443, just so you can get through proxies and other filters and things on the web.  You probably don't want to go off to some weird port because you might find other things would block you.  So what then happens is Firefox continues using the standard connection while in the background attempting to negotiate and bring up a TLS connection on the specified port, because that Alt-Svc header tells the browser what port to go to and which protocol to use, h2 for HTTP/2 or spdy.  If the browser is able to succeed, it then preferentially switches to using that protocol for all subsequent traffic.



And the one other little addition is the browser will cache that information.  It'll cache the fact that a given domain, a given website was using an alternative service.  And at some point in the future - and there's control over the cache, the length of time that the cache will remember that.  If the user goes back there just using http://, the browser will remember that that server was offering TLS on some other port and try it first.  So it'll bring that up from the beginning.



So it'll be interesting to see if this catches on.  To me it's like, well, okay.  Seems like you're going through a lot in order to have sort of a soft switchover, sort of a handoff to encryption.  You can't rely on it because you're not encrypted initially.  If the connection won't come up, then the browser doesn't switch.  It continues to use port 80 and just HTTP.  Which means bad guys could easily interfere.  If they simply blocked the incoming traffic to that website, then, that was offering opportunistic encryption, nobody would use it because it would just be blocked.  And so everybody would say, oh, you know, the Firefox browsers trying to do this would say, oh, I guess that server's down at the moment, and continue using port 80.  And people could block it even after you had a session because it turns out that, if at any point the connection goes down, Firefox falls back to port 80 again.



So after all of this, Mozilla brought it out in 37.  And within hours a problem was found.  A security researcher very cleverly, probably just trying to play with this, realized that, if the alternative service also had an alternative service header, you could redirect traffic to somewhere else.  So it was like, oops.  And Firefox immediately - it was an easy problem to fix.  It was just something that they had overlooked.  They had Firefox processing Alt-Svc headers, not only on the unencrypted connection, but on the alternative service connection, and that led to some chaining possibility.  So 37.0.1 was released like a day later, and we have that now.



So anyway, I wanted to let everyone know that exists.  I'll be surprised if it ends up being a big deal, if sites jump on it, because you can get free certs, legitimately trusted certs for free that last a year from a number, like, what, StartSSL, I think, is one of them.  So there are solutions for this, if you want encryption, that also gives you authentication and just a more straightforward way of doing it, rather than this weird sort of kind of hybrid kludge.



Now, back to that picture at the top on the first page of the show notes, Leo.



LEO:  Yes.  I realized I showed it prematurely.  I apologize.



STEVE:  That's all right.  So this caught Google by surprise on April 4th, which was Saturday morning.  A major service of Google, if you look at the name on the top cert there, the common name...



LEO:  Oh, Gmail.  The outbound server for Gmail.



STEVE:  Smtp.gmail.com expired.  Now, what really happened - yes.  What really happened was, well, and that's what happened was suddenly nobody - everybody was getting errors on trying to use the SMTP service at Gmail.com because they were no longer able to get secure connections.  Everyone's servers and clients were coming back saying, uh, this certificate is no good.



So if we look at this chain, and for those who aren't able to look at it, the CA at the root of the chain is GeoTrust.  So GeoTrust Global CA, GeoTrust Inc., signed an intermediate certificate that they issued to Google, the so-called Google Internet Authority G2 cert.  And that certificate was valid from April 5th of 2013 to April 4th of 2015.  Yeah, 2013 to April 4th of 2015.  So a two-year interval, one day less than two years.  And so that's Google's intermediate certificate that they were then using to sign other things.  We don't know what other things.  But at least they signed this smtp.gmail.com cert, which was installed on the smtp.gmail.com server, and expired Saturday morning.



Now, the way this works is that someone's email server may not trust directly the Google Internet Authority, that is, the intermediate cert.  So the certificate that is from the mail server bundles in, it includes the certificate that signed the end certificate because that intermediate certificate is signed by GeoTrust, and everybody will trust that.  So the point is that the way this certificate expired was it wasn't really the end certificate.  That expired, will expire, would have expired on December 30th of 2015, the end of this year.  But the one whose trust it was dependent on, the intermediate, expired Saturday.



Now, Google, it took them about, like, eight hours, I think it was, to get this thing.  I mean, it caught them by surprise.  They had to figure out where the problem was.  They had to essentially reissue, get a certificate reissued that did not have an expired intermediate.  And they may have had, like, lots of other certificates with intermediate certificates with later expiration dates, and somehow the order in which this happened just sort of caught them by surprise.



Further down in the notes I show the new certificate chain, which is current as of today.  And so the root is still GeoTrust.  Now the intermediate authority is valid through December 31st of 2016.  So whereas that expired on April 4th, 2015, now it's good for the rest of this year and all of next year.  And then it signs the end certificate, that doesn't look like it's changed much.  It's still expiring at the end of this year.  But what I just sort of looked at and shook my head was the signature algorithm that every one of these newly issued certificates is using.



LEO:  Oh, no, no, no, no.



STEVE:  Minted on Saturday.



LEO:  They're still using it.



STEVE:  Signed with SHA-1.  Of course they are.  And you know why?



LEO:  Why?



STEVE:  Because the browser won't complain.



LEO:  But they won't let us do that.



STEVE:  Correct.  Now go to GRC.com, Leo.



LEO:  Right now?



STEVE:  Yeah.



LEO:  Okay.  I'll do it in Chrome.



STEVE:  GRC.com.  Bring up - oh, I'm sorry, yes, you have to.  I should have specified.  Because nobody else cares.  Everybody else is happy.



LEO:  Yeah.  You look good on this.  You're green.  You've got the green cert.



STEVE:  But click on the greenness.



LEO:  All right.



STEVE:  And go to that second tab there.



LEO:  Connection.



STEVE:  Yeah.  And what does that say there, the second item?



LEO:  Obsolete cryptography.  Steve, I'm shocked.  Shocked.



STEVE:  Yes.  So Chrome is saying that my site is using obsolete cryptography, despite the fact that you'll notice it's TLS 1.2, the latest standard.  They're bitching that I'm using...



LEO:  It's the SHA-1; right?



STEVE:  SHA-1, yes.  And they are, too.  Newly minted certificates protecting Gmail are being signed, being now created with SHA-1.  Just because no one is going to complain.



LEO:  Bugs me a little bit.  Yeah, bugs me a little bit.



STEVE:  I know, I know.  And in fact, I've heard from people within the certificate community, the CA world, that this is causing havoc.  A person who works at a CA said to me the other day, "Steve, if I could tell you what a mess Google is making by scaring people."  And in fact someone tweeted me just this morning a beta of Chrome with https in red and a red slash through it, which is now the way my site appears in a forthcoming version of Chrome.  So, yup, Google...



LEO:  Oh, because they're escalating it; right?  Yeah.



STEVE:  That was the plan.  They're escalating.  And actually mine may not because my certs all expire at midnight on New Year's Eve.  Somebody said to me, oh, by the way, Steve, don't forget, you're going to be at the TWiT Brick House on midnight of New Year's Eve.



LEO:  Oh, not this year.  We're not doing it this year, so you're safe.



STEVE:  Oh, good, perfect.  I'll be home.



LEO:  We know where Steve will be.



STEVE:  I'll be home to change my certificates.  There will be a countdown.  As the ball is dropping in New York, I will be - actually, I have to synchronize.



LEO:  You could do it before then; right?  I mean, you don't have to...



STEVE:  Oh, of course I can, yeah.  And I'm sure I will.  But it just - it did bother me, this double standard that here Google is telling everyone that SHA-1 certificates are obsolete, and they're implying that they are insecure.  Yet they're using them still where no one can see them because they know they're just fine.  Gmail is protected with SHA-1, just on Saturday.



LEO:  Kind of frustrating.



STEVE:  So, yeah.  So Microsoft.  I see, like, news blurbs saying Microsoft is abandoning Do Not Track.  Now, and you of course could do that much better with your Walter Cronkite.



LEO:  Microsoft now abandoning Do Not Track.



STEVE:  Perfect.



LEO:  Tracking news.



STEVE:  So on April 3rd - which I guess, if the 4th was Saturday, when the Google certificate expired, the 3rd would be Friday - they blogged about some change.  Now, I'm not going to paraphrase, I'm going to read this, because I don't know what this means.  And I guess we won't know until we see it.  But here's what they said, and then we'll talk about it.



Microsoft writes:  "As industry standards evolve, how we implement those standards evolve as well.  So to reflect the current requirements of the privacy standard for tracking preferences, Microsoft is changing how Do Not Track (DNT) is implemented in future versions of our browsers:  We will no longer enable it as the default state in Windows Express Settings.  While our implementation of DNT two years ago in Internet Explorer 10 was welcomed by many, others voiced concerns, especially given that discussions were underway at the time to establish an industry-wide standard for user tracking preferences.



"Since then, the World Wide Web Consortium (W3C) has continued to refine language to address how users express a preference regarding tracking.  The latest draft of the standard reads:  'Key to that notion of expression is that the signal sent MUST reflect the user's preference, not the choice of some vendor, institution, site, or network-imposed mechanism outside the user's control.  This applies equally to both the general preference and exceptions.  The basic principle is that a tracking preference expression is only transmitted when it reflects a deliberate choice by the user. ? In the absence of user choice, there is no tracking preference expressed.'"



So Microsoft resumes:  "Put simply, we are updating our approach to DNT to eliminate any misunderstanding about whether our chosen implementation will comply with the forthcoming W3C standard.  Without this change, websites that receive a DNT signal from the new browsers could argue that it doesn't reflect the users' preference, and therefore may choose not to honor it.  As a result, DNT will not be the default state in Windows Express Settings moving forward; but we will provide customers with clear information on how to turn this feature on in the browser settings, should they wish to do so.  This change will apply when customers set up a new PC for the first time, as well as when they upgrade from a previous version of Windows or Internet Explorer."



So I don't know quite what Microsoft means when they say "This change will apply."  I guess they mean the lack of future defaulting it to on.  "We said in 2012 that browser vendors should clearly communicate to consumers whether the DNT signal is turned off or on, and make it easy for them to change the setting.  We did that for IE10 and IE11.  And we're continuing to do so with future versions of our browsers."  So I guess my reading of this is they got a lot of heat, and they're backing off.



LEO:  Interesting.



STEVE:  Yeah.  Yeah, so...



LEO:  This is the same heat everybody else is getting.  I mean, this is an interesting - there's two different parties to this, on both sides; right?



STEVE:  Right.  The dilemma is that we have the so-called "tyranny of the default," you know, the expression I coined.  I like it because it just sort of says most users just leave things the way they are.  Whatever the default is, that's the way they're going to be.  So Microsoft, with some fanfare a couple years ago, and we talked about it on the show, decided that the express settings for the browser, which the user would just say, you know, kind of look through the list, do you want it this way, and the user would say, "Yeah, that all looks right."  Enabling Do Not Track was there.  And understand that this argument about the signal must be set and must represent a user preference, we talked about this two years ago.  This isn't new.  This isn't something that just happened.



So I don't think anything has changed except something has happened over on Microsoft's side to, say, uh, you know, this, I mean, these arguments, the idea that, if it was on, then websites could say, well, that really doesn't represent a user preference because Microsoft turns it on by default.  So we're going to choose to ignore it in that instance.  So we'll have to see how Microsoft presents this.  If they don't produce a neutral question, then it's certainly the case that they have abandoned Do Not Track.  If the user has to go in search of it, then that would constitute abandonment.  If, however, Microsoft says, "Hi there, no bias shown, do you want to be tracked or not," then that would represent a user choice that would be explicit.



LEO:  Yeah.  And of course they don't like to put too many of those up as you sign up for these things.  They don't, you know...



STEVE:  Right, it overwhelms everybody.



LEO:  Yeah, yeah.



STEVE:  So, interesting.  So this is an interesting pair of charts.  This is two charts that show the rate of IP address block movement and IP addresses, individual IP addresses over the last couple of years.  And so they're both basically exponential curves, going up crazy.  For example, in November of last year, toward the end of last year, in that one month - or is that a week?  November, oh, yeah, that looks like, no, that's probably one - oh, yeah, I'm sorry, it's one month because there's 12 bars per year.  So somewhere like November 2014, nearly two million IP addresses transferred.



Now, that means that there were IP addresses that were being routed down some channel, some tube, one of those Internet tubes, going in some direction, and something happened to cause one or more typically large blocks of those IP addresses to go now be routed somewhere else.  Meaning that someone gave them up, and somebody else got them.  So they're being transferred.  It turns out that there's an actual sort of a - there's like an aftermarket now that is developing for IPv4 space, even though IPv6 exists, and it's got enough IP addresses that we could all have our own Internet worth several times over.  I mean, when I talked to my provider about getting some IPv6, they said, "So what do you want?  You want 64,000 IPs?"  It's like, what?  It's just me here.



LEO:  They're free.  They're plentiful.  No reason not to.



STEVE:  Yeah.  So what's happening is there is now a resale market.  And so, for example, it turns out that for whatever reason, a fluke of history, Romania has had a surplus of IPv4 space.  And Jump.ro has been selling it off like crazy.  In fact, 51 percent of all the IPv4 blocks transferred last year came from that one Romanian organization, Jump.ro. They will sell large blocks of IPv4 space for $10 per address, or lease smaller blocks for 50 cents per address per year.



And to give you some sense for this, of like where they're going, Saudi Telecom purchased 1.5 million IP addresses in 17 block transfers, 14 of those from Romania, three from Ukraine.  So if we sort of back-of-the-envelope say $10 each, they paid $15 million, Saudi Telecom did last year for 1.5 million IPv4 addresses.  So it's not surprising.  As we know, change is hard.  There's a huge install base, well, I mean, all of the equipment on the Internet knows IPv4.  IPv6 is still moving forward, but at a glacial pace.  And it's just easier for people who need more existing IP space to find people who have it and buy it from them.  So that's happening.  It's a strange world, the fact that, you know, it's like a virtual currency.  It's like, "You got any IPv4?  What can you part with?  If you're not using it, we'll pay you for it."  And of course...



LEO:  Funny.



STEVE:  And one thing that this does is it tends to cause routers problems because what we really want, the original fabulous architecture was that IP space, the IP protocol, the addressing, was hierarchical.  That's why, for example, HP started with 14.  Meaning HP was everything 14.  And so HP could basically, if an IP address began with 14, all the router had to do was send it to HP.  Didn't even have to look at the other three bytes, just, oh, 14, HP.  And many of the early networks were like that.  GE has a Class A network, as those are called, and many major organizations.  Many universities are still today squatting on - maybe they're waiting for the price to go up.  Once it hits a hundred dollars for IP, it's like, ah, we can lower tuition and sell off some of our bulk IPv4 space.



So the problem, though, is, as the IPv4 space becomes more fragmented, that is, for example, while Romania had a huge block, all of that, like one table entry in the router could match a huge number of IP addresses underneath their network number and just send everything to there.  But now, with Romania selling these off to different parties, what was one entry in all of the routers, all of the big iron routers that do this on the Internet, what was one entry now might be a hundred entries because, if they've sold these pieces of one big block, scattered them all over the place, now we need individual address matches on the routers in order to send them off to different destinations.  So this is causing concern among the engineers who worry about the Internet's plumbing because, due to this kind of fragmentation, there is a routing cost that the original engineers just brilliantly sort of considered and came up with an economical solution to in the beginning.



So, miscellaneous stuff.  I ran across an amazing add-in.  We've talked about Firefox configuration, you know, how you do about:config, and up comes so many individual entries that, forget about it, you have to have a search bar.  And so you put in, like, UDP or SSDP or OCSP, for example.  And then it filters out this galaxy of individual tweakable things to just the ones that you hopefully care about.



Turns out somebody built a UI - and I know that we've got a bunch of tweakers here in our midst on the podcast, and people who are, as I am, still using Firefox because it's so much leaner than Chrome is - called Configuration Mania.  So it's a Firefox add-on.  I imagine you can just go to add-ons and search "configuration mania."  It's -4420 is the number in addition to the name for the Firefox add-on.  It gives you basically a beautiful, tabbed, multidimensional, laid-out user interface for that about:config.  More settings than you, I mean, believe me, this is - you will get lost if you're someone who likes to play with things because it exposes them all, just in a very easily browsable fashion.  So I wanted to provide that tip for our Firefox users who are also enjoying tweaking things.



I got a kick out of a tweet that I received last week, following up on our discussion, Leo, you and me, about SETI and Active SETI and the fact that we've been listening with all of these big ears pointed at the sky for all this time, and all we hear is just white noise.  And so Barry Wallis tweeted, he said, "Steve, aliens are smart, so of course all their comms are encrypted and indistinguishable from noise, just exactly like what SETI sees every day."  And it's like, of course.  They're not going to be sending out - they're going to have some crazy...



LEO:  Gee, that's a good point, yeah.



STEVE:  Yeah, it's going to be encrypted, and it's going to be compressed.



LEO:  Yeah, it wouldn't be plaintext.



STEVE:  No.  So we now are sending up...



LEO:  So there'll be no patterns.



STEVE:  Right.  It's noise.  And, gee, so as far as we know, we've been receiving encrypted alien communications since we started listening.



LEO:  A very good point.



STEVE:  We just don't know what the password...



LEO:  Any sufficiently advanced civilization is going to send all its communications encrypted.



STEVE:  So, Leo, we don't know the password.  I don't think it's "monkey."



LEO:  Is it "monkey"?  But they don't have monkeys.



STEVE:  They may not have come down out of the trees.  Maybe it's "lizard."  Maybe they're reptilian, you know, because apparently some aliens are.  So if anyone has any ideas for the aliens' password that then SETI would be able to use to decrypt all these communications, that would be handy.



And equally strange, Indiegogo has a project underway to allow people to purchase a saliva test to measure the average length of their telomeres.



LEO:  Wow.  And why would I care how long my telomere is, whatever that is?



STEVE:  Okay.  Well, the telomere, you'll know what it is, I'm sure you've heard about them.  They're the little bits of protein on the ends of our chromosomes that essentially keep them from unraveling.  They're likened to the little plastic tips on our shoelaces.



LEO:  The aglets.



STEVE:  Yes.  And so these are genetic aglets.  And telomeres limit the number of times cells can reproduce.  And so, for example, there's an enzyme called "telomerase" which is the enzyme that lengthens existing telomeres.  And they are shortened when cells divide.  The point is, they've been linked to health, in the same way that inflammation and other sort of underlying factors have.  So of course you and I both did our genetic tests at 23andMe.  I signed up for this little $89 saliva test, just because I'm curious.  I mean, it's not clear that we have much control over it.  There actually is a ridiculously expensive supplement, it's like $600 a bottle or something, that has been shown to lengthen someone's telomeres.  I don't think I want to mess with this because...



LEO:  We don't know everything there is to know about telomeres.



STEVE:  Mother Nature often has a good reason.  For example, cancer generates telomerase in order to get the accelerated tumor reproduction that it needs.  So it's figured out how to bypass the cell division limitation that telomeres create by sort of building its own accelerator.  So it's like, yeah.  But anyway, I'm curious.  And I just thought I'd give a shout-out for it to anyone who might also be interested.  I think they're about halfway through their campaign, about another month left to go.  So it's at Indiegogo.  It's Titanovo, T-I-T-A-N-O-V-O, Measure Your Health.  I imagine if you google "titanovo measure your health" you'll be able to find them.  So, and I'm just curious.  I don't know what mine are going to be.  But, you know, so I want to find out.



LEO:  I bet you have massive telomeres.



STEVE:  I have a feeling mine are in good shape.  I've - yeah, yeah.  Those indications are interesting.



LEO:  Is it like midichlorians?  I mean, is it, like, maybe - who knows.



STEVE:  Yeah, it's different, yeah.  Just it's another parameter that...



LEO:  I don't like knowing something that I can't do anything about.



STEVE:  Yeah, it's funny because there's one called CRP.  C-reactive protein is a systemic measure of inflammation.  And when I was doing my annual physical, and I've had mine measured, mine's...



LEO:  You can get a CRP test, yeah, yeah.



STEVE:  Oh, yeah, yeah.  But I remember I asked my doctor to add it, and he kind of looked at me, like, why?  I said, "Well, because I want to know."  He says, "Well, you can't do anything about it."  And I said, "Well, actually you can."  And that's why mine is right down at, like, 0.3 at the moment, just because there are things you can do to keep track of it.  And it's weird, too, because I once had a really bad infection, didn't even think about it, this is maybe 10 years ago, when I had a CRP test done, and it was off the scale.  It was like, 12.  It's like, hey, it works, because I had never seen it do anything before.  It was just always sort of down there like water.  But it turns out, yeah, it actually does measure that.  So, yeah, I guess I'm interested sort of as a point of departure for research.  So, you know, I'll find out what mine is.



LEO:  Good.



STEVE:  So a nice note from a - I sort of liked this one because this dates - I don't know how far back the 1980s are.  What is that, like 30 years?



LEO:  Long damn time.



STEVE:  A contemporary Security Now! listener, Paul Windham, recounts his first encounter with SpinRite.  He said, "Dear Steve:  As a contemporary SpinRite user I have to tell you about an experience [stammering], an experience I had with SpinRite many years ago."  Sorry.  "I was in the Marine Corps in 29 Palms, California in the..."



LEO:  Nice, nice berthing there, that's good.



STEVE:  Yeah, "...in the 1980s.  We had a PC which was running some kind of MS-DOS and would no longer boot.  I was fortunate enough to work with a retired Marine named James Kornegay.  He helped me all the time with PC issues, and he owned a copy of SpinRite, which we ran on the unbootable system - after which, of course, it booted right up and ran.  To this day I am a SpinRite user, and it has saved me from a lot of pain.  Thanks for 500 shows and look forward to odometer reading 512.  Paul Windham, SpinRite user, Security Now! user."  So, Paul, thanks for sharing.  And 30 years of SpinRite use, that's great.



LEO:  I'm sorry, I was playing with my phone.  I got the new...



STEVE:  With the fabulous fingerprint reader, I know.



LEO:  I got the new Galaxy S6, and I'm just - it's so pretty, I'm just caressing it a lot.



STEVE:  Ah, nice.  Small.



LEO:  Well, it's not as big as the Note, you're right.



STEVE:  I'm just teasing.



LEO:  It's a five-inch phone.



STEVE:  I'm just teasing.



LEO:  No, you're not.  You're making me feel bad.



STEVE:  And wasn't there a note about a bigger Apple phone coming?  Was that just rumor?  I can't...



LEO:  A bigger?  No, that's - there's no - we don't know what Apple's going to do.  September there'll be a new phone.  That's all we know.



STEVE:  Boy, this Watch sure is creating a lot of stir.



LEO:  Yeah, we can't stop talking about it.



STEVE:  Well, and just it sounds like it's going to turn the Apple Stores upside down.  I mean, really just be a mess.  I'm going to stay away for a while.



LEO:  That's what they're saying.  Don't go to the Apple Store anymore. 



STEVE:  Yeah.



LEO:  Stay home and order online.



STEVE:  Yeah.



LEO:  So much of what we do, we could do in the cloud now, you know.  There's no reason to go to a brick-and-mortar store.



STEVE:  Right.



LEO:  Push a button, and a uniformed member of the United States government will come to your door with it.



STEVE:  And say, "Here you are, sir."



LEO:  Here you are.  Steve Gibberino, let's talk about the TrueCrypt audit.



STEVE:  So certainly our longstanding listeners will all know about that weird day when we woke up and discovered that the TrueCrypt website, which had been there patiently making available versions of TrueCrypt for years, just suddenly went belly-up, disappeared.



LEO:  So unexpected.



STEVE:  Yeah, well, out of the blue.  Nobody expected it.  The authors, my theory is, they wanted to be done with it.  They wanted to be through.  And, I mean, not just we're not going to keep updating it any longer, but we want to be disconnected.  And as I said at the time, the problem with disconnecting from TrueCrypt is that it was the most popular whole-disk and partition encryption system there was because it was beautifully designed, easy to use, really solid.  I mean, it was what we all recommended for people to use.  I've used it.  My tech support guy Greg relies on it to encrypt his laptop.



And so for that kind of application, people - even if these guys said we don't want anything more to do with it, well, people are still using it.  They're, like, well, but wait, you know, what about support?  What about questions?  What about new versions of Windows and so forth?  So my theory has always been that what they chose to do was to paint it in the worst possible light in order to help migrate people away from it.  So they said, "TrueCrypt may be insecure; and, if so, we're not going to fix it."  I mean, and so for people who were made uncomfortable by that statement, they went in search of an alternative.  And that's what the authors of TrueCrypt wanted.  They didn't want to just have this thing stop.  They wanted to reverse time.  They wanted to be through.



So the problem was that this occurred in between the first phase and the second phase of the TrueCrypt audit, which was a project that had been started by and sort of run by a group of cryptographers, Matthew Green, whose name we know well, from John Hopkins and some others.  Money was put together in order to fund an audit of TrueCrypt because, since it was so popular, since this was the one that people were using, someone thought, hey, you know, just the fact that it's open source - and this is what we're realizing with things like the OpenSSL bug that was sitting there on the 'Net for two years before we discovered that problem.  Just the fact that it's open source doesn't guarantee that it's secure.



LEO:  Right.



STEVE:  The only way...



LEO:  In fact, that's what surprised me about this whole thing is that I'd just assume, well, somebody's looking at it.  But apparently nobody was looking at it.



STEVE:  Right.



LEO:  Not in any rigorous way, anyway.



STEVE:  Right.  And so it was like, okay, time to audit TrueCrypt.  So the first phase had been finished and came out fine by the time that the TrueCrypt site shut down, and the authors said, "Stop using TrueCrypt.  Oh, by the way, Microsoft makes BitLocker.  If you're using Windows, go over there."  So the first phase was finished.  The first phase, though, wasn't the deep crypto audit.  They just looked at sort of the startup of the system.  They looked at the boot technology, at the way the system got going, and sort of like the whole, the front end of TrueCrypt to see how that operated, looking to see if there was anything that was in any way suspicious.  And it came up perfect.  Nothing was found that looked wrong that far.



So one of the questions that came up, because we all knew that there was a Phase 2 deep crypto audit looming, was whether these guys knew something that we didn't, and they were bailing before the results of the second phase of the audit came out.  That was, again, one of the multiple theories of why they did this because they really didn't give us much reason.  They just said, "We're not doing this anymore."  No reason given, really.  Although, as I said at the time, there was some Twitter chatter where someone was able to get one of the authors in a dialogue, and they just said, you know, we're done.  We want to move on.  And as a developer of software, I can and could and do understand that.



LEO:  Oh, yeah.



STEVE:  So audit results are available.  The Phase 2 audit is finished.  I'm going to read Matthew Green's short summary.  Then we're going to look at in detail the four things that the auditors found.  So Matthew Green said:  "The TL;DR is that, based on this audit, TrueCrypt appears to be a relatively well-designed piece of crypto software.  The NCC" - that's the group that did the audit - "found no evidence of deliberate backdoors or any severe design flaws that will make the software insecure in most instances."  And so it's those sort of qualifiers where we're going to spend the rest of this time because we're going to exactly qualify or quantify what those instances are.



"That doesn't mean TrueCrypt is perfect," continues Matt.  "The auditors did find a few glitches and some incautious programming, leading to a couple of issues that could, in the right circumstances, cause TrueCrypt to give less assurance than we'd like it to.  For example, the most significant issue in the TrueCrypt report is a finding related to the Windows version of TrueCrypt's random number generator which is responsible for generating the keys that encrypt TrueCrypt volumes.  This is an important piece of code, since a predictable random number generator can spell disaster for the security of everything else in the system.



"The TrueCrypt developers implemented their random number generator based on a 1998 design by Peter Gutmann that uses an entropy pool to collect 'unpredictable'" - and Matt put that in quotes, we'll talk about that as one of the issues - "'unpredictable' values from various sources in the system, including the Windows CryptoAPI itself.  A problem in TrueCrypt is that, in some extremely rare circumstances, the CryptoAPI can fail to properly initialize.  When this happens, TrueCrypt should barf and catch fire.  Instead, it silently accepts this failure and continues to generate keys."



Now, as we'll see, this is not as dire as Matt, I mean, what Matt wrote is true.  But again, we need to quantify this.  "This is not the end of the world, since the likelihood of such a failure is extremely low."  And for other reasons we'll see.  "Moreover," says Matt, "even if the Windows CryptoAPI does fail on your system, TrueCrypt still collects entropy from sources such as system pointers, mouse movements.  These alternatives are probably good enough to protect you.  But it's a bad design and should certainly be fixed in any TrueCrypt forks.



"In addition to the random number generator issues, the NCC auditors also noted some concerns about the resilience of TrueCrypt's AES" - that's of course the Rijndael cipher - "code to cache-timing attacks.  This is probably not a concern unless you're performing encryption and decryption on a shared machine, or in an environment where the attacker can run code on your system, for example, in a sandbox, or potentially in the browser.  Still, this points the way to future hardening of any projects that use TrueCrypt as a base.



"TrueCrypt," finishes Matt, "is a really unique piece of software.  The loss of TrueCrypt's developers is keenly felt by a number of people who rely on full disk encryption to protect their data.  With luck, the code will be carried on by others.  We are hopeful that this review will provide some additional confidence in the code they're starting with."



So that was Matt's statement on what the audit showed.  Now I'm switching to the, I think it's about a 13-page PDF that details it.  I'm not going to go through this in detail.  I'm just going to start reading the authors' findings summary, and then we'll switch to the four things.  So they said:  "During the engagement, CS" - which is the name for Cryptography Services - identified four issues, and none led to a complete bypass of confidentiality in common usage scenarios.  The standard workflow of creating a volume and making use of it was reviewed, and no significant flaws were found that would impact it.



"The most severe finding relates to the use of the Windows API to generate random numbers for master encryption key material, among other things.  While CS believes these calls will succeed" - now, this is important, too.  While CS believes these calls, these Windows API crypto calls, "will succeed in all normal scenarios, at least one unusual scenario would cause the calls to fail and rely on poor sources of entropy.  It is unclear in what additional situations they may fail.



"Additionally, CS identified that volume header decryption relies on improper integrity checks to detect tampering, and that the method of mixing entropy of keyfiles was not cryptographically sound."  We'll talk about both those things.  And then, "Finally, CS identified several included AES implementations that may be vulnerable to cache-timing attacks.  The most straightforward way to exploit this would be using native code, potentially delivered through NaCl in Chrome," meaning Chrome's native code technology that we were talking about because of the RowHammer attack and how they removed the ability for a cache flush to be invoked.  And it turns out, that same mitigation pretty much rules Chrome out as a means for weakening the AES in TrueCrypt, which they say:  "However, the simplest method of exploitation through that attack vector was recently closed off."  Ah, so, yes, they're saying that Chrome got fixed.



So, four vulnerabilities that we're now going to talk about in detail.  Okay.  So now four things.  These are the four things, in order of worst to least bad, that everyone's opinion who audited this ranks.  So the first one is that there is this Windows API call that we heard everybody talking about.  The call, the actual API text is CryptAcquireContext.  So that's what a programmer writes when they want to invoke this.  It's saying to Windows, give me a context, which is sort of like an object-oriented container, for future crypto operations.  It's sort of a way of allocating a chunk of memory which Windows will then use on your behalf.  You give it back this context whenever you're doing things, and Windows manipulates it and says, okay, yeah, I did that for you.



So what they said was that testing on Windows XP indicates that, if this is the first time a user has issued a call with the null container, what happens is the way TrueCrypt uses it, even though this is supposed to acquire a context, and normally you give it a pointer to the container that Windows will fill, you can also call it just saying, no, I don't need a context, that's not what I'm using you for.  And in fact that is the way TrueCrypt called it, with a so-called "null container," which is the second parameter to this call.  They say that the first call made to CryptAcquireContext will fail, while the second, which initializes a new keyset, will succeed.  And they said a later version of Windows tested appears to succeed on the first call, but this was not thoroughly tested.



So what they found was that, in a rather obscure case - and you'll notice that Matthew said that, and these guys said it, but no one's told us yet what that is - Windows XP could fail that call.  Then these guys went on and said, "While disturbing, this issue should not cause failure on common XP uses.  However, this is not the correct method of calling CryptAcquireContext, and it may cause failure on uncommon Windows configurations."



So first takeaway is all of the forked code should fix this because why not fix it?  This was a bug in the code that on Windows XP, in a rather obscure instance, this call could fail.  Now, I'll explain why, even if it does, we don't care.  But when does it fail?  So in their exploit scenario explanation for this first of four bugs, they said:  "A user creates a TrueCrypt volume on a company-managed machine.  Because of the group policy settings in place at the organization, TrueCrypt is unable to open a handle to a cryptographic service provider and falls back to insecure sources of randomness, potentially enabling brute-force attacks on the master key."  So in other words, if you had XP, and if you were in a corporate environment, and if that corporate environment XP machine was using group policy settings which prevented TrueCrypt from opening a handle to the cryptographic server provider, then this one source of entropy for key generation would fail.



Now, listeners will remember that I looked closely at the challenge of generating a large amount of entropy when I was doing what we called "entropy harvesting."  In fact, I think we did a podcast called "Harvesting Entropy" here [SN-456], talking about the solution that I found.  And our listeners will remember that the idea was that you use a vast array of different sources of entropy - counters, timing, unknown stuff.  And, for example, I am using the cryptographic API in SQRL.  I'm calling it, not incorrectly, and adding what it provides to the pool.



But at the same time, I'm pulling from innumerable other sources.  Very high-resolution timing.  I'm, for example, using the instantaneous number of clocks which have occurred at 3.4 GHz, which comes from the chip, bubbling up through the cache queue and instructions, so nobody on the outside can know what it is.  The point is that you always want multiple sources, all being sort of pooled together into one source.  And this was that idea that Peter Gutmann came up with and talked about in 1998 as a way of building an entropy pool.



So TrueCrypt, very much like SQRL, my solution, TrueCrypt uses the value from the CryptoAPI as one of many sources.  The other sources:  11 pointers to a variety of data structures.  Process and thread IDs enumerated from the instantaneous snapshot of that system at that moment.  Milliseconds since Windows was started.  The process startup time.  The cursor position.  The time of the last input message.  Flags indicating what types of messages happen to be in the message queue at the moment.  The X and Y coordinates of the input caret and the mouse cursor.  And remember that, during TrueCrypt volume creation, you're told to move the mouse around randomly in circles and crazy zigzag ways until you get tired.



And so it's sucking all of that in.  Statistics regarding the current memory usage and the working set such as the load measured on the system between zero and a hundred, total physical memory, available virtual memory, minimum and maximum working set sizes.  The creation, the user, and the kernel execution time of the current thread and process.  Network management data, and physical hard drive performance history statistics.



So, okay.  That gives you a sense for the quantity of entropy being collected.  So, yeah, it would be nice to toss a value from the Windows CryptoAPI into that also.  But if XP happened to have group policies in place that prevented it from doing that when you created a volume, oh, darn.  You got everything else.  And so the question is, is this sufficient entropy?  So what's being criticized here is the fact that there was a case in which one of these many sources might fail to add its value to the pool.  Good to know.  The forks of TrueCrypt might as well include it.  But I don't think anybody is in any danger from this.  That's the worst of the problems that was found is that one.



The second worst, which they considered severe, but high difficulty to exploit, is the AES implementation being susceptible to cache-timing attacks.  So what that's about is that, in order to accelerate the performance of AES - the Rijndael cipher, which is the one we like, very fast and bulletproof.  But in a hard disk, a full hard disk encryption system, nothing is more important than speed.  I mean, it's sitting there in the channel between your drive and your machine.  Every file you read, every file you write, the paging file, everything, is going through this encryption and decryption.  So you absolutely want that to be as fast as possible.  In order to speed up AES, precomputed lookup tables are created, essentially so that it's possible to replace a lot of computation with just looking at a precomputed value.



The problem is these tables typically do not comfortably fit entirely within the CPU's cache.  They're bigger than the cache size.  And if they did fit in the cache, then while you were doing the encryption/decryption, already cached values would be found in the cache and wouldn't have to be looked up again.  So it's when the values don't fit in the table,  you have a so-called "cache miss."  And very clever people are able to use this as a so-called side-channel attack, that is, say that they were running in a shared machine, is the example that Matt gave, where they don't have access to anything in your process except you are sharing a CPU, and so you're sharing the CPU's hierarchy of caches.  So apparently the attack involves them somehow getting the attacker able to get you to encrypt and decrypt specific information, and then them looking at modeling what's in the cache and using timing differences which they can theoretically detect in a shared environment in order to glean some information about the secret key which is loaded in there and doing your encryption/decryption.



So, okay.  That's the second worst problem.  And what it requires is that you have the volume mounted.  You've already given your password.  The system is up and running.  And then somehow some malicious code has access to fine-grained analysis of the timing of your processor.  So, okay.  It would be better if, for example, the new Intel instructions were used, which are available probably moving forward to forks of TrueCrypt, because that allows them to speed up AES without using large tables.  And so that makes AES more cache-timing neutral.



But remember that many purposes where you want your drive encrypted is the laptop turned off, sitting next to you at the airport, and you want to make sure no one can get into it.  So understand that the nature of this attack is while it's in use, while the key is loaded.  Remember that may be bad, if you've got malicious code, it's just looking at your hard drive.  If it's able to read your drive, it's reading it after TrueCrypt has decrypted it.  So again, this is an attack that you have to understand how high the bar is for exploitation, and that the typical use case is that you want your system when it's off to be absolutely safe from anyone accessing the drive.  When it's on and running, presumably you're there and using it.  Hopefully there's not bad stuff in there.



But, boy, even if you did have malware in your computer, it's easier for it just to read the drive because the drive is decrypted for it, just like it is for you.  So that's the second worst problem.  And again, in many cases, not to be - nothing that anyone needs to worry about, especially in the case of your secrets being kept when the system is not in use.



Now, these last two are, in fact, it's these guys who are paid to have problems even marked this one as "low severity" and "difficult."  So not only is not bad, but it's hard to do.  And that is, the keyfile mixing was found not to be cryptographically sound.  And I've got to say, I don't understand this because this is just crazy.



LEO:  If you don't understand it, we got no hope.



STEVE:  Well, what I mean is, I don't understand how the same people who engineered this other really good stuff could have done such a poor job with keyfile mixing.  And my theory is that, where there was a model they could follow, like Peter Gutmann's entropy pool, or using the existing XTS mode of disk encryption, where there was a model to follow, they did.  But unfortunately, when they invented something themselves, it was really lame.



So, okay.  So what are keyfiles?  Remember that we could either - okay.  So the results of all of that cryptographic API, moving your mouse around like crazy until you're done, or tired, or the mouse wears out, that's all generating a key which needs to be very random because that's the master key which will be used to encrypt the drive's contents.  Then your passphrase needs to be strong because it encrypts that key, that is, it encrypts the header.  And it's the header on the volume that contains the encrypted master key, which all that entropy went in order to create.  So inventing something else, they said, well, let's not just rely on the user's password.  Let's let them use keyfiles.  So this was a concept that may have been unique to TrueCrypt.



And TrueCrypt, remember, TrueCrypt had a predecessor.  I'm trying to think.  Was it DriveCrypt?  There was something before TrueCrypt.  I have it.  I mean, I was using it way back then.  And there was some argument over intellectual property rights and...



LEO:  Oh, yeah, yeah, yeah.



STEVE:  ...people got upset with each other and wandered off in different directions.  But so I don't know where keyfiles came from.  But the idea was that, rather than just relying on what the user entered for their password, TrueCrypt could also be told, "Go look at this file over in this corner."  We're not telling anybody, like we'll encrypt that in the header, too, so that, when I enter my password, the password decrypts the header.  But then you know to go read a keyfile and get all of that gibberish and mix that in, in order to decrypt the master key for the volume.  So the idea was it was just - you could use any other file or files in the system to provide more secrecy than just your own username or, I'm sorry, your own password.



So what they did was just lame.  So in the auditors' description they said:  "TrueCrypt allows the use of keyfiles that are included with the user's passphrase in the derivation of the key used to unlock a volume.  However, TrueCrypt does not mix the keyfile content into the passphrase in a cryptographically sound manner."  Which is just crazy.  I mean, they just fabulously produced entropy pool because someone else had designed it.  And unfortunately, left to their own devices - okay.  So I'll give our listeners a sense.  And those who are cryptographically astute are going to be groaning.  A 64-byte buffer is constructed, initially zeroed.  That's called the "keypool," that is used to hold the entropy generated from the keyfiles.  For each keyfile, a maximum of 1K bytes - I'm sorry, 1024 kilobytes, one megabyte - are read.



A CRC, a cyclic redundancy check, initially all Fs, all ones, and using the polynomial [some random polynomial] 04c11db7, is constructed.  So that's a polynomial for the CRC.  And for each byte in the file, it is updated.  Each time the CRC is updated, its four bytes are individually added into the keypool, modulo 256, and advancing, so the first time it updates bytes 0 through 3, the second time 3 through 7 - I wonder if they meant 3 through 7 or 4 through, anyway - and so on, wrapping around when it reaches 64.  The keypool output at the end of the first keyfile is used as the input keypool for the second keyfile.  Which just means they don't reinitialize that keypool if you give it multiple files.



So what I just read means that they just sort of made up a lame solution for turning a file into a 64-byte hash, essentially.  But they didn't use a hash.  They did this.  And it isn't even time critical.  So there's no reason.  This doesn't need to be fast.  And then it says after all the keyfiles are processed, each keypool byte is added, again modulo 256, into the user's password byte at that position.  So added into the password byte.  If the password is less than 64 bytes, the keypool byte in that position is used directly.



So then they wrote:  "The use of CRC in this way is not cryptographically sound.  When mixing entropy from multiple sources, an attacker who controls one source of entropy should not be able to fully negate or manipulate the other sources, even if the attacker is aware of what the other data is.  The use of a cryptographic hash function is the correct way to mix entropy together.  Assuming the hash function is unbroken, the best attack able to be mounted is a brute-force search for an input that, when combined with the uncontrolled input, yields a desirable output."  Which is to say it's not possible, as far as we know.



So, okay.  So that's my, I mean, the only way I can explain that something so randomly awful as this was used is that they came up with this themselves.  Or maybe it existed already.  Maybe they inherited it from somewhere else, and they didn't care.  Now, again, this doesn't matter because - okay.  So what would this attack scenario be?  These guys didn't even give one because there isn't one.  It would have to be, while you were creating your volume and supplying keyfiles, some attacker was seeing that, reading the key files, running this algorithm, and then changed a keyfile on the fly to negate the effect of the keyfiles.  And that's all I can imagine.  I mean, it's like, okay.  So basically these guys found something, you know, I mean...



LEO:  It's bad in practice, but not...



STEVE:  Oh, it's beyond bad.  They found a real turd in the middle of TrueCrypt, but in a place where it just absolutely doesn't matter.  I mean, it just - no one cares.  So it's like, okay.  Again, it's embarrassing, and it's inexplicable because the rest of TrueCrypt seemed - maybe it was a summer intern who did this, and they never looked at the code.  I don't know.  And then, lastly, the fourth and least concerning is that they did not authenticate - again, this sort of substantiates my theory because they did not authenticate the volume headers.



So the volume header is the thing they invented which contains the secret key, the decryption key for the rest of the drive, and some other housekeeping information, the size of it and where it is and so forth.  So the volume header and the volume data are encrypted separately because of course the drive is encrypted under the master key for the drive, and that's kept in the volume header, and it's the user's password that is used to encrypt the master key of the volume.



So again, they're using CRC32, and they're using, they've taken advantage of all this great cryptography throughout TrueCrypt, again, sort of where other people had solved the problems.  But here they just use a - so they use a header format where they have a header with a magic string TRUE at the beginning of the volume header.  Then they calculate a 32-bit CRC over the master key material.  So they CRC check the master key.  And then they do another CRC over the rest of the volume header.



And the problem is a CRC is not authentication.  I mean, CRC is useful for checking an error that occurs in communications.  The CRC checksum is what it really is.  A cyclic redundancy check won't match.  It's a high-accuracy, effective way of looking for, like, bits that were changed by noise.  But any attacker could easily create a change that the CRC would think was fine.  That is, you could easily defeat this.  So they kind of, I guess, I mean, we could just say that it was unauthenticated because it's lame authentication, and the proper way to do this is, again, with just a message authentication code.  We have all that crypto, all that technology.  It's trivial to do.  They didn't do it.



Now, does it matter?  No, because what can an attacker do?  I mean, it's the volume header.  In there is the key, but it's encrypted.  And so if they mess it up, then they just mess up the encryption.  So again, nothing to worry about.  What I've just given everyone are the big four problems.  And as we can see, none of them are really a big concern.



So the takeaway is, you know, thank you for the audit.  Everybody gained from this.  The people who have forked TrueCrypt will certainly look at these things and fix them.  And why not?  I mean, they might as well be better.  But in no way should anybody who is currently using TrueCrypt or would still want to use it in the future be dissuaded from doing so.  None of these are deal killers.



LEO:  And even more importantly, people going forward with forks have a really clear roadmap to make something that's a hundred percent perfect.



STEVE:  Yup, exactly.



LEO:  That's well done.



STEVE:  Exactly, fix these problems, and then you can say we fixed the things the TrueCrypt audit found, and we've extended it in all kinds of other ways, too.



LEO:  Of course then you have to have another audit of the new thing.  Make sure they didn't introduce anything.



STEVE:  Yeah, well, yeah, in fact, where did these guys come from?



LEO:  So here's the good news.  If you go to - what was the website?  Is TrueCrypt...



STEVE:  Auditedyet, is it, I think?  Istruecryptauditedyet.



LEO:  Let me just type it in and see, dotcom, and the answer is YES.  That's nice.  That's nice.  And there's all the information, as well.



STEVE:  Yeah.



LEO:  So it was a crowd-sourced project, Indiegogo, and the money was raised.  And Matthew Green, is he part of this company that did it?  Or what's the deal?  It's a different...



STEVE:  No.  No, no.  So he's with Johns Hopkins.



LEO:  Right.



STEVE:  And this is a group of three cryptographers, Tom Ritter among them.  Tom has a site, I think it's Ritter on Cryptography [CiphersByRitter.com].  Tom is a well-known cryptographer.  So it's just three guys who were hired and commissioned in order to perform this work.



LEO:  So that's who iSEC Partners is.



STEVE:  Exactly.



LEO:  Okay.  All right.



STEVE:  That's those guys.



LEO:  Got it.



STEVE:  The iSEC Partners, and they call themselves NCC or Crypto Group or something, so.  And they produced that PDF containing all the details.  So anyway, that's where we are.  It's where I expected we would be.  I'm glad for this.  I think TrueCrypt, if it works, continues to be entirely useful.  And in fact, I guess my feeling is I do wonder about the fork.  That is, I'm staying with TrueCrypt.



LEO:  Right.  We know what the flaws are in TrueCrypt, and they're not significant.



STEVE:  And, yes, we don't know unless we do, unless we find out exactly every single change that has been made to TrueCrypt since then, you know, absolutely better not have introduced any more problems.  And we know how easy it is to introduce problems.  I mean, it's just - it's too easy.



LEO:  Right, right.



STEVE:  It's difficult not to.



LEO:  So in your opinion, none of these four flaws make a hill of beans' difference.



STEVE:  No, not at all.



LEO:  Okay.



STEVE:  Exactly.  And what'll happen is, I think, what is it, was it when Mac OS X 10.10 came out, TrueCrypt's volume or TrueCrypt's version parser saw it incorrectly and said, oh, I won't run on that.  And I don't know about TrueCrypt on UEFI volumes.  And certainly we're probably going to lose it when we switch to Secure Boot.  So what's going to be happening is, its age is going to sort of age it out of use.  But while it's useful, if it works for you, it's still my first choice.



LEO:  Steve Gibson, you did it again.  You made us feel better at the same time as scaring the pants off us.  And I count on that in each and every episode.  Now, that's because - I'm really glad.  In fact, who would have thought we'd get here?  I felt like that was going to be a long - it doesn't solve the mystery at all.



STEVE:  No.  We still - all we have is conjecture.



LEO:  Yeah.



STEVE:  But as far as we know, one of the theories of their departure, which is they were afraid of the results of the audit, and so they wanted to distance themselves before that, that seems like absolutely zero likelihood now.



LEO:  Steve is at GRC.com.  That's where his SpinRite, the world's best hard drive, maintenance, and recovery utility lives.  Go there, buy it, support Steve's fine work.  But there's lots of free stuff there, including SQRL.  We were talking the other day, I hate passwords.  We've got to solve this.  It's fascinating.  He's got all sorts of stuff there.



STEVE:  Oh, I forgot to mention there was a nice TED Talk that was talking about authentication and identity and referred to SQRL as the solution to it.  So...



LEO:  That's great.



STEVE:  Yeah, so the word's getting out.



LEO:  Is it on the TED site?



STEVE:  I thought I had it in my notes, but it must not have made the transfer over to my Google Doc.  So I'll see if I can mention it next week.



LEO:  Yeah.  Or follow Steve on Twitter, @SGgrc.  He has all the information there.



STEVE:  Yup.



LEO:  You can also get to GRC.com for feedback.  That's where we're going to take our questions for next week's feedback episode, GRC.com/feedback.  He's got 16Kb versions of the audio  there.  He's got transcripts.  Elaine's fine.  She's writing - it was just an email glitch.  She's writing away.



STEVE:  Oh, I forgot to say, yes, there was never any problem.  I just didn't receive email from her.  She sent it; it didn't get to me.  And because I use receiving it to trigger all of the other downstream events, they didn't happen, either.  So anyway, she just - she was surprised I hadn't received it.  She sent it again, and then I immediately posted it.



LEO:  Right on.  Those transcripts are great.  A lot of times it's easier to read along while you're listening to the show.  We have higher quality video and audio of the show at our site, TWiT.tv/sn.  We put it on YouTube, too, YouTube.com/securitynow.  That's handy, I should point out, for anybody who wants to share a snippet.  The easiest way to do it is to scrub in the YouTube video to the part you want to share with somebody, whether it's on Twitter or in an email or whatever.  And then if you click the "share" button, it'll say, do you want to start at this point?  You check that box, and the URL will have the minutes and seconds.  And so you can actually share a little part of the show directly that way.  I think a lot of people don't know that about YouTube, but that's one of the reason we put every show we do on YouTube so that you can do that, if you want to share a little bit of it.



You can also get it wherever you get your podcasts, iTunes, of course, and all those places, or your podcast app on your smartphone.  And there are TWiT apps, too, thanks to our great and devoted community.  We thank you.  But that's about it.  If you want to be back next week, we do this every Tuesday at 1:30 p.m. Pacific Daylight Time.  That's 4:30 Eastern time, 2030 UTC, at live.twit.tv.  Watching live is fun because, you know, you can chat in the background.  We have a great bunch of people that are chatting.  We also have some great people in the studio [crosstalk].



STEVE:  And we have our Q&A, we'll do a Q&A next week, as long as the world doesn't collapse in the meantime, in which case we'll cover the collapse.  But GRC.com/feedback, and send your thoughts and questions and comments, and we'll share them and do a podcast about them.



LEO:  Did you see John Oliver's interview with Edward Snowden?



STEVE:  You know, I didn't.  I got a bunch of tweets about it.



LEO:  It's good.  It's on YouTube.



STEVE:  Okay, good, I'll check it out.



LEO:  It's very funny.  I think he cuts right to the core of the matter.  Instead of, like, a lot of airy fairy conversation about what it means and everything, this is what he's so good at.  He really brings it down to the personal level.  And you'll know what I'm talking about.



STEVE:  Neat.  I will absolutely watch it.



LEO:  Yeah.  Thanks, Steve.  We'll see you next week.



STEVE:  Cool.  Thanks, Leo.



LEO:  Bye-bye.



STEVE:  Bye-bye.	



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#503

DATE:		April 14, 2015

TITLE:		Listener Feedback #210

HOSTS:	Steve Gibson & Mike Elgan

SOURCE:	http://media.GRC.com/sn/SN-503.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Mike and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  The EFF wins its podcast patent challenge.  Steve will fill you in on a massive botnet takedown and update you on the Mac Rootpipe vulnerability and so much more.  Stick around.  Security Now! is next.



MIKE ELGAN:  This is Security Now! with Steve Gibson, Episode 503, recorded Tuesday, April 14th, 2015:  Your questions, Steve's answers, #210.



It's time for Security Now! with Steve Gibson, the show about privacy, security, coffee and more.  Steve, how the heck are you?



STEVE GIBSON:  Very good, Mike.  Everyone can tell from the voice that just introduced the show that we have Mike Elgan today co-hosting with me.  Leo is at the National Association of Broadcasters Conference, or Convention.  I guess he was a speaker over the weekend.  And so he's probably hobnobbing and on his way back.  But so Mike is filling in.  We have a Q&A this week, our 210th Q&A for Episode 503 of Security Now!.  And so we're going to hear from our listeners.  I found 10 great questions, which Mike will read and I will then answer at the second half of the show.  And we're going to cover the week's news.  I sent a note to Leo and a whole bunch of email addresses of the TWiT people who I normally send show notes to every week over the weekend because the EFF, our friends at the Electronic...



MIKE:  Frontier Foundation.



STEVE:  Frontier Foundation.  I can never remember that.  It just seems like an awkward acronym for some reason.



MIKE:  They'll always be EFF to me.



STEVE:  Yeah, well, so EFF.  Everyone's been a little bit on pins and needles over the podcast patent suits that have been launched by Personal Audio, I think was the name of the company, that is your classic patent troll.  So we'll talk a little bit about the news over the weekend.  We'll follow up a little bit on the CNNIC catastrophe with them issuing an intermediate certificate that was found in the wild to be itself issuing certificates, and how Google and others have reacted.  We now have some probably final results from the other browsers aside from Chrome.



There was also news of a massive botnet takedown that's sort of interesting.  A problem that has been fixed in the most recent version of Yosemite, Mac OS X, but apparently is not going to be fixed in older ones, known as the "Rootpipe" vulnerability.  Kaspersky, working with some authorities, got a hold of a whole bunch of decryption keys for some ransomware that we'll talk about.  The government, the U.S. government, is still trying to figure out how to negotiate with Silicon Valley and techno companies to find a way for law enforcement to be able to decrypt communications because they're just not happy with the idea that we could be talking, and they can't be listening.



And then I want to also follow up on what Leo and I sort of discovered on the fly last week about the disturbing ordering of cipher suites.  It was BofA that we looked at where the BofA server was, like, offering the worst possible ordering of cipher suites, and a lot of our listeners have followed up on that, too.  So a bunch of great news for the week, and then Q&A.



MIKE:  I don't know about you, Steve, but I can't wait.  I'm looking at some of this stuff, and it's so fascinating.  And we cover a lot of this stuff on Tech News Today, and the difference is that you provide answers.  On Tech News Today, we just scare the daylights out of people.  So Steve, so, now, we're going to go into this list of news.  Now, this podcast patent issue is one that's near and dear to all of our hearts because the idea that a patent troll could actually start mucking around with podcasting kind of gave us all the creeps.  But what's going on with this?



STEVE:  Well, so without getting into all the details because, I mean, this - I attempted to read the legal mumbo jumbo, and it just makes your eyes glaze over because they're literally parsing sentences for meaning, and you really need to have a deep background.  So I'm sure that Denise (TWIL) could probably take this apart a lot more.  What I did manage to figure out is that what was demonstrated essentially by just having the EFF and their intellectual property-savvy attorneys prepare a statement to the U.S. patent and trademark office, is that they found two existing prior art, as it's called, patents, which essentially rendered the patent that was being used by this Personal Audio LLC to be ruled invalid.



So, I mean, this is exactly what we expected when this first surfaced was that here was a company saying, hey, we invented podcasting.  And everyone's intuition was no, you didn't.  Certainly somebody has been doing something like podcasting for far longer than the date of this invention.  But it's one thing for us all in the industry to have an intuition about that, and another thing to be able to demonstrate it to people not involved in the industry, who are at the Patent and Trademark Office, who, if they don't see something clearly demonstrative that there isn't prior art, they'll just say, okay, well, yeah, this sort of seems new.  We'll say yes, and we'll let the courts decide.



And unfortunately, this has been the problem is that, for those of us who do "engineer" software, and I use that term as opposed to "invent" because most of the time that's what this is.  It is, if somebody trained in the practice is asked to solve a problem, we apply the things we know to solving the problem.  That's engineering.  And there are certainly moments of invention.  There are things that represent inventive inspiration.  I think maybe of the zipper or Velcro or something where, you know, you could be struggling with it for a long time and never come up with that.  And then someone shows it to you, and it's like, oh.  That's an invention.  Instead of something where 10 people are asked to solve a problem, and they just all solve the problem.  Which is not invention, it's engineering.



So anyway, the bottom line is that there has been a lot of angst surrounding this because these guys sued the three major broadcasting networks, and I think it was Adam Carolla was also named in the suit, saying that all of these entities were in violation of this patent troll's patent, and they wanted to collect licensing fees for podcasting.  And of course the danger was, if they had been able to prevail in those lawsuits, then everybody else, all other podcasters, then there would be precedent for this patent being upheld.  And it's easier in that case, rather than fighting a patent which has already been upheld, to probably capitulate and pay.  And no one wanted to do that if, in fact, these guys didn't have a true demonstrable intellectual property right for podcasting.



And there were two existing, I mean, basically it was shown this was going on already at the time that this other group, this patent that these guys had, was supposedly invented.  So they didn't invent anything.  Or if they did, it was already in the public domain.  And even if they didn't know about, the fact that it was known disqualifies them as having invented it.



MIKE:  Now, a quick note about patent trolls in general and how this works in the United States.  It turns out that the Eastern District of Texas is very - the judges and juries in that part of Texas are very, very friendly toward patent trolls for some reason.  And so what happens is that companies like Personal Audio LLC, they don't really have a company, they don't have a bank of engineers inventing things.  That's why they're patent trolls.  They just, they basically buy patents and then they sue.



STEVE:  Litigate.



MIKE:  Exactly.  So they get a P.O. Box in Eastern Texas and say that they're headquartered there.  Then this is where the lawsuits take place.  And then they oftentimes win lawsuits that they shouldn't win.  It's really an interesting, to me it's an interesting part of the dirty tricks that patent trolls actually use.



STEVE:  Yeah.  I saw a little blurb about that.  I thought it was funny, Samsung has been brought to trial there so many times and had such bad problems that they started to get much more involved in the community.  They're, like, major financiers of, like, the local stadium, and they've got Samsung brings happy times, you know, like logo stuff all over the place, basically trying to turn the actual citizenry in that area to be a little more pro Samsung so they'll lighten up on all of these bogus decisions that are being fought against. 



MIKE:  That's hilarious.  That is hilarious.



STEVE:  Yeah.



MIKE:  In a bad way.



STEVE:  So, oh, yeah, in an unfortunate way.  So we know from having covered this a couple times that at the beginning of, I guess it was about three weeks ago that alarm bells went off at Google when a fraudulent Google certificate was sniffed by someone's version of Chrome.  That immediately started an investigation where they found that a major certificate authority in China, in fact CN, as in the top-level domain abbreviation of China, CNNIC, had issued an intermediate certificate which allowed another company to sign certs on behalf of any domain they wanted to.



Well, that's an absolute breach of the trust that we put in a root certificate authority like GoDaddy, like VeriSign, or like CNNIC.  So Google's response, after supposedly performing some investigation, talking to the CNNIC people, and we covered this last week where Adam Langley updated his blog, I think it was actually April Fools Day, and he updated his April Fools Day blog posting where he said - I don't think he even used the word "agreed" because that certainly wasn't the way it happened.  But after a joint investigation, we've decided that we're no longer going to honor CNNIC's certificates.  We'll arrange some sort of a whitelist for existing ones, but basically we're putting them out of business.  The major browser on the Internet, which is now Chrome, will no longer allow secure connections to CNNIC customers.



Now, it may be possible to override those in some cases, which of course is a bad thing.  You don't want to train people to ignore security certificate warnings. But the HSTS technology, part of that forbids the user from overriding.  So in many cases you just won't be able to get to those sites.  And here's the key.  If they have a certificate issued after April 1st.  So apparently they're looking at the signing date, that is, Chrome is, April Fools Day of 2015.  And any CNNIC certs signed after April 1st will not be honored by Chrome.  So that bomb dropped.



And we did find a comment, very unhappy, that CNNIC posted in their own blog, saying that it was incomprehensible to them that this is what Google was doing.  I mean, it may have been a joint investigation, but it was certainly not a joint announcement.  CNNIC was, from all appearances, furious with this.  And you can imagine why.  I mean, basically, they are out of business.  No one is going to buy a certificate from them now because the majority browser on the Internet will not honor it.  So everyone is going to get any subsequent certificates somewhere else.  And so essentially this grandfathers in, by using the signing date, this grandfathers in the existing certs, but just says, you know, I mean, it's more than a slap on the hand.  This is, sorry, you're out of business.



MIKE:  Of course, Google said that they welcome CNNIC to reapply for trusted status, quote, "once suitable technical and procedural controls are in place," unquote.  And the other thing that's interesting about this, Steve, to me is that this is kind of the quasi-official Internet authority in China.  This is like, you know, this is...



STEVE:  Big.



MIKE:  I don't know what's comparable there within the United States.  But this is, you know, these guys are completely in bed with the Chinese government.



STEVE:  Yeah.  Yeah.  And the other thing we don't know from even the closest reading of what Adam posted, and I haven't seen anything in any greater depth anywhere else, you get the sense that what we're seeing is sort of the political frosting on top.  And something must have gone on.  And Leo and I were speculating on this without any facts because there aren't any, like what's the real story?  What actually - what don't we know that underlies this decision?



Now, here's what's interesting, and the reason I'm bringing this up yet again, is that we now are three weeks after the fact.  Apple has updated their root CAs in the most recent updates of the Mac OS and iOS.  And CNNIC's root is still there.  So Apple has not followed suit with Google, and it turns out neither has Microsoft.  Microsoft has taken to doing something that - actually we have a question in the Q&A today that I put in there before I ran across this update, where essentially Microsoft delivers certificates on demand.  And a fresh install of Windows 10 just yesterday was able to obtain a CNNIC cert from Microsoft on the fly.  So Windows, Microsoft's products are also still honoring CNNIC certs.  But Mozilla did exactly follow Chrome's behavior.  And as of Mozilla's most recent update, they, too, will no longer honor certificates signed by CNNIC after April 1st.



MIKE:  Now, it has to be said, Steve, that, you know, we follow lots of different stories that involve American companies and how they interact with China and the Chinese government.  And this general trend line follows what has happened historically.  So, for example, Microsoft really kisses the Chinese government's behind.  Apple kisses their behind more than any other company in the world.  They were under attack, Apple is under sustained attack from the official media in China over numerous issues that were all trumped-up, baloney charges.  They accused Apple of discriminating against Chinese customers.  They accused Apple of creating a security nightmare.



In every single case, Apple said, essentially, we sincerely apologize; we'll do anything you want us to do; whatever you say, we'll do it, because of course China is about to become Apple's biggest market.  This is one of the reasons why Apple is the most valuable company in the world is China.  And Google, on the other hand, has a history where they were even probably hacked by the Chinese government, and they left and moved their offices to Hong Kong.  So Apple is one of the few Western companies that has fought the Chinese government, and here is yet another case.  Although, again, this isn't the Chinese government, per se.  But they're not willing to do as much as a lot of other companies are in terms of bending over backwards to please the authorities, whoever they are, in China.



STEVE:  Yeah, and, of course, although Google is certainly a commercial entity, Apple and Microsoft are, I mean, their definition is we're supplying operating systems and solutions that need to operate globally.  And so, for whatever reason, they've just decided, hey, you know, a mistake was made.



I did also learn something that I never mentioned before, because I didn't know it, and that is that this intermediate certificate only had a two-week life.  So it was some sort of a brief testing certificate.  It's not like it was going to ever be alive for three years and all kinds of skullduggery could have gone on if no one had noticed.  It was due to expire.  It was issued for two weeks.  And so it was just during that brief two-week window that it got installed in this proxy that allowed it to sign a Google domain as part of its proxying an HTTPS connection that set off the fire alarms and the alarm bells.  So it even wasn't as bad as it could have been because CNNIC deliberately, under whatever terms and conditions, issued a two-week-long cert that wasn't going to be able to do anything after that time.



So anyway, again, my sense is there's, as you say, a lot of politics going on sort of behind the scenes.  And Mozilla, I guess, arguably the least commercial of the four, just says, you know, we're going to follow Chrome and just say we're not going to honor any certificates that are signed.  And certainly I would hope that CNNIC will do what they can to satisfy Google.  Then Google will say, okay, fine, we're satisfied, and they'll be able to go back to issuing certificates.



MIKE:  I also wouldn't be surprised if the Chinese government started a project again to - they're always trying to launch the Chinese OS, the China OS and stuff like that, and the Chinese browser.  They may want to try to go it alone because they don't like being in this position where a foreign company can do something like this and have power over a Chinese authority like this.  So I wouldn't be surprised if there's a newly revived effort, especially under the current Chinese leadership, to at least get Chinese users using something other than Chrome.



STEVE:  Yeah, I think that our topic for next week is going to be something know as the "Chinese Cannon."  We're all familiar with the firewall.  It turns out that this thing that was doing the big DDoS on GitHub and other sites has apparently some very strong Chinese backing.  And from an analysis of it, it looks like there is an actual technology, a device technology that has been dubbed the "Chinese Cannon."  And I want to go into the operation of that next week.  So, I mean, we really are seeing an escalation of tension on the Internet.



MIKE:  Yeah.  And as I understand it, and again, this is from a news perspective rather than an examination of the actual technology behind it, but my understanding of the "Great Cannon" is that they're taking incoming traffic from outside of China that's intended for Baidu, and they're redirecting it at a target like GitHub, like GreatFire.org.  And this apparently mimics to a certain extent NSA and GCHQ technology, which does something vaguely similar as part of a counterterrorism and surveillance effort.  And so I can't wait to hear your treatment on that next week because it's really a fascinating - this is the first time that, according to some of the people quoted in some of the, you know, Wall Street Journal and so on, that it's been sort of legitimized, this idea that you are rerouting traffic to do essentially DDoS attacks in order to censor the Internet outside of your authority.  So that's the part of it that's so fascinating is the Chinese government is censoring American websites.



STEVE:  Right, yeah, exactly.  They're able to generate essentially a reflection attack against properties, as you said, outside of their control.  Wow.



So a large botnet, which was known to have enslaved more than three quarters of a million machines, 770,000 computers spread across 190 countries, known as the Simda, S-I-M-D-A, Windows botnet was brought down through a collective effort a couple days ago.  This thing was very aggressive.  It was grabbing about 128,000 new machines per month.  It was being monitored by a number of people.



And, for example, I think Kaspersky has a list of the IPs which were known to be infected because they ended up tracking down the 14 distributed command-and-control servers located in The Netherlands, in the U.S., in Luxembourg, Poland, and Russia, and did a coordinated takedown of those 14 servers.  Well, if they're able to monitor those servers, they're able to get the IP addresses of all the infected machines which are phoning home to those servers for botnet instructions.  And so that's how they know how many machines are infected and the rate of infection.  The U.S. had the highest rate at 22%, almost a quarter of the total infections, followed by the U.K. and Turkey at 5% each, and Canada and Russia at 4% each.



MIKE:  We're No. 1.



STEVE:  Yeah, huh, exactly.  And the infections were exploiting known vulnerabilities.  So these are machines not being maintained, so probably not a large percentage of this podcast's or even the Twit Network's listeners, because these people are going to tend to be more tech savvy.  But so they were exploiting known vulnerabilities in Java, in Adobe Flash, in Microsoft Silverlight, in order to get themselves in.  And what was installed was a highly stealth backdoor trojan which was morphing itself every few hours in order to be essentially polymorphic, as the term is, in order to make itself continually undetectable from existing AV tools.



And what's really sneaky is, you know, we've talked about, just in the last couple weeks, we were talking about how websites that - in fact, it may have been in reference to the Chinese DDoS attack because remember that they were using, in that case, they were using the Baidu Analytics.  The Baidu system has an analytics system much like Google Analytics, where all sorts of websites all over the place have a little bit of JavaScript which is added to their page, which causes the user's browser to query and pick up that JavaScript, that then feeds statistics back to headquarters in order to generate stats, in the same way that Google Analytics does.



Well, what this trojan was doing was it was modifying the Windows hosts file for connect.facebook.net and google-analytics.com.  So where we were talking last week was this notion of all these little Facebook icons, the Facebook "like" icons that are everywhere now.  All of those essentially phone home.  They pull from connect.facebook.net.  That's where that little icon comes from.  So what that means is, if you get something in your machine which modifies the hosts file - as we've discussed before, the hosts file is the first place that Windows goes for DNS lookups.  Before it asks any external DNS server, it looks in this so-called hosts file that Windows still has.  And this hails from the original UNIX hosts file, which is where all of this Internet technology came from.  And any domain which is present in the hosts file is looked up in that file.



So the idea was that this backdoor trojan for the Simda botnet would put the IP address of one of these 14 command-and-control servers in the hosts file intercepting lookups, the user's machine's lookups, for connect.facebook.net and google-analytics.com, meaning that any website that the user went to that had a Facebook "like" icon or that had google-analytics running on the page in order to generate statistics and Google Analytics for that site, would actually end up connecting to the botnet and open a vector of control and potential infection.  So this was big and nasty.  And what it took was a joint task force of both private security companies and law enforcement to decide, okay, we've found them all.  Let's take them all down.  And that botnet is now out of action.  So, whew.



MIKE:  Nice.



STEVE:  Yeah.



MIKE:  Unbelievable.  That is incredible.



STEVE:  Now, there's a so-called "Rootpipe" is the name that's been given to this, a privilege escalation bug, which was responsibly reported in early October of last year to Apple by security researcher Emil Kvarnhammar.  I think I got that name about right.  And he named it "Rootpipe."  He discovered the problem because he was going to be going to a security conference, and basically he needed something to talk about.  So he just thought, okay, I'll just poke at OS X for a while.  And he did some binary code analysis and ended up finding this.  And just because he sort of wanted to.  I mean, he didn't stumble on it.  He said, "I need to find something to talk about."  So he plowed in and found this thing, told Apple about it.  Apple said, "Thank you very much."



Now, they're all very low key. They don't tend to disclose the way, for example, Microsoft does.  Apple just says, oh, yes, we fixed a few things; and, you know, don't worry about it.  So he tweeted on October 6th, a few days after talking to Apple.  He said, "Details on the #rootpipe exploit will be presented, but not now.  Let's just give Apple some time to roll out a patch to affected users."  So he did the responsible thing.  So it got patched with this most recent update that we had a few days ago.



But, somewhat controversially, Apple has said they're not going to patch earlier versions of Mac OS X.  They said that it required a lot of changing around of things and that it's just not worth their time.  So this has angered some people who for whatever reason aren't staying current with the latest version and are on earlier ones.  I have seen some documentation of an alternative.  And I was first thinking that I would provide links and some coverage, but it is a mess.  I mean, it's, like, not the sort of thing you want to go off and do yourself.



So the problem is the classic, or, well, the problem is that what Emil found was a way for software you run - now, this is not some guy in Romania is able to take over your machine remotely.  This is a local privilege escalation bug, meaning that it needs to be software running in Mac OS X which, if it's aware of this, that is to say, today that means if you have an older version of Mac OS X, it's able to give itself admin privileges if the account has them.  So this is the classic "Do not run with admin privileges."  Of course, for convenience sake, most people do. 



So what Emil's own explanation in his disclosure said, do not run the system under an admin privileged account.  Create a second admin account, maybe named admin, log in as the admin user, and then remove administrative privileges from the normal account that you normally use, then log out and go back into your normal account.  If you are a normal user, then there's nowhere for this to escalate itself to.  It can only escalate to the maximum privileges you have.  And if you've neutered those because you're not running as an admin, then there's nothing for it to do.



Again, this is fixed in 10.10, but not in earlier versions.  So, and I'm sure anybody who needs to who's a heavy Mac OS X user can find additional detailed instructions on removing admin privileges, if they're deliberating using an older version of OS X and choose to keep using it rather than staying current.



MIKE:  Now, Steve, is this a good idea anyway, just as a matter of course, to not...



STEVE:  Yeah.



MIKE:  ...run under the admin?  Because this kind of thing, you know, if you're under an admin account, of course, you're essentially open to do admin-privileged things.  Not just you, but malware, whatever.  So you've already - you've been recommending that people do this for a while.



STEVE:  Yes, it's standard practice.  And it's worth noting malware had been found that knew about this.  So this is a perfect example of, just because a security researcher has found it and responsibly disclosed it, doesn't mean that it wasn't found by bad guys or maybe gray hat guys.  I mean, you know, we presume that the NSA has all kinds of ways of getting into our systems, if they want to, because they're using things that haven't yet been discovered by anybody else and responsibly disclosed so that the manufacturer can resolve them.  And in fact, we've heard that Microsoft tells the NSA about things they haven't patched yet, which is a little disturbing.  I'm not so sure why that happens.



But, yes, standard operating procedure is that, I mean, and it's uncomfortable because it will get in your way.  But it's the only way to be safe, and that is, remove admin privileges from the account you normally use.  You normally only need them when you're installing software.  And so if, I mean, if your life is, like, being a member of the press, installing software all the time, then, okay, you don't have any choice.  Or actually there you really want to set up a VM and just use rollback, you know, set up a static image with a virtual machine and install stuff all the time in there and then just erase it when you're done rather than uninstalling things that you've installed.  It's just, you know, not safe to do.



But so my point is I can see situations where somebody just by virtue of the mode they're in has to be installing stuff all the time.  It may be less practical to need admin privileges there.  Although you can oftentimes just run as administrator during the setup and provide the administration password at that time in order to give that installation process admin privileges.  So it can also be made feasible.  But, yeah, this is another example of where you don't want to be in admin because it was possible for installation software behind your back to get those privileges and get up to some mischief with them. 



MIKE:  Good to know.



STEVE:  There's one ransomware, you know, we've talked about CryptoLocker and that ilk.  There's one called CoinVault.  And one of apparently several CoinVault servers were found, and the keys were extracted from it.  Kaspersky got their hands on the keys and has a service now called "No Ransom."  So it's noransom.kaspersky.com.  They don't guarantee - first of all, this is only for CoinVault, so it won't help you with CryptoLocker.  It's not like any - it's not a magic bullet for solving this problem for everyone.



But I wanted our listeners to know, if they or they know of someone who has been bitten specifically by the CoinVault ransomware, Kaspersky may have the decryption keys for you.  They didn't get them all, but they got a chunk, enough that it offers some hope.  So I wanted to make sure everyone knew:  noransom.kaspersky.com.  And you pulled the page up right there on the screen, so that's what it looks like when people go there.



There's been just another piece of news I wanted to share.  Nothing really coherent yet in this ongoing struggle that law enforcement and private industry have over encryption.  Everyone knows that several years ago I decided I was going to suspend my work on the product I was excited about.  I was going to do a really high-performance, you know, GRC-style VPN that would do all kinds of tricks in order to solve the problems that VPNs often have of not being able to establish a connection because of VPN-blocking software, and a lot of other features.  I called it CryptoLink.  I got a trademark.  I got the domain names.



But then I could feel, I mean, even before Snowden this was, it just felt to me like we were entering an era of tension where there were some early grumblings about whether the government was going to allow there to be encryption that they could not crack.  And of course then we've had the Snowden revelations that revealed how much of this surveillance was going on.  So there was a piece in Ars Technica where one of many proposals was discussed, and I thought our listeners would get a kick out of it, yeah, the split keying.  Just two paragraphs from the article.  I think it was - was it Dan Goodin who did the piece?  I can't see it on the screen there.



MIKE:  Yes, it is, Dan Goodin.



STEVE:  Yeah.  He does great reporting.



MIKE:  Yes.



STEVE:  He said:  "Critics have also raised concerns that any type of portal that gives government officials access to encrypted contents has a strong likelihood of backfiring.  They said criminals or spies from hostile countries may exploit the weaknesses to obtain classified or confidential data, possibly on a mass scale.  The split-key approach floated by Rogers" - who is the admiral or general or something, he's the head of the NSA, and he's been outspoken on saying, you know, I think he said something like, "We don't want a backdoor, we want a front door with lots of big locks on it."  Of course, he wants a means to have those keys.



MIKE:  And that's Admiral Michael S. Rogers with the NSA.  And he's said a lot of controversial things, and unsettling things, in my opinion.



STEVE:  Yes, yes.  So Dan writes:  "The split-key approach floated by Rogers, for instance, requires a complicated system to allocate the keys, deliver them to each involved party, recombine them when a legitimate court order is issued, and destroy" that key once used.  And so our friend Matt Green at Johns Hopkins, we're referring to Matthew all the time.  He of course, we were talking about, he was a subject of last week's podcast because of the TrueCrypt audit that we covered in detail.  So Matthew said, quote:  "Get any part of that wrong, and all your guarantees go out the window."



And so, continuing the last paragraph from Dan, he wrote:  "The approach is only one of several options being studied by the White House.  One alternative under consideration would have a judge direct a company to set up a mirror account so that law enforcement officials conducting a criminal investigation could read text messages shortly after they are sent.  To obtain encrypted photos, the judge could order the company to back up the suspect's data to a server while the phone is turned on and its contents are unencrypted."  And then the article ends:  "White House aides hope to report to the President this month."



So, lord.  I mean, I don't know.  This is - all I can say is we're living in interesting times because, I mean, this is binary.  Either the system will not have a means for third-party, under any circumstances, court order or not, it simply will not or it will.  It's binary.  It's not gray.  So it either will or it won't.  And the question is, are we going to see in the United States legislation mandating the binary decision that, yes, anything encrypted needs to have a means of court-ordered decryption, or are we not?  It's one or the other.



MIKE:  I have an overarching theory about the evolution of technology and its political consequences.  And typically the general theory is that, every time there's any sort of advance in technology, people in positions of political power will take advantage of that advance to change the balance of power between the public and the government, essentially.



STEVE:  Yeah.



MIKE:  And so this is a case, if you wanted to compare this to real life, this would be a case where the NSA would require that every single person wear a microphone 24/7 so that, even if they're out in the middle of the street whispering to somebody, that that could be accessed by the NSA.  And that's just my opinion.  I think that there has to - I think that, like real life, our digital lives, we have to be able to whisper things to each other sometimes and have secrets and privacy, just as a fundamental human right.



STEVE:  Yes, well, in fact, I think the best example of this is the argument that people say, why do you need privacy if you have nothing to hide?  And so the response is, okay, what about a camera in the bathroom?  Who's going to feel comfortable with that?  They have nothing to hide technically that's presumably going on in the bathroom.  But you have a right to privacy.  I mean, the argument is that the government shouldn't be able to see into our private lives where it's just private.



MIKE:  And that argument also, by the way, has implicit as part of an assumption behind that, that law enforcement and spy agencies are completely trustworthy, they never break the law, they never violate the Constitution, they never do any of those things. But of course we know with absolute certainty that there is lawbreaking, that there is abuse.  And so there really is no authority that is going to be perfectly trustworthy in perpetuity.  We do have to protect ourselves against official abuse.



STEVE:  Well, and of course anybody who has seen John Oliver's interview of Snowden understands the problem.  I mean, Snowden absolutely knew from first-person experience that there were a lot of naked photos being passed around the NSA because they got them, they had them, and they're just human.  I mean, and so there is a problem when humans are being asked to police other humans.  



MIKE:  Yeah, absolutely.  Absolutely true.



STEVE:  So it was either last week or the week before that we were talking about cipher suites.  And Leo put in Bank of America into SSL Labs' site and, in real time, on the air, we were stunned to see the ordering, the preferred ordering that Bank of America chooses, the idea being that, when a browser connects to a server, it presents the server with the list of cipher suites, the encryption algorithms, the encryption hashes, the encryption strengths, whether it's RSA or Diffie-Hellman, the key exchange technology.



Basically all of those are bundled up in a set of standards which each represents a suite of encryption technology.  The browser says, here's the list that I know of.  Then the server, the way SSL and TLS handshaking works, the server looks at the browser's list, and then from its own ordered list, meaning from most desirable to least, it uses its list to pick the cipher suite that'll be used.  And so all logic says that the server puts the strongest ciphers at the top and works its way down to the weakest ones because the logic in the handshake, the logic at the server side is it looks at the first one it knows about and looks for it anywhere in the browser's list.  Is it there?  No.  Okay, now the next one, and looks for that anywhere in the browser's list, is that there, and so on.



Well, it turns out that Bank of America, which was the only banking site we looked at, has the worst of all, like RC4 cipher, which has been roundly criticized and deprecated, with a short key length and bad encryption and a bad hash, I mean, it's just everything about it is wrong as its No. 1.  So if a browser offers that, just for the sake of compatibility, the browser doesn't ever want that to be chosen.  But it would rather that to be chosen than nothing.  So the browser might have that properly at the bottom of its list, not that the browser's list is ordered.  But basically it's in the list so that it's a possibility.  But it doesn't want it chosen.  Yet Bank of America sees that among the choices and chooses it first.



So we were just stunned.  I just wanted to acknowledge that many people checked their own banks, and apparently this is universal.  I got a whole bunch of tweets after that saying, you know, people were just like, oh, my lord, my bank is worse, is as bad as BofA.  So they were just tweeting their despair over discovering that their own banks were in as bad a shape.  And in fact, a question that I saw in the mailbag, I didn't choose it, only because we've sort of covered it, and I just have, was somebody saying, how do I explain this to my bank?  I mean, you know, I'd like them to fix this.  But who?  How?  You know?



MIKE:  Walk up to the teller.  Excuse me, I'd like to mention something.



STEVE:  We have a problem, you have a problem with your cipher suite ordering on your website.  So, yeah.  I mean, I don't know how.  Just maybe - I don't know.  Maybe there's a support email on the website, you know.  Maybe, if they get enough email from people saying that, somebody - it'll, like, percolate up.  I mean, there is no fathomable reason for that list to be as it is, except nobody ever curated it.  I mean, in fact, it's hard to understand how the server could have even been shipped that way.  But there's no reason not to put that at the bottom because, if no better cipher matches first, then it'll still be chosen.  But don't pick it as your first priority.  That's just nuts.



MIKE:  There's so much bad decision-making and bad design in websites for this exact reason, assuming that this is the reason, that is, that something was assigned to somebody who is not looking at the big picture.  They're just trying to go through their list, their checklist of things to do.



STEVE:  Get it done, yup.



MIKE:  And nobody pays attention, nobody follows up, nobody audits it, nobody, nothing, and it's just there forever.  And it's just a terrible state of affairs.



STEVE:  Yeah.  And unfortunately, as we know, the nature of security is a weakest-link-in-the-chain model.



MIKE:  Yeah.



STEVE:  That is, in order to have security, every single piece has to be secure.  And, I mean, I don't know how this ever changes.  You know, I've used the example over the years of firewalls, how the original design of firewalls was that it was all open, and then when something bad would happen, you'd close the port that that had been done on.  And so over time you'd close more ports as more mischief was being done.  Well, we've completely reversed the model now so that the firewall, all ports are closed, and you only open the ones that you know you need because it finally occurred to people, okay, we've been doing this wrong.  And the problem is it's not clear how we can get to the same sort of model with security.



As a consequence, if a website is not designed with every aspect of its security in mind, somebody will find, even with an automated tool that just goes scanning around websites, looking for problems, somebody will find an opening and compromise your web server and then use that to get into your network.  And then you've got another Sony Entertainment catastrophe.



MIKE:  Yeah, very true.  And usually the best way in is through users.  We covered on Tech News Today this morning two new reports from Verizon and Symantec, separate reports, both of which said that one common feature of these big hacks that we've been reporting on all year, this year and last year, is user error, usually phishing attacks.  Phishing attacks is the door to get in.



STEVE:  Yup, yup.



MIKE:  And it's difficult because you can either shut down attachments altogether and sort of hobble the usefulness of email or whatever, or you can train people.  But no matter how much training you do, the user is always going to be the weakest link.  And so that is, I think, a huge challenge.  And it's interesting to see these two reports say the same thing.



STEVE:  Yeah.  And in fact we've discussed, it was a Q&A two weeks ago, and we talked about it again last week, it was a fun question that someone said he was in charge of security for something like North and South Dakota something or other, I don't remember now what, or the north and south of something.  Anyway, he was in charge of security.  He had managed to convince his users never to click on links in email.  And he said, "But when I send them links, I get all this flak back now, which I guess is good because it means they've learned what I've been trying to tell them, except it's from me."



And so of course we explained that, yes, unfortunately, that many phishing attacks appear to come from your mother.  And so they don't because Mom's AOL account or Yahoo! account got breached, and something evil sent email out to everyone your mom knows saying, oh, this is the funniest cat video you'll ever see, you know, click here.  And because it comes from Mom, it's like, well, of course that's innocent.



MIKE:  But, you know, I think one of the most shocking things from our report today, we talked to Joseph Menn, we interviewed Joseph Menn, who's a reporter for Reuters, who covered these two studies.  And he said that, according to one of them, I think it was the Symantec study, you need to send 10 emails, only 10 emails, to have a 90% chance of success with malware.



STEVE:  Wow.  Yeah.



MIKE:  And of course it's free to send 10 or a hundred or a thousand.



STEVE:  Wow.



MIKE:  Incredible.



STEVE:  Yeah.  And, well, in fact we know that the massive RSA breach that we covered years back where RSA had their internal network, it was a persistent threat that had been in their network for a long time, and a third-party security firm was brought in, they did all the forensic studies, and they found an assistant had clicked on a link in a phishing email, and that's the way this APT, this Advanced Persistent Threat, got into RSA and to obviously devastating effect.



MIKE:  Yeah.



STEVE:  And as far as we know, same deal with Sony.  I mean, you just can't, unfortunately, you can't click links in email.  And it's interesting, too, because there was a lot of feedback in this week's mail bag about people's different suggestions and things they tell people.  And what I said last week, following up on this, was the only thing I could see that this guy could do is, if he was in charge of security within some organization, he could maintain a web page and tell people to manually type - make the URL simple so it's news dot security dot whatever it is dotcom, or securitynews dot whatever dotcom, just go there, and there you will find the link for the asset that I want you to click on, the idea being - and this is one of our other standard truisms is rules of conduct.  Never, never do something that is offered.



That is, for example, if you go to a website, and the website tells you your Flash is out of date, do not install it.  You didn't go seeking it.  It is seeking you.  And so don't click on something in mail to go somewhere.  Instead, you go there yourself.  So the idea being, you know, and I think this may originate with Brian Krebs.  If not, we saw it there first, and that was don't install anything you didn't go looking for.  If it's offered, just decline.



MIKE:  But again, that's a training issue.  And I don't know, have you covered the Dyre Wolf on this show?



STEVE:  No.



MIKE:  Okay.  The Dyre Wolf is something that IBM discovered recently, and it's a sophisticated fraud that combines phishing, malware, and phone calls.  And they've extracted a million dollars from U.S. companies, which is not a lot of money.  They kind of nipped it in the bud.  They're calling it the Dyre Wolf, but it comes from Eastern European cybercriminals.  And what these criminals were doing was they had a - it started with a phishing attack, malware attack.  So they get this stuff running on people's systems, employees within banks.  Or, no, I'm sorry, I've got that wrong, a bank customer.



So they get it running on the side of bank customers.  And it would sit there and lurk in the background and wait for the customer to go to the bank website.  And it would see the bank website, and here's the genius part of it.  It would identify the bank, grab the graphics from the website, and put up a fake website that looked like it was part of the bank that says, "We've got a problem with your account."  Okay, all this stuff is the kind of thing you'd expect; right?  If there's a problem with your account, we need to talk to you about it.  But don't do anything on the web.  Give us a call.  Here's our number.



STEVE:  Whoa.



MIKE:  And they had criminals standing by, and the malware would actually send the bank information to the operator so that, when they answered, they said, "Hey, Bank of America, how can we help you?  Oh, yes, yes, I see that your account is..." thing.  But, I mean, what do you do with something like that?



STEVE:  Wow.  Wow.



MIKE:  That is really sophisticated and very deep pockets kind of an attack where they're actually hiring a call center staff.



STEVE:  Yup.  And it also incorporates the whole social engineering side.



MIKE:  Yes.



STEVE:  I mean, it's one thing to just sort of click on a link that says you need to update Flash.  But as you say, this ups the ante because now you have what you're not normally going to get, which is, oh, I dialed a phone number, and I'm talking to a person.



MIKE:  And the fact that they told you don't do any of this over the Internet engenders trust.



STEVE:  Yes, and much more credibility.  Wow.



MIKE:  Yeah.



STEVE:  So two miscellaneous bits.  Tonight, thanks to all of our listeners, with any luck, although we know luck was not involved, Security Now! may be the winner in the Technology category of the 10th Annual Podcast Awards.  For anyone who's interested, that ceremony begins streaming live over PodcastOne.com beginning at 6:00 p.m. Pacific time, so that's 9:00 Eastern.  And we'll see who the winners are of the 10th Annual Podcast Awards.  Leo just sort of rolled his eyes when I said I wanted to do this.  I don't know, there's some history there.



MIKE:  Well, Leo doesn't like to do any sort of explicit promotion like that, self-promotion like that.  I tend to be highly self-promotional.  But Leo just - he just wants things to happen as they're going to happen, for the most part, and doesn't like this kind of explicit thing.  But, hey, if you win, that would be awesome and well-deserved.



STEVE:  Well, I've got two trophies, I have two trophies behind me from prior years.  And I haven't, we haven't done it for many, many years.  And I just thought, okay, this is the last time, just sort of as a show of strength.  Let's see if we can mobilize our listening forces and make it happen.  So I wanted to let everybody know because they closed on the 26th, I think it was, and now they've been counting ever since.  And tonight we'll find out.  And I'll mention who won next week.



And then the second note is there is a TV series that I turned our listeners on to several years ago that has been a huge hit within this community.  So I wanted to make sure, thanks to Randy Thomas, who tweeted from Rapid City, South Dakota, or maybe, actually, maybe it was in my email pile that I encountered, Season 3 of "Orphan Black" resumes this Saturday, April 18th.  So I know we have a huge following of "Orphan Black" fans who follow the podcast, and so this coming Saturday.  I checked, and my TiVo already knew.  It was in the queue, ready to be recorded.  So it will be interesting to have that adventure continue.  So I wanted to make sure that our "Orphan Black" fans didn't miss the beginning.



MIKE:  Very cool.



STEVE:  And I have another fan, in this case of SpinRite.  We have a French language speaker.  He said, "Hi, everybody.  First, I want to apologize for my imperfect English."  To which I always reply, well, it's way better than my, well, nonexistent French.  So I never have any problem with somebody speaking my language less perfectly because I don't speak theirs at all.  He says, "I'm French speaking.  I want to share with you my SpinRite story.  I purchased a license to SpinRite, mainly to support you.  I'm a big fan of Security Now!.  Anyway, I never got the chance to really test my version of SpinRite since I bought it.  I mainly use the program for maintenance," and he says, "preventative scanning."  And those obviously are of his various PCs.



He said, "A couple of weeks ago my Cisco Explorer 8300HD DVR," he says, "cable TV set-top box started to behave strangely."  And you might want to put up the screen that I have on the next page, Mike, because this is where he's leading, that is, the next page of the notes.  He said, "...started to behave strangely."  He said, "A lot of recorded shows would pause and skip frames.  In worst case, I got some shows that would not record at all.  I suspected the hard drive to be the problem, but since these devices runs on custom "encrypted" file system, it was impossible for me to run any usual programs like Windows ScanDisk.



So I plugged the DVR's HDD into my main PC and ran SpinRite at Level 2 on it.  When I checked the S.M.A.R.T. screen," you know, S-M-A-R-T, "I immediately saw the problem."  And then in the email that he sent, he sent this screen, which is here in the show notes.  He says, "The HDD," the hard disk drive, "was slowly dying.  I was lucky enough, the faulty HDD was the external one, the expansion.  SpinRite fixed it, and then I replaced it.  And since I can enjoy my recorded TV shows and feel confident" - oh, he says, "And since then I can enjoy my recorded TV shows, and I feel confident about my scheduled recordings.  Another example of how SpinRite can help in some unexpected situation.  Throw any disk at it, and let it do its magic."  I think his English is just fine.  He says, "Thanks, Steve, and all who work with you on SpinRite.  Steve Rodrigue."



So, Steve, thank you for sharing your story.  And what the screen shows, for anyone who's interested, is the scary thing is that red dot under, on the very top line, showing ECC corrected.  What's happening is that those three lines are three S.M.A.R.T., Self-Monitoring Analysis and Reporting Technology is what S.M.A.R.T. stands for, those are the three parameters which this particular drive publishes.  Not all drives publish the same things.  They're just based on make and manufacturer and what they feel like bringing out to the surface.  But those are the parameters that they publish.



The problem is that they only mean something when the drive is under stress, that is, when it's being used.  If the drive is just sitting there, you're not asking it to do any reading or writing or seeking or anything, then those parameters really don't mean much.  So it turns out that the use of S.M.A.R.T. and SpinRite are synergistic because the idea is these should not fall even in the presence of asking the drive to do anything.  After all, the drive should be able to read and write anything you ask it to.  That's all SpinRite is doing, essentially, is really giving it a workout, while turning off a lot of the things that tend to cover up problems so that SpinRite can see them and so that it can show them to the drive.



And so in this instance the ECC Corrected parameter has dropped, meaning that while SpinRite was reading the drive, the drive itself was being surprised by how much error correction it was being required to do.  SpinRite was able to get the drive to do its correction.  If the drive saw that a sector was worse than it expected, it would have replaced it, thus fixing the drive.  But ultimately a drive that's having this much trouble is screaming out, saying I need help.  And in fact the second, the lower half of this shows the total error correction count, which is a little on the high side, 2,321,837 up to whatever point this was.  And then SpinRite also shows the minimum per megabyte of data written and the maximum.  And that's another indication of a problem.  If there's a huge variation between the error rate, then that's a problem.



So here we see a minimum of 4300 and a maximum of 45, almost 46,000, meaning that there were some areas that were low, and others like rough patches.  You don't want rough patches.  You'd like the minimum/maximum to generally be pretty close to the average.  In this case they weren't.  So lots of indication here that, you know, it's not clear how much more life this drive has.  And in this case, Steve Rodrigue was able to have SpinRite fix it, and then he took it out of service gracefully after watching all the programs that were on it.



MIKE:  Unbelievable.  Another SpinRite success story.  Well, it looks like we are ready for the Q&A portion.  I love this.  I've been reviewing these questions, and I can't wait to hear what your answers are, frankly.  This is listener-driven potpourri No. 210.  And if you're ready, we can jump right into it.



STEVE:  You bet.



MIKE:  All right.  Well, the first one is a very, very basic question from Scott Nickles, who asked it via Twitter.  And here's what he asked:  Can you help me understand this?  How does WiFi assist location info on cell phones?  Of course, as we know, there are many ways for a smartphone to detect location, and one of them is WiFi.  But Scott is asking, how the heck does this work?



STEVE:  Right.  So I guess, what, all of the radios can potentially be used for location services, meaning that many smartphones now have GPS.  So if there's GPS, the global satellite positioning system, then that is obviously a way to get located.  And then, famously, and of course fodder for so many spy and techno movies, is the cell tower location, where we know that the way cell phones operate is that there are, scattered around, individual cell towers; that the whole concept of cellular technology is a multitude of short-range radio connections, rather than just like one monster antenna up on a huge hill somewhere that all of the cell phones talk to.  And so, clearly, it's possible to locate someone to some degree, first off by knowing what cell tower they're using.



But it's often also the case that multiple towers will be able to receive the signal from a single cell phone.  And so to some degree, by comparing the signal strength or the power level that the various towers are seeing, you can even get better than, like, what is the closest tower.  But, for example, there's a radio sort of midway between two, which would be the case if they both were seeing about the same amount of radio energy from the cell phone.  That's still subject to a lot of uncertainty.



What's interesting, though, is that, thanks to all of these crazy street view applications and mapping, one of the things that's happened is that WiFi routers everywhere have had their locations mapped.  That is, of course, this famously got Google in trouble in Germany when they were doing their Google street view and mapping technology, they were sucking in all of the WiFi signals of the routers in their immediate area.  They also had GPS so that they knew where they were.  And so what Google was doing was deliberately mapping which WiFi routers, sometimes by SSID, or by MAC address, because MAC address is supposed to be universally unique globally, and that's easily seen.  So Google built up a correspondence between location and router and router signal strength.  So that essentially, every single router that is within a region, its MAC address and location is known.



And I'll never forget, early in the iPad days, I had an iPad with no cellular radio.  And I was having breakfast somewhere and went to the maps application, and it just nailed where I was.  There was that stickpin sticking up with a little sonar circle going bloop, bloop, bloop.  And, I mean, it was exactly where I was.  And this was in the early days of this, and I was dumbfounded that I was located, with no cellular connection at all, exactly.  It's because I was within range of a standard WiFi hotspot, and the MAC address and probably SSID of that hotspot, its location was known exactly.  And so through this system of associating locations, the exact locations of WiFi hotspots, my location was known.  And all of this technology is now, you know, databases are available, and it's completely available to cell phones.



MIKE:  And clearly Apple is willing, too, because every time, oftentimes I turn off WiFi because my phone is trying to get a WiFi connection, and I just want it to go - I know that the WiFi is off the table, so I want it to just go to mobile broadband.  And it says, oh, wait a minute, are you sure you want to do this?  Your location needs the WiFi.  And I always think, wow, that's amazing that it's important enough to Apple to actually throw up an error message like that, just when I turn off WiFi.



STEVE:  Yeah.  Even, I mean, and these are not hotspots you're connected to.  That's the other point is in the same way that, when you are using a laptop, and you go somewhere, and you say show me a list of WiFi.  Well, there's often 25 things.  I mean, there's all kinds of crazy WiFi within range all the time.  And so, exactly as you say, Mike, it is so important to location because now there's a map of known router identities and location.  And I'm sure they're checked to make sure that they haven't gone bad, that somebody in Arkansas hasn't moved to California, and now their router is suddenly in the wrong state, because you would have to track that.  But the point is it's not even necessary to connect to these.  All of that information is just available in the air to any WiFi receiver which is just sniffing whatever happens to be available.



MIKE:  And this is one of the reasons why I was critical of the Germans for attacking Google over this point.



STEVE:  Yeah.



MIKE:  Because they made it seem like Google was reaching into people's homes and into their routers and routing around and looking around.  No, you're broadcasting that information out into the street.  And it's like putting a TV set in the window with your password written on it, this electromagnetic radiation conveying public information out into the world.  And if somebody wants to come along and take a picture of that, it's identical to what Google was doing with the Google street view cars.  But I was probably in the minority.  People didn't like it.  And it was all a big mistake or task or trial or something that was unauthorized anyway, apparently.  So what are you going to do?  Very interesting.



STEVE:  Well, you may have been in the minority, but I was with you because it was clear from - I remember looking at the software that was used, and it was clear that the engineer that put it together got that as a side effect.  They weren't even, I mean, they didn't care about what the content was.  And if it had been encrypted, fine.  The fact that it wasn't, wasn't their fault.  And the software logged this by default.  So it wasn't something that was turned on in order to be sneaky.  It was just, I mean, they weren't even using the information.  So I'm with you. This was a mistake, and this is something I think Google got into a lot of trouble with that was really unfair to Google.



MIKE:  Yeah, absolutely.  Okay.  So our next question, No. 2, from Gail Standig-Portman.  She had some info about the Configuration Mania Firefox extension.  And she writes:  Steve, in your last podcast you mentioned the Firefox add-on Configuration Mania.  I tried it; but it reset most, if not all, configuration changes I had already made.  I've just gone through them again, trying to reset them back to where they were.  You have a terrific podcast, but please warn your other listeners of this problem.  If someone wants to use the add-on anyway, it would be very helpful for him or her to make note of any previous configuration changes so it'll be easier to make those changes all over again from Configuration Mania.  Best wishes, Gail, a long-time listener.



STEVE:  So just as a public service, I wanted to absolutely make sure everyone knew.  Another listener wrote in, or maybe tweeted, about Configuration Mania because I was talking about this overwhelming list of options you get if you do about:config in Firefox.  I mean, it's astounding how many little tweaks there are now, so much so that you can't scroll through it, that you need the search bar there, and you type, for example, "OCSP" if you're looking for something having to do with certificate verification on the fly.  And it'll then reduce that to three items, and you can see what it is you want.



Anyway, so it turns out Configuration Mania, come to find out, thanks to Gail, when you install it, apparently it doesn't first read the existing set of configuration, if that's even possible.  Maybe it's not available.  But they certainly should warn you that any configurations you have made are going to be reset to default because this thing can only write to the configuration file, is unable to read it, presumably.  I mean, it's hard to understand how it would operate that way, but I absolutely wanted to make sure that no listeners got, if they would spend a lot of time, as it sounds like Gail has in the past, fine-tuning her Firefox config, and boy, there is plenty in there to tweak, I wanted to make sure that no one else got zapped.



MIKE:  Yeah, excellent.  Okay.  The third note here comes from John Reagan in Nicholasville, Kentucky, who had a correction on HP's Class 'A' network.  And John writes:  Hi, Steve.  In the last Security Now!, you said HP's Class A was 14.  In fact, it's 15.  And since HP bought Compaq, which had previously bought DEC, it owns 16, as well.  That was DEC's Class A address.  I wonder if HP knows how much money one of those class A networks is worth?  John Reagan.



STEVE:  So I actually didn't intend to be correct last week.  I knew that it was a low number like that, and I just sort of said 14.  So I really apologize because I should be more careful.  John is one of many people who corrected me.  So for the record, because I do care about being correct, HP is 15.x.x.x.  And I also knew that they had two consecutive ones.  John provides the information that they got 16 from DEC because DEC used to be 16.x.x.x.  And so I guess that's one good thing that Carly Fiorina did for HP is to double their Internet IPv4 space because, boy, those things are valuable.



We talked last week, Mike, about how there was a company, Jump.ro, I think that's - or "ru"?  No, "ro," it's Romanian - that has a whole bunch of IPv4 space that it's not using.  So they're selling them off and making millions of dollars because they're now becoming so scarce, and people are - and certainly it'll be an interesting shaped curve because the price is going to keep going up and up and up and up as IPv4 space runs out.  And the pressure not to have to actually ever, please don't make us move to IPv6, grows.  But at some point it's going to happen.  And then suddenly IPv4 won't be worth anything.  So, you know, there's a formula there.  It's like, okay, I want to hold onto my unused IPv4 right up until it hits just before the decision made to finally give up on not holding onto IPv4 and capitulate and go to IPv6, where there are so many ridiculous IPs that everybody gets to have a Class A network of their own to play with, and good luck to you.



MIKE:  It's like, so, yeah, absolutely.  It's like ber surge pricing.  If there's only one car left in town, you're going to pay for it one way or the other.  Okay.  So No. 4 we have from Matt DeWater in Auburn, Washington, who wanted to make sure about SpinRite and PCIe SSDs.  He writes:  Hi, Steve.  I'm looking at doing my next computer upgrade and have been considering a PCIe SSD.  Will I be able to run SpinRite on a non-SATA drive?  Thank you for everything you do.  Matt.



STEVE:  And I just wanted - I've seen a couple questions like that, so I wanted to assure everyone, yes.  First of all, you'll be able to run it under SpinRite 6 today because the BIOS will understand how to read that, and SpinRite knows how to talk to the BIOS.  What I'm doing in 6.1, which I promise to be back to as soon as SQRL is put to bed, and we're close on that, in fact just yesterday we eliminated a couple features that we decided we didn't really need, and so it got us that much closer.  What I'm doing with 6.1 is essentially finally ridding myself of the BIOS.  What that means is that I'll be talking to the hardware directly.  And the good news is there's a standard called AHCI, Advanced Host - I'm blanking on the name.  I know it so well, I can't believe it.  It'll come to me.  Anyway...



MIKE:  Controller Interface.



STEVE:  Controller Interface.  Advanced Host Controller Interface.  Thank you.  SpinRite, actually, where we left SpinRite was I was talking AHCI, allocating a huge amount, 32MB of RAM in real mode, which is a trick because real mode is supposed to be limited to that 640K barrier, 32MB, and transferring - we benchmarked it, transferring at half a terabyte per hour, meaning that it'll be able to run, do like a 2TB drive overnight, in eight hours, which will be a really nice performance boost.  It can actually do that in some cases with today's BIOSes, if they've been written well.  But that's the problem is BIOSes, many have just been neglected, and so SpinRite ends up having a problem talking through these older BIOSes.  But so absolutely, you can purchase PCIe SSDs with confidence, and SpinRite will be able to keep them in shape for you and recover problems when they occur.



MIKE:  Nice.  Okay, No. 5, Mark Grennan in Oklahoma City wonders why self-signed certificates are not "TNO."  He writes:  Hi, Steve.  You've been talking about SSL certificates a lot, and you've said a couple of times on the podcast that certificates signed by certificate authorities (CA) are more secure than self-signed certificates.  I'm paraphrasing.  But does this not break your TNO policy?  I feel that generating my own certificate for my private email server is more secure.  And wouldn't this be true for any private service, like company employees connecting to the company "X" service?  I understand that, for the general public, adding a "public" CA cert for every service they want to connect to would be too much.  And that is the question.



STEVE:  So, okay.  TNO, of course, is the acronym I coined years ago, Trust No One, which we apply mostly to cloud stuff where, like with Dropbox, if Dropbox is a service for storing your files, and they say, oh, you're able to get your files when you're on the road, just go to the website and log in, and we'll give them to you.  Well, that requires them to be able to do the decryption themselves in order to give it to you without having a client at your end.  So there are ways around that, but that's not Trust No One.  So Mark is applying the Trust No One test to certificates that are self-signed versus certificates where a third party whom we do trust has signed the certificate and is attesting to its authenticity.



In the example Mark gives, I would argue, yes.  If you're a private company, and you want to create a secure connection to an internal server, and everyone you need to have trust that certificate can do so, then there's no reason not to do it.  For example, the reason we use a third-party signer is that everybody in the world, for example, used to trust CNNIC.  Well, now only half of the people in the world trust CNNIC because of their misbehavior.  But the point is that the fact that there's global trust of the CA means that their signature extends that trust to the certificates they sign.  So it is necessary to trust the CA.



And so the perfect example is CNNIC, whom many people no longer trust.  If you sign the certificate yourself, then the problem is the rest of the world won't trust it.  They'll look at it and go, eh, this is a self-signed certificate.  Now, many people have gone to websites, and you're presented with, like, the notice, hey, this website has signed its own certificate.  So you could trust it if you want to, but we're not implicitly trusting it because the certificate was not signed by somebody who verified the site's identity.



And that's the point is somebody could have gotten that site's self-signed certificate and redirected you with DNS to themselves somewhere else and be impersonating them.  I mean, the problem is that, with a self-signed cert, you're trusting the person who signed it.  So outside of a local, like an Intranet, a corporate framework, no one's going to trust that.  Inside, with a private service, sure, you could say to your employees, hey, when you check email, and your email client comes up and says, hey, should we trust the certificate, just say yes.



And so you get a secure connection inside the corporate environment.  You're not having to pay a certificate authority.  Nobody outside needs to trust this service, and they wouldn't because the certificate is signed by itself, essentially, by you, not by someone that everybody trusts.  So it's sort of, you know, a choice you can make about who you want to trust the certificate.  And if it's local, then, yeah, you can get by with a certificate that you sign yourself.  And you don't have to pay anything, and you can set its expiration date way into the future, also.



MIKE:  You need to coin a new set of initials called N-O-T-U, or NOTU, which means No One Will Trust You.  I guess that would be a Y.  Okay, we'll work on that.  All right.  No. 6, Tom Etienne in Killeen, Texas, wonders about secure email providers in 2015.  He writes:  Dear Steve, it must have been a year ago I stumbled across Security Now! following announcement of the Heartbleed bug.  It was fantastic to discover a way to hear a deep examination on these topics given the limited amount of time I have for reading and research on my own.



I've recently begun to investigate alternate email provider options, given the exposure of Gmail and other similar large providers to both internal and external tracking.  While the features and convenience of Gmail are substantial, privacy remains questionable.  I can adopt just about any new tool or service that is available, but I am by no means a security science guru with the ability to audit their stated claims.



Some new email providers have arrived this year, such as ProtonMail.ch and Tutanota.de, to join alongside outfits like Hushmail.  I'm participating in the beta invites for these new sites, but wonder whether or not it is premature to shift the majority of my email communications through one or more of these services.  Review websites offer raves and rants about every service in existence, but I'm curious if you have any deeper insights or recommendations to offer about secure email providers.



STEVE:  So Tom's question is a proxy for a question that is asked so often.  I guess the problem is that people would like secure email.  And so the desire is to have secure email.  The problem is that email's underlying protocol never incorporated security.  I mean, there are variations.  One's called S/MIME, which is the formal secure technology, like the standards-oriented technology for adding encryption to email.  And of course, famously, PGP and GPG and so forth.  But those have just never quite gotten off the ground because the email protocol itself didn't require them.  So they don't get used by everyone.  And if they're not used by everyone, then you don't get end-to-end encryption.



So the problem with any of these so-called "secure email providers" - and, for example, after reading Tom's question, I thought, okay, let's just check in on ProtonMail.ch, just, I mean, because I hear about them all the time.  People are asking me about that in particular, that one in particular.  And so I go.  And it's a very pretty-looking website.  Lots of assurances about security.  No technical details at all.  So the first mistake they make for me is I can't learn what they're doing.  And our listeners of the podcast know that, if they're not willing to show us exactly what they're doing, then we're stuck.



A perfect example is a couple weeks ago I talked - or a perfect counter example is I talked about miniLock.io, which is that fabulous little public key encryption add-on for Chrome and the Chromium browser and Chrome browser.  And, I mean, it's fabulous.  And there on the page was a complete disclosure of the way it works.  And I was able to read that, know that he had done it exactly right, and represent that to our listeners.  And it's, like, our listeners are crazy about it because they understand from me how it works, and it was done right.



Now, here's ProtonMail, for example, that waves their hands around and has a very glossy-looking, pretty website.  But they're not telling me how it works.  And the problem is they're also not making it clear that, unless every party in the email is using ProtonMail, then you don't have security.  That is, they play up the connection that you have to their server and how that's secure, and they don't have the ability to decrypt your email, all that good stuff.  Except the problem is, if your email is going to someone else who is not a ProtonMail user, and you haven't explicitly enabled a feature that sends that party a link which brings up a web page to allow them to decrypt the mail that you're sending them, then it's decrypted and sent as regular insecure mail.



The point is, this is all incredibly awkward because email is not fundamentally secure.  It just isn't.  And everybody wants secure email.  It's a nice-sounding phrase, "secure email."  But email isn't secure.  The protocol never had it.  And so I guess, you know, so I look at something like miniLock.io and say, hey, for those specific instances when I need to encrypt something, this is the way to do it.  I can send somebody my public key.  They send me theirs.  I encrypt something for them.  They can decrypt it because it came from me and was encrypted for them.  It's solved.  The problem is solved.



So if you want everything you send to be secure, now you've got a problem because the only way that happens is if you are sending email to somebody else who is a ProtonMail subscriber, that is, or who is using the same service, and if we believe their assertions.  They're not telling us what their technology is.  There's no description that I could find of how this works.  So we have to simply believe their representations.



And the problem is, even if their heart is in the right place, they may have done it wrong.  We covered a few weeks ago that service that was offering web-based encryption, but was not doing any authentication.  Clearly, they were trying to do the right thing, but they didn't do the crypto right.  Because they told us what they were doing, I was able to say, well, nice first try.  They didn't do the crypto right.  And then they fixed it once, and then they still didn't do it right.  The point is, because of the full disclosure, we could tell and say, eh, it's not ready yet.



ProtonMail, who knows?  Maybe it's secure.  It's certainly only secure if everybody you're sending to is also a user, or if you use that option where it simply sends them a link, and then they have to go and retrieve the email, essentially, back on the ProtonMail site.  But I'd feel more comfortable if a security-based email provider offered a technology whitepaper saying this is the way we implemented our security.  Then someone like me, or anybody else who understands crypto, could look at it and go, they did that right.  They probably did.  Maybe.  But it's just as likely that they made some mistakes.  Which if they would show us, we could help them fix.



MIKE:  Great point.  Great point.  Okay, No. 7, Rafael Beraldo in Brazil has a routable IP from his college.  And he writes:  Hi, Steve and Leo.  Last episode Steve mentioned that Jump.ro, a Romanian company, is selling IPs like crazy because they're worth a lot of money right now.  Older universities also often have a lot of IPs they're sitting on, and mine is no exception.  But this week I noticed something I'd never realized before.  Whenever I connect to my college's wireless network, I'm given an IP on the Internet, and not anything like 192.168.042.042.



While I understand there are advantages - I can run my own services on low ports, for instance - I'm still concerned about the implications of having a public IP address.  I run Arch Linux and make sure there aren't any services such as SSH running when I'm on a public network.  But on the other hand, my Android smartphone, which is connected to the same network, has a public IP that's easily scannable.  That's crazy.  I feel kind of scared that this is the case, even though the network's gateway probably has a firewall.  So how should I feel about this?  I mean, it is easy to find the address space given to a college and then scan all devices for vulnerabilities; isn't it?  Thanks for reading.  Rafael.



STEVE:  Yeah, I loved this because it was my own, in fact, we coined a term, a "Gibsonian response," where you just sort of shudder.  And it's interesting that I have that response when I imagine that the network I'm on is publicly routable.  I guess it's because I am so used to being behind routers, that is, you know, private routers, that the router has a public IP.  I have a 192.168.something.something, or in my own case I use 10-dot as my network.  And even at the datacenter where I have our co-located servers, all of those systems are 10-dot, and there is explicit IP mapping going on in order to make individual services available that I want to make publicly present.



And so the idea that a smartphone, especially, as Rafael says, his Android phone, the idea that it has a routable address means exactly as he knows and wrote, that a scan of the Internet is going to scan the device he's holding in his hand.  And if there's anything flaky in it - and my lord, when is there not something flaky in these devices?  We're constantly talking about, for example, how backdoors are being found in routers.  Well, it's only recently that Windows finally had its firewall turned on - well, recently, XP SP2 - that the firewall was turned on by default.  But initially it was there, but not even on.  And we know that, if you take one of these machines and stick it on the Internet, it'll be taken over immediately.  There's still Nimda and Code Red out there scanning, looking for machines.



So I love, and I just take for granted now, that there is a router which is inherently a hardware firewall.  Nothing that is unsolicited, no incoming unsolicited traffic goes anywhere.  Only conversations that are initiated from inside to the outside create a dynamic map through the router such that returning traffic has a place to go.  It goes back to the initiating computer on the inside network.  I'll tell you, I mean, were I in a situation like that, I would get one of these little mini routers.  I know that D-Link has one.  They're called travel routers.  Or just, you know, you could use any router, actually.  But for some reason I just think of a travel router.  Let that get the public IP address, and then you use its WiFi and/or wired network that is going to be protected, and then you know that you're not subject to attack.



Boy, I mean, and even if the college has a firewall, what about all the mischief that other people within that firewall boundary can get up to?  That is, you're looking at an Intranet.  There may be a firewall on the border.  But presumably all the machines within that campus environment can see each other and are able to scan each other.  That would just - I'd absolutely be behind a router because they're like doorstops now.  You can just find them lying around.



MIKE:  And of course, if you get a Gibsonian response to anything, you should be looking into things, as well, out there in Security Now! land.  Okay, No. 8.  Jim Fletcher in San Francisco was left a bit lost about TrueCrypt and keyfiles.  He writes:  Dear Steve, I was delighted with the TrueCrypt audit results and your great explanations on the show.  This is great news and just as you predicted.  Does using keyfiles in TrueCrypt make the encryption weaker?  I love the concept of keyfiles.  I make up a unique keyfile, for instance, a picture, which will of course be a unique file, then keep it on a thumb drive.  It's two-factor authentication, and the thumb drive can even be kept in a safe.  Brilliant idea.  But since it's such a poor implementation, does it in some way weaken the encryption of the TrueCrypt container or partition?  Great show, great product - SpinRite - and best hosts in the world.



STEVE:  So, great question, Jim.  There were four problems that the crypto auditors found in TrueCrypt.  And I think it was the weakest one, the least concern, or the second to least.  There was that the headers of the containers did not have strong authentication, they just used a CRC technology.  That was one of the two weakest.  The other was this issue of keyfiles, which was they were unimpressed by the way the keying material was merged in with the user's password to create the key that would unlock the header.



So, and the short answer to Jim's question is no, it in no way weakens anything.  This was them being crypto purists, which I completely understand.  What they explained was, because the keyfiles were being combined in a way that was not cryptographically sound, it would be theoretically possible for an attacker who was present at the time the partition was being set up, at the time the keying material was brought together, when the user said, "I want to use this photo along with this password to encrypt this container," at that moment bad guys could look at the contents of the picture and come up with a nullification, come up with a modification that would nullify the contents of the additional keying material that the picture represented.  You could not practically do that if the picture was hashed because, if you're hashing a bunch of things together, the point is it is not mathematically feasible to come up with additional material that creates a given hash result.



And but these guys, the TrueCrypt authors, didn't use a hash, for reasons no one could understand.  They used a simple cyclic redundancy check, a CRC.  And it is absolutely possible to mathematically compute a way to reverse, like to create any output from a CRC that you want to.  It's trivial.  But the point is, even then you have to be present at the moment this is all being done.  I mean, it's not even clear, they didn't articulate an attack.  They just said we don't think this is very good.  But they didn't even say how you could use the fact that it wasn't very good because you actually can't.  But it's true that it's not very good.



And so this is really the only use for this is people who are forking the TrueCrypt source.  They could look at the audit results, and I'm sure they have, and go, oh, yeah, we'll use a hash.  Problem solved.  So, Jim, this is nothing to worry about.  You absolutely have strong multifactor authentication because no one was present, no bad guy happened to be watching when you set this up.  And now you've got a picture, and nobody trying to crack your computer is - even if your password was weak.  And that's what this is protection for.  You could, you know, your password could be "Hi Mom," and the bad guys could guess "Hi Mom," and it wouldn't work because they don't have the unique picture which is your second factor that goes along with your weak password in order to strengthen it.  So you've got great protection.



MIKE:  Great news.  Okay.  No. 9, a listener in Asia requesting anonymity wondered about corporate man-in-the-middle attacks and EV or extended validation certificates.  He writes:  Hi, Steve.  Today was the day that my employer put an appliance to filter SSL traffic into production without telling anyone beforehand.



STEVE:  Oops.



MIKE:  After one of my development tools with pinned certificates broke, I could quickly verify with your Fingerprints webpage that my employer was spoofing SSL certificates.  Your website was also handy to explain to colleagues what was going on.  Two things really surprised me, and I would love to hear your opinion.  No. 1, I noticed that my employer did not seem to spoof EV certificates, e.g., GRC.com's EV cert was not spoofed, while Google.com's non-EV certificate was spoofed.  I'm wondering whether there would be any technical reason why they would not be able to spoof EV certs.



No. 2, while Chrome on Windows seemed to be perfectly happy with spoofed certificates, Firefox was extremely unhappy, thanks to its independent certificate store.  This makes me wonder what the reasons might be that Google Chrome tolerates corporate certificate spoofing.  I'm also wondering if Google has anything in the pipeline for Chrome to make it easier to detect corporate certificate spoofing or even prevent it.  If you pick my question, please don't mention my name.  Thanks.



STEVE:  So I actually, when I was putting the Fingerprints page together, I encountered something that I had not been aware of, or I think I remembered it, but I never really wrestled it to the ground.  And that is that another unique feature of extended validation certificates is that a characteristic of them is that browsers have the EV root specifically embedded in them.  That is, it is specifically for the purpose of preventing this kind of EV certificate spoofing that browsers do not rely on the standard CA hierarchy.  They pin the signing of those certificates to the certificate signers, and they incorporate those certificates.  So Firefox is refusing to - well, okay.



So first of all, everybody is refusing EV certificates except Internet Explorer.  For a reason that I cannot fathom, Microsoft has made it convenient to set the EV character or characteristics in certificates that people, like in corporate environments, make for themselves.  I have no idea why a corporate user - I can understand why they want to make their own certificates for their own servers to use on their Intranet. Why they have any need for, like, essentially fake extended validation, I will never understand.  I think this is a horrible mistake because extended validation needs to mean something.  And the fact that Microsoft lets people make their own certs and turn that on - it's there in the user interface, click this button if you would like extended validation - is beyond me.  So IE is consequently worthless for actually detecting this.  But Firefox is now probably the strongest browser for that.  Chrome is no longer because Chrome uses Windows built-in certificate store.



So the reason that this listener saw that Google's Chrome did not mind spoofing is that they're in a Windows environment, and a group policy was pushed out through the Intranet, forcing every machine at logon to accept this spoofed certificate from the proxy which is now intercepting SSL communications.  That's why nobody had to agree to anything or click anything or say yes, I trust anything.  It's possible for Windows systems to acquire certificates through the group policy system.



So suddenly all the systems in the Internet this morning, when booted, acquired this new certificate.  And IE trusted it because it's in the Windows root store.  Chrome trusted it because Chrome uses Windows' root stores for its certificates.  Firefox said, what the heck, I'm not trusting any sites because I don't know what the certificate is.  So Firefox you can trust.  Safari I believe you can trust.  And probably Opera, although I think, now that Opera has switched over to use the Chromium codebase, it's probably now also no longer trustworthy for this.  When I wrote that page, it was, but probably no longer.  So that's what's going on.  Basically EV is an extra level of useful test, but you need a browser that'll complain about it.  And I'm afraid that only Firefox provides that assurance now.  Unfortunately, Microsoft has allowed their own certificates to have EV flags turned on for reasons, as I said, I just can't fathom.



MIKE:  All right.  Well, No. 10.  John Bailey in Villa Park, Illinois wonders about the relationship between the CA list in browser versus the CA list in the operating system.  He writes:  Steve, in Security Now! 501 you and Leo talked about the CA lists and how to delete them, and also why it's probably not worth the effort.  I looked at the CA list in my Firefox 37.0 browser and found the Hong Kong Post Office, et cetera.  I looked at the Certificate Manager utility in my Windows 8.1 Surface Pro 3 and found a modest list of 24 CAs and 40 certificates.  How does the browser's list relate to the Windows 8.1 list?  By the way, my bank, BMO Harris, looks worse than BofA when you run the SSL Labs test.



STEVE:  Yup, so there was another listener who, like, looked at his own bank after we brought the attention to BofA, and it's like, okay, how could it be that they are, like, I mean, why banks?  You'd think that's where security would count.  But maybe not.  Okay.  So this is really interesting.  I talked about, years ago, discovering 400-some CAs, certificate authorities', certificates in my Windows XP root store and thinking, oh, my god, I had no idea we were trusting this many random people, like CNNIC and Hong Kong Post Office.  Just, I mean, actually Hong Kong Post Office has been the whipping boy ever since because it's like, what?  Why am I trusting anything that the Hong Kong Post Office decides to sign?  But, you know, we are.  Firefox is using that model, that is, the browser brings the certificate store with it.



What I learned when I installed Server 2008 R2, which is the server I upgraded my servers to the holiday season before last, so Christmas of 2013-2014, I looked at the certificate store.  And just as John saw in his Windows 8.1, it was almost empty.  And, I mean, this was a brand new installation.  And it was, like, maybe it was empty.  And it was like, wait a minute.  What happened to the certificate store?  I did some research.  It turns out Microsoft has changed the way they operate.  And I don't really understand the logic.  But they now have, since whatever, since certainly Windows 2008 R2, an on-demand certificate root store.  That is, when your browser goes to a site and gets its certificate, it follows the chain and asks Microsoft on the fly for any certificates not provided in the chain, and the root certificate that by definition cannot be in the chain, and says, "Hey, I'm being asked to trust this certificate.  Should I?"  If so, on the fly, Microsoft provides that to the system.



So this is actually very elegant.  I can't explain it.  Because what it means now is, rather than having a ridiculous number of certificates that you're absolutely never going to need, you only get the ones that you need.  So John, while using 8.1 for some period of time, only encountered 24 different certificates that he actually needed in his root in order to trust all the sites he's been to since he started using that system.  And that's the point that I was making a few weeks ago where I said, boy, you know, there are hundreds of certificates, all of which we're trusting.  And the problem is very few are needed for most people.  And this paints a perfect real-world example of that.



Now, the problem is you will get from Microsoft any certificate you need.  So this isn't actually providing any protection.  It might, if it prompted you with a dialogue box saying, hey, you've been using Windows for a year, and you've never asked for this certificate before.  Are you sure you want to add it to your store?  We're happy to, and up until now we've been doing them all automatically for you, but we thought, yeah, you know, things have settled down after a year.  Maybe you want to - now maybe we should ask you.  That would be nice.  Microsoft doesn't do that.  And Microsoft does recognize that getting them on the fly might be a problem.  So there is a knowledge base link you can click to get the entire 400-plus blob of CA root certs and dump them all in at once, if for some reason you don't want to get them on the fly.  I think getting them on the fly is cool, not to just have hundreds of extra certs that you are absolutely never going to need.



So that explains the mystery, John.  That's the relationship.  Firefox, being its own store, has to bring them - I guess they could do the same thing, but they don't.  They just bring them all along, and they're there.  There will be a little bit of a time penalty when you're making that first connection to a site using a root whose CA you don't yet have loaded in your machine because your machine has to go ping the mothership and get that cert and then install it and verify the chain of trust and then say, okay, yeah, fine, we're good to go.  But, you know, that's only the first time per CA.  And you'll very quickly acquire all the ones you need, as John has demonstrated.  But Firefox just brings them all along, as  has been the way it operates traditionally.



MIKE:  And that was No. 10.  My gosh, this is a great show, and it's so great to not only be able to listen to it, be able to participate in it.  Normally I just listen while I'm doing the dishes.  So this is really fantastic, Steve, and it's such a privilege to co-host the show with you.  Any parting thoughts, before we close this thing out?



STEVE:  No, I just wanted to say it's been great working with you, Mike.  It went smoothly, and I think we did another great podcast together.  So next time, I'm sure there'll be a next time.  I think Leo keeps talking about trips that are coming up.  So hopefully we'll be seeing more of you on the podcast.  Love to have you back.



MIKE:  Yeah, we should send them off to some fabulous vacation somewhere so I can do the show again, absolutely true.  And of course tonight is the big podcast awards, and I'm rooting for you.  And you should win.  And if you don't win, there is just no justice in the world at all, as far as I'm concerned.



STEVE:  Well, I have a feeling we've stacked the deck because we had a lot of listeners who were saying - and, I mean, it was crazy, too, because for some reason they were, like, vote often, vote early.  Vote early, vote often.  You could vote every day.  It's like, what kind of a voting system has everybody, like, I mean, and they would ask you for your email.  I voted for myself, I'm not ashamed to admit.  I wanted to win.



And so I used my Gmail account, and I got a confirmation, and I clicked on the link to verify.  And then I came back within 24 hours, and they said, oh, it hasn't been 24 hours.  So okay, I waited another hour or two, then I voted for myself again.  I didn't do it every day.  But still it's like, that's just loony tunes.  Why wouldn't they just get one vote per person?  But it's not the way they wanted it.  That's not the way they set it up.  So maybe they figured that asking people, giving them the opportunity to vote every day would be a more accurate gauge of people's fervor.  I don't know.  We'll see what happens.



MIKE:  Well, I mean, I just think there's been a lot of acceptance for that kind of thing because of online polls, of course, are just like that.  You can vote as often as you like.  But if somebody's going to stack the deck, it might as well be your audience.  So somebody's got to do it.  Anyway...



STEVE:  So we may talk about the Great Cannon next week, China's Great Cannon.  The technology is staggering, and there's some neat diagrams of it that are up now.  So unless anything else happens between now and then, I think we're going to go into this interesting sort of escalation of the international Internet arms race and how it works and what it means.



MIKE:  Yeah.  I'm looking forward to that because I need answers, answers.  Leo and Steve do Security Now! at 1:30 p.m. Pacific, 4:30 p.m. Eastern, 2030 UTC every Tuesday, right here on the TWiT network.  Of course you can watch live at live.twit.tv.  Or you can subscribe at TWiT.tv/sn, or on the podcasting app of your choice, or both, whichever you choose.  So this is another exciting episode of Security Now!.  Thank you for tuning in.  And you will see Leo and Steve back here next week.  Thanks for joining us.



STEVE:  Thanks, Mike.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#504

DATE:		April 21, 2015

TITLE:		Great Firewalls & Cannons

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-504.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I catch up with the most interesting and significant security and privacy news of the week.  Then we take a close look at what's known of the mechanisms China has developed - both filtering and offensive weaponry - to provide for their censorship needs and to potentially attack external Internet targets.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Yes, as always, the news ripped from the headlines of today's paper including the Great Firewall of China, and now the Great Cannon.  How do they work?  Steve explains all, next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 504, recorded Tuesday, April 21st, 2015:  Great Firewalls and Cannons.



It's time for Security Now!, the show that protects you and your loved ones online.  This guy is the Great Firewall of Gibson.  He protects us all.  And you know what I love about this show, you also listen and learn.  He's a great teacher.  Thank you for being here, Steve Gibson.



STEVE GIBSON:  Hey, you know me, this is a pleasure.  On the 500th episode I thanked everyone for their being here because they're always thanking me.  So, and I know that this is a useful couple of hours that we spend every week.



LEO:  Useful, fun, and enlightening.



STEVE:  Yeah.



LEO:  And, by the way, thanks to Mike Elgan for filling in last week.



STEVE:  Yeah.



LEO:  We were down at the, or up at the, or over at the NAB show.



STEVE:  He did a great job with the Q&A.



LEO:  Good.



STEVE:  And it's funny because, when I don't have you, I'm always a little self-conscious of, like, that we'll be talking about things that you won't get so that - because this podcast, probably more than any other one...



LEO:  You cannot miss an episode.



STEVE:  It builds, yeah.



LEO:  Yeah, yeah.



STEVE:  You know, it really does build on the things we've covered in the past.  How many times am I saying, oh, we talked about this three weeks ago, we talked about this four weeks ago, and now this is happening, blah blah blah.  So I'm always thinking, oh, Leo won't know about this.  Well, that's okay, you know.  But you're rare - although, I was going to say, you're rarely gone.  But you have, you are talking about trips coming up.  So is that in the summertime sometime?



LEO:  Yeah, just so you know, I'll be leaving June 27 through July 14th.



STEVE:  Okay.



LEO:  Lisa and I are going on a river cruise down the Rhine...



STEVE:  Nice.



LEO:  ...the Main and the Danube.



STEVE:  Well, and you need to refresh.



LEO:  You've got to take a break.  But I've got to say, because this is - you're the same way.  It's our passion.  I do nothing but read tech news day in, day out, wherever I am.  So it's - few are the stories that I haven't been reading about and cognizant of.  What frequently happens, though, and I know I'm not alone in this, is I read a story, and I say, I can't wait to hear what Steve has to say about this.



STEVE:  Yeah.  I'm seeing people tweeting that a lot, too.  They'll say, oh, this looks bad, but we'll have to wait and see what Security Now! says.  So, because a lot of this stuff does beg some interpretation.  We've got a really interesting, sort of a very brief follow-up on TrueCrypt audit that we talked about two weeks ago.  That was the topic of our show two weeks ago.  Everyone's talking about a nasty IIS bug that was part of the Patch Tuesday, last Tuesday's Patch Tuesday, which is bad because it is just so easy to do.  We'll talk about that.



I found an interesting, sort of from a privacy standpoint, new service that Google is offering that I want to talk about.  Also some changes in Chrome.  A popular library in iOS that has some people worried.  News of Let's Encrypt, which is the automated server is able to issue its own SSL certs service, which is moving forward.



And then our big topic for the day, the title of the show, is China's Great Firewall and Great Cannon.  There's been, in the wake of the cannon blasting that they were doing of GitHub, like mid-March, now we understand much more about the architecture of the system.  We've never really addressed the Great Firewall at all.  I understand exactly how it works now.  And we did talk about the Great Cannon.  But I want to tie that all together because this is a major actor on the Internet, not only choosing to censor the content that gets into China, but now, as we know, actively using other people's machines for cyberwarfare.



And it's just, I mean, I feel like it's science fiction, but it actually happened a few weeks ago.  And it was embarrassingly public.  China never took any responsibility for it.  They sort of deflected the questions.  We now have hard evidence that it was a state-sponsored attack, intimately tied to the Great Firewall, which we know is a state-sponsored Internet filter.  So lots of new information that I think will be interesting to share with our audience this week.



LEO:  Very, very exciting.



STEVE:  So the picture of the week on the front page of our show notes is a pop-up that I got when I began to experiment with a new feature that Google has made available, that we'll be talking about in a minute.  But it was big, so I stuck it up there on the front page, and we'll come back to it.



I wanted to quickly do a little bit of a follow-up to the TrueCrypt audit coverage from two weeks ago because I spotted something on the 'Net from the - Tom, he would be upset if I called him the "lead cryptographer."  He was the team lead or the managerial lead.  And Tom Ritter is a cryptographer.  He was one of the three who were part of the TrueCrypt audit.  And I found a quote by Tom saying, "The audits of TrueCrypt get a lot of press because it's something flashy.  But the development effort that went into TrueCrypt at the beginning are immense and incredible.  And the developers don't get as much credit as they should for producing a disk and volume encryption project for multiple platforms and for maintaining it for a decade or more.  There are successor projects, and they are improving it in their own ways.  I'm excited to see those projects grow and thrive and last as long as TrueCrypt did.  I still use TrueCrypt," says Tom Ritter, who audited it and is a cryptographer.



LEO:  Now, that's high praise.



STEVE:  That was my point.  "I still use TrueCrypt," he says, "and want to see it supported in the future."  And I have looked at, what is it, VeraCrypt, and can't think of the other one right off the top of my head.  They're making a point of being forward compatible.  That is, being able to take an existing TrueCrypt volume, presumably, and still be able to interpret it.  Although, for example, they're improving some ciphers.  No doubt they're keeping the older legacy ones around in order to be able to still function with an existing TrueCrypt container.



But I just thought it was interesting that Tom Ritter, who would know better, says, "I still use TrueCrypt and want to see it supported in the future."  So, and for what it's worth, I'm using it because it still solves the problem.  And I will be forced away from it when at some point it turns out that it can't handle GPT partition types or something like that, where some compatibility gotcha occurs, just because of TrueCrypt's age.



LEO:  And that's fairly soon; right?  I mean, in some cases, I think, yeah.



STEVE:  Yes, yes.  Yeah.  And so I'm glad that it is being moved forward.  And as I said, I'm so glad for the audit because it spotted a few areas, they weren't critical, but might as well fix them in the code that is now alive and fixable.  And I guess my point was that I'm always going to feel more comfortable with a third-party solution.  I just, you know, using BitLocker from Microsoft is like, you know, they're not going to show us everything that it's doing.  And it's hard to trust that there isn't some way that they could honor a demand for a drive to be decrypted.  And I only, I mean, the reason for using it is that it really, really is safe.  So the industry...



LEO:  And where can we get it, by the way?  I think it's worthy of a note there.  Because you're preserving the - because you can't just go to TrueCrypt.org anymore.



STEVE:  No.  I grabbed the 7.1a, all the archives and resources at that time.  So it is at GRC.com.  I think if you just put, like, TrueCrypt into Google, I was, for a while at least, GRC was one of the links that came up pretty quickly in a Google search.  So, and a lot of people are visiting that page and grabbing the content from me.  And I think it might have been, I don't remember if it was - somebody was also maintaining the hashes on a separate site.  So, oh, yeah, there it is, GRC, TrueCrypt, the final release archive.



LEO:  Now, if you get it from - if you get 7.2 from the TrueCrypt site, don't.



STEVE:  Ah, see, that's the one that they deliberately neutered.  This is why we knew it wasn't something done overnight because 7.2 only removes TrueCrypt.  You can't use it to install TrueCrypt.  And that's a nontrivial change.  They had to go through all of the code and, like, remove all of the aspects of it that were about creating a new volume.  Turns out there was a lot there that they had to do.  So 7.2, it will interpret a TrueCrypt volume, but it will not create one, and it will allow you to remove it.  It'll remove, it'll decrypt a drive for you.  So that's the only thing that they're now making available.



LEO:  I mean, obviously Tom - is that his name?



STEVE:  Yeah, Tom Ritter.



LEO:  Is not using VeraCrypt.  But do you recommend that people go to your site, download the final release of TrueCrypt?  Or would you recommend they use VeraCrypt?



STEVE:  I guess my sense is, I mean, I'm sure VeraCrypt is fine.  But TrueCrypt is bulletproof.  And my recommendation would be, if it works - but you know me.  I'm still sitting - I'm sitting in front of XP, Leo, so I'm really - I'm a bit of a skewed sample.  But my sense is, if it works, use that one.  It's been really just pounded to death by hundreds of thousands of people, that is, the original TrueCrypt 7.1a.  But at some point it won't work for you because your system will no longer be compatible, in which case you'll want to go explore the forks of TrueCrypt.  That would be my strategy, I think.  There's nothing that they have done that makes theirs superior to what TrueCrypt was because there was just nothing wrong with it the way it was.



LEO:  Yeah, yeah.  And it has been vetted.  And it has been audited.



STEVE:  Yes,



LEO:  Which we can't say for anything else.  So there's that, too.



STEVE:  Yes.  And it is so easy to make a mistake.  In fact, that is our next story because this bug was not in Windows Server 2003.  It apparently got introduced in Windows 7 and the same codebase, which is Windows Server 2008, and 8.8 and 8.1 and Windows Server 2012 and the core installation.  Anyway, this is the bug that the security industry has been abuzz about, mainly because it is horribly easy to do.



Microsoft gets in trouble always when they move stuff from the user space into the kernel.  How many times have we run across JPGs or image files that are able to take over your computer?  It's crazy to have an image file able to execute code on your machine.  But they famously moved GDI, the Graphics Device Interface, from user space down into the kernel, at a time when they were desperate for more performance.  And the so-called "ring transition," when an application needs to call an operating system service, the application has limited privileges, and it needs to connect to code in the kernel that has infinite privileges.  I mean, god.  I mean, literally, it can read any address it wants to.  It can do anything.  The kernel is maximally privileged.



It turns out that the architecture to make that transition in a carefully controlled, secure fashion takes some time.  There's lots of caches and buffers that need to get flushed and switched.  And so every single time the code in the user space has a request for anything from the operating system, there's some overhead.  So when you're desperate for performance, as Microsoft has been at various stages during the history of Windows, one of the things you look at is, ooh, you know, if instead of having code in the user space, which is making lots of calls into the kernel, it's so tempting to move that code itself into the kernel because then there's no more transitions.  You'd still have to talk to that from the user space.



But, for example, the user might say, draw a rectangle at these coordinates.  And so that command goes one transition into the kernel.  Then the graphics device interface code is able to just go bzzz, you know, and do it much faster.  All of the individual colors and pens and corners and roundings and shapings and mergings, all the complicated variations can be done far faster than if it was living with the application in the application space and had to keep begging the kernel to do all these little things for it.  So Microsoft did that when they moved GDI in the kernel.



They faced another temptation, which they succumbed to, when they moved a chunk of IIS, the server, into the kernel.  And they did it in a module, a kernel driver called http.sys.  So it is, basically, they looked at a way that they could cut the server in two so that, with a minimal amount of relocation, that is, moving the smallest amount that made sense into the kernel, they could get the most bang for the buck.  And so what they did was they created in Windows 7, which corresponds to Windows Server 2008 and all the subsequent OSes, because this has been there, they allow the kernel to parse the HTTP query enough to see whether the item being requested is in the cache.  And they also put the cache in the kernel.



So the performance gain is potentially dramatic because we know that so many websites are fulfilling requests from cached resources, like all the images, the same images that they're serving, not just over and over to the same browser, but to all the different people who come whose browser needs to get at least one copy of the image.  Well, if it's already been found in the file system and pulled down into memory, and it's sitting in the kernel, there's all kinds of optimizations you can do.  Windows can just sort of point some pointers at it, and it just shoots that asset back to the requester.



Well, it turns out they made a mistake, which is pretty simple, but of course all of these mistakes are simple in retrospect.  And on the show notes here I show the piece of code which is incorrect.  Basically, one of the request headers that a browser or an HTTP client can include is called "range."  If you don't specify a range, then the server assumes you just want the whole thing.  But you can also say, for whatever reason, maybe you're actually running four connections in parallel, and each connection is getting a different piece of something large, and you're doing that, you know, that's what the download accelerators did for years.  For whatever reason, it's in the HTTP spec.  And that allows the browser to say, okay, I want this, but start at byte 702 up through 5,027.  You can just arbitrarily say this is the first byte of the object I want; this is the last byte.



Well, if you have a first and last byte, one of the things you need to do is determine how many bytes that is.  The way you do that is you subtract the first, the beginning offset of the range, from the ending offset.  That gives you the difference.  But this is one of the tricks in programming.  The difference is not the number because say that you wanted - you said I want to start with byte two, and I want to end with byte three.  Well, if you subtract two from three, you get one.  Except that the range is inclusive, so you actually need two.  So you subtract the smaller, the beginning from the ending, and add one.



And in that code that you've got on the screen now, Leo, from the show notes, that is exactly what they're doing.  They have two 64-bit values.  And this is 32-bit code because, for example, the EAX register and EDI, those are 32-bit registers.  But the range, but 32 bits only gives you 4.3GB, as we know, and things can be bigger than that.  And so IIS is treating them as 64-bit sizes.  And so that first subtraction is subtracting the low 32-bits of each of the ends of the range.  And then that second one, the SBB, that's subtract with borrow.  In case there was a borrow from the first, the result of the lower side subtraction, that then subtracts an extra one from the high side subtraction.



And so once they're done, then you can see they add one to EAX, and then they add with carry a zero to ECX.  That's because, if the add of one to EAX does overflow, EAX goes back around to zero, it'll leave the carry bit set.  And so when you add with carry a zero to EAX, that essentially adds that one that fell off the high end to ECX.  So what they missed, and you can see it right there, no test to see if that add of ECX overflows.  They didn't check for overflow.



So it turns out that in practice, simply using a crazy range header, and I've showed here in the show notes, pretty much anything, and then as the starting location, and then this special number, 18446744073709551615, that's the maximum value that a 64-bit quantity, unsigned quantity, can contain.  And so I'm sure this code was written in C.  And so in C they were subtracting a long long, which was the starting point of the range, from a long long, which is a 64-bit quantity, from the ending point, and adding one.  And they didn't check for overflow.  And as a consequence, anyone making a request of IIS with that range line will crash the server.  It just BSODs.



Microsoft called it a remote code execution exploit.  Nobody has figured out yet how to actually make that execute code.  There are some people who have figured out how to get some information disclosure.  Apparently ranges can also have multiple components.  It's crazy.  You can say, like, I want from two to five, and then 27 to 46.  And so you can create, like, compound ranges.  And it turns out that people who've been playing with this have been able to get the server to send them chunks of memory beyond the object that they are requesting.  So that is definitely information leakage, and we don't yet know how bad it is.  But turns out it's much easier to crash the server than it is to get it to give you additional information.  Nobody's figured out how to make it execute.  Maybe if you had - I can't even imagine how you could do that from what we know.



LEO:  But we've talked about this before.  The first step is always a crash, which can be used as a denial of service.  Second step is to see if you can get it to jump somewhere and execute some arbitrary code.



STEVE:  Right.



LEO:  And that takes a while.  But the fact that you can get it to crash is always a very, very, very bad sign.  It's interesting - so we were showing assembly language.  It was written in C, most likely.



STEVE:  Yup.



LEO:  It did say, I noticed the subroutine was @32.



STEVE:  Yes.  Actually, that says UI, a pointer to parse range, and then it says @32 [U1pParseRange@32].  That's a notation for the number of bytes of arguments.  So whatever this parse range routine...



LEO:  The disassembler gave you or something.



STEVE:  Yes.  Yeah.  So it's a clue to say, essentially, once you're done, pop 32 bytes off of the stack in order to clean up the stack because the caller pushes the bytes on the stack, and so the routine itself cleans up the stack afterwards.  So that doesn't refer to the bitness of it.  For example, it wouldn't say 64 if it were 64-bit code.  It's how many parameters were required by that subroutine.



LEO:  It's interesting.  Whoever did the disassembly must have had access to a symbol table because usually you don't get real symbol names, real routine names.



STEVE:  That's true, although the developer tools do have the debugging versions of the code.



LEO:  Oh, okay.  There you go.



STEVE:  And so you are able to figure out what all that stuff is.  And the way Windows works with dynamic link libraries, they sometimes need that also.  I mean, they link by name.  And so the DLLs will have the names of the routines in order for the linker to glue it all together.  So there is some of this inefficiency.  Netcraft estimates that there are about 70, seven zero, million publicly exposed IIS servers on the Internet.  Apache and Nginx have way surpassed IIS, IIS basically sort of losing the war for dominance.  Not that it ever had it.



LEO:  But you still use IIS; right?



STEVE:  I do because I'm a Windows programmer, and I know Windows, and I started.  If I were doing it, if I were starting it today, I would never consider using IIS.  But I have a huge investment in server-side code.  And I've gotten to know it, and I can't quite say that I've gotten to love it because Microsoft keeps going this to us.  It turns out that I would have been vulnerable except that one of the workarounds is to disable that kernel caching.  And I generate so much content dynamically from my server-side code that I never had kernel-caching on.  And so I was never vulnerable to this, just, you know, happily.  Otherwise I would have immediately patched.



So anyway, this is just, you know, this is a perfect example of a problem that Microsoft would not have had, had they not moved what arguably should really stay up in the user land down into the kernel, purely for the sake of performance.  They're under pressure to make IIS competitive, and the architecture that they've got necessitates that they do everything that they can.  And putting more of your web server in the kernel, horrible as that is, is a way to achieve that.  And the risk is a little tiny mistake like this can really ruin your whole day.  And what's happening is people are getting - oh, this is, by the way, when this was released, Microsoft said there are no known attacks.  It's been completely reverse engineered, and it is being scanned for actively on the 'Net, and IIS servers are crashing constantly because they have not been patched.  And the default is to cache content in the kernel for the sake of performance.



LEO:  Although crashing the server usually means just it reboots, restarts, you know.



STEVE:  Right.  Right.  And that's why it's called a "denial of service," because you're denying users service while it gets itself going again.



LEO:  Right, right.



STEVE:  Now, this is interesting.  Google is allowing us, anyone who has a relationship with Google, to download their search history.  Back, I'm not sure how far back it goes.  In my case, because I was curious about this, you go to, guess it's Google.com/history.  Or the link I have is history.google.com/history.  And there's a nice little page that shows some stats about you.  And if you click on the little gear icon in the upper right, there's the download option.  And you can have Google prepare a ZIP file containing every single Google search you have made, in JSON format, for - in my case it goes back to January of 2012.  So I'm looking here, and I just stuck it in the show notes here, so quarterly summaries of every search I've made through 2012, 2013, 2014, and up to now in 2015.  They caution you that there's a lot of potentially sensitive personal information here.  I mean, this is everything I've searched Google for.



LEO:  I don't think this is new.



STEVE:  This isn't.  Okay.



LEO:  So Google, well, and I'm sure some tech blog discovered this and said it's new.  But Google's always had a site called "Google Takeout," where you can download everything.



STEVE:  Ah, yes.  And that's - okay.



LEO:  And you've always been able to do that.  And you get to choose what you want to have in here.  I don't think search history is new.  There's lots more than search history, including your location history.  Every once in a while somebody clicks a link - Google's had this for a long time, Google.com/dashboard - and suddenly realizes, oh, my god, they're keeping track of everything.  And Google's always offered Google Takeout.  They've always been upfront about this.  I don't think this is new, unless I'm missing something.



STEVE:  And I don't know.  I mean, I can't...



LEO:  Yeah, some tech blog published it.  I saw it all of a sudden all over the place.  Google does this.  It's like, yeah.



STEVE:  Anyway, from my standpoint...



LEO:  It's good to know.



STEVE:  I just thought it was cool...



LEO:  Yeah.



STEVE:  ...that, I mean, it's sort of a blast through the past when you browse through, like, what you were searching for three and a half years ago.  It's like, oh, yeah, I remember that.  Actually, I have some tabs that are that old, but that's another story.



LEO:  I bet you do.  You can clear this.  You don't have to let Google save it.  Most of us do because it gives us some value in Google Now and other things.  And Google tailors its searches to previous searches.  But Google's always been very clear about this.  At Google.com/dashboard, you can see what they take, what they keep track of.  And the one that scares people more often is the location history because, if you have a smartphone with Android on it, they've been keeping track of where you are, you know, unless you turned that off, for a long time.  This is all in here.  Even my Orkut postings are still here.



STEVE:  So speaking of Google and Chrome, they are moving forward in their never-ending march to tighten things up.  And with Chrome 42, which is out now, they have finally disabled what's called the NPAPI.  They gave plenty of ample warning, notice that they were going to do this.  The NPAPI is the Netscape Plugin Application Programming Interface that dates back to the '90s.  And I think, like, Navigator 2.0 is where this first happened.  Essentially, Netscape realized that their browser would be able to render HTML pages and JPGs and GIFs, and I don't think there were PNGs back then, but sort of the standard resources.  But there would be other content, for example, a PDF is a perfect example.  How could a browser render a PDF in its UI?  How could it contain it?



So what you need is you need to create a standardized, so-called API, Application Programming Interface, that other developers can use to talk to the browser guts in order so that they just have to handle, for example, if we extend this PDF notion, they would create a PDF rendering plugin which you would then add to Netscape.  You register it with the browser.  And then when you request something with a content type of whatever it is, like application/pdf, Netscape would look to see if it has anything registered to handle that, if there's a plugin that says, oh, yeah, I know how to render those.  In which case it would hand control to the plugin, and the plugin would then get access to the physical screen real estate in order to render what it wants to.



So this has been - it was very widely supported.  Even IE briefly added support, although they dropped it a long time ago, back with v5.5.  So IE has not had support for this Netscape Plugin API.  However, Safari and Firefox still both do and continue to support it.  Chrome, the Chromium people were just, I don't know, their claim, for what it's worth, is that it was causing stability problems.  It's interesting that Java and Silverlight are both hosted under this Netscape Plugin API.  So if Java is going to continue to be supported in Chrome, it's going to have to probably change.



Chrome has its own API that they call "Pepper."  It's PPAPI, which is sort of essentially the same thing.  And, for example, that's the API that hosts Chrome's built-in support for Flash.  So the Flash that's in Chrome, it's sitting in this Pepper container using this PPAPI.  So if Microsoft or Oracle chose to move their Java and Silverlight over, then they could do that.  But as of this version of Chrome, 42, it's now disabled by default.  So it's not gone, it won't actually be gone until Chrome 45, which is targeted for September of this year.  So there's about another six months.  At the moment, you may find that stuff you're using will not function.  But you can turn that back on.



LEO:  It's in the chrome://flags.



STEVE:  Yes.



LEO:  But I'm curious, who uses NPAPI?  I mean, really.  Does somebody still use this?



STEVE:  Well, Java and Silverlight are both still using it.



LEO:  Silverlight, right, right, right.  Java, who cares?



STEVE:  Yeah, and there are - yeah, exactly, safer without it.



LEO:  Safer without that.



STEVE:  Yeah.



LEO:  And Netflix has moved away from Silverlight.  So I don't know...



STEVE:  Correct.  And Netflix was, as you say, the big Silverlight adopter.  But they're away from it.  Essentially, the effort is to move people towards HTML5 that can now do so much more than HTML4 or 3 were able to do back then, that you really needed natively written add-ons.  There just isn't that much demand for it anymore.



LEO:  Yeah.  It seems - this does not seem premature yet.



STEVE:  No, and I don't think it is.  Chromium has made it very clear they were going to be phasing out the NPAPI, giving people as much time as they needed to switch over, if they still wanted to do a plugin, to use Pepper, which is what Flash uses in order to get the same sort of services from the browser.



LEO:  And I'm on Netflix right now in my new NPAPI-less Chrome browser, and it plays just fine.  So I'm not too worried about it.



STEVE:  Yeah.  Yeah, I think Netflix is using the WebM stuff, or the...



LEO:  Yeah, VP9 maybe, and, yeah.



STEVE:  Yeah, yeah.



LEO:  All right.  Well, that's good.



STEVE:  So for a few months this year a very popular networking library for iOS apps called AFNetworking developed a problem.  It was broken in January of this year with v2.5.1 and only fixed three weeks ago in 2.5.2.  The problem is it skips certificate verification checks.  Whoopsie.  So at this point...



LEO:  When Steve says "whoopsie..."



STEVE:  Whoopsie.



LEO:  That's the one thing you don't want to hear your doctor say, whoopsie.



STEVE:  Or staring at the X-rays and going, "Hmm."



LEO:  Hmm.  Or the two together would be bad.



STEVE:  Yes, very bad.  So there's an outfit called SourceDNA that scans iOS, the iOS App Store, you know, iTunes.  And they have identified at least 1500 iOS apps in about two million installations which today remain vulnerable.  None of these seem like really mainstream apps, although Citrix OpenVoice is one, Citrix OpenVoice Audio Conferencing; Alibaba.com's mobile app; and then things like Movies by Flixster with Rotten Tomatoes.  Something called KYBankAgent, that seems a little spooky.



LEO:  That doesn't sound good at all.



STEVE:  No, it doesn't.



LEO:  Whoopsie.



STEVE:  And the Revo Restaurant Point of Sale app. So these are sort of off-the-beaten-path apps.  But for what it's worth, they may be apps that people have, and they need to get updated.  There is a search tool.  SourceDNA.com created something they call "searchlight."  So searchlight.sourcedna.com/lookup is a search tool that allows anyone worried about a specific app to see whether it is vulnerable and whether or not it's been fixed.  This is not a huge problem because it's not a problem in iOS.  And it's not clear how widespread AFNetworking is.



But if you've got a sort of a smaller custom iOS app that is doing Internet communications, the vulnerability is that it is completely open to man-in-the-middle attacks.  An HTTPS proxy could just use a bogus certificate.  It doesn't have to be a certificate that it got from CNNIC.  It could just, I mean, it could be expired.  It could be wrong.  And these apps will not detect that.  I was a little surprised that iOS won't detect that, either.  But apparently it's been verified that it slips right past if the app is using its own, this AFNetworking library.  So anyway, just a heads-up for anyone who might be affected by that.  It doesn't seem, again, like it's a huge deal.



And our illustrious crypto auditors have moved on from the TrueCrypt audit to auditing the Let's Encrypt system, which is really good news.  To recap, Let's Encrypt, which is over at LetsEncrypt.org, that's a forthcoming new certificate authority.  They're going to be a certificate authority.  I'm sure that until they get into our root stores, which may take a while, they will verify their integrity and get somebody like a GlobalSign to sign their certificate, and so they will be an authorized intermediate CA.



The point is, this is that system that we talked about a few months ago.  The EFF is behind it, and it's got a lot of major league industry sponsors.  The point is, let's make encryption so simple that everyone can do it.  Make it, first of all, simple to configure, and free, so no longer does it cost anything, and automated.  So with just two commands to a Linux system, you do an apt-get install lets-encrypt, and then you give the command lets-encrypt and then your domain name.  And with those two commands, your server is online with a certificate.  So to do that, essentially we need the backend management of the CA, so the server-side stuff for this Let's Encrypt certificate authority, and we need a protocol.  The protocol they call ACME, which is short for Automated Certificate Management Environment.  And the server-side stuff is named Boulder, which is largely written in the GO language.



And these guys, the NCC guys who audited TrueCrypt, have now been commissioned to audit this technology.  So they're going to do a full verification of the code that's been written, the backend server-side stuff, and take a look, a hard look at the protocol.  And this is exactly what we would like as a system like this moves forward.  And once it's deployed, and they're still targeting for mid-2015, so we're approaching mid-2015 a few months from now, it will mean that anyone who has the Let's Encrypt module in their server - and I'm not sure for things like Nginx.  I imagine Nginx will be right there.  We know Linux will.  It would be great if someone does support for IIS.  The idea will be that the server has a protocol with the CA saying, hi there.  I am Ajax.org, and I need a certificate.



And so you can imagine how easily this can work.  It's one of those things where you just kind of want to slap your head because the server claims to be Ajax, the server for Ajax.org, to the CA.  The CA probably says, okay, here's a blob.  Go stick this on your root, and let me know when it's there.  And so over the protocol the Ajax server receives the blob, puts it in the root so that it's publicly accessible, and then responds back to the CA, okay, blob's there.  And then the CA goes and tries to fetch it, you know, through the public Internet, gets the blob, verifies it, and says, okay, you must be the server for Ajax.org because you've just proven that.  So here's your certificate.  And the certificate goes back through the protocol, and the server says thank you very much and binds it to the IP and port, and you now have security for free.



And this thing then is an agent running in the background, making sure that the certificate never expires.  As expiration date approaches, maybe a month or two before, it says, "Hey, me again.  Let's do this dance again and update me."  And, you know, bing bing bing, and, okay, now we've got another however many years the certificate lives for.  I mean, it could be - it's so easy, it doesn't have to be a long-lived certificate.  And if anything happens where you lose control, you're able to use the same system for revocation.  So revoke that certificate.  Let me have a new one.  Sorry about that.  And bing bing bing, now the server's got its certificate again.



LEO:  Bing bing.



STEVE:  Bing bing bing.



LEO:  Can I ask a question?  Because of course we want to, I want to, DigiCert gave us a certificate, and we would love to use HTTPS on TWiT.  And I've been told that we can't or shouldn't because it breaks our caching.  So, you know, as many high-traffic sites do, we cache heavily.  We're using Varnish right now.  The new system is going to use Redis and Varnish.  It's going to be a fairly sophisticated caching system.  And I was told that, well, we don't want to do that because then we can't cache it.



STEVE:  So where are the caches located?  Are they, like...



LEO:  In other places.



STEVE:  Yeah, that's the problem.



LEO:  Redis is Redis Labs.  It's not TWiT.tv.  So I imagine we're not alone in this regard.



STEVE:  No.  And in fact, a perfect example is we've talked about how ISPs are unhappy about the move to security because they're depending upon caching.  For example, a big ISP like Cox has all of its customers are going to Google.  Well, only one copy of Google's front page decoration and resources needs to get pulled by one customer over a non-secure connection in order for the ISP to cache it locally.  Then it is so much more efficient for the ISP to serve those same assets to all, you know, a big IP like Cox, to all of its customers who are behind that cache.  And what that does is it dramatically reduces Cox's bandwidth that it needs because it's able to serve all of those essentially redundant queries for the same content from its own local store, which costs it nothing because it's its own network.  And that way it reduces its costs dramatically.  And so you're saying the same thing, Leo.  Obviously, the reason you want to cache is you don't want to have to be serving all of this from your own server over a more constricted pipeline.



LEO:  And, you know, this is the business of Redis.  Redis Labs is one of many providers for Redis caching.



STEVE:  Can you move these to a different domain, like to a cache.twit.tv, and have them manage a subdomain of yours?



LEO:  Hmm.



STEVE:  Because I wonder, I mean, they're going to have to solve this problem one way or the other because the world is...



LEO:  CloudFlare, CloudFlare's a really good example of a company that does this for people all the time.



STEVE:  Right.



LEO:  Apparently, somebody in the chatroom, Julio, says a reverse proxy will solve part of the problem.  And Cloudflare is developing a solution to encrypt, not only client-to-reverse proxy, but reverse proxy-to-host.  I'm sure this will be solved.  I mean, there's a lot of businesses like Cloudflare that are - that's their business.  And obviously Google is forcing us to do HTTPS.



STEVE:  Yup.



LEO:  It's a little annoying.



STEVE:  It is.  Well, and this is, you know, these changes are painful, yeah.



LEO:  Is it really making everything better?



STEVE:  Um...



LEO:  Well, if you go to HTTPS right now, https://TWiT.tv, you're going to get an error because TWiT.tv is not secure, is not a secure server.



STEVE:  Right.



LEO:  We don't have a certificate.  And so thank you, Google, you're scaring everybody with this:  Go back to safety.  Attackers might try to - no.  That's not the case, Google.



STEVE:  Yeah.



LEO:  Right?  This is Chrome doing this.  It isn't that it's - it's not - we don't use HTTPS.  But this is the beginning of a war Google's going to launch on us and other sites who I think you could make an argument don't really need to do HTTPS.  Anyway, thank you, Google.



STEVE:  Yeah.  Yeah, I think that the demand for security will come from users.  For example, there was another blurb that I didn't pick up on, just because we had so much to talk about this week, which was that AT&T Broadband, you probably saw this, is saying that they will, for a fee of $29 a month, they will not watch all of their users' transactions.



LEO:  Well, that's to make up for the loss of revenue; right?



STEVE:  Exactly.  Exactly.  The revenue that they get from watching their users' actions and injecting ads and digging into the content.  The problem is, what this is saying is that, okay, first of all, they can only do this on non-HTTPS connections.  That is, they can only do this on HTTP.  So this puts tremendous pressure on this ecosystem to somehow penetrate privacy which our HTTPS gives us.  And what I mean by that is, just watch.  Mark my words.  Here we are on the Security Now! podcast.  At some point, AT&T customers are going to be asked to put a certificate, an AT&T certificate, in their browser.



LEO:  Right, right.  Because then they can peer inside HTTPS.



STEVE:  Yes, yes.  And, boy, there's going to be fireworks when that happens because there are a lot of people who are going to say, wait a minute, I don't want my security cracked by AT&T.  So, yikes.



LEO:  This is like Superfish.  It's the same exact thing.



STEVE:  Yes, exactly.



LEO:  So am I, because if - we aren't HTTPS at TWiT.  Now that, you know, no account, you don't create an account.  It's a read-only website from your point of view as a user.  Does that mean that we are potentially manipulable, a Great Cannon or, I mean, what is - why is it necessary for a read-only website to be HTTPS?



STEVE:  The only thing, the only vulnerability I could see is that, if someone wanted to inject malicious content onto your pages, they could do that.  So TWiT content would be going in the clear all over the 'Net, and it's just, you know, a page is just a bunch of text.  And so somebody could easily change the ads or add content of any sort that they wanted to, if somebody wanted to.



LEO:  How would they do that?



STEVE:  It's actually pretty trivial.



LEO:  Do they have to compromise the end user's system?



STEVE:  Well, they do have to be in the middle somehow.  So I just saw a tool the other day that was demonstrating a man-in-the-middle attack in an open WiFi environment where it was just ARP spoofing.  I mean, you actually can redirect the traffic of people in an open WiFi environment through your machine and then mess with their traffic.  So, I mean, I guess the problem is that the world is going to encryption.  But at some point there may be so much pressure put on not having encryption that we start being forced to have certificates in our browsers to allow people to proxy and cache.  So, I mean, it's just not clear how this is all going to evolve.  But, boy, I mean, there are a lot of people who will not be happy if their ISP starts saying, sorry, if you're going to use us, and by the way, you don't have a choice, you're going to have to allow us to look into your traffic.



LEO:  Well, I'm hoping that somebody will solve this for us.



STEVE:  So do you have a different domain for these cacheable things?  Or is all your traffic running through this other company so that there...



LEO:  No, it all goes through TWiT.  So I don't know.  I'm not exactly sure what the architecture of it is.  And it isn't turned on yet.  Right now, if you go to - well, you've seen people have image servers elsewhere, where people use Amazon Web Service...



STEVE:  Or, for example, a CDN.  But, for example, when you have a CDN, it'll often say cdn.twit.tv.  And that subdomain is somewhere else.



LEO:  In this case, no.  If you download a Security Now!, you're going to go to - it'll be a link to Cachefly.



STEVE:  Right.



LEO:  And so Cachefly, which I think is secure - I don't know, anyway.  But anyway, Cachefly will serve that content to you.  So you only, when you go to TWiT.tv, you get text and images in a read-only fashion.



STEVE:  And the media comes from big media services.



LEO:  Right now the media all comes from our server.  But eventually nothing will - well, it's still going to all come from our server, but it will be cached.  I guess Redis will be TWiT.tv.  It'll look, I mean, it won't look any different to you.  I don't know how it works.  It's too modern for me.



STEVE:  Yeah, so in order to answer the question we'd have to really take a look at the architecture.



LEO:  Their architecture, yeah.



STEVE:  Yeah, and see.  But I'm sure the problem can be solved.  And, frankly, maybe now is the time for you to think about it.  Rather than not doing it secure and then having to change it later, like address it now.  Say, hey, look, the world is going to HTTPS.  Let's not...



LEO:  Yeah, that's easy to say.  But if it's $100,000 to do it, which it will be, I'm messed up.



STEVE:  I don't think it should cost anything.



LEO:  No, no, no, no, everything costs something.  These are developers.  I have to get them to create some, you know...



STEVE:  Okay, work harder.



LEO:  Nothing's free.



STEVE:  Well, you should tell them, hey, wait a minute.  This is the way it's supposed to be.  Why are you charging me for doing it right?



LEO:  Yeah?  I'm screwed.  Thank you, Google.



STEVE:  So a little miscellaneous note that I just caught, and that is that Twitter, as of yesterday, now allows optional DMs from anyone.



LEO:  I ain't doing it.



STEVE:  I am.



LEO:  You're going to turn that on?



STEVE:  Because - I did.  Well, because I have a lot of dialogue.  And the way I'm using Twitter is sort of as a forum.  And I am a little self-conscious when there's, like, sort of off-topic dialogue that's going back and forth, and everybody is, like, seeing this nonsense.  The problem is, when I was using it much more as a one-to-one communications, I kept getting complaints from people saying, "Hey, I can't DM you because you're not following me."  And they were typically following me, so I was able to DM them.  And anyway, I think for me this is great because this allows someone to send something to me.



LEO:  Privately, yeah.



STEVE:  Privately, that's not for everyone.  And typically they will be followers of mine, so I'm then able to respond, and I'm just not junking up my feed with, like, random conversation that's not of greater general interest.  So anyway, I just wanted to let everyone know that that just became available.  You go to, under Security and Privacy, there's a Privacy section at the bottom of it.  It says Direct Messages, and the little checkbox is "Receive direct messages from anyone."  And mine's on.  I can always turn it off if it turns out to be a problem.  But I just don't see it being a problem.



LEO:  For you it makes perfect sense because you're in the security field.  You would want private communications from people you don't know already.



STEVE:  Right.



LEO:  Of course they could email you, but you don't use email.  I'll just let people email me because I just don't want a whole bunch of DMs from strangers.  But, yeah, I mean, it makes sense for you, though, actually.  So it's nice that it's an option, I guess.



STEVE:  I like it.  And so the concern is that - because, I mean, a DM as opposed to an @ mention.  I mean, that's the way everyone's communicating now is they just do @SGgrc.



LEO:  Right, and it's public.



STEVE:  And they know, yeah, and it's public, and it'll be in the feed.  So people are - so what you're saying is you don't want people knowing that they're able to communicate with you privately through Twitter.



LEO:  That's what email's for.



STEVE:  Right.  Okay.  Yeah, makes sense.



LEO:  Yeah.  Twitter is such a cesspool for me that I don't - those are exactly the people I don't want to talk to me.



STEVE:  So a little bit of SQRL news.  I had coffee on Friday  morning with Stina Ehrensvrd of Yubico, just to sort of catch up.  She was down here doing some corporate business.  And whenever she comes down, she says, "Hey, Steve.  I'm in town.  Let's meet at your Starbucks."  So we did that.  And without, like, getting anyone overly excited, because it's premature, I'll just say that Yubico remains very interested in coming up with a Yubico solution that works with SQRL.  They have the technical ability to do that now with the way their technology has evolved.



I'm going to fly up and meet with the Yubico techies as soon as the client is nailed down.  We're just - just in the last week we've been going back and forth on our last few issues about, like, we've removed a bunch of features and have simplified things.  Then we went a little too far, so we've come back.  And but it's feeling really good now.  Stina also essentially just wants to solve the problem, no matter who wins.  And of course she's bullish on U2F, the Universal 2 Factor, or Universal 2nd Factor, which is the branch of FIDO that she's been involved in and which, for example, Google is looking at and that we've heard is going to be part of Windows 10 for Microsoft.



And so anyway, so we just had a nice conversation.  One of the things that she reminded me, you know, I was talking to her about how one of the advantages of SQRL is that it was not federated authentication, that is, it was just between the user and the site they were visiting.  And I also reminded her that one of the things that FIDO wasn't and actually could not be was secure single-factor authentication, that is, FIDO cannot identify you.  FIDO can only confirm your identity.  You have to first tell it who you are so that the server can send you back a packet which you've asked it to hold for you.  And then you authenticate yourself against that.  So it's more involved.  Whereas SQRL of course is your identity, and you're able to assert your identity with SQRL.



Anyway, she was saying that not having federated authentication would be a problem because there were instances where you wanted a real-world identity.  That is, and we've talked, Leo, on the podcast about how maybe when there's some sort of an ID card or an identity, you'd go to the post office in order to be matched up with your ID, the idea being that the post office is a government facility.  Or maybe it's the DMV, or maybe it's the TSA people who already run the PRE program would do that.  And somehow, if we get to a point where there is an electronic identity which does need to be connected to our real-world identity, we need a mechanism for that.



And as I was driving - I dropped her off at the airport as she was heading back north.  And as I was driving home, I realized, oh, yeah, SQRL could do that.  It's not a problem at all.  You could be, for example, at an IRS website, which is where you want to prove who you really are, or maybe at some future voting website, I mean, who knows, something where your real-world identity, you want to be able to assert an actual identity rather than an anonymous one.  So it turns out it's very simple for that site to present you with the SQRL code for another site which knows your real-world identity, where you have, beforehand, you've matched it up.  And you simply authenticate with that SQRL code, and your real-world identity is able to be associated with you and your current web session.



So anyway, I hadn't really thought about it.  There was a case where we were trying to prevent fraud because there was a way that a man-in-the-middle attack might be able to leverage that, which we have prevention for.  But then I realized the flipside is you could use it in a good way to provide, under the user's control, that kind of real-world authentication, too.  So one more checkmark for SQRL.



I did, I just thought I would mention, I meant to have - somewhere there was a fabulous picture that someone sent me of SpinRite running on their drive with just a scattering of green R's, meaning that it had recovered the data in that location.



LEO:  Nice, nice, nice.



STEVE:  I mean, it was just, oh, I just loved even to see it, to think that here was a system that had major damage just across the surface.  And it was just a beautiful scattering of green R's saying, yup, we worked on that sector and recovered it perfectly.  Your data is fine.  Anyway, I couldn't find that picture, but I have a nice tweet from the 16th of April, so a few days ago, from an Andre Couture, who just sent me a nice note through Twitter.  He said:  "@SGgrc SpinRite just saved my wife's school computer.  Your latest podcast just clarified some of those numbers I saw."



And in fact he was talking about last week with Mike I showed a screenshot of the S.M.A.R.T. system, SpinRite's S.M.A.R.T. screen, where it was very clear that this drive was in trouble, and I talked about what those things meant a little bit.  So Andre was saying, hey, you know, now I understand that better.  And, by the way, SpinRite just saved my wife's computer at school.  So thanks for sharing that, Andre.



LEO:  Very nice.  All right.  Let's talk Great Firewalls and Cannons.  So let's talk about cannons and firewalls.



STEVE:  So, China.  China, of course, wants to control what its citizens are exposed to.  Certainly the so-called Great Firewall has been around long enough that it's just sort of in the ether.  People know that there is censorship of the Internet when Chinese citizens try to get content from outside.  We've never talked about it specifically, or how it works.  And it turns out that the technology to implement the Great Firewall is pretty well understood.



If we flash back to previous podcasts where we've talked about the way the TCP protocol operates, TCP is the connection-oriented protocol, that is, where there's a - some packets go back and forth between the endpoints, agreeing on a bunch of the parameters that they're going to each use in communicating.  The so-called SYN, S-Y-N packet, short for "synchronized," is the way for the originating end of the two connecting points to say, I'm going to start numbering my packets from X.  And the sequence numbers in TCP are 32 bits, so four bytes, so 4.3 billion packets before that sequence number wraps around.  And there are reasons for the sender, security reasons, for the sender to want to choose a sequence number which nobody else on the Internet can guess because there have been lots of attacks over the past where you spoof this sort of initial handshake.



So the initiator sends a SYN packet to the server, that acknowledges the receipt of the SYN and sends its own SYN back.  So that's done in a single packet called a SYN-ACK.  And then the initiator acknowledges the receipt of the server's SYN, sending back an ACK, an acknowledgment.  So that both ends sort of have the numbering scheme that the other one will be using moving forward.  And the other thing this does is it verifies that roundtrips are possible, that is, that the Internet is just a whole bunch of routers sort of loosely confederated, glued together, that sort of just function to move packets in the direction of their destination, but without any guarantee.



So one of the nice things about this is by having each end acknowledging the receipt of the other one's synchronized or SYN packet, they both verify that a complete roundtrip path through the Internet exists.  So at that point the ends are able to asynchronously just sort of start sending data to each other.  And in the case of a web browser, it'll be sending requests for content from the server, that will be responding.



Now, at some point, either end can decide they're done.  They can decide that they're finished with their sending.  And so they make that statement by sending a so-called FIN, F-I-N, short for finish, saying, okay, I'm finished.  And the other side will acknowledge that and often send its own FIN.  So then you have a FIN-ACK packet, which is both saying, yeah, I'm done, too, and I acknowledge yours.  And then, finally, the one who first sent the FIN packet and received the FIN-ACK will send its ACK.  And that's called a "graceful shutdown," where both ends start up, they agree on numbering, they each send whatever data that they want to for as long as they want to, and then they say, okay, I'm all done, I'm finished.  And so they sort of tear down, as it's called, they tear down that connection with agreement.



But there is another type of solution or another way that a connection can be taken down, which is known as an "abortive shutdown."  And that uses a so-called "TCP reset" packet.  If any TCP endpoint that has established a connection, it's done the whole SYN, SYN-ACK, ACK dance, and they're sending data back and forth, if they receive a reset packet, a TCP reset packet, what that says is the other end is done.  Don't know what happened.  Don't know why.  But it's just, basically, it's just hang up.  Just shut up.  No more communications.  This connection is reset.



Now, the sequence numbers are crucial for sort of each end knowing where the other one is in their conversation.  As they're sending data back and forth, each end is acknowledging the receipt of a set of packets, one or more packets, saying, okay, I've now received up to this number from where we began.  And if a reset packet occurs, it has to fit within what makes sense for the other end to have sent.  That is, this is a further guarantee against abuse because otherwise it would be possible for people just to spray the Internet with reset packets, causing connections to be reset.  It's not quite as easy as that because the other thing that identifies the endpoints are the IP addresses and the port numbers.



So part of what the whole SYN and SYN-ACK and ACK process establishes is the - they're called "tuples" because it's sort of a multidimensional connection.  It's the IP address and the port and the sequence numbering, all which have to match.  So when a reset packet comes in, it has to be from the proper IP, from the proper port number - and that's a 16-bit value, that's one of 64,000 or, you know, 65,536 ports - and it has to be sent to the proper IP and to the proper port.  And the sequence number has to be within a reasonable-seeming window, that is, so there's tight criteria on what allows a reset packet to be accepted as a reset.



Okay.  With that little bit of primer on TCP, all that we've covered in past podcasts, and anybody who's interested can, if you just go to GRC.com/sn, there's a search box on the page, and you can put in "TCP protocol" or "TCP reset" or something, quickly find those past podcasts where we went through all of this in much more detail.



So now we have China, that somehow wants to prevent its citizens from seeing content that it objects to, so-called "banned" content.  What China has established inside of the infrastructure of its major bandwidth suppliers, there are four major country, you know, state-scale ISPs operating in China that terminate all of the incoming and outgoing Internet  bandwidth for the country, scattered geographically around.  Inside of the infrastructure, the datacenters of all of those ISPs that have outside China connections is some equipment which implements the so-called Great Firewall.  Every single packet that flows in is examined for keyword matches for anything that doesn't - that is banned.



Now, this is not - and it's important to understand this because the Cannon works differently.  This is the Firewall.  Think of this as a monitor, that is, it's not a man in the middle.  It hasn't been involved in the connection at all.  It's passively sniffing.  So it's just looking at the traffic, looking at the packets that go by.  And there is certainly some sophisticated high-speed string matching going on because there'll be all kinds of keywords or phrases that China has decided, China's government has decided should not be allowed to proceed in.  And they want to block it.  But mostly they don't want to block things.  So this is sniffing the packets that are going by for anything, any string match that China feels is banned content.



When something like that is found, a packet is found that contains a banned content string, the packet itself has all the information needed to satisfy both ends if they were to receive a reset.  That packet has the source IP, the source port, the destination IP, the destination report, and the current sequence numbers for each direction of travel.  So some fast-acting hardware that is the Great Firewall, which has been passively sniffing that flow of traffic, sees a match, grabs the headers for that packet, and immediately synthesizes reset packets for each end and sends them out.



So what the recipient sees is a packet, followed immediately by a reset, which is a legitimate reset for its connection because everything matches - source IP, destination IP, source port, destination port, and the sequence numbers.  And so what the person inside China or the browser of the person inside China experiences is a legitimate connection reset that appears to have originated from the source of this material and will absolutely be obeyed.  It just aborts that query.  And similarly, a reset is sent upstream to the originator of that banned content.  And once again, the source and destination IPs are reversed from the packet that went toward the China direction.  The source and destination ports are reversed because this one is coming in the other direction.  So what is the source in one direction is the destination in the other.  And similarly, the sequence numbers are swapped.



So what the sender of that packet containing banned content receives is an absolutely authentic, perfect-looking TCP reset that appears, I mean, there's no way to tell it's not legitimate, appears exactly as it should have come from the person it was sending content to.  So it resets it.  I mean, it summarily drops the connection, just erases all knowledge of it, stops sending anything.  The connection is terminated.  No additional packets go out.  That is the Chinese Firewall.



So it's not a man in the middle.  You could sort of think of it as a man on the side.  There's someone monitoring the traffic that just - and normally just letting it pass by.  But on a string match for something banned, that one packet containing that content is all the information necessary for that firewall hardware or system, whatever it is, to immediately emit reset packets and terminate any further flow of that content.  And it's effective.  Essentially, it means that nobody on the inside can ever get the stuff that they were looking for if the packet contains a match.  It just doesn't happen.  The connections just get dropped and you're, you know, game over.  So that's the Firewall.



Last month, as we discussed at the time, a few podcasts ago in the middle of March 2015, something unprecedented occurred.  And again, as we discussed, two pages, two sites within GitHub went under sustained denial of service attack.  And this wasn't, like we were talking before, like the denial of service of crashing a server.  This was the classic absolute bandwidth overload.



And it was difficult to filter because this also wasn't the old-school SYN flood, where you'd just send a bunch of these SYN packets, these synchronizing packets, to a server, causing it to initiate, you know, believing them all because any one of them could be valid, having the server initiate all of these connections and then try to honor a flood of connection requests.  Instead, these were actual queries being generated by real users' browsers all over the world.  So there wasn't - it's not like you could block off China because the attack wasn't coming from China.  It was coming from browsers all over the world that were essentially doing China's bidding for this attack.



So what was surprising about this, what was unprecedented, was that this was a very public attack.  That is, two pages on GitHub, which were offering software for circumventing Chinese censorship, were being attacked.  This wasn't the first time China had demonstrated their unhappiness with GitHub.  Earlier, the entire GitHub domain was blacklisted through DNS so that no GitHub was available inside China.  Well, it turns out that that lasted only two days because of the massive outcry from Chinese developers who were depending upon GitHub as the incredible resource that it is.  So after two days of just blacklisting GitHub completely, China backed off and made it again public.  Clearly, though, they were still not happy with the fact that there were these two pages of software designed to help people circumvent the censorship.



So the Great Cannon was presumably designed sometime in the past.  We don't know the history of it.  All we know is that we saw, to devastating effect, its first public use in apparently a state-sponsored, virtually a state-sponsored cyber attack is what this was.  So China is unable to shut down all of GitHub because China is making such great use of it.  But they decided they would just attack two pages.  Maybe, we don't really understand fully the logic, maybe to run up the bandwidth costs, the bills.  Maybe to just demonstrate that they can do this.  It was extremely difficult to block because the way this Cannon worked was to enlist innocent browsers all over the world.



So during the attack, people were probing the operation from outside.  Security researchers were fascinated to understand exactly what this thing was and what it was doing.  What they learned is that the Cannon is a man-in-the-middle attack.  It is intercepting communications.  It is standing in, like a proxy, for connections, and looking at the content which is passing by.  It is based on the destination IP of the content, that is, where this stuff is going.  It can decide to intercept the reply, essentially breaking that query and intercepting the query and generating its own response.  So this is in the same location, and we'll talk about how we know that in a second, and appears to be closely related to the Great Firewall software. 



In this case, though, some observers have noted that, where this attack was intercepting queries bound for some destination IP, it's very likely that China also has the ability to intercept queries from some specific source IP, meaning that at China's decision, and we don't know that this isn't even going on now because we wouldn't tend to see this in the same way that we saw this massive outbound attack.  It might be that China has the ability, with the Great Cannon, to selectively target source IPs so that, if you ask for any - "you" meaning the targeted IP - asks for any resource that comes from somewhere within China, that this Cannon will intercept the response and can replace it with anything they wish, any kind of, for example, malicious content.  So the architecture, from what's been observed, seems to be able to match, not only on the destination of a query, but also on its source.



So we have the Cannon, which is functioning like a proxy, looking at queries and selectively blocking them from proceeding and answering them itself.  The people who were probing this during the attack used very careful packet TTL.  There's another field in all IP packets called TTL, which is short for Time to Live.  The idea is that because the Internet is, as I was saying, just a loose federation of routers, as packets flow from one router to the next, being essentially advanced toward their destination, this little field, it's an eight-bit field, so it can have a value up to 255, and it's known as the Time to Live.  Every router that receives a packet that needs to then be sent on decrements the TTL field, this Time to Live field, in the packet that it receives.  If it goes to zero, if the receiving router receives the TTL set to one and decrements it to zero, that packet will not be forwarded to its destination.  Instead, the router will send back to the packet's originator, because the packet, remember, contains a source IP, so the router will send an expired message back to the originating IP saying, don't know what happened, but this packet has expired.  It's apparently been bouncing around the Internet too long.



So this was an inspired piece of design from the very first guys that created this packet-switching network.  They realized they had to have some way for packets to die.  They had to age off of the Internet, or there might be a possibility, for example, of having something called "routing loops," where Router A sends the packet to Router B, thinking that it's going towards its destination, and then Router B sends it maybe back to A, in the worst case, but maybe onward to C.  And then C, again, through some router misconfiguration, and this does happen, C sends it on to A.  So now A will send it to B, as it did before, and B will send it to C.  So this packet is just going to go around in a circle.  So we can't have it go forever or the Internet would just collapse.



So all packets die.  And this is - it's crucial that they have to be able to.  So it turns out we can use this, and this is the so-called "traceroute" capability, to trace the route of a packet.  You deliberately set the packet's lifetime to one.  And you put it on the Internet, just like you would if it actually had a chance to get anywhere.  And the first router to receive it will decrement that time to live, which it received as one, will decrement it to zero - I'm afraid I'm going to have to...



LEO:  Clear your throat, my friend, and we will put a little TWiT bug up that says, I don't know what.



STEVE:  A little cup of coffee, a little sip of coffee.  Anyway, so that first router decrements the TTL to zero and says, oh, this expired, and sends that message back to you.  Well, now you know the IP address of the first hop router, as it's called.  Then you set the TTL to two, and otherwise send the same packet again.  Now the first router gets it, decrements the two to one, but that's fine.  It sends it on, on to the next router, that gets the one and decrements it to zero.  Now it expires.  But it expired at the second router.  So the IP address of the message coming back to you saying this expired tells you the IP address of the second router.  And so on.



So by using a slowly incrementing TTL, time to live, of the packets that you put onto the Internet, and looking at the messages you get back, you can trace the route that the packet is taking over the 'Net.  And if you are clever, you can do the same thing, not, for example, just with a ping packet, but you could do that with TCP.  All of the packets which are routed by the IP protocol on the Internet have a time to live, whether that's an ICMP, a UDP, a TCP, whatever protocol you're using, it will have the TTL.  So these guys who were probing this Chinese boundary that was acting so strangely a couple weeks ago verified that the path was the same, and the distance was the same, that is, the same number of hops as the Great Wall had and the Great Cannon had.  Meaning that they were at the same router.



And this was done from all the different entry points of China, many different ISPs, many different facilities within the same ISP.  And in every single instance - sometimes it was 17 hops but not 18, sometimes it was 14 hops and not 15 - the packets got the same distance and hit this Chinese interception system behind the exact same router.



And one other thing was noticed, and that is the packets that the Chinese system generates, the packets that the Great Cannon generates when it's sending back its essentially spoofed reply, and the TCP reset packets that the Great Firewall generate, there's something a little strange about their own TTLs which is unusual, but they are identically unusual.  Which leads the people that have analyzed this to conclude, if nothing else, that they are based on a common software foundation such that the packets they're generating are both unusual in the same unusual way, and turns out to be synchronized.



So everything leads us to believe that there is now an offensive cyber attack tool that is available to China, that they can deploy at their whim.  It looks like it's able to spoof a response from any asset inside China to anyone who asks or any specific set of individuals who asks.  It's also able to spoof that content in a way that can cause browsers which are asking for content to behave as denial of service reflectors, essentially receiving some JavaScript which causes those browsers to then launch an attack targeted at wherever the people aiming this Great Cannon choose to point it.



And it's worth noting that all of this only works if there is no security.  That is, all of this only works over HTTP.  So HTTPS avoids all of this interception.  None of this technology works over HTTPS.  Which, again, makes me wonder how long we're going to be allowed to have secure connections one way or another.  It might be that China just says, no, we're going to SSL proxy everything in order to crack open this security, and we are not going to allow VPNs to tunnel through.  We're just not going to allow any means to get to us that we're not able to filter.  And we see the same pressure from a legislative angle here in the U.S.  It's unfortunate that privacy, Internet privacy is under attack, pretty much from every direction.



LEO:  It's hopeless.  I give up.  I'm going home.



STEVE:  It's all technology.  The technology works.  And unfortunately, in some cases, for some people, it works too well.



LEO:  Yeah.



STEVE:  Because it is the case that China is blind over TLS connections, over HTTPS connections.  They cannot see into them.  And so it'll be interesting to see how long they allow that to happen.



LEO:  It's always been my thought, and I think others have agreed, that the Chinese government understands that anybody with some sophistication is going to get around what they're doing.



STEVE:  Right.



LEO:  And they are okay with that.  They don't mind if the elites can see what they want.



STEVE:  Okay.



LEO:  They don't try too hard to prohibit that, as they might in other countries.  They're more worried about the rank and file.



STEVE:  The 99%, not the 1%.



LEO:  Yeah.  So it seems like there's always been a little of a laissez-faire point of view from the Chinese government that people get around this using proxies and VPNs or HTTPS and so forth.  Although I've got to say they're getting more aggressive.  And maybe that's not still the case.  It depends on who is in power.



STEVE:  Yeah.  And I guess one of the things I wanted to convey is that this is not simple technology.  I mean, somebody - this was in place before someone decided to attack these two pages.



LEO:  Right.  Interesting.



STEVE:  So this Great Cannon, I mean, this is cyberwarfare technology.  This is a massive flood from innocent users all over the world.  So, I mean, as I'm thinking about this, I'm thinking, you know, I could probably do without ever resolving a domain that's in China.  I just don't think I ever need to do that.  And it's sort of tempting to just say, okay, fine.  I'd rather draw, you know, consider that a big black hole that none of my assets ever needs to pull a query from.



LEO:  In this case, GitHub is probably the Alderaan for the Giant Cannon Death Star; right?



STEVE:  Yeah.



LEO:  Let's give them a demonstration.



STEVE:  Really, I found it fascinating that they tried to block it completely, and their own people said, oh, my god, we have to have it.  And I'm sure that China saw it, understood that it was too useful for their own developers not to have access to this incredible open source resource.



LEO:  Wow.  Steve, as always, a great education.  And we've got Matt and Jeremy in here, who say this is the best show on the network.  That's why they're here.  They say, "The heck with those other shows.  We are here to hear Steve."  We do Security Now! every week at this time.  Oh, hey, a couple things I want to tell you about before we go.  First of all, we did mention that we are doing The New Screen Savers.  It's returning, and I hope you will be, as you were on the old Screen Savers, a regular.



STEVE:  Yeah.



LEO:  We won't be talking about the Click of Death.



STEVE:  No.



LEO:  Something - we're updating it; right?



STEVE:  The Cannon of Death.



LEO:  The Cannon of Death.  And this is all part of our 10th Anniversary celebration.  TWiT celebrated its 10th year this weekend.  And we made a special T-shirt, and I want to make sure everybody knows about this.  At Teespring.com/twit, that's where we sell our stuff.  But this, as always, is a limited edition, so don't waste too much time getting it.  We have both men's and women's styles and a variety of sizes.



STEVE:  Oh, you mean don't delay getting it.



LEO:  Yeah.



STEVE:  Because when they're gone, they're gone.



LEO:  They're gone, they're gone, baby.  It's got a nice front piece of the No. 10 with the TWiT logo inside the zero.  And then on the back it's got our official 10th Anniversary badge.  It's a nice T-shirt that will be something very nice to have 10 years from now, and 20 and a hundred years from now.  "I was there the first 10 years."  I also want to tell people, you know, we're looking for callers for The Screen Savers, The New Screen Savers.  Because just like the old Screen Savers, we're going to take calls on the TWiT Netcam Network.



STEVE:  Oh, cool.  Very nice.



LEO:  You know, they wanted to call it the Webcam Network when we were doing Tech TV.  And they said, well, that's technically incorrect.  It isn't a web netcam, it's a netcam.  And so that's why it was called the Netcam Network.



STEVE:  So you'll have the technology to solicit calls, like an 800 number where people can call?



LEO:  No, no, no, we'll do Skype.  We'll probably do Skype so we can see you.



STEVE:  Oh, cool, perfect, perfect, of course.



LEO:  If you have a question you want to ask - and sometimes, by the way, we'll call, you know, you can ask a question about, say, the Great Cannon, and we'll call Steve in on Skype and have him answer it; right?



STEVE:  Nice.



LEO:  You don't have to always be in-studio.  Screensavers@twit.tv is the email address.  Squeen - squeensavers at TWiT, ha ha ha ha, TWiT.tv.  And we'll choose the questions and line you up.  You'll need to be available Saturday afternoon, 3:00 p.m. Pacific.  That's when we record, 6:00 p.m. Eastern, 2200 UTC.



STEVE:  You think it'll be about a two-hour show?



LEO:  One hour.  I'm hope - well.



STEVE:  [Laughs]



LEO:  This used to be a 20-minute show.



STEVE:  That's right.  Just a little quick update.



LEO:  Yeah.  We've got the same basic rundown as the original Screen Savers, which was 44 minutes.  I think we can keep it around an hour.



STEVE:  Uh-huh.



LEO:  We'll see.  So do email screensavers@twit.tv with your Skype handle.  By the way, we want audio and video, so you need to have a camera.  An email address so we can get back to you.  A phone number for backup purposes only.  We're not going to sell it or use it in any way, don't worry.  Or the email.  And then we'd like your name and location, obviously.  And of course your question.  Again...



STEVE:  So it will be a call-in show.



LEO:  Yeah.  I mean, not entirely.  It'll be very much like The Screen Savers.



STEVE:  Yeah.



LEO:  There'll be segments.  It's a variety show because there's lots of stuff that we would like, like you doing coffee, that we'd like to do, but we couldn't do every...



STEVE:  There's no real place for it, yeah.



LEO:  Yeah.  So this is the place.  This will be all sorts of stuff, like The Screen Savers was.



STEVE:  Nice.



LEO:  Screensavers@twit.tv.  And don't forget Teespring.com/twit.  And this show, my friends, I know you will not forget, is always available in 16Kb audio from Steve's site, transcriptions, too, GRC.com.  You'll also find all the other great stuff he talks about including SpinRite, the world's best hard drive maintenance and recovery utility.  If you have questions for Steve, you could tweet him.  He's @SGgrc and apparently now accepting direct messages.  But you know what, don't use the direct message unless there's a reason you don't want anybody else to see it; right?  Public messages are better.



STEVE:  Everybody really liked it when I finally understood how Twitter was supposed to work and just lightened up.  I was DMing everyone, and everyone just said, just, no.  And so this whole...



LEO:  We want to see it.  It's public.



STEVE:  Yes.  The @SGgrc works really well.  And really, it's difficult many times to get into 140 characters what you want to ask.



LEO:  Right.



STEVE:  You know, the problem is people want me to do SpinRite tech support through Twitter.  And I say, look, I have Greg for that.  He'll respond to your email.  That's what I pay him for.  I cannot do tech support in 140 characters.



LEO:  But questions about the stuff we talk about here, that's okay.  And of course you can do it on his website, GRC.com/feedback, if you need more.



STEVE:  That is where I go.  Yeah, on Mondays, every other Monday I go there, I dump the mailbag, and I rummage through it to find the 10 questions.  So that's really the way to get on the show is GRC.com/feedback.



LEO:  And we have full audio quality and video, as well, at our website, TWiT.tv/sn for Security Now!.  And you'll find it wherever you find podcasts.  Steve and I have been doing this nearly as long as TWiT, almost 10 years.  So there's lots of episodes, and it's all at TWiT.tv or in your favorite podcatcher.



STEVE:  Yeah.  This was the second podcast.  Yours was the first.



LEO:  Right.  TWiT was first.  This Week in Tech was first, then Security Now!.  Amber with Inside The Net, I think.  Or, no, it was net@night at first.



STEVE:  Ah, right, net@night.



LEO:  Then the Giz Wiz.  And I don't remember after that.  Windows Weekly came soon, and MacBreak Weekly came soon thereafter.



STEVE:  Sure, right.



LEO:  And then it got out of control.



STEVE:  And going strong after 10 years.



LEO:  Yeah.  It's going great.  I'm really pleased.  And it's thanks to people like you, Steve, so I really appreciate it.



STEVE:  And it's thanks to our listeners.



LEO:  And our great listeners, as always.



STEVE:  Yeah.



LEO:  See you next week.



STEVE:  Thanks, buddy.



LEO:  Bye-bye.  



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#505

DATE:		April 28, 2015

TITLE:		Listener Feedback #211

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-505.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We are going to talk.  Lots of questions.  Lots of answers.  At the end, a little discussion of favorite programming languages.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 505, recorded Tuesday, April 28, 2015:  Your questions, Steve's answers, #211.



It's time for Security Now!, the show where we cover your security and privacy online, with a guy who knows all, tells all, and he does it in plain English, which is kind of remarkable, Steve Gibson.



STEVE GIBSON:  And I'm half behind the flowers on your other camera.



LEO:  You are.  ProFlowers.  Well, you know, Mother's Day is next...



STEVE:  That's fine.  We can see me.  Yeah, that's all anybody needs.



LEO:  Lisa sent me these.  This is one of our sponsors, ProFlowers, and I thought I'd just kind of dress it up for you.  



STEVE:  Oh, very cool.  Oh, that's - create a little jungle scene.  I like that.



LEO:  Yeah.  I actually just got a big box from them.  I don't know what this is.



STEVE:  I am peering through the leaves.



LEO:  These might be roses.  Long, long-stem roses.  Anyway...



STEVE:  We didn't talk about advertisers on the show.  How many do we have?



LEO:  We have the usual company of advertisers:  PagerDuty, Dropbox, and Braintree.



STEVE:  Okay.



LEO:  All the geek ones.  Dropbox for Business actually is a new one for you.



STEVE:  Ah, yes.  We have not had them on before.  So this is a Q&A.  And there's a lot of news this week.  So we've got some fun - well, because it was the RSA Conference last week.  And so, as often happens, we learn a lot that we didn't know before from the presentations at the annual RSA security conference.  That of course is where I ran across Stina of Yubico and immediately understood what they were doing.  So all kinds of good things always happen there.  A lot of news from that.  And then great questions and comments and stuff, fodder from our listening audience.  So we've got a great podcast today.



LEO:  I always love the Q&As.  Just because they ask the questions I've really got in my mind.  Oh, I'm glad somebody asked that one.



STEVE:  So I got a kick out of the little Image of the Week on the first page of the show notes.



LEO:  Uh-huh.  I see it.  Let me open it up full screen so everybody else at home can see this cartoon.  It says:  "My biometrics authentication just told me I need a shave."  Oh.



STEVE:  Ah, yes.  And today we actually have a little bit of coverage of some interesting biometrics problems that also surfaced at RSA.  But so this is a guy using his face to authenticate himself.



LEO:  Well, and we are now, aren't we.  Biometrics are big.



STEVE:  Yeah.



LEO:  We use Touch ID on everything now.



STEVE:  Yeah.  Okay.  So the first story coming out, well, the first big one, was one of these where unfortunately all the headlines were inflammatory.  I don't know if it was on purpose, or if the people, well, there have been instances, we know that oftentimes people who write articles are different from the people who put the headlines on them.  I had the problem during my Tech Talk column is the headline would often say something way more over the top than I intended or than the content said.  But that's the way publishing works, for whatever reason.



LEO:  Yeah.  And they're trying to get clicks.



STEVE:  Yes.  So a group known as "Skycure" during the RSA Conference on Tuesday revealed a new flaw in iOS.  The timing was such that it was essentially resolved around the time of the release.  That is, it's fixed in 8.3, which we should all have had for like a week now.  But the headlines said things like, "Security Flaw in iOS 8 Can Permanently Crash Your iPad or iPhone."  Or another one, "iOS Bug Sends iPhones into Endless Crash Cycle When Exposed to Rogue WiFi."  Or "Researchers Find Another Terrifying iOS Flaw."  It's like, oh, my lord.  And I had people, like, in a panic, reaching out to me, saying, "Steve, I love my iPad.  I don't want it to be permanently crashed."  It's like, okay, calm down.



So what this is, is this group discovered that there was a bug in the certificate parsing of iOS 8, or iOS before version 8.3, where it was fixed, that would cause iOS, upon contact with a WiFi hotspot, to crash.  And then they noted that, for example, AT&T iOS devices, like AT&T-based phones or iPads with cellular service, automatically connect to any network named ATT WiFi without even asking.



LEO:  See, promiscuous WiFi.  It's always a problem.



STEVE:  Exactly.  So their whole deal was, okay, they found a certificate parsing flaw, which is not good, and it's been fixed.  And if you were in range of a rogue WiFi hotspot that was offering this certificate, your device would crash.  Then it would reboot, reconnect, and crash; reboot, reconnect, and crash.  And do that endlessly.  All you had to do, of course, was turn it off or walk away, get out of range, and then turn off WiFi, and you'd be fine.  Anyway, it's been resolved.  And I think it falls far short of being a "terrifying iOS flaw."  I mean, there's a...



LEO:  And it's not permanent.  I mean, as soon as you go somewhere else, it'll stop.



STEVE:  Right.  Right.  It was just while it was in - if you had WiFi on.  And of course you're punished for trying to turn it off because, oh, location services work so much better with it on, as we've discussed.  So anyway, that's all that was.  It wasn't doing any permanent damage.  It was a sort of a style of denial of service, inasmuch as, if you happened to be within range of a rogue WiFi that was getting its jollies briefly, until this was fixed, in crashing iOS devices, yeah, then I guess that was an Android-only hotspot for a while.



Also at the RSA Conference, this time on Friday, the guys at FireEye had some not good news for Samsung S5 Fingerprint Reader people.  Basically, it's a security catastrophe.  Their talk was titled, "To Swipe or Not to Swipe?" - and of course using "swipe" figuratively because we're not really doing that anymore, we're using static images - "A Challenge for Your Fingers."  And so they start the talk by noting that, if a password is leaked, you can change it.  But if a fingerprint image is leaked, that's a problem because we're unable to change our fingerprints.



So they articulated three classes of attack, something they called the "confused authorization attack," the "fingerprint database manipulation," and "fingerprint sensor spying attack."  And we can imagine what those are.  I'll just quote a little bit from this.  It said:  "Android phones typically store sensitive data such as fingerprint information in a walled-off area of memory known as the 'trusted zone.'  However, FireEye researchers found it was possible to grab identification data before it is locked away in the secure area.  This method of stealing data was available on all phones running under v5.0 or older of Android, provided the attacker got high-level access to the phone.  They also found that on Samsung Galaxy S5 phones, attackers did not need deep access to a phone.  Instead, just getting access to the gadget's memory could reveal finger scan data.



"Using this information, an attacker could make a fake lock screen that makes victims believe they are swiping to unlock a phone, when they're actually authorizing a payment.  In addition, they found it was possible for attackers to upload their own fingerprints, then authenticate to the device, since the devices were not keeping good records of how many prints were being used on each device.  The flaws they uncovered were widespread throughout handsets running Android 5.0 and below.  Updating to the latest version of Android, v5.1.1, should eliminate the vulnerabilities."



So once again, this was coordinated and timed so that they were able to say, look, this is the important research we did.  At the same time they were - we didn't have to wait long before we got these problems fixed.  But of course we know this is why we inspected so carefully Apple's initial implementation of a fingerprint scanner, because, I mean, exactly these sorts of things.  You really don't want your digital fingerprint to get loose.  But then the flipside is, while fingerprint authentication is easy, we've also seen that all of these sensors can be spoofed.  And now we're even seeing things like high-resolution photos of somebody waving is like - we have enough resolution in our cameras that you can capture a fingerprint from a photograph.



So what this really says is that we need to back off a little bit in thinking that our fingerprint is an unspoofable, super secure method of authenticating ourselves.  It's got the problem that we can't change it, which is one problem.  It's got the problem that law enforcement can force you to use it, which is another problem because it's not something you know, it's something that you can't be separated from, hopefully.  So it's, yes, it is very convenient.  But we need to stop thinking that it's absolute protection.  There is a tradeoff that we're making.  It's just the fact that we leave our fingerprints around all the time, you know, on glasses that we pick up and on the screen of the device which itself might be subject to attack.  So we certainly want the underlying technology to be as secure as possible.  But I would just caution everyone to remember that there are downsides to it.  I love mine.  In fact, it's funny because I have multiple - I have several generations.  Well, I have every generation of iPad.



LEO:  Of course you do.



STEVE:  Of course.



LEO:  Some in the fridge, no doubt.



STEVE:  And the one in the car is the latest, with the fingerprint reader.



LEO:  You have a car iPad?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  Yeah.  It's out there charging.



LEO:  Is that...



STEVE:  Yeah.



LEO:  Okay.  So you just always have it.  So that way - that's for the coffee shop; right?



STEVE:  Exactly.



LEO:  Yeah, okay.



STEVE:  That's for whenever I'm roaming, I've got an iPad with me.  And it stays in the car and charges from the cigarette lighter.  Anyway, so I've got one in the living room, one in the bedroom, one of course in the bathroom.  I've got one next to me right here.  They're all over.  Anyway, only - we don't want any waste of time.



LEO:  How do you keep them in sync?  I mean, you have to install, I mean, aren't they all...



STEVE:  No, they all synchronize themselves through the cloud, magically.  Anyway, my point is that I only have a fingerprint reader on the one that I'm going to be traveling with, the one in the car.  And I get mad now at the other iPads.



LEO:  Yup.



STEVE:  Because I'll put my thumb on the button, and they'll light up, but they don't do anything.  And I go, "Oh, I have to swipe the screen.  What an annoyance."  So anyway, yes.



LEO:  Or worse, enter your password...



STEVE:  Crazy world we're in.



LEO:  ...when you want to buy stuff.  It's so much nicer to have the fingerprint reader.  And I feel like it's accurate.  I know we've talked about this before.  It seems like it's good.  It's not - you're not going to get - despite this problem with the Galaxy S5.  They didn't say it's the Note 4, which also has a fingerprint reader, or the new S6; right?  Just the S5.



STEVE:  True.  The sense I got was that there was something about the design of the Samsung S5 that allowed them easier access to it.  And they pointed it out, and the architecture's been changed in order to sort of move things around a little bit better.  You could actually get access to that authorized fingerprints database from user mode.  And so that stuff should be really walled off better.



LEO:  Also, by the way, the S6, the newest Galaxy, has a fingerprint reader that's very similar, in terms of usability and training, to Apple's.



STEVE:  Nice.



LEO:  So I'm really pleased because it means it won't just be iOS devices that have this capability.  And they're using a Synaptics, I found out, Synaptics fingerprint reader.



STEVE:  Yeah, they've been around forever.



LEO:  Yeah.  They do the track pads on most computers.  So that means this is, I think, a technology you're going to see in a much more widespread fashion.



STEVE:  Yeah.  My feeling is, it is a really good tradeoff.  I like the idea of what Apple has done, that if you don't use your device for 48 hours, it says, you know, we want to make sure you're still you.  And so you have to enter - or after you do a full system restart you have to give it your password to kind of get it up and going.  But then, I mean, we don't want something so onerous that people will not use something secure.  And arguably, the security versus hassle tradeoff of a fingerprint is a win, so long as it then performs perfectly, that is, it isn't leaking data.  It doesn't false positive or false negative.  If we take it from the concept of a perfect fingerprint reader, I think that's a perfect set of tradeoffs because people will tend to use it.  And it's certainly better than having your device unlocked because you get - you're just annoyed having to type your password in every time you turn it on.



LEO:  Yeah.



STEVE:  So one of the real questions we've had has been how are people getting infected by CryptoWall.  And also at RSA, the guys at Malwarebytes revealed just what is frankly a terrifying truth.  For two months, starting on December 10th of 2014 through February 2nd, when Adobe patched a zero-day flaw in Flash, CryptoWall, that we've talked about often, the essentially CryptoLocker lookalike, which encrypts all the files on someone's machine and then asks for ransom, it was able to install itself through malicious ads that were being injected through the number one advertising network.  And they didn't reveal the name, but they just said it's the number one advertising network.  You can figure that out for yourself.



And those ads were appearing on typically for around two days each on sites like - they were found on Dailymotion, Huffington Post, Answers.com, New York Daily News, HowToGeek.com, Tagged.com, and a handful of others.  Because this was a Flash vulnerability, it was not necessary for the user to do anything.  They don't have to - it's not - yeah, I mean, this is as bad as it gets.  You don't have to be fooled into a phishing attack, clicking on a link that looks authentic in email.  You simply go to the Huffington Post or Answers.com or HowToGeek.com with a browser that has the Adobe Flash plugin still enabled and willing to run, and that's all it takes.  You receive, if you happen to, in ad rotation, one of these deliberately crafted malicious Flash ads.  It leverages the vulnerability, escapes from the browser, downloads CryptoWall, and encrypts your system.  So the good news is...



LEO:  That's really bad.  And it probably does it in seconds; right?  I mean, it's probably very quick.



STEVE:  Yeah.  Yeah, it's, I mean, all of this stuff is unfortunately at the speed of light.  So, and then it begins to encrypt, and you're in trouble.  So the Malwarebytes guys found that the hackers were using something called the HanJuan exploit kit, which was hosted on rotating domains to evade detection.  And it's, interestingly, it was also - it wasn't a global attack, even though those websites are globally available.  One of the things it did was it deliberately targeted U.S. consumers operating from residential IP addresses.  We don't really know why, but that was just their target.  And no action needed for the infection, just for Flash to run.  So, boy, I tell you, I mean, if you didn't have enough reason to remove Flash from your browser before, the fact that we're seeing the ability to inject malicious ads using zero-day unpatched vulnerabilities - oh, and what's interesting is this date on February 2nd, the patch was released on the 2nd from Adobe, and the next day the attack campaign stopped.  So...



LEO:  Wow.



STEVE:  Which is really interesting.  To me, that's... 



LEO:  Kind of proves it, doesn't it.



STEVE:  Yeah.  Well, yeah.  And it also says that there were a set of tradeoffs the criminals were balancing because they didn't want to give up their network, that is, they didn't want their network to be discovered.  They didn't want themselves to be discovered in any way.  So as long as there was a high probability, that is, a sufficiently high probability that they could get a percentage of victims that made it worthwhile, they were willing to expose themselves to the degree they were.  And, for example, they did enough that Malwarebytes was able to find them and track them and build this complete profile.



But the moment that probability of infecting people dropped, they immediately pulled their system down, obviously to preserve it for the next opportunity.  They didn't want it to be taken apart.  As soon as it didn't look like it was going to pay off, it's better to protect it and keep it secret than it is to expose it as the number of people patch and the probability of getting CryptoWall infections drops.  So I think that represents, among these facts, one of the most interesting is that the logic, the strategy is, as long as this is unpatched, we're going for it.  But everything we've built in order to make this happen, the bad guys presumably think, only makes sense to keep deployed until the patch happens.  So that also implies that they've seen rather rapid patch adoption.  It's not like they waited a month and then they shut it down.  The next day, gone.  So...



LEO:  Wow.



STEVE:  Yeah.  Really interesting little peek behind the curtains.  Okay.  Now, last week we talked about this arguably, I mean, bad but not end-of-the-world problem in a very popular open source networking library that about five, sorry, 1,500 iOS applications were believed to have used.  That was this AFNetworking Library.  So it's very popular, free, open source.  iOS apps drop it in, essentially use it when they want SSL/TLS connections.  And I'm not an iOS developer, so I don't get why this isn't a system service.  But apparently it isn't.  Apparently, if you want whatever it is this AFNetworking Library does, you can't ask iOS for those services.  Maybe iOS is too protective, or who knows.  But so people are adding it to their own apps.



The problem we discussed last week that had a relatively short window was from 2.52, which was introduced in January, to 2.53, that was where this problem was corrected.  So it was only about three-month window, not really a huge problem.  Well, I guess people have been looking at it a little more closely because now an unbelievable problem has been found.  And it's being misreported as bugs, and it's not a bug.  It is an insane default setting.  There is a setting in the configuration for this AFNetworking Library named "validatesDomainName."  It defaults to "no," starting with v2.  So, which is to say, that's telling the library not to check the name on the SSL certificate that the remote site has just given you.



And it turns out there are somewhere between 25,000 and 50,000 iOS apps that are believed to be at risk.  We don't have an exact number because it's difficult to go in and figure out which version any app is using and so forth.  But what this means is that there are a huge number of apps, including Bank of America, Wells Fargo, and JPMorgan Chase, which are using vulnerable versions of this AFNetworking Library, where the library verifies the validity of the certificate.  It does all of its checks, verifies the signature, verifies the chain of trust back to a root authority, checks the date to make sure that it hasn't expired.  Doesn't check the name.  So that means that all a bad guy has to do in order to intercept and decrypt communications is present any valid certificate.  They don't need a BofA cert.  They can use a Joe's Hardware cert.  And as long as it's valid and signed by one of the regular certificate authorities, the AFNetworking Library says, yeah, fine.



LEO:  It's signed.



STEVE:  Yeah.  It looks good.  Not the right company, not the right domain, but we've been compiled with validatesDomainName set to no.



LEO:  Wow.



STEVE:  So nobody can understand how this change got made or why.



LEO:  Does this remind you of that programming bug that was in there?  What did we call that, where they put in this conditional, and it just jumped around validation?



STEVE:  Yeah, goto, the...



LEO:  Goto.  That was in iOS, as well; wasn't it?  The goto bug?



STEVE:  Yeah. 



LEO:  And it had the same upshot; right?  Which is it ignored validation.



STEVE:  Yup.  It just looked like it was...



LEO:  It's goto fail.  Goto fail.



STEVE:  Goto fail.  Right, right, right.



LEO:  Yeah, thank you, John.



STEVE:  And you could even stare at the code, and it's like, okay, looks fine.  And this is the problem with code is you really have to stare at it in order, I mean, mostly that's where I use a debugger is I don't need it often because I write code incrementally.  I'm a write/test, write/test, write/test.  So I'm constantly checking everything about what I've just written.  Then I move on.  So it's only occasionally that I'm, like, staring at the code, which doesn't do what I expect, and I can't see it.  And so what the debugger does, of course, is it just rubs your face in it.  You go, you know, step by step by step by step.  And it's like, oh.  And then, you know, you realize what your mistake was.  But sometimes that's the nature of this.



LEO:  I'm going to - okay.  Let's go conspiracy, all conspiracy on you.  What if the same person that put goto fail in the code, which was this subtle bug that eliminated domain validation, also made this default no?



STEVE:  Yeah, it's an open source library.  I mean, someone maybe, it would be interesting to see where the commit, who made the commit to...



LEO:  And we never found out who did the goto fail commit, even though Apple must know that.



STEVE:  No.  Yes, right.  And so it's just - it's a little spooky that there could be this sort of longstanding problem.  And, now, if people use the library knowledgeably, that is, if they went through the config and said, wait a minute, validatesDomainName is set to no?  Does that mean what I think it means?  They would set it to yes.  So, but nobody can understand why it wouldn't be yes.  There isn't a - except maybe for testing.  In a testing mode, you might want to say, look, turn off validation for a minute, just because it's a hassle to get the right cert named.  I mean, I'm making something up.  I can't - I'm trying to come up with a justification for this.  But on one believes the package should ever, ever ship this way.  And the whole point of using a library is that you don't have to write it yourself.



Now, some people might argue, well, yes, but you should be a responsible user of it.  Well, okay, but it ought to default to sane settings.  And this defaults to don't bother checking the name on the certificate.  It's incomprehensible.  Now, the problem is a huge number of apps are using this very popular library, at least 25,000, maybe as many as 50.  The company that has been on the front of this, this SourceDNA gang, they've got this search system.  The problem is they can't publish the list because of course then that creates attack targets for the bad guys.  So their sort of compromise is to create searchlight.sourcedna.com, where you can put the name of an app you are wondering about in, and they will tell you what they think about it.



So, I mean, which is really, if I look at the number of icons I've got on my pads, having been an early adopter and a frantic user of all this stuff ever since, I can't imagine checking them all.  But maybe your more important ones - BofA, Wells Fargo, JPMorgan Chase, which unfortunately are all on the bad list - and look for updates.  This is fixed in the latest release.  But unfortunately, whereas this prior problem only had a window, because it was an actual bug that was introduced in 2.5.2, that lasted for three months till 2.5.3 that was about a week ago, this one was everything in v2.  So until last week, everything compiled with v2, unless they either turned validatesDomainName to yes, or they could be using other techniques, for example, certificate pinning, where you actually check the serial number of the cert that cannot be spoofed.  So it is possible that some of these apps, like for example BofA, might have left validatesDomainName set to no because they know, the app knows the serial number of the legitimate certificate and is verifying that, which is a possibility.



I mean, again, we're trying to make excuses.  The only way I could think, well, I mean, I could think of ways to test it.  You could play games with your hosts file on your own system in order to redirect a domain you wanted to check, like Wells Fargo, to Google.com, and see if the app, it's going to give you some sort of error, but see if it gives you a bad certificate error, or refuses to connect, or if it sort of fails in some other way, which would be a concern.  I mean, unfortunately, none of these are good tests.  We're sort of stuck.  We need an incredible number of apps to be updated.  And until that happens, we don't have the security that the application authors intended their apps to have because validation of domain names was set to no for some unbelievable reason, unfathomable reason.



Yubico got caught by a little open source software problem.  They issued a security advisory on April 14th.  It turns out there was a logical mistake in the open source code that Yubico inherited from the Java Card OpenPGP project.  There were - and this is another example of code being hard to read.  This really is hard.  This one makes your eyes cross because - only because it's a double-negative with a conjunction.  You can see the if statement here in my notes.  The source code that they inherited contains a logical flaw that relates to the validation of the PIN that users have to enter which, if abused, allows an attacker with localhost privileges or physical proximity, like within NFC range, to perform security operations without knowledge of the user's PIN code.  So it's a PIN bypass.  And you can see, unfortunately this split across page boundaries, but they've got an if statement, and then open parens, and then "not pw1" is validated and "not pw1_modes" and then some mode function bit.  And so they're...



LEO:  They both need to be true.



STEVE:  They're inverting the sense and then ANDing them.  And in that case...



LEO:  Right.  So they prove that to be false, then; right?



STEVE:  Correct.



LEO:  Let's see, validated and this not satisfied.  So they both have to be true.  And what you really want is either one is true.  That would...



STEVE:  And so that double ampersand should be a double vertical bar.  That should be an OR conjunction, not an AND.  And again, this is, like, this is the kind of thing that our human brain just doesn't process that well.  In fact, in their security advisory, Yubico draws out a truth table of all four possibilities of both modes, their inversions, and their conjunction in order to say, look, this is wrong.  Anyway, so the Java Card OpenPGP project has been notified.  That same if statement occurred in three places in the code, all wrong.  I mean, identical but wrong.  So someone wrote it once and then copied and pasted it because they wanted the same function a couple more times.  And Yubico, this ends up in the firmware of the NEO.  So this only affects the YubiKey NEO.  If you are using any version before 1.0.10, and you're using the OpenPGP applet, they will replace your NEO key at no charge.  So you can go to...



LEO:  Oh, that's nice.



STEVE:  ...yeah, yubi.co/support to learn how to log a support ticket and receive a replacement for free.  They're taking responsibility for this.



LEO:  I guess a firmware update is not possible.  They have to give you a whole new hardware, yeah.



STEVE:  Precisely.  It's deliberate, I mean, this protects it...



LEO:  They don't want it writeable.



STEVE:  ...from the bad, exactly, from the BadUSB problem, is it's like, nope, this is factory only.  Oh, god.  And I just - I got a kick out of this story.  This is sort of random.  But this is from the "what could go wrong" department:  "Amazon to start delivering packages direct to vehicle trunks."



LEO:  I saw this.  I love this.



STEVE:  Oh.  I do, too.  This is just - okay.  So Amazon and Audi in Germany are conducting a pilot experiment to allow DHL delivery trucks to find and remotely open the trunks of Audi vehicles of owners participating in this project.  And the story was interesting because it highlighted some problems I never really appreciated before.  So I'm just going to share this.  It says:  "Together with delivery partner DHL, Amazon and Audi aim to ease a common frustration among commuters:  never being at home when the delivery company brings goods that were purchased online."



LEO:  I hate it when that happens.



STEVE:  Don't you.  Of course, you've got all kinds of doorbell things that ring, so you know when the guy is there.



LEO:  I can even let him in.



STEVE:  That's right.  "Parcel-to-vehicle" is what they're calling this.  "Parcel-to-vehicle delivery might help reduce the number of failed delivery attempts and temper a parcel logjam in large offices caused by employees who input their employer's address when ordering goods."  So you can see what that's saying is that one solution people have found is, oh, deliver it to my office.  Well, yeah, it's a 112-story building.



LEO:  Yeah, where are you, yeah.



STEVE:  You're Mabel Appleby, yeah.  So carmakers, meanwhile, "are seeking to offer," god help us, "to offer an array of add-on 'connected' services to retain tech-savvy customers and ensure the profits accrue to them and not to software companies.  Audi said there were no vehicle insurance implications because the delivery agent will not be able to access the vehicle cabin."  Which rules my car out because from the trunk you're able to pull some snaps and fold the back seats down in order to make room for bigger stuff and thus get into the inside of the car.  But on the other hand, believe me, I'm not a candidate for this wacky thing.



LEO:  I, by the way, I can't wait.



STEVE:  Oh, I know.  "The carmaker said that in future customers would also be able" - oh, get this, it's going to be a two-way service - be able to send letters or parcels..."



LEO:  Mm-hmm, mm-hmm, leave it in your trunk, yeah.



STEVE:  "...left in the trunk of their car."



LEO:  I can't wait.



STEVE:  "And Amazon said it was working on a solution to allow goods to also be returned via the boot," as they call it.  "When ordering, Amazon customers will indicate the rough location of the vehicle and desired delivery time.  A DHL delivery agent will later be notified of the exact location via a smartphone app.  The agent is granted one-time keyless access."  And actually, circumventing this was the topic for next week, except that the congressional testimony of Matt Blaze, famous cryptographer, the guy who found the problem in - I'm blanking.  What was the government key escrow nightmare?



LEO:  Oh, yeah, yeah, the - yeah, mm-hmm.  Clipper Chip.



STEVE:  Clipper Chip.  He found the problem in Clipper Chip.  Tomorrow he's testifying in a congressional committee hearing.  I was hoping that C-SPAN was going to be covering it, but they're just not - no one's doing much tomorrow, unfortunately.  But I do have his testimony that has a number of amazing things in it.  So I'm going to share that with our listeners next week.  But in three weeks from now I want to talk about bypassing keyless entry because I found the whitepaper about how to do that, you know, how these people walk up to the car, and it unlocks.  And it's also really clever, in a different way, and chilling.



Anyway, so "The agent is granted one-time keyless access to the boot of the vehicle; and, when the boot is shut again, it locks automatically," like a good trunk should.  "The customer must agree for their vehicles to be tracked for a specific timeframe and is notified via email upon successful delivery."  And Leo, as soon as this service is available in Petaluma, we want your full report.



LEO:  I'm going to totally do this.



STEVE:  I'm sure that your Watch will tap your wrist as soon as your package has been - as your mail has been taken out and your parcels have been delivered.



LEO:  It's already in the trunk, and I can just drive home with it.



STEVE:  You could be having dinner out in the restaurant parking lot and, oh, look.



LEO:  They deliver this to the front desk, I have to schlep it all the way back to the trunk of my car.  I don't want to do that.  Just put it in the trunk.



STEVE:  That's right.



LEO:  What could possibly go wrong?



STEVE:  What could possibly go wrong.



LEO:  Unless they put, like, I get a malicious DHL guy who puts a bomb in my trunk.  But that could never happen.



STEVE:  This is why the podcast will never end, Leo.



LEO:  [Laughing]



STEVE:  Now, this one is interesting.  This sort of spun me in a circle because I started off - okay.  So the title of this topic in my notes is "Why ad blocking is devastating to the sites you love."  Which was the title of an editorial written by Ken Fisher, the founder and editor-in-chief of Ars Technica, back in early March of 2010.  I found that when searching just sort of curiously for dialogue about the ethics and morality of ad blocking.



LEO:  Thank you.



STEVE:  Because there was a project on GitHub called uBlock, which is there, uBlock, on GitHub, which compares itself to Adblock Plus, MultiBrowser, Safari, Chrome, Opera, Firefox.  It is able to use the - it uses the Adblock Plus protocol, and syntax is really what I meant, so that things like EasyList can be subscribed to.  And they go further, and they compare themselves showing much lower memory usage, much lower CPU usage, blah blah blah.  So I thought, okay.  And it'll do more things.  It's sort of a general purpose blocker.  So I just sort of thought, okay, what's the status of that?  For a while I was thinking I want to launch this as a topic over in the GRC newsgroups, although we did do this, like, a decade ago, probably pre-podcast, had a really interesting discussion about the pros and cons.



But what Ken's article said that stopped me cold was, well, the article begins, the first line is "Did you know that blocking ads truly hurts the websites you visit?  We recently learned that many of our readers did not know this, so I'm going to explain why."  And the short version is that sites are paid for impressions, not only for click-throughs.  In our common...



LEO:  In our case it's impressions a hundred percent.



STEVE:  Right.  And so the common misconception is that only if you click on an ad is any value accrued to the site.



LEO:  We don't do that.  We do impressions.



STEVE:  And I've heard people say, oh, click a few ads to pay them back.  And we've heard, for example, of malicious scams where malware will bring up a site and click the ads in order to generate revenue.  But as you affirm, Leo, it's impressions.  So what that says is that the act of your browser taking the time to retrieve the ads from the ad network or wherever, that act generates revenue for the site.  Which means by preventing your browser from doing that retrieval, I mean, the tough area is that you have control over your browser.  And I'm the first one to say, I mean, I have a low tolerance for obnoxious ads.  But I don't mind at all if there's ads on the page when I understand that the act of my browser retrieving those ads is providing revenue to that site.



And so for me, I mean, it's actually why I've liked what Adblocker has done because there's a huge list of permitted ads.  They just want them not to be obnoxious, not to be jumping up and down and popping stuff up.  I actually turned JavaScript off on Safari for a while on my iPad, my beloved iPad, because as it happened the sites I was going to had just horrible pop-ups coming onto the screen that were really obnoxious.  And so I thought, I'm just going to turn off JavaScript so this stuff can't happen.  I ended up having to turn it back on because of course sites don't function very well without it.



But anyway, so I wanted to make sure that our listeners know that pulling the ads is generating revenue for the sites they visit.  And as long as it's not abusive, I mean, it's true that the advertising agencies could go too far, could flash things and have things jumping around and so forth, which I would regard as a problem.  But short of that, given that ads are willing to sort of be compatible with our main focus, which is to get content from the site, I'm glad to know that it is the browser pulling the ad.  Yes, it takes a little time.  Yes, it takes some CPU resources.  Yes, it does all those things that the uBlock folks are bragging that theirs doesn't.  But is that so much to ask?  You and I, Leo, have talked about how we will give a hundred bucks every year or so to Wikipedia because we're using it.



LEO:  Yeah, I'm a monthly donor, yeah.



STEVE:  I mean, we're actively using it.  Right.  And I also, like the NoScript guy, I'll just send him a blob of money when I realize, you know, I haven't done that for a while, because I really want it to continue.  Well, we really want websites to continue.  And I just don't think having my browser pull the ads and, as long as they're innocuous enough, present them to me.  I mean, I don't look at them.  I don't click on them.  But I think that's a completely acceptable tradeoff.  And I don't have a single ad on my site.  But I still, you know, I want the sites I care about to not go out of business.  And we have seen some sites dying recently.



LEO:  GigaOM.



STEVE:  Yes, that haven't been able to make ends meet.  And anyway, the other point that Ken made was, unfortunately, because Ars Technica is a technically oriented site, they are...



LEO:  That's the problem.  And same with us.  We have savvy viewers.



STEVE:  Disproportionately affected by ad blocking because you're not - it's not the common grandmother who's got a generic machine that she purchased and turned on.



LEO:  Yeah.  Doesn't bother Yahoo! at all.



STEVE:  Right.



LEO:  It bothers Ars Technica.  Now, I'm going to say a few things, if you don't mind, because...



STEVE:  Yeah, please, please.



LEO:  A, we don't - I completely understand why people block ads.  And somebody shut me down, I think it was probably on Twitter, when they said, "But Leo, do you skip ads on your TiVo?"  Of course I do.  We don't watch "American Idol" or "The Voice" live because there's so many ads in there.



STEVE:  It's impossible.  You can't.



LEO:  We just skip through them.  And so we're doing - I do the same thing to television.  So that's one thing.  The other thing is our ads on our website are a very small amount of income for us.  We use them, we do it for other reasons, the way we can get them - it's part of a package that we sell which includes the important ad, which is the ad on our show.  The other thing that is really important, I think, is that of course people are blocking ads because they're annoying, but also they're malware.  There's all sorts of issues with these banner ads.  And I understand that.



And so to me the solution, really, long-term solution is for publishers, and I include podcasters as well as website publishers, to consider their audience, to make sure that, if they're doing advertising, they're doing it in an appropriate way with ads that they might be interested in.  We're very picky.  I turn down advertisers every day.  And you ought to see how pissed off people get when I say I'm not going to take your ad.  It drives them nuts.  They say, "Why not?  You think there's something wrong with us?"  I say no, it's just not a good ad for our audience, or for whatever reason I don't want to advertise for it.  And then I think the other thing is you have to have a connection with your audience.  So we know that our ads work because our audience wants to support us; right?  People love Steve.  They buy SpinRite because they love you.



STEVE:  Right.



LEO:  As much as because it's useful.  So you do exactly the same thing.  You make a useful product, you tell people about it every show, and they buy it to support you.  And that's kind of the same thing we do.  And that has worked for us.  So it is possible.  And I think you have to respect your audience.  And I think the real problem is so many sites don't that the audience has been compelled to use ad blockers because they can't take it.  But there's this ethical conundrum because you're saying I want the content, but I don't want to pay for it.



STEVE:  Yeah.  I would, I guess, first of all, I'm also a commercial skipper.  I cannot watch them.  But I think that's more like the ads are on the page, and my eyes refuse to focus on them.



LEO:  I do that, too, by the way.  When they do an ad takeover that you can't read the content, I avert my eyes for the four seconds because I don't - and then I click "continue."



STEVE:  Yeah, I just, I mean, I'm averse to having stuff pushed in my face.



LEO:  I agree.  I agree.



STEVE:  And if TV commercials were engaging and, you know, like Super Bowl, look at Super Bowl commercials, my goodness.  They're fantastic commercials.



LEO:  You watch the Super Bowl to see the commercials.



STEVE:  Right.  Oftentimes that's the case.  So anyway...



LEO:  So we do things because we understand that.  We only do one ad per half hour ever.  That's the maximum, compared to 15 minutes per half hour on network television.  We only do ads for products we use and can endorse.  We try to pick products we think our audience would be interested in.  We try to make them relevant.  And we don't spy on our audience to find out about that.  I just use my instinct.  I think we do the, I mean, we are ad supported, so this is something that's of interest to us.



STEVE:  Well, and our listeners don't know that I get email from your staff saying, "Hey, Steve, this is a company that wants to advertise.  Do they look okay?"  I mean, that happens all the time.



LEO:  Yeah, we vet every single - and, you know, we're at the point, we've been around long enough now, that we get approached every day by people who want to buy ads.  And they're just shocked that we will turn their money down.  Just shocks people.  But it's part of our deal with you, our audience.  So, and yeah, we do, we vet every single advertiser.  We make sure they're the real deal, and blah blah blah.  It's an interesting thing, and I do still skip ads on TV all the time.



STEVE:  Yeah, I just...



LEO:  I understand.



STEVE:  But on the other hand, they're there, and it's what pays for the content, such as it is.  And there are a lot of people who, I mean, what, are you obligated not to go to the bathroom during the commercial break?



LEO:  No, in fact...



STEVE:  What can you do?  Anybody who's watching in real time may have other things to do.  So, I mean, ads have always had sort of a rough go of it.



LEO:  Yeah, yeah.



STEVE:  I think they have to survive on their own.



LEO:  They do.  If they weren't annoying, we wouldn't do it.



STEVE:  Right.  And so I just - I wanted to make sure people understood.  I thought that was an interesting point.



LEO:  Thank you.



STEVE:  First, that impressions, your browser pulling the ad generates revenue for the site.  And secondly, that also then, that note that we probably tend to - we, this podcast-listening audience, tend to more technical sites that may also have higher costs just because to have higher quality content, more technical content, is a little more expensive.  And we're also the same people who would tend to be blockers.  And so I would just say, you know, think about how you feel about it.  I've seen other people's computers where there is no control, and it's like, oh, my god, this is for people...



LEO:  It's pretty bad, isn't it.



STEVE:  Oh, lord.



LEO:  It's worse than you knew.



STEVE:  How do you use this?



LEO:  You know, it's funny, because Ars Technica, shortly after that column, started a premium service where you would pay and get some additional features.  And I paid immediately to support them because I really love their content, and I don't want them to suffer.  I want them to do well.



STEVE:  Yeah.



LEO:  It's a great site.



STEVE:  So somebody posted on Stack Exchange a quick modification to - and I haven't got a link yet to my TrueCrypt page, but I will - to the installer script for TrueCrypt, which has had a problem with Yosemite when it went to 10.10 because the installer script wants to make sure that you're on Mac OS X v10.4 or later.  So it was happy when you were at 10.9.  But when you went to 10.10, unfortunately the comparison, it's probably a string compare or something, which sees the one as being lower than the four of 10.4 and refuses to install.  So it's like five lines that you remove where it's checking the version of the install - it's checking the version of Mac OS 10, and then it installs just fine on Yosemite 10.10.



So this happened when we went to 10.10.everything because it's just doing a non-numerical compare.  If you google "TrueCrypt requires Mac OS X or later," that will bring you to this page, I verified, since the link is crazy.  I didn't want to create a bit.ly link for this.  And because I will get this on my page soon.  If you google "TrueCrypt requires Mac OS X or later," those are words from the crazy URL.  And so Google found it.  It'll take you to the page.  And it's just a trivial change to one file in the installer that performs that check and normally rejects you.  And then you're able to keep using TrueCrypt 7.1a for as long as you want.



Okay, Leo, miscellany.  Hook.  The puzzle you hooked me on a week ago.



LEO:  I can't believe you've finished it already.  You were...



STEVE:  Oh, instantly.  I finished it in a day and was very disappointed that, when I finished level 50, 50...



LEO:  Oh.  See, I'm almost there.  I didn't realize that's all there were.



STEVE:  That's all there was.  Now, I'm in dialogue with the author.



LEO:  Oh.



STEVE:  Because this thing is too good for it not to continue.  It is just - it's just wonderful.



LEO:  It's so great that you love it so much.  That's so great.



STEVE:  I'm just - it's the definition of a perfect relaxing puzzle.  And that's what - the comments that people have had is generally that.  Basically it's sort of a graphical kind of wiring combinatorial puzzle.  You're playing the video on his site.  And that's at PlayTheHook.com.  So for people who don't know, it's 99 cents.  It's iOS, Android, or Windows Phone.  The guy first did an HTML5 version over at Kongregate.  And in fact, if you go to PlayTheHook.com, Leo, yup, there it is.  So there's his HTML5 version.  And that is workable.  It runs.  You can click that and start playing.  And it's interesting because this one has additional features, widgets, that his doesn't.  And so I'm very much hoping that this is going to be - he's a neat kid.  I can't remember...



LEO:  He's a kid?



STEVE:  Yeah.  He dropped out of college or university.  And he has another one that is my worst nightmare kind of game, where it's twitch and reflex and...



LEO:  Yeah, I like this because you have as long as you need to solve it.



STEVE:  Yes.  There's no timing base. You can just sit there and sort of study it.  And there are - you can solve it in a minimum number or just sort of be a little more relaxed.



LEO:  Yeah, that's kind of fun is to kind of go back and see if you could do it in fewer moves.



STEVE:  Yes, because many of them you can have multiple things happening at once.



LEO:  Right.



STEVE:  Which you can or cannot bother to do.  So anyway, all I want from him is more because it's just wonderful.  But so I wanted to let our listeners know, if you're not hooked on the idea to spend 99 cents, go to PlayTheHook.com, then follow the link to Kongregate, where you can actually play it, although you do have to turn every JavaScript thing on you've ever seen.



LEO:  It's not the Flash, though; right?  It's JavaScript.



STEVE:  No, it's not.  It's JavaScript.  But it took me a half an hour of enabling NoScript to finally get all the pieces.



LEO:  That's so funny.  That's probably because of all the stuff around it, too; right?



STEVE:  Yeah, yeah, exactly.



LEO:  A lot of ads on it and stuff.



STEVE:  Yeah.  But if you go a little further, you might see something you've never seen before.  He's got like a rotating circle with a chunk taken out of it.  And I haven't gotten to it yet.  Anyway, so he has some ideas that are a little bit off of the theme of there being no timing.  He introduces that.  I don't care what he does.  I just want more because it was just - it was very enjoyable.  So for anyone who likes the idea of a calm puzzle, I got a lot of positive feedback from our talking about it last week.



LEO:  These look like all new levels.  I don't recognize these levels.



STEVE:  Oh, yeah, these are not from his - basically this HTML5 version did so well, and it got such good, positive feedback, that he decided to take it to a full commercial app and implement it that way.



LEO:  I hope he's doing well because it's nice.  And it's original, which is kind of fun.  You played Blek; right?  We showed you Blek.



STEVE:  Yes.



LEO:  This is like Blek.



STEVE:  And I did it a little bit, and then I thought I was well named.



LEO:  Ah.



STEVE:  So, yeah, that one didn't grab me.  This one, I like the idea of just sort of being able to stare at it.  You sort of say, okay, now, that one's going to come out first, so follow that line around.  And I've got to switch that one here, then I've got to press that.  It's just - it is very enjoyable.  So I wanted to make sure that people knew, just as a follow-up on our discovery of it last time.  You keep doing that because I want you to find the cool round thing.



LEO:  Okay.  And it's on iOS, Android, and Windows Phone, which is great.



STEVE:  Yes.  I did talk about the Apple Watch already.  I mistakenly thought that the band, the $300 band could be too small for someone.  But you explained that that was the woman's version, or at least the smaller person's version, and that the band for the regular watch, the larger watch, is proportionally larger.



LEO:  And Apple tells you how big it is and has a little sizer.  So you know ahead of time.



STEVE:  Yes.  They've got a beautiful sizing chart and everything.  And as you said, they're encouraging people to come in and not just press some buttons on the website and hope for the best.



LEO:  Well, now you understand why; right?  Yeah.



STEVE:  Yes.  Now, everybody knows that I've got these blinking lights behind me.  I'm trying to point to them, there.  There they are.  And that was from a relatively expensive, but also very nice, PDP-8 mini computer kit which I built years ago.  That was based on an increasingly scarce chip, which was actually an integrated one-chip PDP-8 computer.  They put the whole thing on a chip, which, you know, it sounds like a big deal, but obviously it's not because look what we put on chips now.  Anyway, a beautiful, talented designer, I want to say Germany, has developed a PDP-8/I kit, where the engine behind it is a Raspberry PI.



LEO:  It's probably faster than a PDP-8, too.



STEVE:  And, now, you need to bring this up.  I created a bit.ly shortcut.



LEO:  Okay.



STEVE:  Bit.ly/pdp8kit, all lowercase, pdp8kit.



LEO:  And appropriately, it's from Obsolescence Guaranteed.



STEVE:  Yes.  Bring up a picture of it, Leo.  The guy has done an incredible job, and he's offering the kits for sale for less than $200.



LEO:  What?



STEVE:  You have to provide your own Raspberry PI.



LEO:  Well, that's 35 bucks, so that doesn't add a lot.



STEVE:  So maybe it's - I think the link's a little bit lower down, the information about it.  Nope, not there.  Like in that second group of links on the page, I think, right - nope.  Yeah, that one.



LEO:  Get one?



STEVE:  Below, that one.



LEO:  Get one.



STEVE:  Nope.



LEO:  I'll find it.  I'll keep looking.



STEVE:  It's at the top of the - there you go, that's the one.  No, no, no, lower.  Okay.  In that last group.  The first button of the last group.  There you go.



LEO:  PIDP-8/I.



STEVE:  Oh, no?  Shoot.  Well, okay.  Go ahead.  We have to show it because it's intoxicating.  Whereas the PDP-8 only had two rows of lights, this thing...



LEO:  No, more?



STEVE:  ...shows all of the different registers.



LEO:  There you go.  Here's the front part, anyway.  All the registers are lights on the screen, on the front.



STEVE:  Why, how are we not seeing it?



LEO:  Oh, they've hidden it away somewhere.  All right.  Keep talking.  I'll find it.  Here's something.  Is this it?  That's it.  It's the very first...



STEVE:  Yay, there it is.  Oh, the very first link.



LEO:  Yeah.



STEVE:  Look at it.  I mean, it's just - it is gorgeous.  So life-size, acrylic panel, painted switches, in a beautiful case, less than $200, because...



LEO:  Is there a lot of soldering involved?  No, because...



STEVE:  Oh, well, yeah, there's a lot of, like, individual little LEDs that need to be soldered into the circuit board.  But one of your minions - you have minions, Leo.



LEO:  Hey, Minion.



STEVE:  A minion.  Get a minion.



LEO:  Get a minion in here.



STEVE:  Anyway, less than $200.  I think it's like 186.  The more orders he gets, the lower his price will be.  He knows all about me, and he spent a lot of time over on my PDP-8 pages, looking at my project.  But, I mean, look at that front panel.  Oh, my goodness.  No one...



LEO:  So are these silkscreened?  Do we know how he's doing this?



STEVE:  Yes, silkscreen, multilayer silkscreen with a blackout mask behind.



LEO:  Nice.  And is that wood, I supply the wood case, or...



STEVE:  I don't know. 



LEO:  Yeah.



STEVE:  So our listeners need to - I'm sure that he's able to supply that.  I don't know whether you have to pay more for that.  Anyway, I wanted everyone - many people were interested, but they were put off by the high price of these guys that I did.  You have to supply a Raspberry PI, but what's that, 40 bucks or something.



LEO:  Thirty-five bucks, yeah.



STEVE:  Yeah.  And so...



LEO:  You know what's hysterical is - oh, look, he does have some prebuilt.  So that's...



STEVE:  Well, I'm worried about that.  He's offering them prebuilt.  He's going to get a landslide of people.  And he's just - I don't know how he's going to build them all.  I don't think he understands what the demand will be.  He and I are in a dialogue.  I told him watch out.  And when I tweeted it yesterday, he started getting, like, three per hour, where nothing was happening before.  And I said, "Well, I'm going to talk about this on the podcast tomorrow."  And I said, "I created a short link for you, bit.ly/pdp8kit."  So I need three more of these because they go with the - because look how many more lights they have.  I've just got to make all those lights blink, Leo.



LEO:  That is sweet.  Now, we should warn people, this doesn't do anything you want to do.



STEVE:  Well, it...



LEO:  It's not like - it's just a pretty thing.



STEVE:  No, it will run the OS/8 operating system, which was written for the 8.  And it's based on a famous emulator.  There's a sim, I can't remember the name, there's a simulator for many of these old machines that has been written.  This is based on that.



LEO:  So you're really running a simulator on the PDP-8, an emulator.



STEVE:  So, for example, you can connect a terminal to it and write BASIC and write FOCAL, which was the DEC language, or run...



LEO:  Wow, that's kind of cool.



STEVE:  ...the assembler and editor.  And, I mean, this is where I cut my teeth was literally writing assembly language, machine language, for the PDP-8, with those tools.



LEO:  Wow.  Wow.



STEVE:  So anyway, this brings the price of doing that way down and creates like a little museum piece in the process.  So I wanted everyone to know.  Anyone who felt like they couldn't get one of these cool little guys that I've got blinking behind me.  And I will, of course, write some software for the big one so that it does the same sort of thing.



LEO:  The kit does come with two wooden mount blocks.  So I think you get everything you need.  You do have to supply...



STEVE:  I see the case above it, at the top of the picture.



LEO:  Yeah.  You do have to supply a Raspberry PI Model A+, B+, or 2.  Although he says the $21 model A+ is recommended.  And then you need an SD card of 4GB or larger.  You could put a USB hub on it.



STEVE:  If you can get one that small.



LEO:  And a micro USB WiFi adapter.  What?  Can I surf the 'Net on my PDP-8 using links?  I can't wait.



STEVE:  So I just wanted to say that one of my very favorite shows finished its third season, and that's "The Americans" on FX.



LEO:  I know you love this show.



STEVE:  Oh, my lord.  I just, for what it's worth, if you get to a point in the upcoming summer that you're looking for something, it's the story of two Russians who come over and take up residence and raise a family in Washington, D.C., in the shadow of the Washington Monument, and get up to no good.  And now their teenage daughter has begun to suspect that something fishy is going on because her parents are not acting, like, you know, the phone rings, and they leave at all hours.  And so she begins to recognize - anyway, I just - I don't want to do a spoiler.  But the way this ended, this third season, makes the whole thing worthwhile so far.  So for what it's worth, people have appreciated my opinion on these things before, so I just want to share one because I got one.  And it is that "The Americans" is really worthwhile.  And what's her name, Felicity is how I always know her, Keri Russell...



LEO:  Oh, I love Keri Russell, yeah.



STEVE:  Yeah, and she...



LEO:  She's great in this, yeah.



STEVE:  The acting is phenomenal.  I mean, this is one of those really good cable-produced shows.  Top recommendation.



And I talked last week or the week before about how I could not find the screenshot that someone had sent me for SpinRite.  And then I found it in my Twitter feed because he had tweeted it to me.  And so I wanted to just show it.  So what I liked about this was his tweet was - and this is Sean McCormack, who said, "Thank you @SGgrc!" with a big exclamation point.  And all of those green R's mean "recovered."  And in order for - and all the little blues mean there was nothing wrong.  Which is to say that, wherever there's a green R - and there's how many, there's like 10 of them.  Wherever there's a green R, and it's only about, what, maybe, not quite, it was not halfway through, maybe a little over a third through, that means that that was a sector where the software, any software said I want to read that, and the drive said sorry, can't give it to you.



Now, normally that's where it ends.  That's it.  Game over.  Not if you're running SpinRite.  So those green R's mean that when the drive refused to give up its data easily, SpinRite went to work and essentially bore down and did all kinds of tricks, playing with a set of commands that are not normal data transfer commands, but can be used for data recovery.  And this was stuff I developed years ago and have been refining a little bit along the way such that, in order to earn a green R, one or more sectors that fit within that space on the map, sometimes there's multiple sectors because they kind of tend to die in groups, have had 100% data recovery, meaning that we got all of the data and confirmed it was the original data that was written.  Maybe we rewrote it back to the sector and then verified that we could now read it properly, so that anybody can now.  Or maybe, in the process, the drive said, wow, this sector's in bad shape, and put in a spare.  And then we rewrote the final data back into the spare.



Anyway, many people haven't actually seen what this looks like, but this was a beautiful case where this drive was in bad shape, and SpinRite has 100% recovery of many, at least 10, different spots where it was completely unreadable.  It was just, sorry, error.  You can't have your data there.  That's SpinRite.



LEO:  Pretty good.  All right.  I've got questions for you, Steven.  All right.  Let me open up the questions here because we've got some for you.  And I'm ready to read them if you're ready to answer them.



STEVE:  Yup.



LEO:  Numero uno, Bobby in Idaho.  He appears to be a troublemaker.  He wants more on, get this, brute-forcing encryption.  Sure, Bobby.  We'll tell you everything.  Steve's glad to help out.  In Episode 501 you explained how you know when you've successful brute-force broken encryption.  Because it's actually checking against the authentication.  So if encryption doesn't authenticate, how would you brute force it?  Hmm, hmm, hmm?



STEVE:  Okay.  So I answered a listener's question a couple weeks ago on this question.  And I explained that proper encryption is always then wrapped with a layer of authentication because there are many ways to mess with encryption if it is not authenticated, that is, if the attacker is allowed to make a change, even to the encrypted data, there are well-known available attacks that can produce trouble.  So you authenticate what looks like noise because it's encrypted.  It'll be maximum entropy.  You authenticate it separately to prevent from ever considering it valid if it's been changed.  Thus you know when you're brute forcing, you know when authentication works that you have found the right password.



So Bobby's saying, okay, if you don't have that outer authentication wrapper, then what?  Okay?  And the answer is heuristics.  You literally look at what the output is from a test key and see whether it could possibly be correct.  It's a little bit like what Turing did with the Bombe and decrypting the Enigma machine because it was looking for possible solutions.  So the machine would stop when the constraints that they had imposed on it were met, and then they would look.



So, for example, say that this is, again, if you're decrypting something, you typically know what it is.  For example, say it's email.  Okay, email in a language, and you know what the language is going to be, is going to have, when it's decrypted, some very definable characteristics.  For example, ASCII is a seven-bit code in an eight-bit byte.  So the high bits will all be off.  Now, the chance of using the wrong key and misdecrypting something such that a chunk of it comes out wrong, but with all the high bits off, is vanishingly small.



So a perfect example is you simply decrypt the first block of the cipher text using every possible key, checking just to see, given that you know that it's ASCII, given, you know, checking to see that all the high bits are off in your decrypted result.  If not, you know it cannot be the right key.  If they are off, then you can be a little more sure by checking the next block using that same key, making sure that they, too, are all off.  At that point you pretty much know that you've got it nailed.  Then, of course, look at it and see if it makes sense.



There's some vanishingly small chance that you would get the wrong key that would produce ASCII gibberish, but with all the high bits off.  Probably won't happen.  But if that's the case, you say, oh, that's like the Bombe stopping at a code that could have been possible, but then they tried to use those settings in an actual Enigma machine with a different message from the same day to see whether it would decrypt properly.  If it did, they had it solved.  If not, they pressed "keep going" on the Bombe, and it picked up where it left off.  So basically, brute force without authentication means you just have to brute force.  Which means you look at each output and apply some heuristic to say, could this be possible?  And if it could be, then it stops, and then someone human looks at it and goes, uh, no, keep going; or, yeah.



LEO:  You'll know.



STEVE:  Yeah, exactly.  You'll know.



LEO:  You'll know.



STEVE:  You'll know when you get it right.



LEO:  I love that seven-bit in an eight-bit byte because, I mean, that's great.  That could be done by a computer very quickly.



STEVE:  Yup.



LEO:  And do we see any eight-bit set?  No?  Okay.



STEVE:  Got it.



LEO:  Question 2, Brian Tillman in Wyoming, Michigan - by the way, that'd be a fun exercise, is what would be a quick and simple effective test against various kinds of data to know you've done the brute force correctly.  Wouldn't that be fun?



STEVE:  Yes.



LEO:  Kind of like a little puzzle?  Brian Tillman in Wyoming, Michigan is haunted - haunted, I tell you - by the idea of malware in disk drives:  Back in Episode 496 or '7, you related evidence that had been found outside of disk drive firmware of malware that deliberately alters said firmware to malicious ends.  Following up in the Q&A later you elaborated how it was not practically possible to know whether a drive's firmware had been infected so.



But drives are usually made in countries whose governments are extremely interested in learning U.S. business secrets.  I see these devices - hard drives, flash drives, memory cards - as a great way to implement industrial espionage.  Who knows what might be embedded in these drives, and how would we even know?  You said we wouldn't.  No one reverse-engineers the majority of these devices.  Their designs are considered closed and proprietary.  They could be collecting data or doing anything.  We wouldn't even know.  I'm haunted, too, now.  What is your answer, Steven?



STEVE:  We're in trouble.  No, you know, this is - through this podcast I have often commented how odd it is to me that, for example, the Chinese government and populace use Windows that comes from a U.S. company.  And we've talked about problems where routers were being infected, either by unknown agents or, unfortunately, by our own NSA, in transit, in order to have them modified.  I guess I'm sort of bemused.



You know, right now at this point in time we're all - the whole Trans-Pacific trade agreement is in the news, where the President is negotiating to try to figure out how we extend trade and increase opportunities.  And some of the people that we're trading with, as Brian notes, are diplomatically, politically hostile.  Yet one of the things we're doing is we're swapping hardware that we cannot see inside of, that we can't see into.  There was an article I ran across about a hand scanner that was coming from China that had malware embedded in it such that it waited until it got plugged into a certain type of system, and then infiltrated the network.  And, I mean, so this is not science fiction.  This stuff is being found.  So the problem with drives is that their firmware is not readable.  So we don't know what's in there.  And the drive manufacturers consider their firmware proprietary.



Now, maybe at some point in the future the technology will evolve to a point where we'll end up with something like open source drive firmware, the way we sort of had open source everything else occurring over time.  It used to be OSes were all closed source.  Now very good ones are open source, and so forth.  So, I mean, and that might happen because, if this becomes a big enough problem that people say, look, we're not going to buy a drive whose firmware we can't have vetted by a third party because there is just too much opportunity for real mischief.



But the fact is we're in this phase now where the value to the attacker is rapidly increasing, and our true responsible management and oversight is hugely lacking.  It's, I mean, we're taking so much on faith that this stuff is what it says it is and isn't more, and we have no way of verifying it.  I mean, I can't - of course the famous expression is "trust and verify."  Well, all we can do is one of those two.  And we really are just hoping for the best.



LEO:  There's trust in everything.  We've talked about this before.  You can't drive down the street without trusting that the other guy's not going to cross the line and slam into you.



STEVE:  Yup.  Yup.



LEO:  The problem is we're trusting people we don't know and don't trust.



STEVE:  Yes.  And at a scale.  That's the other thing, too, is if someone is suicidal and decides to take themselves out with your car, well...



LEO:  It's limited in its impact; right.



STEVE:  They've taken you out, too.  But now they're done.  Whereas, if a nation-state is able to infiltrate a vast number of networks, I mean, the problem is these things really scale, these sorts of attacks.



LEO:  Michael S. McElrath in Flint, Texas - sounds like a flinty place - worries about SSD warranty returns.  I have an issue most users may not consider when returning warranteed solid state drives:  They are prone to just quitting without any notice.  No further access is possible.  Bam.  Gone.  My dead SSD has my personal/company tax filings, my personal files including bank and credit card information and my customer files; facility layouts, production data.  In other words, crucially privacy-sensitive content.  Now it's dead.  For the $200 cost of the drive, would you return it on the assurances that they will erase any information they find?  TNO.  SSDs must be encrypted at all times, especially during the warranty period.  Thank you.  Michael in Texas.



STEVE:  So it has been my experience, and I know it's been many people's experience, that SSDs, very much like hard drives, can fail in either of two ways.  They can fail slowly, or they can just turn into a doorstop.  I have seen SSDs that just, as Michael says, just bang, they're just gone.  It stops being an SSD.  Hard drives, notoriously, if they have a head crash or the servoing mechanism dies, I mean, there are catastrophic ways for a hard drive - did I say the spindle motor just doesn't spin anymore, or the heads stick on the platter and refuse, with what's called "stiction," refuse to allow the drive to spin up.  Again, no more data coming off of that drive unless you can break that contact with the heads and the surface.



So Michael's point is, and it's a good one, is that something to consider is, if you intend to avail yourself of an SSD's warranty, there's all the more reason to apply external encryption.  He didn't mention this, but drives today will have the "security feature set," as it's called, which allows you, like typically the BIOS, to give the drive a password which will then encrypt the contents of the drive.  The problem is that can be removed at the factory.  So it's a weak solution, one that specifically, if you're worried about the factory warrantying the drive and not poking around in it, you can't use.  You need TrueCrypt or a similar add-on whole-drive encryption solution.



And so it's just something to consider, that, again, if you want to take advantage of the warranty, if you're worried that a dead drive - which of course it's not really dead.  They can certainly look at the chips and get the data off it, exactly as Michael suggests.  It's just dead to the interface for whatever reason, who knows why.  You might consider that it's worth putting your own external encryption on that drive, whole drive encryption that you add, because then it's just a drive full of noise.



LEO:  You know, people may say, well, I'm not going to worry about warranty returns on my SSD.  But you know where this really hits is on your smartphone.  Because how often, I mean, it's not unusual at all that your smartphone dies, and you bring it back to the store, and they say, "Oh, yeah, sorry, here's a new one."  Well, all your stuff's on there.



STEVE:  Right.



LEO:  So if you're using an iPhone, you're okay, right, because Apple encrypts.



STEVE:  Right, yup.



LEO:  But on Android devices, not all of them encrypt by default.  Might be good to turn that on.  Nexus 6 does, but others may not.



STEVE:  Yup, that's exactly right.



LEO:  And it's the same issue, exactly the same issue.



STEVE:  Yes, yes.



LEO:  Maybe more so.



STEVE:  And unfortunately there are a lot of immature people who would get their jollies from poking around in someone else's business.  I take great pride in the fact that I, back in the day, the early days of SpinRite, I would sometimes receive customers' drives who had problems beyond what SpinRite could do.  Their file system was messed up, and they absolutely had to have something.  I never looked in.  It just doesn't interest me, as a point of pride.  But I know that there are people who have a different approach, unfortunately, and they just get a big kick out of that.



LEO:  Question 4 comes from Andy Martin in Los Angeles.  He wants a quick message encryption tutorial:  Steve, I've been listening to Security Now! for two years.  Oh, there's your problem, Andy.  You need at least eight more years.  You understand encryption, but I'm more interested in the programming behind it.  Have you ever written a tutorial on how to implement secure messaging?  It seems so easy to do right, but it appears no one wants to take the time to do it right.  Surely there is an open source library out there that makes this easy.



This is the flow I would want:  Imagine that I manage the server, and I want no way to decrypt any messages.  Every client generates their own private key and public key.  They push the public key to the server.  Now Client 1 wants to send a message to Client 2.  The message has to be authenticated, then encrypted; right?  How can the client encrypt it so that the other client can decrypt it?  It seems that just knowing the public key is not enough because then anyone with the public key can decrypt it.  Mmm, no.  And frankly, I don't know what "encrypt with public key" even really means at the algorithmic level.  I think you need a few more years, Andy.



Anyway, then the client sends the message to the server, which routes it to the other client, who could then decrypt and magically authenticate it.  Help!  If the client ever lost their private key, they would just need to re-make a public key/private key pair and push it to the server again, losing any messages that might come while they had not yet posted their new public key.  I think he needs some help, Steven.



STEVE:  So, okay.  We have discussed this at length, and I don't want to go over the whole thing again.  I will just say that the server, as Andy notes, holds all the public keys.  And so, and the server then is, as it's called, a "key server."  So if Client 1 wants to encrypt something from Client 2, you first choose a random number.  So you need a good source of randomness, "entropy" as we call it.  And you use that as the symmetric key for encrypting the bulk because public key crypto is so slow that it's never practical to do bulk encryption with it.  Instead, you use the public key encryption only to encrypt this random key that you generated just out of thin air and used to encrypt the bulk.



So the idea is that you have, from the key server, you have the target's public key, which means that something you encrypt with their public key can only be decrypted with their private key.  So you take their public key, which you receive from the key server, use it to encrypt the key, the symmetric key that encrypted the bulk of your message.  And you could also, for example, use your private key to sign the result.  Then you send it either to the server to relay or directly to Client 2, whichever makes more sense.  Now Client 2 has it.  They get your public key from the key server, which allows them to verify the signature on it, which could only have been made by somebody having Client 1's private key.  And so they verify that.  Then they've got...



LEO:  So key understanding, fundamental concept, the public key, which can be distributed widely, freely, publicly, can be used to do two things:  to encrypt and to verify.  Right?



STEVE:  And to decrypt.



LEO:  Public key?



STEVE:  Yes, yes.  Because...



LEO:  Don't you have to have...



STEVE:  Oh, no, I'm sorry, to...



LEO:  Authenticate and encrypt.



STEVE:  ...encrypt and verify the signatures, right.



LEO:  Yeah.  That's important.  The decryption requires the private, closely held, only I have it key.



STEVE:  Exactly.



LEO:  You don't let that one out of your sight.



STEVE:  Exactly.  And so that's what Client 2 does after verifying using Client 1's public key that it actually is coming from Client 1 and has not been modified because authentication will verify that.  It'll both verify who signed it and that it has not been modified.  And then Client 2 uses their private key in order to decrypt that symmetric key, which is that random number, that big random key that Client 1 generated.  And then that they use to decrypt the message.  So that's the whole flow.



Now, because Andy's right, there's a need for a library, it has been created.  Dan Bernstein, world-famous cryptographer, has something called NaCl, which is a library.  Unfortunately, it is not broadly cross-platform, but it has been taken and extended and made absolutely cross-platform.  And that's called "libsodium."  So GitHub has libsodium, L-I-B-S-O-D-I-U-M, which is basically an API-compatible recoding to be cross-platform of Dan Bernstein's NaCl.  It has a simple API that does everything anyone wants.  It uses the state-of-the-art, efficient, elliptic curve crypto.  And it's got functions like encapsulate this message where here's the public key of the recipient, the private key of the sender, and I want you to encrypt it and authenticate it and give me the result.  It does all the work for you.  It's been heavily scrutinized.  I'm using several of the functions for SQRL, specifically the digital signature stuff because that's what we need.



Anyway, that's what you want to use, libsodium from GitHub.  And there's something also I just discovered called GitBook, which is for eBooks.  And there is a beautiful libsodium book on how to use libsodium in the GitBook.com repository.  So, and it's available in all kinds of eBook formats.  So there's no excuse.  Use that library, read that book, you'll have everything you need, Andy.



LEO:  What about OTR, Off The Record?  Because that's used often for messaging.



STEVE:  Right.  So there the requirements are different because that's a real-time protocol.



LEO:  Ah.



STEVE:  And you need to have a real-time interchange between the endpoints.



LEO:  Right.



STEVE:  This system that we just laid out is completely static.  I mean, it's very much like the original PGP model.  This approach has been around now for years.



LEO:  Right, right.  And it solves all the criteria that Andy laid out for what he wants.



STEVE:  Yup.



LEO:  And the thing is, if you share your public key, as I do, and I don't know, do you share your public key?  You should.



STEVE:  Don't have one.



LEO:  You should make one.  I'm going to send you an invite to this place, Keybase.io.  It's JavaScript based, although if you prefer you could do it at the command line.  That's what I do.  It is a way to - you know what?  It solves the problem of the key signing.  Because one of the problems with PGP is it's a self-generated key.  So you want to create a web of trust of people who've said, yes, that's Leo's key, I know that.  This kind of solves that problem.  You don't have to go to a key-signing party.  But you use your other things, like your GitHub or your Twitter or your Reddit account or your website, to validate that, yes, that's me, THE Leo Laporte.  And then on this site I've got my key.  So you can get, from this, you can actually get my public key right there and add it to your keychain.  And that way you can do two things.  Again, you can encrypt to me, not decrypt, but encrypt to me, and authenticate messages from me and say, oh, yeah, Leo sent it.  It's unchanged."



STEVE:  Yeah, I guess I just don't have the need.  I mean, I've never...



LEO:  Well, I'll tell you why you might.  Well, we talked about miniLock.  I guess you could use that. 



STEVE:  Right.



LEO:  The idea that maybe somebody would want to send you a private message.  And since you use Twitter, a public messaging system, they could use encryption to do that over Twitter.



STEVE:  Yeah.  But again, I mean, no one ever has.



LEO:  So there you go.  If you don't need it...



STEVE:  I just don't have the problem.



LEO:  ...you don't need it.



STEVE:  No.



LEO:  That solves that.  Thank you, Andy.  Jim in Grand Rapids coming up with an update on PCIE SSDs and AHCI/NVMe.  Whoa, well.  It's about time.  Actually, let's do it now.  I can't stand the suspense.



STEVE:  It's a quickie.



LEO:  It's a quickie.  Two weeks ago you had a listener question about SpinRite and SSDs on the PCI Express bus.  I know I'm the 8,000th person to point this out, but while most PCIe SSDs on the market now use the AHCI interface, the newest drives are using something called NVMe, or Non-Volatile Memory express interfaces.  Just a heads up.



STEVE:  So, yes.  Apple, in fact, is using the new NVMe on this latest MacBook because it turns out that AHCI, powerful and fast as it is, is not as fast as you can make an SSD.  That is, if you squeeze an SSD through a SATA interface, an S-A-T-A interface, they can go, what, is it 6Gbps is as fast as SATA3 will go.  But an SSD, I mean, we're inherently kind of coming from a spinning media mindset, where the SSD, solid-state disk, I mean, it's even got "disk" in its name, it sort of says, okay, there's all these disks in the world with this SATA interface.  I want to be plug-compatible with the SATA interface.  So that's the way SSDs got into the market.  And they were faster than spinning disks, but they still had this serial notion, that is, that the data would be transferred serially.  So even at 6Gbps, it turns out there's no reason for it to be serial.  Essentially, it's just RAM.  You can have it all, right now.



So what the designers - and this has been a few years in coming.  There's an Intel spec, this NVMe interface.  Essentially, whereas AHCI, the Advanced Host Controller Interface, is serial, NVMe is parallel.  You can have multiple queues.  You can ask the - I keep saying "SSD."  You can ask the NVMe interface storage device to just sort of say, you know, give it everything it has.  And it's just, blam, there you go.



So people have asked, "What about SpinRite?"  And my answer is that the way I have already designed the 6.1 that I've got running is that it is multi-interface.  And it enumerates the PCI bus to determine what's there and then uses the driver it needs.  I don't know exactly where in the cycle I'm going to do this.  6.1 adds many features.  But for compatibility, AHCI, it doesn't use the - I'm trying to think what - the Mac.  I've already got it running on the Mac keyboards, which was a problem for SpinRite.  And it will understand the GPT partition table.  I don't want to slow 6.1 down to add anything else.



So I'm committed to getting 6.1 out ASAP.  But the whole point of the 6 series is to create a foundation for 7.  So I also need to support USB natively, rather than through the BIOS.  So that has been slated for 6.2.  So I don't know where NVMe will fit.  Maybe it'll be 6.2 instead, or maybe it'll be 6.3.  But I will not stop working on SpinRite, believe me, because my goal is to catch up and have it running perfectly screaming speed on everything.  So the 6 series, which will follow one after the other, will support NVMe.  And it turns out I've already dug into it, and it's not difficult to do.  So SpinRite'll have it.



LEO:  M. Weber, who is on the move, wonders about the WiFi location confusion:  My plane from Orange County - oh, I've had this happen - landed in Dallas.  And while we were still in taxi to the gate, I pulled up a map on my Android phone to get directions from the rental car facility to my client's office.  To my shock, to my horror, the driving directions told me it would take more than 20 hours to drive there.  Once I got over my shock, I realized the map was showing my starting point in San Jose.  Then I remembered your discussion from a few weeks ago of how the location service uses the available WiFi devices to establish coordinates.  I turned off WiFi, ignored the location service's begging me to turn WiFi back on "Because it's so much more accurate with WiFi."  Hah.  And problem solved.  I guess someone's portable WiFi hotspot had been pegged as stationary.  Seems like a pretty big flaw in a system that we are more reliant on.  Thanks, Steve, for a timely and practical show.  I have an alternative explanation of that, by the way.



STEVE:  Which is that it knew where he was?



LEO:  No, that he was on the WiFi of the plane.  And often the case, especially with commercial WiFi providers, I've had this happen on cruise ships, it identifies its location as the home office.



STEVE:  Interesting.



LEO:  So he was using Boingo on the plane, Boingo WiFi, which is in San Jose.  And so it says that's where we are.  On the cruise ship, I kept going back to Venice.  I'd be in Croatia.  It was amazing.  In, like, 30 seconds I could go back and forth and back and forth.  So that's kind of not really...



STEVE:  Well, and the point I wanted to make was that this is an imperfect system.



LEO:  Yeah.



STEVE:  GPS is perfect, but we don't always have it.  And cellular...



LEO:  Yeah.  You're in a plane, dude.



STEVE:  Right.  And cellular is another means, is a more reliable means, but doesn't provide the granularity that we would like.  So what's happened is, in a classic sort of let's use a heuristic, we are doing something which could fail, much like the heuristic I suggested for brute-force cracking encryption.  It could give you a false positive.  It could be wrong.  You could get the wrong key and still by some miracle have all the high bits off.  Very unlikely, but possible.  Similarly, hotspots do move around.  So, you know, it's probably better than not using it.  But you would hope, for example, that the software would look at all the hotspots in the area and see whether, first of all, they make sense.  Like does it make sense that all of these are in the same relative proximity to each other, and then reject the one which is clearly some sort of a crazy false positive, and then go from there.  So maybe the software could have been smarter.  But it's a classic heuristic.



LEO:  Well, if you think about it, if you're in a plane, and you're enclosed in metal, you probably don't have access to other WiFi, just the plane's WiFi.



STEVE:  Right.



LEO:  GPS may not be working because you don't have line of sight to the sky.  So it's going to use what it's got, which is the location of the WiFi router, which is back in San Jose.  It doesn't - the router in the plane doesn't identify where it is.  It identifies where the Internet's coming from or whatever, where the company was.  And Boingo, of course, is in San Jose.



STEVE:  Right.



LEO:  So I think that that's probably what it was.



STEVE:  Yup, makes sense.



LEO:  It's a great conundrum.  And I bet you, as soon as it got a GPS signal, it would reject the spurious WiFi signal.



STEVE:  Yeah, yeah.



LEO:  And certainly by turning off WiFi you did that.  You said no, no, no, no.  Look and see where you are.



STEVE:  Bad information coming in here.



LEO:  Right, right.  Let's take a break, come back with more.  You have already agreed, by the way, I hope, to supply some cute little tips for The New Screen Savers?



STEVE:  Absolutely, I have.



LEO:  We can record those after the show some week and just, you know, they can be little things like, you know, turn off your whatever, WiFi, or don't, I don't know, whatever it is that you think would be important.



STEVE:  Yeah.  I'm chatting with...



LEO:  Jerry or Karsten or Lisa or...



STEVE:  A gal.  I'm blanking on her name.



LEO:  Oh, Tonya.  We have so many producers on the show.



STEVE:  I'm chatting with Tonya tomorrow morning about doing that.



LEO:  Excellent.  And then after a show some week we'll record those.  The New Screen Savers launch is May 2nd, right after the radio show, about 3:00 p.m. Pacific, 6:00 p.m. Eastern time.



STEVE:  Talk about a lot of buzz.  People are very, very excited.



LEO:  They're very happy.  Lot of buzz going on in the Comcast headquarters, too, apparently, but that's another story.  If you have an idea for the show, or we are actually looking for questions for our Help Me! segment, you can email newscreensavers@twit.tv.  And don't forget, we're going to be live, 3:00 p.m. Pacific, 6:00 p.m. Eastern time, 2200 UTC, Saturday, May 2nd.  And we decided - this is a great opportunity.  One of the reasons we're doing it, we wanted to do a variety show so we could have little tips and stuff and bits from everybody.  Our experience on New Year's Eve was what told us that.



STEVE:  How did the dry run go on Sunday?



LEO:  Great.  It's going to be a great show.



STEVE:  Yeah.



LEO:  You know, it's going to be so much fun.  Everybody's, you know, people have wanted me to do this for 10 years.  And but now we have the horsepower to do it, I think.  So I'm excited.  New Screen Savers at TWiT.  Actually, you know, it says "newscreensavers," but I think screensavers@twit.tv is actually the email.  I think this is wrong.  Do screensavers@twit.tv.  Unless we've got two addresses.



All right.  More questions for Steverino, starting with Patrick in Central Minnesota.  He wants to remove RC4.  I want it gone.  What?  In the last two podcasts, you've described the unfathomable realization that many banking sites, like Bank of America, are using the bad RC4 cipher as their main communication medium.  You also described how a browser offers a list of ciphers to the bank's server, and then it chooses one, in theory the best of the bunch, but apparently sometimes the bad one, RC4.  So can I just remove that from the list?  In fact, let's take all the weak ciphers out of the list so my browser just says, hey, I don't do that.  And then Bank of America will be forced to choose a better one.  If I can't get rid of RC4, can I configure my browser to not even mention it in the cipher list?  Seems like this would solve a lot of problems. And if a site only accepts RC4, well, I don't want to talk to it anyway.



As a side note, I've been a listener of Leo's shows since day one.  I got hooked on Leo from Tech TV until that channel went belly-up without any explanation as to why it was suddenly gone.  Oh, I could tell you some stories, my friend.  Every so often I'd google him to see what he was up to, and then one day he made his first podcast with some of the old crew.  Those first ones were kind of crazy, but his personality always carried a lot of weight on the show.  Thank you.  Wow, he's come a long way.  I'm sure glad you two found each other.  Thank you for many, many years of "netcasts," with a wink to Leo.



STEVE:  So, okay.  So first of all, I realized why banks had RC4.



LEO:  Oh, why?



STEVE:  First in the list.  Not quite as unfathomable as I had been saying.



LEO:  Probably has something to do with IE6 or something.



STEVE:  Actually, it has to do with some of the attacks that we found, like BEAST.



LEO:  Ah.



STEVE:  Which were attacks on the block ciphers.  Block ciphers like, well, any of the block ciphers, like AES, use some sort of a mode like cipher block chaining mode.  And as we've covered on the podcast, various little nicks have appeared in those, where if the attacker has access to the communications and can generate lots of bandwidth, there are games that they can play that the block cipher modes are specifically vulnerable to, BEAST being the first one.  And our listeners who've been with us the longest will remember when BEAST was revealed, the recommendation was move RC4 to the top of the list.



LEO:  Oh.



STEVE:  Because RC4, while it's an old creaky cipher, oddly enough, there's no known attacks against it.  There was a paper maybe six months ago where the keying of RC4 was further brutalized.  But there are actually no known attacks against RC4.  Whereas now, with BEAST and then Lucky 13 and then POODLE, all of these are attacks against the block cipher.  So this sort of leaves us in a conundrum because people feel nervous about RC4.  People just don't like it because it's so simple.  It's actually one of the reasons I do like it.  And if you just warm it up further, then it scrambles up its starting state.  And then it's a fantastic, very fast cipher.  In fact, some of the original designers of RC4 have done a - have, like, fixed it.  By just making a very few changes to it, they have strengthened it.  But people are just not liking a stream cipher.  What's different is that it is a stream cipher.  It produces a pseudorandom bitstream which you XOR your plaintext with to get the ciphertext, which is different from a block cipher that takes your plaintext in chunks of bits, in blocks, and then mutates that block into a different block, and then does some fancy interblock linking in order to create the so-called "chain."



So, I mean, the dilemma we have is that we want to promote state-of-the-art stronger ciphers.  The later versions of TLS have mitigations against these block ciphers.  So people who have TLS 1.2, for example, are going to be okay.  But people who don't then have a problem.  At the same time, all the browsers quickly added mitigations, you know, prevention for like the BEAST attack.  But not everyone is known to be using the latest browser.  So what's someone to do?  Weirdly enough, there is no good solution.



Ivan Ristic over at SSL Labs is right in the middle of this because he's trying to give people a letter grade, A through F.  And he's decided that, if you use RC4, if RC4 is present, you cannot get better than a B because he wants to encourage people to remove RC4.  GRC has an A now, and we don't support the RC4 cipher.  There just is no reason to.  So what banks should do is remove it, except then the concern is that there may be some creaky old person browser something somewhere that still needs it.  I doubt that's true.  The problem is, as long as everybody is worried that removing it might break something, nobody at either end will remove it.  And then, if the bank puts it first in the list, that's what you're going to use.  At the same time, there's actually nothing wrong with using it.  There are no known attacks against it, against the cipher itself.  And the browsers have solved problems where the browser, where the client has been able to.



So we're sort of in this weird place.  For what it's worth, it looks like Windows is the only operating system that through some registry manipulation will allow you to turn off RC4.  I haven't bothered to do it, but I did some digging around.  And if you just google, like, "removing cipher suites from Windows," that will take you to a page where Microsoft explains it.  You go into the registry, you flip some bits, and your system will no longer run the RC4 cipher.  It'll just remove it from the list.  Now, Firefox won't get the benefit of that because it's got its own security suite.  Once upon a time it had a way of doing that, and they removed that.  So there's nowhere, there's no way now to take it out in Firefox.



LEO:  Ah, not so fast.



STEVE:  Oh, yeah?



LEO:  It looks like Aurora, the development edition, has added that.  In fact, "disables use of RC4 except for temporarily whitelisted hosts."



STEVE:  Nice.  Nice, nice, nice.



LEO:  So it's back, baby.  This is Aurora, is, what, the developer edition; right?



STEVE:  Nice.  So we're right on the edge of making this transition.



LEO:  If you use Firefox or Windows.



STEVE:  Yeah.



LEO:  I bet you Google and others will follow suit; right?



STEVE:  Yeah.  I think people are just getting to the point where it's like, okay, it's just time to stop using it.  And what Ivan is going to do at SSL Labs is, I think by September of this year, if you still offer it on your server, you get an F.



LEO:  Good.



STEVE:  He's going to deprecate servers this summer to a D.  And if it's still there in September, F.  It's just time to yank it because what you really want to do is just stop using it.  Just let's not use it.  Then we don't have that whole issue.



LEO:  Chatroom has also given me a link to this Microsoft security advisory update for disabling RC4.



STEVE:  Nice.



LEO:  Not sure when this went out, but it was for all versions of Windows from 7 and up.  And it gives you some information, as you said, for what to modify in the registry to completely disable RC4.



STEVE:  Yup.



LEO:  So you can do that, as you said.



STEVE:  So it can be done.



LEO:  Yup.  Good news.  Actually this - I'm really glad you had that question.  Very interesting.  Tim Trott, Marianna, Florida, continues the conversation, wonders about SSL and a shared server:  SSL requires a dedicated IP address.  I run a server at Cyberchute.com where all except e-commerce sites are on a shared IP address.  I've been assigned 16 IPs for a total of 185-plus websites.  Wow.  Will I be forced to obtain IPv6 assignments, which cost money at Rackspace, for my remaining shared IP hosted sites in order to give them each their own IP address?  Some SSL certs cost more than the retail price for hosting, so I will welcome Let's Encrypt.  That's the free thing we were talking about.



STEVE:  Yup.



LEO:  And will that require a dedicated IP?  And what will happen to self-signed certs, which I of course have never used, he says.



STEVE:  Okay.  So here is the story.  It is no longer the case that SSL requires a dedicated IP.  It used to be true because the negotiation with the certificate took place before the encrypted TCP tunnel was first used.  So what you had was an IP-to-IP connection where you were negotiating SSL and needed to verify the server's domain name.  That's why you had to have - that's why the server had to assert its certificate, its domain name, based on the IP that you were connecting to, since it wasn't until that was done that the web server could then make a query with a hosts header and say, hi, I'm hoping that I'm going to www.google.com.  So consequently, the IP address had to be bound to the certificate.  That changed with TLS.



There's something called SNI, I want to say server name - I'm blanking on the acronym, SNI, Server Name Indication.  And that is an option which has always been available, starting with TLS, which solves this problem completely.  And it was somewhat worrisome maybe five years ago.  But everybody now supports at least TLS 1.0, which is essentially SSL 3.0, but, again, has additional features.  TLS 1.0 and on allows the initial handshake from the client to the server to have an extension field saying I'm going to be connecting to www.google.com.  That is the domain name for the first time ever.  Not just the IP is in the handshake.  Which allows a multi-homed server hosting many different websites to recognize that extension field and then supply from an array of certificates that it has.  Go look up "server name indication" on Wikipedia, and you'll see a list of all the browsers and all the servers that support it at each end.  Basically, everybody supports it at each end.  So it is now something, Tim, that you are safe to use.  So you could put all your commercial sites with free certificates from Let's Encrypt behind one IP if you wanted to.



LEO:  Yay.  And an update, we were talking a little bit about the challenge we were having going HTTPS on TWiT.tv because we use so many different...



STEVE:  Caching.



LEO:  Caching, well, it's not just caching.  You know, I totaled it up.  We have a CDN, that's Cachefly.  And of course we will be pulling from that if you want to watch the video or listen to the audio on the website.  We have an API server, Apiary.  The website is served from a Node.js hosting service called Heroku.  And the API itself is served from a Drupal host called Acquia.  So at least four.  There may be others involved.  However, thank you for bringing up the issue because I did - at our scrum last week.  The next day I said to the developers...



STEVE:  What's the story?



LEO:  Yeah, hey, you think we could go HTTPS?  And they very strongly said yes, we should do that.  Matt, who's great, a really a good programmer, said, "Yeah, I strongly encourage you to do that."  And they came back, and they said, "We can do this.  It's not as hard as we thought."  You know, he said, "Let me look into it because, yeah, you're right, it raises some issues."  Not as hard as we thought.  There's some chaining or something.  And it's going to cost us another $2,000 for the time involved in doing that, which is nothing, as far as I'm concerned, 1% of the total cost, less than, and well worth it.



STEVE:  Nice, nice.



LEO:  So we will be HTTPS everywhere.



STEVE:  Yay.  Using DigiCert EV certificates.



LEO:  With a DigiCert EV, which is really neat.



STEVE:  Wonderful.  Wonderful.



LEO:  Yes, and we'll be green.  We won't just be HTTPS, we'll be green, baby.



STEVE:  Yup, baby.



LEO:  And proud of that.  So it was great.  The developers said "Yes, thank you for asking, we will do this."  Yeah, so that was good.  Joe Laba, Question 9, in Metropolitan Detroit 



says, "But, but, but..." of TrueCrypt:  Steve, apparently I missed something somewhere.  I remember you saying that there was no legal way for anyone to fork the TrueCrypt source code.  But it sounds like someone - not just one, many - are going to be doing just that.  I think it would be great, but what happened to make this possible?  It was - TrueCrypt, we did point out, is not actually open source.



STEVE:  No, it's not.  It's open license.  And people are just doing it anyway because...



LEO:  What are they going to do?



STEVE:  It's there, yeah.



LEO:  Come out of the dark and sue you?



STEVE:  Yeah, I mean, it is absolutely true, the letter of the law of the TrueCrypt license says this is yours to inspect, but not to modify.  And so they were making it available in exactly in the open source spirit that you've often talked about Leo, of we need to be able to inspect it.  And doubtless they were helped by people over the years finding problems in the source.  And look at the audit.  It found some problems.  Nothing major, but better to have found them than not, only because it didn't need to be reverse-engineered.  It was open source.  The license says you can't change it.  Well, the developers also said, and we're going away, and we're going to remain anonymous, and you're never going to find out who we are, and we're not supporting it any longer.  So people are like, well, fine, we're going to take it and keep it alive because...



LEO:  And my suspicion is the existing developers would embrace that.



STEVE:  Yes.  I think, again, there's their officially stated policy, and there's their, eh, fine, you know, we made it very clear we are disassociated with it.  Nobody come crying to us.



LEO:  They're done.



STEVE:  Yup.



LEO:  But that's a good question because we did say that.  We were talking about that.



STEVE:  Yeah.



LEO:  Last question.



STEVE:  And it's been reaffirmed.



LEO:  Robert Lowery of Kansas:  Steve and Leo, thanks for the great podcast.  I've been a listener for blah, blah, blah.  SpinRite saved my bacon, blah, blah, blah.  Fan, blah, blah, blah.  I want to turn the tables a bit and ask Leo a question:  You occasionally mention that you enjoy programming, and you're obviously able to converse with Steve about some fairly in-depth programming topics.  I'm curious what you use your programming skills to create?  What languages are you most comfortable using?  If you're going to get up to speed on a new language, how do you approach learning?  Have a great day.  Get out and grill.  Believe me, Robert, I am.  Robert in Kansas.  He's obviously a beef farmer.  Well, we know you love assembly language.



STEVE:  Yup, that's my language.



LEO:  But you're a professional programmer.  I am the farthest thing from a professional programmer.  I'm a hobbyist.  I love it.  I did write some software that was relatively widely used, but it's been many moons, 20, more than 20, almost 30 years ago, in assembly language, for the Macintosh, for the early Macintosh.



STEVE:  That's right, 68000.



LEO:  I was running a BBS, and one of the first - I wrote two things that I released to the world, open source, by the way, before there was even open source.  I just made it public domain and published the source code.  Yeah, 68000 assembler is beautiful.  But I love C.  I learned C.  And somewhere, yeah, I have my Kernighan & Ritchie right here.  This is actually - this is not the original.  The original is so beaten up that I actually bought a second copy of this.  So C was my first - BASIC was my first language on Atari.  I learned assembly, which assembly's beautiful.  I agree with you.  I love assembly.  And there's something magical about getting down to the how the machine works.



STEVE:  There's just nothing below it.



LEO:  Yeah.  And it's useful, very useful, in understanding that.  And then C I learned.  I love Forth, believe it or not, but that's when it started becoming a hobby; right?  That's when it was, like, I just collect these.  And I do collect languages.  And I have books on every possible language.  You know, once you learn C, you could pretty much learn anything.



STEVE:  Yeah.  Although Forth, Forth is a write-only language.



LEO:  Wrong.  Forth can be written so that it looks like English prose.



STEVE:  Okay.



LEO:  Because the essence of Forth is you create your own primitives out of Forth primitives.



STEVE:  True, true.



LEO:  And you can write a sentence in Forth that actually...



STEVE:  That is true.



LEO:  It was created by Charles Moore for controlling telescopes.  And I think it's still used...



STEVE:  Yeah, astronomy.



LEO:  Yeah.  But I loved it.  It was a stack-based language.  It was just wild architecture.



STEVE:  And there's, like, weird - it pops up.  Like there's something to do with a UEFI has like a Forth interpreter in it because...



LEO:  Yeah, well, Forth is good in embedded because it's compact.



STEVE:  Yes, yes.



LEO:  Very compact.  So most languages are like C, they're imperative languages.  But you go back to Forth and even earlier, you go back to Lisp, these are languages that are very different.  And so I've, believe it or not, I've been learning Lisp, as my new thing is Common Lisp.  I decided I wanted to go back to the beginning, a language as old as I am.



STEVE:  Yeah, well, and in fact Lisp in particular has a really rich heritage.  I mean, it is a...



LEO:  Oh, it's amazing.



STEVE:  And for it to have continued the way it has for so many years, I mean, because it is in a class of its own.



LEO:  And it's interesting because it actually has started to influence modern languages.  You know, everybody followed the C root.  But as time has gone by, many elements of Lisp, and that style of programming...



STEVE:  And as computers get more powerful, I mean, one of the reasons we have C is that it was written on one of the PDPs, it was written on the PDP-11, when you needed - really the whole concept was the smallest increment above assembly language that was machine independent.  So for me, that's why it's my second language is it is, well, and in fact I wrote a big chunk of SQRL in C because it needed to be cross-platform.  I implemented the GCM authenticated encryption technology.  And because there wasn't a public domain library and open source, I created one and made it available to everyone because you need that as part of SQRL.  And C was my choice for implementing it because it needed to be - I needed to offer the source.  And for it to be able to be compiled for iOS or Android, you know, the ARM platform or whatever.



But what I loved about C was these guys, they first wrote the OS in assembly language, PDP-11 assembly language.  And then they said let's recode this in something that is really, I mean, just like the smallest step away that gives us more expressability.  We can do expressions.  We can do the sorts of things, flow control that is more elegant.  And that's C.  But then again, that was because they were still dealing with very small, very low-power mini computers.  Today, we just have so much more power to do much more powerful languages, dynamic languages.



LEO:  I think, though, the point, really, is that the language - so all languages are what we call Turing complete.  They can all be made to do the same thing.  But there are some languages, for whatever reason, maybe my personality, yours, or whatever, that we just kind of get better, and we're more fluent and expressive in.  And that's what you're kind of looking for, if you're a programmer.  And I have to say Python, I love Python.  I used Perl for a long time, wrote a lot of little bits of utilities and grep stuff in Perl.  I love Ruby.  Ruby's gorgeous.  It's kind of, after Python, Ruby was the next logical step.  There's more modern languages.  Go from Google is really great for concurrency.  Each has its kind of merits.  And Haskell, there's a great book called "[Learn You a Haskell for Great Good!]"



STEVE:  That's a wacky language.



LEO:  But it's really - but it's, by the way, it's going back to Lisp.  That's what's so interesting.  So I finally said, you know what, I learned Scheme, which is a derivative in Racket.  But I want to go back and go to Common Lisp.  And, by the way, it's really fun.  And it's actually very easy to learn.



STEVE:  And it's available everywhere.



LEO:  It's free.  In fact, you know what, I'll show you, I'm using Emacs to do it because Emacs is written in Lisp.  Emacs is the programming language - or actually it's really a lifestyle more than an editor.  Richard Stallman wrote it, and he wrote it in Lisp.  But I'm using a thing called Slime, which is a mode for Lisp programming, makes it very easy.  So I'm actually in what's called a REPL, a Read Evaluate Print Loop, that lets you enter in code and execute it immediately.  In fact, you see I had a typo in here.  It dumped me out into the debugger.  This is the debugger.  You can't see it because the color contrast is bad.  But it looks fine on my screen.  And it tells me, oh, you've got a typo.  So let me go back here.  Let me go back up in my Emacs.  And the problem is this parenthesis.  So I've already entered it in, but I'm going to reenter it.  I'm going to make that a brace.  Hit return, it's going to put it back down there, it's going to execute it.  It warned me, it says you've redefined this function.  That's all right.  I'm in Emacs, executing Lisp, which is awesome.



STEVE:  Nice, yup.



LEO:  It's awesome.  And so this is an IDE, in a way, like a modern IDE, in a very old-fashioned form, in essentially command-line.  So, now, he said how do you learn?  There's some really great - the web is wonderful now.  Look for - there are series of books that teach a variety of languages.  "How to Think Like a Computer Scientist" is one, and they have every language, although it was, I think, originally Python.  And you'll find these online.  If you look at my programming folder, I have a lot of links to various places and things and ways to learn.  You should also look at "The Hard Way," "[Learn] X the Hard Way."  This is a style of teaching, and many different languages have "[Learn] X the Hard Way" books.  It's really fun.  There's a lot of - if you want to learn, of course there's Code Academy.  They teach JavaScript, which is not a bad language to learn.  You taught yourself JavaScript, Steve.  Was it hard?



STEVE:  Yup, yup.  No, it was, well...



LEO:  It's very C-like; isn't it?



STEVE:  Yeah, I've been programming forever, but, yeah.



LEO:  Yeah, but it's like C.  Well, you know what the rule about programming is, you've got to do it every day.  At least an hour or two every day.  Because then, if you don't, you have to relearn the language.  Randal Schwartz told me this.  He's a Perl guru.  Randal is such a guru...



STEVE:  That's especially true for Perl.



LEO:  Yeah.  Because you forget.  You don't do it for four days...



STEVE:  Oh, lord. 



LEO:  You've got to get the book out.



STEVE:  Yeah.  I've got the whole - GRC's news server uses a Perl frontend for adding a whole bunch of features.  I mean, that I wrote.



LEO:  You wrote it?



STEVE:  I wrote a Perl wrapper around the news server.



LEO:  Oh, respect.



STEVE:  And it does all kinds of extra stuff.  But, boy, I have to go look at my source, and I go, you know, I sort of like relearn Perl from looking at what I wrote before and go, oh, yeah, that's the way I do that.  What I would say, answering the question of how you learn a language, is start with a book and read it until you start getting antsy.  At some point you just kind of like, you start feeling like, come on, I want to get going, I want to - and then solve a problem.



LEO:  Yeah.



STEVE:  That's the key, is solve a problem.  Think of something that you want to do in that language, and put yourself about that task.  Because it is by solving a specific problem that you will then realize, oh, I'm not quite as ready as I thought.  And so basically it slaps you down a little bit.  It'll put your antsiness back in its place.  And then you'll go about finding the answers that you need for how to solve the problem.  But that's - I think that's the key.  You just can't, like, do nothing because it's just, at some point...



LEO:  No, you have to write something.



STEVE:  Yeah, exactly, you've got to create something.



LEO:  That's actually, for me, that's the biggest challenge is, oh, well, what problem should I solve?  So it's nice to have a problem to solve.  Somewhere, and I'll find it, there is a document I found once, a guy who said, "I learn a lot of languages as a professional programmer.  I have 10 things, if I want to learn a language, I have to solve these 10 problems.  And by the time I've solved all 10 in that language, that dialect, I'm fluent.  I wish I could find it.  I thought I had it in my bookmarks here, but...



STEVE:  I've also seen that.  I'm kind of like, I know...



LEO:  It was like on a news - it was a news server somewhere I saw years ago, and I copied it.  I have a PDF of it.  The other thing I'd recommend, I really recommend, and we've mentioned this before, is HTDP.org, which is designed to teach people to think about programming in a kind of a - more than just kind of get out there and write code way, kind of - this is from MIT Press.  It's free and it's online, HTDP.org.  And this actually uses a Lisp dialect called Scheme that's free and easily available.  It's a good teaching language.



STEVE:  Nice.



LEO:  But it's fun for me.  I'm not a pro; I'm too old to be a professional programmer.  I wish I had been in my youth because I love it.  But it's kind of like doing crossword puzzles.



STEVE:  What was the kid's programming language that Alan Kay did?  There was a...



LEO:  Well, he did Logo, Turtle Graphics.  But I think you're thinking of Smalltalk.  And then Scratch.



STEVE:  No, Scratch, Scratch is what I was thinking of, yes.  Logo...



LEO:  Yeah.  Scratch is a Smalltalk, yeah.



STEVE:  Logo, then Smalltalk, then Scratch was a Smalltalk variant.  And that's another...



LEO:  Scratch is still there.  A great place to go is Scratch.MIT.edu.  And Scratch is very much like that - we were talking about that Android app inventor from MIT.  It's the same exact idea where you click blocks together to make it do things.  Yeah, this is Alan Kay's, still alive, this thing.  In fact, Scratch, I think the one laptop per child is - much of the UI is written in Scratch.



STEVE:  Nice.



LEO:  Smalltalk is a great language to learn, by the way.



STEVE:  Yup, yup.



LEO:  What a good language.  And that's test-driven programming, really some really good disciplines built into Smalltalk.  And it's the original object-oriented language.  It's, see, it's fun.  You can just go on and on.



STEVE:  Yeah, there's been so much, there's so much depth and history here.



LEO:  I love it.



STEVE:  And I've often thought I would do someday what you are doing, which is just sort of decide I'm going to learn another language and pick it up.



LEO:  Really fun.  Really, really fun.  And I wanted to start, I wanted to kind of do foundational work.  And so for me, going back to Common Lisp and starting there...



STEVE:  I think that's very neat.



LEO:  ...is like tearing everything down and starting over.



STEVE:  Yup.



LEO:  It's actually quite simple.



STEVE:  And look how much fun you're having.  I mean, that's the whole point.  Have fun.



LEO:  So much fun.  Steve, we are, speaking of fun, we are done.  But always fun to do this show, learn so much from it.  And I hope you all enjoy it as much as I do.  We do Security Now! every Tuesday, right after MacBreak Weekly, about 1:30 Pacific, 4:30 Eastern time, 2030 UTC at live.twit.tv.  Please tune in.  Love it when you're in the chatroom.  It really adds to the show for me.  And then of course you can participate in other ways.  Steve is on the Twitter, @SGgrc.  You can send him questions there, or comments, or suggestions.  He reads those.  If you have questions for the show itself, you can go to GRC.com/feedback and fill out the form there.  That's the best way.  Steve also has lots of other stuff at GRC, including SpinRite, the world's best hard drive maintenance utility, a must-have.



STEVE:  It works.



LEO:  If you've got a hard drive, you need SpinRite.  It works.  You might also be interested in all the other freebies he's got there.  See, you only, really, you only pay for one thing.  Everything else is free at GRC.com, including 16Kb audio versions and the transcriptions of this show.  We offer full fidelity audio, soon to be stereo, soon to be joint stereo versions of this show.



STEVE:  Ah.



LEO:  I don't know why, but - oh, I do know, actually I do know why, and I can't say.



STEVE:  Okay.



LEO:  But a partner wants them in stereo, let's put it that way.  So we thought, well, we'll just go stereo.  So Steve will be slightly left, I'll be slightly right.  Or something.



STEVE:  Interesting.  Interesting.



LEO:  Not so much that if you were listening in one ear you wouldn't understand it.  It's just slight stereo.  A little fullness to it.  We also have video, if you want to watch.  It's a fascinating thing to watch.  You could see Steve's blinking lights from his PDP-8.  Those are all at TWiT.tv/sn, or look for Security Now! on all your favorite podcatchers and the TWiT apps and all that stuff.  Steve, always a pleasure.



STEVE:  Well, and next week the - I have read Matt Blaze's testimony that he'll be giving to Congress tomorrow.  And this is the whole issue of government's backdoor or front door or golden key or whatever.  And there are some - there's some subtlety to it, but some really good points that he makes.  And so it's my intention to share his testimony with our audience for next week's podcast.  I think everyone will find it really interesting.  And so we'll do that, and then we'll spend the rest of the podcast talking about it.



LEO:  Oh, I can't wait.



STEVE:  Yeah.  Because, I mean, this is the big, this is really the big question.  Is our legal system going to force people, force encryption technologies to have some way for law enforcement to decrypt?  The government and law enforcement desperately want it.  And everybody who understands why it's a bad idea, even those who aren't concerned about privacy, but actually understand why it's a bad idea, Matt understands it.  And he raises some points that I had never considered.  And so I think it's going to be a fascinating podcast.



LEO:  Oh, I can't wait.  Next week.



STEVE:  Yup.



LEO:  See you later, Steve.



STEVE:  Thanks, my friend.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










